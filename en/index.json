[
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/alloc/",
	"title": "Alloc",
	"tags": [],
	"description": "",
	"content": "heap.cc\nHeap::ChangeCollector(CollectorType) void Heap::ChangeCollector(CollectorType collector_type) { /*CollectorType是一个枚举变量，用于定义不同的回收器类型。collector_type_是 Heap类的成员变量，描述当前设定的回收器类型。对笔者所搭建的模拟器而言，虚拟机使用的 回收器类型为kCollectorTypeCMS。CMS是ConcurrentMarkSweep的缩写。它是标记 清除垃圾回收算法的一种。本书后续章节会详细介绍它们。此处，读者仅作简单了解即可。 */ if (collector_type != collector_type_) { collector_type_ = collector_type;//设置垃圾回收器类型  ...... switch (collector_type_) { case kCollectorTypeCC: {//CC是Concurrent Copying的缩写  ..... if (use_tlab_) {//是否使用TLAB。本例中不使用它，所以use_tlab_为false  //ChangeAllocator函数将设置内存分配器的类型  ChangeAllocator(kAllocatorTypeRegionTLAB); } else { ChangeAllocator(kAllocatorTypeRegion); } break; } case kCollectorTypeMC://MC:Mark Compact  case kCollectorTypeSS://SS:Semi-space  //GSS:改进版的SS  case kCollectorTypeGSS:{ ..... if (use_tlab_) { ChangeAllocator(kAllocatorTypeTLAB); } else { ChangeAllocator(kAllocatorTypeBumpPointer); } break; } case kCollectorTypeMS: {//MS：mark-sweep  ...... ChangeAllocator(kUseRosAlloc ? kAllocatorTypeRosAlloc : kAllocatorTypeDlMalloc); break; } case kCollectorTypeCMS: {//本例对应这种情况  ..... //kUseRosAlloc默认为true  ChangeAllocator(kUseRosAlloc ? kAllocatorTypeRosAlloc : kAllocatorTypeDlMalloc); break; } ..... } ...... } } ChangeAllocator(AllocatorType) void Heap::ChangeAllocator(AllocatorType allocator) { //current_allocator_为Heap成员变量，表示当前所设定的内存分配器类型  if (current_allocator_ != allocator) { current_allocator_ = allocator; MutexLock mu(nullptr, *Locks::runtime_shutdown_lock_); //下面这两个函数比较关键，我们来看它们  SetQuickAllocEntryPointsAllocator(current_allocator_); Runtime::Current()-\u0026gt;GetInstrumentation()-\u0026gt;ResetQuickAllocEntryPoints(); } } quick_alloc_entrypoints.cc::SetQuickAllocEntryPointsAllocator /*SetQuickAllocEntryPointsAllocator函数定义在quick_alloc_entrypoints.cc文件中。 请读者注意这个文件的文件名，它是quickallocentrypoints。ART虚拟机以机器码运行Java程序的 时候，如果涉及内存分配有关的指令（下文将介绍new instance/array机器码的处理），则需要跳 转到和内存分配有关的入口地址去执行。这些内存分配的入口地址都定义在这个quick_alloc_entrypoints.cc 文件中。 entry_points_allocator是一个静态变量，默认取值为DlMalloc，表示默认使用dlmalloc作为内存 分配器。而SetQuickAllocEntryPointsAllocator可以修改它的值。下文将见到这个静态变量的作用。 */ static gc::AllocatorType entry_points_allocator = gc::kAllocatorTypeDlMalloc; //修改entry_poionts_allocator静态变量的取值 void SetQuickAllocEntryPointsAllocator(gc::AllocatorType allocator) { entry_points_allocator = allocator; } instrumentation.cc\nInstrumentation::ResetQuickAllocEntryPoints void Instrumentation::ResetQuickAllocEntryPoints() { Runtime* runtime = Runtime::Current(); if (runtime-\u0026gt;IsStarted()) { MutexLock mu(Thread::Current(), *Locks::thread_list_lock_); //针对每一个线程对象调用ResetQuickAllocEntryPointsForThread函数。其内部将  //调用Thread的ResetQuickAllocEntryPointsForThread  runtime-\u0026gt;GetThreadList()-\u0026gt;ForEach(ResetQuickAllocEntryPointsForThread, nullptr); } } Thread::ResetQuickAllocEntryPointsForThread thread.h\nclass Thread{ ... /*每一个线程对象都包含tlsPtr_成员，而这个成员中有一个quick_entrypoints，它包含了很多入口 地址，它们在Java指令经编译得到的机器码中大量被调用。其实，它们就是机器码（也就是由Java 开发人员编写的程序逻辑）和虚拟机交互的入口。相关知识请读者回顾本书前面介绍的与虚拟机执行 有关的内容。*/ struct PACKED(sizeof(void*)) tls_ptr_sized_values { QuickEntryPoints quick_entrypoints; }tlsPtr_; void Thread::ResetQuickAllocEntryPointsForThread() { //修改tlsPtr_ quick_entrypoins结构体  ResetQuickAllocEntryPoints(\u0026amp;tlsPtr_.quick_entrypoints); } quick_alloc_entrypoints.cc::ResetQuickAllocEntryPoints void ResetQuickAllocEntryPoints(QuickEntryPoints* qpoints) { #if !defined(__APPLE__) || !defined(__LP64__)  //这个变量我们在上文中介绍过了。以笔者所搭建的模拟器为例，它的取值是kAllocatorTypeRosAlloc  switch (entry_points_allocator) { case gc::kAllocatorTypeDlMalloc: { SetQuickAllocEntryPoints_dlmalloc(qpoints, entry_points_instrumented); return; } case gc::kAllocatorTypeRosAlloc: { //entry_points_instrumented也是一个静态变量，表示是否使用辅助工具  //（instrumentation的含义），默认为false。我们不讨论它  SetQuickAllocEntryPoints_rosalloc(qpoints, entry_points_instrumented); return; } ...... } ..... UNREACHABLE(); } quick_alloc_entrypoints.cc::SetQuickAllocEntryPoints##suffix //在SetQuickAllocEntryPoints_rosalloc函数中，rosalloc是下面的suffix //所以，下面代码中pAllocObject的取值就是art_quick_alloc_object_rosalloc void SetQuickAllocEntryPoints##suffix(QuickEntryPoints* qpoints,\\ bool instrumented) { \\ if (instrumented) { ......\\ } else { \\ qpoints-\u0026gt;pAllocObject = art_quick_alloc_object##suffix; \\ ...... } \\ } //借助suffix，我们可以定义不同内存分配器所对应的artAllocObjectFromCodeXXX函数 extern \u0026#34;C\u0026#34; mirror::Object* artAllocObjectFromCode ##suffix##suffix2( \\ uint32_t type_idx, ArtMethod* method, Thread* self) { \\ ScopedQuickEntrypointChecks sqec(self); \\ .....\\略过一些其他情况的处理，感兴趣的读者可自行阅读 //AllocObjectFromCode我们在解释执行模式中见过了  return AllocObjectFromCode\u0026lt;false, instrumented_bool\u0026gt;(type_idx, method, self, allocator_type); \\ } \\ extern \u0026#34;C\u0026#34; mirror::Array* artAllocArrayFromCode##suffix##suffix2( \\ uint32_t type_idx, int32_t component_count, ArtMethod* method, \\ Thread* self) { \\ ScopedQuickEntrypointChecks sqec(self); \\ //AllocArrayFromCode我们也在上文中介绍过了  return AllocArrayFromCode\u0026lt;false, instrumented_bool\u0026gt;(type_idx,\\ component_count, method, self, allocator_type); \\ } \\ 解释执行 interpreter_switch_impl.cc\nExecuteSwitchImpl template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; JValue ExecuteSwitchImpl(.....) { ...... case Instruction::NEW_INSTANCE: { Object* obj = nullptr; Class* c = ResolveVerifyAndClinit(inst-\u0026gt;VRegB_21c(), shadow_frame.GetMethod(),self, false, do_access_check); if (LIKELY(c != nullptr)) { if (UNLIKELY(c-\u0026gt;IsStringClass())) { gc::AllocatorType allocator_type = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator(); //下面这个函数对象类的代码，请读者自行研究  mirror::SetStringCountVisitor visitor(0); //如果new一个String对象，则调用String Alloc函数  obj = String::Alloc\u0026lt;true\u0026gt;(self, 0, allocator_type, visitor);//main  } else { //如果new非String对象，则调用AllocObjectFromCode函数  obj = AllocObjectFromCode\u0026lt;do_access_check, true\u0026gt;(//main  inst-\u0026gt;VRegB_21c(), shadow_frame.GetMethod(), self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()); } } ...... break; } case Instruction::NEW_ARRAY: { int32_t length = shadow_frame.GetVReg(inst-\u0026gt;VRegB_22c(inst_data)); //如果new一个数组，则调用AllocArrayFromCode函数  Object* obj = AllocArrayFromCode\u0026lt;do_access_check, true\u0026gt;(//main  inst-\u0026gt;VRegC_22c(), length, shadow_frame.GetMethod(), self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()); ...... break; } ..... } array.h\nclass MANAGED Array : public Object { ...... private: int32_t length_;//元素的个数  /*用于存储数组元素的内容。注意，虽然first_element_元素长度是32位，但它其实只是一 块存储空间。该数组元素的个数需要根据Java层中对应数组元素所占位长来计算。比如，假设 Java层中要创建包含4个short元素的数组。那么，first_element_数组的长度就是2。 因为uint32_t为32位，而Java层short类型的位长是16,。*/ uint32_t first_element_[0]; }; string.h\nString::Alloc class MANAGED String FINAL : public Object { ..... int32_t count_; uint32_t hash_code_; uint16_t value_[0]; //value_数组才是真正存储字符串内容的地方。  ..... }; template \u0026lt;bool kIsInstrumented, typename PreFenceVisitor\u0026gt; inline String* String::Alloc(Thread* self, int32_t utf16_length, gc::AllocatorType allocator_type, const PreFenceVisitor\u0026amp; pre_fence_visitor) { //注意参数，utf16_length代表以UTF-16编码的字符个数。也就是说，一个字符占2个字节  //sizeof(String)将返回String类的大小（不包括value_数组的内容）  constexpr size_t header_size = sizeof(String); size_t length = static_cast\u0026lt;size_t\u0026gt;(utf16_length); size_t data_size = sizeof(uint16_t) * length;//计算字符串内容所需的内存大小  //计算最终所需分配的内存大小  size_t size = header_size + data_size; //size按8字节向上对齐  size_t alloc_size = RoundUp(size, kObjectAlignment); Class* string_class = GetJavaLangString(); ..... gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); //调用Heap AllocObjectWithAllocator函数分配内存,main  return down_cast\u0026lt;String*\u0026gt;( heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, true\u0026gt;(self, string_class, alloc_size,allocator_type, pre_fence_visitor)); } entrypoint_utils-inl.h\nAllocObjectFromCode inline mirror::Object* AllocObjectFromCode(uint32_t type_idx, ArtMethod* method, Thread* self, gc::AllocatorType allocator_type) { ......//我们仅考察内存分配的调用逻辑  //klass代表所要创建的对象的类。调用它的Alloc函数  return klass-\u0026gt;Alloc\u0026lt;kInstrumented\u0026gt;(self, allocator_type); } Class::Alloc //class-inl.h template\u0026lt;bool kIsInstrumented, bool kCheckAddFinalizer\u0026gt; inline Object* Class::Alloc(Thread* self,gc::AllocatorType allocator_type){ .....//我们仅考察内存分配的调用逻辑  mirror::Object* obj = heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, false\u0026gt;(self, this, this-\u0026gt;object_size_,allocator_type, VoidFunctor()); ...... return obj; } AllocArrayFromCode template \u0026lt;bool kAccessCheck, bool kInstrumented\u0026gt; inline mirror::Array* AllocArrayFromCode(uint32_t type_idx, int32_t component_count, ArtMethod* method, Thread* self, gc::AllocatorType allocator_type) { ...... return mirror::Array::Alloc\u0026lt;kInstrumented\u0026gt;(self, klass, component_count, klass-\u0026gt;GetComponentSizeShift(), allocator_type); } Array::Alloc array-inl.h template \u0026lt;bool kIsInstrumented, bool kFillUsable\u0026gt; inline Array* Array::Alloc(Thread* self, Class* array_class, int32_t component_count, size_t component_size_shift, gc::AllocatorType allocator_type) { /*下面的ComputeArraySize将根据要创建数组的元素个数（component_count决定）和元素的数据 类型（由component_size_shift间接决定可参考primitive.hComponentSizeShift函数） 来计算该数组对象最终所需要的内存大小。 */ size_t size = ComputeArraySize(component_count, component_size_shift); ...... gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); Array* result; if (!kFillUsable) {//kFillUsable默认为false  SetLengthVisitor visitor(component_count); result = down_cast\u0026lt;Array*\u0026gt;( heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, true\u0026gt;(self, array_class, size,allocator_type, visitor)); } else { ......} ...... return result; } heap(-inl).h\nAllocObjectWithAllocator /*AllocObjectWithAllocator为模板函数，包含三个模板参数： kInstrumented：和工具使用有关。我们不讨论它的情况 kCheckLargeObject：判断要分配的内存大小是否属于大对象的范围 PreFenceVisitor：一个函数对象，AllocObjectWithAllocator完成工作后会调用它。*/ template \u0026lt;bool kInstrumented, bool kCheckLargeObject, typename PreFenceVisitor\u0026gt; ALWAYS_INLINE mirror::Object* AllocObjectWithAllocator(Thread* self, mirror::Class* klass, size_t byte_count, AllocatorType allocator, const PreFenceVisitor\u0026amp; pre_fence_visitor) { //AllocObjectWithAllocator函数参数的含义都很简单，笔者不拟赘述。另外，请读者注意 //解释执行和机器码模式下调用这个函数时传入的内存器分配类型都是kAllocatorTypeRosAlloc  mirror::Object* obj; /*kCheckLargeObject为true并且ShouldAllocLargeObject返回true时，将转入 AllocLargeObject函数。ShouldAllocLargeObject判断条件我们在上文介绍 LargeObjectSpace时已经讲过，如果要分配的内存大于12KB（由Heap成员变量 large_object_threshhold_控制，默认为12KB），并且所创建对象的类型为基础数据类 型的数组或String，则属于大对象内存分配的范畴。*/ if (kCheckLargeObject \u0026amp;\u0026amp; UNLIKELY(ShouldAllocLargeObject(klass , byte_count))) { //AllocLargeObject函数将以kAllocatorTypeLOS为内存分配器的类型再次调用AllocObjectWithAllocator函数  obj = AllocLargeObject\u0026lt;kInstrumented, PreFenceVisitor\u0026gt;(self, \u0026amp;klass, byte_count, pre_fence_visitor); /*如果obj不为空，表明内存分配成功，返回obj。如果obj为空指针，则清除可能产生的异常 但还需要继续尝试分配内存。因为kAllocatorTypeLOS内存分配器没有内存可分配，但其他 类型的内存分配器（本例是kAllocatorTypeRosAlloc）可能还有内存供分配）。 */ if (obj != nullptr) { return obj; } else { self-\u0026gt;ClearException(); } } size_t bytes_allocated; size_t usable_size; size_t new_num_bytes_allocated = 0; if (allocator == kAllocatorTypeTLAB || allocator == kAllocatorTypeRegionTLAB) { //所需内存大小按8字节向上对齐  byte_count = RoundUp(byte_count, space::BumpPointerSpace::kAlignment); } /*如果使用线程本地内存资源（TLAB），则先判断线程对象（self指定）TLAB是否还有足够 内存。如果有，则直接从线程的TLAB中分配内存。注意，只有BumpPointerSpace和 RegionSpace支持TLAB。rosalloc也有线程本地内存资源，只不过名字不叫TLAB。 */ if ((allocator == kAllocatorTypeTLAB || allocator == kAllocatorTypeRegionTLAB) \u0026amp;\u0026amp; byte_count \u0026lt;= self-\u0026gt;TlabSize()) { obj = self-\u0026gt;AllocTlab(byte_count); obj-\u0026gt;SetClass(klass); ...... bytes_allocated = byte_count; usable_size = bytes_allocated; pre_fence_visitor(obj, usable_size);//调用回调对象  QuasiAtomic::ThreadFenceForConstructor(); } else if (!kInstrumented \u0026amp;\u0026amp; allocator == kAllocatorTypeRosAlloc\u0026amp;\u0026amp; (obj = rosalloc_space_-\u0026gt;AllocThreadLocal(self, byte_count , \u0026amp;bytes_allocated)) \u0026amp;\u0026amp; LIKELY(obj != nullptr)) { //如果使用rosalloc，则调用RosAllocSpace的AllocThreadLocal在self所属线程  //对应的内存空间中分配资源。上文已经对rosalloc做了详尽介绍，感兴趣的读者可自行研究这部分代码  obj-\u0026gt;SetClass(klass); .....//  usable_size = bytes_allocated; pre_fence_visitor(obj, usable_size); QuasiAtomic::ThreadFenceForConstructor(); } else { /*如果前面的if条件均不满足（并不一定说明内存分配失败，有可能是内存分配器不满足if 的条件），则调用TryToAlloce函数进行内存分配。下文将单独介绍它。 */ size_t bytes_tl_bulk_allocated = 0; obj = TryToAllocate\u0026lt;kInstrumented, false\u0026gt;(self, allocator, byte_count, \u0026amp;bytes_allocated, \u0026amp;usable_size, \u0026amp;bytes_tl_bulk_allocated); if (UNLIKELY(obj == nullptr)) { //TryToAllocate如果返回空指针，说明内存资源有点紧张，下面将调用  //AllocateInternalWithGc再次进行内存分配尝试，但该函数内部会开展垃圾回收。  //下文将单独介绍AllocateInternalWithGc函数  obj = AllocateInternalWithGc(self, allocator,.....); if (obj == nullptr) { //如果obj依然为空指针，还需要判断是否有异常发生。根据注释所言，如果上面代码执行  //过程中切换了内存分配器的类型，则obj为空并且没有待投递的异常。  if (!self-\u0026gt;IsExceptionPending()) { /*调用AllocObject。注意，这里并没有传入内存分配器类型。如上面所说，此时 内存分配器类型已经发生了变化（否则不会满足if的条件）。AllocObject将使用 新的内存分配器类型重新调用一次AllocObjectWithAllocator。 */ return AllocObject\u0026lt;true\u0026gt;(self,klass, byte_count, pre_fence_visitor); } //返回空指针，说明确实没有内存。此时一定会有一个OutOfMemory的异常等待我们  return nullptr; } } //如果代码执行到此处，说明内存分配成功  obj-\u0026gt;SetClass(klass); ...... //下面这个if代码块也和垃圾回收有关。我们后续章节再讨论它们  if (collector::SemiSpace::kUseRememberedSet\u0026amp;\u0026amp; UNLIKELY( allocator == kAllocatorTypeNonMoving)) { .... WriteBarrierField(obj, mirror::Object::ClassOffset(), klass); } pre_fence_visitor(obj, usable_size); QuasiAtomic::ThreadFenceForConstructor(); //Heap的num_bytes_allocated_成员变量保存了当前所分配的内存大小  new_num_bytes_allocated = static_cast\u0026lt;size_t\u0026gt;( num_bytes_allocated_.FetchAndAddRelaxed(bytes_tl_bulk_allocated)) + bytes_tl_bulk_allocated; } ..... /*下面的AllocatorHasAllocationStack函数将检查分配器的类型，如果分配器类型不为 kAllocatorTypeBumpPointer、kAllocatorTypeTLAB、 kAllocatorTypeRegion、kAllocatorTypeRegionTLAB中时将返回true。 PushOnAllocationStack的代码将把obj保存到self线程的对应数据结构中。详情见下文13.6.4.3节的介绍。*/ if (AllocatorHasAllocationStack(allocator)) { PushOnAllocationStack(self, \u0026amp;obj);//main  } //下面的if语句和GC有关，我们统一留待后续章节再介绍  if (AllocatorMayHaveConcurrentGC(allocator) \u0026amp;\u0026amp;IsGcConcurrent()) { CheckConcurrentGC(self, new_num_bytes_allocated, \u0026amp;obj); } ....... return obj; } Heap::TryToAllocate template \u0026lt;const bool kInstrumented, const bool kGrow\u0026gt; inline mirror::Object* Heap::TryToAllocate(Thread* self, AllocatorType allocator_type,.....) { /*TryToAllocate有一个模板参数kGrow。它的含义和Heap对内存水位线的控制有关。 后续章节我们再来介绍与之有关的内容。注意，上文AllocObjectWithAllocator调用TryToAllocate时，kGrow设置为false */ ...... mirror::Object* ret; //根据内存分配器的类型选择不同的内存分配器  switch (allocator_type) { case kAllocatorTypeBumpPointer: {//使用BumpPointerSpace  alloc_size = RoundUp(alloc_size, space::BumpPointerSpace::kAlignment); ret = bump_pointer_space_-\u0026gt;AllocNonvirtual(alloc_size); ..... break; } case kAllocatorTypeRosAlloc: {//使用RosAllocSpace  if (kInstrumented \u0026amp;\u0026amp; UNLIKELY(is_running_on_memory_tool_)) { ...... } else { /*结合上文对rosalloc分配器的介绍可知，rosalloc分配内存时会先确定一个Run，然后 从这个Run中找到空闲的slot作为最终的内存资源。如果这个Run没有空闲资源，则会先创建 这个Run（其所包含的slot都需要分配好）。虽然我们此次要分配的内存只有alloc_size 大小，但它可能会导致一个Run的内存被分配。所以，下面的MaxBytesBulkAllocated- ForNonvirtual函数返回能匹配alloc_size的slot所属的Run需要多大内存（一个Run 包含多个slot。一个slot大于或等于alloc_size）。 IsOutOfMemoryOnAllocation为Heap的成员函数，它将判断可能需要分配的内存 大小是否超过水位线。如果超过水位线，则内存分配失败。*/ size_t max_bytes_tl_bulk_allocated = rosalloc_space_-\u0026gt;MaxBytesBulkAllocatedForNonvirtual(alloc_size); if (UNLIKELY(IsOutOfMemoryOnAllocation\u0026lt;kGrow\u0026gt;(allocator_type, max_bytes_tl_bulk_allocated))) { return nullptr; } //调用RosAllocSpace AllocNonVirtual分配内存  ret = rosalloc_space_-\u0026gt;AllocNonvirtual(self, alloc_size,...); } break; } case kAllocatorTypeDlMalloc: {//dlmalloc的处理  ...... break; } case kAllocatorTypeNonMoving: { /*non_moving_space_的类型为MallocSpace*。这说明kAllocatorTypeNonMoving 并不是一种独立的内存分配算法，它只是MallocSpace的一种使用场景。从内存分配角度来 说，下面的Alloc要么由RosAllocSpace实现，要么由DlMallocSpace实现。 kAllocatorTypeNonMoving的真正作用和下一章要介绍的GC有关，我们后续碰到时再介绍 它们。 */ ret = non_moving_space_-\u0026gt;Alloc(self, alloc_size, bytes_allocated, usable_size, bytes_tl_bulk_allocated); break; } case kAllocatorTypeLOS:....//其他内存分配器类型的处理，笔者不拟赘述  case kAllocatorTypeTLAB:.... case kAllocatorTypeRegion:.... case kAllocatorTypeRegionTLAB:... ...... } return ret; } Heap::AllocateInternalWithGc mirror::Object* Heap::AllocateInternalWithGc(Thread* self, AllocatorType allocator, bool instrumented,....,mirror::Class** klass) { .... /*WaitForGcToComplete：等待GC完成（如果当前正有GC任务的话）。返回值的类型GcType 我们在7.6.2节中曾介绍过它。此处回顾如下： GcType为枚举变量，它有四种取值，对应垃圾回收力度由轻到重： (1) kGcTypeNone：没有做GC。 (2) kGcTypeSticky：表示仅扫描和回收上次GC到本次GC这个时间段内所创建的对象 (3) kGcTypePartial：仅扫描和回收应用进程自己的堆，不处理zygote的堆。这种方式和 Android中Java应用程序的创建方式有关。在Android中，应用进程是zygote进程fork 出来的。 (4) kGcTypeFull：它将扫描APP自己以及它从父进程zygote继承得到的堆。 垃圾回收时会由轻到重开展回收，以本例所设置的垃圾回收器类型kCollectorTypeCMS而言， 它会由轻到重，分别尝试kGcTypeSticky、kGcTypePartial、kGcTypeFull。 请读者注意，笔者在第14章中将介绍这几种回收策略的代码实现逻辑。*/ collector::GcType last_gc = WaitForGcToComplete(kGcCauseForAlloc, self); ..... //last_gc不为kGcTypeNone，表示系统完成了一次GC，再次尝试分配内存。注意，这次GC  //并不是由AllocateInternalWithGc发起的  if (last_gc != collector::kGcTypeNone) { mirror::Object* ptr = TryToAllocate\u0026lt;true, false\u0026gt;(self,....); if (ptr != nullptr) { return ptr; } } /*next_gc_type_表示我们要发起的GC粒度。它的取值和垃圾回收器类型有关。next_gc_type_ 的类型也是GcType。我们上文介绍过它的取值情况。 */ collector::GcType tried_type = next_gc_type_; //CollectGarbageInternal将发起GC，注意它的最后一个参数表示是否回收  //Soft Reference对象（详情见GC相关的知识）  const bool gc_ran = CollectGarbageInternal(tried_type, kGcCauseForAlloc, false) != collector::kGcTypeNone; ...... if (gc_ran) {//gc_ran为true，表示执行了一次GC。现在，再次尝试分配内存  mirror::Object* ptr = TryToAllocate\u0026lt;true, false\u0026gt;(self, ......); if (ptr != nullptr) { return ptr; } } //还是没有内存，此时，我们需要根据gc_plan_（数组），以上面代码中注释提到的CMS而言，  //该数组的内容分别是kGcTypeSticky、kGcTypePartial、kGcTypeFull。下面的for循环将  //由轻到重开展垃圾回收  for (collector::GcType gc_type : gc_plan_) { if (gc_type == tried_type) { continue; } const bool plan_gc_ran = CollectGarbageInternal(gc_type, kGcCauseForAlloc, false) != collector::kGcTypeNone; ...... if (plan_gc_ran) {//每执行一次回收就尝试分配一次内存  mirror::Object* ptr = TryToAllocate\u0026lt;true, false\u0026gt;(self,.....); if (ptr != nullptr) { return ptr; } } } //再次尝试分配内存，但需要设置TryToAllocate的kGrow模板参数为true。读者可以看看  //TryToAllocate函数的代码，对rosalloc而言，kGrow为true并没有多大用处  mirror::Object* ptr = TryToAllocate\u0026lt;true, true\u0026gt;(self, allocator,....); if (ptr != nullptr) { return ptr; } //还是没有空余内存的话，则以最强力度（gc_plan_数组的末尾元素代表最强力度的GcType），  //并且不放过soft reference对象（第三个参数为true）再做一次GC  CollectGarbageInternal(gc_plan_.back(), kGcCauseForAlloc, true); ..... ptr = TryToAllocate\u0026lt;true, true\u0026gt;(self, allocator,.....); if (ptr == nullptr) { //根据内存分配器的类型尝试做内存压缩（Compact）等操作。操作成功的话还会尝试  //内存分配。这部分内容也和GC有关，我们后续章节再介绍  .... } if (ptr == nullptr) {//设置OOM异常  ThrowOutOfMemoryError(self, alloc_size, allocator); } return ptr; } Heap::PushOnAllocationStack inline void Heap::PushOnAllocationStack(Thread* self, mirror::Object** obj) { //编译常量kUseThreadLocalAllocationStack表示是否使用线程的Allocation Stack，  //默认取值为true。  if (kUseThreadLocalAllocationStack) { /*调用Thread PushOnThreadLocalAllocationStack函数保存这个obj对象。该obj 保存在线程的Allocation Stack中。注意，该函数如果返回false，说明Allocation Stack内存不足。此时需要调用Heap PushOnThreadLocalAllocationStackWithInternalGC函数为线程分配Allocation Stack的空间。 */ if (UNLIKELY(!self-\u0026gt;PushOnThreadLocalAllocationStack(*obj))) { PushOnThreadLocalAllocationStackWithInternalGC(self, obj); } } else if ...... } inline bool Thread::PushOnThreadLocalAllocationStack(mirror::Object* obj) { if (tlsPtr_.thread_local_alloc_stack_top\u0026lt; tlsPtr_.thread_local_alloc_stack_end) { //obj存储到stack_top所指向的位置，此后递增stack_top的值  tlsPtr_.thread_local_alloc_stack_top-\u0026gt;Assign(obj); ++tlsPtr_.thread_local_alloc_stack_top; return true; } return false; //返回false，说明Allocation Stack空间不够 } void Heap::PushOnThreadLocalAllocationStackWithInternalGC(Thread* self, mirror::Object** obj) { StackReference\u0026lt;mirror::Object\u0026gt;* start_address; StackReference\u0026lt;mirror::Object\u0026gt;* end_address; /*kThreadLocalAllocationStackSize取值为128，即每个线程有能存128个Object对象 指针的空间。AtomicBumpBack的功能见上文对AtomicStack的讲解。 */ while (!allocation_stack_-\u0026gt;AtomicBumpBack(kThreadLocalAllocationStackSize, \u0026amp;start_address, \u0026amp;end_address)) { ....... CollectGarbageInternal(collector::kGcTypeSticky, kGcCauseForAlloc,false); } //设置self线程的Allocation Stack  self-\u0026gt;SetThreadLocalAllocationStack(start_address, end_address); } thread.h\nstruct PACKED(sizeof(void*)) tls_ptr_sized_values { ...... /*下面这两个成员变量的初始值为nullptr，它们标示了一段内存的起始和结束位置。代码中称 这段内存为Allocation Stack。Allocation Stack就是一个栈容器，它存储的是一组 StackReference\u0026lt;Object\u0026gt;元素。读者可以将一个StackReference\u0026lt;Object\u0026gt;实例看成一 个指向Object的指针。 */ StackReference\u0026lt;mirror::Object\u0026gt;* thread_local_alloc_stack_top; StackReference\u0026lt;mirror::Object\u0026gt;* thread_local_alloc_stack_end; ...... 机器码执行 code_generator_x86.cc\nInstructionCodeGeneratorX86::VisitNewInstance void InstructionCodeGeneratorX86::VisitNewInstance(HNewInstance* instruction) { if (instruction-\u0026gt;IsStringAlloc()) {//如果是创建String类型的对象  Register temp = instruction-\u0026gt;GetLocations()-\u0026gt;GetTemp(0).AsRegister\u0026lt;Register\u0026gt;(); MemberOffset code_offset = ArtMethod::EntryPointFromQuickCompiledCodeOffset(kX86WordSize); /*根据thread.cc InitStringEntryPoints函数的设置可知，QuickEntryPoints pNewEmptyString指向java lang StringFactory newEmptyString函数的机器码 入口地址。也就是说，如果创建String类型的对象，则会调用StringFactory类的 newEmptyString函数。 */ __ fs()-\u0026gt;movl(temp, Address::Absolute(QUICK_ENTRY_POINT(pNewEmptyString))); __ call(Address(temp, code_offset.Int32Value())); ...... } else { /*参考instruction_builder.ccBuildNewInstance函数可知，下面的GetEntryPoint返回 kQuickAllocObject或kQuickAllocObjectInitialized，它们分别对应QuickEntryPoints 结构体里的pQuickAllocObject和pQuickAllocObjectInitialized成员变量。*/ codegen_-\u0026gt;InvokeRuntime(instruction-\u0026gt;GetEntrypoint(),....); ...... } } String::Alloc //StringFactory.java public static String newEmptyString() { //newStringFromChars最终将调用下面代码所示的native函数  return newStringFromChars(EmptyArray.CHAR, 0, 0); } //最终会调用下面这个native函数 static native String newStringFromChars(int offset, int charCount, char[] data); //java_lang_StringFactory.cc static jstring StringFactory_newStringFromChars(JNIEnv* env, jclass, jint offset,jint char_count, jcharArray java_data) { ..... gc::AllocatorType allocator_type = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator(); //内部调用String Alloc函数。其内容我们在解释执行模式一节中已经介绍过了  mirror::String* result = mirror::String::AllocFromCharArray\u0026lt;true\u0026gt;( soa.Self(), char_count,char_array, offset, allocator_type); return soa.AddLocalReference\u0026lt;jstring\u0026gt;(result); } InstructionCodeGeneratorX86::VisitNewArray void InstructionCodeGeneratorX86::VisitNewArray(HNewArray* instruction) { InvokeRuntimeCallingConvention calling_convention; __ movl(calling_convention.GetRegisterAt(0), Immediate(instruction-\u0026gt;GetTypeIndex())); /*参考instruction_builder.ccProcessDexInstruction函数对NEW_ARRAY的处理， GetEntryPoint返回值为kQuickAllocArrayWithAccessCheck或kQuickAllocArray， 它们分别对应QuickEntryPoints结构体里的pQuickAllocArrayWithAccessCheck和 pQuickAllocArray成员变量。 */ codegen_-\u0026gt;InvokeRuntime(instruction-\u0026gt;GetEntrypoint(), instruction, instruction-\u0026gt;GetDexPc(), nullptr); ...... } Heap构造函数中所创建的Space 图13-9　Heap构造函数中所创建的Space (heapSize=384MB)\nHeap::Heap Heap::Heap(size_t initial_size, size_t growth_limit,... size_t capacity,size_t non_moving_space_capacity, const std::string\u0026amp; image_file_name,..... CollectorType foreground_collector_type, CollectorType background_collector_type, space::LargeObjectSpaceType large_object_space_type, size_t large_object_threshold,....){ ...... /*foreground_collector_type：当应用程序处于前台（即用户能感知的情况）时GC的类型。 此处为kCollectorTypeCMS（以后简称CMS） background_collector_type：当应用程序位于后台时GC的类型。此处为 kCollectorTypeHomogeneousSpaceCompact（以后简称HSC）。注意，这是 一种空间压缩的方法，可减少内存碎片。但需要较长时间暂停程序的运行，所以只能 在程序位于后台（用户不可见）的时候来执行。 large_object_threshold：被认定为大对象的标准。来自runtime_options.def的 LargeObjectThreshold参数，默认取值为Heap.h kDefaultLargeObjectThreshold（大小为3个内存页，此处为12KB）。*/ //desired_collector_type_取值同foreground_collector_type，本例为kCollectorTypeCMS  ChangeCollector(desired_collector_type_); //初始化live_bitmap_和mark_bitmap_成员变量，类型为HeapBitmap，读者可参考  //7.6.1.1节  live_bitmap_.reset(new accounting::HeapBitmap(this)); mark_bitmap_.reset(new accounting::HeapBitmap(this)); ...... Heap::AddSpace void Heap::AddSpace(space::Space* space) { WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); if (space-\u0026gt;IsContinuousSpace()) { //根据图13-1，除了LargeObjectSpace外，其他的Space都属于ContinuousSpace  space::ContinuousSpace* continuous_space = space-\u0026gt;AsContinuousSpace(); /*ContinuousSpace GetLiveBitmap和GetMarkBitmap是虚函数。其实现者为 ContinuousMemMapAllocSpace。而ContinuousMemMapAllocSpace定义了 live_bitmap_和mark_bitmap_两个成员变量。根据13.7.3节可知，只有DlMallocSpace 和RosAllocSpace初始化了这两个成员变量。 */ accounting::ContinuousSpaceBitmap* live_bitmap = continuous_space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = continuous_space-\u0026gt;GetMarkBitmap(); if (live_bitmap != nullptr) { /*下面的live_bitmap_和mark_bitmap_为Heap的成员变量，类型为HeapBitmap。 其详细信息可参考7.6.1.1节的内容。简单来说，下面的AddContinuousSpaceBitmap 函数将把一个位图对象加到HeapBitmap continuous_space_bitmaps_ （ContinuousSpaceBitmap数组）中去。*/ live_bitmap_-\u0026gt;AddContinuousSpaceBitmap(live_bitmap); mark_bitmap_-\u0026gt;AddContinuousSpaceBitmap(mark_bitmap); } //continuous_spaces_为Heap的成员变量，类型为vector\u0026lt;ContinuousSpace*\u0026gt;，即  //一个存储ContinuousSpace对象的数组。下面将continuous_space加到这个数组中  continuous_spaces_.push_back(continuous_space); //对continuous_spaces_数组中的元素进行排序，内存空间起始位置小的排在前面。  //图13-9中Space对象就是按这个顺序排列的（从左到右，内存起始地址由低到高）  std::sort(continuous_spaces_.begin(), continuous_spaces_.end(), [](const space::ContinuousSpace* a, const space::ContinuousSpace* b) { return a-\u0026gt;Begin() \u0026lt; b-\u0026gt;Begin(); }); } else { //处理DiscontinuousSpace，也就是唯一的LargeObjectMapSpace  space::DiscontinuousSpace* discontinuous_space = space-\u0026gt;AsDiscontinuousSpace(); //AddLargeObjectBitmap用于将位图对象加入HeapBitmap large_object_bitmaps_数组中  live_bitmap_-\u0026gt;AddLargeObjectBitmap(discontinuous_space-\u0026gt;GetLiveBitmap()); mark_bitmap_-\u0026gt;AddLargeObjectBitmap(discontinuous_space-\u0026gt;GetMarkBitmap()); //discontinuous_spaces_为Heap成员变量，类型为vector\u0026lt;DiscontinuousSpace*\u0026gt;  discontinuous_spaces_.push_back(discontinuous_space); } //如果Space可分配内存，则还需要将这个AllocSpace对象加到  //Heap alloc_spaces_数组中保存，其类型为vector\u0026lt;AllocSpace*\u0026gt;  if (space-\u0026gt;IsAllocSpace()) { alloc_spaces_.push_back(space-\u0026gt;AsAllocSpace()); } } Heap::RemoveSpace void Heap::RemoveSpace(space::Space* space) { WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); if (space-\u0026gt;IsContinuousSpace()) { space::ContinuousSpace* continuous_space = space-\u0026gt;AsContinuousSpace(); accounting::ContinuousSpaceBitmap* live_bitmap =continuous_space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = continuous_space-\u0026gt;GetMarkBitmap(); if (live_bitmap != nullptr) { live_bitmap_-\u0026gt;RemoveContinuousSpaceBitmap(live_bitmap); mark_bitmap_-\u0026gt;RemoveContinuousSpaceBitmap(mark_bitmap); } auto it = std::find(continuous_spaces_.begin(), continuous_spaces_.end(), continuous_space); continuous_spaces_.erase(it); } else { ....//类似处理，操作discontinuous_spaces_数组  } if (space-\u0026gt;IsAllocSpace()) { auto it = std::find(alloc_spaces_.begin(), alloc_spaces_.end(),space-\u0026gt;AsAllocSpace()); alloc_spaces_.erase(it); } } CardTable,Space,RememberedSet,ModUionTable的关系 图13-10　分代GC示意\nheap.cc\nHeap::Heap //构造方法 ...... static constexpr size_t kMinHeapAddress = 4 * KB; //CardTable的覆盖范围从4KB开始，到4GB结束。读者可参考图13-11 card_table_.reset(accounting::CardTable::Create(//main  reinterpret_cast\u0026lt;uint8_t*\u0026gt;(kMinHeapAddress), 4 * GB - kMinHeapAddress)); ...... if (collector::SemiSpace::kUseRememberedSet \u0026amp;\u0026amp; non_moving_space_ != main_space_) { accounting::RememberedSet* non_moving_space_rem_set = new accounting::RememberedSet(\u0026#34;Non-moving space remembered set\u0026#34;, this, non_moving_space_); /*Heap中有一个名为remembered_sets_的成员变量，其数据类型为 AllocationTrackingSafeMap\u0026lt;space::Space*,accounting::RememberedSet*,...\u0026gt;。 读者可将AllocationTrackingSafeMap看作std map。下面的AddRememberedSet函数 将把一个RememberedSet对象和它所关联的space_加入到remembered_sets_容器中。 AddRememberedSet非常简单，请读者自行阅读。*/ AddRememberedSet(non_moving_space_rem_set); } card_table(-inl).h/cc\nCardTable::Create CardTable* CardTable::Create(const uint8_t* heap_begin, size_t heap_capacity) { /*CardTable类定义了几个编译常量，如下所示： static constexpr size_t kCardShift = 7; static constexpr size_t kCardSize = 1 \u0026lt;\u0026lt;kCardShift;//kCardSize值为128 static constexpr uint8_t kCardClean = 0x0; static constexpr uint8_t kCardDirty = 0x70;*/ //计算需要多少个Card  size_t capacity = heap_capacity / kCardSize; std::string error_msg; //创建一个MemMap映射对象，其大小为capacity+256。  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map( MemMap::MapAnonymous(\u0026#34;card table\u0026#34;, nullptr, capacity + 256, PROT_READ | PROT_WRITE,...)); //下面省略了一段代码，用于计算图13-11中提到的对齐区域，见下文介绍  ...... //创建CardTable对象。biased_begin是第一个card的位置，offset是用于计算偏移量的值  return new CardTable(mem_map.release(), biased_begin, offset); } thread.cc\nvoid Thread::InitCardTable() { //Heap GetCardTable返回Heap card_table_成员变量。这说明所有线程对象共用一个  //CardTable。CardTable GetBiasedBegin函数返回这个CardTable用于存储记录的内存  //空间的起始地址。  tlsPtr_.card_table = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCardTable()-\u0026gt;GetBiasedBegin(); } CardTable::CardTable(MemMap* mem_map, uint8_t* biased_begin, size_t offset) : mem_map_(mem_map), biased_begin_(biased_begin), offset_(offset) { } remembered_set.cc\nRememberedSet class RememberedSet {//为方便讲解，代码行位置有所调整  public: //CardSet是类型别名，它是一个std set容器，key的类型为uint8_t*。一个元素代表  //CardTable中的一个Card，也就是该Card的地址保存在CardSet中  typedef std::set\u0026lt;uint8_t*, std::less\u0026lt;uint8_t*\u0026gt;,....\u0026gt;CardSet; private: //RememberedSet只有如下四个成员变量  const std::string name_;//RememberedSet的名称  Heap* const heap_; space::ContinuousSpace* const space_;//关联一个Space，读者可回顾图13-11  CardSet dirty_cards_; public: /*RemeberedSet的构造函数。代码中有几处地方会创建RememberedSet对象 (1) Heap构造函数中为non_moving_space_对象创建一个RememberedSet对象 (2) CreateMallocSpaceFromMemMap函数，为每一个通过该函数创建的MallocSpace对象创建一个RememberedSet对象。 注意，non_moving_space_虽然是MallocSpace对象，但它是由DlMallocSpace CreateFromMemMap函数创建而来，所以并不受上面第2条的影响。*/ explicit RememberedSet(const std::string\u0026amp; name, Heap* heap, space::ContinuousSpace* space) : name_(name), heap_(heap), space_(space) {} .... //RememberedSet成员函数较少，下面两个是其中最重要的成员函数，详情见下文代码分析  void ClearCards(); void UpdateAndMarkReferences(space::ContinuousSpace* target_space, collector::GarbageCollector* collector); ...... }; ClearCards void RememberedSet::ClearCards() { CardTable* card_table = GetHeap()-\u0026gt;GetCardTable(); RememberedSetCardVisitor card_visitor(\u0026amp;dirty_cards_); /*上文介绍了CardTable ModifyCardsAtomic函数的作用。此处的ClearCards函数将用到 它。其功能为扫描space_对应的card，调用AgeCardVisitor函数获取card的新值，然后 调用card_visitor函数对象。 */ card_table-\u0026gt;ModifyCardsAtomic(space_-\u0026gt;Begin(), space_-\u0026gt;End(), AgeCardVisitor(), card_visitor); } /*ModifyCardsAtomic用于修改从scan_begin到scan_end内存范围对应CardTable card的值。修改前调用模板参数visitor函数对象，visitor需要返回该Card的新值。 如果新值和旧值不同，则调用模板参数modified函数对象以通知外界。函数名中的Atomic意 为原子操作。该函数的代码不短，但难度不大。*/ template \u0026lt;typename Visitor, typename ModifiedVisitor\u0026gt; void ModifyCardsAtomic(uint8_t* scan_begin, uint8_t* scan_end, const Visitor\u0026amp; visitor, const ModifiedVisitor\u0026amp; modified); class AgeCardVisitor { public: uint8_t operator()(uint8_t card) const { //参数card就是指CardTable中的一个Card。如果它的值为kCardDirty，则返回  //0x6E（kCardDirty - 1），否则返回0。总之，card的新值不会是kCardDirty  return (card == accounting::CardTable::kCardDirty) ? card - 1 : 0; } }; class RememberedSetCardVisitor { public: explicit RememberedSetCardVisitor( RememberedSet::CardSet* const dirty_cards) : dirty_cards_(dirty_cards) {} //expected_value为card的旧值（调用AgeCardVisitor之前的值），而  //new_value为AgeCardVisitor返回的新值。此处没有用到new_value  void operator()(uint8_t* card, uint8_t expected_value, uint8_t new_value ATTRIBUTE_UNUSED) const { //如果card的值为kCardDirty，将其加入RememberedSet dirty_cards_ set容器中  if (expected_value == CardTable::kCardDirty) { dirty_cards_-\u0026gt;insert(card); } } private: RememberedSet::CardSet* const dirty_cards_; }; UpdateAndMarkReferences //遍历space_里所有存在跨Space引用的Object，然后对它们进行标记 void RememberedSet::UpdateAndMarkReferences( space::ContinuousSpace* target_space, collector::GarbageCollector* collector) { /*注意target_space的含义：UpdateAndMarkReferences将检查space_中的Object是否 引用了位于target_space空间中的Object。*/ CardTable* card_table = heap_-\u0026gt;GetCardTable(); //如果space_中的对象引用了target_space中的对象，则下面这个变量会被设置为true，  //此时它的值为false  bool contains_reference_to_target_space = false; //创建RememberedSetObjectVisitor函数对象  RememberedSetObjectVisitor obj_visitor(target_space,\u0026amp;contains_reference_to_target_space, collector); //要遍历一个ContinuousSpaceBitmap中所包含的Object，需要借助与之关联的位图对象  ContinuousSpaceBitmap* bitmap = space_-\u0026gt;GetLiveBitmap(); CardSet remove_card_set; //dirty_cards容器已经包含了space_中那些标志为kDirtyCard的card信息。  //下面的循环将遍历dirty_cards中的card  for (uint8_t* const card_addr : dirty_cards_) { contains_reference_to_target_space = false; //将card地址转换为Space中对应的那个128字节单元的基地址。读者可回顾图13-11  uintptr_t start = reinterpret_cast\u0026lt;uintptr_t\u0026gt;( card_table-\u0026gt;AddrFromCard(card_addr)); /*访问这个128字节单元中的Object，调用obj_visitor函数对象。7.6.1.1.3节SpaceBitmap的 Walk函数。VisitMarkedRange与之类似，它将访问[start，start+128)这部分位图所对应内 存空间中的Object们，每得到一个Object，就调用一次obj_visitor函数对象。VisitMarkRange 函数中有一段参考性的实现代码，读者不妨一看（笔者在13.2节中曾展示过这段代码）。 */ bitmap-\u0026gt;VisitMarkedRange(start, start + CardTable::kCardSize, obj_visitor); //如果这个128字节单元中的Object没有引用target_space中的Object，则对应的  //card区域需要从dirty_cards容器中移除。先将这个card存到临时容器  //remove_card_set中，后续将一次性移除它们  if (!contains_reference_to_target_space) { remove_card_set.insert(card_addr); } } //从dirty_cards_中移除那些不存在跨Space引用的card  for (uint8_t* const card_addr : remove_card_set) { dirty_cards_.erase(card_addr); } } class RememberedSetObjectVisitor { public: ...... //SpaceBitmap VisitMarkedRange每找到一个Object都会调用下面这个函数  void operator()(mirror::Object* obj) const { /*调用Object VisitReferences函数，传入另外一个函数对象。Object VisitReferences用于访问一个Object的引用型成员变量。想必读者已经猜到了，GC中 常说的标记（Mark）操作肯定会用到这个函数来寻找对象之间的引用关系。13.8.3节将详细 介绍此函数。 */ RememberedSetReferenceVisitor visitor(target_space_, contains_reference_to_target_space_,collector_); obj-\u0026gt;VisitReferences(visitor, visitor); } ...... }; class RememberedSetReferenceVisitor { public: ...... /*RememberedSetReferenceVisitor有多个调用函数以及回调函数。它们和Object VisitReferences的实现有关。本节仅看下面一个函数，其他几个函数的作用大同小异。 */ void operator()(mirror::Object* obj, MemberOffset offset, bool is_static ATTRIBUTE_UNUSED) const { //offset是成员变量位于obj所在内存中的位置。将其转换成对应的Object。即ref_ptr  //就是这个引用型成员变量所指向的那个Object  mirror::HeapReference\u0026lt;mirror::Object\u0026gt;* ref_ptr = obj-\u0026gt;GetFieldObjectReferenceAddr(offset); //判断target_space_中是否包含ref_ptr。如果包含，则存在跨Space的引用关系  if (target_space_-\u0026gt;HasAddress(ref_ptr-\u0026gt;AsMirrorPtr())) { *contains_reference_to_target_space_ = true; //我们后续章节再介绍MarkHeapReference函数  collector_-\u0026gt;MarkHeapReference(ref_ptr); } } //其他几个回调函数，和Object VisitReferences有关  ...... }; Object-inl.h\ntemplate \u0026lt;VerifyObjectFlags kVerifyFlags\u0026gt; inline HeapReference\u0026lt;Object\u0026gt;* Object::GetFieldObjectReferenceAddr(MemberOffset field_offset) { if (kVerifyFlags \u0026amp; kVerifyThis) { VerifyObject(this); } return reinterpret_cast\u0026lt;HeapReference\u0026lt;Object\u0026gt;*\u0026gt;(reinterpret_cast\u0026lt;uint8_t*\u0026gt;(this) + field_offset.Int32Value()); } MarkCard 发生下述依赖时，将a对应的card设置为kCardDirty\ngraph TB a(\u0026quot;a.b\u0026quot;)--\u0026gt;|引用|b 解释执行模式下，iput-object指令将触发DoFieldPut函数被调用\ninterpreter_common.cc\nDoFieldPut bool DoFieldPut(Thread* self,... uint16_t inst_data){ ...... //f是代表目标成员变量的ArtField对象  ArtField* f = FindFieldFromCode\u0026lt;find_type, do_access_check\u0026gt;(field_idx, .... Primitive::ComponentSize(field_type)); ...... switch (field_type) { case Primitive::kPrimNot: { Object* reg = shadow_frame.GetVRegReference(vregA); ...... f-\u0026gt;SetObj\u0026lt;transaction_active\u0026gt;(obj, reg); break; } ..... } //art_field-inl.h template\u0026lt;bool kTransactionActive\u0026gt; inline void ArtField::SetObj(mirror::Object* object, mirror::Object* new_value) { if (UNLIKELY(IsVolatile())) {.....} else { //调用Object SetFieldObject函数  object-\u0026gt;SetFieldObject\u0026lt;kTransactionActive\u0026gt;(GetOffset(), new_value); } } //object-inl.h inline void Object::SetFieldObject(MemberOffset field_offset, Object* new_value) { /*设置对应成员变量的值其不使用Write Barrier。其内部就是更新本Object对象 field_offset内存处的值为new_value。不熟悉Object对象内存布局的读者请阅读8.7.4.2 节的内容。 */ SetFieldObjectWithoutWriteBarrier\u0026lt;...\u0026gt;(field_offset, new_value); //只要新值不为空，都需要调用Heap WriteBarrierField函数  if (new_value != nullptr) { Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;WriteBarrierField(this, field_offset, new_value); ...... } } //heap.h ALWAYS_INLINE void WriteBarrierField(const mirror::Object* dst, MemberOffset offset ATTRIBUTE_UNUSED, const mirror::Object* new_value ATTRIBUTE_UNUSED) { /*注意，WriteBarrierField只用到第一个参数dst，它就是成员变量被赋值的那个对象，而成员变 量的新值（new_value表示）并未使用。在下面的代码中，上文Heap构造函数中已经见过card_table_ 了。而MarkCard将标记dst对应的Card标志为kCardDirty。其详情见下文的介绍。 */ card_table_-\u0026gt;MarkCard(dst); } MarkCard ALWAYS_INLINE void MarkCard(const void *addr) { /*CardFromAddr返回addr对应的Card，然后设置其值为kCardDirty。从这里也可以看出， ART虚拟机中，一个Card为一个字节（CardFromAddr返回值类型为uint8_t*）。*/ *CardFromAddr(addr) = kCardDirty; } inline uint8_t* CardTable::CardFromAddr(const void *addr) const { //由基地址加上addr右移7位（相当于除以128）以得到对应card的位置。而CardTable的基  //准位置从biased_begin_算起  uint8_t *card_addr = biased_begin_ + (reinterpret_cast\u0026lt;uintptr_t\u0026gt;(addr) \u0026gt;\u0026gt;kCardShift); return card_addr; } bool IsDirty(const mirror::Object* obj) const { return GetCard(obj) == kCardDirty; } uint8_t GetCard(const mirror::Object* obj) const { return *CardFromAddr(obj); } Object-inl.h::VisitReferences template \u0026lt;bool kVisitNativeRoots = true, VerifyObjectFlags kVerifyFlags = kDefaultVerifyFlags, ReadBarrierOption kReadBarrierOption = kWithReadBarrier, typename Visitor, typename JavaLangRefVisitor = VoidFunctor\u0026gt; void VisitReferences(const Visitor\u0026amp; visitor, const JavaLangRefVisitor\u0026amp; ref_visitor) { //klass为Object所属的类（即mirrorObject的成员变量klass）  mirror::Class* klass = GetClass\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;(); //klass是Object第一个引用型成员变量，调用visitor来访问它  visitor(this, ClassOffset(), false); //获取类的类型  const uint32_t class_flags = klass-\u0026gt;GetClassFlags\u0026lt;kVerifyNone\u0026gt;(); if (LIKELY(class_flags == kClassFlagNormal)) { /*调用VisitInstanceFieldsReferences函数访问其引用型成员变量。这个函数的实现与 我们在8.7.4.3节介绍的引用型成员变量在Object内存中的布局密切相关。我们在该节中还 展示了下面这个函数内部将要调用的VisitFieldsReferences的代码。另外，VisitInstances- FieldsReferences用于访问对象的非静态引用型成员变量。*/ VisitInstanceFieldsReferences\u0026lt;.....\u0026gt;(klass, visitor); } else {//其他类标志位的处理。  if ((class_flags \u0026amp;kClassFlagNoReferenceFields) == 0) { if (class_flags == kClassFlagClass) { //如果目标对象本身就是一个Java Class对象，则将其转换为Class对象，然后调用  //mirror Class VisitReferences函数  mirror::Class* as_klass = AsClass\u0026lt;...\u0026gt;(); as_klass-\u0026gt;VisitReferences\u0026lt;....\u0026gt;(klass, visitor); } else if (class_flags == kClassFlagObjectArray) { //如果是一个Object数组，则转换成mirror ObjectArray，调用它的  //VisitReferences函数  AsObjectArray\u0026lt;mirror::Object,.....\u0026gt;()-\u0026gt;VisitReferences(visitor); } else if ((class_flags \u0026amp;kClassFlagReference) != 0) { //如果类的类型为Java Reference的一种，则先调用VisitInstanceFieldsReferences  VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); //然后调用JavaLangRefVisitor。注意，第二个参数将目标对象转换成一个mirror  //Reference对象  ref_visitor(klass, AsReference\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;()); } else if (class_flags == kClassFlagDexCache) { //将自己转换为DexCache  mirror::DexCache* const dex_cache = AsDexCache\u0026lt;....\u0026gt;(); //调用DexCache VisitReference函数  dex_cache-\u0026gt;VisitReferences\u0026lt;...\u0026gt;(klass, visitor); } else { mirror::ClassLoader* const class_loader = AsClassLoader\u0026lt;...\u0026gt;(); //将自己转换成ClassLoader，然后调用它的VisitReferences  class_loader-\u0026gt;VisitReferences\u0026lt;...\u0026gt;(klass, visitor); } } } } Visitor和JavaLangRefVisitor示例 class VisitorAndJavaLangRefVisitor {//同时支持Visitor和JavaLangRefVisitor  /*Visitior需要重载如下所示的函数调用操作符。obj代表目标对象，offset代表目标对象中的 某个引用型成员变量在内存中的位置（读者可回顾8.7.4.2节的内容以了解Object的内存布 局），is_static表示该成员变量是否为static类型 void operator()(mirror::Object* obj, MemberOffset offset,bool is_static) const{} /*JavaLangRefVisitor需要重载如下所示的函数调用操作符。klass代表目标对象所属的类，ref 则是目标对象本身。注意，只有类的数据类型属于Java Reference的其中一种时（说明目标对象 为mirror Reference对象），下面这个函数才会被调用。注意，它并不是用来访问成员变量，而是 访问目标对象本身（将其从mirror Object转换成mirror Reference后）*/ void operator()(mirror::Class* klass, mirror::Reference* ref) const{} //下面这两个函数是Visitor必须实现的成员函数，其使用场景见下文的介绍  void VisitRootIfNonNull(mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* root) const {} void VisitRoot(mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* root) const { } ...... }; class-inl.h\nClass::VisitReferences template \u0026lt;bool kVisitNativeRoots,...,typename Visitor\u0026gt; inline void Class::VisitReferences(mirror::Class* klass, const Visitor\u0026amp; visitor) { //调用mirror Object的VisitInstanceFieldsReferences函数以访问非静态的引用型成员变量  VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); if (IsResolved\u0026lt;kVerifyFlags\u0026gt;()) { //访问静态引用型成员变量  VisitStaticFieldsReferences\u0026lt;....\u0026gt;(this, visitor); } if (kVisitNativeRoots) { //类的成员函数（对应为ArtMethod）、成员变量（对应为ArtField）均定义在mirror  //Class中。下面的VisitNativeRoots用于访问它们，来看代码  VisitNativeRoots(visitor, Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;GetImagePointerSize()); } } template\u0026lt;class Visitor\u0026gt; void Class::VisitNativeRoots(Visitor\u0026amp; visitor, size_t pointer_size) { //访问静态成员变量  for (ArtField\u0026amp; field : GetSFieldsUnchecked()) { field.VisitRoots(visitor); } //访问非静态成员变量  for (ArtField\u0026amp; field : GetIFieldsUnchecked()) { field.VisitRoots(visitor); } //GetMethods返回一个Class所定义的所有成员方法（不包括其继承得来的方法）。读者可回顾  //8.7.4.1节的内容  for (ArtMethod\u0026amp; method : GetMethods(pointer_size)) { method.VisitRoots(visitor, pointer_size); } } art_field-inl.h\nArtField::VisitRoots template\u0026lt;typename RootVisitorType\u0026gt; inline void ArtField::VisitRoots(RootVisitorType\u0026amp; visitor) { //调用函数对象的VisitRoot函数。declaring_class_是该成员变量所属的类  visitor.VisitRoot(declaring_class_.AddressWithoutBarrier()); } object_array-inl.h\nObjectArray::VisitReferences template\u0026lt;class T\u0026gt; template\u0026lt;typename Visitor\u0026gt; inline void ObjectArray\u0026lt;T\u0026gt;::VisitReferences(const Visitor\u0026amp; visitor) { const size_t length = static_cast\u0026lt;size_t\u0026gt;(GetLength()); for (size_t i = 0; i \u0026lt; length; ++i) { visitor(this, OffsetOfElement(i), false); } } dex_cache-inl.h\nDexCache::VisitReferences template \u0026lt;bool kVisitNativeRoots,..., typename Visitor\u0026gt; inline void DexCache::VisitReferences(mirror::Class* klass, const Visitor\u0026amp; visitor) { VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); if (kVisitNativeRoots) { //访问DexCache里的字符串信息。读者可回顾8.7.1.2节的内容  //GetString返回DexCache strings_成员变量  GcRoot\u0026lt;mirror::String\u0026gt;* strings = GetStrings(); for (size_t i = 0, num_strings = NumStrings(); i != num_strings; ++i) { //调用Visitor VisitRootIfNonNull函数  visitor.VisitRootIfNonNull(strings[i].AddressWithoutBarrier()); } //访问DexCache里的类型信息（DexCache resolved_types_成员变量）  GcRoot\u0026lt;mirror::Class\u0026gt;* resolved_types = GetResolvedTypes(); for (size_t i = 0, num_types = NumResolvedTypes(); i != num_types; ++i) { visitor.VisitRootIfNonNull(resolved_types[i].AddressWithoutBarrier()); } }//if判断结束 } class_loader-inl.h\nClassLoader::VisitReferences template \u0026lt;bool kVisitClasses,... typename Visitor\u0026gt; inline void ClassLoader::VisitReferences(mirror::Class* klass, const Visitor\u0026amp; visitor) { VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); if (kVisitClasses) { ClassTable* const class_table = GetClassTable(); if (class_table != nullptr) { //调用ClassTable的VisitRoots函数，内部将调用visitor的VisitRoots函数  //请读者自行阅读ClassTable VisitRoots函数的实现，非常简单  class_table-\u0026gt;VisitRoots(visitor); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/",
	"title": "alloc_gc",
	"tags": [],
	"description": "",
	"content": "alloc_gc 探索总结alloc_gc知识\n Alloc     AllocRelated     GC     GC_ConcurrentCopying     GC_MarkCompact     GC_MS_CMS     GC_Semi_Space     Runtime_VisitRoots     Space     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/allocrelated/",
	"title": "AllocRelated",
	"tags": [],
	"description": "",
	"content": "Instruction::NEW_INSTANCE ExecuteSwitchImplCpp template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; void ExecuteSwitchImplCpp(SwitchImplContext* ctx) { switch (inst-\u0026gt;Opcode(inst_data)) { case Instruction::NEW_INSTANCE: { PREAMBLE(); ObjPtr\u0026lt;mirror::Object\u0026gt; obj = nullptr; ObjPtr\u0026lt;mirror::Class\u0026gt; c = ResolveVerifyAndClinit(dex::TypeIndex(inst-\u0026gt;VRegB_21c()), shadow_frame.GetMethod(), self, false, do_access_check); if (LIKELY(c != nullptr)) { if (UNLIKELY(c-\u0026gt;IsStringClass())) { gc::AllocatorType allocator_type = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator(); obj = mirror::String::AllocEmptyString\u0026lt;true\u0026gt;(self, allocator_type); } else { obj = AllocObjectFromCode\u0026lt;true\u0026gt;( c.Ptr(), self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()); } } if (UNLIKELY(obj == nullptr)) { HANDLE_PENDING_EXCEPTION(); } else { obj-\u0026gt;GetClass()-\u0026gt;AssertInitializedOrInitializingInThread(self); // Don\u0026#39;t allow finalizable objects to be allocated during a transaction since these can\u0026#39;t  // be finalized without a started runtime.  if (transaction_active \u0026amp;\u0026amp; obj-\u0026gt;GetClass()-\u0026gt;IsFinalizable()) { AbortTransactionF(self, \u0026#34;Allocating finalizable object in transaction: %s\u0026#34;, obj-\u0026gt;PrettyTypeOf().c_str()); HANDLE_PENDING_EXCEPTION(); break; } shadow_frame.SetVRegReference(inst-\u0026gt;VRegA_21c(inst_data), obj.Ptr()); inst = inst-\u0026gt;Next_2xx(); } break; } art/runtime/entrypoints/entrypoint_utils-inl.h\nAllocObjectFromCode // Allocate an instance of klass. Throws InstantationError if klass is not instantiable, // or IllegalAccessError if klass is j.l.Class. Performs a clinit check too. template \u0026lt;bool kInstrumented\u0026gt; ALWAYS_INLINE inline mirror::Object* AllocObjectFromCode(mirror::Class* klass, Thread* self, gc::AllocatorType allocator_type) { bool slow_path = false; klass = CheckObjectAlloc(klass, self, \u0026amp;slow_path); if (UNLIKELY(slow_path)) { if (klass == nullptr) { return nullptr; } // CheckObjectAlloc can cause thread suspension which means we may now be instrumented.  return klass-\u0026gt;Alloc\u0026lt;/*kInstrumented*/true\u0026gt;( self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()).Ptr(); } DCHECK(klass != nullptr); return klass-\u0026gt;Alloc\u0026lt;kInstrumented\u0026gt;(self, allocator_type).Ptr(); } ALWAYS_INLINE inline mirror::Class* CheckObjectAlloc(mirror::Class* klass, Thread* self, bool* slow_path) { if (UNLIKELY(!klass-\u0026gt;IsInitialized())) { StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Class\u0026gt; h_klass(hs.NewHandle(klass)); // EnsureInitialized (the class initializer) might cause a GC.  // may cause us to suspend meaning that another thread may try to  // change the allocator while we are stuck in the entrypoints of  // an old allocator. Also, the class initialization may fail. To  // handle these cases we mark the slow path boolean as true so  // that the caller knows to check the allocator type to see if it  // has changed and to null-check the return value in case the  // initialization fails.  *slow_path = true; if (!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized(self, h_klass, true, true)) { DCHECK(self-\u0026gt;IsExceptionPending()); return nullptr; // Failure  } else { DCHECK(!self-\u0026gt;IsExceptionPending()); } return h_klass.Get(); } return klass; art/runtime/gc/heap.h\nAllocatorType GetCurrentAllocator() const { return current_allocator_; } art/runtime/mirror/class-inl.h\nClass::Alloc template\u0026lt;bool kIsInstrumented, bool kCheckAddFinalizer\u0026gt; inline ObjPtr\u0026lt;Object\u0026gt; Class::Alloc(Thread* self, gc::AllocatorType allocator_type) { CheckObjectAlloc(); gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); const bool add_finalizer = kCheckAddFinalizer \u0026amp;\u0026amp; IsFinalizable(); if (!kCheckAddFinalizer) { DCHECK(!IsFinalizable()); } // Note that the this pointer may be invalidated after the allocation.  ObjPtr\u0026lt;Object\u0026gt; obj = heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, false\u0026gt;(self, this, this-\u0026gt;object_size_, allocator_type, VoidFunctor()); if (add_finalizer \u0026amp;\u0026amp; LIKELY(obj != nullptr)) { heap-\u0026gt;AddFinalizerReference(self, \u0026amp;obj); if (UNLIKELY(self-\u0026gt;IsExceptionPending())) { // Failed to allocate finalizer reference, it means that the whole allocation failed.  obj = nullptr; } } return obj.Ptr(); } art/runtime/gc/heap-inl.h\nHeap::AllocObjectWithAllocator template \u0026lt;bool kInstrumented, bool kCheckLargeObject, typename PreFenceVisitor\u0026gt; inline mirror::Object* Heap::AllocObjectWithAllocator(Thread* self, ObjPtr\u0026lt;mirror::Class\u0026gt; klass, size_t byte_count, AllocatorType allocator, const PreFenceVisitor\u0026amp; pre_fence_visitor) { obj = TryToAllocate\u0026lt;kInstrumented, false\u0026gt;(self, allocator, byte_count, \u0026amp;bytes_allocated, \u0026amp;usable_size, \u0026amp;bytes_tl_bulk_allocated); Heap::TryToAllocate template \u0026lt;const bool kInstrumented, const bool kGrow\u0026gt; inline mirror::Object* Heap::TryToAllocate(Thread* self, AllocatorType allocator_type, size_t alloc_size, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { mirror::Object* ret; switch (allocator_type) { case kAllocatorTypeBumpPointer: { DCHECK(bump_pointer_space_ != nullptr); alloc_size = RoundUp(alloc_size, space::BumpPointerSpace::kAlignment); ret = bump_pointer_space_-\u0026gt;AllocNonvirtual(alloc_size); if (LIKELY(ret != nullptr)) { *bytes_allocated = alloc_size; *usable_size = alloc_size; *bytes_tl_bulk_allocated = alloc_size; } break; } case kAllocatorTypeNonMoving: { ret = non_moving_space_-\u0026gt;Alloc(self, alloc_size, bytes_allocated, usable_size, bytes_tl_bulk_allocated); break; case kAllocatorTypeTLAB: FALLTHROUGH_INTENDED; case kAllocatorTypeRegionTLAB: { DCHECK_ALIGNED(alloc_size, kObjectAlignment); static_assert(space::RegionSpace::kAlignment == space::BumpPointerSpace::kAlignment, \u0026#34;mismatched alignments\u0026#34;); static_assert(kObjectAlignment == space::BumpPointerSpace::kAlignment, \u0026#34;mismatched alignments\u0026#34;); if (UNLIKELY(self-\u0026gt;TlabSize() \u0026lt; alloc_size)) { // kAllocatorTypeTLAB may be the allocator for region space TLAB if the GC is not marking,  // that is why the allocator is not passed down.  return AllocWithNewTLAB(self, alloc_size, kGrow, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } libcore/ojluni/src/main/native/Runtime.c\nRuntime_freeMemory JNIEXPORT jlong JNICALL Runtime_freeMemory(JNIEnv *env, jobject this) { return JVM_FreeMemory(); } art/openjdkjvm/OpenjdkJvm.cc\nJVM_FreeMemory JNIEXPORT jlong JVM_FreeMemory(void) { return art::Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetFreeMemory(); } art/runtime/gc/heap.h\nheap.h::GetFreeMemory // Returns how much free memory we have until we need to grow the heap to perform an allocation. // Similar to GetFreeMemoryUntilGC. Implements java.lang.Runtime.freeMemory. size_t GetFreeMemory() const { size_t byte_allocated = num_bytes_allocated_.LoadSequentiallyConsistent(); size_t total_memory = GetTotalMemory(); // Make sure we don\u0026#39;t get a negative number.  return total_memory - std::min(total_memory, byte_allocated); }  art/runtime/class_linker.cc\nDefineClass\u0026rsquo;s Alloc ClassLinker::DefineClass mirror::Class* ClassLinker::DefineClass(Thread* self, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def) { StackHandleScope\u0026lt;3\u0026gt; hs(self); auto klass = hs.NewHandle\u0026lt;mirror::Class\u0026gt;(nullptr); // Load the class from the dex file.  if (klass == nullptr) { // Allocate a class with the status of not ready.  // Interface object should get the right size here. Regular class will  // figure out the right size later and be replaced with one of the right  // size when the class becomes resolved.  klass.Assign(AllocClass(self, SizeOfClassWithoutEmbeddedTables(dex_file, dex_class_def))); } ClassLinker::SizeOfClassWithoutEmbeddedTables uint32_t ClassLinker::SizeOfClassWithoutEmbeddedTables(const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def) { const uint8_t* class_data = dex_file.GetClassData(dex_class_def); ...... // We allow duplicate definitions of the same field in a class_data_item  // but ignore the repeated indexes here, b/21868015.  uint32_t last_field_idx = dex::kDexNoIndex; for (ClassDataItemIterator it(dex_file, class_data); it.HasNextStaticField(); it.Next()) { uint32_t field_idx = it.GetMemberIndex(); // Ordering enforced by DexFileVerifier.  DCHECK(last_field_idx == dex::kDexNoIndex || last_field_idx \u0026lt;= field_idx); if (UNLIKELY(field_idx == last_field_idx)) { continue; } last_field_idx = field_idx; const DexFile::FieldId\u0026amp; field_id = dex_file.GetFieldId(field_idx); const char* descriptor = dex_file.GetFieldTypeDescriptor(field_id); char c = descriptor[0]; switch (c) { case \u0026#39;L\u0026#39;: case \u0026#39;[\u0026#39;: num_ref++; break; case \u0026#39;J\u0026#39;: case \u0026#39;D\u0026#39;: num_64++; break; case \u0026#39;I\u0026#39;: case \u0026#39;F\u0026#39;: num_32++; break; case \u0026#39;S\u0026#39;: case \u0026#39;C\u0026#39;: num_16++; break; case \u0026#39;B\u0026#39;: case \u0026#39;Z\u0026#39;: num_8++; break; default: LOG(FATAL) \u0026lt;\u0026lt; \u0026#34;Unknown descriptor: \u0026#34; \u0026lt;\u0026lt; c; UNREACHABLE(); } } return mirror::Class::ComputeClassSize(false, 0, num_8, num_16, num_32, num_64, num_ref, image_pointer_size_); } ClassLinker::AllocClass mirror::Class* ClassLinker::AllocClass(Thread* self, uint32_t class_size) { return AllocClass(self, GetClassRoot(kJavaLangClass), class_size); } mirror::Class* ClassLinker::AllocClass(Thread* self, ObjPtr\u0026lt;mirror::Class\u0026gt; java_lang_Class, uint32_t class_size) { DCHECK_GE(class_size, sizeof(mirror::Class)); gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); mirror::Class::InitializeClassVisitor visitor(class_size); ObjPtr\u0026lt;mirror::Object\u0026gt; k = kMovingClasses ? heap-\u0026gt;AllocObject\u0026lt;true\u0026gt;(self, java_lang_Class, class_size, visitor) : heap-\u0026gt;AllocNonMovableObject\u0026lt;true\u0026gt;(self, java_lang_Class, class_size, visitor); if (UNLIKELY(k == nullptr)) { self-\u0026gt;AssertPendingOOMException(); return nullptr; } return k-\u0026gt;AsClass(); } heap.h::AllocObject // Allocates and initializes storage for an object instance. template \u0026lt;bool kInstrumented, typename PreFenceVisitor\u0026gt; mirror::Object* AllocObject(Thread* self, ObjPtr\u0026lt;mirror::Class\u0026gt; klass, size_t num_bytes, const PreFenceVisitor\u0026amp; pre_fence_visitor) REQUIRES_SHARED(Locks::mutator_lock_) REQUIRES(!*gc_complete_lock_, !*pending_task_lock_, !*backtrace_lock_, !Roles::uninterruptible_) { return AllocObjectWithAllocator\u0026lt;kInstrumented, true\u0026gt;(self, klass, num_bytes, GetCurrentAllocator(), pre_fence_visitor); } 其他 art/runtime/gc/allocator_type.h\nallocator_type.h // Different types of allocators. enum AllocatorType { kAllocatorTypeBumpPointer, // Use BumpPointer allocator, has entrypoints.  kAllocatorTypeTLAB, // Use TLAB allocator, has entrypoints.  kAllocatorTypeRosAlloc, // Use RosAlloc allocator, has entrypoints.  kAllocatorTypeDlMalloc, // Use dlmalloc allocator, has entrypoints.  kAllocatorTypeNonMoving, // Special allocator for non moving objects, doesn\u0026#39;t have entrypoints.  kAllocatorTypeLOS, // Large object space, also doesn\u0026#39;t have entrypoints.  kAllocatorTypeRegion, kAllocatorTypeRegionTLAB, }; GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(DlMalloc, gc::kAllocatorTypeDlMalloc) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(RosAlloc, gc::kAllocatorTypeRosAlloc) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(BumpPointer, gc::kAllocatorTypeBumpPointer) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(TLAB, gc::kAllocatorTypeTLAB) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(Region, gc::kAllocatorTypeRegion) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(RegionTLAB, gc::kAllocatorTypeRegionTLAB) "
},
{
	"uri": "https://huanle19891345.github.io/en/android/",
	"title": "android",
	"tags": [],
	"description": "",
	"content": "android 探索总结android知识\n jetpack    arch    databinding    Databinding      lifecycle    Lifecycle      livedata    LiveData     LiveData封装     MediatorLiveData      viewmodel    ViewModel     ViewModel封装     数据保存和恢复       supportToAndroidx      性能优化    内存优化    DumpHprof     Hprof_binary_dump_format     LeakCanary2Source     OOM       系统机制原理    ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Looper     ThreadLocal      input    touchEventNative      kernel    kernel      layoutinflater    LayoutInflater      sharedpreferences    SharedPreferences      thread    StackTraceElement     ThreadState      zygote    SystemServerSource     ZygoteSource     Zygote进程      后台任务    后台任务处理      多进程    binder    BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理      mmkv    MMKV       应用启动退出    应用启动      源码研究方法    Syscall查找方式      系统绘制    Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制       虚拟机    alloc_gc    Alloc     AllocRelated     GC     GC_ConcurrentCopying     GC_MarkCompact     GC_MS_CMS     GC_Semi_Space     Runtime_VisitRoots     Space      ART_Lock     jni    C启动Java     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常     解释执行7_0      启动流程    ART启动流程      基础数据结构     混合编译_运行    JVM_JIT     混合编译_运行      类加载    Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层      类编译    dex2oat       "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E7%B1%BB%E5%8A%A0%E8%BD%BD/android_n%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AF%B9%E7%83%AD%E8%A1%A5%E4%B8%81%E5%BD%B1%E5%93%8D%E8%A7%A3%E6%9E%90/",
	"title": "Android_N混合编译与对热补丁影响解析",
	"tags": [],
	"description": "",
	"content": "Android_N混合编译与对热补丁影响解析.md\n入口文件位于dex2oat.cc中，在这里并不想贴具体的调用函数，简单的描述一下流程：若dex2oat参数中有输入profile文件，会读取profile中的数据。与以往不同的是，这里不仅会根据profile文件来生成base.odex文件，同时还会生成称为app_image的base.art文件。与boot.art类似，base.art文件主要为了加快应用的对“热代码”的加载与缓存。\n那么我们就剩下最后一个问题，app image文件是什么时候被加载，并且为什么它会影响热补丁的机制？\n###App image文件的加载 在apk启动时我们需要加载应用的oat文件以及可能存在的app image文件，它的大致流程如下：\n 通过OpenDexFilesFromOat加载oat时，若app image存在，则通过调用OpenImageSpace函数加载； 在加载app image文件时，通过UpdateAppImageClassLoadersAndDexCaches函数，将art文件中的dex_cache中dex的所有class插入到ClassTable，同时将method更新到dex_cache; 在类加载时，使用时ClassLinker::LookupClass会先从ClassTable中去查找，找不到时才会走到DefineClass中。   非常简单的说，app image的作用是记录已经编译好的“热代码”，并且在启动时一次性把它们加载到缓存。预先加载代替用时查找以提升应用的性能，到这里我们终于明白为什么base.art会影响热补丁的机制。\n无论是使用插入pathlist还是parent classloader的方式，若补丁修改的class已经存在与app image，它们都是无法通过热补丁更新的。它们在启动app时已经加入到PathClassLoader的ClassTable中，系统在查找类时会直接使用base.apk中的class。\n最后我们再来总结一下Android N混合编译运行的整个流程，它就像一个小型生态系统那样和谐。\n##Android N上热补丁的出路 假设base.art文件在补丁前已经存在，这里存在三种情况：\n 补丁修改的类都不app image中；这种情况是最理想的，此时补丁机制依然有效； 补丁修改的类部分在app image中；这种情况我们只能更新一部分的类，此时是最危险的。一部分类是新的，一部分类是旧的，app可能会出现地址错乱而出现crash。 补丁修改的类全部在app image中；这种情况只是造成补丁不生效，app并不会因此造成crash。  ###运行时替换PathClassLoader方案 事实上，App image中的class是插入到PathClassloader中的ClassTable中。假设我们完全废弃掉PathClassloader，而采用一个新建Classloader来加载后续的所有类，即可达到将cache无用化的效果。\n实际代码对应AndroidNClassLoader中的findClass和findLibrary方法，通过调用super.findClass和super.findLibrary来避开调用原本应用PathClassLoader的find方法，原本的findClass方法会先查找classTable造成修复的class无法加载到\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/",
	"title": "arch",
	"tags": [],
	"description": "",
	"content": "arch 探索总结arch知识\n databinding    Databinding      lifecycle    Lifecycle      livedata    LiveData     LiveData封装     MediatorLiveData      viewmodel    ViewModel     ViewModel封装     数据保存和恢复      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/art_lock/",
	"title": "ART_Lock",
	"tags": [],
	"description": "",
	"content": "ObjectLock\u0026lt;mirror::Class\u0026gt; lock(self, klass); art/runtime/object_lock.cc\nobject_lock.cc ObjectLock template \u0026lt;typename T\u0026gt; ObjectLock\u0026lt;T\u0026gt;::ObjectLock(Thread* self, Handle\u0026lt;T\u0026gt; object) : self_(self), obj_(object) { CHECK(object != nullptr); obj_-\u0026gt;MonitorEnter(self_); } ~ObjectLock template \u0026lt;typename T\u0026gt; ObjectLock\u0026lt;T\u0026gt;::~ObjectLock() { obj_-\u0026gt;MonitorExit(self_); } art/runtime/mirror/object-inl.h\nobject-inl.h MonitorEnter inline mirror::Object* Object::MonitorEnter(Thread* self) { return Monitor::MonitorEnter(self, this, /*trylock*/false); } art/runtime/monitor.cc\nmonitor.cc MonitorEnter mirror::Object* Monitor::MonitorEnter(Thread* self, mirror::Object* obj, bool trylock) { StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Object\u0026gt; h_obj(hs.NewHandle(obj)); while (true) { // We initially read the lockword with ordinary Java/relaxed semantics. When stronger  // semantics are needed, we address it below. Since GetLockWord bottoms out to a relaxed load,  // we can fix it later, in an infrequently executed case, with a fence.  LockWord lock_word = h_obj-\u0026gt;GetLockWord(false); switch (lock_word.GetState()) { case LockWord::kUnlocked: { // No ordering required for preceding lockword read, since we retest.  LockWord thin_locked(LockWord::FromThinLockId(thread_id, 0, lock_word.GCState())); if (h_obj-\u0026gt;CasLockWordWeakAcquire(lock_word, thin_locked)) { AtraceMonitorLock(self, h_obj.Get(), false /* is_wait */); return h_obj.Get(); // Success!  } continue; // Go again.  } case LockWord::kThinLocked: { case LockWord::kFatLocked: { art/runtime/lock_word.h\nlock_word.h LockState enum LockState { kUnlocked, // No lock owners.  kThinLocked, // Single uncontended owner.  kFatLocked, // See associated monitor.  kHashCode, // Lock word contains an identity hash.  kForwardingAddress, // Lock word contains the forwarding address of an object. }; "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/art%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/",
	"title": "ART启动流程",
	"tags": [],
	"description": "",
	"content": "graph TB Init(\u0026quot;init进程通过解析配置脚本\u0026quot;)--\u0026gt;|fork子进程运行Zygote服务|AppProcess(\u0026quot;/system/bin/app_process: frameworks\\base\\cmds\\app_process\\app_main.cc\u0026quot;) frameworks\\base\\cmds\\app_process\\app_main.cpp\nint main(int argc, char* const argv[]) { if (zygote) { runtime.start(\u0026#34;com.android.internal.os.ZygoteInit\u0026#34;, args, zygote); } else if (className) { runtime.start(\u0026#34;com.android.internal.os.RuntimeInit\u0026#34;, args, zygote); } else { fprintf(stderr, \u0026#34;Error: no class name or --zygote supplied.\\n\u0026#34;); app_usage(); LOG_ALWAYS_FATAL(\u0026#34;app_process: no class name or --zygote supplied.\u0026#34;); return 10; } void AndroidRuntime::start(const char* className, const Vector\u0026lt;String8\u0026gt;\u0026amp; options, bool zygote) { ...... JniInvocation jni_invocation; jni_invocation.Init(NULL); //它将加载ART虚拟机的核心动态库。  JNIEnv* env; startVm(\u0026amp;mJavaVM, \u0026amp;env, zygote) != 0) { ...;}//在ART虚拟机对应的核心动态库加载到zyogte进程后，该函数将启动ART虚拟机。  ... JniInvocation::Init bool JniInvocation::Init(const char* library) { library = GetLibrary(library, buffer); const int kDlopenFlags = RTLD_NOW | RTLD_NODELETE; handle_ = dlopen(library, kDlopenFlags);//动态加载libart.so,main  //初始化三个函数指针,main  if (!FindSymbol(reinterpret_cast\u0026lt;void**\u0026gt;(\u0026amp;JNI_GetDefaultJavaVMInitArgs_), \u0026#34;JNI_GetDefaultJavaVMInitArgs\u0026#34;)) { return false; } if (!FindSymbol(reinterpret_cast\u0026lt;void**\u0026gt;(\u0026amp;JNI_CreateJavaVM_),//赋值创建虚拟机的入口函数,main  \u0026#34;JNI_CreateJavaVM\u0026#34;)) { return false; } if (!FindSymbol(reinterpret_cast\u0026lt;void**\u0026gt;(\u0026amp;JNI_GetCreatedJavaVMs_), \u0026#34;JNI_GetCreatedJavaVMs\u0026#34;)) { return false; } AndroidRuntime::startVm int AndroidRuntime::startVm(JavaVM** pJavaVM, JNIEnv** pEnv, bool zygote) { initArgs.version = JNI_VERSION_1_4; initArgs.options = mOptions.editArray(); initArgs.nOptions = mOptions.size(); initArgs.ignoreUnrecognized = JNI_FALSE; /* * Initialize the VM. * * The JavaVM* is essentially per-process, and the JNIEnv* is per-thread. * If this call succeeds, the VM is ready, and we can start issuing * JNI calls. */ if (JNI_CreateJavaVM(pJavaVM, pEnv, \u0026amp;initArgs) \u0026lt; 0) { ALOGE(\u0026#34;JNI_CreateJavaVM failed\\n\u0026#34;); return -1; } return 0; extern \u0026#34;C\u0026#34; jint JNI_CreateJavaVM(JavaVM** p_vm, JNIEnv** p_env, void* vm_args) { return JniInvocation::GetJniInvocation().JNI_CreateJavaVM(p_vm, p_env, vm_args); } jint JniInvocation::JNI_CreateJavaVM(JavaVM** p_vm, JNIEnv** p_env, void* vm_args) { return JNI_CreateJavaVM_(p_vm, p_env, vm_args);//调用libart.so中的实现 } java_vm_ext.cc\nJNI_CreateJavaVM extern \u0026#34;C\u0026#34; jint JNI_CreateJavaVM(JavaVM** p_vm, JNIEnv** p_env,void* vm_args) { ScopedTrace trace(__FUNCTION__); const JavaVMInitArgs* args = static_cast\u0026lt;JavaVMInitArgs*\u0026gt;(vm_args); .....//为虚拟机准备参数  bool ignore_unrecognized = args-\u0026gt;ignoreUnrecognized; //①创建Runtime对象，它就是ART虚拟机的化身  if (!Runtime::Create(options, ignore_unrecognized)) {...} //加载其他关键动态库，它们的文件路径由/etc/public.libraries.txt文件描述  android::InitializeNativeLoader(); Runtime* runtime = Runtime::Current();//获取刚创建的Runtime对象  bool started = runtime-\u0026gt;Start();//②启动runtime。注意，这部分内容留待下一章介绍  .... //获取JNI Env和Java VM对象  *p_env = Thread::Current()-\u0026gt;GetJniEnv(); *p_vm = runtime-\u0026gt;GetJavaVM(); return JNI_OK; } runtime.cc\nRuntime::Create bool Runtime::Create(const RuntimeOptions\u0026amp; raw_options, bool ignore_unrecognized) { /*虚拟机是一个复杂系统，所以它有很多控制参数。创建Runtime时，调用者将这些参数信息放在本函数的入参raw_options对象中，该对象的类型是RuntimeOptions。不过，Runtime内部却使用类型为RuntimeArgumentMap的对象来存储参数。下面这段代码中，ParseOptions函数将存储在raw_options里的参数信息提取并保存到runtime_options对象里，而runtime_options的类型就是RuntimeArgumentMap。*/ RuntimeArgumentMap runtime_options; return ParseOptions(raw_options, ignore_unrecognized, \u0026amp;runtime_options) \u0026amp;\u0026amp; Create(std::move(runtime_options)); } bool Runtime::Create(RuntimeArgumentMap\u0026amp;\u0026amp; runtime_options) { //一个虚拟机进程中只有一个Runtime对象，名为instance_，采用单例方式来创建  if (Runtime::instance_ != nullptr) { return false; } instance_ = new Runtime; //创建Runtime对象  //用保存了虚拟机控制参数信息的runtime_options来初始化这个runtime对象。  //重点来看Init函数  if (!instance_-\u0026gt;Init(std::move(runtime_options))) {....} return true; } Runtime::Init bool Runtime::Init(RuntimeArgumentMap\u0026amp;\u0026amp; runtime_options_in) { RuntimeArgumentMap runtime_options(std::move(runtime_options_in)); //关键模块之MemMap：用于管理内存映射。ART大量使用了内存映射技术。比如.oat文件  //就会通过mmap映射到虚拟机进程的虚拟内存中来。  MemMap::Init(); using Opt = RuntimeArgumentMap;//C++11里using的用法  QuasiAtomic::Startup(); //MIPS架构中需要使用它，其他CPU架构可不考虑  //关键模块之OatFileManager：art虚拟机会打开多个oat文件，通过该模块可统一管理它们  oat_file_manager_ = new OatFileManager; Thread::SetSensitiveThreadHook(runtime_options.GetOrDefault( Opt::HookIsSensitiveThread)); //关键模块之Monitor：和Java中的monitor有关，用于实现线程同步的模块。其详情见本书第12章的内容  Monitor::Init(runtime_options.GetOrDefault(Opt::LockProfThreshold)); /*从runtime_options中提取参数。Opt是RuntimeArgumentMap的别名，而BootClassPath是runtime_options.def中定义的一个控制参数的名称。该控制参数的数据类型是vector\u0026lt;unique_ptr\u0026lt;const DexFile\u0026gt;\u0026gt;。从RuntimeArgumentMap中获取一个控制参数的值的函数有两个： （1）GetOrDefault：从指定参数中获取其值，如果外界没有设置该控制参数，则返回参数配置文件里的配置的默认值。这里的参数配置文件就是上文提到的runtime_options.def。 （2）ReleaseOrDefault：功能和GetOrDefault一样，唯一的区别在于如果外界设置了该参数，该函数将通过std::move函数将参数的值返回给调用者。std move的含义我们在第5章中已做过介绍。使用move的话，外界传入的参数将移动到返回值所在对象里，从而节省了一份内存。比如，假设参数值存储在一个string对象中，如果不使用move的话，那么RuntimeArgumentMap内部将保留一份string，而调用者拿到作为返回值的另外一份string。显然，不使用move的话，将会有两个string对象，内存会浪费一些。所以，ReleaseOrDefault用于获取类类型的控制参数的值，而对于int等基础数据类型，使用GetOrDefault即可。*/ boot_class_path_string_ = runtime_options.ReleaseOrDefault(Opt::BootClassPath); ......//从runtime_options中获取其他控制参数的值  /*接下来的关键模块为： （1）MointorList：它维护了一组Monitor对象 （2）MonitorPool：用于创建Monitor对象 （3）ThreadList：用于管理ART中的线程对象（线程对象的数据类型为Thread）的模块 （4）InternTable：该模块和string intern table有关。它其实就是字符串常量池。根据Java语言规范（Java Language Specification，简写为JLS）的要求，内容完全相同的字符串常量（string literal）应该共享同一份资源。比如，假设String a=\u0026#34;hello\u0026#34;，String b=\u0026#34;hello\u0026#34;，那么a==b（直接比较对象a是否等于对象b）应该返回true。intern table的目的很好理解，就是减少内存占用。另外，String类中有一个intern方法，它可以将某个String对象添加到intern table中。*/ monitor_list_ = new MonitorList; monitor_pool_ = MonitorPool::Create(); thread_list_ = new ThreadList; intern_table_ = new InternTable; .....//从runtime_options中获取控制参数  //关键模块之Heap：heap是art虚拟机中非常重要的模块。详情见下文分析  heap_ = new gc::Heap(......); .... //和lambda有关，以后碰见它时再来介绍  lambda_box_table_ = MakeUnique\u0026lt;lambda::BoxTable\u0026gt;(); /*关键模块ArenaPool及LinearAlloc：runtime内部也需要创建很多对象或者需要存储一些信息。为了更好地管理虚拟机自己的内存使用，runtime设计了： （1）内存池类ArenaPool。ArenaPool可管理多个内存单元（由Arena表示）。 （2）对内存使用者而言，使用内存分配器（LinearAlloc）即可在ArenaPool上分配任意大小的内存。该模块的代码非常简单，请读者自行阅读。*/ const bool use_malloc = IsAotCompiler(); arena_pool_.reset(new ArenaPool(use_malloc, false)); jit_arena_pool_.reset(new ArenaPool(false, false, \u0026#34;CompilerMetadata\u0026#34;)); linear_alloc_.reset(CreateLinearAlloc()); //接下来的一段代码和信号处理有关。ART虚拟机进程需要截获来自操作系统的某些信号  BlockSignals();//阻塞SIGPIPE、SIGQUIT和SIGUSER1信号  /*为某些信号设置自定义的信号处理函数。该函数在linux和android平台上的处理不尽相同。在android（也就是针对设备的编译）平台上，这段代码并未启用。详情可参考该函数在runtime_android.cc中的实现*/ InitPlatformSignalHandlers(); if (!no_sig_chain_) {//对在目标设备上运行的art虚拟机来说，该变量取默认值false  //获取sigaction和sigprocmask两个函数的函数指针。这和linux信号处理  //函数的调用方法有关。此处不拟讨论它，感兴趣的读者可参考代码中的注释  InitializeSignalChain(); /*下面三个变量的介绍如下： （1）implicit_null_checks_：是否启用隐式空指针检查，此处取值为true。 （2）implict_so_checkes_：是否启用隐式堆栈溢出（stackoverflow）检查，此处取值为true。 （3）implict_suspend_checks_：是否启用隐式线程暂停（thread suspension）检查，此处取值为false。suspend check相关内容将在第11章做详细介绍。*/ if (implicit_null_checks_ || implicit_so_checks_ || implicit_suspend_checks_) { //关键模块之FaultManager：该模块用于处理SIGSEV信号  fault_manager.Init(); /*下面的SuspensionHandler、StackOverflowHandler和NullPointerHandler有共同的基类FaultHandler，笔者将它们归为关键模块FaultManager之中。这部分内容 留待下文再介绍*/ if (implicit_suspend_checks_) { new SuspensionHandler(\u0026amp;fault_manager); } if (implicit_so_checks_) { new StackOverflowHandler(\u0026amp;fault_manager); } if (implicit_null_checks_) { new NullPointerHandler(\u0026amp;fault_manager); } ..... } } /*关键模块之JavaVmExt：JavaVmExt就是JNI中代表Java虚拟机的对象，其基类为JavaVM，真实类型为JavaVmExt。根据JNI规范，一个进程只有唯一的一个JavaVm对象。对art虚拟机来说，这个JavaVm对象就是此处的java_vm_。*/ java_vm_ = new JavaVMExt(this, runtime_options); //关键模块之Thread：Thread是虚拟机中代表线程的类，下面两个函数调用Thread类的  //Startup和Attach以初始化虚拟机主线程  Thread::Startup(); Thread* self = Thread::Attach(\u0026#34;main\u0026#34;, false, nullptr, false); self-\u0026gt;TransitionFromSuspendedToRunnable(); //关键模块之ClassLinker：ClassLinker也是非常重要的模块。从其命名可以看出，它处理  //和Class有关的工作，比如解析某个类、寻找某个类等  class_linker_ = new ClassLinker(intern_table_); if (GetHeap()-\u0026gt;HasBootImageSpace()) { std::string error_msg; //从oat镜像文件中初始化class linker，也就是从oat文件中获取类等信息。  bool result = class_linker_-\u0026gt;InitFromBootImage(\u0026amp;error_msg); { ScopedTrace trace2(\u0026#34;AddImageStringsToTable\u0026#34;); //处理和intern table有关的初始化  GetInternTable()-\u0026gt;AddImagesStringsToTable(heap_-\u0026gt;GetBootImageSpaces()); } { ScopedTrace trace2(\u0026#34;MoveImageClassesToClassTable\u0026#34;); //art虚拟机中每一个class loader都有一个class table，它存储了该loader  //所加载的各种class。下面这个函数将把来自镜像中的类信息添加到boot class loader  //对应的ClassTable中。这部分内容将在ClassLinker一节中介绍  GetClassLinker()-\u0026gt;AddBootImageClassesToClassTable(); } } ...... //关键模块之MethodVerifier：用于校验Java方法的模块。下一章介绍类校验方面知识时  //将接触MethodVerifier类。本书不拟对该类做过多介绍。  verifier::MethodVerifier::Init(); /*下面这段代码用于创建两个异常对象。注意，此处ThrowNewException将创建异常对象，而ClearException将清除异常对象。这样的话，Init函数返回后将不会导致异常投递。这是JNI函数中常用的做法。读者可以先不用了解这么多，后续章节介绍JNI及异常投递时还会详细介绍。 pre_allocated_OutOfMemoryError_和pre_allocated_NoClassDefFoundError_代表Java层OutOfMemoryError对象和NoClassDefFoundError对象。*/ self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/OutOfMemoryError;\u0026#34;,....); pre_allocated_OutOfMemoryError_ = GcRoot\u0026lt;mirror::Throwable\u0026gt;(self-\u0026gt;GetException()); self-\u0026gt;ClearException(); self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/NoClassDefFoundError;\u0026#34;,...); pre_allocated_NoClassDefFoundError_ = GcRoot\u0026lt;mirror::Throwable\u0026gt;(self-\u0026gt;GetException()); self-\u0026gt;ClearException(); ......//native bridge library加载，本文不涉及相关内容  return true; } MemMap\nstatic MemMap* MapAnonymous(const char* name, uint8_t* addr, size_t byte_count, int prot, bool low_4gb, bool reuse, std::string* error_msg, bool use_ashmem = true); static MemMap* MapFile(size_t byte_count,int prot, int flags, int fd,off_t start, bool low_4gb, const char* filename, std::string* error_msg) { return MapFileAtAddress(nullptr,....);//最终调用这个函数完成内存映射  } static MemMap* MapFileAtAddress(uint8_t* addr, size_t byte_count, .....std::string* error_msg); static Maps* maps_ GUARDED_BY(Locks::mem_maps_lock_); MemMap(const std::string\u0026amp; name,uint8_t* begin,size_t size, void* base_begin,size_t base_size,int prot, bool reuse,size_t redzone_size = 0) REQUIRES(!Locks::mem_maps_lock_); //该函数内部将调用mmap来完成实际的内存映射操作，读者可自行查看其代码  static void* MapInternal(void* addr, size_t length,int prot, int flags,int fd, off_t offset, bool low_4gb); .....; }; void MemMap::Init() { MutexLock mu(Thread::Current(), *Locks::mem_maps_lock_); if (maps_ == nullptr) {//Init中使用了mem_maps_lock_锁  maps_ = new Maps; } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/ashmem/",
	"title": "ashmem",
	"tags": [],
	"description": "",
	"content": "ashmem 探索总结ashmem知识\n 匿名共享内存Ashmem     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/",
	"title": "binder",
	"tags": [],
	"description": "",
	"content": "binder 探索总结binder知识\n BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderclient/",
	"title": "BinderClient",
	"tags": [],
	"description": "",
	"content": "Data Flow graph LR parcel_data--\u0026gt;flat_binder_object flat_binder_object--\u0026gt;binder_transaction_data getService SystemServiceRegistry ContextImpl.getSystemService @Override public Object getSystemService(String name) { return SystemServiceRegistry.getSystemService(this, name); } registerServices /** * Manages all of the system services that can be returned by {@link Context#getSystemService}. Used by {@link ContextImpl}. */ static { ...... registerService(Context.ACTIVITY_SERVICE, ActivityManager.class, new CachedServiceFetcher\u0026lt;ActivityManager\u0026gt;() { @Override public ActivityManager createService(ContextImpl ctx) { return new ActivityManager(ctx.getOuterContext(), ctx.mMainThread.getHandler()); }}); ...... registerService(Context.DISPLAY_SERVICE, DisplayManager.class, new CachedServiceFetcher\u0026lt;DisplayManager\u0026gt;() { @Override public DisplayManager createService(ContextImpl ctx) { return new DisplayManager(ctx.getOuterContext()); }}); registerService /** * Statically registers a system service with the context. * This method must be called during static initialization only. */ private static \u0026lt;T\u0026gt; void registerService(String serviceName, Class\u0026lt;T\u0026gt; serviceClass, ServiceFetcher\u0026lt;T\u0026gt; serviceFetcher) { SYSTEM_SERVICE_NAMES.put(serviceClass, serviceName); SYSTEM_SERVICE_FETCHERS.put(serviceName, serviceFetcher); } getSystemService public static Object getSystemService(ContextImpl ctx, String name) { ServiceFetcher\u0026lt;?\u0026gt; fetcher = SYSTEM_SERVICE_FETCHERS.get(name); return fetcher != null ? fetcher.getService(ctx) : null; } CachedServiceFetcher.getService static abstract class CachedServiceFetcher\u0026lt;T\u0026gt; implements ServiceFetcher\u0026lt;T\u0026gt; { @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public final T getService(ContextImpl ctx) { service = createService(ctx); cache[mCacheIndex] = service; return service; } } createService\u0026ndash;\u0026gt;ServiceManager.getService final IBinder b = ServiceManager.getService(Context.CONNECTIVITY_SERVICE);//getService final IConnectivityManager service = IConnectivityManager.Stub.asInterface(b);//asInterface final ProxyInfo proxyInfo = service.getProxyForNetwork(null);//useService ServiceManager getService /** * Returns a reference to a service with the given name. * * @param name the name of the service to get * @return a reference to the service, or \u0026lt;code\u0026gt;null\u0026lt;/code\u0026gt; if the service doesn\u0026#39;t exist */ public static IBinder getService(String name) { try { IBinder service = sCache.get(name); if (service != null) { return service; } else { return Binder.allowBlocking(rawGetService(name)); } } catch (RemoteException e) { Log.e(TAG, \u0026#34;error in getService\u0026#34;, e); } return null; } rawGetService private static IBinder rawGetService(String name) throws RemoteException { final IBinder binder = getIServiceManager().getService(name);//getService then useService  return binder; } getIServiceManager private static IServiceManager getIServiceManager() { if (sServiceManager != null) { return sServiceManager; } // Find the service manager  sServiceManager = ServiceManagerNative .asInterface(Binder.allowBlocking(BinderInternal.getContextObject())); return sServiceManager; } frameworks/base/core/java/com/android/internal/os/BinderInternal.java\nBinderInternal.getContextObject /** * Return the global \u0026#34;context object\u0026#34; of the system. This is usually * an implementation of IServiceManager, which you can use to find * other services. */ public static final native IBinder getContextObject(); frameworks/base/core/jni/android_util_Binder.cpp\nandroid_os_BinderInternal_getContextObject static jobject android_os_BinderInternal_getContextObject(JNIEnv* env, jobject clazz) { sp\u0026lt;IBinder\u0026gt; b = ProcessState::self()-\u0026gt;getContextObject(NULL); return javaObjectForIBinder(env, b); } system/libhwbinder/ProcessState.cpp\nProcessState::getContextObject sp\u0026lt;IBinder\u0026gt; ProcessState::getContextObject(const sp\u0026lt;IBinder\u0026gt;\u0026amp; /*caller*/) { return getStrongProxyForHandle(0); } ProcessState::getStrongProxyForHandle sp\u0026lt;IBinder\u0026gt; ProcessState::getStrongProxyForHandle(int32_t handle) { sp\u0026lt;IBinder\u0026gt; result; handle_entry* e = lookupHandleLocked(handle); if (e != NULL) { // We need to create a new BpHwBinder if there isn\u0026#39;t currently one, OR we  // are unable to acquire a weak reference on this current one. See comment  // in getWeakProxyForHandle() for more info about this.  IBinder* b = e-\u0026gt;binder; if (b == NULL || !e-\u0026gt;refs-\u0026gt;attemptIncWeak(this)) { b = new BpHwBinder(handle); e-\u0026gt;binder = b; if (b) e-\u0026gt;refs = b-\u0026gt;getWeakRefs(); result = b; } else { // This little bit of nastyness is to allow us to add a primary  // reference to the remote proxy when this team doesn\u0026#39;t have one  // but another team is sending the handle to us.  result.force_set(b); e-\u0026gt;refs-\u0026gt;decWeak(this); } } return result; } ProcessState::lookupHandleLocked Vector\u0026lt;handle_entry\u0026gt; mHandleToObject; ProcessState::handle_entry* ProcessState::lookupHandleLocked(int32_t handle) { const size_t N=mHandleToObject.size(); if (N \u0026lt;= (size_t)handle) { handle_entry e; e.binder = NULL; e.refs = NULL; status_t err = mHandleToObject.insertAt(e, N, handle+1-N); if (err \u0026lt; NO_ERROR) return NULL; } return \u0026amp;mHandleToObject.editItemAt(handle); } asInterface(cast IBinder into IxxxInterface) public abstract class ServiceManagerNative extends Binder implements IServiceManager { /** * Cast a Binder object into a service manager interface, generating * a proxy if needed. */ static public IServiceManager asInterface(IBinder obj) { if (obj == null) { return null; } IServiceManager in = (IServiceManager)obj.queryLocalInterface(descriptor); if (in != null) { return in; } return new ServiceManagerProxy(obj); } useService IServiceManager.getService(name) ServiceManagerProxy.getService class ServiceManagerProxy implements IServiceManager { public ServiceManagerProxy(IBinder remote) { mRemote = remote; } public IBinder asBinder() { return mRemote; } public IBinder getService(String name) throws RemoteException { Parcel data = Parcel.obtain(); Parcel reply = Parcel.obtain(); data.writeInterfaceToken(IServiceManager.descriptor); data.writeString(name); mRemote.transact(GET_SERVICE_TRANSACTION, data, reply, 0); IBinder binder = reply.readStrongBinder(); reply.recycle(); data.recycle(); return binder; } asInterface(cast IBinder into IxxxInterface) IConnectivityManager public interface IConnectivityManager extends android.os.IInterface Stub public static abstract class Stub extends android.os.Binder implements android.net.IConnectivityManager asInterface /** * Cast an IBinder object into an android.net.IConnectivityManager interface, * generating a proxy if needed. */ public static android.net.IConnectivityManager asInterface(android.os.IBinder obj) { if ((obj==null)) { return null; } android.os.IInterface iin = obj.queryLocalInterface(DESCRIPTOR); if (((iin!=null)\u0026amp;\u0026amp;(iin instanceof android.net.IConnectivityManager))) { return ((android.net.IConnectivityManager)iin); } return new android.net.IConnectivityManager.Stub.Proxy(obj); } Binder.queryLocalInterface /** * Use information supplied to attachInterface() to return the * associated IInterface if it matches the requested * descriptor. */ public @Nullable IInterface queryLocalInterface(@NonNull String descriptor) { if (mDescriptor != null \u0026amp;\u0026amp; mDescriptor.equals(descriptor)) { return mOwner; } return null; } BinderProxy.queryLocalInterface final class BinderProxy implements IBinder { public IInterface queryLocalInterface(String descriptor) { return null; } Proxy private static class Proxy implements android.net.IConnectivityManager { private android.os.IBinder mRemote; Proxy(android.os.IBinder remote) { mRemote = remote; } useService @Override public android.net.ProxyInfo getProxyForNetwork(android.net.Network nework) throws android.os.RemoteException { android.os.Parcel _data = android.os.Parcel.obtain(); android.os.Parcel _reply = android.os.Parcel.obtain(); android.net.ProxyInfo _result; try { _data.writeInterfaceToken(DESCRIPTOR); if ((nework!=null)) { _data.writeInt(1); nework.writeToParcel(_data, 0); } else { _data.writeInt(0); } mRemote.transact(Stub.TRANSACTION_getProxyForNetwork, _data, _reply, 0); _reply.readException(); if ((0!=_reply.readInt())) { _result = android.net.ProxyInfo.CREATOR.createFromParcel(_reply); } else { _result = null; } } finally { _reply.recycle(); _data.recycle(); } return _result; } Parcel obtain /** * Retrieve a new Parcel object from the pool. */ public static Parcel obtain() { final Parcel[] pool = sOwnedPool; synchronized (pool) { Parcel p; for (int i=0; i\u0026lt;POOL_SIZE; i++) { p = pool[i]; if (p != null) { pool[i] = null; if (DEBUG_RECYCLE) { p.mStack = new RuntimeException(); } p.mReadWriteHelper = ReadWriteHelper.DEFAULT; return p; } } } return new Parcel(0); } recycle /** * Put a Parcel object back into the pool. You must not touch * the object after this call. */ public final void recycle() { if (DEBUG_RECYCLE) mStack = null; freeBuffer(); final Parcel[] pool; if (mOwnsNativeParcelObject) { pool = sOwnedPool; } else { mNativePtr = 0; pool = sHolderPool; } synchronized (pool) { for (int i=0; i\u0026lt;POOL_SIZE; i++) { if (pool[i] == null) { pool[i] = this; return; } } } } transact BinderProxy /** * Java proxy for a native IBinder object. * Allocated and constructed by the native javaObjectforIBinder function. Never allocated * directly from Java code. */ final class BinderProxy implements IBinder { public boolean transact(int code, Parcel data, Parcel reply, int flags) throws RemoteException { Binder.checkParcel(this, code, data, \u0026#34;Unreasonably large binder buffer\u0026#34;); try { return transactNative(code, data, reply, flags); } finally { if (tracingEnabled) { Trace.traceEnd(Trace.TRACE_TAG_ALWAYS); } } } static const JNINativeMethod gBinderProxyMethods[] = { /* name, signature, funcPtr */ {\u0026#34;transactNative\u0026#34;, \u0026#34;(ILandroid/os/Parcel;Landroid/os/Parcel;I)Z\u0026#34;, (void*)android_os_BinderProxy_transact}, android_os_BinderProxy_transact static jboolean android_os_BinderProxy_transact(JNIEnv* env, jobject obj, jint code, jobject dataObj, jobject replyObj, jint flags) // throws RemoteException { Parcel* data = parcelForJavaObject(env, dataObj); Parcel* reply = parcelForJavaObject(env, replyObj); IBinder* target = getBPNativeData(env, obj)-\u0026gt;mObject.get(); //printf(\u0026#34;Transact from Java code to %p sending: \u0026#34;, target); data-\u0026gt;print();  status_t err = target-\u0026gt;transact(code, *data, reply, flags); //if (reply) printf(\u0026#34;Transact from Java code to %p received: \u0026#34;, target); reply-\u0026gt;print();  if (kEnableBinderSample) { if (time_binder_calls) { conditionally_log_binder_call(start_millis, target, code); } } ...... } parcelForJavaObject Parcel* parcelForJavaObject(JNIEnv* env, jobject obj) { if (obj) { Parcel* p = (Parcel*)env-\u0026gt;GetLongField(obj, gParcelOffsets.mNativePtr); return p; } return NULL; } getBPNativeData BinderProxyNativeData* getBPNativeData(JNIEnv* env, jobject obj) { return (BinderProxyNativeData *) env-\u0026gt;GetLongField(obj, gBinderProxyOffsets.mNativeData); } BpBinder status_t BpBinder::transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { // Once a binder has died, it will never come back to life.  if (mAlive) { status_t status = IPCThreadState::self()-\u0026gt;transact( mHandle, code, data, reply, flags);//传递mHandle  if (status == DEAD_OBJECT) mAlive = 0; return status; } return DEAD_OBJECT; } IPCThreadState Parcel mIn; Parcel mOut; self IPCThreadState* IPCThreadState::self() { const pthread_key_t k = gTLS; IPCThreadState* st = (IPCThreadState*)pthread_getspecific(k); if (st) return st; return new IPCThreadState; IPCThreadState() 每个线程都有一个IPCThreadState，每个IPCThreadState中都有一个mIn、一个mOut。成员变量mProcess保存了ProcessState变量(每个进程只有一个)。\n mIn 用来接收来自Binder设备的数据，默认大小为256字节； mOut用来存储发往Binder设备的数据，默认大小为256字节。  IPCThreadState::IPCThreadState() : mProcess(ProcessState::self()), mStrictModePolicy(0), mLastTransactionBinderFlags(0) { pthread_setspecific(gTLS, this); clearCaller(); mIn.setDataCapacity(256); mOut.setDataCapacity(256); } transact status_t IPCThreadState::transact(int32_t handle, uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { flags |= TF_ACCEPT_FDS; err = writeTransactionData(BC_TRANSACTION, flags, handle, code, data, NULL);、//传递handle  if ((flags \u0026amp; TF_ONE_WAY) == 0) { if (reply) {//call waitForResponse with param reply not null  err = waitForResponse(reply); } else { Parcel fakeReply; err = waitForResponse(\u0026amp;fakeReply);//call waitForResponse with param reply null  } } else { //oneway，则不需要等待reply的场景  err = waitForResponse(NULL, NULL); } writeTransactionData status_t IPCThreadState::writeTransactionData(int32_t cmd, uint32_t binderFlags, int32_t handle, uint32_t code, const Parcel\u0026amp; data, status_t* statusBuffer) { binder_transaction_data tr; tr.target.ptr = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ tr.target.handle = handle;//准备写入handle  tr.code = code; //wrapped code  tr.flags = binderFlags; tr.cookie = 0; tr.sender_pid = 0; tr.sender_euid = 0; const status_t err = data.errorCheck(); if (err == NO_ERROR) { tr.data_size = data.ipcDataSize();// mDataSize,binder_transaction的数据大小  tr.data.ptr.buffer = data.ipcData();//mData, binder_transaction的数据的起始地址  tr.offsets_size = data.ipcObjectsCount()*sizeof(binder_size_t);//mObjectsSize,记录着flat_binder_object结构体的个数  tr.data.ptr.offsets = data.ipcObjects();//mObjects, 记录着flat_binder_object结构体在数据偏移量  } mOut.writeInt32(cmd);//cmd = BC_TRANSACTION  mOut.write(\u0026amp;tr, sizeof(tr));//写入binder_transaction_data数据  return NO_ERROR; } Parcel::ipcData uintptr_t Parcel::ipcData() const { return reinterpret_cast\u0026lt;uintptr_t\u0026gt;(mData); } waitForResponse status_t IPCThreadState::waitForResponse(Parcel *reply, status_t *acquireResult) { uint32_t cmd; int32_t err; while (1) { if ((err=talkWithDriver()) \u0026lt; NO_ERROR) break; err = mIn.errorCheck(); if (err \u0026lt; NO_ERROR) break; if (mIn.dataAvail() == 0) continue; cmd = (uint32_t)mIn.readInt32(); switch (cmd) { case BR_TRANSACTION_COMPLETE: if (!reply \u0026amp;\u0026amp; !acquireResult) goto finish; break; case BR_REPLY: { binder_transaction_data tr; err = mIn.read(\u0026amp;tr, sizeof(tr)); if (reply) { if ((tr.flags \u0026amp; TF_STATUS_CODE) == 0) { reply-\u0026gt;ipcSetDataReference( reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), freeBuffer, this); } else { err = *reinterpret_cast\u0026lt;const status_t*\u0026gt;(tr.data.ptr.buffer); freeBuffer(NULL, reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), this); } } else { freeBuffer(NULL, reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), this); continue; } ...... } goto finish; default: err = executeCommand(cmd); if (err != NO_ERROR) goto finish; break; Parcel::dataAvail size_t Parcel::dataAvail() const { size_t result = dataSize() - dataPosition(); if (result \u0026gt; INT32_MAX) { abort(); } return result; } talkWithDriver status_t IPCThreadState::talkWithDriver(bool doReceive) { binder_write_read bwr; // Is the read buffer empty?  const bool needRead = mIn.dataPosition() \u0026gt;= mIn.dataSize(); // We don\u0026#39;t want to write anything if we are still reading  // from data left in the input buffer and the caller  // has requested to read the next data.  const size_t outAvail = (!doReceive || needRead) ? mOut.dataSize() : 0; bwr.write_size = outAvail; bwr.write_buffer = (uintptr_t)mOut.data();//写入write buffer  // This is what we\u0026#39;ll read.  if (doReceive \u0026amp;\u0026amp; needRead) { bwr.read_size = mIn.dataCapacity(); bwr.read_buffer = (uintptr_t)mIn.data(); } else { bwr.read_size = 0; bwr.read_buffer = 0; } // Return immediately if there is nothing to do.  if ((bwr.write_size == 0) \u0026amp;\u0026amp; (bwr.read_size == 0)) return NO_ERROR; bwr.write_consumed = 0; bwr.read_consumed = 0; do { if (ioctl(mProcess-\u0026gt;mDriverFD, BINDER_WRITE_READ, \u0026amp;bwr) \u0026gt;= 0) err = NO_ERROR; else err = -errno; if (mProcess-\u0026gt;mDriverFD \u0026lt;= 0) { err = -EBADF; } } while (err == -EINTR); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderdeath/",
	"title": "BinderDeath",
	"tags": [],
	"description": "",
	"content": "原理总结 Binder死亡通知机制之linkToDeath\nUnlinkToDeath流程类似，参考上文，不做记录\n死亡通知是为了让Bp端(客户端进程)进能知晓Bn端(服务端进程)的生死情况，当Bn端进程死亡后能通知到Bp端。\n 定义：AppDeathRecipient是继承IBinder::DeathRecipient类，主要需要实现其binderDied()来进行死亡通告。 注册：binder-\u0026gt;linkToDeath(AppDeathRecipient)是为了将AppDeathRecipient死亡通知注册到Binder上。  Bp端只需要覆写binderDied()方法，实现一些后尾清除类的工作，则在Bn端死掉后，会回调binderDied()进行相应处理。\nlinkToDeath android_os_BinderProxy_linkToDeath static void android_os_BinderProxy_linkToDeath(JNIEnv* env, jobject obj, jobject recipient, jint flags) { //获取BinderProxy.mObject成员变量值, 即BpBinder对象  IBinder* target = (IBinder*)env-\u0026gt;GetLongField(obj, gBinderProxyOffsets.mObject); sp\u0026lt;JavaDeathRecipient\u0026gt; jdr = new JavaDeathRecipient(env, recipient, list); //建立死亡通知[见小节2.2]  status_t err = target-\u0026gt;linkToDeath(jdr, NULL, flags); }  获取DeathRecipientList: 其成员变量mList记录该BinderProxy的JavaDeathRecipient列表信息；  一个BpBinder可以注册多个死亡回调   创建JavaDeathRecipient: 继承于IBinder::DeathRecipient  linkToDeath status_t BpBinder::linkToDeath( const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie, uint32_t flags) { IPCThreadState* self = IPCThreadState::self(); self-\u0026gt;requestDeathNotification(mHandle, this); self-\u0026gt;flushCommands(); } requestDeathNotification status_t IPCThreadState::requestDeathNotification(int32_t handle, BpBinder* proxy) { mOut.writeInt32(BC_REQUEST_DEATH_NOTIFICATION); mOut.writeInt32((int32_t)handle); mOut.writePointer((uintptr_t)proxy); return NO_ERROR; } flushCommands void IPCThreadState::flushCommands() { if (mProcess-\u0026gt;mDriverFD \u0026lt;= 0) return; talkWithDriver(false); } binder_ioctl_write_read static int binder_ioctl_write_read(struct file *filp, unsigned int cmd, unsigned long arg, struct binder_thread *thread) { int ret = 0; struct binder_proc *proc = filp-\u0026gt;private_data; void __user *ubuf = (void __user *)arg; struct binder_write_read bwr; if (copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr))) { //把用户空间数据ubuf拷贝到bwr  ret = -EFAULT; goto out; } if (bwr.write_size \u0026gt; 0) { //此时写缓存有数据【见小节3.2】  ret = binder_thread_write(proc, thread, bwr.write_buffer, bwr.write_size, \u0026amp;bwr.write_consumed); ... } if (bwr.read_size \u0026gt; 0) { //此时读缓存没有数据  ... } if (copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr))) { //将内核数据bwr拷贝到用户空间ubuf  ret = -EFAULT; goto out; } out: return ret; } binder_thread_write static int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed) { uint32_t cmd; //proc, thread都是指当前发起端进程的信息  while (ptr \u0026lt; end \u0026amp;\u0026amp; thread-\u0026gt;return_error == BR_OK) { get_user(cmd, (uint32_t __user *)ptr); //获取BC_REQUEST_DEATH_NOTIFICATION  ptr += sizeof(uint32_t); switch (cmd) { case BC_REQUEST_DEATH_NOTIFICATION:{ //注册死亡通知  uint32_t target; void __user *cookie; struct binder_ref *ref; struct binder_ref_death *death; get_user(target, (uint32_t __user *)ptr); //获取target  ptr += sizeof(uint32_t); get_user(cookie, (void __user * __user *)ptr); //获取BpBinder  ptr += sizeof(void *); ref = binder_get_ref(proc, target); //拿到目标服务的binder_ref  if (cmd == BC_REQUEST_DEATH_NOTIFICATION) { //native Bp可注册多个，但Kernel只允许注册一个死亡通知  if (ref-\u0026gt;death) { break; } death = kzalloc(sizeof(*death), GFP_KERNEL); INIT_LIST_HEAD(\u0026amp;death-\u0026gt;work.entry); death-\u0026gt;cookie = cookie; //BpBinder指针  ref-\u0026gt;death = death; //当目标binder服务所在进程已死,则直接发送死亡通知。这是非常规情况  if (ref-\u0026gt;node-\u0026gt;proc == NULL) { ref-\u0026gt;death-\u0026gt;work.type = BINDER_WORK_DEAD_BINDER; //当前线程为binder线程,则直接添加到当前线程的todo队列.  if (thread-\u0026gt;looper \u0026amp; (BINDER_LOOPER_STATE_REGISTERED | BINDER_LOOPER_STATE_ENTERED)) { list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;thread-\u0026gt;todo); } else { list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;proc-\u0026gt;todo); wake_up_interruptible(\u0026amp;proc-\u0026gt;wait); } } } else { ... } 在处理BC_REQUEST_DEATH_NOTIFICATION过程，正好遇到对端目标binder服务所在进程已死的情况， 向todo队列增加BINDER_WORK_DEAD_BINDER事务，直接发送死亡通知，但这属于非常规情况。\n更常见的场景是binder服务所在进程死亡后,会调用binder_release方法, 然后调用binder_node_release.这个过程便会发出死亡通知的回调.\n触发死亡通知 当Binder服务所在进程死亡后，会释放进程相关的资源，Binder也是一种资源。 binder_open打开binder驱动/dev/binder，这是字符设备，获取文件描述符。在进程结束的时候会有一个关闭文件系统的过程中会调用驱动close方法，该方法相对应的是release()方法。当binder的fd被释放后，此处调用相应的方法是binder_release().\n但并不是每个close系统调用都会触发调用release()方法. 只有真正释放设备数据结构才调用release(),内核维持一个文件结构被使用多少次的计数，即便是应用程序没有明显地关闭它打开的文件也适用: 内核在进程exit()时会释放所有内存和关闭相应的文件资源, 通过使用close系统调用最终也会release binder.\n[-\u0026gt; binder.c]\nbinder_fops static const struct file_operations binder_fops = { .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .compat_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release, //对应于release的方法 }; binder_release static int binder_release(struct inode *nodp, struct file *filp) { struct binder_proc *proc = filp-\u0026gt;private_data; debugfs_remove(proc-\u0026gt;debugfs_entry); binder_defer_work(proc, BINDER_DEFERRED_RELEASE); return 0; } binder_defer_work static void binder_defer_work(struct binder_proc *proc, enum binder_deferred_state defer) { mutex_lock(\u0026amp;binder_deferred_lock); //获取锁  //添加BINDER_DEFERRED_RELEASE  proc-\u0026gt;deferred_work |= defer; if (hlist_unhashed(\u0026amp;proc-\u0026gt;deferred_work_node)) { hlist_add_head(\u0026amp;proc-\u0026gt;deferred_work_node, \u0026amp;binder_deferred_list); //向工作队列添加binder_deferred_work [见小节4.4]  queue_work(binder_deferred_workqueue, \u0026amp;binder_deferred_work); } mutex_unlock(\u0026amp;binder_deferred_lock); //释放锁 } queue_work //全局工作队列 static struct workqueue_struct *binder_deferred_workqueue; static int __init binder_init(void) { int ret; //创建了名叫“binder”的工作队列  binder_deferred_workqueue = create_singlethread_workqueue(\u0026#34;binder\u0026#34;); if (!binder_deferred_workqueue) return -ENOMEM; ... } device_initcall(binder_init); 关于binder_deferred_work的定义：\nstatic DECLARE_WORK(binder_deferred_work, binder_deferred_func); 在Binder设备驱动初始化的过程执行binder_init()方法中，调用 create_singlethread_workqueue(“binder”)，创建了名叫“binder”的工作队列(workqueue)。 workqueue是kernel提供的一种实现简单而有效的内核线程机制，可延迟执行任务。\n此处binder_deferred_work的func为binder_deferred_func，接下来看该方法。\nbinder_deferred_func static void binder_deferred_func(struct work_struct *work) { struct binder_proc *proc; struct files_struct *files; int defer; do { mutex_lock(\u0026amp;binder_main_lock); //获取binder_main_lock  mutex_lock(\u0026amp;binder_deferred_lock); preempt_disable(); //禁止CPU抢占  if (!hlist_empty(\u0026amp;binder_deferred_list)) { proc = hlist_entry(binder_deferred_list.first, struct binder_proc, deferred_work_node); hlist_del_init(\u0026amp;proc-\u0026gt;deferred_work_node); defer = proc-\u0026gt;deferred_work; proc-\u0026gt;deferred_work = 0; } else { proc = NULL; defer = 0; } mutex_unlock(\u0026amp;binder_deferred_lock); files = NULL; if (defer \u0026amp; BINDER_DEFERRED_PUT_FILES) { files = proc-\u0026gt;files; if (files) proc-\u0026gt;files = NULL; } if (defer \u0026amp; BINDER_DEFERRED_FLUSH) binder_deferred_flush(proc); if (defer \u0026amp; BINDER_DEFERRED_RELEASE) binder_deferred_release(proc); //[见小节4.6]  mutex_unlock(\u0026amp;binder_main_lock); //释放锁  preempt_enable_no_resched(); if (files) put_files_struct(files); } while (proc); } binder_deferred_release 此处proc是来自Bn端的binder_proc\nstatic void binder_deferred_release(struct binder_proc *proc) { struct binder_transaction *t; struct rb_node *n; int threads, nodes, incoming_refs, outgoing_refs, buffers, active_transactions, page_count; hlist_del(\u0026amp;proc-\u0026gt;proc_node); //删除proc_node节点  if (binder_context_mgr_node \u0026amp;\u0026amp; binder_context_mgr_node-\u0026gt;proc == proc) { binder_context_mgr_node = NULL; } //释放binder_thread[见小节4.6.1]  threads = 0; active_transactions = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;threads))) { struct binder_thread *thread; thread = rb_entry(n, struct binder_thread, rb_node); threads++; active_transactions += binder_free_thread(proc, thread); } //释放binder_node [见小节4.6.2]  nodes = 0; incoming_refs = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;nodes))) { struct binder_node *node; node = rb_entry(n, struct binder_node, rb_node); nodes++; rb_erase(\u0026amp;node-\u0026gt;rb_node, \u0026amp;proc-\u0026gt;nodes); incoming_refs = binder_node_release(node, incoming_refs);//key  } //释放binder_ref [见小节4.6.3]  outgoing_refs = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;refs_by_desc))) { struct binder_ref *ref; ref = rb_entry(n, struct binder_ref, rb_node_desc); outgoing_refs++; binder_delete_ref(ref); } //释放binder_work [见小节4.6.4]  binder_release_work(\u0026amp;proc-\u0026gt;todo); binder_release_work(\u0026amp;proc-\u0026gt;delivered_death); buffers = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;allocated_buffers))) { struct binder_buffer *buffer; buffer = rb_entry(n, struct binder_buffer, rb_node); t = buffer-\u0026gt;transaction; if (t) { t-\u0026gt;buffer = NULL; buffer-\u0026gt;transaction = NULL; } //释放binder_buf [见小节4.6.5]  binder_free_buf(proc, buffer); buffers++; } binder_stats_deleted(BINDER_STAT_PROC); page_count = 0; if (proc-\u0026gt;pages) { int i; for (i = 0; i \u0026lt; proc-\u0026gt;buffer_size / PAGE_SIZE; i++) { void *page_addr; if (!proc-\u0026gt;pages[i]) continue; page_addr = proc-\u0026gt;buffer + i * PAGE_SIZE; unmap_kernel_range((unsigned long)page_addr, PAGE_SIZE); __free_page(proc-\u0026gt;pages[i]); page_count++; } kfree(proc-\u0026gt;pages); vfree(proc-\u0026gt;buffer); } put_task_struct(proc-\u0026gt;tsk); kfree(proc); } binder_deferred_release的主要工作有：\n binder_free_thread： proc-\u0026gt;threads所有线程  binder_send_failed_reply(send_reply, BR_DEAD_REPLY)：将发起方线程的return_error值设置为BR_DEAD_REPLY，让其直接返回；   binder_node_release: proc-\u0026gt;nodes所有节点  binder_release_work(\u0026amp;node-\u0026gt;async_todo) node-\u0026gt;refs的所有死亡回调   binder_delete_ref: proc-\u0026gt;refs_by_desc所有引用  清除引用   binder_release_work: proc-\u0026gt;todo, proc-\u0026gt;delivered_death  binder_send_failed_reply(t, BR_DEAD_REPLY)   binder_free_buf: proc-\u0026gt;allocated_buffers所有已分配buffer  释放已分配的buffer   __free_page: proc-\u0026gt;pages所有物理内存页  static int binder_node_release(struct binder_node *node, int refs) { struct binder_ref *ref; int death = 0; list_del_init(\u0026amp;node-\u0026gt;work.entry); //[见小节4.6.4]  binder_release_work(\u0026amp;node-\u0026gt;async_todo); if (hlist_empty(\u0026amp;node-\u0026gt;refs)) { kfree(node); //引用为空，则直接删除节点  binder_stats_deleted(BINDER_STAT_NODE); return refs; } node-\u0026gt;proc = NULL; node-\u0026gt;local_strong_refs = 0; node-\u0026gt;local_weak_refs = 0; hlist_add_head(\u0026amp;node-\u0026gt;dead_node, \u0026amp;binder_dead_nodes); hlist_for_each_entry(ref, \u0026amp;node-\u0026gt;refs, node_entry) { refs++; if (!ref-\u0026gt;death) continue; death++; if (list_empty(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry)) { //添加BINDER_WORK_DEAD_BINDER事务到todo队列 [见小节5.1]  ref-\u0026gt;death-\u0026gt;work.type = BINDER_WORK_DEAD_BINDER; list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;ref-\u0026gt;proc-\u0026gt;todo); wake_up_interruptible(\u0026amp;ref-\u0026gt;proc-\u0026gt;wait); } } return refs; } 该方法会遍历该binder_node所有的binder_ref, 当存在binder死亡通知，则向相应的binder_ref 所在进程的todo队列添加BINDER_WORK_DEAD_BINDER事务并唤醒处于proc-\u0026gt;wait的binder线程,执行binder_thread_read\n处理死亡通知 binder_thread_read static int binder_thread_read(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed, int non_block) ... //唤醒等待中的binder线程  wait_event_freezable_exclusive(proc-\u0026gt;wait, binder_has_proc_work(proc, thread)); binder_lock(__func__); //加锁  if (wait_for_proc_work) proc-\u0026gt;ready_threads--; //空闲的binder线程减1  thread-\u0026gt;looper \u0026amp;= ~BINDER_LOOPER_STATE_WAITING; while (1) { uint32_t cmd; struct binder_transaction_data tr; struct binder_work *w; struct binder_transaction *t = NULL; //从todo队列拿出前面放入的binder_work, 此时type为BINDER_WORK_DEAD_BINDER  if (!list_empty(\u0026amp;thread-\u0026gt;todo)) { w = list_first_entry(\u0026amp;thread-\u0026gt;todo, struct binder_work, entry); } else if (!list_empty(\u0026amp;proc-\u0026gt;todo) \u0026amp;\u0026amp; wait_for_proc_work) { w = list_first_entry(\u0026amp;proc-\u0026gt;todo, struct binder_work, entry); } switch (w-\u0026gt;type) { case BINDER_WORK_DEAD_BINDER: { struct binder_ref_death *death; uint32_t cmd; death = container_of(w, struct binder_ref_death, work); if (w-\u0026gt;type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) ... else cmd = BR_DEAD_BINDER; //进入此分支  put_user(cmd, (uint32_t __user *)ptr);//拷贝到用户空间[见小节5.2]  ptr += sizeof(uint32_t); //此处的cookie是前面传递的BpBinder  put_user(death-\u0026gt;cookie, (binder_uintptr_t __user *)ptr); ptr += sizeof(binder_uintptr_t); if (w-\u0026gt;type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) { ... } else //把该work加入到delivered_death队列  list_move(\u0026amp;w-\u0026gt;entry, \u0026amp;proc-\u0026gt;delivered_death); if (cmd == BR_DEAD_BINDER) goto done; } break; } } ... return 0; } 将命令BR_DEAD_BINDER写到用户空间，此时用户空间执行过程：\ngetAndExecuteCommand status_t IPCThreadState::getAndExecuteCommand() { status_t result; int32_t cmd; result = talkWithDriver(); //该Binder Driver进行交互  if (result \u0026gt;= NO_ERROR) { size_t IN = mIn.dataAvail(); if (IN \u0026lt; sizeof(int32_t)) return result; cmd = mIn.readInt32(); //读取命令  pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount++; pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); result = executeCommand(cmd); //【见小节5.3】  pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount--; pthread_cond_broadcast(\u0026amp;mProcess-\u0026gt;mThreadCountDecrement); pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); set_sched_policy(mMyThreadId, SP_FOREGROUND); } return result; } executeCommand status_t IPCThreadState::executeCommand(int32_t cmd) { BBinder* obj; RefBase::weakref_type* refs; status_t result = NO_ERROR; switch ((uint32_t)cmd) { case BR_DEAD_BINDER: { BpBinder *proxy = (BpBinder*)mIn.readPointer(); proxy-\u0026gt;sendObituary(); //[见小节5.4]  mOut.writeInt32(BC_DEAD_BINDER_DONE); mOut.writePointer((uintptr_t)proxy); } break; ... } ... return result; } 同一个bp端即便注册多次死亡通知，但只会发送一次死亡回调。\nsendObituary void BpBinder::sendObituary() { mAlive = 0; if (mObitsSent) return; mLock.lock(); Vector\u0026lt;Obituary\u0026gt;* obits = mObituaries; if(obits != NULL) { IPCThreadState* self = IPCThreadState::self(); //清空死亡通知[见小节6.2]  self-\u0026gt;clearDeathNotification(mHandle, this); self-\u0026gt;flushCommands(); mObituaries = NULL; } mObitsSent = 1; mLock.unlock(); if (obits != NULL) { const size_t N = obits-\u0026gt;size(); for (size_t i=0; i\u0026lt;N; i++) { //发送死亡通知 [见小节5.5]  reportOneDeath(obits-\u0026gt;itemAt(i)); } delete obits; } } reportOneDeath void BpBinder::reportOneDeath(const Obituary\u0026amp; obit) { //将弱引用提升到sp  sp\u0026lt;DeathRecipient\u0026gt; recipient = obit.recipient.promote(); if (recipient == NULL) return; //回调死亡通知的方法  recipient-\u0026gt;binderDied(this); } 本文开头的实例传递的是AppDeathRecipient，那么回调如下方法。\nprivate final class AppDeathRecipient implements IBinder.DeathRecipient { ... public void binderDied() { synchronized(ActivityManagerService.this) { appDiedLocked(mApp, mPid, mAppThread, true); } } } 结论 对于Binder IPC进程都会打开/dev/binder文件，当进程异常退出时，Binder驱动会保证释放将要退出的进程中没有正常关闭的/dev/binder文件，实现机制是binder驱动通过调用/dev/binder文件所对应的release回调函数，执行清理工作，并且检查BBinder是否有注册死亡通知，当发现存在死亡通知时，那么就向其对应的BpBinder端发送死亡通知消息。\n死亡回调DeathRecipient只有Bp才能正确使用，因为DeathRecipient用于监控Bn端挂掉的情况， 如果Bn建立跟自己的死亡通知，自己进程都挂了，也就无法通知。\n每个BpBinder都有一个记录DeathRecipient列表的对象DeathRecipientList。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderkernel/",
	"title": "BinderKernel",
	"tags": [],
	"description": "",
	"content": "binder_write_read struct binder_write_read { binder_size_t\twrite_size;\t/* bytes to write */ binder_size_t\twrite_consumed;\t/* bytes consumed by driver */ binder_uintptr_t\twrite_buffer; binder_size_t\tread_size;\t/* bytes to read */ binder_size_t\tread_consumed;\t/* bytes consumed by driver */ binder_uintptr_t\tread_buffer; }; binder_transaction_data struct binder_transaction_data { /* The first two are only used for bcTRANSACTION and brTRANSACTION, * identifying the target and contents of the transaction. */ union { /* target descriptor of command transaction */ __u32\thandle; /* target descriptor of return transaction */ binder_uintptr_t ptr; } target; binder_uintptr_t\tcookie;\t/* target object cookie */ __u32\tcode;\t/* transaction command */ /* General information about the transaction. */ __u32\tflags; pid_t\tsender_pid; uid_t\tsender_euid; binder_size_t\tdata_size;\t/* number of bytes of data */ binder_size_t\toffsets_size;\t/* number of bytes of offsets */ /* If this transaction is inline, the data immediately * follows here; otherwise, it ends with a pointer to * the data buffer. */ union { struct { /* transaction data */ binder_uintptr_t\tbuffer; /* offsets from buffer to flat_binder_object structs */ binder_uintptr_t\toffsets; } ptr; __u8\tbuf[8]; } data; }; drivers/android/binder.c\nbinder.c binder_ioctl static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { int ret; struct binder_proc *proc = filp-\u0026gt;private_data; switch (cmd) { case BINDER_WRITE_READ: ret = binder_ioctl_write_read(filp, cmd, arg, thread); } } binder_ioctl_write_read static int binder_ioctl_write_read(struct file *filp, unsigned int cmd, unsigned long arg, struct binder_thread *thread) { int ret = 0; struct binder_proc *proc = filp-\u0026gt;private_data; unsigned int size = _IOC_SIZE(cmd); void __user *ubuf = (void __user *)arg; struct binder_write_read bwr; //将用户空间bwr结构体拷贝到内核空间  copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr)); binder_debug(BINDER_DEBUG_READ_WRITE, \u0026#34;%d:%d write %lld at %016llx, read %lld at %016llx\\n\u0026#34;, proc-\u0026gt;pid, thread-\u0026gt;pid, (u64)bwr.write_size, (u64)bwr.write_buffer, (u64)bwr.read_size, (u64)bwr.read_buffer); if (bwr.write_size \u0026gt; 0) { //将数据放入目标进程 \tret = binder_thread_write(proc, thread, bwr.write_buffer, bwr.write_size, \u0026amp;bwr.write_consumed); } if (bwr.read_size \u0026gt; 0) { //读取自己队列的数据 \tret = binder_thread_read(proc, thread, bwr.read_buffer, bwr.read_size, \u0026amp;bwr.read_consumed, filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK); } //将内核空间bwr结构体拷贝到用户空间  copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr)) return ret; } binder_thread_write static int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed) { uint32_t cmd; struct binder_context *context = proc-\u0026gt;context; void __user *buffer = (void __user *)(uintptr_t)binder_buffer; void __user *ptr = buffer + *consumed; void __user *end = buffer + size; while (ptr \u0026lt; end \u0026amp;\u0026amp; thread-\u0026gt;return_error.cmd == BR_OK) { if (get_user(cmd, (uint32_t __user *)ptr))////拷贝用户空间的cmd命令，此时为BC_TRANSACTION \treturn -EFAULT; ptr += sizeof(uint32_t); switch (cmd) { case BC_TRANSACTION: case BC_REPLY: { struct binder_transaction_data tr; //拷贝用户空间的binder_transaction_data \tif (copy_from_user(\u0026amp;tr, ptr, sizeof(tr))) return -EFAULT; ptr += sizeof(tr); binder_transaction(proc, thread, \u0026amp;tr, cmd == BC_REPLY, 0); break; } } binder_transaction static void binder_transaction(struct binder_proc *proc, struct binder_thread *thread, struct binder_transaction_data *tr, int reply, binder_size_t extra_buffers_size) { struct binder_proc *target_proc = NULL; struct binder_thread *target_thread = NULL; struct binder_node *target_node = NULL; if (reply) { ...... } else { if (tr-\u0026gt;target.handle) { struct binder_ref *ref; binder_proc_lock(proc); ref = binder_get_ref_olocked(proc, tr-\u0026gt;target.handle, true); if (ref) { target_node = binder_get_node_refs_for_txn( ref-\u0026gt;node, \u0026amp;target_proc, \u0026amp;return_error); } else { binder_user_error(\u0026#34;%d:%d got transaction to invalid handle\\n\u0026#34;,proc-\u0026gt;pid, thread-\u0026gt;pid);...... } binder_proc_unlock(proc); } else { // handle=0则找到servicemanager实体 \tmutex_lock(\u0026amp;context-\u0026gt;context_mgr_node_lock); target_node = context-\u0026gt;binder_context_mgr_node; if (target_node) target_node = binder_get_node_refs_for_txn( target_node, \u0026amp;target_proc, \u0026amp;return_error); else return_error = BR_DEAD_REPLY; mutex_unlock(\u0026amp;context-\u0026gt;context_mgr_node_lock); } t-\u0026gt;buffer = binder_alloc_new_buf(\u0026amp;target_proc-\u0026gt;alloc, tr-\u0026gt;data_size, tr-\u0026gt;offsets_size, extra_buffers_size, !reply \u0026amp;\u0026amp; (t-\u0026gt;flags \u0026amp; TF_ONE_WAY)); ...... if (reply) { ...... } else if (!(t-\u0026gt;flags \u0026amp; TF_ONE_WAY)) { BUG_ON(t-\u0026gt;buffer-\u0026gt;async_transaction != 0); /* * Defer the TRANSACTION_COMPLETE, so we don\u0026#39;t return to * userspace immediately; this allows the target process to * immediately start processing this transaction, reducing * latency. We will then return the TRANSACTION_COMPLETE when * the target replies (or there is an error). */ binder_enqueue_deferred_thread_work_ilocked(thread, tcomplete); t-\u0026gt;need_reply = 1; t-\u0026gt;from_parent = thread-\u0026gt;transaction_stack; thread-\u0026gt;transaction_stack = t; if (!binder_proc_transaction(t, target_proc, target_thread)) { ...... goto err_dead_proc_or_thread; } } else { BUG_ON(target_node == NULL); BUG_ON(t-\u0026gt;buffer-\u0026gt;async_transaction != 1); binder_enqueue_thread_work(thread, tcomplete); if (!binder_proc_transaction(t, target_proc, NULL)) goto err_dead_proc_or_thread; } binder_alloc_new_buf /** * binder_alloc_new_buf() - Allocate a new binder buffer * @alloc: binder_alloc for this proc * @data_size: size of user data buffer * @offsets_size: user specified buffer offset * @extra_buffers_size: size of extra space for meta-data (eg, security context) * @is_async: buffer for async transaction * * Allocate a new buffer given the requested sizes. Returns * the kernel version of the buffer pointer. The size allocated * is the sum of the three given sizes (each rounded up to * pointer-sized boundary) * * Return:\tThe allocated buffer or %NULL if error */ struct binder_buffer *binder_alloc_new_buf(struct binder_alloc *alloc, size_t data_size, size_t offsets_size, size_t extra_buffers_size, int is_async) { struct binder_buffer *buffer; mutex_lock(\u0026amp;alloc-\u0026gt;mutex); buffer = binder_alloc_new_buf_locked(alloc, data_size, offsets_size, extra_buffers_size, is_async); mutex_unlock(\u0026amp;alloc-\u0026gt;mutex); return buffer; } binder_get_ref_olocked static struct binder_ref *binder_get_ref_olocked(struct binder_proc *proc, u32 desc, bool need_strong_ref) { struct rb_node *n = proc-\u0026gt;refs_by_desc.rb_node; struct binder_ref *ref; while (n) { ref = rb_entry(n, struct binder_ref, rb_node_desc); if (desc \u0026lt; ref-\u0026gt;data.desc) { n = n-\u0026gt;rb_left; } else if (desc \u0026gt; ref-\u0026gt;data.desc) { n = n-\u0026gt;rb_right; } else if (need_strong_ref \u0026amp;\u0026amp; !ref-\u0026gt;data.strong) { binder_user_error(\u0026#34;tried to use weak ref as strong ref\\n\u0026#34;); return NULL; } else { return ref; } } return NULL; } binder_get_node_refs_for_txn /** Return: The target_node with refs taken or NULL if no @node-\u0026gt;proc is NULL. * Also sets @proc if valid. If the @node-\u0026gt;proc is NULL indicating that the * target proc has died, @error is set to BR_DEAD_REPLY */ static struct binder_node *binder_get_node_refs_for_txn( struct binder_node *node, struct binder_proc **procp, uint32_t *error) { struct binder_node *target_node = NULL; binder_node_inner_lock(node); if (node-\u0026gt;proc) { target_node = node; binder_inc_node_nilocked(node, 1, 0, NULL); binder_inc_node_tmpref_ilocked(node); node-\u0026gt;proc-\u0026gt;tmp_ref++; *procp = node-\u0026gt;proc; } else *error = BR_DEAD_REPLY; binder_node_inner_unlock(node); return target_node; } struct binder_ref struct binder_ref { /* Lookups needed: */ /* node + proc =\u0026gt; ref (transaction) */ /* desc + proc =\u0026gt; ref (transaction, inc/dec ref) */ /* node =\u0026gt; refs + procs (proc exit) */ struct binder_ref_data data; struct rb_node rb_node_desc; struct rb_node rb_node_node; struct hlist_node node_entry; struct binder_proc *proc; struct binder_node *node; struct binder_ref_death *death; }; binder_proc_transaction /** * binder_proc_transaction() - sends a transaction to a process and wakes it up * @t:\ttransaction to send * @proc:\tprocess to send the transaction to * @thread:\tthread in @proc to send the transaction to (may be NULL) * * This function queues a transaction to the specified process. It will try * to find a thread in the target process to handle the transaction and * wake it up. If no thread is found, the work is queued to the proc * waitqueue. * * If the @thread parameter is not NULL, the transaction is always queued * to the waitlist of that specific thread. * * Return:\ttrue if the transactions was successfully queued *\tfalse if the target process or thread is dead */ static bool binder_proc_transaction(struct binder_transaction *t, struct binder_proc *proc, struct binder_thread *thread) { struct binder_node *node = t-\u0026gt;buffer-\u0026gt;target_node; struct binder_priority node_prio; bool oneway = !!(t-\u0026gt;flags \u0026amp; TF_ONE_WAY); bool pending_async = false; if (oneway) { BUG_ON(thread); if (node-\u0026gt;has_async_transaction) { pending_async = true; } else { node-\u0026gt;has_async_transaction = 1; } } if (!thread \u0026amp;\u0026amp; !pending_async) thread = binder_select_thread_ilocked(proc); if (thread) { binder_transaction_priority(thread-\u0026gt;task, t, node_prio, node-\u0026gt;inherit_rt); binder_enqueue_thread_work_ilocked(thread, \u0026amp;t-\u0026gt;work); } else if (!pending_async) { binder_enqueue_work_ilocked(\u0026amp;t-\u0026gt;work, \u0026amp;proc-\u0026gt;todo); } else { binder_enqueue_work_ilocked(\u0026amp;t-\u0026gt;work, \u0026amp;node-\u0026gt;async_todo); } if (!pending_async) binder_wakeup_thread_ilocked(proc, thread, !oneway /* sync */); return true; } binder_wakeup_thread_ilocked /** * binder_wakeup_thread_ilocked() - wakes up a thread for doing proc work. * @proc:\tprocess to wake up a thread in * @thread:\tspecific thread to wake-up (may be NULL) * @sync:\twhether to do a synchronous wake-up * * This function wakes up a thread in the @proc process. * The caller may provide a specific thread to wake-up in * the @thread parameter. If @thread is NULL, this function * will wake up threads that have called poll(). * * Note that for this function to work as expected, callers * should first call binder_select_thread() to find a thread * to handle the work (if they don\u0026#39;t have a thread already), * and pass the result into the @thread parameter. */ static void binder_wakeup_thread_ilocked(struct binder_proc *proc, struct binder_thread *thread, bool sync) { assert_spin_locked(\u0026amp;proc-\u0026gt;inner_lock); if (thread) { if (sync) wake_up_interruptible_sync(\u0026amp;thread-\u0026gt;wait); else wake_up_interruptible(\u0026amp;thread-\u0026gt;wait); return; } /* Didn\u0026#39;t find a thread waiting for proc work; this can happen * in two scenarios: * 1. All threads are busy handling transactions * In that case, one of those threads should call back into * the kernel driver soon and pick up this work. * 2. Threads are using the (e)poll interface, in which case * they may be blocked on the waitqueue without having been * added to waiting_threads. For this case, we just iterate * over all threads not handling transaction work, and * wake them all up. We wake all because we don\u0026#39;t know whether * a thread that called into (e)poll is handling non-binder * work currently. */ binder_wakeup_poll_threads_ilocked(proc, sync); } include/linux/wait.h\nwait.h #define wake_up_interruptible(x)\t__wake_up(x, TASK_INTERRUPTIBLE, 1, NULL) #define wake_up_interruptible_nr(x, nr)\t__wake_up(x, TASK_INTERRUPTIBLE, nr, NULL) #define wake_up_interruptible_all(x)\t__wake_up(x, TASK_INTERRUPTIBLE, 0, NULL) #define wake_up_interruptible_sync(x)\t__wake_up_sync((x), TASK_INTERRUPTIBLE, 1) drivers/android/binder_alloc.h\nbinder_alloc.h struct binder_alloc /** * struct binder_alloc - per-binder proc state for binder allocator * @vma: vm_area_struct passed to mmap_handler * (invarient after mmap) * @tsk: tid for task that called init for this proc * (invariant after init) * @vma_vm_mm: copy of vma-\u0026gt;vm_mm (invarient after mmap) * @buffer: base of per-proc address space mapped via mmap * @user_buffer_offset: offset between user and kernel VAs for buffer * @buffers: list of all buffers for this proc * @free_buffers: rb tree of buffers available for allocation * sorted by size * @allocated_buffers: rb tree of allocated buffers sorted by address * @free_async_space: VA space available for async buffers. This is * initialized at mmap time to 1/2 the full VA space * @pages: array of binder_lru_page * @buffer_size: size of address space specified via mmap * @pid: pid for associated binder_proc (invariant after init) * @pages_high: high watermark of offset in @pages * * Bookkeeping structure for per-proc address space management for binder * buffers. It is normally initialized during binder_init() and binder_mmap() * calls. The address space is used for both user-visible buffers and for * struct binder_buffer objects used to track the user buffers */ //open系统调用时返回的fd信息的private_data里是binder_proc，而mmap过程会修改这个binder_proc的alloc字段信息，从而确保申请的内存位于target process对应的内核空间 struct binder_alloc { } include/linux/rbtree.h\nrbtree.h//红黑树 rb_node struct rb_node { unsigned long __rb_parent_color; struct rb_node *rb_right; struct rb_node *rb_left; } __attribute__((aligned(sizeof(long)))); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderserver/",
	"title": "BinderServer",
	"tags": [],
	"description": "",
	"content": "Binder Native And Java Design classDiagram class IBinder { +queryLocalInterface(descriptor) +linkToDeath(recipient, cookie, flags) status_t +unlinkToDeath(recipient, cookie, flags, outRecipient) status_t +transact(code, data, reply, flags) status_t +localBinder() BBinder +remoteBinder() BpBinder } class BpBinder { } class BBinder { +transact(code, data, reply, flags) #onTransact(code, data, reply, flags) } class BnInterface~INTERFACE~ { +queryLocalInterface(_descriptor) IInterface +getInterfaceDescriptor() descriptor #onAsBinder() IBinder } class BnGraphicBufferProducer { +onTransact() status_t } class IInterface { +asBinder(IInterface*) IBinder } class IGraphicBufferProducer { +ipcMethod() } class BufferQueueProducer { +ipcMethod() } class JavaBBinder { +onTransact() } IBinder \u0026lt;|-- BpBinder IBinder \u0026lt;|-- BBinder BBinder \u0026lt;|-- BnInterface : native type server BBinder \u0026lt;|-- JavaBBinder : java type server BnInterface \u0026lt;|-- BnGraphicBufferProducer : BnInterface\u0026lt;IGraphicBufferProducer\u0026gt; IInterface \u0026lt;|-- IGraphicBufferProducer BnGraphicBufferProducer \u0026lt;|-- BufferQueueProducer IGraphicBufferProducer \u0026lt;|.. BnInterface : INTERFACE classDiagram class IBinder { +queryLocalInterface(descriptor) IInterface +linkToDeath(recipient, flags) +unlinkToDeath(recipient, flags) +transact(code, data, reply, flags) } class BinderProxy { } class Binder { +attachInterface(iinterface, descriptor) +transact(code, data, reply, flags) #onTransact(code, data, reply, flags) } class Stub { +asInterface(iBinder) IConnectivityManager +asBinder() IBinder +onTransact(code, data, reply, flags) } class IInterface { +asBinder() IBinder } class IConnectivityManager { +ipcMethod() } class ConnectivityService { +ipcMethod() } class Proxy { - IBinder mRemote +ipcMethod() } IBinder \u0026lt;|-- BinderProxy IBinder \u0026lt;|-- Binder Binder \u0026lt;|-- Stub IConnectivityManager \u0026lt;|.. Stub IInterface \u0026lt;|-- IConnectivityManager Stub \u0026lt;|-- ConnectivityService IConnectivityManager \u0026lt;|.. Proxy Stub --\u0026gt; Proxy : asInterface返回 NativeBBinder associated with JavaBinder 原理图 addService frameworks/base/core/java/android/os/ServiceManager.java\nServiceManager /** * Place a new @a service called @a name into the service * manager. * * @param name the name of the new service * @param service the service object * @param allowIsolated set to true to allow isolated sandboxed processes * @param dumpPriority supported dump priority levels as a bitmask * to access this service */ public static void addService(String name, IBinder service, boolean allowIsolated, int dumpPriority) { getIServiceManager().addService(name, service, allowIsolated, dumpPriority); } getService \u0026amp;\u0026amp; asInterface 即getiservicemanager()过程参考binderclient\nuseService(addService) class ServiceManagerProxy implements IServiceManager { public ServiceManagerProxy(IBinder remote) { mRemote = remote; } public IBinder asBinder() { return mRemote; } public void addService(String name, IBinder service, boolean allowIsolated, int dumpPriority) throws RemoteException { Parcel data = Parcel.obtain(); Parcel reply = Parcel.obtain(); data.writeInterfaceToken(IServiceManager.descriptor); data.writeString(name); data.writeStrongBinder(service); data.writeInt(allowIsolated ? 1 : 0); data.writeInt(dumpPriority); mRemote.transact(ADD_SERVICE_TRANSACTION, data, reply, 0); reply.recycle(); data.recycle(); } } writeStrongBinder记录BBinder /** * Write an object into the parcel at the current dataPosition(), * growing dataCapacity() if needed. */ public final void writeStrongBinder(IBinder val) { nativeWriteStrongBinder(mNativePtr, val); } frameworks/base/core/jni/android_os_Parcel.cpp\nstatic void android_os_Parcel_writeStrongBinder(JNIEnv* env, jclass clazz, jlong nativePtr, jobject object) { Parcel* parcel = reinterpret_cast\u0026lt;Parcel*\u0026gt;(nativePtr); if (parcel != NULL) { const status_t err = parcel-\u0026gt;writeStrongBinder(ibinderForJavaObject(env, object)); if (err != NO_ERROR) { signalExceptionForError(env, clazz, err); } } } frameworks/base/core/jni/android_util_Binder.cpp\nc和javaBinder对应 gBinderOffsets.mClass = MakeGlobalRefOrDie(env, clazz); gBinderOffsets.mExecTransact = GetMethodIDOrDie(env, clazz, \u0026#34;execTransact\u0026#34;, \u0026#34;(IJJI)Z\u0026#34;); gBinderOffsets.mObject = GetFieldIDOrDie(env, clazz, \u0026#34;mObject\u0026#34;, \u0026#34;J\u0026#34;); sp\u0026lt;IBinder\u0026gt; ibinderForJavaObject(JNIEnv* env, jobject obj) { if (obj == NULL) return NULL; // Instance of Binder?  if (env-\u0026gt;IsInstanceOf(obj, gBinderOffsets.mClass)) { JavaBBinderHolder* jbh = (JavaBBinderHolder*) env-\u0026gt;GetLongField(obj, gBinderOffsets.mObject); return jbh-\u0026gt;get(env, obj); } // Instance of BinderProxy?  if (env-\u0026gt;IsInstanceOf(obj, gBinderProxyOffsets.mClass)) { return getBPNativeData(env, obj)-\u0026gt;mObject; } ALOGW(\u0026#34;ibinderForJavaObject: %p is not a Binder object\u0026#34;, obj); return NULL; } frameworks/base/core/jni/android_util_Binder.cpp\nclass JavaBBinderHolder { public: sp\u0026lt;JavaBBinder\u0026gt; get(JNIEnv* env, jobject obj) { sp\u0026lt;JavaBBinder\u0026gt; b = mBinder.promote(); if (b == NULL) { b = new JavaBBinder(env, obj); mBinder = b; } return b; } wp\u0026lt;JavaBBinder\u0026gt; mBinder; } frameworks/native/libs/binder/Parcel.cpp\nstatus_t Parcel::writeStrongBinder(const sp\u0026lt;IBinder\u0026gt;\u0026amp; val) { return flatten_binder(ProcessState::self(), val, this); } 将BBinder设置为flat_binder_object的cookie status_t flatten_binder(const sp\u0026lt;ProcessState\u0026gt;\u0026amp; /*proc*/, const sp\u0026lt;IBinder\u0026gt;\u0026amp; binder, Parcel* out) { flat_binder_object obj; if (binder != NULL) { IBinder *local = binder-\u0026gt;localBinder();//本地Binder即BBinder,即Server端的Binder  if (!local) {//BBinder为空时  BpBinder *proxy = binder-\u0026gt;remoteBinder(); const int32_t handle = proxy ? proxy-\u0026gt;handle() : 0; obj.hdr.type = BINDER_TYPE_HANDLE; obj.binder = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ obj.handle = handle; obj.cookie = 0; } else { //进入该分支  obj.hdr.type = BINDER_TYPE_BINDER;//后续在binder_transaction时会被调整为BINDER_TYPE_HANDLE类型，进而保存到serviceManager的链表当中  obj.binder = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local-\u0026gt;getWeakRefs()); obj.cookie = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local);//BBinder设置为flat_binder_object的cookie  } } else { obj.hdr.type = BINDER_TYPE_BINDER; obj.binder = 0; obj.cookie = 0; } return finish_flatten_binder(binder, obj, out); } 将flat_binder_object写入Parcel inline static status_t finish_flatten_binder( const sp\u0026lt;IBinder\u0026gt;\u0026amp; , const flat_binder_object\u0026amp; flat, Parcel* out) { return out-\u0026gt;writeObject(flat, false);//将flat_binder_object写入out } transact(ADD_SERVICE_TRANSACTION\u0026hellip;) mRemote.transact(ADD_SERVICE_TRANSACTION, data, reply, 0); serverInit camefromzygote\nframeworks/native/libs/binder/ProcessState.cpp\n#define BINDER_VM_SIZE ((1 * 1024 * 1024) - sysconf(_SC_PAGE_SIZE) * 2) #define DEFAULT_MAX_BINDER_THREADS 15 ProcessState::self sp\u0026lt;ProcessState\u0026gt; ProcessState::self() { gProcess = new ProcessState(\u0026#34;/dev/binder\u0026#34;); return gProcess; } open_driver \u0026amp;\u0026amp; mmap ProcessState::ProcessState(const char *driver) : mDriverName(String8(driver)) , mDriverFD(open_driver(driver))//call open_driver  , mVMStart(MAP_FAILED) , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER) , mThreadCountDecrement(PTHREAD_COND_INITIALIZER) , mExecutingThreadsCount(0) , mMaxThreads(DEFAULT_MAX_BINDER_THREADS) , mStarvationStartTimeMs(0) , mManagesContexts(false) , mBinderContextCheckFunc(NULL) , mBinderContextUserData(NULL) , mThreadPoolStarted(false) , mThreadPoolSeq(1) { if (mDriverFD \u0026gt;= 0) { // mmap the binder, providing a chunk of virtual address space to receive transactions.  mVMStart = mmap(0, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0); } } static int open_driver(const char *driver) { int fd = open(driver, O_RDWR | O_CLOEXEC); if (fd \u0026gt;= 0) { int vers = 0; status_t result = ioctl(fd, BINDER_VERSION, \u0026amp;vers); size_t maxThreads = DEFAULT_MAX_BINDER_THREADS; result = ioctl(fd, BINDER_SET_MAX_THREADS, \u0026amp;maxThreads); } else { ALOGW(\u0026#34;Opening \u0026#39;%s\u0026#39; failed: %s\\n\u0026#34;, driver, strerror(errno)); } return fd; } startThreadPool void ProcessState::startThreadPool() { AutoMutex _l(mLock); if (!mThreadPoolStarted) { mThreadPoolStarted = true; spawnPooledThread(true); } } spawnPooledThread void ProcessState::spawnPooledThread(bool isMain)//创建一个Thread用于提供Binder服务 { if (mThreadPoolStarted) { String8 name = makeBinderThreadName(); ALOGV(\u0026#34;Spawning new pooled thread, name=%s\\n\u0026#34;, name.string()); sp\u0026lt;Thread\u0026gt; t = new PoolThread(isMain); t-\u0026gt;run(name.string()); } } String8 ProcessState::makeBinderThreadName() { int32_t s = android_atomic_add(1, \u0026amp;mThreadPoolSeq); pid_t pid = getpid(); String8 name; name.appendFormat(\u0026#34;Binder:%d_%X\u0026#34;, pid, s); return name; } PoolThread::threadLoop │50 class PoolThread : public Thread │51 { 58 protected: │59 virtual bool threadLoop() │60 { \u0026gt;│61 IPCThreadState::self()-\u0026gt;joinThreadPool(mIsMain); │62 return false; │63 } 66 }; void IPCThreadState::threadDestructor(void *st) { IPCThreadState* const self = static_cast\u0026lt;IPCThreadState*\u0026gt;(st); if (self) { self-\u0026gt;flushCommands(); if (self-\u0026gt;mProcess-\u0026gt;mDriverFD \u0026gt; 0) { ioctl(self-\u0026gt;mProcess-\u0026gt;mDriverFD, BINDER_THREAD_EXIT, 0); } delete self; } } IPCThreadState::joinThreadPool 528 void IPCThreadState::joinThreadPool(bool isMain) │529 { │532 mOut.writeInt32(isMain ? BC_ENTER_LOOPER : BC_REGISTER_LOOPER); │533 │534 status_t result; │535 do { │536 processPendingDerefs(); │537 // now get the next command to be processed, waiting if necessary  \u0026gt;│538 result = getAndExecuteCommand(); │539 │540 if (result \u0026lt; NO_ERROR \u0026amp;\u0026amp; result != TIMED_OUT \u0026amp;\u0026amp; result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF) { │541 ALOGE(\u0026#34;getAndExecuteCommand(fd=%d) returned unexpected error %d, aborting\u0026#34;, │542 mProcess-\u0026gt;mDriverFD, result); │543 abort(); │544 } │545 │546 // Let this thread exit the thread pool if it is no longer  │547 // needed and it is not the main process thread.  │548 if(result == TIMED_OUT \u0026amp;\u0026amp; !isMain) { │549 break; │550 } │551 } while (result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF); │552 │556 mOut.writeInt32(BC_EXIT_LOOPER); │557 talkWithDriver(false); │558 } IPCThreadState::getAndExecuteCommand │435 status_t IPCThreadState::getAndExecuteCommand() │436 { │437 status_t result; │438 int32_t cmd; │439 │440 result = talkWithDriver(); 441 if (result \u0026gt;= NO_ERROR) { │442 size_t IN = mIn.dataAvail(); │443 if (IN \u0026lt; sizeof(int32_t)) return result; │444 cmd = mIn.readInt32(); \u0026gt;│458 result = executeCommand(cmd); │459 │460 pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); │461 mProcess-\u0026gt;mExecutingThreadsCount--; │471 pthread_cond_broadcast(\u0026amp;mProcess-\u0026gt;mThreadCountDecrement); │472 pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); │473 } │474 │475 return result; │476 } │477 IPCThreadState::executeCommand │998 status_t IPCThreadState::executeCommand(int32_t cmd) │999 { │1000 BBinder* obj; │1001 RefBase::weakref_type* refs; │1002 status_t result = NO_ERROR; │1003 │1004 switch ((uint32_t)cmd) { 1077 case BR_TRANSACTION: │1078 { │1079 binder_transaction_data tr; │1080 result = mIn.read(\u0026amp;tr, sizeof(tr)); │1103 Parcel reply; │1104 status_t error; │1116 if (tr.target.ptr) { │1117 // We only have a weak reference on the target object, so we must first try to  │1118 // safely acquire a strong reference before doing anything else with it.  │1119 if (reinterpret_cast\u0026lt;RefBase::weakref_type*\u0026gt;( │1120 tr.target.ptr)-\u0026gt;attemptIncStrong(this)) { \u0026gt;│1121 error = reinterpret_cast\u0026lt;BBinder*\u0026gt;(tr.cookie)-\u0026gt;transact(tr.code, buffer, │1122 \u0026amp;reply, tr.flags); │1123 reinterpret_cast\u0026lt;BBinder*\u0026gt;(tr.cookie)-\u0026gt;decStrong(this); │1124 } else { │1125 error = UNKNOWN_TRANSACTION; │1126 } │1127 │1128 } else { │1129 error = the_context_object-\u0026gt;transact(tr.code, buffer, \u0026amp;reply, tr.flags); │1130 } │1135 if ((tr.flags \u0026amp; TF_ONE_WAY) == 0) { │1136 LOG_ONEWAY(\u0026#34;Sending reply to %d!\u0026#34;, mCallingPid); │1137 if (error \u0026lt; NO_ERROR) reply.setError(error); │1138 sendReply(reply, 0); │1139 } else { │1140 LOG_ONEWAY(\u0026#34;NOT sending reply to %d!\u0026#34;, mCallingPid); │1141 } │1155 break; case BR_SPAWN_LOOPER: mProcess-\u0026gt;spawnPooledThread(false); break; binder_transaction_data.cookie作为BBinder,调用其transact │118 status_t BBinder::transact( │119 uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) │120 { │121 data.setDataPosition(0); │122 │123 status_t err = NO_ERROR; │124 switch (code) { │125 case PING_TRANSACTION: │126 reply-\u0026gt;writeInt32(pingBinder()); │127 break; │128 default: \u0026gt;│129 err = onTransact(code, data, reply, flags); │130 break; │131 } │132 │133 if (reply != NULL) { │134 reply-\u0026gt;setDataPosition(0); │135 } │136 │137 return err; │138 } JavaBBinder::onTransact调用java层Binder对应的execTransact方法 参考c和javabinder对应\nvirtual status_t onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0) { JNIEnv* env = javavm_to_jnienv(mVM); //printf(\u0026#34;Transact from %p to Java code sending: \u0026#34;, this);  //data.print();  //printf(\u0026#34;\\n\u0026#34;);  jboolean res = env-\u0026gt;CallBooleanMethod(mObject, gBinderOffsets.mExecTransact, code, reinterpret_cast\u0026lt;jlong\u0026gt;(\u0026amp;data), reinterpret_cast\u0026lt;jlong\u0026gt;(reply), flags); Binder.java\n// Entry point from android_util_Binder.cpp\u0026#39;s onTransact  private boolean execTransact(int code, long dataObj, long replyObj, int flags) { res = onTransact(code, data, reply, flags); } 其他关联知识点 system/core/libutils/Threads.cpp\nThreads::run status_t Thread::run(const char* name, int32_t priority, size_t stack) { if (mCanCallJava) { res = createThreadEtc(_threadLoop, this, name, priority, stack, \u0026amp;mThread); } else { res = androidCreateRawThreadEtc(_threadLoop, this, name, priority, stack, \u0026amp;mThread); } androidCreateRawThreadEtc int androidCreateRawThreadEtc(android_thread_func_t entryFunction, void *userData, const char* threadName __android_unused, int32_t threadPriority, size_t threadStackSize, android_thread_id_t *threadId) { int result = pthread_create(\u0026amp;thread, \u0026amp;attr, (android_pthread_entry)entryFunction, userData); } _threadLoop │711 int Thread::_threadLoop(void* user) │712 { 726 do { │727 bool result; │728 if (first) { │729 first = false; │730 self-\u0026gt;mStatus = self-\u0026gt;readyToRun(); │731 result = (self-\u0026gt;mStatus == NO_ERROR); │732 │733 if (result \u0026amp;\u0026amp; !self-\u0026gt;exitPending()) { │734 // Binder threads (and maybe others) rely on threadLoop  │735 // running at least once after a successful ::readyToRun()  │736 // (unless, of course, the thread has already been asked to exit  │737 // at that point).  │738 // This is because threads are essentially used like this:  │739 // (new ThreadSubclass())-\u0026gt;run();  │740 // The caller therefore does not retain a strong reference to  │741 // the thread and the thread would simply disappear after the  │742 // successful ::readyToRun() call instead of entering the  │743 // threadLoop at least once.  \u0026gt;│744 result = self-\u0026gt;threadLoop(); │745 } │746 } else { │747 result = self-\u0026gt;threadLoop(); │748 } 766 // Release our strong reference, to let a chance to the thread  │767 // to die a peaceful death.  │768 strong.clear(); │769 // And immediately, re-acquire a strong reference for the next loop  │770 strong = weak.promote(); │771 } while(strong != 0); frameworks/native/libs/binder/include/binder/IBinder.h\nIBinder /** * Base class and low-level protocol for a remotable object. * You can derive from this class to create an object for which other * processes can hold references to it. Communication between processes * (method calls, property get and set) is down through a low-level * protocol implemented on top of the transact() API. */ class IBinder : public virtual RefBase { /** * Check if this IBinder implements the interface named by * @a descriptor. If it does, the base pointer to it is returned, * which you can safely static_cast\u0026lt;\u0026gt; to the concrete C++ interface. */ virtual sp\u0026lt;IInterface\u0026gt; queryLocalInterface(const String16\u0026amp; descriptor); virtual status_t transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0) = 0; /** * Register the @a recipient for a notification if this binder * goes away. If this binder object unexpectedly goes away * (typically because its hosting process has been killed), * then DeathRecipient::binderDied() will be called with a reference * to this. * * The @a cookie is optional -- if non-NULL, it should be a * memory address that you own (that is, you know it is unique). * * @note You will only receive death notifications for remote binders, * as local binders by definition can\u0026#39;t die without you dying as well. * Trying to use this function on a local binder will result in an * INVALID_OPERATION code being returned and nothing happening. * * @note This link always holds a weak reference to its recipient. * * @note You will only receive a weak reference to the dead * binder. You should not try to promote this to a strong reference. * (Nor should you need to, as there is nothing useful you can * directly do with it now that it has passed on.) */ virtual status_t linkToDeath(const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie = NULL, uint32_t flags = 0) = 0; frameworks/native/libs/binder/include/binder/Binder.h\nBBinder class BBinder : public IBinder { public: virtual status_t transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0); virtual status_t linkToDeath(const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie = NULL, uint32_t flags = 0); protected: virtual ~BBinder(); virtual status_t onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0); frameworks/native/libs/binder/include/binder/IInterface.h\nIInterface class IInterface : public virtual RefBase { public: IInterface(); static sp\u0026lt;IBinder\u0026gt; asBinder(const IInterface*); static sp\u0026lt;IBinder\u0026gt; asBinder(const sp\u0026lt;IInterface\u0026gt;\u0026amp;); protected: virtual ~IInterface(); virtual IBinder* onAsBinder() = 0; }; template\u0026lt;typename INTERFACE\u0026gt; class BnInterface : public INTERFACE, public BBinder { public: virtual sp\u0026lt;IInterface\u0026gt; queryLocalInterface(const String16\u0026amp; _descriptor); virtual const String16\u0026amp; getInterfaceDescriptor() const; protected: virtual IBinder* onAsBinder(); }; template\u0026lt;typename INTERFACE\u0026gt; class BpInterface : public INTERFACE, public BpRefBase { public: explicit BpInterface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; remote); protected: virtual IBinder* onAsBinder(); }; BinderInternal_setMaxThreads frameworks/base/core/jni/android_util_Binder.cpp\nstatic void android_os_BinderInternal_setMaxThreads(JNIEnv* env, jobject clazz, jint maxThreads)// called by SystemServer.java BinderInternal.setMaxThreads { ProcessState::self()-\u0026gt;setThreadPoolMaxThreadCount(maxThreads); } frameworks/native/libs/binder/BpBinder.cpp\nBpBinder::create BpBinder* BpBinder::create(int32_t handle) { int32_t trackedUid = -1; if (sCountByUidEnabled) { trackedUid = IPCThreadState::self()-\u0026gt;getCallingUid(); } return new BpBinder(handle, trackedUid); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderservicemanager/",
	"title": "BinderServiceManager",
	"tags": [],
	"description": "",
	"content": "Sequence svclist frameworks/native/cmds/servicemanager/service_manager.c\nservice_manager.c(ServiceManger is single thread) main int main(int argc, char** argv) { struct binder_state *bs; union selinux_callback cb; char *driver; if (argc \u0026gt; 1) { driver = argv[1]; } else { driver = \u0026#34;/dev/binder\u0026#34;; } bs = binder_open(driver, 128*1024);//1  if (binder_become_context_manager(bs)) {//2  ALOGE(\u0026#34;cannot become context manager (%s)\\n\u0026#34;, strerror(errno)); return -1; } binder_loop(bs, svcmgr_handler);//3  return 0; } binder_open\nbinder_become_context_manager\nbinder_loop\nsvcmgr_handler int svcmgr_handler(struct binder_state *bs, struct binder_transaction_data *txn, struct binder_io *msg, struct binder_io *reply) { switch(txn-\u0026gt;code) { case SVC_MGR_GET_SERVICE: case SVC_MGR_CHECK_SERVICE: s = bio_get_string16(msg, \u0026amp;len); handle = do_find_service(s, len, txn-\u0026gt;sender_euid, txn-\u0026gt;sender_pid); if (!handle) break; bio_put_ref(reply, handle); return 0; case SVC_MGR_ADD_SERVICE: s = bio_get_string16(msg, \u0026amp;len); handle = bio_get_ref(msg); allow_isolated = bio_get_uint32(msg) ? 1 : 0; dumpsys_priority = bio_get_uint32(msg); if (do_add_service(bs, s, len, handle, txn-\u0026gt;sender_euid, allow_isolated, dumpsys_priority, txn-\u0026gt;sender_pid)) return -1; break; case SVC_MGR_LIST_SERVICES: { uint32_t n = bio_get_uint32(msg); uint32_t req_dumpsys_priority = bio_get_uint32(msg); if (!svc_can_list(txn-\u0026gt;sender_pid, txn-\u0026gt;sender_euid)) { ALOGE(\u0026#34;list_service() uid=%d - PERMISSION DENIED\\n\u0026#34;, txn-\u0026gt;sender_euid); return -1; } si = svclist; // walk through the list of services n times skipping services that  // do not support the requested priority  while (si) { if (si-\u0026gt;dumpsys_priority \u0026amp; req_dumpsys_priority) { if (n == 0) break; n--; } si = si-\u0026gt;next; } if (si) { bio_put_string16(reply, si-\u0026gt;name); return 0; } return -1; } default: ALOGE(\u0026#34;unknown code %d\\n\u0026#34;, txn-\u0026gt;code); return -1; } bio_put_uint32(reply, 0); return 0; } bio_get_string16\ndo_find_service\ndo_add_service int do_add_service(struct binder_state *bs, const uint16_t *s, size_t len, uint32_t handle, uid_t uid, int allow_isolated, uint32_t dumpsys_priority, pid_t spid) { struct svcinfo *si; if (!handle || (len == 0) || (len \u0026gt; 127)) return -1; if (!svc_can_register(s, len, spid, uid)) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - PERMISSION DENIED\\n\u0026#34;, str8(s, len), handle, uid); return -1; } si = find_svc(s, len); if (si) { if (si-\u0026gt;handle) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - ALREADY REGISTERED, OVERRIDE\\n\u0026#34;, str8(s, len), handle, uid); svcinfo_death(bs, si); } si-\u0026gt;handle = handle; } else { si = malloc(sizeof(*si) + (len + 1) * sizeof(uint16_t)); if (!si) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - OUT OF MEMORY\\n\u0026#34;, str8(s, len), handle, uid); return -1; } si-\u0026gt;handle = handle; si-\u0026gt;len = len; memcpy(si-\u0026gt;name, s, (len + 1) * sizeof(uint16_t)); si-\u0026gt;name[len] = \u0026#39;\\0\u0026#39;; si-\u0026gt;death.func = (void*) svcinfo_death; si-\u0026gt;death.ptr = si; si-\u0026gt;allow_isolated = allow_isolated; si-\u0026gt;dumpsys_priority = dumpsys_priority; si-\u0026gt;next = svclist; svclist = si; } binder_acquire(bs, handle); binder_link_to_death(bs, handle, \u0026amp;si-\u0026gt;death); return 0; } do_find_service uint32_t do_find_service(const uint16_t *s, size_t len, uid_t uid, pid_t spid) { struct svcinfo *si = find_svc(s, len); if (!si || !si-\u0026gt;handle) { return 0; } if (!si-\u0026gt;allow_isolated) { // If this service doesn\u0026#39;t allow access from isolated processes,  // then check the uid to see if it is isolated.  uid_t appid = uid % AID_USER; if (appid \u0026gt;= AID_ISOLATED_START \u0026amp;\u0026amp; appid \u0026lt;= AID_ISOLATED_END) { return 0; } } if (!svc_can_find(s, len, spid, uid)) { return 0; } return si-\u0026gt;handle; } find_svc\nstruct svcinfo struct svcinfo { struct svcinfo *next; uint32_t handle; struct binder_death death; int allow_isolated; uint32_t dumpsys_priority; size_t len; uint16_t name[0]; }; find_svc struct svcinfo *find_svc(const uint16_t *s16, size_t len) { struct svcinfo *si; for (si = svclist; si; si = si-\u0026gt;next) { if ((len == si-\u0026gt;len) \u0026amp;\u0026amp; !memcmp(s16, si-\u0026gt;name, len * sizeof(uint16_t))) { return si; } } return NULL; } frameworks/native/cmds/servicemanager/binder.c\nbinder.c binder_open struct binder_state *binder_open(const char* driver, size_t mapsize) { struct binder_state *bs; struct binder_version vers; bs-\u0026gt;fd = open(driver, O_RDWR | O_CLOEXEC); ioctl(bs-\u0026gt;fd, BINDER_VERSION, \u0026amp;vers) bs-\u0026gt;mapped = mmap(NULL, mapsize, PROT_READ, MAP_PRIVATE, bs-\u0026gt;fd, 0); } binder_become_context_manager int binder_become_context_manager(struct binder_state *bs) { return ioctl(bs-\u0026gt;fd, BINDER_SET_CONTEXT_MGR, 0); } binder_loop void binder_loop(struct binder_state *bs, binder_handler func) { int res; struct binder_write_read bwr; uint32_t readbuf[32]; bwr.write_size = 0; bwr.write_consumed = 0; bwr.write_buffer = 0; readbuf[0] = BC_ENTER_LOOPER; binder_write(bs, readbuf, sizeof(uint32_t)); for (;;) { bwr.read_size = sizeof(readbuf); bwr.read_consumed = 0; bwr.read_buffer = (uintptr_t) readbuf; res = ioctl(bs-\u0026gt;fd, BINDER_WRITE_READ, \u0026amp;bwr); res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func); } } binder_parse\nbinder_write int binder_write(struct binder_state *bs, void *data, size_t len) { struct binder_write_read bwr; int res; bwr.write_size = len; bwr.write_consumed = 0; bwr.write_buffer = (uintptr_t) data; bwr.read_size = 0; bwr.read_consumed = 0; bwr.read_buffer = 0; res = ioctl(bs-\u0026gt;fd, BINDER_WRITE_READ, \u0026amp;bwr); return res; } binder_parse int binder_parse(struct binder_state *bs, struct binder_io *bio, uintptr_t ptr, size_t size, binder_handler func) { while (ptr \u0026lt; end) { uint32_t cmd = *(uint32_t *) ptr; ptr += sizeof(uint32_t); switch(cmd) { case BR_TRANSACTION: { struct binder_transaction_data *txn = (struct binder_transaction_data *) ptr; if ((end - ptr) \u0026lt; sizeof(*txn)) { ALOGE(\u0026#34;parse: txn too small!\\n\u0026#34;); return -1; } binder_dump_txn(txn); if (func) { unsigned rdata[256/4]; struct binder_io msg; struct binder_io reply; int res; bio_init(\u0026amp;reply, rdata, sizeof(rdata), 4); bio_init_from_txn(\u0026amp;msg, txn); res = func(bs, txn, \u0026amp;msg, \u0026amp;reply);//callback method svcmgr_handler  if (txn-\u0026gt;flags \u0026amp; TF_ONE_WAY) { binder_free_buffer(bs, txn-\u0026gt;data.ptr.buffer); } else { binder_send_reply(bs, \u0026amp;reply, txn-\u0026gt;data.ptr.buffer, res); } } ptr += sizeof(*txn); break; } } bio_init_from_txn\nsvcmgr_handler\nstruct binder_io struct binder_io { char *data; /* pointer to read/write from */ binder_size_t *offs; /* array of offsets */ size_t data_avail; /* bytes available in data buffer */ size_t offs_avail; /* entries available in offsets array */ char *data0; /* start of data buffer */ binder_size_t *offs0; /* start of offsets buffer */ uint32_t flags; uint32_t unused; }; bio_init_from_txn void bio_init_from_txn(struct binder_io *bio, struct binder_transaction_data *txn) { bio-\u0026gt;data = bio-\u0026gt;data0 = (char *)(intptr_t)txn-\u0026gt;data.ptr.buffer; bio-\u0026gt;offs = bio-\u0026gt;offs0 = (binder_size_t *)(intptr_t)txn-\u0026gt;data.ptr.offsets; bio-\u0026gt;data_avail = txn-\u0026gt;data_size; bio-\u0026gt;offs_avail = txn-\u0026gt;offsets_size / sizeof(size_t); bio-\u0026gt;flags = BIO_F_SHARED; } bio_get_string16 uint16_t *bio_get_string16(struct binder_io *bio, size_t *sz) { size_t len; /* Note: The payload will carry 32bit size instead of size_t */ len = (size_t) bio_get_uint32(bio); if (sz) *sz = len; return bio_get(bio, (len + 1) * sizeof(uint16_t)); } uint32_t bio_get_uint32(struct binder_io *bio) { uint32_t *ptr = bio_get(bio, sizeof(*ptr)); return ptr ? *ptr : 0; } bio_get static void *bio_get(struct binder_io *bio, size_t size) { size = (size + 3) \u0026amp; (~3); if (bio-\u0026gt;data_avail \u0026lt; size){ bio-\u0026gt;data_avail = 0; bio-\u0026gt;flags |= BIO_F_OVERFLOW; return NULL; } else { void *ptr = bio-\u0026gt;data; bio-\u0026gt;data += size; bio-\u0026gt;data_avail -= size; return ptr; } } bio_get_ref uint32_t bio_get_ref(struct binder_io *bio) { struct flat_binder_object *obj; obj = _bio_get_obj(bio); if (!obj) return 0; if (obj-\u0026gt;hdr.type == BINDER_TYPE_HANDLE) return obj-\u0026gt;handle; return 0; } bio_put_ref void bio_put_ref(struct binder_io *bio, uint32_t handle) { struct flat_binder_object *obj; if (handle) obj = bio_alloc_obj(bio); else obj = bio_alloc(bio, sizeof(*obj)); if (!obj) return; obj-\u0026gt;flags = 0x7f | FLAT_BINDER_FLAG_ACCEPTS_FDS; obj-\u0026gt;hdr.type = BINDER_TYPE_HANDLE; obj-\u0026gt;handle = handle; obj-\u0026gt;cookie = 0; } _bio_get_obj static struct flat_binder_object *_bio_get_obj(struct binder_io *bio) { size_t n; size_t off = bio-\u0026gt;data - bio-\u0026gt;data0; for (n = 0; n \u0026lt; bio-\u0026gt;offs_avail; n++) { if (bio-\u0026gt;offs[n] == off) return bio_get(bio, sizeof(struct flat_binder_object)); } bio-\u0026gt;data_avail = 0; bio-\u0026gt;flags |= BIO_F_OVERFLOW; return NULL; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binder%E5%8E%9F%E7%90%86/",
	"title": "Binder原理",
	"tags": [],
	"description": "",
	"content": "写给 android 应用工程师的 binder 原理剖析\n架构设计分析（三）Android 9.0 Binder机制\n彻底理解Android Binder通信架构 Android 6.0\nBinder系列5—注册服务(addService)\nAndroid IPC: Part 2 - Binder and Service Manager Perspective\n深入理解Binder通信原理及面试问题\nBinder | 内存拷贝的本质和变迁\nLinux 背景知识 传统 IPC 通信原理 Binder IPC 原理 BinderProcedure flow struct binder_write_read transact total "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/bitmap/bitmap/",
	"title": "Bitmap",
	"tags": [],
	"description": "",
	"content": "Bitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/bitmap/",
	"title": "bitmap",
	"tags": [],
	"description": "",
	"content": "bitmap 探索总结bitmap知识\n Bitmap     BitmapSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/bitmap/bitmapsource/",
	"title": "BitmapSource",
	"tags": [],
	"description": "",
	"content": "类设计 NativeAllocationRegistry procedure ART reclaim NativeAllocationRegistry procedure(only object which will be reclaim(GC not reachable) would be enqueued)\ngraph TB ReferenceQueueDaemon.runInernal--\u0026gt;ReferenceQueue.enqueuePending ReferenceQueue.enqueuePending--\u0026gt;ReferenceQueue.enqueueLocked ReferenceQueue.enqueueLocked--\u0026gt;Cleaner.clean Cleaner.clean--\u0026gt;CleanerChunk.run CleanerChunk.run--\u0026gt;NativeAllocationRegistry.applyFreeFunction ImageDecoder decodeDrawable public static Drawable decodeDrawable(@NonNull Source src, @NonNull OnHeaderDecodedListener listener) throws IOException { return decodeDrawableImpl(src, listener); } decodeDrawableImpl private static Drawable decodeDrawableImpl(@NonNull Source src, @Nullable OnHeaderDecodedListener listener) throws IOException { ImageDecoder decoder = src.createImageDecoder() decoder.mSource = src; decoder.callHeaderDecoded(listener, src); Bitmap bm = decoder.decodeBitmapInternal(); return new BitmapDrawable(res, bm); } decodeBitmapInternal private Bitmap decodeBitmapInternal() throws IOException { checkState(); return nDecodeBitmap(mNativePtr, this, mPostProcessor != null, mDesiredWidth, mDesiredHeight, mCropRect, mMutable, mAllocator, mUnpremultipliedRequired, mConserveMemory, mDecodeAsAlphaMask, mDesiredColorSpace); } Source frameworks/base/core/jni/android/graphics/ImageDecoder.cpp\nImageDecoder.cpp ImageDecoder_nDecodeBitmap static jobject ImageDecoder_nDecodeBitmap(JNIEnv* env, jobject /*clazz*/, jlong nativePtr, jobject jdecoder, jboolean jpostProcess, jint desiredWidth, jint desiredHeight, jobject jsubset, jboolean requireMutable, jint allocator, jboolean requireUnpremul, jboolean preferRamOverQuality, jboolean asAlphaMask, jobject jcolorSpace) {\t...... SkBitmap bm; auto bitmapInfo = decodeInfo; if (asAlphaMask \u0026amp;\u0026amp; colorType == kGray_8_SkColorType) { bitmapInfo = bitmapInfo.makeColorType(kAlpha_8_SkColorType); } if (!bm.setInfo(bitmapInfo)) { doThrowIOE(env, \u0026#34;Failed to setInfo properly\u0026#34;); return nullptr; } sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap; // If we are going to scale or subset, we will create a new bitmap later on,  // so use the heap for the temporary.  // FIXME: Use scanline decoding on only a couple lines to save memory. b/70709380.  if (allocator == ImageDecoder::kSharedMemory_Allocator \u0026amp;\u0026amp; !scale \u0026amp;\u0026amp; !jsubset) { nativeBitmap = Bitmap::allocateAshmemBitmap(\u0026amp;bm); } else { nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;bm);//nativeBitmap和bm都被赋值完毕  } ...... return bitmap::createBitmap(env, nativeBitmap.release(), bitmapCreateFlags, ninePatchChunk, ninePatchInsets); } allocateheapbitmap\ncreateBitmap\nBitmap.java android/graphics/Bitmap.java\ncreateBitmap public static Bitmap createBitmap(@Nullable DisplayMetrics display, int width, int height, @NonNull Config config, boolean hasAlpha, @NonNull ColorSpace colorSpace) { bm = nativeCreate(null, 0, width, width, height, config.nativeInt, true, null, null); return bm; nativeCreate\nBitmapCons() /** * Private constructor that must received an already allocated native bitmap * int (pointer). */ // called from JNI Bitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { mWidth = width; mHeight = height; mIsMutable = isMutable; mRequestPremultiplied = requestPremultiplied; mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); } frameworks/base/core/jni/android/graphics/\nBitmap.cpp(graphics) gBitmapMethods nativeCreate \u0026ndash;\u0026gt; Bitmap_creator\nstatic const JNINativeMethod gBitmapMethods[] = { { \u0026#34;nativeCreate\u0026#34;, \u0026#34;([IIIIIIZ[FLandroid/graphics/ColorSpace$Rgb$TransferParameters;)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_creator }, { \u0026#34;nativeCopy\u0026#34;, \u0026#34;(JIZ)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copy }, { \u0026#34;nativeCopyAshmem\u0026#34;, \u0026#34;(J)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copyAshmem }, { \u0026#34;nativeCopyAshmemConfig\u0026#34;, \u0026#34;(JI)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copyAshmemConfig }, { \u0026#34;nativeGetNativeFinalizer\u0026#34;, \u0026#34;()J\u0026#34;, (void*)Bitmap_getNativeFinalizer }, { \u0026#34;nativeRecycle\u0026#34;, \u0026#34;(J)Z\u0026#34;, (void*)Bitmap_recycle }, { \u0026#34;nativeReconfigure\u0026#34;, \u0026#34;(JIIIZ)V\u0026#34;, (void*)Bitmap_reconfigure }, { \u0026#34;nativeCompress\u0026#34;, \u0026#34;(JIILjava/io/OutputStream;[B)Z\u0026#34;, (void*)Bitmap_compress }, { \u0026#34;nativeErase\u0026#34;, \u0026#34;(JI)V\u0026#34;, (void*)Bitmap_erase }, { \u0026#34;nativeRowBytes\u0026#34;, \u0026#34;(J)I\u0026#34;, (void*)Bitmap_rowBytes }, { \u0026#34;nativeGetPixel\u0026#34;, \u0026#34;(JII)I\u0026#34;, (void*)Bitmap_getPixel }, { \u0026#34;nativeGetPixels\u0026#34;, \u0026#34;(J[IIIIIII)V\u0026#34;, (void*)Bitmap_getPixels }, { \u0026#34;nativeSetPixel\u0026#34;, \u0026#34;(JIII)V\u0026#34;, (void*)Bitmap_setPixel }, { \u0026#34;nativeSetPixels\u0026#34;, \u0026#34;(J[IIIIIII)V\u0026#34;, (void*)Bitmap_setPixels }, { \u0026#34;nativeCopyPixelsToBuffer\u0026#34;, \u0026#34;(JLjava/nio/Buffer;)V\u0026#34;, (void*)Bitmap_copyPixelsToBuffer }, { \u0026#34;nativeCopyPixelsFromBuffer\u0026#34;, \u0026#34;(JLjava/nio/Buffer;)V\u0026#34;, (void*)Bitmap_copyPixelsFromBuffer }, }; Bitmap_creator static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkBitmap bitmap; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;bitmap); if (!nativeBitmap) { ALOGE(\u0026#34;OOM allocating Bitmap with dimensions %i x %i\u0026#34;, width, height); doThrowOOME(env); return NULL; } if (jColors != NULL) { GraphicsJNI::SetPixels(env, jColors, offset, stride, 0, 0, width, height, bitmap); } return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); allocateheapbitmap\ncreateBitmap\nbitmap::createBitmap jobject createBitmap(JNIEnv* env, Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { bool isMutable = bitmapCreateFlags \u0026amp; kBitmapCreateFlag_Mutable; bool isPremultiplied = bitmapCreateFlags \u0026amp; kBitmapCreateFlag_Premultiplied; // The caller needs to have already set the alpha type properly, so the  // native SkBitmap stays in sync with the Java Bitmap.  BitmapWrapper* bitmapWrapper = new BitmapWrapper(bitmap); jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmapWrapper), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); return obj; } bitmapcons\nBitmap_getNativeFinalizer static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } Bitmap_destruct static void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } libcore/luni/src/main/java/libcore/util\nNativeAllocationRegistry.java /** * A NativeAllocationRegistry is used to associate native allocations with * Java objects and register them with the runtime. * There are two primary benefits of registering native allocations associated * with Java objects: * \u0026lt;ol\u0026gt; * \u0026lt;li\u0026gt;The runtime will account for the native allocations when scheduling * garbage collection to run.\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;The runtime will arrange for the native allocation to be automatically * freed by a user-supplied function when the associated Java object becomes * unreachable.\u0026lt;/li\u0026gt; * \u0026lt;/ol\u0026gt; * A separate NativeAllocationRegistry should be instantiated for each kind * of native allocation, where the kind of a native allocation consists of the * native function used to free the allocation and the estimated size of the * allocation. Once a NativeAllocationRegistry is instantiated, it can be * used to register any number of native allocations of that kind. * @hide */ public class NativeAllocationRegistry { public NativeAllocationRegistry(ClassLoader classLoader, long freeFunction, long size) { this.classLoader = classLoader; this.freeFunction = freeFunction; this.size = size; } } registerNativeAllocation /** * Registers a new native allocation and associated Java object with the * runtime. * This NativeAllocationRegistry\u0026#39;s \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; will * automatically be called with \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; as its sole * argument when \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable. If you * maintain copies of \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; outside * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt;, you must not access these after * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable, because they may be dangling * pointers. * \u0026lt;p\u0026gt; * The returned Runnable can be used to free the native allocation before * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable. The runnable will have no * effect if the native allocation has already been freed by the runtime * or by using the runnable. * \u0026lt;p\u0026gt; * WARNING: This unconditionally takes ownership, i.e. deallocation * responsibility of nativePtr. nativePtr will be DEALLOCATED IMMEDIATELY * if the registration attempt throws an exception (other than one reporting * a programming error). * * @param referent Non-null java object to associate the native allocation with * @param nativePtr Non-zero address of the native allocation * @return runnable to explicitly free native allocation * @throws IllegalArgumentException if either referent or nativePtr is null. * @throws OutOfMemoryError if there is not enough space on the Java heap * in which to register the allocation. In this * case, \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; will be * called with \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; as its * argument before the OutOfMemoryError is * thrown. */ public Runnable registerNativeAllocation(Object referent, long nativePtr) { if (referent == null) { throw new IllegalArgumentException(\u0026#34;referent is null\u0026#34;); } if (nativePtr == 0) { throw new IllegalArgumentException(\u0026#34;nativePtr is null\u0026#34;); } CleanerThunk thunk; CleanerRunner result; try { thunk = new CleanerThunk(); Cleaner cleaner = Cleaner.create(referent, thunk); result = new CleanerRunner(cleaner); registerNativeAllocation(this.size); } catch (VirtualMachineError vme /* probably OutOfMemoryError */) { applyFreeFunction(freeFunction, nativePtr); throw vme; } // Other exceptions are impossible.  // Enable the cleaner only after we can no longer throw anything, including OOME.  thunk.setNativePtr(nativePtr); return result; } CleanerThunk private class CleanerThunk implements Runnable { private long nativePtr; public CleanerThunk() { this.nativePtr = 0; } public void run() { if (nativePtr != 0) { applyFreeFunction(freeFunction, nativePtr); registerNativeFree(size); } } public void setNativePtr(long nativePtr) { this.nativePtr = nativePtr; } } applyFreeFunction /** * Calls \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt;(\u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt;). * Provided as a convenience in the case where you wish to manually free a * native allocation using a \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; without using a * NativeAllocationRegistry. */ public static native void applyFreeFunction(long freeFunction, long nativePtr); registerNativeFree private static void registerNativeFree(long size) { VMRuntime.getRuntime().registerNativeFree((int)Math.min(size, Integer.MAX_VALUE)); } registerNativeAllocation private static void registerNativeAllocation(long size) { VMRuntime.getRuntime().registerNativeAllocation((int)Math.min(size,Integer.MAX_VALUE)); } CleanerRunner private static class CleanerRunner implements Runnable { private final Cleaner cleaner; public CleanerRunner(Cleaner cleaner) { this.cleaner = cleaner; } public void run() { cleaner.clean(); } } libcore/ojluni/src/main/java/sun/misc/Cleaner.java\nCleaner create public class Cleaner extends PhantomReference\u0026lt;Object\u0026gt; { /** * Creates a new cleaner. * * @param ob the referent object to be cleaned * @param thunk * The cleanup code to be run when the cleaner is invoked. The * cleanup code is run directly from the reference-handler thread, * so it should be as simple and straightforward as possible. * * @return The new cleaner */ public static Cleaner create(Object ob, Runnable thunk) { if (thunk == null) return null; return add(new Cleaner(ob, thunk)); } add private static synchronized Cleaner add(Cleaner cl) { if (first != null) { cl.next = first; first.prev = cl;//双向链表，插入表头  } first = cl; return cl; }\tclean /** * Runs this cleaner, if it has not been run before. */ public void clean() { if (!remove(this)) return; try { thunk.run(); } } libcore/libart/src/main/java/dalvik/system/\nVMRuntime.java registerNativeAllocation /** * Registers a native allocation so that the heap knows about it and performs GC as required. * If the number of native allocated bytes exceeds the native allocation watermark, the * function requests a concurrent GC. If the native bytes allocated exceeds a second higher * watermark, it is determined that the application is registering native allocations at an * unusually high rate and a GC is performed inside of the function to prevent memory usage * from excessively increasing. Memory allocated via system malloc() should not be included * in this count. The argument must be the same as that later passed to registerNativeFree(), * but may otherwise be approximate. */ @UnsupportedAppUsage @libcore.api.CorePlatformApi public native void registerNativeAllocation(long bytes); frameworks/base/libs/hwui/hwui/Bitmap.cpp\nBitmap.cpp(hwui) class ANDROID_API Bitmap : public SkPixelRef {} AllocPixelRef function typedef sk_sp\u0026lt;Bitmap\u0026gt; (*AllocPixelRef)(size_t allocSize, const SkImageInfo\u0026amp; info, size_t rowBytes); allocateHeapBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateHeapBitmap(SkBitmap* bitmap) { return allocateBitmap(bitmap, \u0026amp;android::allocateHeapBitmap); } allocateBitmap static sk_sp\u0026lt;Bitmap\u0026gt; allocateBitmap(SkBitmap* bitmap, AllocPixelRef alloc) { const SkImageInfo\u0026amp; info = bitmap-\u0026gt;info(); // we must respect the rowBytes value already set on the bitmap instead of  // attempting to compute our own.  const size_t rowBytes = bitmap-\u0026gt;rowBytes(); if (!computeAllocationSize(rowBytes, bitmap-\u0026gt;height(), \u0026amp;size)) { return nullptr; } auto wrapper = alloc(size, info, rowBytes); if (wrapper) { wrapper-\u0026gt;getSkBitmap(bitmap); } return wrapper; alloc\nandroid::allocateHeapBitmap static sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { void* addr = calloc(size, 1);//申请bitmap内存空间,单位bytes，默认初始化为0  if (!addr) { return nullptr; } return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } getSkBitmap void Bitmap::getSkBitmap(SkBitmap* outBitmap) { outBitmap-\u0026gt;setHasHardwareMipMap(mHasHardwareMipMap); if (isHardware()) { if (uirenderer::Properties::isSkiaEnabled()) { outBitmap-\u0026gt;allocPixels(SkImageInfo::Make(info().width(), info().height(), info().colorType(), info().alphaType(), nullptr)); } else { outBitmap-\u0026gt;allocPixels(info()); } uirenderer::renderthread::RenderProxy::copyGraphicBufferInto(graphicBuffer(), outBitmap); if (mInfo.colorSpace()) { sk_sp\u0026lt;SkPixelRef\u0026gt; pixelRef = sk_ref_sp(outBitmap-\u0026gt;pixelRef()); outBitmap-\u0026gt;setInfo(mInfo); outBitmap-\u0026gt;setPixelRef(std::move(pixelRef), 0, 0); } return; } outBitmap-\u0026gt;setInfo(mInfo, rowBytes()); outBitmap-\u0026gt;setPixelRef(sk_ref_sp(this), 0, 0); } setinfo\nsetpixelref\nallocateAshmemBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateAshmemBitmap(SkBitmap* bitmap) { return allocateBitmap(bitmap, \u0026amp;Bitmap::allocateAshmemBitmap); } allocatebitmap\nallocateAshmemBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateAshmemBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { // Create new ashmem region with read/write priv  int fd = ashmem_create_region(\u0026#34;bitmap\u0026#34;, size); if (fd \u0026lt; 0) { return nullptr; } void* addr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if (addr == MAP_FAILED) { close(fd); return nullptr; } if (ashmem_set_prot_region(fd, PROT_READ) \u0026lt; 0) { munmap(addr, size); close(fd); return nullptr; } return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, fd, size, info, rowBytes)); } external/skia/src/core/\nSkBitmap.cpp setInfo bool SkBitmap::setInfo(const SkImageInfo\u0026amp; info, size_t rowBytes) { fPixelRef = nullptr; // Free pixels.  fPixmap.reset(info.makeAlphaType(newAT), nullptr, SkToU32(rowBytes)); return true; makealphatype\nsetPixelRef void SkBitmap::setPixelRef(sk_sp\u0026lt;SkPixelRef\u0026gt; pr, int dx, int dy) { fPixelRef = kUnknown_SkColorType != this-\u0026gt;colorType() ? std::move(pr) : nullptr; void* p = nullptr; size_t rowBytes = this-\u0026gt;rowBytes(); // ignore dx,dy if there is no pixelref  if (fPixelRef) { rowBytes = fPixelRef-\u0026gt;rowBytes(); // TODO(reed): Enforce that PixelRefs must have non-null pixels.  p = fPixelRef-\u0026gt;pixels(); if (p) { p = (char*)p + dy * rowBytes + dx * this-\u0026gt;bytesPerPixel(); } } SkPixmapPriv::ResetPixmapKeepInfo(\u0026amp;fPixmap, p, rowBytes); pixels\nexternal/skia/include/core/SkPixelRef.h\nSkPixelRef pixels void* pixels() const { return fPixels; } size_t rowBytes() const { return fRowBytes; } external/skia/include/core/\nSkImageInfo.h makeAlphaType SkImageInfo makeAlphaType(SkAlphaType newAlphaType) const { return Make(fWidth, fHeight, fColorType, newAlphaType, fColorSpace); } external/skia/src/core/\nSkPixmap reset void SkPixmap::reset(const SkImageInfo\u0026amp; info, const void* addr, size_t rowBytes) { fPixels = addr; fRowBytes = rowBytes; fInfo = info; } "
},
{
	"uri": "https://huanle19891345.github.io/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/jni/c%E5%90%AF%E5%8A%A8java/",
	"title": "C启动Java",
	"tags": [],
	"description": "",
	"content": "AndroidRuntime::start void AndroidRuntime::start(const char* className, const Vector\u0026lt;String8\u0026gt;\u0026amp; options, bool zygote){ ...... JniInvocation jni_invocation; jni_invocation.Init(NULL); JNIEnv* env; //startVm将启动虚拟机  if (startVm(\u0026amp;mJavaVM, \u0026amp;env, zygote) != 0) { return; } onVmCreated(env); ...... jclass stringClass; jobjectArray strArray; jstring classNameStr; ...... char* slashClassName = toSlashClassName(className);//\u0026#34;com.android.internal.os.RuntimeInit\u0026#34;  //找到目标类对应的mirror Class对象  jclass startClass = env-\u0026gt;FindClass(slashClassName);//main  if (startClass == NULL) {} else { //找到该类中的静态main函数对应的ArtMethod对象  jmethodID startMeth = env-\u0026gt;GetStaticMethodID(startClass, \u0026#34;main\u0026#34;,//main  \u0026#34;([Ljava/lang/String;)V\u0026#34;); if (startMeth == NULL) {} else { //调用这个main函数  env-\u0026gt;CallStaticVoidMethod(startClass, startMeth, strArray);//main  ...... } } ...... jni_internal.FindClass static jclass FindClass(JNIEnv* env, const char* name) { CHECK_NON_NULL_ARGUMENT(name); Runtime* runtime = Runtime::Current(); ClassLinker* class_linker = runtime-\u0026gt;GetClassLinker(); std::string descriptor(NormalizeJniClassDescriptor(name)); ScopedObjectAccess soa(env); mirror::Class* c = nullptr; if (runtime-\u0026gt;IsStarted()) { StackHandleScope\u0026lt;1\u0026gt; hs(soa.Self()); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle(GetClassLoader(soa))); c = class_linker-\u0026gt;FindClass(soa.Self(), descriptor.c_str(), class_loader);//main  } else { c = class_linker-\u0026gt;FindSystemClass(soa.Self(), descriptor.c_str()); } return soa.AddLocalReference\u0026lt;jclass\u0026gt;(c); } jni_internal.GetStaticMethodID static jmethodID GetStaticMethodID(JNIEnv* env, jclass java_class, const char* name, const char* sig) { CHECK_NON_NULL_ARGUMENT(java_class); CHECK_NON_NULL_ARGUMENT(name); CHECK_NON_NULL_ARGUMENT(sig); ScopedObjectAccess soa(env); return FindMethodID(soa, java_class, name, sig, true); } static jmethodID FindMethodID(ScopedObjectAccess\u0026amp; soa, jclass jni_class, const char* name, const char* sig, bool is_static) SHARED_REQUIRES(Locks::mutator_lock_) { mirror::Class* c = EnsureInitialized(soa.Self(), soa.Decode\u0026lt;mirror::Class*\u0026gt;(jni_class)); if (c == nullptr) { return nullptr; } ArtMethod* method = nullptr; auto pointer_size = Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;GetImagePointerSize(); if (is_static) { method = c-\u0026gt;FindDirectMethod(name, sig, pointer_size); } else if (c-\u0026gt;IsInterface()) { method = c-\u0026gt;FindInterfaceMethod(name, sig, pointer_size); } else { method = c-\u0026gt;FindVirtualMethod(name, sig, pointer_size); if (method == nullptr) { // No virtual method matching the signature. Search declared  // private methods and constructors.  method = c-\u0026gt;FindDeclaredDirectMethod(name, sig, pointer_size); } } ...... return soa.EncodeMethod(method); } jni_internal.CallStaticVoidMethod static void CallStaticVoidMethod(JNIEnv* env, jclass, jmethodID mid, ...) { va_list ap; va_start(ap, mid); CHECK_NON_NULL_ARGUMENT_RETURN_VOID(mid); ScopedObjectAccess soa(env); InvokeWithVarArgs(soa, nullptr, mid, ap); va_end(ap); } static jobject CallStaticObjectMethod(JNIEnv* env, jclass, jmethodID mid, ...) { va_list ap; va_start(ap, mid); ScopedObjectAccess soa(env); //先调用InvokeWithVarArgs，返回值存储在result中  JValue result(InvokeWithVarArgs(soa, nullptr, mid, ap)); jobject local_result = soa.AddLocalReference\u0026lt;jobject\u0026gt;(result.GetL()); va_end(ap); return local_result; } reflection.InvokeWithVarArgs JValue InvokeWithVarArgs(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject obj, jmethodID mid, va_list args) { ..... ArtMethod* method = soa.DecodeMethod(mid); bool is_string_init = .....; if (is_string_init) {......} mirror::Object* receiver = method-\u0026gt;IsStatic() ? nullptr : soa.Decode\u0026lt;mirror::Object*\u0026gt;(obj); uint32_t shorty_len = 0; const char* shorty = method-\u0026gt;GetInterfaceMethodIfProxy( sizeof(void*))-\u0026gt;GetShorty(\u0026amp;shorty_len); JValue result; ArgArray arg_array(shorty, shorty_len); arg_array.BuildArgArrayFromVarArgs(soa, receiver, args); //调用InvokeWithArgArray  InvokeWithArgArray(soa, method, \u0026amp;arg_array, \u0026amp;result, shorty); ..... return result; } static void InvokeWithArgArray(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, ArtMethod* method, ArgArray* arg_array, JValue* result, const char* shorty) { uint32_t* args = arg_array-\u0026gt;GetArray(); ...... //调用ArtMethod的Invoke函数  method-\u0026gt;Invoke(soa.Self(), args, arg_array-\u0026gt;GetNumBytes(), result, shorty); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/databinding/databinding/",
	"title": "Databinding",
	"tags": [],
	"description": "",
	"content": "类设计 基于androidx.databinding:databinding-runtime:4.0.1\nDataBindingUtil private static DataBinderMapper sMapper = new DataBinderMapperImpl(); private static DataBindingComponent sDefaultComponent = null; setContentView public static \u0026lt;T extends ViewDataBinding\u0026gt; T setContentView(@NonNull Activity activity, int layoutId) { return setContentView(activity, layoutId, sDefaultComponent); } public static \u0026lt;T extends ViewDataBinding\u0026gt; T setContentView(@NonNull Activity activity, int layoutId, @Nullable DataBindingComponent bindingComponent) { activity.setContentView(layoutId); View decorView = activity.getWindow().getDecorView(); ViewGroup contentView = (ViewGroup) decorView.findViewById(android.R.id.content); return bindToAddedViews(bindingComponent, contentView, 0, layoutId); } bindToAddedViews private static \u0026lt;T extends ViewDataBinding\u0026gt; T bindToAddedViews(DataBindingComponent component, ViewGroup parent, int startChildren, int layoutId) { final int endChildren = parent.getChildCount(); final int childrenAdded = endChildren - startChildren; if (childrenAdded == 1) { final View childView = parent.getChildAt(endChildren - 1); return bind(component, childView, layoutId); } else { final View[] children = new View[childrenAdded]; for (int i = 0; i \u0026lt; childrenAdded; i++) { children[i] = parent.getChildAt(i + startChildren); } return bind(component, children, layoutId); } } bind static \u0026lt;T extends ViewDataBinding\u0026gt; T bind(DataBindingComponent bindingComponent, View[] roots, int layoutId) { return (T) sMapper.getDataBinder(bindingComponent, roots, layoutId); } sMapper\nMergedDataBinderMapper public class MergedDataBinderMapper extends DataBinderMapper { private List\u0026lt;DataBinderMapper\u0026gt; mMappers = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); } getDataBinder @Override public ViewDataBinding getDataBinder(DataBindingComponent bindingComponent, View view, int layoutId) { for(DataBinderMapper mapper : mMappers) { ViewDataBinding result = mapper.getDataBinder(bindingComponent, view, layoutId); if (result != null) { return result; } } return null; } androidx.databinding.DataBinderMapperImpl public class DataBinderMapperImpl extends MergedDataBinderMapper { DataBinderMapperImpl() { addMapper(new com.example.myapplication.DataBinderMapperImpl()); } } com.example.myapplication.DataBinderMapperImpl getDataBinder @Override public ViewDataBinding getDataBinder(DataBindingComponent component, View view, int layoutId) { int localizedLayoutId = INTERNAL_LAYOUT_ID_LOOKUP.get(layoutId); final Object tag = view.getTag(); switch(localizedLayoutId) { case LAYOUT_ACTIVITYLOGIN: { if (\u0026#34;layout/activity_login_0\u0026#34;.equals(tag)) { return new ActivityLoginBindingImpl(component, view); } } } } ViewDatabinding mFrameCallback private final Choreographer.FrameCallback mFrameCallback; CREATE_LIVE_DATA_LISTENER private static final CreateWeakListener CREATE_LIVE_DATA_LISTENER = new CreateWeakListener() { @Override public WeakListener create(ViewDataBinding viewDataBinding, int localFieldId) { return new LiveDataListener(viewDataBinding, localFieldId).getListener(); } }; livedatalistener\nconstructor protected ViewDataBinding(DataBindingComponent bindingComponent, View root, int localFieldCount) { mBindingComponent = bindingComponent; mLocalFieldObservers = new WeakListener[localFieldCount]; this.mRoot = root; mChoreographer = Choreographer.getInstance(); mFrameCallback = new Choreographer.FrameCallback() { @Override public void doFrame(long frameTimeNanos) { mRebindRunnable.run(); } }; } mrebindrunnable\nsetLifecycleOwner public void setLifecycleOwner(@Nullable LifecycleOwner lifecycleOwner) { ...... mLifecycleOwner = lifecycleOwner; if (lifecycleOwner != null) { if (mOnStartListener == null) { mOnStartListener = new OnStartListener(this); } lifecycleOwner.getLifecycle().addObserver(mOnStartListener); } for (WeakListener\u0026lt;?\u0026gt; weakListener : mLocalFieldObservers) { if (weakListener != null) { weakListener.setLifecycleOwner(lifecycleOwner); } } } OnStartListener static class OnStartListener implements LifecycleObserver { final WeakReference\u0026lt;ViewDataBinding\u0026gt; mBinding; private OnStartListener(ViewDataBinding binding) { mBinding = new WeakReference\u0026lt;\u0026gt;(binding); } @OnLifecycleEvent(Lifecycle.Event.ON_START) public void onStart() { ViewDataBinding dataBinding = mBinding.get(); if (dataBinding != null) { dataBinding.executePendingBindings(); } } } executependingbindings\nrequestRebind protected void requestRebind() { if (mContainingBinding != null) { mContainingBinding.requestRebind(); } else { final LifecycleOwner owner = this.mLifecycleOwner; if (owner != null) { Lifecycle.State state = owner.getLifecycle().getCurrentState(); if (!state.isAtLeast(Lifecycle.State.STARTED)) { return; // wait until lifecycle owner is started  } } mChoreographer.postFrameCallback(mFrameCallback); } } mFrameCallback\nmRebindRunnable private final Runnable mRebindRunnable = new Runnable() { @Override public void run() { processReferenceQueue(); executePendingBindings(); } }; executePendingBindings public void executePendingBindings() { if (mContainingBinding == null) { executeBindingsInternal(); } else { mContainingBinding.executePendingBindings(); } } executeBindingsInternal private void executeBindingsInternal() { ....... executeBindings(); ...... } executebindings\nupdateLiveDataRegistration protected boolean updateLiveDataRegistration(int localFieldId, LiveData\u0026lt;?\u0026gt; observable) { mInLiveDataRegisterObserver = true; try { return updateRegistration(localFieldId, observable, CREATE_LIVE_DATA_LISTENER); } finally { mInLiveDataRegisterObserver = false; } } updateRegistration private boolean updateRegistration(int localFieldId, Object observable, CreateWeakListener listenerCreator) { ...... if (listener.getTarget() == observable) { return false;//nothing to do, same object  } unregisterFrom(localFieldId); registerTo(localFieldId, observable, listenerCreator); return true; } registerTo protected void registerTo(int localFieldId, Object observable, CreateWeakListener listenerCreator) { if (observable == null) { return; } WeakListener listener = mLocalFieldObservers[localFieldId]; if (listener == null) { listener = listenerCreator.create(this, localFieldId); mLocalFieldObservers[localFieldId] = listener; if (mLifecycleOwner != null) { listener.setLifecycleOwner(mLifecycleOwner); } } listener.setTarget(observable); } listener\nsettarget\nhandleFieldChange private void handleFieldChange(int mLocalFieldId, Object object, int fieldId) { boolean result = onFieldChange(mLocalFieldId, object, fieldId); if (result) { requestRebind(); } } requestrebind\nLiveDataListener private static class LiveDataListener implements Observer, ObservableReference\u0026lt;LiveData\u0026lt;?\u0026gt;\u0026gt; { final WeakListener\u0026lt;LiveData\u0026lt;?\u0026gt;\u0026gt; mListener; LifecycleOwner mLifecycleOwner; public LiveDataListener(ViewDataBinding binder, int localFieldId) { mListener = new WeakListener(binder, localFieldId, this); } } getListener @Override public WeakListener\u0026lt;LiveData\u0026lt;?\u0026gt;\u0026gt; getListener() { return mListener; } addListener @Override public void addListener(LiveData\u0026lt;?\u0026gt; target) { if (mLifecycleOwner != null) { target.observe(mLifecycleOwner, this); } } onChanged @Override public void onChanged(@Nullable Object o) { ViewDataBinding binder = mListener.getBinder(); if (binder != null) { binder.handleFieldChange(mListener.mLocalFieldId, mListener.getTarget(), 0); } } handlefieldchange\nWeakListener private final ObservableReference\u0026lt;T\u0026gt; mObservable; setTarget public void setTarget(T object) { unregister(); mTarget = object; if (mTarget != null) { mObservable.addListener(mTarget); } } addlistener\nActivityLoginBindingImpl private ActivityLoginBindingImpl(androidx.databinding.DataBindingComponent bindingComponent, View root, Object[] bindings) { super(bindingComponent, root, 3 , (android.widget.Button) bindings[3] , (android.widget.EditText) bindings[2] , (com.example.myapplication.arch.login.CustomTextView) bindings[4] , (android.widget.EditText) bindings[1] ); this.login.setTag(null); this.mboundView0 = (androidx.constraintlayout.widget.ConstraintLayout) bindings[0]; this.mboundView0.setTag(null); this.password.setTag(null); this.uid.setTag(null); this.userName.setTag(null); setRootTag(root); // listeners  mCallback1 = new com.example.myapplication.generated.callback.OnClickListener(this, 1); invalidateAll(); } invalidateAll public void invalidateAll() { synchronized(this) { mDirtyFlags = 0x10L; } requestRebind(); } requestrebind\nsetVm public void setVm(@Nullable com.example.myapplication.arch.login.LoginViewModel Vm) { this.mVm = Vm; synchronized(this) { mDirtyFlags |= 0x8L; } notifyPropertyChanged(BR.vm); super.requestRebind(); } onFieldChange @Override protected boolean onFieldChange(int localFieldId, Object object, int fieldId) { switch (localFieldId) { case 0 : return onChangeVmUserNameLiveData((androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt;) object, fieldId); case 1 : return onChangeVmUidLiveData((androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt;) object, fieldId); case 2 : return onChangeVmPasswordLiveData((androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt;) object, fieldId); } return false; } onChangeVmUidLiveData private boolean onChangeVmUidLiveData(androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; VmUidLiveData, int fieldId) { if (fieldId == BR._all) { synchronized(this) { mDirtyFlags |= 0x2L; } return true; } return false; } executeBindings @Override protected void executeBindings() { long dirtyFlags = 0; synchronized(this) { dirtyFlags = mDirtyFlags; mDirtyFlags = 0; } java.lang.String vmUserNameLiveDataGetValue = null; androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; vmUserNameLiveData = null; androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; vmUidLiveData = null; com.example.myapplication.arch.login.LoginViewModel vm = mVm; java.lang.String vmUidLiveDataGetValue = null; java.lang.String vmPasswordLiveDataGetValue = null; androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; vmPasswordLiveData = null; ...... if ((dirtyFlags \u0026amp; 0x1aL) != 0) { if (vm != null) { // read vm.uidLiveData  vmUidLiveData = vm.getUidLiveData(); } updateLiveDataRegistration(1, vmUidLiveData); if (vmUidLiveData != null) { // read vm.uidLiveData.getValue()  vmUidLiveDataGetValue = vmUidLiveData.getValue(); } } if ((dirtyFlags \u0026amp; 0x1aL) != 0) { // api target 1  androidx.databinding.adapters.TextViewBindingAdapter.setText(this.uid, vmUidLiveDataGetValue); com.example.myapplication.arch.login.CustomTextView.changeBgIfLong(this.uid, vmUidLiveDataGetValue); } } updatelivedataregistration\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/databinding/",
	"title": "databinding",
	"tags": [],
	"description": "",
	"content": "databinding 探索总结databinding知识\n Databinding     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E7%B1%BB%E7%BC%96%E8%AF%91/dex2oat/",
	"title": "dex2oat",
	"tags": [],
	"description": "",
	"content": "pre-compilation的好处 Code pre-compilation: We pre-compile all the hot code. When the apps execute, the most important parts of the code are already optimized and ready to be natively executed. The app no longer needs to wait for the JIT compiler to kick in.\nThe benefit is that the code is mapped as clean memory (compared to the JIT dirty memory) which improves the overall memory efficiency. The clean memory can be released by the kernel when under memory pressure while the dirty memory cannot, lessening the chances that the kernel will kill the app.\noat文件 JVM执行 java 字节码， Dalvik执行 dalvik 字节码。\nART（Android Runtime），是Android4.4上开始提供的另一个 JVM实现，在4.4时，默认的虚拟机还是 dalvik，ART作为可选项，到Android5.0，开始作为Android默认的虚拟机。\n同样的，ART也支持运行 dalvik bytecode（否则没有办法兼容之前的app），另外 ART 提出了一个 AOT（Ahead of time）的方法。\n这个 AOT就是相对于 1.2节中提到的 JIT， AOT是说在代码运行之前进行编译。即把dex文件中的 dalvik bytecode编译为处理器可识别执行的汇编指令，我们把编译后生成的代码称为Native code。\n而==OAT文件就是包含了dex文件，dex文件编译出的 native Code，以及OAT header，OAT class等组织文件的数据==。\n在==使用oat文件的时候，通过这些组织关系，来查找一个类中java函数对应的 native code，从而在执行时去运行 native code==;\n实际上app编译出来的==OAT文件是一种特殊的ELF文件，在这个ELF文件的 oatdata 和 oatlastword之间的数据为oat数据。也即 oat文件数据是嵌入在ELF文件中的==。\nART运行的时候，会查询当前app对应的 oat文件进行执行，当找不到oat文件时再解释dex的 bytecode 执行。\n简单来讲：ART执行 oat文件，执行其中 java 函数对应 native code; 当函数没有对应的native code或者app没有对应的oat文件时，仍然解释执行dex文件中其对应的 dalvik bytecode。\nprofile文件 Android7.0之后，ART使用的文件，用来进行 profile-guide编译，即指导 dex2oat 如何编译 dex文件\nprofile文件：/data/misc/profiles/cur/0/com.***.home/primary.prof\n==每个app的profile文件都在 /data/misc/profiles/ 目录下==。profile文件用来记录运行比较频繁的代码，用来进行 profile-guide 编译，使得 dex2oat编译代码更精准。\nprofile的创建： App安装的过程中，会调用到 installd的 create_app_data()函数，\n如果当前支持profile编译，则会为app创建 profile文件。\nAndroid7.1:\n/frameworks/native/cmds/installd/commands.cpp int create_app_data(const char *uuid, const char *pkgname, userid_t userid, int flags, appid_t appid, const char* seinfo, int target_sdk_version) { ... if (property_get_bool(\u0026#34;dalvik.vm.usejitprofiles\u0026#34;)) { std::string profile_file = create_primary_profile(profile_path);//组织 profile文件所在路径  if (fs_prepare_file_strict(profile_file.c_str(), 0600, uid, uid) != 0) {//在这里创建 profile文件，且只对owner Read-Write  return -1; } ... } profile信息的收集 在App启动的时候，开启profile的收集线程：\n-\u0026gt;ActivityThread.main() -\u0026gt;... -\u0026gt;ActivityThread.performLaunchActivity() -\u0026gt;ActivityClientRecord.packageInfo.getClassLoader() -\u0026gt;LoadedApk.getClassLoader() -\u0026gt;setupJitProfileSupport() VMRuntime.registerAppInfo(profileName） Runtime::RegisterAppInfo(profileName) jit_-\u0026gt; StartProfileSaver(profileName) ProfileSaver::Start(profilName)//在这里会创建一个thread 用来收集 resolved class与method  ProfileSaver::Run() { FetchAndCacheResolvedClassesAndMethods(); bool profile_saved_to_disk = ProcessProfilingInfo(\u0026amp;new_methods); // 在这个方法中会把达到条件的 methodId 和 classid记录到 profile文件  在这个方法中，会编译当前进程中所有已经Load的Class，如果这些class是apk中的class，则将会被添加到 profile信息中。\n对于要记录的 method则需要达到一定的条件（函数的调用次数）,函数调用次数有以下几个 threshold：\nuint16_t hot_method_threshold_; uint16_t warm_method_threshold_; uint16_t osr_method_threshold_; 在解释执行一个函数时，会调用 AddSamples函数，从而会记录函数的调用次数。从而生成profile文件。生成的profile文件格式如下：\nprofile文件格式： /** * Serialization format: * magic,version,number_of_lines * dex_location1,number_of_methods1,number_of_classes1,dex_location_checksum1, \\ * method_id11,method_id12...,class_id1,class_id2... * dex_location2,number_of_methods2,number_of_classes2,dex_location_checksum2, \\ * method_id21,method_id22...,,class_id1,class_id2... * ..... **/ profile文件 的查看:\nxxxx:/data/misc/profiles/cur/0/com.***.home # profman --profile-file=primary.prof --dump-only  === profile === ProfileInfo: XXXHome.apk methods: 1824,1837,1843,1846,1907,1908,...... classes: 62,63,64,68,69,74,75,77,79,83,86,...... 其中：\nXXXHome.apk表示 dex文件的位置，如果这个apk中有多个dex，比如 classes.dex 和 classes2.dex，则classes2.dex中的类，则以 XXXHome.apk:classes2.dex 命名。\nmethods 和 classes 后面的数据，表示他们在dex文件中的index。\n我们使用profile模式 dex2oat编译时，会只编译profile中记录的这些 class 和 methods。\nApp-image 文件 /data/app/com.facebook.katana-1/oat/arm/base.art /data/app/com.facebook.katana-1/oat/arm/base.odex base.art就是对应的 app-image文件。\nbase.art文件主要记录已经编译好的类的具体信息以及函数在oat文件的位置，相当于缓存，在app运行的时候会加载到虚拟机，可以加快启动速度。\napp-image文件是Android7.0之后，ART使用的文件，它是App使用的类以及函数数据的缓存，在app启动的使用mmap到内存空间，以加快app启动速度，App启动过程越复杂，使用app-image时的提升越明显\nApp Images: We use the start up classes to build a pre-populated heap where the classes are pre-initialized (called an app image). When the application starts, we map the image directly into memory so that all the startup classes are readily available.\nThe benefit here is that the app\u0026rsquo;s execution saves cycles since it doesn\u0026rsquo;t need to do the work again, leading to a faster startup time.\noatdump xxx:/data/dalvik-cache/arm # oatdump --app-image=system@priv-app@Browser@Browser.apk@classes.art --app-oat=system@priv-app@Browser@Browser.apk@classes.dex --image=/system/framework/boot.art --instruction-set=arm --header-only 获取完整数据可以把 header-only 参数去掉即可。\ndex2oat dex2oat 是什么 dex2oat是一个可执行程序，在手机的 /system/bin/dex2oat，它的作用是编译dex文件，生成oat文件。\ndex文件被编译为 oat文件的过程，就是由 /system/bin/dex2oat 程序触发的; 而实际上编译业务是在 libart-compiler.so中做的。\n== dex2oat（dex文件） =\u0026gt; oat文件/image文件==\ndex2oat 什么时候被触发 dex2oat进程的启动，可以分为两大类：一类是 installd进程触发的dex2oat；另一类是由 app中直接调用的 dex2oat。\ninstalld 中触发的 dex2oat 有以下几个场景：\n1.应用安装，（包括普通安装和通过shellCmd安装），安装一个app时，安装过程中需要编译dex文件，会通知installd来触发一个dex2oat进程;\n2.开机扫描，开机过程中，PMS扫描已安装app过程，判断需要优化时，则会对install发出通知;\n3.BackgroundDexOptService，（空闲时段或者开机之后触发的Backgroud的 Job），会通知installd进行dex2oat;\n4.OTADexoptService，好象是OTA过程中的触发的，这个场景没有进行过实际的验证;\napp中调用 dex2oat 一般是App的进程fork出一个子进程，子进程用来执行dex2oat，编译相关的dex，而父进程进行 waitpid 等待，等待完成后再运行其他逻辑。\n比如：\n1.微信安装后的首次启动，是有dex2oat的调用\n2.淘宝安装后的首次搜索，也有dex2oat的调用\n这个也是其首次启动或者搜索的一个耗时点。\ndex2oat生成oat和app-image文件 dex2oat --dex-file=/data/app/com.facebook.katana-1/base.apk --app-image-file=/data/app/com.facebook.katana-1/oat/arm/base.art --oat-file=/data/app/com.facebook.katana-1/oat/arm/base.odex --instruction-set=arm --instruction-set-variant=kryo --instruction-set-features=default --runtime-arg -Xms64m --runtime-arg -Xmx512m --compiler-filter=interpret-only --image-format=lz4 --runtime-arg -classpath --runtime-arg /system/framework/com.google.android.maps.jar dex2oat 主要流程 dex2oat源码流程分析\nART世界探险(16) - 快速编译器下的方法编译\ndex2oat main函数 int main(int argc, char** argv) { int result = art::dex2oat(argc, argv); ... } static int dex2oat(int argc, char** argv) { ... dex2oat-\u0026gt;ParseArgs(argc, argv); if (dex2oat-\u0026gt;UseProfileGuidedCompilation()) { if (!dex2oat-\u0026gt;LoadProfile()) { return EXIT_FAILURE; } } dex2oat-\u0026gt;Setup(); bool result; if (dex2oat-\u0026gt;IsImage()) { result = CompileImage(*dex2oat); } else { result = CompileApp(*dex2oat); } ... 当使用profile-guide 编译app时，会先 LoadProfile()，这里就是 load /data/misc/profiles/cur/0/packagename/primary.prof，进行解析出 class index 和 method index，放到 ProfileCompilationinfo 中;\n如果当前的编译要生成 image时，走CompileImage流程，否则走CompileApp流程;\nbool IsImage() const { return IsAppImage() || IsBootImage();//不论是编译boot image（boot.art）或者时 app 要生成image. } CompileApp和CompileImage    static int CompileApp(Dex2Oat\u0026amp; dex2oat) {dex2oat.Compile();if (!dex2oat.WriteOatFiles()) {dex2oat.EraseOatFiles();return EXIT_FAILURE;}\u0026hellip;dex2oat.DumpTiming();return EXIT_SUCCESS;} static int CompileImage(Dex2Oat\u0026amp; dex2oat) {dex2oat.LoadClassProfileDescriptors();dex2oat.Compile();if (!dex2oat.WriteOatFiles()) {dex2oat.EraseOatFiles();return EXIT_FAILURE;}\u0026hellip;// Creates the boot.art and patches the oat files.if (!dex2oat.HandleImage()) {return EXIT_FAILURE;}\u0026hellip;dex2oat.DumpTiming();return EXIT_SUCCESS;          区别是：\n  编译image时需要 LoadClassProfileDescriptors() 产生 image_classes_ 集合\n  生成 image（HandleImage()）;\n  在生成的app image中将会包含 image_classes_ 集合中类的对象，不在 image_classes_集合中的app的类的对象，将不会被生成到 app-image中。\nLoadClassProfileDescriptors（）在从 profile信息中获取 image_classes_集合时，将会把 app dex 中的类以外的类，都过滤掉，比如 classpath dex 对应的类将不会生成到 app-image;\nvoid LoadClassProfileDescriptors() { if (profile_compilation_info_ != nullptr \u0026amp;\u0026amp; app_image_) { std::set\u0026lt;DexCacheResolvedClasses\u0026gt; resolved_classes(profile_compilation_info_-\u0026gt;GetResolvedClasses()); // 获取 profile信息中记录的所有 class  // Filter out class path classes since we don\u0026#39;t want to include these in the image.  std::unordered_set\u0026lt;std::string\u0026gt; dex_files_locations; for (const DexFile* dex_file : dex_files_) { dex_files_locations.insert(dex_file-\u0026gt;GetLocation()); // 当前app的所有dex file  } for (auto it = resolved_classes.begin(); it != resolved_classes.end(); ) { if (dex_files_locations.find(it-\u0026gt;GetDexLocation()) == dex_files_locations.end()) { // 如果这个类不在当前app 的dex file中，则过滤掉  VLOG(compiler) \u0026lt;\u0026lt; \u0026#34;Removed profile samples for non-app dex file \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;GetDexLocation(); it = resolved_classes.erase(it); } else { ++it; } } image_classes_.reset(new std::unordered_set\u0026lt;std::string\u0026gt;(runtime-\u0026gt;GetClassLinker()-\u0026gt;GetClassDescriptorsForProfileKeys(resolved_classes))); } dex2oat流程总结  根据dex2oat接收到的参数，组织编译参数 如果是 profile-guide 编译，则先进行 load app对应的 profile 收集参数中包含的所有dex file，启动 Compiler 编译这些dex file（classpath中对应的dex file，即uses-library 引用的jar文件，不会被编译），编译生成的数据放在compiler-driver中 使用 compiler-driver 中的数据，依据 oat文件设计的格式，组织成oat文件，嵌入到 ELF文件中 如果指定需要生成 app-image，则使用 HandleImage()， 生成app-image， 即 ***.art 文件  Compile 流程  // Create and invoke the compiler driver. This will compile all the dex files. void Compile() { ... driver_.reset(new CompilerDriver(compiler_options_.get(), verification_results_.get(), \u0026amp;method_inliner_map_, compiler_kind_, instruction_set_, instruction_set_features_.get(), IsBootImage(), IsAppImage(), image_classes_.release(), compiled_classes_.release(), /* compiled_methods */ nullptr, thread_count_, dump_stats_, dump_passes_, compiler_phases_timings_.get(), swap_fd_, profile_compilation_info_.get())); driver_-\u0026gt;SetDexFilesForOatFile(dex_files_); driver_-\u0026gt;CompileAll(class_loader_, dex_files_, timings_); 编译dex文件时在 CompilerDriver 中完成， 其中LoadProfile时构造的 ==profile_compilation_info_也会指导 将要编译哪些class和 methods==。\ndriver_-\u0026gt;SetDexFilesForOatFile(dex_files_);//表示将要编译的所有 dex file，这个集合是 \u0026ndash;dex-file=/data/app/com.facebook.katana-1/base.apk 这个文件中包含的所有dex文件，比如facebook的apk中有 12个 dex文件，则会依次编译这12个文件。\nvoid CompilerDriver::CompileAll(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { InitializeThreadPools(); // Precompile:  // 1) Load image classes  // 2) Resolve all classes  // 3) Attempt to verify all classes  // 4) Attempt to initialize image classes, and trivially initialized classes  PreCompile(class_loader, dex_files, timings); // Compile:  // 1) Compile all classes and methods enabled for compilation.  if (!GetCompilerOptions().VerifyAtRuntime()) { Compile(class_loader, dex_files, timings); } } void CompilerDriver::PreCompile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { LoadImageClasses(timings); //这里只针对 bootimage的编译  Resolve(class_loader, dex_files, timings); Verify(class_loader, dex_files, timings); InitializeClasses(class_loader, dex_files, timings); } void CompilerDriver::Verify(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { for (const DexFile* dex_file : dex_files) { CHECK(dex_file != nullptr); VerifyDexFile(class_loader, *dex_file, dex_files, parallel_thread_pool_.get(), parallel_thread_count_, timings); } } void CompilerDriver::VerifyDexFile(...){ ... VerifyClassVisitor visitor(\u0026amp;context, log_level); context.ForAll(0, dex_file.NumClassDefs(), \u0026amp;visitor, thread_count); } class VerifyClassVisitor : public CompilationVisitor { public: VerifyClassVisitor(const ParallelCompilationManager* manager, LogSeverity log_level) : manager_(manager), log_level_(log_level) {} virtual void Visit(size_t class_def_index) REQUIRES(!Locks::mutator_lock_) OVERRIDE { if (!manager_-\u0026gt;GetCompiler()-\u0026gt;ShouldVerifyClassBasedOnProfile(dex_file, class_def_index)) { // Skip verification since the class is not in the profile.  return; } ... } } bool CompilerDriver::ShouldVerifyClassBasedOnProfile(const DexFile\u0026amp; dex_file, uint16_t class_idx) const { ... bool result = profile_compilation_info_-\u0026gt;ContainsClass(dex_file, class_idx); return result; 在这里可以看到，==前面从 profile中load出来的信息，将会决定只有这些 class才会进行Verify==。\n接下来看下真正的编译，实际上编译对应的是 dalvik bytecode到 native code的转换，主要针对的 method;\nvoid CompilerDriver::Compile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { for (const DexFile* dex_file : dex_files) { CHECK(dex_file != nullptr); CompileDexFile(class_loader, *dex_file, dex_files, parallel_thread_pool_.get(), parallel_thread_count_, timings); // 按照dexfile 依次编译  } ... } void CompilerDriver::CompileDexFile(jobject class_loader, const DexFile\u0026amp; dex_file, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, ThreadPool* thread_pool, size_t thread_count, TimingLogger* timings) { TimingLogger::ScopedTiming t(\u0026#34;Compile Dex File\u0026#34;, timings); ParallelCompilationManager context(Runtime::Current()-\u0026gt;GetClassLinker(), class_loader, this, \u0026amp;dex_file, dex_files, thread_pool); CompileClassVisitor visitor(\u0026amp;context); context.ForAll(0, dex_file.NumClassDefs(), \u0026amp;visitor, thread_count); //从dexfile的第一个class，直到最后一个class  编译的工作在 CompileClassVisitor 的Visit方法中进行;\nclass CompileClassVisitor : public CompilationVisitor { public: explicit CompileClassVisitor(const ParallelCompilationManager* manager) : manager_(manager) {} virtual void Visit(size_t class_def_index) REQUIRES(!Locks::mutator_lock_) OVERRIDE { // 传递的参数为 class在 dexfile中的 index，以此来查找class 数据  const DexFile::ClassDef\u0026amp; class_def = dex_file.GetClassDef(class_def_index); const char* descriptor = dex_file.GetClassDescriptor(class_def); Handle\u0026lt;mirror::Class\u0026gt; klass(hs.NewHandle(class_linker-\u0026gt;FindClass(soa.Self(), descriptor, class_loader))); const uint8_t* class_data = dex_file.GetClassData(class_def); ClassDataItemIterator it(dex_file, class_data); while (it.HasNextDirectMethod()) { // 编译direct mothod  uint32_t method_idx = it.GetMemberIndex(); CompileMethod(soa.Self(), driver, it.GetMethodCodeItem(), it.GetMethodAccessFlags(), it.GetMethodInvokeType(class_def), class_def_index, method_idx, jclass_loader, dex_file, dex_to_dex_compilation_level, compilation_enabled, dex_cache); it.Next(); } while (it.HasNextVirtualMethod()) { // 编译virtual methods  uint32_t method_idx = it.GetMemberIndex(); CompileMethod(soa.Self(), driver, it.GetMethodCodeItem(), it.GetMethodAccessFlags(), it.GetMethodInvokeType(class_def), class_def_index, method_idx, jclass_loader, dex_file, dex_to_dex_compilation_level, compilation_enabled, dex_cache); it.Next(); } ... } 从这一步中，我们可以看到，编译代码工作，主要的就是编译 method成为 native code;\nCompileMethod static void CompileMethod(Thread* self, CompilerDriver* driver, const DexFile::CodeItem* code_item, uint32_t access_flags, InvokeType invoke_type, uint16_t class_def_idx, uint32_t method_idx, jobject class_loader, const DexFile\u0026amp; dex_file, optimizer::DexToDexCompilationLevel dex_to_dex_compilation_level, bool compilation_enabled, Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache) REQUIRES(!driver-\u0026gt;compiled_methods_lock_) { MethodReference method_ref(\u0026amp;dex_file, method_idx); if ((access_flags \u0026amp; kAccNative) != 0) { // 编译 JNI 函数  compiled_method = driver-\u0026gt;GetCompiler()-\u0026gt;JniCompile(access_flags, method_idx, dex_file); } else if((access_flags \u0026amp; kAccAbstract) != 0) { // abstract 函数没有代码，不需要编译  } else { //编译其他函数  const VerifiedMethod* verified_method = driver-\u0026gt;GetVerificationResults()-\u0026gt;GetVerifiedMethod(method_ref); bool compile = compilation_enabled \u0026amp;\u0026amp; driver-\u0026gt;GetVerificationResults() -\u0026gt;IsCandidateForCompilation(method_ref, access_flags) \u0026amp;\u0026amp; verified_method != nullptr \u0026amp;\u0026amp; !verified_method-\u0026gt;HasRuntimeThrow() \u0026amp;\u0026amp; (verified_method-\u0026gt;GetEncounteredVerificationFailures() \u0026amp; (verifier::VERIFY_ERROR_FORCE_INTERPRETER | verifier::VERIFY_ERROR_LOCKING)) == 0 \u0026amp;\u0026amp; driver-\u0026gt;IsMethodToCompile(method_ref) \u0026amp;\u0026amp; driver-\u0026gt;ShouldCompileBasedOnProfile(method_ref);// 如果是profile-guide编译，需要检查是否是 profile中指定的函数，如果不是，则不编译该函数  if (compile) { // NOTE: if compiler declines to compile this method, it will return null.  compiled_method = driver-\u0026gt;GetCompiler()-\u0026gt;Compile(code_item, access_flags, invoke_type, class_def_idx, method_idx, class_loader, dex_file, dex_cache); } ... driver-\u0026gt;AddCompiledMethod(method_ref, compiled_method, non_relative_linker_patch_count);//把编译得到的 compiled-method 添加到 compiler-driver中，以便后面生成oat文件时使用  } bool CompilerDriver::ShouldCompileBasedOnProfile(const MethodReference\u0026amp; method_ref) const { if (profile_compilation_info_ == nullptr) { // If we miss profile information it means that we don\u0026#39;t do a profile guided compilation.  // Return true, and let the other filters decide if the method should be compiled.  return true; } bool result = profile_compilation_info_-\u0026gt;ContainsMethod(method_ref);// 判断当前method是不是在前面 load到的 profile 中  return result; compiled-method 的生成过程，是真正ART编译器工作的过程，使用了图等算法进行编译，非常复杂，这里不再详述，总之，这个过程中，完成了dalvik bytecode 到 native code的转化以及一定的优化，到这一步，我们得到了产出： compiled-method，ART运行过程中，执行函数时，如果这个函数被编译过，那么就会执行其对应的 compiled-method，否则继续解释执行其对应的 dalvik bytecode。\nCompile流程总结  PreCompile 做一些准备工作，ResolveClass（可以认为是从dex文件中构造class到内存中），VerifyClass（验证错误），InitializeClass（初始化）等动作，做一些过滤动作，比如把verify失败的class过滤掉 Compile过程，多线成编译，线程数目是 CPU count -1， 最小编译单位是 method，依次按照method所在 dex，所在class进行编译 ==如果存在profile的情况下，Verify过程只对profile中存在的Class进行verify，CompileMethod过程，只对profile中存在的method进行编译== 编译后生成的compiled-method 放到 compiler-driver中，以备在dex2oat中，准备写入OAT文件时使用  OAT 文件写入流程 在Compile流程结束后，会进行OAT文件的写入操作。\nenum class WriteState { kAddingDexFileSources, // 添加dex文件到 oat文件中 kPrepareLayout, //准备文件布局 kWriteRoData, //写入RoData kWriteText, //写入代码段 kWriteHeader, // 写入 oat header kDone // 写入完成 } 从OatWriteState可以看到，其写入oat文件的流程。\n AddDexFileSource，在dex2oat Setup时，就已经将将要编译的dex file 写入到 OatWriter 中，并设置 write_state_ = WriteState::kPrepareLayout; 后续的步骤都在编译完成后，由 WriteOatFiles 完成 kPrepareLayout，初始化 OatClass，OatMaps，OatCode， 准备OatMethod信息 和 bss段的DexCacheArray kWriteRoData，写入 readOnly 数据，依次写入 ClassOffset，写入 OatClass，写入函数的vmap Table，写入 padding kWriteText，对于要生成 bootimage时，写入trampoline，对与app只写入quick code kWriteHeader，填充 Oat Header信息，写入到oat文件  bool Setup() { CreateOatWriters(); if (!AddDexFileSources()) { return false; } } bool WriteOatFiles() { if (IsImage()) { // 如果本次dex2oat要生成 image，则会在写入 oat文件时，做准备工作  image_writer_.reset(new ImageWriter(*driver_, image_base_, compiler_options_-\u0026gt;GetCompilePic(),IsAppImage(), image_storage_mode_, oat_filenames_, dex_file_oat_index_map_)); if (!image_writer_-\u0026gt;PrepareImageAddressSpace()) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to prepare image address space.\u0026#34;; return false; } } oat_writer-\u0026gt;PrepareLayout(driver_.get(), image_writer_.get(), dex_files, \u0026amp;patcher); size_t rodata_size = oat_writer-\u0026gt;GetOatHeader().GetExecutableOffset(); size_t text_size = oat_writer-\u0026gt;GetSize() - rodata_size; elf_writer-\u0026gt;SetLoadedSectionSizes(rodata_size, text_size, oat_writer-\u0026gt;GetBssSize()); if (!oat_writer-\u0026gt;WriteRodata(rodata)) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to write .rodata section to the ELF file \u0026#34; \u0026lt;\u0026lt; oat_file-\u0026gt;GetPath(); return false; } OutputStream* text = elf_writer-\u0026gt;StartText(); if (!oat_writer-\u0026gt;WriteCode(text)) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to write .text section to the ELF file \u0026#34; \u0026lt;\u0026lt; oat_file-\u0026gt;GetPath(); return false; } if (!oat_writer-\u0026gt;WriteHeader(elf_writer-\u0026gt;GetStream(), image_file_location_oat_checksum_, image_file_location_oat_data_begin_, image_patch_delta_)) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to write oat header to the ELF file \u0026#34; \u0026lt;\u0026lt; oat_file-\u0026gt;GetPath(); return false; } OAT文件的写入流程就是按照这几个步骤完成，可以参照oat文件的加载完成OAT文件格式的详细了解。\napp-image如何使用 app-image在App启动的过程中加载，加载流程如下：\n-\u0026gt;ActivityThread.main() -\u0026gt;... -\u0026gt;ActivityThread.performLaunchActivity() -\u0026gt;ActivityClientRecord.packageInfo.getClassLoader() -\u0026gt;LoadedApk.getClassLoader() -\u0026gt;LoadedApk.createOrUpdateClassLoaderLocked() -\u0026gt;ApplicationLoaders.getDefault().getClassLoader() -\u0026gt;new PathClassLoader() -\u0026gt;new BaseDexClassLoader() -\u0026gt;new DexPathList() -\u0026gt;makePathElements -\u0026gt;loadDexFile -\u0026gt;new DexFile（） -\u0026gt;openDexFile() -\u0026gt;openDexFileNative -\u0026gt;openDexFilesFromOat() -\u0026gt;OpenImageSpace(source_oat_file)// 在这里尝试打开oat文件对应的image文件， -\u0026gt; heap -\u0026gt;AddSpace(image_space); -\u0026gt; class_linker -\u0026gt;AddImageSpace(image-space) class_linker的 AddImageSpace中会调用 UpdateAppImageClassLoadersAndDexCaches()方法:\nbool ClassLinker::UpdateAppImageClassLoadersAndDexCaches( ... ClassTable* table = InsertClassTableForClassLoader(class_loader.Get()); for (size_t i = 0; i \u0026lt; num_dex_caches; i++) { mirror::DexCache* const dex_cache = dex_caches-\u0026gt;Get(i); const DexFile* const dex_file = dex_cache-\u0026gt;GetDexFile(); RegisterDexFileLocked(*dex_file, hs3.NewHandle(dex_cache)); GcRoot\u0026lt;mirror::Class\u0026gt;* const types = dex_cache-\u0026gt;GetResolvedTypes(); const size_t num_types = dex_cache-\u0026gt;NumResolvedTypes(); for (int32_t j = 0; j \u0026lt; static_cast\u0026lt;int32_t\u0026gt;(num_types); j++) { mirror::Class* klass = types[j].Read(); if (space-\u0026gt;HasAddress(klass)) { klass-\u0026gt;SetClassLoader(class_loader.Get()); } table-\u0026gt;Insert(klass); } ... ==在这个函数中，会把app-image中的所有类的 classLoader更新为当前的 classLoader，并将它们添加到当前的ClassLoader的class table中;之后在当前进程中有使用相关类时，在FindClass过程中，直接就能在 class table中找到，即可使用，免去了类的加载。至此，app进程在后续的运行中，就可以直接使用app-image中的类了==。\n三段式编译模型 图2 基于LLVM架构开发的编译器执行过程\n图3 利用现成的与语言无关的优化器和后端为语言相关的前端生成各种体系结构相关的机器指令\nELF格式的oat文件 图4 ART翻译classes.dex后得到的ELF格式的oat文件\n参考 Other site Android profile-guided dex2oat\nhttps://android-developers.googleblog.com/2019/04/improving-app-performance-with-art.html\nAndroid运行时ART简要介绍和学习计划\nAndroid运行时ART加载OAT文件的过程分析\nToc of my detailed dex2oat.vsdx below ParseArgs(argc, argv)\u0026ndash;\u0026gt;创建CompilerOptions OpenFile()创建目标oat文件 Setup() 创建VerificationResults verification_results_.reset(new VerificationResults(compiler_options_.get())); 配置QuickCompilerCallbacks 在做类校验时，外界可以传递一个回调接口对象。\n·当类校验失败时，该接口对象的ClassRejected函数将被调用。\n·当类的Java方法校验通过时，该接口对象的MethodVerified函数将被调用。\ncallbacks_.reset(new QuickCompilerCallbacks( verification_results_.get(),\u0026amp;method_inliner_map_, IsBootImage() ? CompilerCallbacks::CallbackMode::kCompileBootImage : CompilerCallbacks::CallbackMode::kCompileApp)); ClassRejected() MethodVerified() 去虚拟化de virtual得到concrete_method const VerifiedMethod* VerifiedMethod::Create( verifier::MethodVerifier* method_verifier, bool compile) { if (compile) {//compile为true时表示这个方法将会被编译。  //如果这个Java方法中有invoke-virtual或invoke-interface相关的指令，则下面if的条  //件满足  if (method_verifier-\u0026gt;HasVirtualOrInterfaceInvokes()) { //去虚拟化de virtual。下面将介绍这个函数  verified_method-\u0026gt;GenerateDevirtMap(method_verifier); } 创建elf_writers_和oat_writers_ 配置oat_writers_[0]中的oat_dex_files_ WriteAndOpenDexFiles_WriteTypeLookupTables CompileImage 在dex2oat中，一个Java方法根据其具体情况有三种编译处理模式\n1: dex到dex的编译\n2: jni方法的编译\n3: dex字节码到机器码的编译\ndex2oat.Compile compilerDriver.CompileAll ClassLinker.ResolveType,ResolveField和ResolveMethod void CompilerDriver::PreCompile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files,....) { ...... if ((never_verify || verification_enabled) \u0026amp;\u0026amp; !verify_only_profile) { /*下面的Resolve函数主要工作为遍历dex文件，然后： （1）解析其中的类型，即遍历dex文件里的type_ids数组。内部将调用ClassLinker的ResolveType函数。 （2）解析dex里的类、成员变量、成员函数。内部将调用ClassLinker的ResolveType、ResolveField和ResolveMethod等函数。读者可回顾8.7.8.1节的内容。 */ Resolve(class_loader, dex_files, timings); } /*下面两个函数的作用： （1）Verify：遍历dex文件，校验其中的类。校验结果通过QuickCompilationCallback存储在 CompilerDriver的verification_results_中。 （2）InitializeClasses：遍历dex文件，确保类的初始化。*/ Verify(class_loader, dex_files, timings); InitializeClasses(class_loader, dex_files, timings); } CompileDexFile void CompilerDriver::Compile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { for (const DexFile* dex_file : dex_files) { CompileDexFile(class_loader,*dex_file,dex_files,......); ...... } void CompilerDriver::CompileDexFile(jobject class_loader, const DexFile\u0026amp; dex_file, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, ThreadPool* thread_pool, size_t thread_count, TimingLogger* timings) { CompileClassVisitor visitor(\u0026amp;context); /*context.ForAll将触发线程池进行编译工作。注意，编译是以类为单位进行处理的，每一个待编译 的类都会交由CompileClassVisitor的Visit函数进行处理。*/ context.ForAll(0, dex_file.NumClassDefs(), \u0026amp;visitor, thread_count); } //编译时，编译线程将调用下面的这个Visit函数，参数为待处理类在dex文件里class_ids数组中的索引  virtual void Visit(size_t class_def_index) ..... { //遍历direct的Java方法  int64_t previous_direct_method_idx = -1; while (it.HasNextDirectMethod()) { uint32_t method_idx = it.GetMemberIndex(); ..... previous_direct_method_idx = method_idx; CompileMethod(soa.Self(), driver, it.GetMethodCodeItem(), it.GetMethodAccessFlags(),it.GetMethodInvokeType(class_def), class_def_index, method_idx, jclass_loader, dex_file, dex_to_dex_compilation_level,compilation_enabled, dex_cache); it.Next(); } //编译虚函数，也是调用CompileMethod函数  } CompileMethod() driver-\u0026gt;AddCompiledMethod() WriteOatFiles输出.oat文件 HandleImage处理.art文件 oat和art文件格式和关系 graph LR OatDexFile(\u0026quot;OatDexFile[N]\u0026quot;)--\u0026gt;DexFile(\u0026quot;DexFile[N]\u0026quot;)--\u0026gt;TypeLookup-Table(\u0026quot;TypeLookup-Table[N]\u0026quot;)--\u0026gt;ClassOffsets(\u0026quot;ClassOffsets[N]\u0026quot;) ClassOffsets--\u0026gt;OatClass0 ClassOffsets--\u0026gt;OatClass1 ClassOffsets--\u0026gt;OatClassXxx OatClass1--\u0026gt;CompliedMethod0 OatClass1--\u0026gt;CompliedMethod1 OatClass1--\u0026gt;CompliedMethodXxx Detail in dex2oat.vsdx "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/dumphprof/",
	"title": "DumpHprof",
	"tags": [],
	"description": "",
	"content": "art/runtime/native/dalvik_system_VMDebug.cc\nVMDebug_dumpHprofData /* * static void dumpHprofData(String fileName, FileDescriptor fd) * * Cause \u0026#34;hprof\u0026#34; data to be dumped. We can throw an IOException if an * error occurs during file handling. */ static void VMDebug_dumpHprofData(JNIEnv* env, jclass, jstring javaFilename, jint javaFd) { std::string filename; if (javaFilename != nullptr) { ScopedUtfChars chars(env, javaFilename); if (env-\u0026gt;ExceptionCheck()) { return; } filename = chars.c_str(); } else { filename = \u0026#34;[fd]\u0026#34;; } int fd = javaFd; hprof::DumpHeap(filename.c_str(), fd, false); libnativehelper/header_only_include/nativehelper/scoped_utf_chars.h\nScopedUtfChars(JNIEnv* env, jstring s) : env_(env), string_(s) { if (s == nullptr) { utf_chars_ = nullptr; jniThrowNullPointerException(env, nullptr); } else { utf_chars_ = env-\u0026gt;GetStringUTFChars(s, nullptr); } } art/runtime/hprof/hprof.cc\nclass Hprof : public SingleRootVisitor { hprof::DumpHeap // If \u0026#34;direct_to_ddms\u0026#34; is true, the other arguments are ignored, and data is // sent directly to DDMS. // If \u0026#34;fd\u0026#34; is \u0026gt;= 0, the output will be written to that file descriptor. // Otherwise, \u0026#34;filename\u0026#34; is used to create an output file. void DumpHeap(const char* filename, int fd, bool direct_to_ddms) { CHECK(filename != nullptr); Thread* self = Thread::Current(); // Need to take a heap dump while GC isn\u0026#39;t running. See the comment in Heap::VisitObjects().  // Also we need the critical section to avoid visiting the same object twice. See b/34967844  gc::ScopedGCCriticalSection gcs(self, gc::kGcCauseHprof, gc::kCollectorTypeHprof); ScopedSuspendAll ssa(__FUNCTION__, true /* long suspend */); Hprof hprof(filename, fd, direct_to_ddms); hprof.Dump(); } art/runtime/thread_list.cc\nScopedSuspendAll ScopedSuspendAll::ScopedSuspendAll(const char* cause, bool long_suspend) { Runtime::Current()-\u0026gt;GetThreadList()-\u0026gt;SuspendAll(cause, long_suspend); } hprof.Dump void Dump() REQUIRES(Locks::mutator_lock_) REQUIRES(!Locks::heap_bitmap_lock_, !Locks::alloc_tracker_lock_) { { // First pass to measure the size of the dump.  size_t overall_size; size_t max_length; { EndianOutput count_output; output_ = \u0026amp;count_output; ProcessHeap(false); overall_size = count_output.SumLength(); max_length = count_output.MaxLength(); output_ = nullptr; } void ProcessHeap(bool header_first) REQUIRES(Locks::mutator_lock_) { ...... if (header_first) { ProcessHeader(true); ProcessBody(); } else { ProcessBody(); ProcessHeader(false); } } ProcessBody void ProcessBody() REQUIRES(Locks::mutator_lock_) { Runtime* const runtime = Runtime::Current(); // Walk the roots and the heap.  output_-\u0026gt;StartNewRecord(HPROF_TAG_HEAP_DUMP_SEGMENT, kHprofTime); simple_roots_.clear(); runtime-\u0026gt;VisitRoots(this); runtime-\u0026gt;VisitImageRoots(this); //method callback params  auto dump_object = [this](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_) { DCHECK(obj != nullptr); DumpHeapObject(obj); }; runtime-\u0026gt;GetHeap()-\u0026gt;VisitObjectsPaused(dump_object); output_-\u0026gt;StartNewRecord(HPROF_TAG_HEAP_DUMP_END, kHprofTime); output_-\u0026gt;EndRecord(); } StartNewRecord void StartNewRecord(uint8_t tag, uint32_t time) { if (length_ \u0026gt; 0) { EndRecord(); } AddU1(tag); AddU4(time); AddU4(0xdeaddead); // Length, replaced on flush.  started_ = true; } VisitRoots(this)\u0026ndash;\u0026gt;Hprof::VisitRoot void Hprof::VisitRoot(mirror::Object* obj, const RootInfo\u0026amp; info) { static const HprofHeapTag xlate[] = { HPROF_ROOT_UNKNOWN, HPROF_ROOT_JNI_GLOBAL, HPROF_ROOT_JNI_LOCAL, HPROF_ROOT_JAVA_FRAME, HPROF_ROOT_NATIVE_STACK, HPROF_ROOT_STICKY_CLASS, HPROF_ROOT_THREAD_BLOCK, HPROF_ROOT_MONITOR_USED, HPROF_ROOT_THREAD_OBJECT, HPROF_ROOT_INTERNED_STRING, HPROF_ROOT_FINALIZING, HPROF_ROOT_DEBUGGER, HPROF_ROOT_REFERENCE_CLEANUP, HPROF_ROOT_VM_INTERNAL, HPROF_ROOT_JNI_MONITOR, }; CHECK_LT(info.GetType(), sizeof(xlate) / sizeof(HprofHeapTag)); if (obj == nullptr) { return; } MarkRootObject(obj, 0, xlate[info.GetType()], info.GetThreadId()); } void Hprof::MarkRootObject(const mirror::Object* obj, jobject jni_obj, HprofHeapTag heap_tag, uint32_t thread_serial) { switch (heap_tag) { // ID: object ID  case HPROF_ROOT_UNKNOWN: case HPROF_ROOT_STICKY_CLASS: case HPROF_ROOT_MONITOR_USED: case HPROF_ROOT_INTERNED_STRING: case HPROF_ROOT_DEBUGGER: case HPROF_ROOT_VM_INTERNAL: { uint64_t key = (static_cast\u0026lt;uint64_t\u0026gt;(heap_tag) \u0026lt;\u0026lt; 32) | PointerToLowMemUInt32(obj); if (simple_roots_.insert(key).second) { __ AddU1(heap_tag); __ AddObjectId(obj); } break; } ...... // ID: thread object ID  // U4: thread serial number  // U4: stack trace serial number  case HPROF_ROOT_THREAD_OBJECT: __ AddU1(heap_tag); __ AddObjectId(obj); __ AddU4(thread_serial); __ AddU4((uint32_t)-1); // xxx  break; case HPROF_CLASS_DUMP: case HPROF_INSTANCE_DUMP: case HPROF_OBJECT_ARRAY_DUMP: case HPROF_PRIMITIVE_ARRAY_DUMP: case HPROF_HEAP_DUMP_INFO: case HPROF_PRIMITIVE_ARRAY_NODATA_DUMP: // Ignored.  break; case HPROF_ROOT_FINALIZING: case HPROF_ROOT_REFERENCE_CLEANUP: case HPROF_UNREACHABLE: LOG(FATAL) \u0026lt;\u0026lt; \u0026#34;obsolete tag \u0026#34; \u0026lt;\u0026lt; static_cast\u0026lt;int\u0026gt;(heap_tag); break; } ++objects_in_segment_; VisitObjectsPaused(dump_object)\u0026ndash;\u0026gt;DumpHeapObject void Hprof::DumpHeapObject(mirror::Object* obj) { // Ignore classes that are retired.  if (obj-\u0026gt;IsClass() \u0026amp;\u0026amp; obj-\u0026gt;AsClass()-\u0026gt;IsRetired()) { return; } ++total_objects_; RootCollector visitor; // Collect all native roots.  if (!obj-\u0026gt;IsClass()) { obj-\u0026gt;VisitReferences(visitor, VoidFunctor()); } ...... mirror::Class* c = obj-\u0026gt;GetClass(); if (c == nullptr) { // This object will bother HprofReader, because it has a null  // class, so just don\u0026#39;t dump it. It could be  // gDvm.unlinkedJavaLangClass or it could be an object just  // allocated which hasn\u0026#39;t been initialized yet.  } else { if (obj-\u0026gt;IsClass()) { DumpHeapClass(obj-\u0026gt;AsClass()); //HPROF_CLASS_DUMP  } else if (c-\u0026gt;IsArrayClass()) { DumpHeapArray(obj-\u0026gt;AsArray(), c); //HPROF_OBJECT_ARRAY_DUMP or HPROF_PRIMITIVE_ARRAY_DUMP  } else { DumpHeapInstanceObject(obj, c, visitor.GetRoots()); //HPROF_INSTANCE_DUMP  } } ++objects_in_segment_; DumpHeapInstanceObject void Hprof::DumpHeapInstanceObject(mirror::Object* obj, mirror::Class* klass, const std::set\u0026lt;mirror::Object*\u0026gt;\u0026amp; fake_roots) { // obj is an instance object.  __ AddU1(HPROF_INSTANCE_DUMP); __ AddObjectId(obj); __ AddStackTraceSerialNumber(LookupStackTraceSerialNumber(obj)); __ AddClassId(LookupClassId(klass)); // Reserve some space for the length of the instance data, which we won\u0026#39;t  // know until we\u0026#39;re done writing it.  size_t size_patch_offset = output_-\u0026gt;Length(); __ AddU4(0x77777777); // Write the instance data; fields for this class, followed by super class fields, and so on.  do { const size_t instance_fields = klass-\u0026gt;NumInstanceFields(); for (size_t i = 0; i \u0026lt; instance_fields; ++i) { ArtField* f = klass-\u0026gt;GetInstanceField(i); size_t size; HprofBasicType t = SignatureToBasicTypeAndSize(f-\u0026gt;GetTypeDescriptor(), \u0026amp;size); switch (t) { case hprof_basic_byte: __ AddU1(f-\u0026gt;GetByte(obj)); break; case hprof_basic_boolean: __ AddU1(f-\u0026gt;GetBoolean(obj)); break; case hprof_basic_char: __ AddU2(f-\u0026gt;GetChar(obj)); break; ...... case hprof_basic_double: case hprof_basic_long: __ AddU8(f-\u0026gt;Get64(obj)); break; } } klass = klass-\u0026gt;GetSuperClass(); } while (klass != nullptr); // Patch the instance field length.  __ UpdateU4(size_patch_offset, output_-\u0026gt;Length() - (size_patch_offset + 4)); "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/engine/engine/",
	"title": "Engine",
	"tags": [],
	"description": "",
	"content": "window.dart lib/ui\n/// Requests that, at the next appropriate opportunity, the [onBeginFrame]  /// and [onDrawFrame] callbacks be invoked.  ///  /// See also:  ///  /// * [SchedulerBinding], the Flutter framework class which manages the  /// scheduling of frames.  void scheduleFrame() native \u0026#39;PlatformConfiguration_scheduleFrame\u0026#39;; lib/ui/window/platform_configuration.cc\nPlatformConfiguration void PlatformConfiguration::RegisterNatives( tonic::DartLibraryNatives* natives) { natives-\u0026gt;Register({ {\u0026#34;PlatformConfiguration_defaultRouteName\u0026#34;, DefaultRouteName, 1, true}, {\u0026#34;PlatformConfiguration_scheduleFrame\u0026#34;, ScheduleFrame, 1, true}, {\u0026#34;PlatformConfiguration_sendPlatformMessage\u0026#34;, _SendPlatformMessage, 4, true}, {\u0026#34;PlatformConfiguration_respondToPlatformMessage\u0026#34;, _RespondToPlatformMessage, 3, true}, {\u0026#34;PlatformConfiguration_render\u0026#34;, Render, 2, true}, {\u0026#34;PlatformConfiguration_updateSemantics\u0026#34;, UpdateSemantics, 2, true}, {\u0026#34;PlatformConfiguration_setIsolateDebugName\u0026#34;, SetIsolateDebugName, 2, true}, {\u0026#34;PlatformConfiguration_reportUnhandledException\u0026#34;, ReportUnhandledException, 2, true}, {\u0026#34;PlatformConfiguration_setNeedsReportTimings\u0026#34;, SetNeedsReportTimings, 2, true}, {\u0026#34;PlatformConfiguration_getPersistentIsolateData\u0026#34;, GetPersistentIsolateData, 1, true}, {\u0026#34;PlatformConfiguration_computePlatformResolvedLocale\u0026#34;, _ComputePlatformResolvedLocale, 2, true}, }); } void ScheduleFrame(Dart_NativeArguments args) { UIDartState::ThrowIfUIOperationsProhibited(); UIDartState::Current()-\u0026gt;platform_configuration()-\u0026gt;client()-\u0026gt;ScheduleFrame(); } runtime/runtime_controller.cc\nRuntimeController:PlatformConfigurationClient //------------------------------------------------------------------------------ /// Represents an instance of a running root isolate with window bindings. In /// normal operation, a single instance of this object is owned by the engine /// per shell. This object may only be created, used, and collected on the UI /// task runner. Window state queried by the root isolate is stored by this /// object. In cold-restart scenarios, the engine may collect this before /// installing a new runtime controller in its place. The Clone method may be /// used by the engine to copy the currently accumulated window state so it can /// be referenced by the new runtime controller. /// class RuntimeController : public PlatformConfigurationClient { // |PlatformConfigurationClient|  void RuntimeController::ScheduleFrame() { client_.ScheduleFrame(); } } shell/common/engine.cc\nEngine:RuntimeDelegate class Engine final : public RuntimeDelegate, public HintFreedDelegate, PointerDataDispatcher::Delegate { private: Delegate\u0026amp; delegate_; void Engine::ScheduleFrame(bool regenerate_layer_tree) { animator_-\u0026gt;RequestFrame(regenerate_layer_tree); } } Shell:Engine::Delegate class Shell final : public PlatformView::Delegate, public Animator::Delegate, public Engine::Delegate, public Rasterizer::Delegate, public ServiceProtocol::Handler { shell/common/animator.cc\nvoid Animator::RequestFrame(bool regenerate_layer_tree) { // The AwaitVSync is going to call us back at the next VSync. However, we want  // to be reasonably certain that the UI thread is not in the middle of a  // particularly expensive callout. We post the AwaitVSync to run right after  // an idle. This does NOT provide a guarantee that the UI thread has not  // started an expensive operation right after posting this message however.  // To support that, we need edge triggered wakes on VSync.  task_runners_.GetUITaskRunner()-\u0026gt;PostTask([self = weak_factory_.GetWeakPtr(), frame_number = frame_number_]() { if (!self) { return; } TRACE_EVENT_ASYNC_BEGIN0(\u0026#34;flutter\u0026#34;, \u0026#34;Frame Request Pending\u0026#34;, frame_number); self-\u0026gt;AwaitVSync(); }); frame_scheduled_ = true; } void Animator::AwaitVSync() { waiter_-\u0026gt;AsyncWaitForVsync( [self = weak_factory_.GetWeakPtr()](fml::TimePoint vsync_start_time, fml::TimePoint frame_target_time) { if (self) { if (self-\u0026gt;CanReuseLastLayerTree()) { self-\u0026gt;DrawLastLayerTree(); } else { self-\u0026gt;BeginFrame(vsync_start_time, frame_target_time); } } }); delegate_.OnAnimatorNotifyIdle(dart_frame_deadline_); } shell/common/vsync_waiter.cc\n// Public method invoked by the animator. void VsyncWaiter::AsyncWaitForVsync(const Callback\u0026amp; callback) { if (!callback) { return; } TRACE_EVENT0(\u0026#34;flutter\u0026#34;, \u0026#34;AsyncWaitForVsync\u0026#34;); { std::scoped_lock lock(callback_mutex_); if (callback_) { // The animator may request a frame more than once within a frame  // interval. Multiple calls to request frame must result in a single  // callback per frame interval.  TRACE_EVENT_INSTANT0(\u0026#34;flutter\u0026#34;, \u0026#34;MultipleCallsToVsyncInFrameInterval\u0026#34;); return; } callback_ = std::move(callback); if (secondary_callback_) { // Return directly as `AwaitVSync` is already called by  // `ScheduleSecondaryCallback`.  return; } } AwaitVSync(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/engine/",
	"title": "engine",
	"tags": [],
	"description": "",
	"content": "engine 探索总结engine知识\n Engine     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/",
	"title": "flutter",
	"tags": [],
	"description": "",
	"content": "flutter 探索总结flutter知识\n engine    Engine      startup    startup     startup_dart_framework     startup_embedder_framwwork      touch    Touch      动画    动画      混合开发    FlutterBoost     混合开发      渲染    Widget     渲染      路由    路由      通信    MessageLoop     MethodChannel      "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/flutterboost/",
	"title": "FlutterBoost",
	"tags": [],
	"description": "",
	"content": "BoostFlutterActivity.onCreate BoostFlutterActivity implements FlutterActivityAndFragmentDelegate.Host { private FlutterActivityAndFragmentDelegate delegate; public static class NewEngineIntentBuilder { public Intent build(@NonNull Context context) { SerializableMap serializableMap = new SerializableMap(); serializableMap.setMap(params); return new Intent(context, activityClass) .putExtra(EXTRA_BACKGROUND_MODE, backgroundMode) .putExtra(EXTRA_DESTROY_ENGINE_WITH_ACTIVITY, false) .putExtra(EXTRA_URL, url) .putExtra(EXTRA_PARAMS, serializableMap); } @Override public String getContainerUrl() { if (getIntent().hasExtra(EXTRA_URL)) { return getIntent().getStringExtra(EXTRA_URL); } } @Override protected void onCreate(@Nullable Bundle savedInstanceState) { delegate = new FlutterActivityAndFragmentDelegate(this); delegate.onAttach(this); setContentView(createFlutterView()); } FlutterActivityAndFragmentDelegate implements IFlutterViewContainer { protected IOperateSyncer mSyncer; FlutterActivityAndFragmentDelegate(@NonNull Host host) { this.host = host; } void onAttach(@NonNull Context context) { // When \u0026#34;retain instance\u0026#34; is true, the FlutterEngine will survive configuration  // changes. Therefore, we create a new one only if one does not already exist.  if (flutterEngine == null) { setupFlutterEngine(); } } private void setupFlutterEngine() { // Second, defer to subclasses for a custom FlutterEngine.  flutterEngine = host.provideFlutterEngine(host.getContext()); if (flutterEngine != null) { isFlutterEngineFromHost = true; return; } } } provideFlutterEngine /** \\* Hook for subclasses to easily provide a custom {@link FlutterEngine}. \\* \u0026lt;p\u0026gt; \\* This hook is where a cached {@link FlutterEngine} should be provided, if a cached \\* {@link FlutterEngine} is desired. */ @Nullable @Override public FlutterEngine provideFlutterEngine(@NonNull Context context) { // No-op. Hook for subclasses.  return FlutterBoost.instance().engineProvider(); } setContentView(createFlutterView()) @NonNull protected View createFlutterView() { return delegate.onCreateView( null /* inflater */, null /* container */, null /* savedInstanceState */); } View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) { Log.v(TAG, \u0026#34;Creating FlutterView.\u0026#34;); flutterEngine.getActivityControlSurface().attachToActivity( host.getActivity(), host.getLifecycle() ); mSyncer = FlutterBoost.instance().containerManager().generateSyncer(this); mSyncer.onCreate(); } mSyncer.onCreate() ContainerRecord implements IContainerRecord implements IOperateSyncer { private MethodChannelProxy mProxy = new MethodChannelProxy(); @Override public void onCreate() { mState = STATE_CREATED; mProxy.create(); } private class MethodChannelProxy { private void create() { if (mState == STATE_UNKNOW) { invokeChannelUnsafe(\u0026#34;didInitPageContainer\u0026#34;, mContainer.getContainerUrl(), mContainer.getContainerUrlParams(), mUniqueId ); //Debuger.log(\u0026#34;didInitPageContainer\u0026#34;);  mState = STATE_CREATED; } } public void invokeChannelUnsafe(String method, String url, Map params, String uniqueId) { HashMap\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;pageName\u0026#34;, url); args.put(\u0026#34;params\u0026#34;, params); args.put(\u0026#34;uniqueId\u0026#34;, uniqueId); FlutterBoost.instance().channel().invokeMethodUnsafe(method, args);//goto dart ContainerCoordinator._onMethodCall  } } ContainerCoordinator._onMethodCall //ContainerCoordinator Future\u0026lt;dynamic\u0026gt; _onMethodCall(MethodCall call) { Logger.log(\u0026#34;onMetohdCall ${call.method}\u0026#34;); switch (call.method) { case \u0026#34;didInitPageContainer\u0026#34;: { String pageName = call.arguments[\u0026#34;pageName\u0026#34;]; Map params = call.arguments[\u0026#34;params\u0026#34;]; String uniqueId = call.arguments[\u0026#34;uniqueId\u0026#34;]; _nativeContainerDidInit(pageName, params, uniqueId); } break; case \u0026#34;didShowPageContainer\u0026#34;: { String pageName = call.arguments[\u0026#34;pageName\u0026#34;]; Map params = call.arguments[\u0026#34;params\u0026#34;]; String uniqueId = call.arguments[\u0026#34;uniqueId\u0026#34;]; nativeContainerDidShow(pageName, params, uniqueId); } break; _nativeContainerDidInit bool _nativeContainerDidInit(String name, Map params, String pageId) { performContainerLifeCycle(_createContainerSettings(name, params, pageId),ContainerLifeCycle.Init); return true; } _createContainerSettings BoostContainerSettings _createContainerSettings( String name, Map params, String pageId) { Widget page; final BoostContainerSettings routeSettings = BoostContainerSettings(//main  uniqueId: pageId, name: name, params: params, builder: (BuildContext ctx) {//main  //Try to build a page using keyed builder.  if (_pageBuilders[name] != null) { page = _pageBuilders[name](name, params, pageId);//main  } //Build a page using default builder.  if (page == null \u0026amp;\u0026amp; _defaultPageBuilder != null) { page = _defaultPageBuilder(name, params, pageId); } assert(page != null); Logger.log(\u0026#39;build widget:$pagefor page:$name($pageId)\u0026#39;); return page; }); return routeSettings; } BoostFlutterActivity.onResume @Override protected void onResume() { super.onResume(); lifecycle.handleLifecycleEvent(Lifecycle.Event.ON_RESUME); delegate.onResume(); } void onResume() { mSyncer.onAppear();//main  ensureAlive(); flutterEngine.getLifecycleChannel().appIsResumed(); BoostPluginRegistry registry = (BoostPluginRegistry) FlutterBoost.instance().getPluginRegistry(); ActivityPluginBinding binding = registry.getRegistrarAggregate().getActivityPluginBinding(); if (binding != null \u0026amp;\u0026amp; (binding.getActivity() != this.host.getActivity())) { flutterEngine.getActivityControlSurface().attachToActivity( host.getActivity(), host.getLifecycle() ); } } mSyncer.onAppear() //ContainerRecord @Override public void onAppear() { Utils.assertCallOnMainThread(); if (mState != STATE_CREATED \u0026amp;\u0026amp; mState != STATE_DISAPPEAR) { Debuger.exception(\u0026#34;state error\u0026#34;); } mState = STATE_APPEAR; mManager.pushRecord(this); mProxy.appear(); mContainer.getBoostFlutterView().onAttach(); } ContainerCoordinator.nativeContainerDidShow bool nativeContainerDidShow(String name, Map params, String pageId) { FlutterBoost.containerManager?.showContainer(_createContainerSettings(name, params, pageId)); ContainerManagerState.showContainer BoostContainerManager extends StatefulWidget { @override ContainerManagerState createState() =\u0026gt; ContainerManagerState(); } ContainerManagerState extends State\u0026lt;BoostContainerManager\u0026gt; { BoostContainer _onstage; //Current visible container.  BoostContainerState get onstageContainer =\u0026gt; _stateOf(_onstage); List\u0026lt;_ContainerOverlayEntry\u0026gt; _leastEntries; final GlobalKey\u0026lt;OverlayState\u0026gt; _overlayKey = GlobalKey\u0026lt;OverlayState\u0026gt;(); //If container exists bring it to front else create a container.  void showContainer(BoostContainerSettings settings) { if (settings.uniqueId == _onstage.settings.uniqueId) { _onShownContainerChanged(null, settings.uniqueId); return; } final int index = _offstage.indexWhere((BoostContainer container) =\u0026gt; container.settings.uniqueId == settings.uniqueId); if (index \u0026gt; -1) { _offstage.add(_onstage); _onstage = _offstage.removeAt(index); setState(() {}); } else { pushContainer(settings);//main  } } } pushContainer void pushContainer(BoostContainerSettings settings) { assert(settings.uniqueId != _onstage.settings.uniqueId); assert(_offstage.every((BoostContainer container) =\u0026gt; container.settings.uniqueId != settings.uniqueId)); _offstage.add(_onstage); _onstage = BoostContainer.obtain(widget.initNavigator, settings);//main  setState(() {}); } BoostContainer.obtain BoostContainer extends Navigator { final BoostContainerSettings settings; @override BoostContainerState createState() =\u0026gt; BoostContainerState(); @override StatefulElement createElement() =\u0026gt; ContainerElement(this); factory BoostContainer.obtain( Navigator navigator, BoostContainerSettings settings) =\u0026gt; BoostContainer( key: GlobalKey\u0026lt;BoostContainerState\u0026gt;(), settings: settings, onGenerateRoute: (RouteSettings routeSettings) {//main  if (routeSettings.name == \u0026#39;/\u0026#39;) { return BoostPageRoute\u0026lt;dynamic\u0026gt;(//main  pageName: settings.name, params: settings.params, uniqueId: settings.uniqueId, animated: false, settings: routeSettings, builder: settings.builder);//main  } else { return navigator.onGenerateRoute(routeSettings); } }, observers: \u0026lt;NavigatorObserver\u0026gt;[ ContainerNavigatorObserver.bindContainerManager() ], onUnknownRoute: navigator.onUnknownRoute); } BoostContainerState extends NavigatorState ContainerManagerState.setState @override void setState(VoidCallback fn) { if (SchedulerBinding.instance.schedulerPhase == SchedulerPhase.persistentCallbacks) { SchedulerBinding.instance.addPostFrameCallback((Duration duration) { _refreshOverlayEntries(); }); } else { _refreshOverlayEntries();//main  } fn(); //return super.setState(fn);  } void _refreshOverlayEntries() { final OverlayState overlayState = _overlayKey.currentState; final List\u0026lt;BoostContainer\u0026gt; containers = \u0026lt;BoostContainer\u0026gt;[]; containers.addAll(_offstage); assert(_onstage != null, \u0026#39;Should have a least one BoostContainer\u0026#39;); containers.add(_onstage); _leastEntries = containers .map\u0026lt;_ContainerOverlayEntry\u0026gt;( (BoostContainer container) =\u0026gt; _ContainerOverlayEntry(container)) .toList(growable: false); overlayState.insertAll(_leastEntries);//main  SchedulerBinding.instance.addPostFrameCallback((Duration timeStamp) { final String now = _onstage.settings.uniqueId; if (_lastShownContainer != now) { final String old = _lastShownContainer; _lastShownContainer = now; _onShownContainerChanged(old, now);//main  } updateFocuse(); }); void _onShownContainerChanged(String old, String now) { FlutterBoost.singleton.channel.invokeMethod(\u0026#39;onShownContainerChanged\u0026#39;,properties); } BoostPageRoute BoostPageRoute\u0026lt;T\u0026gt; extends MaterialPageRoute\u0026lt;T\u0026gt; { final String pageName; final String uniqueId; final Map params; final bool animated; final WidgetBuilder builder; final RouteSettings settings; static BoostPageRoute\u0026lt;T\u0026gt; of\u0026lt;T\u0026gt;(BuildContext context) { final Route\u0026lt;T\u0026gt; route = ModalRoute.of(context); if (route != null \u0026amp;\u0026amp; route is BoostPageRoute\u0026lt;T\u0026gt;) { return route; } else { throw Exception(\u0026#39;not in a BoostPageRoute\u0026#39;); } } BoostPageRoute( {Key stubKey, this.pageName, this.params, this.uniqueId, this.animated, this.builder, this.settings}) : super( builder: (BuildContext context) =\u0026gt; Stub(stubKey, builder(context)), settings: settings); @immutable class Stub extends StatefulWidget { final Widget child; const Stub(Key key, this.child) : super(key: key); @override _StubState createState() =\u0026gt; _StubState(); } class _StubState extends State\u0026lt;Stub\u0026gt; { @override Widget build(BuildContext context) =\u0026gt; widget.child; } } main.dart main void main() { runApp(MyApp()); } class MyApp extends StatefulWidget { @override _MyAppState createState() =\u0026gt; _MyAppState(); } class _MyAppState extends State\u0026lt;MyApp\u0026gt; { @override void initState() { super.initState(); FlutterBoost.singleton.registerPageBuilders({//main  \u0026#39;embeded\u0026#39;: (pageName, params, _)=\u0026gt;EmbededFirstRouteWidget(), \u0026#39;first\u0026#39;: (pageName, params, _) =\u0026gt; FirstRouteWidget(), \u0026#39;second\u0026#39;: (pageName, params, _) =\u0026gt; SecondRouteWidget(), \u0026#39;tab\u0026#39;: (pageName, params, _) =\u0026gt; TabRouteWidget(), \u0026#39;platformView\u0026#39;: (pageName, params, _) =\u0026gt; PlatformRouteWidget(), \u0026#39;flutterFragment\u0026#39;: (pageName, params, _) =\u0026gt; FragmentRouteWidget(params), ///可以在native层通过 getContainerParams 来传递参数  \u0026#39;flutterPage\u0026#39;: (pageName, params, _) { print(\u0026#34;flutterPage params:$params\u0026#34;); return FlutterRouteWidget(params:params); }, }); } @override Widget build(BuildContext context) { return MaterialApp( title: \u0026#39;Flutter Boost example\u0026#39;, builder: FlutterBoost.init(postPush: _onRoutePushed),//main  home: Container()); } void _onRoutePushed( String pageName, String uniqueId, Map params, Route route, Future _) { } registerPageBuilders FlutterBoost\ntypedef Widget PageBuilder(String pageName, Map params, String uniqueId); ///Register a map builders  void registerPageBuilders(Map\u0026lt;String, PageBuilder\u0026gt; builders) { ContainerCoordinator.singleton.registerPageBuilders(builders); } ContainerCoordinator\nvoid registerPageBuilders(Map\u0026lt;String, PageBuilder\u0026gt; builders) { if (builders?.isNotEmpty == true) { _pageBuilders.addAll(builders);//main  } } init FlutterBoost\nstatic TransitionBuilder init( {TransitionBuilder builder, PrePushRoute prePush, PostPushRoute postPush}) { if (Platform.isAndroid) { onPageStart(); } return (BuildContext context, Widget child) { assert(child is Navigator, \u0026#39;child must be Navigator, what is wrong?\u0026#39;); final BoostContainerManager manager = BoostContainerManager( key: _instance.containerManagerKey, initNavigator: child, prePushRoute: prePush, postPushRoute: postPush); if (builder != null) { return builder(context, manager); } else { return manager; } }; 总结  初始化engine，调用dart main方法，注册页面url和widget的映射关系 startActivity前在intent里配置页面url container_manager控制showContainer重绘，重新build时选择新的route 为什么不使用官方的routes+Navigator控制当前的flutter页面?  参考 FlutterBoost open Future\u0026lt;Map\u0026lt;dynamic, dynamic\u0026gt;\u0026gt; open(String url, {Map\u0026lt;dynamic, dynamic\u0026gt; urlParams, Map\u0026lt;dynamic, dynamic\u0026gt; exts}) { Map\u0026lt;dynamic, dynamic\u0026gt; properties = new Map\u0026lt;dynamic, dynamic\u0026gt;(); properties[\u0026#34;url\u0026#34;] = url; properties[\u0026#34;urlParams\u0026#34;] = urlParams; properties[\u0026#34;exts\u0026#34;] = exts; return channel.invokeMethod\u0026lt;Map\u0026lt;dynamic, dynamic\u0026gt;\u0026gt;(\u0026#39;openPage\u0026#39;, properties); } FlutterEngine /* \u0026lt;p\u0026gt; * To start rendering Flutter content to the screen, use {@link #getRenderer()} to obtain a * {@link FlutterRenderer} and then attach a {@link RenderSurface}. Consider using a * {@link io.flutter.embedding.android.FlutterView} as a {@link RenderSurface}.*/ FlutterEngine /** \\* The rendering system associated with this {@code FlutterEngine}. \\* \u0026lt;p\u0026gt; \\* To render a Flutter UI that is produced by this {@code FlutterEngine}\u0026#39;s Dart code, attach \\* a {@link RenderSurface} to this \\* {@link FlutterRenderer}. */ @NonNull public FlutterRenderer getRenderer() { return renderer; } FlutterRenderer private final FlutterJNI flutterJNI; startRenderingToSurface /** \\* Notifies Flutter that the given {@code surface} was created and is available for Flutter \\* rendering. \\* \u0026lt;p\u0026gt; \\* See {@link android.view.SurfaceHolder.Callback} and \\* {@link android.view.TextureView.SurfaceTextureListener} */ public void startRenderingToSurface(@NonNull Surface surface) { if (this.surface != null) { stopRenderingToSurface(); } this.surface = surface; flutterJNI.onSurfaceCreated(surface); } RenderSurface /** \\* Owns a {@code Surface} that {@code FlutterRenderer} would like to paint. \\* \u0026lt;p\u0026gt; \\* {@code RenderSurface} is responsible for providing a {@code Surface} to a given \\* {@code FlutterRenderer} when requested, and then notify that {@code FlutterRenderer} when \\* the {@code Surface} changes, or is destroyed. \\* \u0026lt;p\u0026gt; \\* The behavior of providing a {@code Surface} is delegated to this interface because the timing \\* of a {@code Surface}\u0026#39;s availability is determined by Android. Therefore, an accessor method \\* would not fulfill the requirements. Therefore, a {@code RenderSurface} is given a \\* {@code FlutterRenderer}, which the {@code RenderSurface} is expected to notify as a \\* {@code Surface} becomes available, changes, or is destroyed. */ RenderSurface { /** \\* Returns the {@code FlutterRenderer} that is attached to this {@code RenderSurface}, or \\* null if no {@code FlutterRenderer} is currently attached. */ @Nullable FlutterRenderer getAttachedRenderer(); /** \\* Instructs this {@code RenderSurface} to give its {@code Surface} to the given \\* {@code FlutterRenderer} so that Flutter can paint pixels on it. \\* \u0026lt;p\u0026gt; \\* After this call, {@code RenderSurface} is expected to invoke the following methods on \\* {@link FlutterRenderer} at the appropriate times: \\* \u0026lt;ol\u0026gt; \\* \u0026lt;li\u0026gt;{@link FlutterRenderer#startRenderingToSurface(Surface)}\u0026lt;/li\u0026gt; \\* \u0026lt;li\u0026gt;{@link FlutterRenderer#surfaceChanged(int, int)}}\u0026lt;/li\u0026gt; \\* \u0026lt;li\u0026gt;{@link FlutterRenderer#stopRenderingToSurface()}\u0026lt;/li\u0026gt; \\* \u0026lt;/ol\u0026gt; */ void attachToRenderer(@NonNull FlutterRenderer renderer); } XFlutterView attachToFlutterEngine public void attachToFlutterEngine( @NonNull FlutterEngine flutterEngine ) { Log.d(TAG, \u0026#34;Attaching to a FlutterEngine: \u0026#34; + flutterEngine); if (isAttachedToFlutterEngine()) { if (flutterEngine == this.flutterEngine) { // We are already attached to this FlutterEngine  Log.d(TAG, \u0026#34;Already attached to this engine. Doing nothing.\u0026#34;); return; } // Detach from a previous FlutterEngine so we can attach to this new one.  Log.d(TAG, \u0026#34;Currently attached to a different engine. Detaching and then attaching\u0026#34; \\+ \u0026#34; to new engine.\u0026#34;); detachFromFlutterEngine(); } this.flutterEngine = flutterEngine; // Instruct our FlutterRenderer that we are now its designated RenderSurface.  FlutterRenderer flutterRenderer = this.flutterEngine.getRenderer(); flutterRenderer.attachToRenderSurface(renderSurface); ContainerManagerState _ContainerOverlayEntry ContainerManagerState extends State\u0026lt;BoostContainerManager\u0026gt; { class _ContainerOverlayEntry extends OverlayEntry { bool _removed = false; _ContainerOverlayEntry(BoostContainer container) : super( builder: (BuildContext ctx) =\u0026gt; container, opaque: true, maintainState: true); @override Widget build(BuildContext context) { return Overlay( key: _overlayKey, initialEntries: const \u0026lt;OverlayEntry\u0026gt;[], ); } } providePlatformPlugin public PlatformPlugin providePlatformPlugin(@Nullable Activity activity, @NonNull FlutterEngine flutterEngine) { if (activity != null) { return new PlatformPlugin(getActivity(), flutterEngine.getPlatformChannel()); } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/gc/",
	"title": "GC",
	"tags": [],
	"description": "",
	"content": "类设计 runtime.cc\nRuntime::VisitRoots void Runtime::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) { /*RootVisitor是一个纯虚类，其定义了几个函数，供root访问时调用。参数flags有一个默认 值，为kVisitRootFlagAllRoots，表示要访问所有的root。*/ VisitNonConcurrentRoots(visitor); VisitConcurrentRoots(visitor, flags); } Runtime::VisitNonConcurrentRoots void Runtime::VisitNonConcurrentRoots(RootVisitor* visitor) { //1：调用所有Thread对象的VisitRoots函数  thread_list_-\u0026gt;VisitRoots(visitor); VisitNonThreadRoots(visitor);//接着看该函数的代码 } Thread::VisitRoots void Thread::VisitRoots(RootVisitor* visitor) { /*GetThreadId返回的是Thread tlsPtr_ thin_lock_thread_id thin_lock_id。 我们在12.2.1节中介绍过它。该id并不是代表操作系统里线程的tid，而是由虚拟机自己维护的用 于线程同步的id。*/ const uint32_t thread_id = GetThreadId(); //tlsPtr_opeer指向一个Java层Thread对象，它是一个mirror Thread对象在Java层  //的对应物。这类根对象的类型为kRootThreadObject  visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.opeer, RootInfo(kRootThreadObject, thread_id)); /*tlsPtr_ exception指向一个Java异常对象。注意，GetDeoptimizationException返 回的值非常特殊（为-1）。所以，它并不是一个真正的Java异常对象，只是用-1来表示和 HDeoptimize有关的处理（详情可参考10.4节的内容） */ if (tlsPtr_.exception != nullptr \u0026amp;\u0026amp; tlsPtr_.exception != GetDeoptimizationException()) { //使用kRootNativeStack作为tlsPtr_ exception的root类型  visitor-\u0026gt;VisitRoot(reinterpret_cast\u0026lt;mirror::Object**\u0026gt;( \u0026amp;tlsPtr_.exception), RootInfo(kRootNativeStack, thread_id)); } //tlsPtr_ monitor_enter_object指向用于monitor-enter的那个Java对象。详情可参考  //12.3.2.1.1节的内容  visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.monitor_enter_object,RootInfo(kRootNativeStack, thread_id)); /*tlsPtr_ jni_env locals的类型为IndirectReferenceTable（简写为IRTable）， 而tlsPtr_ jni_env monitors与synchronized修饰的java native函数的调用有关， 用于同步native函数的调用。本书关于JNI的部分中并未对synchronized修饰的native 函数做过讲解，读者可结合第11章的内容自行研究它。*/ tlsPtr_.jni_env-\u0026gt;locals.VisitRoots(visitor, RootInfo(kRootJNILocal,thread_id)); tlsPtr_.jni_env-\u0026gt;monitors.VisitRoots(visitor, RootInfo(kRootJNIMonitor, thread_id)); /*HandleScopeVisitRoots也和JNI有关，读者可回顾9.5.3节的内容。调用jni函数时，引用型参 数会借助一个HandleScope保存在栈上。而HandleScopeVisitRoots函数将遍历tlsPtr_top_ handle_scope链表，然后访问其中的引用型对象。简单点说，下面这个函数将找到那些传递 给了native函数的引用型对象。 */ HandleScopeVisitRoots(visitor, thread_id); .....//其他一些情况下root Object的遍历。与之相关的内容建议读者在本书基础上自行研究  /*下面来看最关键的一个知识。我们先举个例子，假设有这样一段代码，funcA函数中创建一个 Object对象obj，然后用它作为参数调用funcB： void funcA(){ Object obj= new Object();//创建一个对象 funcB(obj);//如果屏蔽这行代码，那么obj就是垃圾对象 } 在上述代码中，如果没有funcB调用的那行代码，obj就是一个没有人用的垃圾对象，否则，我们就需 要特殊考虑。因为对funcB调用而言，obj被用到了。但这种被用的方式显然和对象的某个引用型成员 变量的引用方式不同，它是通过作为函数调用的引用型参数来引用的。从某种意义上说，它和JNI HandleScope 里的引用型参数一样。对于这种和函数调用有关的对象，就需要遍历线程的调用栈帧，找到其中所有引 用型的参数，把它们视为根对象。下面几行代码就是干这个工作的，我们重点介绍它们。 */ Context* context = GetLongJumpContext(); RootCallbackVisitor visitor_to_callback(visitor, thread_id); ReferenceMapVisitor\u0026lt;RootCallbackVisitor\u0026gt; mapper(this, context,visitor_to_callback); //ReferenceMapVisitor派生自StackVisitor类。10.2.4节曾详细介绍过StackVisitor。  mapper.WalkStack(); ReleaseLongJumpContext(context); ...... } Runtime::VisitNonThreadRoots void Runtime::VisitNonThreadRoots(RootVisitor* visitor) { //java_vm_类型为JavaVmExt，2：调用它的VisitRoots函数  java_vm_-\u0026gt;VisitRoots(visitor); /*3: sentinel_是Runtime的成员变量，类型为GcRoot\u0026lt;Object\u0026gt;，它对应一个Java层的java.lang. Object对象。其作用我们后续碰到时再介绍。 */ sentinel_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); /*:3: preallocated_OutOfMemoryError_以及pre_allocated_NoClassDefFoundError_是Runtime 的成员变量，类型为GcRoot\u0026lt;Throwable\u0026gt;。它们属于由虚拟机直接创建的JavaObject对象。创建 它们的代码可参考7.2.2节所示Runtime Init函数的最后几行。 */ pre_allocated_OutOfMemoryError_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); pre_allocated_NoClassDefFoundError_.VisitRootIfNonNull(visitor,RootInfo(kRootVMInternal)); //4: 调用RegTypeCache的VisitStaticRoots函数  verifier::MethodVerifier::VisitStaticRoots(visitor); //下面这个函数的内容和dex2oat的编译流程有关，我们不拟介绍它  VisitTransactionRoots(visitor); } Runtime::VisitConcurrentRoots void Runtime::VisitConcurrentRoots(RootVisitor* visitor, VisitRootFlags flags) { //5: intern_table_的类型为InternTable，和Intern String有关  intern_table_-\u0026gt;VisitRoots(visitor, flags); //6: 调用ClassLinker的VisitRoots函数  class_linker_-\u0026gt;VisitRoots(visitor, flags); .... if ((flags \u0026amp; kVisitRootFlagNewRoots) == 0) { VisitConstantRoots(visitor);//7  } Dbg::VisitRoots(visitor);//和调试有关，本书不拟介绍它 } heap.cc\nHeap初始化时对Collector的设置 Heap::Heap(... CollectorType foreground_collector_type, CollectorType background_collector_type, ...) : ... foreground_collector_type_(foreground_collector_type), background_collector_type_(background_collector_type), desired_collector_type_(foreground_collector_type_), ...{ //设置回收器类型和回收策略，详情见下文代码分析  ChangeCollector(desired_collector_type_); //创建Space对象等工作，比较复杂，这也是Heap难度较大的原因之一。Android后续版本  //对此处的代码逻辑做了一些优化和调整  ...... /*创建回收器。garbage_collectors_是一个数组，元素类型为GarbageCollector*。 下面的MayUseCollector函数将检查前台回收器类型（foreground_collector_type_）或后台 回收器类型（background_collector_type_）是否为输入的回收器类型，只要有一个回收器类型 满足条件，则MayUseCollector返回true。如果回收器类型为CMS或MS，下面这段for循环代码中 的if代码块只会执行一次，不论哪一次执行都会创建三个垃圾回收器对象，它们分别是MarkSweep、 PartialMarkSweep和StickyMarkSweep。CMS和MS区别之处在于这三个回收器对象是否用 concurrent gc功能。*/ for (size_t i = 0; i \u0026lt; 2; ++i) { const bool concurrent = i != 0; if ((MayUseCollector(kCollectorTypeCMS) \u0026amp;\u0026amp; concurrent) || (MayUseCollector(kCollectorTypeMS) \u0026amp;\u0026amp; !concurrent)) { garbage_collectors_.push_back(new collector::MarkSweep(this, concurrent)); garbage_collectors_.push_back(new collector::PartialMarkSweep(this, concurrent)); garbage_collectors_.push_back(new collector::StickyMarkSweep(this, concurrent)); } } if (kMovingCollector) {//kMovingCollector默认为true  if (MayUseCollector(kCollectorTypeSS) || MayUseCollector(kCollectorTypeGSS) || MayUseCollector(kCollectorTypeHomogeneousSpaceCompact) || use_homogeneous_space_compaction_for_oom_) { //前台回收器类型为GSS时，generational才为true  const bool generational = foreground_collector_type_ == kCollectorTypeGSS; //如果使用SS、GSSS或HSC，则再创建一个SemiSpace collector对象  semi_space_collector_ = new collector::SemiSpace(this, generational, generational ? \u0026#34;generational\u0026#34; : \u0026#34;\u0026#34;); garbage_collectors_.push_back(semi_space_collector_); } ......//其他回收器类型的处理，读者可自行阅读  } ...... } void Heap::ChangeCollector(CollectorType collector_type) { if (collector_type != collector_type_) { ...... //collector_tyoe_和gc_plan_均为Heap成员变量  collector_type_ = collector_type;//设置回收器类型  gc_plan_.clear(); switch (collector_type_) { ...... case kCollectorTypeMC: // Fall-through.  case kCollectorTypeSS: // Fall-through.  case kCollectorTypeGSS: { //gc_plan_为数组，保存了回收策略。ART在GC时将用到它  gc_plan_.push_back(collector::kGcTypeFull); ......//设置内存分配器的类型为kAllocatorTypeBumpPointer  break; } ...... case kCollectorTypeCMS: { gc_plan_.push_back(collector::kGcTypeSticky); gc_plan_.push_back(collector::kGcTypePartial); gc_plan_.push_back(collector::kGcTypeFull); .....//设置内存分配器的类型为kAllocatorTypeRosAlloc  break; } ...... } // IsGcConcurrent判断collector_type_是否为CMS或CC（kCollectorTypeCC，意为Concurrent Copying）  if (IsGcConcurrent()) { //concurrent_start_bytes_和concurrent gc有关。其用途我们后续代码分析时候  //将看到。kMinConcurrentRemainingBytes取值为128KB  concurrent_start_bytes_ = std::max(max_allowed_footprint_, kMinConcurrentRemainingBytes) – kMinConcurrentRemainingBytes; } else { concurrent_start_bytes_ = std::numeric_limits\u0026lt;size_t\u0026gt;::max(); } } } garbage_collector.cc\nGarbageCollector::Run void GarbageCollector::Run(GcCause gc_cause, bool clear_soft_references) { //GcCause为枚举变量，表示触发本次gc的原因。后文介绍相关代码时将了解到不同的Gc原因  ..... Thread* self = Thread::Current(); uint64_t start_time = NanoTime();//本次GC的GC开始时间  /*GetCurrentIteration返回Heap current_gc_iteration_成员变量。由上文所述可知， 它用于统计GC的执行效果。Iteration Reset将重新设置相关的统计参数。*/ Iteration* current_iteration = GetCurrentIteration(); current_iteration-\u0026gt;Reset(gc_cause, clear_soft_references); RunPhases(); // RunPhase由GarbageCollector子类实现，它将完成真正的GC工作,main  //RunPhases之后，本次GC也就算执行完了。下面的代码用于统计此次GC的执行效果  cumulative_timings_.AddLogger(*GetTimings()); /*total_freed_objects_和total_freed_bytes_GarbageCollector的成员变量，代表虚拟机 从运行开始所有GC操作释放的对象总个数以及内存大小总数。Iteration的GetFreedObjects和 GetFreedLargeObjects、GetFreedBytes和GetFreedLargeObjectBytes返回一次GC （也就是调用每次调用Run函数）所释放的对象个数以及内存大小（包括非大内存对象以及大内存对 象）。 */ total_freed_objects_ += current_iteration-\u0026gt;GetFreedObjects() + current_iteration-\u0026gt;GetFreedLargeObjects(); total_freed_bytes_ += current_iteration-\u0026gt;GetFreedBytes() + _iteration-\u0026gt;GetFreedLargeObjectBytes(); uint64_t end_time = NanoTime(); //本次GC的结束时间  //设置本次GC的耗时时间  current_iteration-\u0026gt;SetDurationNs(end_time - start_time); //更新暂停时间以及总的GC运行时间等统计信息。这里省略部分代码，建议读者学习完本章后，再  //来看它。  ..... total_time_ns_ += current_iteration-\u0026gt;GetDurationNs(); ...... } 其他: gc_root.h\nRoot enum RootType enum RootType { kRootUnknown = 0, kRootJNIGlobal,kRootJNILocal, kRootJavaFrame, kRootNativeStack, kRootStickyClass, kRootThreadBlock, kRootMonitorUsed, kRootThreadObject, kRootInternedString, //下面三种root类型和HPROF(A Heap/CPU Profiling Tool，性能调优工具)以及调试有关，  //本书不拟介绍它们  kRootFinalizing, kRootDebugger,kRootReferenceCleanup, //最后两种root的类型  kRootVMInternal, kRootJNIMonitor, }; RootInfo //RootInfo用于描述一个root的信息。具体而言，root信息包括该root的类型以及它所在的 //线程id。 class RootInfo { public: //由于不是所有root信息都和线程有关系，所有下面这个构造函数中，thread_id默认值为0  explicit RootInfo(RootType type, uint32_t thread_id = 0) : type_(type), thread_id_(thread_id) { } .... private: const RootType type_;//该root的类型  const uint32_t thread_id_;//该root所在的线程 }; GcRootSource class GcRootSource {//它仅包含两个成员变量。  ..... private: ArtField* const field_; ArtMethod* const method_; }; GcRoot template\u0026lt;class MirrorType\u0026gt; class GcRoot { //一个GcRoot实例就代表一个被认为是根的Object对象  private: /*GcRoot只有下面一个成员变量，其类型为CompressedReference。CompressedReference 中只有一个reference_（类型为uint32_t）成员。这个成员也就是某个Object对象的内存 地址。所以，简单来说，root_也就是代表某个Object对象。*/ mutable mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;root_; public: /*GcRoot提供了几个成员函数用于很方便地访问root_。如上文所述，一个GcRoot对象代表一个 被认为是根的Object对象（以后我们称之为root Object或根Object）。所以，下面的几个 root访问函数其实访问的就是root_的一个对象。*/ void VisitRoot(RootVisitor* visitor, const RootInfo\u0026amp; info) const{ mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* roots[1] = { \u0026amp;root_ }; visitor-\u0026gt;VisitRoots(roots, 1u, info); } void VisitRootIfNonNull(RootVisitor* visitor, const RootInfo\u0026amp; info) const { if (!IsNull()) {//如果root_不为空指针，则访问它  VisitRoot(visitor, info); } } bool IsNull() const { return root_.IsNull(); } ..... }; RootVisitor class RootVisitor { public: virtual ~RootVisitor() { } //下面两个VisitRoots为虚函数，由RootVisitor的子类实现。它们用于访问一组root Object对象  virtual void VisitRoots(mirror::Object*** roots, size_t count, const RootInfo\u0026amp; info) = 0; virtual void VisitRoots(mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;** roots, size_t count, const RootInfo\u0026amp; info) = 0; //下面两个函数为辅助函数，用于访问单个root Object对象  void VisitRoot(mirror::Object** root, const RootInfo\u0026amp; info) { VisitRoots(\u0026amp;root, 1, info); } void VisitRootIfNonNull(mirror::Object** root, const RootInfo\u0026amp; info) { if (*root != nullptr) { VisitRoot(root, info); } } ...... }; BufferedRootVisitor template \u0026lt;size_t kBufferSize\u0026gt; class BufferedRootVisitor { private: RootVisitor* const visitor_; //roots_数组，数组最大容量由模板参数kBufferSize决定。该数组中的root Object对应  //同一种RootType（由root_info_的type_表示）  mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* roots_[kBufferSize]; RootInfo root_info_; size_t buffer_pos_;//roots_数组中元素的个数  public: template \u0026lt;class MirrorType\u0026gt; void VisitRoot(mirror::CompressedReference\u0026lt;MirrorType\u0026gt;* root){ if (UNLIKELY(buffer_pos_ \u0026gt;= kBufferSize)) { Flush();//如果roots_数组已满，则调用Flush  } //如果roots_数组还没有填满，则仅仅是把root存到roots_数组中  roots_[buffer_pos_++] = root; } void Flush() { //一次性访问roots_数组中的root Object内容  visitor_-\u0026gt;VisitRoots(roots_, buffer_pos_, root_info_); buffer_pos_ = 0; } //其他访问函数  template \u0026lt;class MirrorType\u0026gt; void VisitRootIfNonNull(GcRoot\u0026lt;MirrorType\u0026gt;\u0026amp; root) { if (!root.IsNull()) { VisitRoot(root); } } template \u0026lt;class MirrorType\u0026gt; void VisitRootIfNonNull(mirror::CompressedReference\u0026lt;MirrorType\u0026gt;* root) { if (!root-\u0026gt;IsNull()) { VisitRoot(root); } } .... }; collector_type.h\nenum CollectorType enum CollectorType { kCollectorTypeNone, //下面两个枚举值和MarkSweep类有关。详情见本章对应小节的分析  kCollectorTypeMS,kCollectorTypeCMS, //下面两个枚举值和SemiSpace类有关  kCollectorTypeSS,kCollectorTypeGSS, //和MarkCompact类有关  kCollectorTypeMC, //和GarbageCollector类家族无关，其作用见后续代码分析  kCollectorTypeHeapTrim, //和ConcurrentCopying类有关  kCollectorTypeCC, kCollectorTypeInstrumentation, //和GarbageCollector类家族无关，其作用见后续代码分析  kCollectorTypeAddRemoveAppImageSpace, //和CMS有关。详情见后续代码分析  kCollectorTypeHomogeneousSpaceCompact, //和GarbageCollector类家族无关，其作用见后续代码分析  kCollectorTypeClassLinker, }; gc_type.h\nenum GcType //从某种意义上来说，GcType反应的是回收工作的力度。枚举值越大，力度越高，工作也越“辛苦” enum GcType { kGcTypeNone, //表示仅扫描和回收上次GC到本次GC这个时间段内所创建的对象  kGcTypeSticky, /*仅扫描和回收应用进程自己的堆，不处理zygote的堆。这种方式和Android中Java应用程序的创建 方式有关。在Android中，应用进程是zygote进程fork出来的。*/ kGcTypePartial, //力度最大的一种回收策略，扫描APP自己以及它从父进程zygote继承得到的堆  kGcTypeFull, kGcTypeMax, }; Mutator the program that modifies the objects in heap (simply, the user program)\nmutator和collector：我们在第13章中曾提到过它们。这两个词是由已故世界级计算机科学先驱Edsger W.Dijkstra于1976年左右提出的。简单来说，collector表示内存回收相关的功能模块。而mutator和collector相对，一般情况下代表应用程序中除collector之外的其他部分。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/gc_concurrentcopying/",
	"title": "GC_ConcurrentCopying",
	"tags": [],
	"description": "",
	"content": "ConcurrentCopying virtual GcType GetGcType() const OVERRIDE { //ConcurrentCopying仅支持kGcTypePartial，也就是不扫描ImageSpace和  //ZygoteSpace（除了那些有dirty card的对象）  return kGcTypePartial; } virtual CollectorType GetCollectorType() const OVERRIDE { return kCollectorTypeCC;//返回回收器类型 } void SetRegionSpace(space::RegionSpace* region_space) { //region_space_是ConcurrentCopying的成员变量  //ConcurrentCopying要回收的垃圾对象就在这个region_space_中  region_space_ = region_space; } RunPhases void ConcurrentCopying::RunPhases() { is_active_ = true; Thread* self = Thread::Current(); thread_running_gc_ = self; { ReaderMutexLock mu(self, *Locks::mutator_lock_); InitializePhase();//①初始化阶段  } FlipThreadRoots();//②完成半空间Flip工作  { ReaderMutexLock mu(self, *Locks::mutator_lock_); MarkingPhase();//③标记  } ...... { ReaderMutexLock mu(self, *Locks::mutator_lock_); ReclaimPhase();//④回收  } FinishPhase();//收尾工作，非常简单，请读者自行阅读  is_active_ = false; thread_running_gc_ = nullptr; } InitializePhase void ConcurrentCopying::InitializePhase() { ...... CheckEmptyMarkStack();//详情见下文代码分析  //immune_spaces_类型为ImmuneSpace，保存了不需要GC的空间对象  immune_spaces_.Reset(); ..... /*下面的代码逻辑将设置force_evacuate_all_成员变量，它和RegionSpace有关，我们 后续用到该变量时再介绍其含义。*/ if (GetCurrentIteration()-\u0026gt;GetGcCause() == kGcCauseExplicit || GetCurrentIteration()-\u0026gt;GetGcCause() == kGcCauseForNativeAlloc || GetCurrentIteration()-\u0026gt;GetClearSoftReferences()) { force_evacuate_all_ = true; } else { force_evacuate_all_ = false; } BindBitmaps();//详解见下文代码分析  ...... } CheckEmptyMarkStack void ConcurrentCopying::CheckEmptyMarkStack() { Thread* self = Thread::Current(); /*Thread tlsPtr_中有一个名为thread_local_mark_stack的成员变量，其定义如下： AtomicStack\u0026lt;:Object\u0026gt;* thread_local_mark_stack; thread_local_mark_stack是专门配合ConcurrentCopying而使用的，其数据类型就是 AtomicStack（和上文提到的Heap allocation_stack_、mark_stack_一样） tlsPtr_ thread_local_mark_stack的具体用法我们后文碰到时再介绍。 MarkStackMode是枚举变量，其中定义了4个枚举值（它们的含义们下文碰到时再介绍）： enum MarkStackMode { kMarkStackModeOff = 0, kMarkStackModeThreadLocal, kMarkStackModeShared, kMarkStackModeGcExclusive }; mark_stack_mode_是ConcurrentCopying成员变量，初始值为kMarkStackModeOff。 GC过程中将修改它。*/ MarkStackMode mark_stack_mode = mark_stack_mode_.LoadRelaxed(); //mark_stack_mode取值为kMarkStackModeThreadLocal的处理逻辑  if (mark_stack_mode == kMarkStackModeThreadLocal) { /*RevokeThreadLocalMarkStack将要求各个Java Thread执行一个CheckPoint任务， 该任务有三个关键处理，笔者列举如下： (1) 获取线程对象的tlsPtr_ thread_local_mark_stack对象（通过Thread GetThreadLocalMarkStack）。该对象初值为空，ConcurrentCopying GC过程中 会设置它（详情见后文分析）。 (2) 如果线程的thread_local_mark_stack不为空，则将它保存到ConcurrentCopying revoked_mark_stacks_（类型为vector\u0026lt;ObjectStack*\u0026gt;）成员变量中。 (3) 调用Thread SetThreadLocalMarkStack，将thread_local_mark_stack设置为空。 RevokeThreadLocalMarkStacks的调用结果就是将线程对象中不为空的 thread_local_mark_stack放到revoked_mark_stacks_数组中。 */ RevokeThreadLocalMarkStacks(false); MutexLock mu(Thread::Current(), mark_stack_lock_); //如果revoked_mark_stacks_不为空，则需要逐个清除其中所包含的Object对象  if (!revoked_mark_stacks_.empty()) { for (accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;* mark_stack : revoked_mark_stacks_) { while (!mark_stack-\u0026gt;IsEmpty()) { mirror::Object* obj = mark_stack-\u0026gt;PopBack(); ......//打印信息  } } } } else {//如果mark_stack_mode取值为其他值  MutexLock mu(Thread::Current(), mark_stack_lock_); //gc_mark_stack_指向一个ObjectStack对象  CHECK(gc_mark_stack_-\u0026gt;IsEmpty()); CHECK(revoked_mark_stacks_.empty()); } } BindBitmaps void ConcurrentCopying::BindBitmaps() { Thread* self = Thread::Current(); WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); for (const auto\u0026amp; space : heap_-\u0026gt;GetContinuousSpaces()) { //ConcurrentCopying只支持kGcTypePartial，所以ImageSpace、ZygoteSpace  //同样会被加到immune_spaces_中  if (space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyNeverCollect || space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyFullCollect) { CHECK(space-\u0026gt;IsZygoteSpace() || space-\u0026gt;IsImageSpace()); immune_spaces_.AddSpace(space); /*cc_heap_bitmap_类型为HeapBitmap，cc_bitamps_类型为 vector\u0026lt; SpaceBitmap\u0026lt;kObjectAlignment\u0026gt;*\u0026gt;。这两个成员变量由 ConcurrentCopying内部使用。*/ const char* bitmap_name = space-\u0026gt;IsImageSpace() ? \u0026#34;cc image space bitmap\u0026#34; : \u0026#34;cc zygote space bitmap\u0026#34;; accounting::ContinuousSpaceBitmap* bitmap = accounting::ContinuousSpaceBitmap::Create(bitmap_name,space-\u0026gt;Begin(), space-\u0026gt;Capacity()); cc_heap_bitmap_-\u0026gt;AddContinuousSpaceBitmap(bitmap); cc_bitmaps_.push_back(bitmap); } else if (space == region_space_) { accounting::ContinuousSpaceBitmap* bitmap = accounting::ContinuousSpaceBitmap::Create( \u0026#34;cc region space bitmap\u0026#34;, space-\u0026gt;Begin(), space-\u0026gt;Capacity()); cc_heap_bitmap_-\u0026gt;AddContinuousSpaceBitmap(bitmap); cc_bitmaps_.push_back(bitmap); region_space_bitmap_ = bitmap; } } } FlipThreadRoots void ConcurrentCopying::FlipThreadRoots() { ...... Thread* self = Thread::Current(); Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); gc_barrier_-\u0026gt;Init(self, 0); ThreadFlipVisitor thread_flip_visitor(this, heap_-\u0026gt;use_tlab_); FlipCallback flip_callback(this); heap_-\u0026gt;ThreadFlipBegin(self); /*Runtime FlipThreadRoots将先暂停线程对象，然后设置它们的flip_function， 接着再恢复它们的运行。FlipThreadRoots前两个参数分别是两个闭包对象，其中： (1) GC线程（也就是当前调用FlipThreadRoots的线程）先执行flip_callback。 (2) 其他所有Java线程对象再执行thread_flip_visitor。 根据ThreadList的注释，FlipThreadRoots只由ConcurrentCopying使用。 */ size_t barrier_count = Runtime::Current()-\u0026gt;FlipThreadRoots(\u0026amp;thread_flip_visitor, \u0026amp;flip_callback, this); heap_-\u0026gt;ThreadFlipEnd(self); ...... is_asserting_to_space_invariant_ = true; ...... } FlipCallback class FlipCallback : public Closure { public: ...... virtual void Run(Thread* thread) OVERRIDE { ConcurrentCopying* cc = concurrent_copying_; ...... Thread* self = Thread::Current(); ...... /*调用RegionSpace的SetFromSpace。rb_table_为ReadBarrierTable，来自Heap的成员 变量rb_table_。ReadBarrieTable的启用需要设置前台回收器类型为 kCollectorTypeCC，并且定义编译宏kUseTableLookupReadBarrier。*/ cc-\u0026gt;region_space_-\u0026gt;SetFromSpace(cc-\u0026gt;rb_table_,cc-\u0026gt;force_evacuate_all_); //内部调用HeapSwapStacks。交换Heap allocation_stack_和live_stack_  cc-\u0026gt;SwapStacks(); ...... cc-\u0026gt;is_marking_ = true; //设置mark_stack_mode_的值为kMarkStackModeThreadLocal  cc-\u0026gt;mark_stack_mode_.StoreRelaxed(ConcurrentCopying::kMarkStackModeThreadLocal); ....... } ...... }; region_space.cc\nRegionSpace::SetFromSpace void RegionSpace::SetFromSpace(accounting::ReadBarrierTable* rb_table, bool force_evacuate_all) { /*回顾13.3.2节的内容可知，RegionSpace把内存资源划分成数个块，每一个块由一个Region对象 描述。num_regions_是Region的个数，而region_数组保存了各个内存块对应的Region信息。*/ ...... for (size_t i = 0; i \u0026lt;num_regions_; ++i) { Region* r = \u0026amp;regions_[i]; /*RegionState枚举变量描述了一个Region的状态，我们重点看前两个枚举值的含义： (1) kRegionStateFree：表示Region为空闲待使用状态 (2) kRegionStateAllocated：表示Region已经有一部分内存被分配了。 RegionType枚举变量描述了一个Region的类型，它有如下五种取值： (1) kRegionTypeAll：代码中没有明确使用它的地方，读者可不考虑 (2) kRegionTypeFromSpace：Region位于From Space中，需要被清除（evacuate） (3) kRegionTypeUnevacFromSpace：该Region位于From Space，但是不需要被清除 (4) kRegionTypeToSpace：Region位于To Space中。 (5) kRegionTypeNone：Region的默认类型。 如果一个Region首先被使用，其类型将从kRegionTypeNone转换为 kRegionTypeToSpace。相关代码见Region Unfree函数。 */ RegionState state = r-\u0026gt;State(); RegionType type = r-\u0026gt;Type(); if (!r-\u0026gt;IsFree()) {//IsFree返回false，说明该Region已经被使用  if (LIKELY(num_expected_large_tails == 0U)) { /*ShouldBeEvacuated用于判断一个Region是否需要被清除。Region中有两个成员变量 与之相关： (1) is_newly_allocated_：bool型。一个Region从kRegionStateFree到kRegion- StateAllocated时，该成员变量被设置为true（通过调用Region SetNewlyAllocated 函数来完成）。如果is_newly_allocated_为true，ShouldBeEvacuated返回也为true。 (2) live_bytes_：非垃圾对象所占内存的字节数。如果它和该Region中所分配的总内存字节数 之比小于75%（kEvaculateLivePercentThreshold），则ShouldBeEvacuated也返 回true。*/ bool should_evacuate = force_evacuate_all || r-\u0026gt;ShouldBeEvacuated(); if (should_evacuate) { r-\u0026gt;SetAsFromSpace();//设置Region的类型为kRegionTypeFromSpace  } else { //设置Region的类型为kRegionTypeUnevacFromSpace  r-\u0026gt;SetAsUnevacFromSpace(); } ........ }....... } else { ...... } } current_region_ = \u0026amp;full_region_; evac_region_ = \u0026amp;full_region_; } ThreadFlipVisitor class ThreadFlipVisitor : public Closure { public: ...... virtual void Run(Thread* thread) OVERRIDE { Thread* self = Thread::Current(); //设置线程对象tls32_is_gc_marking为true  thread-\u0026gt;SetIsGcMarking(true); if (use_tlab_ \u0026amp;\u0026amp; thread-\u0026gt;HasTlab()) { if (ConcurrentCopying::kEnableFromSpaceAccountingCheck) { ...... } else { //撤销RegionSpace为线程thread分配的TLAB  concurrent_copying_-\u0026gt;region_space_-\u0026gt;RevokeThreadLocalBuffers(thread); } } if (kUseThreadLocalAllocationStack) { //撤销线程本地Allocation Stack  thread-\u0026gt;RevokeThreadLocalAllocationStack(); } ReaderMutexLock mu(self, *Locks::heap_bitmap_lock_); //访问线程根对象。ConcurrentCopying的VisitRoots函数将被调用，其内部调用  //MarkRoot。我们下文将重点分析MarkRoot函数  thread-\u0026gt;VisitRoots(concurrent_copying_); concurrent_copying_-\u0026gt;GetBarrier().Pass(self); } ...... }; // Process some roots. inline void ConcurrentCopying::VisitRoots( mirror::Object*** roots, size_t count, const RootInfo\u0026amp; info ATTRIBUTE_UNUSED) { for (size_t i = 0; i \u0026lt; count; ++i) { mirror::Object** root = roots[i]; mirror::Object* ref = *root; mirror::Object* to_ref = Mark(ref); ...... } } inline void ConcurrentCopying::VisitRoots( mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;** roots, size_t count, const RootInfo\u0026amp; info ATTRIBUTE_UNUSED) { for (size_t i = 0; i \u0026lt; count; ++i) { mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* const root = roots[i]; if (!root-\u0026gt;IsNull()) { // kGrayImmuneObject is true because this is used for the thread flip.  MarkRoot\u0026lt;/*kGrayImmuneObject*/true\u0026gt;(root); } } } inline void ConcurrentCopying::MarkRoot(CompressedReference\u0026lt;Object\u0026gt;* root) { //ref是当前正在被访问的某个线程根对象  mirror::Object* const ref = root-\u0026gt;AsMirrorPtr(); /*调用ConcurrentCopying Mark，返回一个to_ref对象。to_ref的内容和ref一样， 但它可能位于其他空间中（这就是拷贝的含义，详情见下文对Mark的分析）。 如果to_ref和ref不相同，则需要修改存储ref的内存，使得它指向新的to_ref。 具体的修改方式是先将root转换为一个Atomic\u0026lt;CompressedReference\u0026lt;Object\u0026gt;\u0026gt;*对象， 然后进行原子操作。总之，在Mark函数后，原线程根对象可能被更新为位于另外一个空间中的对象。*/ mirror::Object* to_ref = Mark(ref); if (to_ref != ref) { auto* addr = reinterpret_cast\u0026lt;Atomic\u0026lt;CompressedReference\u0026lt;Object\u0026gt;\u0026gt;*\u0026gt; (root); auto expected_ref = CompressedReference\u0026lt;Object\u0026gt;::FromMirrorPtr(ref); auto new_ref = CompressedReference\u0026lt;Object\u0026gt;::FromMirrorPtr(to_ref); do { if (ref != addr-\u0026gt;LoadRelaxed().AsMirrorPtr()) { break; } } while (!addr-\u0026gt;CompareExchangeWeakRelaxed(expected_ref, new_ref)); } } ConcurrentCopying::Mark inline mirror::Object* ConcurrentCopying::Mark(mirror::Object* from_ref) { ...... //获取from_ref所在的Region的类型。注意，如果from_ref不是region_space_的对象，  //则GetRegionType返回kRegionTypeNone  space::RegionSpace::RegionType rtype = region_space_-\u0026gt;GetRegionType(from_ref); switch (rtype) { case space::RegionSpace::RegionType::kRegionTypeToSpace: //如果from_ref已经在To Space中，则直接返回它。不需要后续的拷贝  return from_ref; case space::RegionSpace::RegionType::kRegionTypeFromSpace: { /*如果from_ref位于From Space中（由Region ShouldEvacuate函数决定），则调用 GetFwdPtr找到from_ref的拷贝对象。下文将介绍GetFwdPtr函数。main*/ mirror::Object* to_ref = GetFwdPtr(from_ref); ...... if (to_ref == nullptr) { //如果from_ref不存在对应的拷贝对象，则调用Copy生成一个拷贝对象  to_ref = Copy(from_ref); } return to_ref; } case space::RegionSpace::RegionType::kRegionTypeUnevacFromSpace: { mirror::Object* to_ref = from_ref; //如果from_ref位于from space中不需要清理的Region的话，则对该对象进行标记  if (region_space_bitmap_-\u0026gt;AtomicTestAndSet(from_ref)) { } else { //如果from_ref是初次标记，则调用PushOntoMarkStack，下文将介绍该函数,main  PushOntoMarkStack(to_ref); } return to_ref; } case space::RegionSpace::RegionType::kRegionTypeNone: /*如果Region类型为kRegionTypeNone，说明from_ref不是region_space_中的 对象（有可能是ImageSpace或ZygoteSpace中的对象），则调用MarkNonMoving 函数。这种情况下无须拷贝from_ref。但它的引用型成员变量所指向的对象可能被拷贝 了，我们需要做对应的处理。读者不妨自行阅读MarkNonMoving函数。 */ return MarkNonMoving(from_ref); default: UNREACHABLE(); } } inline mirror::Object* ConcurrentCopying::GetFwdPtr( mirror::Object* from_ref) { //先拿到from_ref monitor_对应的LockWord对象  LockWord lw = from_ref-\u0026gt;GetLockWord(false); /*如果lw的状态为kForwardingAddress，说明lw包含了一个mirror Object对象的地址 信息。对Copying Collection而言，这个地址就是from_ref对应的拷贝对象的地址， GC理论称之为Forwarding Address。*/ if (lw.GetState() == LockWord::kForwardingAddress) { Object* fwd_ptr = reinterpret_cast\u0026lt;Object*\u0026gt;(lw.ForwardingAddress()); return fwd_ptr; //fwd_ptr就是from_ref的拷贝对象  } else { return nullptr; } } ConcurrentCopying::Copy //Copy函数拷贝from_ref对象的信息到一个新的对象to_ref中，然后将to_ref的地址存储到from_ref monitor_成员变量中。在GC理论中，这个地址叫Forwading Address。 mirror::Object* ConcurrentCopying::Copy(mirror::Object* from_ref) { //获取from_ref对象的内存大小  size_t obj_size = from_ref-\u0026gt;SizeOf\u0026lt;...\u0026gt;(); //按Region的要求进行对齐  size_t region_space_alloc_size = RoundUp(obj_size, space::RegionSpace::kAlignment); ...... //从region_space_中分配一块内存用来存储from_ref的内容。这块内存的起始地址为  //to_ref  mirror::Object* to_ref = region_space_-\u0026gt;AllocNonvirtual\u0026lt;true\u0026gt;(....); ......//region_space_分配失败的处理，这部分逻辑比较复杂，读者可先不关注它  while (true) { //拷贝：将from_ref的信息拷贝到to_ref  memcpy(to_ref, from_ref, obj_size); /*下面这段代码比较复杂，但功能很简单，设置from_ref的monitor_，就是把to_ref的地址 值设置到from_ref monitor_中。*/ LockWord old_lock_word = to_ref-\u0026gt;GetLockWord(false); ...... //构造新的LockWord对象  LockWord new_lock_word = LockWord::FromForwardingAddress( reinterpret_cast\u0026lt;size_t\u0026gt;(to_ref)); //原子操作，设置到from_ref里去。所以这段逻辑会比较复杂  bool success = from_ref-\u0026gt;CasLockWordWeakSequentiallyConsistent( old_lock_word, new_lock_word); if (LIKELY(success)) { ...... PushOntoMarkStack(to_ref);//保存to_ref  return to_ref; } ..... } } ConcurrentCopying::PushOntoMarkStac void ConcurrentCopying::PushOntoMarkStack(mirror::Object* to_ref) { Thread* self = Thread::Current(); MarkStackMode mark_stack_mode = mark_stack_mode_.LoadRelaxed(); //在FlipCallback中，mark_stack_mode_已经设置为kMarkStackModeThreadLocal了  if (LIKELY(mark_stack_mode == kMarkStackModeThreadLocal)) { if (LIKELY(self == thread_running_gc_)) { ...... //根据上文的介绍可知，PushOntoMarkStack可能由不同的Java线程调用。如果  //调用者是GC线程自己，则把to_ref加到ConcurrentCopying gc_mark_stack_中  gc_mark_stack_-\u0026gt;PushBack(to_ref); } else { /*如果是非GC线程调用PushOntoMarkStack，则需要使用线程对象tlsPtr_ thread_local_mark_stack。注意，如果线程对象还没有这个容器或者它已经存满的话，下 面的代码将从ConcurrentCopying pooled_mark_stacks_容器中取一个空闲的容器给线程。 pooled_mark_stacks_是一个数组，保存了256个ObjectStack对象，每一个ObjectStack只 能保存最多4096个Object指针。*/ accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;* tl_mark_stack = self-\u0026gt;GetThreadLocalMarkStack(); //tl_mark_stack不存在或者tl_mark_stack已满的情况  if (UNLIKELY(tl_mark_stack == nullptr || tl_mark_stack-\u0026gt;IsFull())) { MutexLock mu(self, mark_stack_lock_); accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;* new_tl_mark_stack; if (!pooled_mark_stacks_.empty()) { new_tl_mark_stack = pooled_mark_stacks_.back(); pooled_mark_stacks_.pop_back(); } else { //如果pooled_mark_stacks_被用完，则新建一个ObjectStack  new_tl_mark_stack = accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;::Create( \u0026#34;thread local mark stack\u0026#34;, 4 * KB, 4 * KB); } new_tl_mark_stack-\u0026gt;PushBack(to_ref); self-\u0026gt;SetThreadLocalMarkStack(new_tl_mark_stack); if (tl_mark_stack != nullptr) { revoked_mark_stacks_.push_back(tl_mark_stack); } } else { tl_mark_stack-\u0026gt;PushBack(to_ref); } } } /*mark_stack_mode取值为非kMarkStackModeThreadLocal的处理，也是将对象 存储到ConcurrentCopying gc_mark_stack_中。*/ ...... } MarkingPhase void ConcurrentCopying::MarkingPhase() { /*MarkingPhase调用前，我们只对线程根对象进行了Mark（注意，此处使用Mark这个词一方 面代表它是ConcurrentCopying中的一个函数。另一方面，根据上文相关函数的代码分析可 知，ConcurrentCopying中的Mark除了做标记之外，还会根据需要生成拷贝对象）。*/ ...... { ...... /*扫描ImageSpace中的根对象。这里我们要多说几句。在MarkSweep中，对ImageSpace的扫描是 基于Write Barrier以及CardTable的。但Write Barrier这种技术却不能用于会移动对象的垃圾 回收算法。比如Copying collection。原因很简单，因为对象被移动后，它在card table中对 应card的位置也会发生变化。所以，对Copying Collection来说，Read Barrier就派上了用 场。Read Barrier有好几种比较经典的实现。ART中有三种，如TableLookup RB、Baker RB以 及Brooks RB。 笔者简单介绍下RB的大致作用：当mutator读取一个对象A的引用型成员变量a时，如果a所指向的对 象B携有forwarding address（B的拷贝对象B\u0026#39;），则转去读取B\u0026#39;。因为B有了拷贝对象B\u0026#39;，我们 自然希望凡是读取B的地方都改成读取B\u0026#39;。*/ for (space::ContinuousSpace* space : heap_-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;IsImageSpace()) { gc::space::ImageSpace* image = space-\u0026gt;AsImageSpace(); if (image != nullptr) { mirror::ObjectArray\u0026lt;mirror::Object\u0026gt;* image_root = image-\u0026gt;GetImageHeader().GetImageRoots(); //ImageSpace中的根对象不会被拷贝，所以marked_image_root等于image_root，  //这段代码有些类似校验的作用  mirror::Object* marked_image_root = Mark(image_root); ......//一些校验相关的工作  } } } } {//访问其他类型的根对象  ...... Runtime::Current()-\u0026gt;VisitConcurrentRoots(this, kVisitRootFlagAllRoots); } {//访问其他类型的根对象  ...... Runtime::Current()-\u0026gt;VisitNonThreadRoots(this); } //访问immune_spaces_中的空间  for (auto\u0026amp; space : immune_spaces_.GetSpaces()) { accounting::ContinuousSpaceBitmap* live_bitmap = space-\u0026gt;GetLiveBitmap(); /*ConcurrentCopyingImmuneSpaceObjVisitor内部将在cc_heap_bitmap_中对扫描到 的对象进行标记，同时调用PushOntoMarkStack*/ ConcurrentCopyingImmuneSpaceObjVisitor visitor(this); live_bitmap-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;Limit()), visitor); } /*到此，所有根对象（包括immune_space_中的对象）都进行了标记。并且，根对象如果发生了 拷贝，则原始根对象将被替换为新的拷贝对象。接下来的工作就比较简单了，我们要遍历这些根 对象，将它们所引用的对象进行Mark（标记、拷贝）。同时，我们还要更新引用值。*/ Thread* self = Thread::Current(); {/*下面这段代码中包含三次ProcessMarkStack，这和ConcurrentCopying中的mark_stack_ mode_有关，它有四种取值。此次调用ProcessMarkStack时，mark_stack_mode_取值为 kMarkStackModeThreadLocal。*/ ProcessMarkStack(); //切换mark_stack_mode_为kMarkStackModeShared  SwitchToSharedMarkStackMode(); ProcessMarkStack(); //切换mark_stack_mode_为kMarkStackModeGcExclusive  SwitchToGcExclusiveMarkStackMode(); //对Java Reference对象的处理，各种回收器的处理都一样。我们后续统一介绍  ProcessReferences(self); ...... ProcessMarkStack(); ......; Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;CleanupClassLoaders(); DisableMarking(); ...... } ...... } //ProcessMarkStack内部将遍历通过PushOntoMarkStack保存下来的对象（这些对象都是拷贝后得到的对象，代码中用to_ref来表示）。其中最关键函数的是Scan。 inline void ConcurrentCopying::Scan(mirror::Object* to_ref) { //Scan很简单，就是遍历to_ref的引用型成员变量，内部调用ConcurrentCopying的Process函数进行处理。 */  ConcurrentCopyingRefFieldsVisitor visitor(this); to_ref-\u0026gt;VisitReferences\u0026lt;...\u0026gt;(visitor, visitor); } inline void ConcurrentCopying::Process(mirror::Object* obj, MemberOffset offset) { //obj是上面Scan中的to_ref，而offset是obj的某个引用型成员变量（由下面的ref表示）  mirror::Object* ref = obj-\u0026gt;GetFieldObject\u0026lt;....\u0026gt;(offset); //对ref进行Mark，得到ref的to_ref，如果两个一样，则不需要更新obj offset的内容  mirror::Object* to_ref = Mark(ref); if (to_ref == ref) { return; } /*到此，更新obj offset的内容，使得它指向to_ref。由于使用的是原子操作，所以下面的 代码逻辑中会使用循环。*/ mirror::Object* expected_ref = ref; mirror::Object* new_ref = to_ref; do { if (expected_ref != obj-\u0026gt;GetFieldObject\u0026lt;......\u0026gt;(offset)) { break; } } while (!obj-\u0026gt;CasFieldWeakRelaxedObjectWithoutWriteBarrier\u0026lt;...\u0026gt;( offset, expected_ref, new_ref)); } ReclaimPhase void ConcurrentCopying::ReclaimPhase() { ...... { ..... ComputeUnevacFromSpaceLiveRatio();//详情见下文代码分析  } { ..... region_space_-\u0026gt;ClearFromSpace();//详情见下文代码分析  } { WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); ...... /*清空除immune_spaces_、region_space_外的空间中其他的垃圾对象。代码逻辑和 MarkSweep Sweep的类似。内部调用ContinuousMemMapAllocSpace的Sweep函数进 行处理。*/ Sweep(false); //调用GarbageCollector的SwapBitmaps函数，和MarkSweep的处理一样  SwapBitmaps(); heap_-\u0026gt;UnBindBitmaps(); ...... } void ConcurrentCopying::ComputeUnevacFromSpaceLiveRatio() { ...... //对RegionSpace中的标记对象进行统计  ConcurrentCopyingComputeUnevacFromSpaceLiveRatioVisitor visitor(this); region_space_bitmap_-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(region_space_-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(region_space_-\u0026gt;Limit()), visitor); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/gc_markcompact/",
	"title": "GC_MarkCompact",
	"tags": [],
	"description": "",
	"content": "mark_compact.h/cc virtual GcType GetGcType() const OVERRIDE { return kGcTypePartial;//MarkCompact不处理ImageSpace和ZygoteSpace } virtual CollectorType GetCollectorType() const OVERRIDE { return kCollectorTypeMC; } void MarkCompact::SetSpace(space::BumpPointerSpace* space) { space_ = space;//space_是MarkCompact成员变量 } RunPhases void MarkCompact::RunPhases() { Thread* self = Thread::Current(); /* InitializePhase非常简单，其中需要注意的是MarkCompact下面两个成员变量的设置： (1) mark_stack_ = heap_-\u0026gt;GetMarkStack(); (2) mark_bitmap_ = heap_-\u0026gt;GetMarkBitmap(); */ InitializePhase(); { ScopedPause pause(this);//MarkCompact是stop-the-world类型的回收器  ...... MarkingPhase();//①标记阶段，详情见下文分析  ReclaimPhase();//②回收阶段，详情见下文分析  } ...... FinishPhase();//收尾工作，非常简单，读者可自行阅读 } MarkingPhase void MarkCompact::MarkingPhase() { Thread* self = Thread::Current(); /*MarkCompact基于Mark-Compact回收原理，所以它也需要标记能搜索到的对象。不过，由于 BumpPointerSpace空间对象不包含位图对象，所以下面将为space_（指向一个 BumpPointerSpace空间）创建一个位图对象objects_before_forwarding。它用于记录 搜索到的对象。*/ objects_before_forwarding_.reset(accounting::ContinuousSpaceBitmap::Create( \u0026#34;objects before forwarding\u0026#34;, space_-\u0026gt;Begin(), space_-\u0026gt;Size())); //此外还创建了一个位图对象objects_with_lockword_，它和GC没有什么关系，只是用于  //保存一些信息。下文将见到objects_with_lockword_的作用  objects_with_lockword_.reset(accounting::ContinuousSpaceBitmap::Create( \u0026#34;objects with lock words\u0026#34;, space_-\u0026gt;Begin(), space_-\u0026gt;Size())); //将ImageSpace或ZygoteSpace加到MarkCompact immune_space_容器中  BindBitmaps(); /*ProcessCards和ClearCardTable用于处理CardTable中对应的card。此处请读者注意， 虽然MarkCompact也是通过移动对象来实现内存回收，但MarkCompact移动对象的过程是在 最后的回收阶段。此时，所有的非垃圾对象都已经标记。所以，MarkCompact中可以使用Write Barrier来记录跨空间的对象引用。作为对比，ConcurrentCopying在标记阶段可能就会移动 对象，这时就不方便使用Write Barrier了，而只能使用Read Barrier。 */ heap_-\u0026gt;ProcessCards(GetTimings(), false, false, true); heap_-\u0026gt;GetCardTable()-\u0026gt;ClearCardTable(); //下面几个函数我们都介绍过  if (kUseThreadLocalAllocationStack) { ...... heap_-\u0026gt;RevokeAllThreadLocalAllocationStacks(self); } ...... heap_-\u0026gt;SwapStacks(); { WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); MarkRoots();//搜索并标记根对象，详情见下文  //借助CardTable来处理ImageSpace或ZygoteSpace中存在跨空间引用的对象，每找到  //这样一个对象就对其做标记并压入mark_stack_中。读者可先了解上面的MarkRoots函数  UpdateAndMarkModUnion(); MarkReachableObjects();//从根对象出发，扫描它们所引用的对象  } ......//Java Reference对象的处理等 } ReclaimPhase void MarkCompact::ReclaimPhase() { ...... WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); /*Sweep将回收除space_、immune_spaces_外其他空间对象中的垃圾。内部代码逻辑非常简单， 就是调用ContinuousMemMapAllocSpace的Sweep函数进行回收。这些空间的垃圾回收使用 的是Mark-Sweep方法，不是Mark-Compact。*/ Sweep(false); //调用GarbageCollector SwapBitmaps函数，该函数在MarkSweep类中已经介绍过了  SwapBitmaps(); GetHeap()-\u0026gt;UnBindBitmaps();//该函数在MarkSweep中已经介绍过了  //压缩，这才是MarkCompact的精髓  Compact(); } Compact void MarkCompact::Compact() { ..... /*Compact中有三个关键函数，此处先简单介绍它们的作用： 1: CalculateObjectForwardingAddresses：计算每个存活对象的forwarding address。 这个地址也就是这些对象的新的内存地址。 2: UpdateReferences：更新对象的引用关系，将所引用的对象修改为对应的forwarding address。这个函数没有什么特殊的知识，读者可自行阅读。 3: MoveObjects：将对象移动到它的forwarding address处。 */ CalculateObjectForwardingAddresses(); UpdateReferences(); MoveObjects(); ...... /*更新space_的末尾位置。经过上面压缩处理后，space_中的垃圾对象被清除，而非垃圾对象们 又被移动到了一起。这些非垃圾对象在space_中的末尾位置由bump_pointer_标示。 */ space_-\u0026gt;SetEnd(bump_pointer_); //清零[bump_Pointer_,bump_pointer_+bytes_freed)这段空间。这段空间就是垃圾对象所  //占据的内存大小  memset(bump_pointer_, 0, bytes_freed); } CalculateObjectForwardingAddresses //CalculateObjectForwardingAddress展示了MarkCompact中Compact的方法，就是将非垃圾对象一个一个排列起来。显然，要支持这种操作的话非BumpPointerSpace不可。 void MarkCompact::CalculateObjectForwardingAddresses() { ...... //bump_pointer_初值为space_的起始位置  bump_pointer_ = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(space_-\u0026gt;Begin()); /*objects_before_forwarding_记录了space_中非垃圾对象的位图信息。下面的代码 将遍历space_中的非垃圾对象，然后调用函数对象进行处理。 CalculateObjectForwardingAddressVisitor内部调用MarkCompact ForwardObject 对每一个非垃圾对象进行处理。我们直接来看ForwardObject。*/ CalculateObjectForwardingAddressVisitor visitor(this); objects_before_forwarding_-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;End()), visitor); } void MarkCompact::ForwardObject(mirror::Object* obj) { //获取这个对象的所占内存的大小  const size_t alloc_size = RoundUp(obj-\u0026gt;SizeOf(), space::BumpPointerSpace::kAlignment); LockWord lock_word = obj-\u0026gt;GetLockWord(false); /*如果这个obj之前有设置LockWord（可能代表一个用于线程同步的Monitor），下面的if代码将 把LockWord旧值保存起来。等后续对象移动完毕后，我们需要恢复Obj的LockWord的旧值。 */ if (!LockWord::IsDefault(lock_word)) { //objects_with_lockword_记录哪个对象存在LockWord的旧值  objects_with_lockword_-\u0026gt;Set(obj); //lock_words_to_restore_是一个stddqueue（双端队列），用于保存obj的  //LockWord旧值  lock_words_to_restore_.push_back(lock_word); } //设置obj的forwarding address，为bump_pointer_  obj-\u0026gt;SetLockWord(LockWord::FromForwardingAddress(reinterpret_cast\u0026lt;size_t\u0026gt;(bump_pointer_)),false); //移动bump_poionter_，使得它指向下一个对象的forwarding address  bump_pointer_ += alloc_size; ++live_objects_in_space_; } UpdateReferences \u0026hellip;\u0026hellip;\nMoveObjects void MarkCompact::MoveObjects() { ...... /*遍历存活对象，MoveObjectVisitor内部调用MoveObject函数进行处理，下面将直接介绍 MoveObject的内容。*/ MoveObjectVisitor visitor(this);//内部调用MoveObject  objects_before_forwarding_-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;End()), visitor); ...... } void MarkCompact::MoveObject(mirror::Object* obj, size_t len) { //从LockWord中获取obj的目标地址  uintptr_t dest_addr = obj-\u0026gt;GetLockWord(false).ForwardingAddress(); mirror::Object* dest_obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(dest_addr); //使用memmove将obj移动到dest_addr处。  memmove(reinterpret_cast\u0026lt;void*\u0026gt;(dest_addr), reinterpret_cast\u0026lt;const void*\u0026gt;(obj), len); LockWord lock_word = LockWord::Default(); //如果obj之前有LockWord旧值，则需要从lock_words_to_restore_中拿到旧值  if (UNLIKELY(objects_with_lockword_-\u0026gt;Test(obj))) { lock_word = lock_words_to_restore_.front(); lock_words_to_restore_.pop_front(); } //设置dest_obj的LockWord。  dest_obj-\u0026gt;SetLockWord(lock_word, false); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/gc_ms_cms/",
	"title": "GC_MS_CMS",
	"tags": [],
	"description": "",
	"content": "MarkSweep类家族 表14-1　MarkSweep类家族GetGcType取值情况\n集合Live和集合Mark构成 CMS时Heap space相关成员变量取值情况 CMS时Heap位图相关成员变量取值情况 图14-7　CMS时Heap位图相关成员变量取值情况\n一个HeapBitmap对象可以管理多个ContinuousSpace的某一种位图对象\nCMS时Heap mark_stack_等成员变量的情况 MarkSweep::MarkSweep MarkSweep::MarkSweep(Heap* heap, bool is_concurrent, const std::string\u0026amp; name_prefix) : GarbageCollector(heap, name_prefix + (is_concurrent ? \u0026#34;concurrent mark sweep\u0026#34;: \u0026#34;mark sweep\u0026#34;)), current_space_bitmap_(nullptr), mark_bitmap_(nullptr), mark_stack_(nullptr), ..... is_concurrent_(is_concurrent),...... { /*MarkSweep构造函数并不复杂，此处先介绍下它的几个成员变量（其作用留待后续代码分析时时再详细讲解）： current_space_bitmap_：类型为ContinuousSpaceBitmap*。 mark_bitmap_：类型为HeapBitmap*。 mark_stack_：类型为ObjectStack*。 */ ..... /*下面的代码行将创建一个内存映射对象。ART内部大量使用内存映射对象。下面的 sweep_array_free_buffer_mem_map_的用法需要到介绍StickyMarkSweep时才能见到。总之，读者将它看作一块内存即可。*/ MemMap* mem_map = MemMap::MapAnonymous(......); sweep_array_free_buffer_mem_map_.reset(mem_map); ..... } MarkSweep::RunPhases graph TB IsConcurrent{IsConcurrent}--\u0026gt;|yes|MarkingPhaseC(MarkingPhase) MarkingPhaseC--\u0026gt;pauseC(pause) pauseC--\u0026gt;PausePhaseC(\u0026quot;PausePhase_reMark\u0026quot;) PausePhaseC--\u0026gt;RevokeAllThreadLocalBuffers RevokeAllThreadLocalBuffers--\u0026gt;ReclaimPhase ReclaimPhase--\u0026gt;FinishPhase IsConcurrent--\u0026gt;|no|pause pause--\u0026gt;MarkingPhase MarkingPhase--\u0026gt;PausePhase PausePhase--\u0026gt;RevokeAllThreadLocalBuffers void MarkSweep::RunPhases() { Thread* self = Thread::Current(); //初始化MarkSweep类的几个成员变量。其中，MarkSweep的mark_bitmap_将设置为Heap的成员变量mark_bitmap_（读者可回顾图14-7）  InitializePhase(); if (IsConcurrent()) {//if条件为true，则是CMS的行为  ...... { /*CMS和MS的区别：下面代码中ReaderMutexLock为辅助类，真正用于同步的关键对象为 mutator_lock_。它是一个全局定义的读写互斥锁。即支持多个线程同时进行读操作。但如果 某个线程要执行写操作的话，必须等待所有执行读操作的线程释放这个锁。同理，执行写操作的 线程如果先抢到这个锁的话，其他想做读操作或写操作的线程都必须要等待当前拥有这个锁的写 线程释放该锁。ReaderMutextLock在构造函数中将针对mutator_lock_申请一个读锁，而在析构函数中释放读锁。*/ ReaderMutexLock mu(self, *Locks::mutator_lock_); MarkingPhase();//①标记工作，详情见下文代码分析,main  } /*ScopedPause也是一个辅助类，其构造函数中会暂停除调用线程外其他所有Java线程的运行，其内部 调用ThreadList的SuspendAll，详情可参考12.2.3节的内容。ScopedPause的析构函数中会恢复这些线程的运行。 简单来说，下面的这段代码运行时，其他Java线程将停止运行。 */ ScopedPause pause(this); .... PausePhase();//②PausePhase的详情见下文代码分析,main  /*撤销线程对象的TLAB空间。此后Thread TLAB空间为0，TLAB的作用在于加速内存分配的速度。 TLAB所需的内存资源来自对应的空间对象，例如BumpPointerSpace、RegionSpace等。请读者 注意，Revoke是撤销的意思，不是Free（释放）。撤销TLAB之后那些创建在TLAB上的对象依然存在。 这些对象中的垃圾对象将在后续清除阶段回收。*/ RevokeAllThreadLocalBuffers(); } else { //如果回收器类型为MS，则先暂停其他Java线程的运行，  ScopedPause pause(this); ..... MarkingPhase(); ...... PausePhase(); RevokeAllThreadLocalBuffers(); } //标记相关的工作结束，开始准备清除工作  { //注意，mutator_lock_被用作读锁。这和上面CMS逻辑中调用MarkingPhase函数的处理  //一样。这说明无论CMS还是MS，清除任务（Reclaim Phase）可以和mutator同时执行  ReaderMutexLock mu(self, *Locks::mutator_lock_); ReclaimPhase();//③回收工作，详情见下文代码分析,main  } ..... FinishPhase();//④GC的收尾，详情见下文代码分析,main } InitializePhase \u0026hellip;\u0026hellip;\nMarkingPhase void MarkSweep::MarkingPhase() { TimingLogger::ScopedTiming t(__FUNCTION__, GetTimings()); Thread* self = Thread::Current(); //①我们单独介绍下面三个函数调用，笔者将它们归为标记前的准备工作  BindBitmaps(); FindDefaultSpaceBitmap(); /*调用Heap ProcessCards函数，该函数的作用见下文解释。此处请注意最后一个参数的取值： (1) MarkSweep GetGcType返回kGcTypeFull，所以最后一个参数取值为false。 (2) PartialMarkSweep GetGcType返回kGcTypePartial，所以最后一个参数取值为false。 (3) StickyMarkSweep GetGcType返回值为kGcTypeSticky，所以最后一个参数取值为 true。 */ heap_-\u0026gt;ProcessCards(GetTimings(), false, true, GetGcType() != kGcTypeSticky); WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); //②标记相关函数，，标记的信息保存在各个空间的mark_bitmap_中  MarkRoots(self);//MarkRoots用于标记根对象  MarkReachableObjects();//从根对象出发以标记所有能追踪到的对象  //③下面这个函数和CMS有关，我们后续统一介绍它  PreCleanCards(); } BeforeMark BindBitmaps void MarkSweep::BindBitmaps() { ...... WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); /*搜索Heap continuous_spaces_数组中的空间对象，如果某个空间对象的gc_retention_policy_ 成员变量取值为kGcRetentionPolicyNeverCollect，则将它加入MarkSweep immune_spaces_ （类型为ImmuneSpace，其内部有一个std set容器）中。回顾13.7.1节的内容可知，只有ImageSpace （结合14.3.3节的图14-6可知，它就是boot.art文件映射到内存后得到的空间对象）满足这个条 件。再次请读者注意，kGcRetentionPolicyNeverCollect表示不用对该空间的对象进行垃圾回收。*/ for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyNeverCollect) { immune_spaces_.AddSpace(space);//AddSpace的代码见下文介绍  } } } immune_spaces.cc\nImmuneSpaces::AddSpace void ImmuneSpaces::AddSpace(space::ContinuousSpace* space) { //ImageSpace重载了GetLiveBitmap和GetMarkBitmap函数，返回的都是  //ImageSpace的live_bitmap_成员。所以，下面的if条件对ImageSpace而言并不满足  if (space-\u0026gt;GetLiveBitmap() != space-\u0026gt;GetMarkBitmap()) { //调用ContinuousMemMapAllocSpace BindLiveToMarkBitmap函数。它的作用我们  //在StickyMarkSweep类中再来介绍。MarkSweep还用不到它  space-\u0026gt;AsContinuousMemMapAllocSpace()-\u0026gt;BindLiveToMarkBitmap(); } //spaces_是ImmuneSpace的成员，为一个std set集合  spaces_.insert(space); //ImmuneSpaces是一个辅助类的数据结构  CreateLargestImmuneRegion(); } FindDefaultSpaceBitmap void MarkSweep::FindDefaultSpaceBitmap() { ...... //遍历Heap continuous_space_数组，读者可回顾图14-6了解CMS情况下Heap continuous_space_数组的取值情况  for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { accounting::ContinuousSpaceBitmap* bitmap = space-\u0026gt;GetMarkBitmap(); /*参考13.7.1节的内容可知，DlMallocSpace和RosAllocSpace 都满足下面的if条件（它们的回收策略为kGcRetentionPolicyAlwaysCollect）。 if条件满足后，将把空间对象中的mark_bitmap_赋值给MarkSweep的成员变量 current_space_bitmap_。*/ if (bitmap != nullptr \u0026amp;\u0026amp; space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyAlwaysCollect) { //current_space_bitmap_为MarkSweep的成员变量，指向一个ContinuousSpaceBitmap对象  current_space_bitmap_ = bitmap; //从下面这个if条件来看，current_space_bitmap_取值来自Heap main_space_的  //mark_bitmap_。读者可回顾14.3.3节中的图14-6  if (space != heap_-\u0026gt;GetNonMovingSpace()) { break; } } } } Heap::ProcessCards void Heap::ProcessCards(..., bool use_rem_sets, bool process_alloc_space_cards, bool clear_alloc_space_cards) { /*注意参数，MarkSweep 调用它时，所传入的参数值为： use_rem_sets为false。 process_alloc_space_cards为true。clear_alloc_space_cards为true。 */ //遍历continuous_spaces_数组  for (const auto\u0026amp; space : continuous_spaces_) { //找到和这个space关联的ModUnionTable或者RememberedSet对象  //无论使用ModUnionTable还是RememberedSet，最终操作的都是Heap card_table_  accounting::ModUnionTable* table = FindModUnionTableFromSpace(space); accounting::RememberedSet* rem_set = FindRememberedSetFromSpace(space); /*在Heap PreZygoteFork被调用前，Heap中space对象的情况见图14-6。在那里， ImageSpace对象关联了一个ModUnionTable对象，其余两个空间对象各关联了 一个RememberedSet对象。 */ if (table != nullptr) { /*调用ModUnionTable的ClearCards函数，其作用我们在13.8.2.4节中曾介绍过。 该函数调用的结果是： 这个ModUnionTable管理的空间对象在Heap CardTable中对应card的值将发生如下变化： (1) 如果card旧值为kCardDirty，则设置其新值为kCardDirty - 1， (2) 否则设置其新值为0。*/ table-\u0026gt;ClearCards(); } else if (use_rem_sets\u0026amp;\u0026amp; rem_set != nullptr) { /*在本例中，use_rem_sets取值为false，if条件不满足。RememberedSet ClearCards 函数的代码见13.8.2.3.1节。其效果和上面ModUnionTableClearCards一样。 */ rem_set-\u0026gt;ClearCards(); } else if (process_alloc_space_cards) {//对本例而言，该参数为true  if (clear_alloc_space_cards) {//满足条件  /*下面将处理card_table_中覆盖space对象的card信息。ClearCardRange函数 将设置对应card的值为0。*/ uint8_t* end = space-\u0026gt;End(); ...... card_table_-\u0026gt;ClearCardRange(space-\u0026gt;Begin(), end); } else { /*如果clear_alloc_space_cards为false，则调用CardTable的 ModifyCardsAtomic函数修改对应内存范围的card的值。其中： (1) 如果card的旧值为kCardDirty，则新值为kCardDirty-1 (2) card的旧值为非kCardDirty时，新值为0。*/ card_table_-\u0026gt;ModifyCardsAtomic(space-\u0026gt;Begin(), space-\u0026gt;End(), AgeCardVisitor(),VoidFunctor()); } } } } Mark MarkRoots void MarkSweep::MarkRoots(Thread* self) { ...... if (Locks::mutator_lock_-\u0026gt;IsExclusiveHeld(self)) { /*如果if条件为true，说明其他Java线程已暂停运行。14.2节中我们已经介绍过Runtime VisitRoots函数了。此处，MarkSweep实现了RootVisitor接口。下面将直接介绍MarkSweep 所实现的RootVisitor VisitRoots接口函数。*/ Runtime::Current()-\u0026gt;VisitRoots(this); /*下面这个函数将遍历所有Thread对象，设置它们的tlsPtr_thread_local_alloc_stack_ end和thread_local_alloc_stack_top为空，即收回线程的Allocation Stack空间。 注意，结合图14-8的内容和13.6.4.3节的相关知识可知，此处只是将线程的Allocation Stack 空间大小设置为0，而存储在Allocation Stack中的信息依然存在（因为Heap allocation_ stack_没有被修改）。*/ RevokeAllThreadLocalAllocationStacks(self); } else { ......//和CMS有关，详见14.4.9节  } } VisitRoots void MarkSweep::VisitRoots(mirror::Object*** roots, size_t count,const RootInfo\u0026amp; info) { for (size_t i = 0; i \u0026lt; count; ++i) { MarkObjectNonNull(*roots[i]); } } void MarkSweep::VisitRoots(CompressedReference\u0026lt;Object\u0026gt;** roots, size_t count,const RootInfo\u0026amp; info) { for (size_t i = 0; i \u0026lt; count; ++i) { MarkObjectNonNull(roots[i]-\u0026gt;AsMirrorPtr()); } } MarkObjectNonNull //对Obj进行标记。标记就是设置该Obj所在空间对象的mark_bimap_位图对应位的值为1。 //这个新被标记的Obj保存到MarkSweep mark_sweep_容器中。 inline void MarkSweep::MarkObjectNonNull(mirror::Object* obj, mirror::Object* holder, MemberOffset offset) { //MarkObjectNonNull最后两个参数有默认值，分别为nullptr和MemberOffset(0)  ...... //如果obj位于immune_spaces_所包含的空间对象中，则无须标记，详情见if中的解释  if (immune_spaces_.IsInImmuneRegion(obj)) { ...... /*注意下面这句调试时才会执行的代码。MarkSweep成员变量mark_bitmap_类型为HeapBitmap， 它其实就是Heap的mark_bitmap_成员。回顾本章的图14-6可知，HeapBitmap包含了所有 连续空间对象的mark_bitmap_成员。不过，对ImageSpace来说，它的live_bitmap_也被 包含在Heap mark_bitmap_中了。 在下面这行代码中，Test函数将测试obj在位图中对应的位是否为1。如果Test返回值为0， DCHECK会打印一条错误信息（如果打开调试的话）。这说明一个Obj如果位于ImageSpace空 间的话，它一定是存活的（同时也是早就被标记了的。因为ImageSpaceGetMarkBitmap返回 的也是live_bitmap_）。但是，请读者注意，尽管位于ImageSpace空间中的对象是长久存 活的，但是这些对象的引用型成员变量所指向的对象却可能位于其他空间，而这些对象就可能 是垃圾。*/ DCHECK(mark_bitmap_-\u0026gt;Test(obj)); } else if (LIKELY(current_space_bitmap_-\u0026gt;HasAddress(obj))) { /*根据“准备工作”一节FindDefaultSpaceBitmap函数可知，current_space_bitmap_ 为某个空间对象的mark_bitmap_。判断一个Obj是否被标记的标准就是该Obj 在mark_bitmap_中对应位的值是否为1。所以，本段代码的主要工作可总结为： (1) HasAddress检查current_space_bitmap_对应的内存空间是否包含了obj对象 (2) 如果满足条件，则调用Set函数设置obj对应位的值为1。于是，这个Obj就算被标记了。 (3) Set函数返回该位的旧值。如果旧值为0，说明这个obj之前没有被标记。调用 PushOnMarkStack将obj加入到MarkSweep mark_stack_容器中。mark_stack_为 一个ObjectStack对象。 */ if (UNLIKELY(!current_space_bitmap_-\u0026gt;Set(obj))) { PushOnMarkStack(obj); } } else { /*说明obj不在current_space_bitmap_所关联的那个空间对象中，此时就需要搜索Heap 所有的空间对象，显然这比直接操作current_space_bitmap_要耗时。从这里可以看出， 使用current_space_bitmap_是一种优化处理。后面我们还会看到类似的这种优化处理。*/ ...... /*mark_bitmap_指向一个HeapBitmap对象，它就是Heap中的mark_bitmap_。根据图 14-8的介绍，HeapBitmap管理了所有空间对象的SpaceBitmap。下面的Set函数将搜索 所有空间对象，找到包含这个Obj的Space对象，然后设置对应位的值。 */ if (!mark_bitmap_-\u0026gt;Set(obj,...)) { PushOnMarkStack(obj); } } } MarkReachableObjects void MarkSweep::MarkReachableObjects() { //处理immune_spaces_空间中的对象，对理解card table的作用非常关键，请读者注意  UpdateAndMarkModUnion(); RecursiveMark();//我们重点介绍这个函数 } UpdateAndMarkModUnion void MarkSweep::UpdateAndMarkModUnion() { for (const auto\u0026amp;space : immune_spaces_.GetSpaces()) { ....... /*space要么是ImageSpace，要么是ZygoteSpace。如果它们关联了一个ModUnionTable 对象，则通过ModUnionTable的UpdateAndMarkReference函数来处理。否则通过它们的 live_bitmap_来处理。其中： UpdateAndMarkReference的参数是一个MarkObjectVisitor类型的函数调用对象，MarkSweep 类实现了它的MarkObject和MarkHeapReference接口函数。 而live_bimap_ VisitMarkedRange函数最后一个参数为函数调用对象。最终，不管下面 代码中的if和else哪个条件满足，MarkSweep的MarkObjectNonNull都将被调用。 */ accounting::ModUnionTable* mod_union_table = heap_-\u0026gt;FindModUnionTableFromSpace(space); if (mod_union_table != nullptr) { mod_union_table-\u0026gt;UpdateAndMarkReferences(this); } else { //如果该空间没有关联ModUnionTable，则只能遍历该空间的所有存活对象了  space-\u0026gt;GetLiveBitmap()-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;End()), ScanObjectVisitor(this)); } } } RecursiveMark void MarkSweep::RecursiveMark() { ...... if (kUseRecursiveMark) {//kUseRecursiveMark为编译常量，默认值为false  ....//这部分代码中有和parallel处理有关的内容，感兴趣的读者可自行阅读  } ProcessMarkStack(false);//此处传递的参数为false } ProcessMarkStack void MarkSweep::ProcessMarkStack(bool paused) { /*ProcessMarkStack就是遍历mark_stack_中的obj对象，追踪它们的引用型参数。 注意，追踪根对象的引用型成员变量是一个非常耗时的工作，所以可以利用多线程来处理，这就是 parallel collection的一个体现。根据下面的if条件判断，是否使用parallel gc需要 满足一定条件，即： (1) kParallelProcessMarkStack：编译常量，默认取值为true. (2) GetThreadCount返回值大于1。 (3) mark_stack_所保存的Obj对象个数大于128（kMinimumParallelMarkStackSize的值） GetThreadCount的代码请读者自行阅读。其中会涉及kProcessStateJankPerceptible枚举 变量。我们在10.3.2.2节中曾介绍过它。当应用处于前台时，它的进程状态会被设置为这个值，表 示如果应用发生卡顿，用户是能感受到的。*/ size_t thread_count = GetThreadCount(paused);//  if (kParallelProcessMarkStack \u0026amp;\u0026amp; thread_count \u0026gt; 1 \u0026amp;\u0026amp; mark_stack_-\u0026gt;Size() \u0026gt;= kMinimumParallelMarkStackSize) { ProcessMarkStackParallel(thread_count);//后文再详细介绍这个函数  } else { /*else代码块为不使用parallel collection的处理。处理方式很简单，就是遍历 mark_stack_中的元素，调用它们的VisitReference函数。每找到一个引用型参数就调用 MarkSweep MarkObject函数进行标记。如果是新标记的对象，就将其加入mark_stack_ 容器中。如此往复直到mark_stack_中的元素都处理完为止。 */ static const size_t kFifoSize = 4; BoundedFifoPowerOfTwo\u0026lt;mirror::Object*, kFifoSize\u0026gt; prefetch_fifo; for (;;) { mirror::Object* obj = nullptr; if (kUseMarkStackPrefetch) {//kUseMarkStackPrefetch默认为true  /*这段代码为一种优化实现，利用了GCC的__builtin_prefetch功能加速获取 mark_stack_中的元素。感兴趣的读者可以自行研究它。*/ ..... } else { //如果不使用优化实现的话，遍历mark_stack_的代码逻辑就非常简单了  if (mark_stack_-\u0026gt;IsEmpty()) { break; } obj = mark_stack_-\u0026gt;PopBack(); } /*ScanObject将调用Object VisitReferences，所设置的函数调用对象最终会通过MarkSweep MarkObject函数来标记所找到的引用型成员变量。我们在13.8.3节中曾介绍过VisitReferences 函数。注意，对Reference类型的对象有一些特殊处理。我们后文将介绍这部分内容。 */ ScanObject(obj); } } } PausePhase void MarkSweep::PausePhase() { Thread* self = Thread::Current(); if (IsConcurrent()) {//①如果是CMS，则需要调用下面两个函数  WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); /*回顾MarkSweep RunPhases可知，在CMS情况下gc线程执行MarkingPhase的时候，mutator 线程可同时运行。也就是说，对CMS而言，MarkingPhase标记的对象可能还不全面，所以在 PausePhase的时候要重新做一次标记。当然，这次标记不会像MarkingPhase那样耗时，否则 CMS就没有什么价值了。 */ ReMarkRoots(); RecursiveMarkDirtyObjects(true, accounting::CardTable::kCardDirty); } { ...... //写锁，使用全局静态变量heap_bitmap_lock_同步对象  WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); /*②调用Heap SwapStack函数，内部将执行下面这条语句： allocation_stack_.swap(live_stack_)。它将live_stack_和allocation_stack_ 的内容进行交换。 */ heap_-\u0026gt;SwapStacks(); live_stack_freeze_size_ = heap_-\u0026gt;GetLiveStack()-\u0026gt;Size(); /*再次清空Thread的Allocation Stack空间。注意，我们在MarkRoots函数中也 调用过这个函数。两次执行它的原因是因为在MarkRoots中清空之后直到代码运行到这里时， 可能有mutator线程又重新分配和使用了Allocation Stack。*/ RevokeAllThreadLocalAllocationStacks(self); } //③下文将简单介绍Runtime DisallowNewSystemWeaks的内容  Runtime::Current()-\u0026gt;DisallowNewSystemWeaks(); //④下面这行代码和Java Reference对象的处理有关，我们后续单独介绍这部分知识  GetHeap()-\u0026gt;GetReferenceProcessor()-\u0026gt;EnableSlowPath(); } RecursiveMarkDirtyObjects void MarkSweep::RecursiveMarkDirtyObjects(bool paused, uint8_t minimum_age) { /*ScanGrayObjects是一个比较复杂的函数，但理解它并不难，笔者仅介绍其功能，感兴趣的 读者可以自行研究它的代码。 在StickyMarkSweep MarkReachableObjects中，mark_stack_被清空。这并不是说 StickyMarkSweep不需要它，而是StickyMarkSweep需要往mark_stack_填充自己的内 容（MarkRoots往mark_stack_填充的对象算MarkSweep的）—该工作由下面的 ScanGrayObjects完成。ScanGrayObjects的功能很简单： (1) 遍历Heap continuous_spaces_中的空间对象。每找到一个mark_bitmap_不为空指针 的空间对象，就转到2去执行。 (2) 调用Heap card_table_的Scan函数。找到那些card值大于或等于minimum_age的card， 然后根据这个card再到空间对象去找到对应的mirror Object对象。注意，这些对象必须 是在空间对象mark_bitmap_所标记过了的。 (3) 每找到这样的一个mirror Object对象就调用MarkSweep的ScanObject以标记它的 引用型成员变量。ScanObject内部会调用MarkSweep MarkObject进行标记处理。 现在我们以某个空间对象A为例来说明和ScanGrayObjects有关的处理逻辑： (1) BindBitmaps中，A的mark_bitmap_的内容替换成了live_bitmap_。这表示 mark_bitmap_保存了上次GC后留存的对象。 (2) A对应的card在Heap ProcessCards中被修改为kCardDirty – 1或者0。 值为kCardDirty – 1的card表示对应的对象的引用型成员变量被修改过。 (3) ScanGrayObject扫描属于A的并且值为kCardDirty -1的card。然后找到这些card 中被标记了的对象（对象是否被标记由于A的mark_bitmap_决定）。 (4) 每找到一个这样的对象就调用MarkObject对它们的引用型成员变量进行标记。 简单来说，ScanGrayObjects就是确定被标记过的对象中有哪些对象的引用型成员变量被 修改过。main*/ ScanGrayObjects(paused, minimum_age); //下面这个函数在14.4.3.2.2节中介绍过该函数  ProcessMarkStack(paused); } runtime.cc\nDisallowNewSystemWeaks void Runtime::DisallowNewSystemWeaks() { //DisallocwNewSystemWeaks涉及ART虚拟机的很多个模块，比如下面的monitor_list_、  //intern_table_、java_vm_等。出于篇幅考虑，本节仅介绍java_vm_的情况  monitor_list_-\u0026gt;DisallowNewMonitors(); intern_table_-\u0026gt;ChangeWeakRootState(gc::kWeakRootStateNoReadsOrWrites); //禁止JNI层创建新的WeakGlobal对象，或者解析一个WeakGlobal对象。我们简单介绍它对创建WeakGlobal型对象的影响  java_vm_-\u0026gt;DisallowNewWeakGlobals(); heap_-\u0026gt;DisallowNewAllocationRecords(); lambda_box_table_-\u0026gt;DisallowNewWeakBoxedLambdas(); } void JavaVMExt::DisallowNewWeakGlobals() { Thread* const self = Thread::Current(); MutexLock mu(self, weak_globals_lock_); //下面这个变量的数据类型为Atomic\u0026lt;bool\u0026gt;，设置其值为false  allow_accessing_weak_globals_.StoreSequentiallyConsistent(false); } ReclaimPhase void MarkSweep::ReclaimPhase() { Thread* const self = Thread::Current(); ProcessReferences(self);//①对Java Reference对象的处理，我们后续统一介绍  //②清除系统中\u0026#34;Weak\u0026#34;型的垃圾对象。我们将介绍JNI WeakGlobal型对象的清除  SweepSystemWeaks(self); Runtime* const runtime = Runtime::Current(); runtime-\u0026gt;AllowNewSystemWeaks();//重新允许\u0026#34;Weak\u0026#34;对象的创建和解析  //清除不再需要的ClassLoader对象。请感兴趣的读者自行研究  runtime-\u0026gt;GetClassLinker()-\u0026gt;CleanupClassLoaders(); { WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); GetHeap()-\u0026gt;RecordFreeRevoke(); //③下面的Sweep函数是关键，用于清理之前未被标记的对象  Sweep(false);//注意，此处调用Sweep的参数为false  //下面这两个函数用于处理空间对象中的位图  SwapBitmaps(); //UnBindBitmaps的处理需结合StickyMarkSweep来介绍  GetHeap()-\u0026gt;UnBindBitmaps(); } } SweepSystemWeaks void MarkSweep::SweepSystemWeaks(Thread* self) { ReaderMutexLock mu(self, *Locks::heap_bitmap_lock_); /*调用Runtime SweepSystemWeaks函数，参数为一个IsMarkedVisitor类型的对象。 根据14.3.1节的介绍可知，IsMarkedVisitor是一个虚基类，仅定义 了一个IsMarked虚函数。GarbageCollector类继承了IsMarkedVistior类。而 IsMarked由GarbageCollector的具体子类来实现。*/ Runtime::Current()-\u0026gt;SweepSystemWeaks(this); } inline mirror::Object* MarkSweep::IsMarked(mirror::Object* object) { //先看看这个object是否属于immue_spaces_空间中的对象  if (immune_spaces_.IsInImmuneRegion(object)) { return object; } //current_space_bitmap_来自某个Space对象的mark_bitmap_，先检查这个object是否  //属于该空间，然后判断它是否被标记  if (current_space_bitmap_-\u0026gt;HasAddress(object)) { return current_space_bitmap_-\u0026gt;Test(object) ? object : nullptr; } //mark_bitmap_就是Heap mark_bitmap_的成员，它将遍历Heap的所有space对象，  //先判断object属于哪个空间，然后检查是否被标记。  return mark_bitmap_-\u0026gt;Test(object) ? object : nullptr; } void Runtime::SweepSystemWeaks(IsMarkedVisitor* visitor) { GetInternTable()-\u0026gt;SweepInternTableWeaks(visitor); GetMonitorList()-\u0026gt;SweepMonitorList(visitor); //笔者仅介绍JNI层对WeakGlobal型对象的清除过程  GetJavaVM()-\u0026gt;SweepJniWeakGlobals(visitor); GetHeap()-\u0026gt;SweepAllocationRecords(visitor); GetLambdaBoxTable()-\u0026gt;SweepWeakBoxedLambdas(visitor); } java_vm_ext.cc\nvoid JavaVMExt::SweepJniWeakGlobals(IsMarkedVisitor* visitor) { MutexLock mu(Thread::Current(), weak_globals_lock_); Runtime* const runtime = Runtime::Current(); /*weak_globals_的类型为IndirectReferenceTable（笔者简写其为IRTable）， 在下面这段C++11的for each循环中，entry的类型为GcRoot\u0026lt;mirror::Object\u0026gt;*。 它直接来自IRTable的成员变量table_。如果修改了entry的值，也就是修改了 weak_globals_的内容。*/ for (auto* entry : weak_globals_) { //遍历weak_globals_中的元素，元素是一个WeakGlobal型的对象  if (!entry-\u0026gt;IsNull()) { //调用GcRoot的Read函数，不使用ReadBarrier。GcRoot的Read函数其实很有讲究，  //主要和Read Barrier的处理有关。本书所使用的例子均不使用Read barrier  mirror::Object* obj = entry-\u0026gt;Read\u0026lt;kWithoutReadBarrier\u0026gt;(); /*调用IsMarkedVisitor的IsMarked函数。对MS而言，此处调用的是MarkSweep类 的IsMarked函数，下文将看到它的代码。IsMarked返回值为一个Object对象。如果 MarkSweep IsMarked返回为空指针，说明输入obj没有被标记—说明该obj是 垃圾对象。 */ mirror::Object* new_obj = visitor-\u0026gt;IsMarked(obj); if (new_obj == nullptr) { /*new_obj为空指针，说明这个WeakGlobal型对象指向的那个对象是垃圾，将会被清除。 这时我们需要修改WeakGlobal型对象的内容，使它指向另外一个有特殊含义的对象— 即Runtime的sentinel_成员变量（由GetClearedJniWeakGlobal函数返回）。Runtime sentinel_就是一个Java Object对象，它在ClassLinker InitFromBootImage 函数中创建。该对象本身没有什么特别之处，只不过它有特殊用途而已。*/ new_obj = runtime-\u0026gt;GetClearedJniWeakGlobal(); } //修改WeakGloabl型对象的内容  *entry = GcRoot\u0026lt;mirror::Object\u0026gt;(new_obj); } } } Sweep void MarkSweep::Sweep(bool swap_bitmaps) {//注意，调用时swap_bitmaps为false  ...... { /*GetLiveStack返回Heap的live_stack_。14.4.4节中介绍过Heap live_stack_的内容。它 保存了mutator线程所创建的对象。从严格意义上来说是从下面的Reset调用后到PausePhase调用 Heap SwapStacks之前这段时间内mutator创建的对象。为什么这么说呢？原因是在于它们的使用 步骤： (1) mutator只会将创建的对象存储于Heap allocation_stack_中。 (2) Heap SwapStacks将交换Heap live_stack_和allocation_stack_的内容。此后， allocation_stack_容器为空容器（原因在步骤3）。 (3) Heap MarkAllocStackAsLive后，live_stack_会被Reset，也就是容器会被清空。 而live_stack_在第2步中会和allocation_stack_交换，所以交换后， allocation_stack_就是空容器了。 简单来说，live_stack_中的对象属于集合Live。但是，请读者注意，live_stack_只是集合 Live的一部分。因为它只保存了两次GC间创建的对象。*/ accounting::ObjectStack* live_stack = heap_-\u0026gt;GetLiveStack(); /*调用Heap MarkAllocStackAsLive对live_stack中的元素进行处理。 (1) 这些元素就是一个个mirror Object对象，它们属于集合Live。 (2) MarkAllocStackAsLive将找到这些对象所在的空间，然后对这些空间对象的 live_bitmap_位图进行设置。也就是说，集合Live由空间对象的live_bitmap_表示。*/ heap_-\u0026gt;MarkAllocStackAsLive(live_stack); live_stack-\u0026gt;Reset();//清空Heap live_stack_的内容  } //遍历HeapContinuous_spaces_的成员，读者可回顾14.4.1节中的图14-6。  for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { /*结合图14-6以及13.1节的内容可知，只有 \u0026#34;main rosalloc space\u0026#34;和\u0026#34;zygote / non moving space\u0026#34;这两个空间为 ContinuousMemMapAllocSpace。而\u0026#34;.../boot.art\u0026#34;对应的ImageSpace属于 ContinuousSpace。 */ if (space-\u0026gt;IsContinuousMemMapAllocSpace()) { space::ContinuousMemMapAllocSpace* alloc_space = space-\u0026gt;AsContinuousMemMapAllocSpace(); ...... //调用ContinuousMemMapAllocSpace的Sweep函数，swap_bitmaps值为false  RecordFree(alloc_space-\u0026gt;Sweep(swap_bitmaps)); } } //回收DiscontinuousSpace对象中的垃圾，请读者自行阅读这部分代码  SweepLargeObjects(swap_bitmaps) } ContinuousMemMapAllocSpace::Sweep collector::ObjectBytePair ContinuousMemMapAllocSpace::Sweep(bool swap_bitmaps) { /*Sweep的返回值类型为ObjectBytePair，它类似std的pair类，包含两个信息，第一个信息 是回收的垃圾对象的个数，第二个信息是回收的内存的字节数。*/ //获取空间的live_bitmap_和mark_bitmap_成员，它们分别代表集合Live和集合Mark  accounting::ContinuousSpaceBitmap* live_bitmap = GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = GetMarkBitmap(); //如果live_bitmap和mark_bitmap是同一个对象，则不需要清除  if (live_bitmap == mark_bitmap) { return collector::ObjectBytePair(0, 0); } SweepCallbackContext scc(swap_bitmaps, this); //交换live_bitmap和mark_bitmap的值。本次调用if的条件不满足  if (swap_bitmaps) { std::swap(live_bitmap, mark_bitmap); } /*调用ContinuousSpaceBitmap的SweepWalk函数，它将扫描从Begin()开始，到End() 结束的这段内存空间。请读者注意SweepWalk的参数： live_bitmap：代表集合Live。 mark_bitmap：代表集合Mark。 SweepWalk判断一个对象是否为垃圾对象的条件很简单。假设某个对象在两个位图中的索引是i， 那么，该对象是垃圾的条件是\u0026#34;live_bitmap[i] \u0026amp; ~mark_bitmap[i]\u0026#34;为true，即： (1) 如果live_bitmap[i]为1，说明它属于集合Live。 (2) 如果mark_bitmap[i]为0，说明这个对象不属于集合Mark。 当条件1和2满足时，这个对象就是垃圾对象。 GetSweepCallback由子类实现，返回一个处理垃圾对象回调函数。SweepWalk每找到一个垃圾对象 都会调用这个回调函数进行处理。*/ accounting::ContinuousSpaceBitmap::SweepWalk( *live_bitmap, *mark_bitmap, reinterpret_cast\u0026lt;uintptr_t\u0026gt;(Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(End()), GetSweepCallback(), reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;scc)); return scc.freed; } MallocSpace::SweepCallback void MallocSpace::SweepCallback(size_t num_ptrs, mirror::Object** ptrs, void* arg) { /*ContinuousSpaceBitmap SweepWalk找到垃圾对象后就会回调SweepCallback。 参数中的num_ptrs代表垃圾对象的个数，而**ptrs代表一个垃圾对象数组的起始地址。*/ SweepCallbackContext* context = static_cast\u0026lt;SweepCallbackContext*\u0026gt;(arg); space::MallocSpace* space = context-\u0026gt;space-\u0026gt;AsMallocSpace(); Thread* self = context-\u0026gt;self; //回调时传入的信息，swap_bitmaps为false  if (!context-\u0026gt;swap_bitmaps) { accounting::ContinuousSpaceBitmap* bitmap = space-\u0026gt;GetLiveBitmap(); //既然是垃圾对象，则需要将其从live_bitmap_中去除  for (size_t i = 0; i \u0026lt; num_ptrs; ++i) { bitmap-\u0026gt;Clear(ptrs[i]); } } context-\u0026gt;freed.objects += num_ptrs; //RosAlloc和DlMallocSpace均实现了FreeList函数，用于释放一组对象的内存  context-\u0026gt;freed.bytes += space-\u0026gt;FreeList(self, num_ptrs, ptrs); } SwapBitmaps /*SwapBitmaps的作用其实很简单，就是交换集合Live和集合Mark在相关数据结构中对应的成员变量。我们以集合Live和集合Mark为目标来看待交换后的结果。 集合Live包含了此次GC中搜索到的对象。显然，它们构成了集合Live第二部分的内容——即上一次GC后剩下的对象。注意，本次GC的剩余对象将作为下一次GC中集合Live的内容。 集合Mark包含的信息是原集合Live去掉本次GC中的垃圾对象后的结果。*/ void GarbageCollector::SwapBitmaps() { ...... const GcType gc_type = GetGcType(); for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { /*回顾13.7.1节的内容可知，ZygoteSpace的gc_retention_policy_取值为kGcRetention- PolicyFullCollect，而BumpPointerSpace、RegionSpace、DlMallocSpace、 RosAllocSpace的gc_retention_policy_取值为kGcRetentionPolicyAlwaysCollect， ImageSpace的gc_retention_policy_取值为kGcRetentionPolicyNeverCollect。 下面这个if条件中包含两个判断，其中的第二个判断说明只在MarkSweep的时候才处理ZygoteSpace 空间。而PartialMarkSweep以及StickMarkSweep均不需要处理它。 这也符合kGcTypeFull等回收策略的要求。 */ if( space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyAlwaysCollect || (gc_type == kGcTypeFull \u0026amp;\u0026amp; space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyFullCollect)) { accounting::ContinuousSpaceBitmap* live_bitmap = space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = space-\u0026gt;GetMarkBitmap(); if (live_bitmap != nullptr \u0026amp;\u0026amp; live_bitmap != mark_bitmap) { /*更新Heap live_bitmap_和mark_bitmap_数组中的元素，ReplaceBitmap第一个 参数为旧值，第二个参数为新值。其内部将先找到旧值所在的数组索引，然后将新值存储 到该索引位置上。下面这两行代码就是交换Heap live_bitmap_和mark_bitmap_ 对应元素的信息。 */ heap_-\u0026gt;GetLiveBitmap()-\u0026gt;ReplaceBitmap(live_bitmap, mark_bitmap); heap_-\u0026gt;GetMarkBitmap()-\u0026gt;ReplaceBitmap(mark_bitmap, live_bitmap); //交换space中live_bitmap_和mark_bitmap_。  space-\u0026gt;AsContinuousMemMapAllocSpace()-\u0026gt;SwapBitmaps(); } } } ......//对大内存对象的处理，和上面类似 } Heap::UnBindBitmaps void Heap::UnBindBitmaps() { ...... for (const auto\u0026amp; space : GetContinuousSpaces()) { if (space-\u0026gt;IsContinuousMemMapAllocSpace()) { space::ContinuousMemMapAllocSpace* alloc_space = space-\u0026gt;AsContinuousMemMapAllocSpace(); //temp_bitmap_不为空，说明之前曾经调用过BindLiveToMarkBitmap  if (alloc_space-\u0026gt;HasBoundBitmaps()) alloc_space-\u0026gt;UnBindBitmaps(); } } } space.cc\nvoid ContinuousMemMapAllocSpace::UnBindBitmaps() { //temp_bitmap_保存了原mark_bitmap_的内容，而mark_bitmap_保存了原live_bitmap_的内容  accounting::ContinuousSpaceBitmap* new_bitmap = temp_bitmap_.release(); //恢复Heap mark_bitmap_对应索引的内容  Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetMarkBitmap()-\u0026gt;ReplaceBitmap( mark_bitmap_.get(), new_bitmap); //恢复mark_bitmap_的内容  mark_bitmap_.reset(new_bitmap); } FinishPhase void MarkSweep::FinishPhase() { ...... mark_stack_-\u0026gt;Reset();//清空MarkSweep mark_stack_的内容  Thread* const self = Thread::Current(); ReaderMutexLock mu(self, *Locks::mutator_lock_); WriterMutexLock mu2(self, *Locks::heap_bitmap_lock_); //清空空间对象mark_bitmap_，也就是GC结束后，集合Mark将被清空  heap_-\u0026gt;ClearMarkedObjects(); } partial_mark_sweep\nPartialMarkSweep class PartialMarkSweep : public MarkSweep { public: virtual GcType GetGcType() const OVERRIDE { return kGcTypePartial; //回收策略  } ...... protected: virtual void BindBitmaps() OVERRIDE; ...... }; BindBitmaps void PartialMarkSweep::BindBitmaps() { //调用父类的BindBitmaps，根据14.4.3.1节的介绍可知，ImageSpace将  //加入immune_spaces_  MarkSweep::BindBitmaps(); WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { //根据13.1节的内容可知，只有ZygoteSpace空间的回收策略是  //kGcRetentionPolicyFullCollect。所以，下面这几行代码就是将ZygoteSpace加入  //immune_spaces_  if (space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyFullCollect) { immune_spaces_.AddSpace(space); } } } sticky_mark_sweep\nStickyMarkSweep class StickyMarkSweep FINAL : public PartialMarkSweep { //StickyMarkSweep派生自PartialMarkSweep  public: GcType GetGcType() const OVERRIDE { return kGcTypeSticky; } .... protected: void BindBitmaps() OVERRIDE; void MarkReachableObjects() OVERRIDE ; void Sweep(bool swap_bitmaps) OVERRIDE; ...... }; BindBitmaps void StickyMarkSweep::BindBitmaps() { //StickyMarkSweep不处理ImageSpace和ZygoteSpace  PartialMarkSweep::BindBitmaps(); WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;IsContinuousMemMapAllocSpace() \u0026amp;\u0026amp; space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyAlwaysCollect) { //调用ContinuousMemMapAllocSpace的BindLiveToMarkBitmap函数，见下文解释  space-\u0026gt;AsContinuousMemMapAllocSpace()-\u0026gt;BindLiveToMarkBitmap(); } } //处理DiscontinuousSpace的情况，请读者自行阅读  ...... } ContinuousMemMapAllocSpace::BindLiveToMarkBitmap void ContinuousMemMapAllocSpace::BindLiveToMarkBitmap() { accounting::ContinuousSpaceBitmap* live_bitmap = GetLiveBitmap(); if (live_bitmap != mark_bitmap_.get()) { accounting::ContinuousSpaceBitmap* mark_bitmap = mark_bitmap_.release(); /*下面这行代码的意思是更新Heap mark_bitmap_中原mark_bitmap所在的元素。 更新前,该元素的旧值为mark_bitmap，更新后该元素的新增为live_bitmap。 要理解这行代码的含义，需要读者明白两点： (1) 根据上文对MarkSweep GC代码逻辑的介绍可知，空间对象的live_bitmap_就是本次 GC的集合Live。 (2) Heap mark_bitmap_为集合Mark。调用BindBitmaps的时候，标记工作还未开展， 所以集合Mark为空（集合Mark在上次GC的FinishPhase中被清空）。 结合1和2，对StickyMarkSweep来说，标记还没有开始做（BindBitmaps函数为GC的 准备工作），我们就已经把上次GC的幸存对象“标记”好了。所以，上次GC的幸存对象在本 次GC中将被保留。*/ Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetMarkBitmap()-\u0026gt;ReplaceBitmap(mark_bitmap, live_bitmap); //mark_bitmap的值保存到temp_bitmap_中  temp_bitmap_.reset(mark_bitmap); //原live_bitmap的信息保存到mark_bitmap_中  mark_bitmap_.reset(live_bitmap); } } MarkReachableObjects void StickyMarkSweep::MarkReachableObjects() { //mark_stack_被清空，这表示在MarkRoots中做过标记的对象不再需要。但集合Mark的  //信息却留了下来  mark_stack_-\u0026gt;Reset(); //注意下面这个函数最后一个参数的取值为kCardDirty – 1  RecursiveMarkDirtyObjects(false, accounting::CardTable::kCardDirty - 1); } Sweep void StickyMarkSweep::Sweep(bool swap_bitmaps ATTRIBUTE_UNUSED) { /*SweepArray的第一个参数为Heap live_stack_。live_stack_包含了两次GC间所创建的 对象。它就是StickyMarkSweep中的集合Live。 */ SweepArray(GetHeap()-\u0026gt;GetLiveStack(), false); } SweepArray void MarkSweep::SweepArray(accounting::ObjectStack* allocations, bool swap_bitmaps) { Thread* self = Thread::Current(); /*sweep_array_free_buffer_mem_map_是MarkSweep的成员变量，在构造函数中创建 读者将它看作一块内存即可。下面这行代码将这块内存转成数组变量以方便后续代码的使用。 数据变量名为chunk_free_buffer，数组元素的类型为Object*。 */ mirror::Object** chunk_free_buffer = reinterpret_cast\u0026lt;mirror::Object**\u0026gt;( sweep_array_free_buffer_mem_map_-\u0026gt;BaseBegin()); size_t chunk_free_pos = 0; ...... /*allocations为输入参数，指向Heap live_stack_，读者将live_stack_看成一个数组 容器即可。下面的变量中，objects为这个数组的起始元素，count为数组的元素个数。 */ StackReference\u0026lt;mirror::Object\u0026gt;* objects = allocations-\u0026gt;Begin(); size_t count = allocations-\u0026gt;Size(); /*sweep_spaces是一个数组，用于保存此次GC所要扫描的空间对象。请读者注意，这段 代码中包含一个优化处理。根据注释可知，Heapnon_moving_space_中不太可能出现很多垃 圾对象，所以代码将把non_moving_space_放到sweep_spaces数组的最后。*/ std::vector\u0026lt;space::ContinuousSpace*\u0026gt;sweep_spaces; space::ContinuousSpace* non_moving_space = nullptr; for (space::ContinuousSpace* space : heap_-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;IsAllocSpace() \u0026amp;\u0026amp;!immune_spaces_.ContainsSpace(space)\u0026amp;\u0026amp; space-\u0026gt;GetLiveBitmap() != nullptr) { if (space == heap_-\u0026gt;GetNonMovingSpace()) { //如果是Heap non_moving_space_，则先不加到sweep_spaces数组中  non_moving_space = space; } else { sweep_spaces.push_back(space);//将space保存到数组中  } } } //如果存在non_moving_space，则将其加到数组的最后  if (non_moving_space != nullptr) { sweep_spaces.push_back(non_moving_space); } //接下来开始处理垃圾对象，逐个空间处理  for (space::ContinuousSpace* space : sweep_spaces) { //space和alloc_space指向的是同一个空间对象。只不过后续需要调用AllocSpace的  //FreeList函数释放内存，所以这里会先定义一个alloc_space变量  space::AllocSpace* alloc_space = space-\u0026gt;AsAllocSpace(); accounting::ContinuousSpaceBitmap* live_bitmap = space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = space-\u0026gt;GetMarkBitmap(); ...... //objects为Heap live_stack_容器的起始元素，count为容器的元素个数,main  StackReference\u0026lt;mirror::Object\u0026gt;* out = objects; for (size_t i = 0; i \u0026lt;count; ++i) { mirror::Object* const obj = objects[i].AsMirrorPtr(); //kUseThreadLocalAllocationStack为编译常量，默认为true  if (kUseThreadLocalAllocationStack\u0026amp;\u0026amp; obj == nullptr) { continue; } //先判断space是否包含obj  if (space-\u0026gt;HasAddress(obj)) { //空间对象的mark_bitmap没有设置obj，所以obj是垃圾对象,main  if (!mark_bitmap-\u0026gt;Test(obj)) { /*kSweepArrayChunkFreeSize的值为0。我们找到一个垃圾对象后并不是马上就 清理它，而是先存起来，等攒到一定数量后再一起清理。所以，下面这段代 码的含义就很好理解了。kSweepArrayChunkFreeSize值为1024。 */ if (chunk_free_pos \u0026gt;= kSweepArrayChunkFreeSize) { freed.objects += chunk_free_pos; //释放一组垃圾对象的内存,main  freed.bytes += alloc_space-\u0026gt;FreeList(self, chunk_free_pos, chunk_free_buffer); chunk_free_pos = 0; } //如果个数还未超过1024，先存起来  chunk_free_buffer[chunk_free_pos++] = obj; } } else {//对应!mark_bitmap-\u0026gt;Test(obj)为false的时候，即obj不是垃圾对象  /*obj不是垃圾对象的话，则把obj存到Heap live_stack_新的位置上。随着垃圾对象 被清除，非垃圾对象将向前移动以填补垃圾对象所占据的位置，这样可减少后续其他空间 对象处理的工作量。当然，live_stack_的元素个数也需要相应调整。main*/ (out++)-\u0026gt;Assign(obj); } } ...... count = out - objects;//调整live_stack_的元素个数  } ......//对Discontinuousspaces的处理  { ...... allocations-\u0026gt;Reset();//清空Heap live_stack_的内容  } sweep_array_free_buffer_mem_map_-\u0026gt;MadviseDontNeedAndZero(); } 其他 mark_sweep.h/cc GetCollectorType //PartialMarkSweep和StickyMarkSweep均未重载下面这个函数  virtual CollectorType GetCollectorType() const OVERRIDE { //is_concurrent_为MarkSweep的成员变量，如果为true，则返回kCollectorTypeCMS  return is_concurrent_ ? kCollectorTypeCMS : kCollectorTypeMS; } GetGcType virtual GcType GetGcType() const OVERRIDE { return kGcTypeFull;//MarkSweep支持最强力度的GC策略 } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/gc_semi_space/",
	"title": "GC_Semi_Space",
	"tags": [],
	"description": "",
	"content": "semi_space.cc\nRunPhases void SemiSpace::RunPhases() { Thread* self = Thread::Current(); InitializePhase();//①回收器初始化  //if为true，说明mutator线程已被暂停。这种情况的出现和SemiSpace的用法有关，  //我们暂且不用考虑这些  if (Locks::mutator_lock_-\u0026gt;IsExclusiveHeld(self)) { MarkingPhase();//②标记工作  ReclaimPhase();//回收工作，非常简单，留给读者自行研究  } else { //如果mutator未暂停，则SemiSpace只有标记阶段需要暂停mutator  { ScopedPause pause(this);//暂停mutator  MarkingPhase();//标记工作  } {//mutator恢复运行，可同时开展回收工作  ReaderMutexLock mu(self, *Locks::mutator_lock_); ReclaimPhase(); } } FinishPhase(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/graphics/",
	"title": "Graphics",
	"tags": [],
	"description": "",
	"content": "https://source.android.com/devices/graphics/index.html\nAndroid graphics components No matter what rendering API developers use, everything is rendered onto a \u0026ldquo;surface.\u0026rdquo; The surface represents the producer side of a buffer queue that is often consumed by SurfaceFlinger. Every window that is created on the Android platform is backed by a surface. A==ll of the visible surfaces rendered are composited onto the display by SurfaceFlinger.==\nThe following diagram shows how the key components work together:\nFigure 1. How surfaces are rendered\nThe main components are described below:\nImage Stream Producers An image stream producer can be anything that ==produces graphic buffers for consumption==. Examples include ==OpenGL ES, Canvas 2D==, and mediaserver video decoders.\nFigure 2. Graphic data flow through Android\n OpenGL ES OpenGL for Embedded Systems (OpenGL ES or GLES) is a subset[2] of the OpenGL computer graphics rendering application programming interface (API) for rendering 2D and 3D computer graphics such as those used by video games, ==typically hardware-accelerated using a graphics processing unit (GPU)==. It is designed for embedded systems like smartphones, tablet computers, video game consoles and PDAs. OpenGL ES is the \u0026ldquo;most widely deployed 3D graphics API in history\u0026rdquo;.[3]\nThe API is cross-language and multi-platform. The libraries GLUT and GLU are not available for OpenGL ES. OpenGL ES is managed by the non-profit technology consortium Khronos Group. Vulkan, a next-generation API from Khronos, is made for simpler high performance drivers for mobile and desktop devices.[4]\nVulkan Application developers use Vulkan to create apps that ==execute commands on the GPU== with significantly reduced overhead. Vulkan also provides a more direct mapping to the capabilities found in current graphics hardware ==compared to EGL and GLES==, minimizing opportunities for driver bugs and reducing developer testing time.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/handler/",
	"title": "handler",
	"tags": [],
	"description": "",
	"content": "handler 探索总结handler知识\n Looper     ThreadLocal     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/hprof_binary_dump_format/",
	"title": "Hprof_binary_dump_format",
	"tags": [],
	"description": "",
	"content": "JVM HPROF_查看_Binary Dump Format (format=b) graph LR STRING_IN_UTF8--\u0026gt;xxxx HEAP_DUMP_SEGMENT--\u0026gt;ROOT_UNKNOWN HEAP_DUMP_SEGMENT--\u0026gt;ROOT_JNI_GLOBAL HEAP_DUMP_SEGMENT--\u0026gt;...... HEAP_DUMP_SEGMENT--\u0026gt;CLASS_DUMP HEAP_DUMP_SEGMENT--\u0026gt;INSTANCE_DUMP HEAP_DUMP_SEGMENT--\u0026gt;OBJECT_ARRAY_DUMP HEAP_DUMP_SEGMENT--\u0026gt;PRIMITIVE_ARRAY_DUMP HEAP_DUMP_END--\u0026gt;xxx Binary Dump Format (format=b) The basic fields in the binary output are u1 (1 byte), u2 (2 byte), u4 (4 byte), and u8 (8 byte). An ID in this implementation is a u4, however the size of an ID is really determined by the \u0026ldquo;size of identifiers\u0026rdquo; field in the header.\nWARNING: This format is still considered highly experimental, however, all attempts were made to match the format of past HPROF implementations.\nThe binary output begins with the information:\nHeader    [u1]* An initial NULL terminated series of bytes representing the format name and version, in this implementation and historically, the string \u0026ldquo;JAVA PROFILE 1.0.1\u0026rdquo; (18 u1 bytes) followed by a NULL byte. If the TAG \u0026ldquo;HEAP DUMP SEGMENT\u0026rdquo; is used this string will be \u0026ldquo;JAVA PROFILE 1.0.2\u0026rdquo;.     u4 size of identifiers. Identifiers are used to represent UTF8 strings, objects, stack traces, etc. They can have the same size as host pointers or sizeof(void*), but are not required to be.   u4 high word of number of milliseconds since 0:00 GMT, 1/1/70   u4 low word of number of milliseconds since 0:00 GMT, 1/1/70    Records Followed by a sequence of records that look like:\n   u1 TAG: denoting the type of the record     u4 TIME: number of microseconds since the time stamp in the header   u4 LENGTH: number of bytes that follow this u4 field and belong to this record   [u1]* BODY: as many bytes as specified in the above u4 field    The following TAGs are supported:\n\u0026hellip;\u0026hellip;\nHEAP DUMP or HEAP DUMP SEGMENT    HEAP DUMP or HEAP DUMP SEGMENT 0x0C or 0x1C Contains any number of sub-tags(as body), each begins a u1 field (no order implied here):     HEAP DUMP END 0x2C Terminates a series of HEAP DUMP SEGMENTS. Concatenation of HEAP DUMP SEGMENTS equals a HEAP DUMP.       ROOT UNKNOWN 0xFF ID object ID     ROOT JNI GLOBAL 0x01 ID object ID ID JNI global ref ID   ROOT JNI LOCAL 0x02 ID object ID u4 thread serial number u4 frame number in stack trace (-1 for empty)   ROOT JAVA FRAME 0x03 ID object ID u4 thread serial number u4 frame number in stack trace (-1 for empty)   ROOT NATIVE STACK 0x04 ID object ID u4 thread serial number   ROOT STICKY CLASS 0x05 ID object ID   ROOT THREAD BLOCK 0x06 ID object ID u4 thread serial number   ROOT MONITOR USED 0x07 ID object ID   ROOT THREAD OBJECT 0x08 ID thread object ID u4 thread serial number u4 stack trace serial number   CLASS DUMP 0x20    INSTANCE DUMP 0x21    OBJECT ARRAY DUMP 0x22    PRIMITIVE ARRAY DUMP 0x23     CLASS DUMP    ID class object ID     u4 stack trace serial number   ID super class object ID   ID class loader object ID   ID signers object ID   ID protection domain object ID   ID reserved   ID reserved   u4 instance size (in bytes)   u2 size of constant pool and number of records that follow: u2 constant pool index u1 type of entry: (See Basic Type) value value of entry (u1, u2, u4, or u8 based on type of entry)   u2 Number of static fields: ID static field name string ID u1 type of field: (See Basic Type) value value of entry (u1, u2, u4, or u8 based on type of field)   u2 Number of instance fields (not including super class\u0026rsquo;s) ID field name string ID u1 type of field: (See Basic Type)    INSTANCE DUMP    ID object ID     u4 stack trace serial number   ID class object ID   u4 number of bytes that follow   [value]* instance field values (this class, followed by super class, etc)    OBJECT ARRAY DUMP    ID array object ID     u4 stack trace serial number   u4 number of elements   ID array class object ID   [ID]* elements    PRIMITIVE ARRAY DUMP    ID array object ID     u4 stack trace serial number   u4 number of elements   u1 element type (See Basic Type)   [u1]* elements (packed array)    HEAP DUMP INFO\u0026ndash;Android meaning that heap type have changed\nAndroid Studio Hprof Android Hprof\nsrc/main/java/com/android/tools/perflib/heap/HprofParser.java\nShark Hprof shark-hprof/src/main/java/shark/Hprof.kt\n/** * Reads the headers of the provided [hprofFile] and returns an opened [Hprof]. Don\u0026#39;t forget * to call [close] once done. */ fun open(hprofFile: File): Hprof { val endOfVersionString = source.indexOf(0) val versionName = source.readUtf8(endOfVersionString) // Skip the 0 at the end of the version string.  source.skip(1) val identifierByteSize = source.readInt() // heap dump timestamp  val heapDumpTimestamp = source.readLong() val reader = HprofReader(source, identifierByteSize, byteReadCount) return Hprof( channel, source, reader, heapDumpTimestamp, hprofVersion, fileLength ) "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/input/",
	"title": "input",
	"tags": [],
	"description": "",
	"content": "input 探索总结input知识\n touchEventNative     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/jni/java_jni%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E5%8E%9F%E7%90%86/",
	"title": "java_jni方法调用原理",
	"tags": [],
	"description": "",
	"content": "Method Execute Flow graph TB PerformCall(PerformCall)--\u0026gt;|Interpreter|ArtInterpreterToInterpreterBridge(interpreter::ArtInterpreterToInterpreterBridge) ArtInterpreterToInterpreterBridge--\u0026gt;ExecuteSwitchImplCpp(interpreter::ExecuteSwitchImplCpp) ExecuteSwitchImplCpp--\u0026gt;DoInvoke(case Instruction::xxx: interpreter::DoInvoke, find called ArtMethod) DoInvoke--\u0026gt;DoCallCommon(interpreter::DoCallCommon, prepare shadow frame) DoCallCommon--\u0026gt;PerformCall ArtMethod::Invoke--\u0026gt;art_quick_invoke_stub(art_quick_invoke_stub: function in quick_entry_point.S) artQuickToInterpreterBridge(artQuickToInterpreterBridge, prepare shadow frame)--\u0026gt;EnterInterpreterFromEntryPoint(interpreter::EnterInterpreterFromEntryPoint) EnterInterpreterFromEntryPoint--\u0026gt;ExecuteSwitchImplCpp PerformCall--\u0026gt;|CompiledCode|ArtInterpreterToCompiledCodeBridge(interpreter::ArtInterpreterToCompiledCodeBridge) ArtInterpreterToCompiledCodeBridge--\u0026gt;ArtMethod::Invoke compiledCode--\u0026gt;|Interpreter|artQuickToInterpreterBridge art_quick_invoke_stub--\u0026gt;|ART_METHOD_QUICK_CODE_OFFSET_32|IsJniMethod{Is JNI method?} IsJniMethod--\u0026gt;|no|entry_point_from_quick_compiled_code_(entry_point_from_quick_compiled_code_ linkCode时设置) IsJniMethod--\u0026gt;|yes|art_quick_generic_jni_trampoline_汇编 art_quick_generic_jni_trampoline_汇编--\u0026gt;artQuickGenericJniTrampoline artQuickGenericJniTrampoline--\u0026gt;data_(data_RegisterNative时设置) data_--\u0026gt;IsJniDlsymLookupStub{IsJniDlsymLookupStub?} IsJniDlsymLookupStub--\u0026gt;|no|nativeCode IsJniDlsymLookupStub--\u0026gt;|yes|artFindNativeMethod entry_point_from_quick_compiled_code_--\u0026gt;IsCompiled{Is Compiled?} IsCompiled--\u0026gt;|yes|compiledCode IsCompiled--\u0026gt;|no|art_quick_to_interpreter_bridge汇编 art_quick_to_interpreter_bridge汇编--\u0026gt;artQuickToInterpreterBridge Trampoline code 所有Trampoline code都是一段汇编代码编写的函数，这段汇编代码函数内部一般会跳转到一个由更高级的编程语言（C++）实现的函数。\nclass Thread{ ...... struct PACKED(sizeof(void*)) tls_ptr_sized_values { ...... //针对jni方法的Trampoline code，只包含一个pDlsymLookup函数指针,对应的Trampoline code在jni_entrypoints_x86.S里实现。  //结构体，和JNI调用有关。里边只有一个函数指针成员变量，名为pDlsymLookup。当JNI函数未注册时，这个成员变量将被调用以找到目标JNI函数  JniEntryPoints jni_entrypoints; //针对非jni方法的Trampoline code，一共包含132个函数指针,对应的Trampoline code在quick_entrypoints_x86.S里实现。  //结构体，其成员变量全是个函数指针类型，其定义可参考quick_entrypoints_list.h。它包含了一些由ART虚拟机提供的某些功能，而我们编译得到的机器码可能会用到它们。生成机器码时，我们需要生成对应的调用指令以跳转到这些函数  QuickEntryPoints quick_entrypoints; ...... } tlsPtr_; } art/runtime/interpreter/interpreter.cc\nArtInterpreterToInterpreterBridge void ArtInterpreterToInterpreterBridge(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame* shadow_frame, JValue* result) { self-\u0026gt;PushShadowFrame(shadow_frame); ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); if (LIKELY(!shadow_frame-\u0026gt;GetMethod()-\u0026gt;IsNative())) { result-\u0026gt;SetJ(Execute(self, accessor, *shadow_frame, JValue()).GetJ());//main  } else { // We don\u0026#39;t expect to be asked to interpret native code (which is entered via a JNI compiler  // generated stub) except during testing and image writing.  CHECK(!Runtime::Current()-\u0026gt;IsStarted()); ObjPtr\u0026lt;mirror::Object\u0026gt; receiver = is_static ? nullptr : shadow_frame-\u0026gt;GetVRegReference(0); uint32_t* args = shadow_frame-\u0026gt;GetVRegArgs(is_static ? 0 : 1); UnstartedRuntime::Jni(self, shadow_frame-\u0026gt;GetMethod(), receiver.Ptr(), args, result); } self-\u0026gt;PopShadowFrame(); Execute static inline JValue Execute( Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame\u0026amp; shadow_frame, JValue result_register, bool stay_in_interpreter = false) REQUIRES_SHARED(Locks::mutator_lock_) { if (LIKELY(shadow_frame.GetDexPC() == 0)) { // Entering the method, but not via deoptimization.  if (!stay_in_interpreter) { jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;MethodEntered(self, shadow_frame.GetMethod()); if (jit-\u0026gt;CanInvokeCompiledCode(method)) { JValue result; // Pop the shadow frame before calling into compiled code.  self-\u0026gt;PopShadowFrame(); //Calculate the offset of the first input reg. The input registers are in the high regs.  //It\u0026#39;s ok to access the code item here since JIT code will have been touched by the  // interpreter and compiler already.  uint16_t arg_offset = accessor.RegistersSize() - accessor.InsSize(); ArtInterpreterToCompiledCodeBridge(self, nullptr, \u0026amp;shadow_frame, arg_offset, \u0026amp;result); // Push the shadow frame back as the caller will expect it.  self-\u0026gt;PushShadowFrame(\u0026amp;shadow_frame); return result; } } } } ArtMethod* method = shadow_frame.GetMethod();//method为当前帧的方法  return ExecuteSwitchImpl\u0026lt;false, false\u0026gt;(self, accessor, shadow_frame, result_register, false); art/runtime/interpreter/interpreter_switch_impl.h/cc\nExecuteSwitchImpl // Wrapper around the switch interpreter which ensures we can unwind through it. template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; ALWAYS_INLINE JValue ExecuteSwitchImpl(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame\u0026amp; shadow_frame, JValue result_register, bool interpret_one_instruction) REQUIRES_SHARED(Locks::mutator_lock_) { SwitchImplContext ctx { .self = self, .accessor = accessor, .shadow_frame = shadow_frame, .result_register = result_register, .interpret_one_instruction = interpret_one_instruction, .result = JValue(), }; void* impl = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;ExecuteSwitchImplCpp\u0026lt;do_access_check, transaction_active\u0026gt;);//main  const uint16_t* dex_pc = ctx.accessor.Insns(); ExecuteSwitchImplAsm(\u0026amp;ctx, impl, dex_pc); return ctx.result; } template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; void ExecuteSwitchImplCpp(SwitchImplContext* ctx) { Thread* self = ctx-\u0026gt;self; const CodeItemDataAccessor\u0026amp; accessor = ctx-\u0026gt;accessor; ShadowFrame\u0026amp; shadow_frame = ctx-\u0026gt;shadow_frame; JValue result_register = ctx-\u0026gt;result_register; bool interpret_one_instruction = ctx-\u0026gt;interpret_one_instruction; constexpr bool do_assignability_check = do_access_check; self-\u0026gt;VerifyStack(); uint32_t dex_pc = shadow_frame.GetDexPC(); const auto* const instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); const uint16_t* const insns = accessor.Insns(); const Instruction* inst = Instruction::At(insns + dex_pc); uint16_t inst_data; jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); do { dex_pc = inst-\u0026gt;GetDexPc(insns); shadow_frame.SetDexPC(dex_pc); TraceExecution(shadow_frame, inst, dex_pc); inst_data = inst-\u0026gt;Fetch16(0); switch (inst-\u0026gt;Opcode(inst_data)) { case Instruction::INVOKE_DIRECT: { PREAMBLE(); bool success = DoInvoke\u0026lt;kDirect, false, do_access_check\u0026gt;( self, shadow_frame, inst, inst_data, \u0026amp;result_register); POSSIBLY_HANDLE_PENDING_EXCEPTION(!success, Next_3xx); break; } case Instruction::INVOKE_STATIC: { PREAMBLE(); bool success = DoInvoke\u0026lt;kStatic, false, do_access_check\u0026gt;( self, shadow_frame, inst, inst_data, \u0026amp;result_register); POSSIBLY_HANDLE_PENDING_EXCEPTION(!success, Next_3xx); break; } } } while (!interpret_one_instruction); // Record where we stopped.  shadow_frame.SetDexPC(inst-\u0026gt;GetDexPc(insns)); ctx-\u0026gt;result = result_register; return; art/runtime/interpreter/interpreter_common.h\nDoInvoke // Handles all invoke-XXX/range instructions except for invoke-polymorphic[/range]. // Returns true on success, otherwise throws an exception and returns false. template\u0026lt;InvokeType type, bool is_range, bool do_access_check\u0026gt; static inline bool DoInvoke(Thread* self, ShadowFrame\u0026amp; shadow_frame, const Instruction* inst, uint16_t inst_data, JValue* result) { // Make sure to check for async exceptions before anything else.  if (UNLIKELY(self-\u0026gt;ObserveAsyncException())) { return false; } const uint32_t method_idx = (is_range) ? inst-\u0026gt;VRegB_3rc() : inst-\u0026gt;VRegB_35c(); const uint32_t vregC = (is_range) ? inst-\u0026gt;VRegC_3rc() : inst-\u0026gt;VRegC_35c(); ObjPtr\u0026lt;mirror::Object\u0026gt; receiver = (type == kStatic) ? nullptr : shadow_frame.GetVRegReference(vregC); ArtMethod* sf_method = shadow_frame.GetMethod();//发起调用的方法  ArtMethod* const called_method = FindMethodFromCode\u0026lt;type, do_access_check\u0026gt;( method_idx, \u0026amp;receiver, sf_method, self);//被调用方法  // The shadow frame should already be pushed, so we don\u0026#39;t need to update it.  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr \u0026amp;\u0026amp; (type == kVirtual || type == kInterface)) { jit-\u0026gt;InvokeVirtualOrInterface(receiver, sf_method, shadow_frame.GetDexPC(), called_method); } // TODO: Remove the InvokeVirtualOrInterface instrumentation, as it was only used by the JIT.  if (type == kVirtual || type == kInterface) { instrumentation::Instrumentation* instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); if (UNLIKELY(instrumentation-\u0026gt;HasInvokeVirtualOrInterfaceListeners())) { instrumentation-\u0026gt;InvokeVirtualOrInterface( self, receiver.Ptr(), sf_method, shadow_frame.GetDexPC(), called_method); } } return DoCall\u0026lt;is_range, do_access_check\u0026gt;(called_method, self, shadow_frame, inst, inst_data, result); art/runtime/interpreter/interpreter_common.cc\nDoCall template\u0026lt;bool is_range, bool do_assignability_check\u0026gt; bool DoCall(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame, const Instruction* inst, uint16_t inst_data, JValue* result) { // Argument word count.  const uint16_t number_of_inputs = (is_range) ? inst-\u0026gt;VRegA_3rc(inst_data) : inst-\u0026gt;VRegA_35c(inst_data); // TODO: find a cleaner way to separate non-range and range information without duplicating  // code.  uint32_t arg[Instruction::kMaxVarArgRegs] = {}; // only used in invoke-XXX.  uint32_t vregC = 0; if (is_range) { vregC = inst-\u0026gt;VRegC_3rc(); } else { vregC = inst-\u0026gt;VRegC_35c(); inst-\u0026gt;GetVarArgs(arg, inst_data); } return DoCallCommon\u0026lt;is_range, do_assignability_check\u0026gt;( called_method, self, shadow_frame, result, number_of_inputs, arg, vregC); } art/runtime/interpreter/interpreter_common.cc\nDoCallCommon template \u0026lt;bool is_range, bool do_assignability_check\u0026gt; static inline bool DoCallCommon(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame, JValue* result, uint16_t number_of_inputs, uint32_t (\u0026amp;arg)[Instruction::kMaxVarArgRegs], uint32_t vregC) { // Compute method information.  CodeItemDataAccessor accessor(called_method-\u0026gt;DexInstructionData()); // Number of registers for the callee\u0026#39;s call frame.  uint16_t num_regs; // Test whether to use the interpreter or compiler entrypoint, and save that result to pass to  // PerformCall. A deoptimization could occur at any time, and we shouldn\u0026#39;t change which  // entrypoint to use once we start building the shadow frame.  // For unstarted runtimes, always use the interpreter entrypoint. This fixes the case where we are  // doing cross compilation. Note that GetEntryPointFromQuickCompiledCode doesn\u0026#39;t use the image  // pointer size here and this may case an overflow if it is called from the compiler. b/62402160  const bool use_interpreter_entrypoint = !Runtime::Current()-\u0026gt;IsStarted() || ClassLinker::ShouldUseInterpreterEntrypoint( called_method, called_method-\u0026gt;GetEntryPointFromQuickCompiledCode()); ...... // Allocate shadow frame on the stack.  //called_method是被调用的方法  const char* old_cause = self-\u0026gt;StartAssertNoThreadSuspension(\u0026#34;DoCallCommon\u0026#34;); ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, \u0026amp;shadow_frame, called_method, /* dex pc */ 0); ShadowFrame* new_shadow_frame = shadow_frame_unique_ptr.get(); ...... PerformCall(self, accessor, shadow_frame.GetMethod(), first_dest_reg, new_shadow_frame, result, use_interpreter_entrypoint); art/runtime/common_dex_operations.h\nPerformCall inline void PerformCall(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ArtMethod* caller_method, const size_t first_dest_reg, ShadowFrame* callee_frame, JValue* result, bool use_interpreter_entrypoint) REQUIRES_SHARED(Locks::mutator_lock_) { if (LIKELY(Runtime::Current()-\u0026gt;IsStarted())) { if (use_interpreter_entrypoint) { interpreter::ArtInterpreterToInterpreterBridge(self, accessor, callee_frame, result); } else { interpreter::ArtInterpreterToCompiledCodeBridge( self, caller_method, callee_frame, first_dest_reg, result); } } else { interpreter::UnstartedRuntime::Invoke(self, accessor, callee_frame, result, first_dest_reg); } } ArtInterpreterToCompiledCodeBridge void ArtInterpreterToCompiledCodeBridge(Thread* self, ArtMethod* caller, ShadowFrame* shadow_frame, uint16_t arg_offset, JValue* result) REQUIRES_SHARED(Locks::mutator_lock_) { ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); ...... jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr \u0026amp;\u0026amp; caller != nullptr) { jit-\u0026gt;NotifyInterpreterToCompiledCodeTransition(self, caller); } method-\u0026gt;Invoke(self, shadow_frame-\u0026gt;GetVRegArgs(arg_offset), (shadow_frame-\u0026gt;NumberOfVRegs() - arg_offset) * sizeof(uint32_t), result, method-\u0026gt;GetInterfaceMethodIfProxy(kRuntimePointerSize)-\u0026gt;GetShorty()); art/runtime/art_method.cc\nArtMethod::Invoke void ArtMethod::Invoke(Thread* self, uint32_t* args, uint32_t args_size, JValue* result, const char* shorty) { if (!IsStatic()) { (*art_quick_invoke_stub)(this, args, args_size, self, result, shorty); } else { (*art_quick_invoke_static_stub)(this, args, args_size, self, result, shorty);//in art/runtime/arch/x86/quick_entrypoints_x86.S  } art_quick_invoke_stub namespace art { extern \u0026#34;C\u0026#34; void art_quick_invoke_stub(ArtMethod*, uint32_t*, uint32_t, Thread*, JValue*, const char*); extern \u0026#34;C\u0026#34; void art_quick_invoke_static_stub(ArtMethod*, uint32_t*, uint32_t, Thread*, JValue*, const char*);  art/runtime/arch/x86/quick_entrypoints_x86.S\nDEFINE_FUNCTION art_quick_invoke_stub mov 20(%ebp), %eax // move method pointer into eax  call *ART_METHOD_QUICK_CODE_OFFSET_32(%eax) // call the method. java method转到art_quick_to_interpreter_bridge，jni method转到art_quick_generic_jni_trampoline art_quick_to_interpreter_bridge DEFINE_FUNCTION art_quick_to_interpreter_bridge PUSH eax // pass method  call SYMBOL(artQuickToInterpreterBridge) // (method, Thread*, SP) art/runtime/entrypoints/quick/quick_trampoline_entrypoints.cc\nartQuickToInterpreterBridge extern \u0026#34;C\u0026#34; uint64_t artQuickToInterpreterBridge(ArtMethod* method, Thread* self, ArtMethod** sp) REQUIRES_SHARED(Locks::mutator_lock_) { ...... JValue result; if (UNLIKELY(deopt_frame != nullptr)) { HandleDeoptimization(\u0026amp;result, method, deopt_frame, \u0026amp;fragment); } else { const char* old_cause = self-\u0026gt;StartAssertNoThreadSuspension( \u0026#34;Building interpreter shadow frame\u0026#34;); uint16_t num_regs = accessor.RegistersSize(); // No last shadow coming from quick.  ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, /* link */ nullptr, method, /* dex pc */ 0); ShadowFrame* shadow_frame = shadow_frame_unique_ptr.get(); size_t first_arg_reg = accessor.RegistersSize() - accessor.InsSize(); BuildQuickShadowFrameVisitor shadow_frame_builder(sp, method-\u0026gt;IsStatic(), shorty, shorty_len, shadow_frame, first_arg_reg); shadow_frame_builder.VisitArguments(); const bool needs_initialization = method-\u0026gt;IsStatic() \u0026amp;\u0026amp; !method-\u0026gt;GetDeclaringClass()-\u0026gt;IsInitialized(); // Push a transition back into managed code onto the linked list in thread.  self-\u0026gt;PushManagedStackFragment(\u0026amp;fragment); self-\u0026gt;PushShadowFrame(shadow_frame); self-\u0026gt;EndAssertNoThreadSuspension(old_cause); if (needs_initialization) { // Ensure static method\u0026#39;s class is initialized.  StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Class\u0026gt; h_class(hs.NewHandle(shadow_frame-\u0026gt;GetMethod()-\u0026gt;GetDeclaringClass())); if (!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized(self, h_class, true, true)) { DCHECK(Thread::Current()-\u0026gt;IsExceptionPending()) \u0026lt;\u0026lt; shadow_frame-\u0026gt;GetMethod()-\u0026gt;PrettyMethod(); self-\u0026gt;PopManagedStackFragment(fragment); return 0; } } result = interpreter::EnterInterpreterFromEntryPoint(self, accessor, shadow_frame); } EnterInterpreterFromEntryPoint JValue EnterInterpreterFromEntryPoint(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame* shadow_frame) { DCHECK_EQ(self, Thread::Current()); bool implicit_check = !Runtime::Current()-\u0026gt;ExplicitStackOverflowChecks(); if (UNLIKELY(__builtin_frame_address(0) \u0026lt; self-\u0026gt;GetStackEndForInterpreter(implicit_check))) { ThrowStackOverflowError(self); return JValue(); } jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;NotifyCompiledCodeToInterpreterTransition(self, shadow_frame-\u0026gt;GetMethod()); } return Execute(self, accessor, *shadow_frame, JValue()); } art_quick_generic_jni_trampoline DEFINE_FUNCTION art_quick_generic_jni_trampoline call SYMBOL(artQuickGenericJniTrampoline) // (Thread*, sp)  // On x86 there are no registers passed, so nothing to pop here.  // Native call.  call *%eax //调用native层的具体方法实现 artQuickGenericJniTrampoline extern \u0026#34;C\u0026#34; TwoWordReturn artQuickGenericJniTrampoline(Thread* self, ArtMethod** sp) REQUIRES_SHARED(Locks::mutator_lock_) { // Retrieve the stored native code.  void const* nativeCode = called-\u0026gt;GetEntryPointFromJni(); // There are two cases for the content of nativeCode:  // 1) Pointer to the native function.  // 2) Pointer to the trampoline for native code binding.  // In the second case, we need to execute the binding and continue with the actual native function  // pointer.  // after find the native method pointer, set it to nativeCode variable to avoid find native method again  DCHECK(nativeCode != nullptr); if (nativeCode == GetJniDlsymLookupStub()) { #if defined(__arm__) || defined(__aarch64__)  nativeCode = artFindNativeMethod(); #else  nativeCode = artFindNativeMethod(self); #endif art/runtime/entrypoints/jni/jni_entrypoints.cc\nartFindNativeMethod extern \u0026#34;C\u0026#34; const void* artFindNativeMethod(Thread* self) { DCHECK_EQ(self, Thread::Current()); #endif  Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); // We come here as Native.  ScopedObjectAccess soa(self); ArtMethod* method = self-\u0026gt;GetCurrentMethod(nullptr);//获取当前线程栈顶方法  DCHECK(method != nullptr); // Lookup symbol address for method, on failure we\u0026#39;ll return null with an exception set,  // otherwise we return the address of the method we found.  void* native_code = soa.Vm()-\u0026gt;FindCodeForNativeMethod(method); if (native_code == nullptr) { self-\u0026gt;AssertPendingException(); return nullptr; } // Register so that future calls don\u0026#39;t come here  return method-\u0026gt;RegisterNative(native_code); } art/runtime/java_vm_ext.cc\nJavaVMExt::FindCodeForNativeMethod void* JavaVMExt::FindCodeForNativeMethod(ArtMethod* m) { CHECK(m-\u0026gt;IsNative()); mirror::Class* c = m-\u0026gt;GetDeclaringClass(); // If this is a static method, it could be called before the class has been initialized.  CHECK(c-\u0026gt;IsInitializing()) \u0026lt;\u0026lt; c-\u0026gt;GetStatus() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; m-\u0026gt;PrettyMethod(); std::string detail; Thread* const self = Thread::Current(); void* native_method = libraries_-\u0026gt;FindNativeMethod(self, m, detail); if (native_method == nullptr) { // Lookup JNI native methods from native TI Agent libraries. See runtime/ti/agent.h for more  // information. Agent libraries are searched for native methods after all jni libraries.  native_method = FindCodeForNativeMethodInAgents(m); } // Throwing can cause libraries_lock to be reacquired.  if (native_method == nullptr) { LOG(ERROR) \u0026lt;\u0026lt; detail; self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/UnsatisfiedLinkError;\u0026#34;, detail.c_str()); } return native_method; } FindNativeMethod // See section 11.3 \u0026#34;Linking Native Methods\u0026#34; of the JNI spec. void* FindNativeMethod(Thread* self, ArtMethod* m, std::string\u0026amp; detail) REQUIRES(!Locks::jni_libraries_lock_) REQUIRES_SHARED(Locks::mutator_lock_) { std::string jni_short_name(m-\u0026gt;JniShortName());//\u0026#34;Java_com_example_myapplication_loadLibrary_jni_XHCoreJni_getSignatureKey\u0026#34;  std::string jni_long_name(m-\u0026gt;JniLongName());//\u0026#34;Java_com_example_myapplication_loadLibrary_jni_XHCoreJni_getSignatureKey__\u0026#34;  const char* shorty = m-\u0026gt;GetShorty(); { // Go to suspended since dlsym may block for a long time if other threads are using dlopen.  ScopedThreadSuspension sts(self, kNative); void* native_code = FindNativeMethodInternal(self, declaring_class_loader_allocator, shorty, jni_short_name, jni_long_name); if (native_code != nullptr) { return native_code; } } return nullptr; } FindNativeMethodInternal void* FindNativeMethodInternal(Thread* self, void* declaring_class_loader_allocator, const char* shorty, const std::string\u0026amp; jni_short_name, const std::string\u0026amp; jni_long_name) REQUIRES(!Locks::jni_libraries_lock_) REQUIRES(!Locks::mutator_lock_) { MutexLock mu(self, *Locks::jni_libraries_lock_); for (const auto\u0026amp; lib : libraries_) { SharedLibrary* const library = lib.second; // Use the allocator address for class loader equality to avoid unnecessary weak root decode.  if (library-\u0026gt;GetClassLoaderAllocator() != declaring_class_loader_allocator) { // We only search libraries loaded by the appropriate ClassLoader.  continue; } // Try the short name then the long name...  const char* arg_shorty = library-\u0026gt;NeedsNativeBridge() ? shorty : nullptr; void* fn = library-\u0026gt;FindSymbol(jni_short_name, arg_shorty); if (fn == nullptr) { fn = library-\u0026gt;FindSymbol(jni_long_name, arg_shorty); } if (fn != nullptr) { VLOG(jni) \u0026lt;\u0026lt; \u0026#34;[Found native code for \u0026#34; \u0026lt;\u0026lt; jni_long_name \u0026lt;\u0026lt; \u0026#34; in \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; library-\u0026gt;GetPath() \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;]\u0026#34;; return fn; } } return nullptr; } art/runtime/entrypoints/entrypoint_utils-inl.h\nFindMethodFromCode template\u0026lt;InvokeType type, bool access_check\u0026gt; inline ArtMethod* FindMethodFromCode(uint32_t method_idx, ObjPtr\u0026lt;mirror::Object\u0026gt;* this_object, ArtMethod* referrer, Thread* self) { ClassLinker* const class_linker = Runtime::Current()-\u0026gt;GetClassLinker(); constexpr ClassLinker::ResolveMode resolve_mode = access_check ? ClassLinker::ResolveMode::kCheckICCEAndIAE : ClassLinker::ResolveMode::kNoChecks; ArtMethod* resolved_method; if (type == kStatic) { resolved_method = class_linker-\u0026gt;ResolveMethod\u0026lt;resolve_mode\u0026gt;(self, method_idx, referrer, type); } else { StackHandleScope\u0026lt;1\u0026gt; hs(self); HandleWrapperObjPtr\u0026lt;mirror::Object\u0026gt; h_this(hs.NewHandleWrapper(this_object)); resolved_method = class_linker-\u0026gt;ResolveMethod\u0026lt;resolve_mode\u0026gt;(self, method_idx, referrer, type); } art/runtime/class_linker-inl.h\nClassLinker::ResolveMethod template \u0026lt;ClassLinker::ResolveMode kResolveMode\u0026gt; inline ArtMethod* ClassLinker::ResolveMethod(Thread* self, uint32_t method_idx, ArtMethod* referrer, InvokeType type) { // We do not need the read barrier for getting the DexCache for the initial resolved method  // lookup as both from-space and to-space copies point to the same native resolved methods array.  ArtMethod* resolved_method = referrer-\u0026gt;GetDexCache\u0026lt;kWithoutReadBarrier\u0026gt;()-\u0026gt;GetResolvedMethod( method_idx, image_pointer_size_); if (UNLIKELY(resolved_method == nullptr)) { referrer = referrer-\u0026gt;GetInterfaceMethodIfProxy(image_pointer_size_); ObjPtr\u0026lt;mirror::Class\u0026gt; declaring_class = referrer-\u0026gt;GetDeclaringClass(); StackHandleScope\u0026lt;2\u0026gt; hs(self); Handle\u0026lt;mirror::DexCache\u0026gt; h_dex_cache(hs.NewHandle(referrer-\u0026gt;GetDexCache())); Handle\u0026lt;mirror::ClassLoader\u0026gt; h_class_loader(hs.NewHandle(declaring_class-\u0026gt;GetClassLoader())); resolved_method = ResolveMethod\u0026lt;kResolveMode\u0026gt;(method_idx, h_dex_cache, h_class_loader, referrer, type); } art/runtime/mirror/dex_cache-inl.h\nDexCache::GetResolvedMethod inline ArtMethod* DexCache::GetResolvedMethod(uint32_t method_idx, PointerSize ptr_size) { DCHECK_EQ(Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;GetImagePointerSize(), ptr_size); auto pair = GetNativePairPtrSize(GetResolvedMethods(), MethodSlotIndex(method_idx), ptr_size); return pair.GetObjectForIndex(method_idx); } art/runtime/class_linker.cc\nClassLinker::ResolveMethod template \u0026lt;ClassLinker::ResolveMode kResolveMode\u0026gt; ArtMethod* ClassLinker::ResolveMethod(uint32_t method_idx, Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, ArtMethod* referrer, InvokeType type) { .... // The method was not in the DexCache, resolve the declaring class.  klass = ResolveType(method_id.class_idx_, dex_cache, class_loader); resolved = FindResolvedMethod(klass, dex_cache.Get(), class_loader.Get(), method_idx); // If we found a method, check for incompatible class changes.  if (LIKELY(resolved != nullptr) \u0026amp;\u0026amp; LIKELY(kResolveMode == ResolveMode::kNoChecks || !resolved-\u0026gt;CheckIncompatibleClassChange(type))) { return resolved; } else { // If we had a method, or if we can find one with another lookup type,  // it\u0026#39;s an incompatible-class-change error.  if (resolved == nullptr) { resolved = FindIncompatibleMethod(klass, dex_cache.Get(), class_loader.Get(), method_idx); } if (resolved != nullptr) { ThrowIncompatibleClassChangeError(type, resolved-\u0026gt;GetInvokeType(), resolved, referrer); } else { // We failed to find the method (using all lookup types), so throw a NoSuchMethodError.  const char* name = dex_file.StringDataByIdx(method_id.name_idx_); const Signature signature = dex_file.GetMethodSignature(method_id); ThrowNoSuchMethodError(type, klass, name, signature); } Thread::Current()-\u0026gt;AssertPendingException(); return nullptr; ClassLinker::ResolveType ClassLinker::FindResolvedMethod ArtMethod* ClassLinker::FindResolvedMethod(ObjPtr\u0026lt;mirror::Class\u0026gt; klass, ObjPtr\u0026lt;mirror::DexCache\u0026gt; dex_cache, ObjPtr\u0026lt;mirror::ClassLoader\u0026gt; class_loader, uint32_t method_idx) { // Search for the method using dex_cache and method_idx. The Class::Find*Method()  // functions can optimize the search if the dex_cache is the same as the DexCache  // of the class, with fall-back to name and signature search otherwise  ArtMethod* resolved = nullptr; if (klass-\u0026gt;IsInterface()) { resolved = klass-\u0026gt;FindInterfaceMethod(dex_cache, method_idx, image_pointer_size_); } else { resolved = klass-\u0026gt;FindClassMethod(dex_cache, method_idx, image_pointer_size_); } if (resolved != nullptr \u0026amp;\u0026amp; hiddenapi::GetMemberAction( resolved, class_loader, dex_cache, hiddenapi::kLinking) == hiddenapi::kDeny) { resolved = nullptr; } if (resolved != nullptr) { // In case of jmvti, the dex file gets verified before being registered, so first  // check if it\u0026#39;s registered before checking class tables.  const DexFile\u0026amp; dex_file = *dex_cache-\u0026gt;GetDexFile(); DCHECK(!IsDexFileRegistered(Thread::Current(), dex_file) || FindClassTable(Thread::Current(), dex_cache) == ClassTableForClassLoader(class_loader)) \u0026lt;\u0026lt; \u0026#34;DexFile referrer: \u0026#34; \u0026lt;\u0026lt; dex_file.GetLocation() \u0026lt;\u0026lt; \u0026#34; ClassLoader: \u0026#34; \u0026lt;\u0026lt; DescribeLoaders(class_loader, \u0026#34;\u0026#34;); // Be a good citizen and update the dex cache to speed subsequent calls.  dex_cache-\u0026gt;SetResolvedMethod(method_idx, resolved, image_pointer_size_); // Disable the following invariant check as the verifier breaks it. b/73760543  // const DexFile::MethodId\u0026amp; method_id = dex_file.GetMethodId(method_idx);  // DCHECK(LookupResolvedType(method_id.class_idx_, dex_cache, class_loader) != nullptr)  // \u0026lt;\u0026lt; \u0026#34;Method: \u0026#34; \u0026lt;\u0026lt; resolved-\u0026gt;PrettyMethod() \u0026lt;\u0026lt; \u0026#34;, \u0026#34;  // \u0026lt;\u0026lt; \u0026#34;Class: \u0026#34; \u0026lt;\u0026lt; klass-\u0026gt;PrettyClass() \u0026lt;\u0026lt; \u0026#34; (\u0026#34; \u0026lt;\u0026lt; klass-\u0026gt;GetStatus() \u0026lt;\u0026lt; \u0026#34;), \u0026#34;  // \u0026lt;\u0026lt; \u0026#34;DexFile referrer: \u0026#34; \u0026lt;\u0026lt; dex_file.GetLocation();  } return resolved; art/runtime/native/java_lang_reflect_Method.cc\njava_lang_reflect_Method.cc::Method_invoke static JNINativeMethod gMethods[] = { FAST_NATIVE_METHOD(Method, invoke, \u0026#34;(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;\u0026#34;), }; static jobject Method_invoke(JNIEnv* env, jobject javaMethod, jobject javaReceiver, jobjectArray javaArgs) { ScopedFastNativeObjectAccess soa(env); return InvokeMethod(soa, javaMethod, javaReceiver, javaArgs); } art/runtime/reflection.cc\nreflection.cc::InvokeMethod jobject InvokeMethod(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject javaMethod, jobject javaReceiver, jobject javaArgs, size_t num_frames) { ObjPtr\u0026lt;mirror::Executable\u0026gt; executable = soa.Decode\u0026lt;mirror::Executable\u0026gt;(javaMethod); const bool accessible = executable-\u0026gt;IsAccessible(); ArtMethod* m = executable-\u0026gt;GetArtMethod(); ObjPtr\u0026lt;mirror::Class\u0026gt; declaring_class = m-\u0026gt;GetDeclaringClass(); // Check that the receiver is non-null and an instance of the field\u0026#39;s declaring class.  receiver = soa.Decode\u0026lt;mirror::Object\u0026gt;(javaReceiver); if (!VerifyObjectIsClass(receiver, declaring_class)) { return nullptr; } // Find the actual implementation of the virtual method.  m = receiver-\u0026gt;GetClass()-\u0026gt;FindVirtualMethodForVirtualOrInterface(m, kRuntimePointerSize); InvokeWithArgArray(soa, m, \u0026amp;arg_array, \u0026amp;result, shorty); } art/runtime/mirror/class-inl.h\ninline ArtMethod* Class::FindVirtualMethodForVirtualOrInterface(ArtMethod* method, PointerSize pointer_size) { if (method-\u0026gt;IsDirect()) { return method; } if (method-\u0026gt;GetDeclaringClass()-\u0026gt;IsInterface() \u0026amp;\u0026amp; !method-\u0026gt;IsCopied()) { return FindVirtualMethodForInterface(method, pointer_size); } return FindVirtualMethodForVirtual(method, pointer_size); } reflection.cc::InvokeWithArgArray void InvokeWithArgArray(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, ArtMethod* method, ArgArray* arg_array, JValue* result, const char* shorty) REQUIRES_SHARED(Locks::mutator_lock_) { uint32_t* args = arg_array-\u0026gt;GetArray(); if (UNLIKELY(soa.Env()-\u0026gt;IsCheckJniEnabled())) { CheckMethodArguments(soa.Vm(), method-\u0026gt;GetInterfaceMethodIfProxy(kRuntimePointerSize), args); } method-\u0026gt;Invoke(soa.Self(), args, arg_array-\u0026gt;GetNumBytes(), result, shorty); } 其他 ClassLinker::ShouldUseInterpreterEntrypoint bool ClassLinker::ShouldUseInterpreterEntrypoint(ArtMethod* method, const void* quick_code) //method-\u0026gt;IsNative() 判断是否是jni方法(在java中标记native关键字的方法)  if (UNLIKELY(method-\u0026gt;IsNative() || method-\u0026gt;IsProxyMethod())) { return false; } if (quick_code == nullptr) { return true; } Runtime* runtime = Runtime::Current(); instrumentation::Instrumentation* instr = runtime-\u0026gt;GetInstrumentation(); if (instr-\u0026gt;InterpretOnly()) { return true; } if (runtime-\u0026gt;GetClassLinker()-\u0026gt;IsQuickToInterpreterBridge(quick_code)) { // Doing this check avoids doing compiled/interpreter transitions.  return true; } if (Dbg::IsForcedInterpreterNeededForCalling(Thread::Current(), method)) { // Force the use of interpreter when it is required by the debugger.  return true; } if (Thread::Current()-\u0026gt;IsAsyncExceptionPending()) { // Force use of interpreter to handle async-exceptions  return true; } if (runtime-\u0026gt;IsJavaDebuggable()) { // For simplicity, we ignore precompiled code and go to the interpreter  // assuming we don\u0026#39;t already have jitted code.  // We could look at the oat file where `quick_code` is being defined,  // and check whether it\u0026#39;s been compiled debuggable, but we decided to  // only rely on the JIT for debuggable apps.  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); return (jit == nullptr) || !jit-\u0026gt;GetCodeCache()-\u0026gt;ContainsPc(quick_code); } if (runtime-\u0026gt;IsNativeDebuggable()) { DCHECK(runtime-\u0026gt;UseJitCompilation() \u0026amp;\u0026amp; runtime-\u0026gt;GetJit()-\u0026gt;JitAtFirstUse()); // If we are doing native debugging, ignore application\u0026#39;s AOT code,  // since we want to JIT it (at first use) with extra stackmaps for native  // debugging. We keep however all AOT code from the boot image,  // since the JIT-at-first-use is blocking and would result in non-negligible  // startup performance impact.  return !runtime-\u0026gt;GetHeap()-\u0026gt;IsInBootImageOatFile(quick_code); } return false; } art/runtime/jit/jit.cc\nJit::CanInvokeCompiledCode bool Jit::CanInvokeCompiledCode(ArtMethod* method) { return code_cache_-\u0026gt;ContainsPc(method-\u0026gt;GetEntryPointFromQuickCompiledCode()); } art::ShadowFrame art::shadowFrame * link_ //nextFrame below current frame, eg, caller reflection.cc::InvokeVirtualOrInterfaceWithJValues JValue InvokeVirtualOrInterfaceWithJValues(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject obj, jmethodID mid, jvalue* args) { ObjPtr\u0026lt;mirror::Object\u0026gt; receiver = soa.Decode\u0026lt;mirror::Object\u0026gt;(obj); ArtMethod* method = FindVirtualMethod(receiver, jni::DecodeArtMethod(mid)); arg_array.BuildArgArrayFromJValues(soa, receiver, args); InvokeWithArgArray(soa, method, \u0026amp;arg_array, \u0026amp;result, shorty); return result; art_method.cc DexInstructionData inline CodeItemDataAccessor ArtMethod::DexInstructionData() { return CodeItemDataAccessor(*GetDexFile(), GetCodeItem()); } GetCodeItem inline const DexFile::CodeItem* ArtMethod::GetCodeItem() { return GetDexFile()-\u0026gt;GetCodeItem(GetCodeItemOffset()); } GetDexFile inline const DexFile* ArtMethod::GetDexFile() { // It is safe to avoid the read barrier here since the dex file is constant, so if we read the  // from-space dex file pointer it will be equal to the to-space copy.  return GetDexCache\u0026lt;kWithoutReadBarrier\u0026gt;()-\u0026gt;GetDexFile(); } GetDexCache template \u0026lt;ReadBarrierOption kReadBarrierOption\u0026gt; inline mirror::DexCache* ArtMethod::GetDexCache() { if (LIKELY(!IsObsolete\u0026lt;kReadBarrierOption\u0026gt;())) { mirror::Class* klass = GetDeclaringClass\u0026lt;kReadBarrierOption\u0026gt;(); return klass-\u0026gt;GetDexCache\u0026lt;kDefaultVerifyFlags, kReadBarrierOption\u0026gt;(); } else { DCHECK(!IsProxyMethod()); return GetObsoleteDexCache(); } } GetEntryPointFromQuickCompiledCode const void* GetEntryPointFromQuickCompiledCode() { return GetEntryPointFromQuickCompiledCodePtrSize(kRuntimePointerSize); } ALWAYS_INLINE const void* GetEntryPointFromQuickCompiledCodePtrSize(PointerSize pointer_size) { return GetNativePointer\u0026lt;const void*\u0026gt;( EntryPointFromQuickCompiledCodeOffset(pointer_size), pointer_size); } static MemberOffset EntryPointFromQuickCompiledCodeOffset(PointerSize pointer_size) { return MemberOffset(PtrSizedFieldsOffset(pointer_size) + OFFSETOF_MEMBER( PtrSizedFields, entry_point_from_quick_compiled_code_) / sizeof(void*) * static_cast\u0026lt;size_t\u0026gt;(pointer_size)); } 参考 ART执行类方法解析流程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/",
	"title": "jetpack",
	"tags": [],
	"description": "",
	"content": "jetpack 探索总结jetpack知识\n arch    databinding    Databinding      lifecycle    Lifecycle      livedata    LiveData     LiveData封装     MediatorLiveData      viewmodel    ViewModel     ViewModel封装     数据保存和恢复       supportToAndroidx     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/jni/",
	"title": "jni",
	"tags": [],
	"description": "",
	"content": "jni 探索总结jni知识\n C启动Java     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常     解释执行7_0     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/jni/jni%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2/",
	"title": "Jni数据转换",
	"tags": [],
	"description": "",
	"content": "数据转换总结 graph TB jstring--\u0026gt;|soa.decode|mirror::String* mirror::String*--\u0026gt;|encode/AddLocalReference|jstring mirror::String*--\u0026gt;char* char*--\u0026gt;|mirror::String::AllocFromModifiedUtf8|mirror::String* jmethodid--\u0026gt;|decode|ArtMethod* ArtMethod*--\u0026gt;|encode|jmethodid jobject(\u0026quot;jobject/IndirectRef\u0026quot;)--\u0026gt;|decode|mirrorObject(\u0026quot;art::mirror::Object*\u0026quot;) mirrorObject--\u0026gt;|Assign/Compress|StackReference(\u0026quot;art::StackReference\u0026lt;mirror::Object\u0026gt;*\u0026quot;) StackReference--\u0026gt;|AsMirrorPtr/UnCompress|mirrorObject StackReference--\u0026gt;|OwnedBy|Handle(\u0026quot;art::Handle~T~\u0026quot;) StackHandleScope--\u0026gt;|Provided|Handle StackHandleScope--\u0026gt;|OwnsMulti|StackReference ThreadTlsPtr--\u0026gt;|OwnsLinkedList|StackHandleScope mirrorObject--\u0026gt;|encode|jobject HandleScope的作用 类设计 //8.2.2 ScopedObjectAccess等辅助类\nScopedObjectAccessAlreadyRunnable DecodeMethod ArtMethod* DecodeMethod(jmethodID mid) const SHARED_REQUIRES(Locks::mutator_lock_) { Locks::mutator_lock_-\u0026gt;AssertSharedHeld(Self()); return reinterpret_cast\u0026lt;ArtMethod*\u0026gt;(mid);//main  } EncodeMethod jmethodID EncodeMethod(ArtMethod* method) const SHARED_REQUIRES(Locks::mutator_lock_) { Locks::mutator_lock_-\u0026gt;AssertSharedHeld(Self()); return reinterpret_cast\u0026lt;jmethodID\u0026gt;(method);//main  } T AddLocalReference(mirror::Object* obj) /* * Add a local reference for an object to the indirect reference table associated with the * current stack frame. When the native function returns, the reference will be discarded. * * We need to allow the same reference to be added multiple times, and cope with nullptr. * * This will be called on otherwise unreferenced objects. We cannot do GC allocations here, and * it\u0026#39;s best if we don\u0026#39;t grab a mutex. */ template\u0026lt;typename T\u0026gt; T AddLocalReference(mirror::Object* obj) const SHARED_REQUIRES(Locks::mutator_lock_) { return obj == nullptr ? nullptr : Env()-\u0026gt;AddLocalReference\u0026lt;T\u0026gt;(obj); } T Decode(jobject obj) template\u0026lt;typename T\u0026gt; T Decode(jobject obj) const SHARED_REQUIRES(Locks::mutator_lock_) { Locks::mutator_lock_-\u0026gt;AssertSharedHeld(Self()); return down_cast\u0026lt;T\u0026gt;(Self()-\u0026gt;DecodeJObject(obj));//main  } jni_env_ext(-inl.h).h AddLocalReference // JNI local references. IndirectReferenceTable locals GUARDED_BY(Locks::mutator_lock_); template\u0026lt;typename T\u0026gt; inline T JNIEnvExt::AddLocalReference(mirror::Object* obj) { IndirectRef ref = locals.Add(local_ref_cookie, obj); return reinterpret_cast\u0026lt;T\u0026gt;(ref); } libnativehelper/include_jni/jni.h\njni.h 类型定义 /* Primitive types that match up with Java equivalents. */ typedef uint8_t jboolean; /* unsigned 8 bits */ typedef int8_t jbyte; /* signed 8 bits */ typedef uint16_t jchar; /* unsigned 16 bits */ typedef int16_t jshort; /* signed 16 bits */ typedef int32_t jint; /* signed 32 bits */ typedef int64_t jlong; /* signed 64 bits */ typedef float jfloat; /* 32-bit IEEE 754 */ typedef double jdouble; /* 64-bit IEEE 754 */ /* \u0026#34;cardinal indices and sizes\u0026#34; */ typedef jint jsize; class _jobject {}; class _jclass : public _jobject {}; class _jstring : public _jobject {}; class _jarray : public _jobject {}; class _jobjectArray : public _jarray {}; class _jbooleanArray : public _jarray {}; class _jbyteArray : public _jarray {}; class _jcharArray : public _jarray {}; class _jshortArray : public _jarray {}; class _jintArray : public _jarray {}; class _jlongArray : public _jarray {}; class _jfloatArray : public _jarray {}; class _jdoubleArray : public _jarray {}; class _jthrowable : public _jobject {}; typedef _jobject* jobject; typedef _jclass* jclass; typedef _jstring* jstring; typedef _jarray* jarray; typedef _jobjectArray* jobjectArray; typedef _jbooleanArray* jbooleanArray; typedef _jbyteArray* jbyteArray; typedef _jcharArray* jcharArray; typedef _jshortArray* jshortArray; typedef _jintArray* jintArray; typedef _jlongArray* jlongArray; typedef _jfloatArray* jfloatArray; typedef _jdoubleArray* jdoubleArray; typedef _jthrowable* jthrowable; typedef _jobject* jweak; struct _jfieldID; /* opaque structure */ typedef struct _jfieldID* jfieldID; /* field IDs */ struct _jmethodID; /* opaque structure */ typedef struct _jmethodID* jmethodID; /* method IDs */ JNINativeMethod typedef struct { const char* name; const char* signature; void* fnPtr; } JNINativeMethod; NewObject jobject NewObject(jclass clazz, jmethodID methodID, ...) { va_list args; va_start(args, methodID); jobject result = functions-\u0026gt;NewObjectV(this, clazz, methodID, args); va_end(args); return result; } libnativehelper/platform_include/nativehelper/jni_macros.h\nNATIVE_METHOD #define NATIVE_METHOD(className, functionName, signature) \\ MAKE_JNI_NATIVE_METHOD(#functionName, signature, className ## _ ## functionName) //java方法对应的native实现函数方法名规范 art/runtime/jni_internal.cc\njni_internal.cc GetStringUTFChars static const char* GetStringUTFChars(JNIEnv* env, jstring java_string, jboolean* is_copy) { if (is_copy != nullptr) { *is_copy = JNI_TRUE; } ScopedObjectAccess soa(env); ObjPtr\u0026lt;mirror::String\u0026gt; s = soa.Decode\u0026lt;mirror::String\u0026gt;(java_string); size_t byte_count = s-\u0026gt;GetUtfLength(); char* bytes = new char[byte_count + 1]; CHECK(bytes != nullptr); // bionic aborts anyway.  if (s-\u0026gt;IsCompressed()) { for (size_t i = 0; i \u0026lt; byte_count; ++i) { bytes[i] = s-\u0026gt;CharAt(i); } } else { const uint16_t* chars = s-\u0026gt;GetValue(); ConvertUtf16ToModifiedUtf8(bytes, byte_count, chars, s-\u0026gt;GetLength()); } bytes[byte_count] = \u0026#39;\\0\u0026#39;; return bytes; } ReleaseStringUTFChars static void ReleaseStringUTFChars(JNIEnv*, jstring, const char* chars) { delete[] chars; } NewStringUTF static jstring NewStringUTF(JNIEnv* env, const char* utf) { if (utf == nullptr) { return nullptr; } ScopedObjectAccess soa(env); mirror::String* result = mirror::String::AllocFromModifiedUtf8(soa.Self(), utf); return soa.AddLocalReference\u0026lt;jstring\u0026gt;(result); } NewObjectV static jobject NewObjectV(JNIEnv* env, jclass java_class, jmethodID mid, va_list args) { CHECK_NON_NULL_ARGUMENT(java_class); CHECK_NON_NULL_ARGUMENT(mid); ScopedObjectAccess soa(env); mirror::Class* c = EnsureInitialized(soa.Self(), soa.Decode\u0026lt;mirror::Class*\u0026gt;(java_class)); if (c == nullptr) { return nullptr; } if (c-\u0026gt;IsStringClass()) { // Replace calls to String.\u0026lt;init\u0026gt; with equivalent StringFactory call.  jmethodID sf_mid = WellKnownClasses::StringInitToStringFactoryMethodID(mid); return CallStaticObjectMethodV(env, WellKnownClasses::java_lang_StringFactory, sf_mid, args); } mirror::Object* result = c-\u0026gt;AllocObject(soa.Self()); if (result == nullptr) { return nullptr; } jobject local_result = soa.AddLocalReference\u0026lt;jobject\u0026gt;(result); CallNonvirtualVoidMethodV(env, local_result, java_class, mid, args); if (soa.Self()-\u0026gt;IsExceptionPending()) { return nullptr; } return local_result; art/runtime/thread.cc\nthread.cc GetTopHandleScope HandleScope* GetTopHandleScope() { return tlsPtr_.top_handle_scope; } PushHandleScope void PushHandleScope(HandleScope* handle_scope) { DCHECK_EQ(handle_scope-\u0026gt;GetLink(), tlsPtr_.top_handle_scope); tlsPtr_.top_handle_scope = handle_scope; } DecodeJObject ObjPtr\u0026lt;mirror::Object\u0026gt; Thread::DecodeJObject(jobject obj) const { if (obj == nullptr) { return nullptr; } //将jobject转换为IndirectRef  IndirectRef ref = reinterpret_cast\u0026lt;IndirectRef\u0026gt;(obj); IndirectRefKind kind = IndirectReferenceTable::GetIndirectRefKind(ref); ObjPtr\u0026lt;mirror::Object\u0026gt; result; bool expect_null = false; // The \u0026#34;kinds\u0026#34; below are sorted by the frequency we expect to encounter them.  if (kind == kLocal) {//如果是local型引用，则从local的IRTable中找到对应的对象  IndirectReferenceTable\u0026amp; locals = tlsPtr_.jni_env-\u0026gt;locals_; // Local references do not need a read barrier.  result = locals.Get\u0026lt;kWithoutReadBarrier\u0026gt;(ref); } else if (kind == kHandleScopeOrInvalid) { // TODO: make stack indirect reference table lookup more efficient.  // Check if this is a local reference in the handle scope.  if (LIKELY(HandleScopeContains(obj))) { //如果是栈上传递过来的对象(如方法参数)，则可以直接转换成mirror Object对象  // Read from handle scope.  result = reinterpret_cast\u0026lt;StackReference\u0026lt;mirror::Object\u0026gt;*\u0026gt;(obj)-\u0026gt;AsMirrorPtr(); VerifyObject(result); } else { tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;JniAbortF(nullptr, \u0026#34;use of invalid jobject %p\u0026#34;, obj); expect_null = true; result = nullptr; } } else if (kind == kGlobal) { //对Global型对象的处理，想必是要交给JavaVMExt globals_来处理  result = tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;DecodeGlobal(ref); } else {//对WeakGlobal型对象的处理，如果该对象已经回收，则返回nullptr  DCHECK_EQ(kind, kWeakGlobal); result = tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;DecodeWeakGlobal(const_cast\u0026lt;Thread*\u0026gt;(this), ref); if (Runtime::Current()-\u0026gt;IsClearedJniWeakGlobal(result)) { //对象被回收了，所以返回nullptr  // This is a special case where it\u0026#39;s okay to return null.  expect_null = true; result = nullptr; } } if (UNLIKELY(!expect_null \u0026amp;\u0026amp; result == nullptr)) { tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;JniAbortF(nullptr, \u0026#34;use of deleted %s %p\u0026#34;, ToStr\u0026lt;IndirectRefKind\u0026gt;(kind).c_str(), obj); } return result; } indirect_reference_table(-inl).h IrtEntry* const table_; size_t i_; const size_t capacity_; Get template\u0026lt;ReadBarrierOption kReadBarrierOption\u0026gt; inline mirror::Object* IndirectReferenceTable::Get(IndirectRef iref) const { if (!GetChecked(iref)) { return nullptr; } uint32_t idx = ExtractIndex(iref); mirror::Object* obj = table_[idx].GetReference()-\u0026gt;Read\u0026lt;kReadBarrierOption\u0026gt;(); VerifyObject(obj); return obj; } Add IndirectRef IndirectReferenceTable::Add(uint32_t cookie, mirror::Object* obj) { // We know there\u0026#39;s enough room in the table. Now we just need to find  // the right spot. If there\u0026#39;s a hole, find it and fill it; otherwise,  // add to the end of the list.  IndirectRef result; ...... table_[index].Add(obj); result = ToIndirectRef(index); return result; ToIndirectRef /* * The object pointer itself is subject to relocation in some GC * implementations, so we shouldn\u0026#39;t really be using it here. */ IndirectRef ToIndirectRef(uint32_t tableIndex) const { DCHECK_LT(tableIndex, 65536U); uint32_t serialChunk = table_[tableIndex].GetSerial(); uintptr_t uref = (serialChunk \u0026lt;\u0026lt; 20) | (tableIndex \u0026lt;\u0026lt; 2) | kind_; return reinterpret_cast\u0026lt;IndirectRef\u0026gt;(uref); } class IrtEntry class IrtEntry { void Add(mirror::Object* obj) SHARED_REQUIRES(Locks::mutator_lock_) { ++serial_; if (serial_ == kIRTPrevCount) { serial_ = 0; } references_[serial_] = GcRoot\u0026lt;mirror::Object\u0026gt;(obj); } GcRoot\u0026lt;mirror::Object\u0026gt;* GetReference() { DCHECK_LT(serial_, kIRTPrevCount); return \u0026amp;references_[serial_]; } void SetReference(mirror::Object* obj) { DCHECK_LT(serial_, kIRTPrevCount); references_[serial_] = GcRoot\u0026lt;mirror::Object\u0026gt;(obj); } private: uint32_t serial_; GcRoot\u0026lt;mirror::Object\u0026gt; references_[kIRTPrevCount]; } Gc_root.h template\u0026lt;class MirrorType\u0026gt; class GcRoot { public: template\u0026lt;ReadBarrierOption kReadBarrierOption = kWithReadBarrier\u0026gt; ALWAYS_INLINE MirrorType* Read(GcRootSource* gc_root_source = nullptr) const SHARED_REQUIRES(Locks::mutator_lock_); art/rumtime/mirror/String.h\nmirror/String.h GetValue uint16_t value_[0]; uint16_t* GetValue() SHARED_REQUIRES(Locks::mutator_lock_) { return \u0026amp;value_[0]; } art/runtime/native/java_lang_reflect_Method.cc\nava_lang_reflect_Method.cc Method_invoke static jobject Method_invoke(JNIEnv* env, jobject javaMethod, jobject javaReceiver, jobjectArray javaArgs) { ScopedFastNativeObjectAccess soa(env); return InvokeMethod(soa, javaMethod, javaReceiver, javaArgs); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/jvm_jit/",
	"title": "JVM_JIT",
	"tags": [],
	"description": "",
	"content": "JVM解释器和编译器 JVM：JVM有自己完善的硬件架构，如处理器、堆栈（Stack）、寄存器等，还具有相应的指令系统（字节码就是一种指令格式）。JVM屏蔽了与具体操作系统平台相关的信息，使得Java程序只需要生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。JVM是Java平台无关的基础。JVM负责运行字节码：JVM把每一条要执行的字节码交给解释器，翻译成对应的机器码，然后由解释器执行。JVM解释执行字节码文件就是JVM操作Java解释器进行解释执行字节码文件的过程。\nJava编译器：将Java源文件（.java文件）编译成字节码文件（.class文件，是特殊的二进制文件，二进制字节码文件），这种字节码就是JVM的“机器语言”。javac.exe可以简单看成是Java编译器。\nJava解释器：是JVM的一部分。Java解释器用来解释执行Java编译器编译后的程序。java.exe可以简单看成是Java解释器。\n注意：通常情况下，一个平台上的二进制可执行文件不能在其他平台上工作，因为此可执行文件包含了对目标处理器的机器语言。而Class文件这种特殊的二进制文件，是可以运行在任何支持Java虚拟机的硬件平台和操作系统上的！\n维基百科定义：\nJVM：一种能够运行Java字节码（Java bytecode）的虚拟机。\n字节码：字节码是已经经过编译，但与特定机器码无关，需要解释器转译后才能成为机器码的中间代码。\nJava字节码：是Java虚拟机执行的一种指令格式。\n解释器：是一种电脑程序，能够把高级编程语言一行一行直接翻译运行。解释器不会一次把整个程序翻译出来，只像一位“中间人”，每次运行程序时都要先转成另一种语言再作运行，因此解释器的程序运行速度比较缓慢。它每翻译一行程序叙述就立刻运行，然后再翻译下一行，再运行，如此不停地进行下去。它会先将源码翻译成另一种语言，以供多次运行而无需再经编译。其制成品无需依赖编译器而运行，程序运行速度比较快。\n即时编译(Just-in-time compilation: JIT)：又叫实时编译、及时编译。是指一种在运行时期把字节码编译成原生机器码的技术，一句一句翻译源代码，但是会将翻译过的代码缓存起来以降低性能耗损。这项技术是被用来改善虚拟机的性能的。\nJIT编译器是JRE的一部分。原本的Java程序都是要经过解释执行的，其执行速度肯定比可执行的二进制字节码程序慢。为了提高执行速度，引入了JIT。在运行时，JIT会把翻译过来的机器码保存起来，以备下次使用。而如果JIT对每条字节码都进行编译，则会负担过重，所以，JIT只会对经常执行的字节码进行编译，如循环，高频度使用的方法等。它会以整个方法为单位，一次性将整个方法的字节码编译为本地机器码，然后直接运行编译后的机器码。\n 深入理解java虚拟机（程序编译与代码优化）\n编译对象与触发条件 编译对象 程序在运行过程中会被即时编译器编译的「热点代码」有两类：\n 被多次调用的方法； 被多次执行的循环体。 这两种被多次重复执行的代码，称之为「热点代码」。  对于被多次调用的方法，方法体内的代码自然会被执行多次，理所当然的就是热点代码。\n而对于多次执行的循环体则是为了解决一个方法只被调用一次或者少量几次，但是方法体内部存在循环次数较多的循环体问题，这样循环体的代码也被重复执行多次，因此这些代码也是热点代码。\n对于第一种情况，由于是方法调用触发的编译，因此编译器理所当然地会以整个方法作为编译对象，这种编译也是虚拟机中标准的 JIT 编译方式。而对于后一种情况，尽管编译动作是由循环体所触发的，但是编译器依然会以整个方法（而不是单独的循环体）作为编译对象。这种编译方式因为发生在方法执行过程中，因此形象地称之为栈上替换（On Stack Replacement，简称 OSR 编译，即方法栈帧还在栈上，方法就被替换了）。\n即时编译器的触发条件 判断一段代码是不是热点代码，是不是需要触发即时编译，这样的行为称为「热点探测」。其实进行热点探测并不一定需要知道方法具体被调用了多少次，目前主要的热点探测判定方式有两种。\n  基于采样的热点探测：采用这种方法的虚拟机会周期性地检查各个线程栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是「热点方法」。基于采样的热点探测的好处是实现简单、高效，还可以很容易地获取方法调用关系（将调用栈展开即可），缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因数的影响而扰乱热点探测。\n  基于计数器的热点探测：采用这种方法的虚拟机会为每个方法（甚至代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是「热点方法」。这种统计方法实现起来麻烦一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是统计结果相对来说更加精确和严谨。\n  HotSpot 虚拟机采用的是第二种：基于计数器的热点探测。因此它为每个方法准备了两类计数器：方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）。在确定虚拟机运行参数的情况下，这两个计数器都有一个确定的阈值，当计数器超过阈值就会触发 JIT 编译。\n方法调用计数器 顾名思义，这个计数器用于统计方法被调用的次数。当一个方法被调用时，会首先检查该方法是否存在被 JIT 编译过的版本，如果存在，则优先使用编译后的本地代码来执行。如果不存在，则将此方法的调用计数器加 1，==然后判断方法调用计数器与回边计数器之和是否超过方法调用计数器的阈值==。如果超过阈值，将会向即时编译器提交一个该方法的代码编译请求。\n如果不做任何设置，执行引擎不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成。当编译完成后，这个方法的调用入口地址就会被系统自动改写成新的，下一次调用该方法时就会使用已编译的版本。\n热度衰减 如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间内方法调用的次数。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的调用计数器值就会被减少一半，这个过程称为方法调用计数器热度的衰减，而这段时间就称为此方法统计的==半衰期==。\n进行热度衰减的动作是在虚拟机进行 GC 时顺便进行的，可以设置虚拟机参数来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。此外还可以设置虚拟机参数调整半衰期的时间。\n回边计数器 回边计数器的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为「回边」（Back Edge）。建立回边计数器统计的目的是为了触发 OSR 编译。\n当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否已经有编译好的版本，如果有，它将优先执行已编译的代码，否则就把回边计数器值加 1，然后判断方法调用计数器和回边计数器值之和是否超过计数器的阈值。当超过阈值时，将会提交一个 OSR 编译请求，并且把回边计数器的值降低一些，以便继续在解释器中执行循环，等待编译器输出编译结果。\n与方法计数器不同，回边计数器没有计算热度衰减的过程，因此这个计数器统计的就是该方法循环执行的绝对次数。当计数器溢出时，它还会把方法计数器的值也调整到溢出状态，这样下次再进入该方法的时候就会执行标准编译过程。\n编译优化技术 我们都知道，以编译方式执行本地代码比解释执行方式更快，一方面是因为节约了虚拟机解释执行字节码额外消耗的时间；另一方面是因为虚拟机设计团队几乎把所有对代码的优化措施都集中到了即时编译器中。这一小节我们来介绍下 HotSpot 虚拟机的即时编译器在编译代码时采用的优化技术。\n方法内联 第一步是进行方法内联（Method Inlining），方法内联的重要性要高于其它优化措施。方法内联的目的主要有两个，一是去除方法调用的成本（比如建立栈帧），二是为其它优化建立良好的基础，方法内联膨胀之后可以便于更大范围上采取后续的优化手段，从而获得更好的优化效果。因此，各种编译器一般都会把内联优化放在优化序列的最前面\n冗余消除 第二步进行冗余消除\n复写传播 第三步进行复写传播\n无用代码消除 第四步进行无用代码消除\n 公共子表达式消除； 数组边界检查消除； 方法内联； 逃逸分析。  JIT Code Cache https://docs.oracle.com/javase/8/embedded/develop-apps-platforms/codecache.htm\n15 Codecache Tuning This chapter describes techniques for reducing the just-in-time (JIT) compiler\u0026rsquo;s consumption of memory in the codecache, where it stores compiled methods.\nThis chapter contains the following topics:\nIntroduction\njava Launcher Codecache Option Summary\nMeasuring Codecache Usage\nConstraining the Codecache Size\nReducing Compilations\nReducing Compiled Method Sizes\nIntroduction The Java Virtual Machine (JVM) generates native code and ==stores it in a memory area called the codecache==. The JVM generates native code for a variety of reasons, including for the dynamically generated interpreter loop, Java Native Interface (JNI) stubs, and for Java methods that are compiled into native code by the just-in-time (JIT) compiler. The JIT is by far the biggest user of the codecache. This appendix describes techniques for reducing the JIT compiler\u0026rsquo;s codecache usage while still maintaining good performance.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/kernel/",
	"title": "kernel",
	"tags": [],
	"description": "",
	"content": "kernel 探索总结kernel知识\n kernel     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/kernel/kernel/",
	"title": "kernel",
	"tags": [],
	"description": "",
	"content": "下载和编译内核步骤 Android 9.0内核编译\n下载内核 cd kernel git clone https://android.googlesource.com/kernel/goldfish 执行完这两条命令后就可以看到kernel目录下有一个goldfish目录了,goldfish内核专门是提供给emulator用的.\ncd goldfish git branch -r git checkout origin/android-goldfish-4.4-dev -b android-goldfish-4.4-dev 这里涉及到要下载哪个版本的内核,emulator命令默认用的是qemu内核, 一般跟这个版本的内核一样就可以了,可以直接启用emulator然后进入到Settings-\u0026gt;System-\u0026gt;About phone-\u0026gt;点击Android version,里面就有内核版本号.\n编译内核 一定要和Android编译时lunch选的一样, 可以进入到out/target/product目录下查看自己编的是什么版本, 如果是generic_x86_64,那lunch的就是aosp_x86_64_eng的,其他版本依此类推. 接下来就可以编译了,下面我提供了几个编译的脚本大家可以进行对比和参照,lunch不同的版本对应的脚本是不一样的,即使编译通过了,也不能运行,我因为这个浪费了很长的时间 使用方法:\n 在goldfish目录下创建一个build.sh文件 将脚本里面的内容复制到build.sh中,或者根据脚本自己写, 注意lunch的版本 执行chmod a+rx build.sh并且执行./build.sh.  aosp_x86-eng #指定编译的内核类型 export ARCH=x86 #指定的gcc编译器的前缀, 就是下面PATH中的x86_64-linux-android-4.9的前缀 export CROSS_COMPILE=x86_64-linux-android- export REAL_CROSS_COMPILE=x86_64-linux-android- #这里android_root要写是android根目录的绝对地址例如: ~/google/android-9.0 PATH=$PATH:/home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gcc/linux-x86/x86/x86_64-linux-android-4.9/bin #编译的配置,在arch/x86/configs目录下, make x86_64_ranchu_defconfig #编译内核命令 make -j16 编译内核大概10来分钟就可以完成了,之后会生成一个arch/x86_64/boot/bzImage的东西,不同kernel生成的是不一样的,要看清楚. 最后回到android根目录执行emulator -kernel kernel/goldfish/arch/x86/boot/bzImage启动虚拟机\n启动虚拟机 ~/Android/Source/android-9.0.0_r3$ emulator -show-kernel -kernel /home/zhenghuan/Android/Source/kernel/goldfish/arch/x86/boot/bzImage -qemu -s  -kernel use specific emulated kernel 指定模拟器的内核，这里指定我们自己编译的内核arch/x86/boot/bzImage -qemu args... pass arguments to qemu 传递qemu参数，emulator就是基于qemu开发的 -s 是qemu参数，等同于-gdb tcp::1234，意思就是通过tcp的1234端口，gdb可以连接到内核中的kgdb。一般连接kgdb都要通过串口来连接，但是qemu通过指定-gdb tcp::1234就可以了，不知到原理是什么。  调试android内核 使用Android模拟器调试linux内核\n如何在Android上调试内核 在Android上调试内核，一般都要借助于内核中的kgdb。kgdb是内核对gdb的支持，通过编译配置kgdb和其他相关配置，可以通过gdb远程连接到内核中的kgdb。kgdb只能远程调试，也就是说，要有一台被调试的机器(target machine)和一台开发机器(develop machine)。如果真机调试，target就是手机，develop就是ubuntu主机。如果是模拟器调试，target就是模拟器，develop是ubuntu主机。\n步骤 goldfish/.config编译选项 CONFIG_DEBUG_KERNEL=y 打开这个选项后，vmlinux 才有符号 CONFIG_DEBUG_INFO=y CONFIG_FRAME_POINTER=y //开启kgdb CONFIG_KGDB=y CONFIG_DEBUG_RODATA=n CONFIG_RANDOMIZE_BASE=n CONFIG_DEBUG_RODATA这个选项我们虽然手动设置为n，但是执行make后会被覆盖，所以我们要改以下两个文件，确保CONFIG_DEBUG_RODATA不开启:\nzhangjg@zjg:~/deve/open_source/android-kernel/goldfish$ git diff diff --git a/arch/arm/mm/Kconfig b/arch/arm/mm/Kconfig index 41218867a9a6..e67810313d97 100644 --- a/arch/arm/mm/Kconfig +++ b/arch/arm/mm/Kconfig @@ -1052,7 +1052,7 @@ config ARM_KERNMEM_PERMS config DEBUG_RODATA bool \u0026#34;Make kernel text and rodata read-only\u0026#34; depends on ARM_KERNMEM_PERMS - default y + default n help If this is set, kernel text and rodata will be made read-only. This is to help catch accidental or malicious attempts to change the diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig index ad1f3bfafe75..50fa4dc68eff 100644 --- a/arch/x86/Kconfig +++ b/arch/x86/Kconfig @@ -307,7 +307,7 @@ config FIX_EARLYCON_MEM def_bool y config DEBUG_RODATA - def_bool y + def_bool n config PGTABLE_LEVELS int 注意，一定确保CONFIG_DEBUG_RODATA和CONFIG_RANDOMIZE_BASE不开启，如果开启这两个选项，通过gdb不能设置断点，报如下错误:\n(gdb) b vfs_write Breakpoint 1 at 0xffffffff803474d8: file fs/read_write.c, line 524. (gdb) c Continuing. Warning: Cannot insert breakpoint 1. Cannot access memory at address 0xffffffff803474d8 make -j16 Serial console over KGDB NMI debugger port (SERIAL_KGDB_NMI) [N/y/?] (NEW) N KGDB: kernel debugger (KGDB) [Y/n/?] y KGDB: use kgdb over the serial console (KGDB_SERIAL_CONSOLE) [Y/n/m/?] (NEW) n KGDB: internal test suite (KGDB_TESTS) [N/y/?] (NEW) N KGDB: Allow debugging with traps in notifiers (KGDB_LOW_LEVEL_TRAP) [N/y/?] (NEW) N KGDB_KDB: include kdb frontend for kgdb (KGDB_KDB) [N/y/?] (NEW) y KDB: Select kdb command functions to be enabled by default (KDB_DEFAULT_ENABLE) [0x1] (NEW) 0x1 KGDB_KDB: keyboard as input device (KDB_KEYBOARD) [N/y/?] (NEW) y KDB: continue after catastrophic errors (KDB_CONTINUE_CATASTROPHIC) [0] (NEW) 0 Kernel: arch/x86/boot/bzImage is ready (#2) ton在内核源码根目录生成vmlinux文件 启动虚拟机(见上部) gdb /path/to/vmlinux 最好使用aosp/prebuilts/gdb/linux-x86里的gdb，这个版本的gdb是兼容所有体系结构的。 gdb命令在aosp/prebuilts/gdb/linux-x86/bin目录中\n~/Android/Source/kernel/goldfish$ export PATH=/home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gdb/linux-x86/bin:$PATH ~/Android/Source/kernel/goldfish$ which gdb /home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gdb/linux-x86/bin/gdb ~/Android/Source/kernel/goldfish$ gdb ./vmlinux GNU gdb (GDB) 7.11 Copyright (C) 2016 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-linux-gnu\u0026#34;. Type \u0026#34;show configuration\u0026#34; for configuration details. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;. Find the GDB manual and other documentation resources online at: \u0026lt;http://www.gnu.org/software/gdb/documentation/\u0026gt;. For help, type \u0026#34;help\u0026#34;. Type \u0026#34;apropos word\u0026#34; to search for commands related to \u0026#34;word\u0026#34;... Reading symbols from ./vmlinux...done. (gdb) target remote :1234 Remote debugging using :1234 0xffffffff834345e8 in ?? () (gdb) bt #0 0xffffffff834345e8 in ?? () #1 0xffffffff84003ec8 in ?? () #2 0xffffffff8340c0d9 in ?? () #3 0x0000000000000000 in ?? () 调试效果 可以设置断点并进入断点停下，但无法next和step(step有概率能成功)单步跳转,总是跳转到apic模块，考虑使用走读+断点调试的方式研究\n其他 全局修改编译优化，位于goldfish/Makefile:\n#ifdef CONFIG_CC_OPTIMIZE_FOR_SIZE #KBUILD_CFLAGS\t+= $(call cc-option,-Oz,-Os) #else #ifdef CONFIG_PROFILE_ALL_BRANCHES #KBUILD_CFLAGS\t+= -O2 #else #KBUILD_CFLAGS += -O2 #endif #endif KBUILD_CFLAGS += -Og  https://github.com/torvalds/linux\nhttps://source.android.com/setup/build/building-kernels\nhttps://source.android.com/devices/architecture/kernel\nhttps://android.googlesource.com/kernel/common/\n下载时Repo Branches选择common-android-4.14\nBuilding Kernels This page details the process of building custom kernels for Android devices. The following instructions guide you through the process of selecting the right sources, building the kernel, and embedding the results into a system image built from the Android Open Source Project (AOSP).\n android版本与linux内核版本对应关系\nhttps://blog.csdn.net/ly890700/article/details/75040704/\n6.0 Marshmallow |23 |3.18.10\nAndroid安卓版本 | API级别 | Linux内核版本 ——————————————————————- 1.5 Cupcake | 3 | 2.6.27 1.6 Donut | 4 | 2.6.29 2.0/1 Eclair | 5-7 | 2.6.29 2.2.x Froyo | 8 | 2.6.32 2.3.x Gingerbread | 9, 10 | 2.6.35 3.x.x Honeycomb | 11-13 | 2.6.36 4.0.x Ice Cream San | 14, 15 | 3.0.1 4.1.x Jelly Bean | 16 | 3.0.31 4.2.x Jelly Bean | 17 | 3.4.0 4.3 Jelly Bean | 18 | 3.4.39 4.4 Kit Kat | 19, 20 | 3.10 5.x Lollipop | 21, 22 | 3.16.1 6.0 Marshmallow | 23 | 3.18.10 7.0 Nougat | 24 | 4.4.1 7.1 Nougat | 25 | 4.4.1 8.0 Oreo | 26 | 4.10 8.1 Oreo | 27 | 4.10 9.0 Pie | 28 | 4.4, 4.9 and 4.14\n"
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/",
	"title": "kotlin",
	"tags": [],
	"description": "",
	"content": "kotlin 探索总结kotlin知识\n 协程    kotlin协程     kotlin协程Source      "
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/%E5%8D%8F%E7%A8%8B/kotlin%E5%8D%8F%E7%A8%8B/",
	"title": "kotlin协程",
	"tags": [],
	"description": "",
	"content": "协程是通过编译技术实现(不需要虚拟机VM/操作系统OS的支持),通过插入相关代码来生效！ 与之相反,线程/进程是需要虚拟机VM/操作系统OS的支持,通过调度CPU执行生效!\n优秀文章 Kotlin Coroutines(协程) 完全解析（一），协程简介\nKotlin Coroutines(协程) 完全解析（二），深入理解协程的挂起、恢复与调度\nKotlin Coroutines(协程) 完全解析（三），封装异步回调、协程间关系及协程的取消\nKotlin Coroutines(协程) 完全解析（四），协程的异常处理\nKotlin Coroutines(协程) 完全解析（五），协程的并发\n谷歌开发者 在 android 开发中使用协程 | 背景介绍\n在 View 上使用挂起函数\n协程中的取消和异常 | 异常处理详解\n官网doc 英文:\nhttps://kotlinlang.org/docs/reference/coroutines/basics.html\nhttps://github.com/Kotlin/kotlinx.coroutines/blob/master/docs/coroutines-guide.md\nhttps://github.com/Kotlin/KEEP/blob/master/proposals/coroutines.md\n中文:\nhttps://www.kotlincn.net/docs/reference/coroutines/coroutines-guide.html\n和Android Jetpack结合 https://developer.android.com/topic/libraries/architecture/coroutines#lifecyclescope\n异步编程模型 异步的含义是被调用的方法执行完之后，无法直接拿到返回值(切换了线程)，需要通过回调接收返回值\n协程相当于提前切换到子线程，然后同步走逻辑，进而改变每一层的异步调用为同步，\n协程将同步方法和线程切换两者相隔离，所有方法都是同步方法，单独控制执行线程，避免异步方法去接收回调参数\n区别：\n 回调调用时机: 回调接口可以有多个method，并在不同时机调用(对应的也可以在return对象中区分处理) 回调方法参数: 可以封装成method的return参数， 调用方上下文: 需要利用调用方的上下文(提供变量等)  异步回调 fun requestTokenAsync(cb: (Token) -\u0026gt; Unit) { ... } fun createPostAsync(token: Token, item: Item, cb: (Post) -\u0026gt; Unit) { ... } fun processPost(post: Post) { ... } fun postItem(item: Item) { requestTokenAsync { token -\u0026gt; createPostAsync(token, item) { post -\u0026gt; processPost(post) } } } CompletableFuture and Rx fun requestTokenAsync(): CompletableFuture\u0026lt;Token\u0026gt; { ... } fun createPostAsync(token: Token, item: Item): CompletableFuture\u0026lt;Post\u0026gt; { ... } fun processPost(post: Post) { ... } fun postItem(item: Item) { requestTokenAsync() .thenCompose { token -\u0026gt; createPostAsync(token, item) } .thenAccept { post -\u0026gt; processPost(post) } .exceptionally { e -\u0026gt; e.printStackTrace() null } } fun requestToken(): Token { ... } fun createPost(token: Token, item: Item): Post { ... } fun processPost(post: Post) { ... } fun postItem(item: Item) { Single.fromCallable { requestToken() } .map { token -\u0026gt; createPost(token, item) } .subscribe( { post -\u0026gt; processPost(post) }, // onSuccess  { e -\u0026gt; e.printStackTrace() } // onError  ) } 协程-同步函数返回 suspend fun requestToken(): Token { ... } // 挂起函数 suspend fun createPost(token: Token, item: Item): Post { ... } // 挂起函数 fun processPost(post: Post) { ... } fun postItem(item: Item) { GlobalScope.launch { val token = requestToken() val post = createPost(token, item) processPost(post) // 需要异常处理，直接加上 try/catch 语句即可  } } 协程恢复resume 协程的挂起通过suspend挂起函数实现，协程的恢复通过Continuation.resumeWith实现。\nsuspend fun requestToken(): Token { ... } 实际上在 JVM 中更像下面这样：\nObject requestToken(Continuation\u0026lt;Token\u0026gt; cont) { ... } Continuation的定义如下，类似于一个通用的回调接口：\n/** * Interface representing a continuation after a suspension point that returns value of type `T`. */ public interface Continuation\u0026lt;in T\u0026gt; { /** * Context of the coroutine that corresponds to this continuation. */ public val context: CoroutineContext /** * Resumes the execution of the corresponding coroutine passing successful or failed [result] as the * return value of the last suspension point. */ public fun resumeWith(result: Result\u0026lt;T\u0026gt;) } 现在再看之前postItem函数：\nsuspend fun requestToken(): Token { ... } // 挂起函数 suspend fun createPost(token: Token, item: Item): Post { ... } // 挂起函数 fun processPost(post: Post) { ... } fun postItem(item: Item) { GlobalScope.launch { val token = requestToken() val post = createPost(token, item) processPost(post) } } 然而，协程内部实现不是使用普通回调的形式，而是使用状态机来处理不同的挂起点，大致的 CPS(Continuation Passing Style) 代码为：\n// 编译后生成的内部类大致如下 final class postItem$1 extends SuspendLambda ... { public final Object invokeSuspend(Object result) { ... switch (this.label) { case 0: this.label = 1; token = requestToken(this) break; case 1: this.label = 2; Token token = result; post = createPost(token, this.item, this) break; case 2: Post post = result; processPost(post) break; } } } 上面代码中每一个挂起点和初始挂起点对应的 Continuation 都会转化为一种状态，协程恢复只是跳转到下一种状态中。挂起函数将执行过程分为多个 Continuation 片段，并且利用状态机的方式保证各个片段是顺序执行的。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/%E5%8D%8F%E7%A8%8B/kotlin%E5%8D%8F%E7%A8%8Bsource/",
	"title": "kotlin协程Source",
	"tags": [],
	"description": "",
	"content": "总结 类设计 协程的三层包装  常用的launch和async返回的Job、Deferred，里面封装了协程状态，提供了取消协程接口，而它们的实例都是继承自AbstractCoroutine，它是协程的第一层包装。 第二层包装是编译器生成的SuspendLambda的子类，封装了协程的真正运算逻辑，继承自BaseContinuationImpl，其中completion属性就是协程的第一层包装。 第三层包装是前面分析协程的线程调度时提到的DispatchedContinuation，封装了线程调度逻辑，包含了协程的第二层包装。三层包装都实现了Continuation接口，通过代理模式将协程的各层包装组合在一起，每层负责不同的功能。  resumeWith CoroutineContext graph LR coroutineContext--\u0026gt;Element1[\u0026quot;Element1: a singleton context by itself.\u0026quot;] coroutineContext--\u0026gt;Element2[\u0026quot;Element2: a singleton context by itself.\u0026quot;] coroutineContext--\u0026gt;ContinuationInterceptor[\u0026quot;ContinuationInterceptor: DefaultDispatcher.\u0026quot;] coroutineContext--\u0026gt;ElementXxx[\u0026quot;ElementXxx: a singleton context by itself.\u0026quot;] Coroutine构造和启动 CoroutineScope.launch public val coroutineContext: CoroutineContext launch本质上也是将用户配置的协程闭包作为一个suspend函数(()-\u0026gt;Unit),并将该函数在指定的dispatcher上执行，和withContext类似\npublic fun CoroutineScope.launch( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; Unit ): Job { val newContext = newCoroutineContext(context) val coroutine = if (start.isLazy) LazyStandaloneCoroutine(newContext, block) else StandaloneCoroutine(newContext, active = true) coroutine.start(start, coroutine, block)//main  return coroutine } CoroutineScope.newCoroutineContext intercepted过程会用到(context[ContinuationInterceptor]: DefaultScheduler实例DefaultDispatcher作为后续resume时的线程调度器\npublic actual fun CoroutineScope.newCoroutineContext(context: CoroutineContext): CoroutineContext { val combined = coroutineContext + context val debug = if (DEBUG) combined + CoroutineId(COROUTINE_ID.incrementAndGet()) else combined return if (combined !== Dispatchers.Default \u0026amp;\u0026amp; combined[ContinuationInterceptor] == null) debug + Dispatchers.Default else debug } coroutine.start CoroutineStart.start\u0026ndash;\u0026gt;invoke\npublic operator fun \u0026lt;R, T\u0026gt; invoke(block: suspend R.() -\u0026gt; T, receiver: R, completion: Continuation\u0026lt;T\u0026gt;) = when (this) { //receiver and completion both are StandaloneCoroutine instance,same one  CoroutineStart.DEFAULT -\u0026gt; block.startCoroutineCancellable(receiver, completion)//main  CoroutineStart.ATOMIC -\u0026gt; block.startCoroutine(receiver, completion) CoroutineStart.UNDISPATCHED -\u0026gt; block.startCoroutineUndispatched(receiver, completion) CoroutineStart.LAZY -\u0026gt; Unit // will start lazily  } commonMain\\intrinsics\\Cancellable.kt\n/** * Use this function to start coroutine in a cancellable way, so that it can be cancelled * while waiting to be dispatched. */ internal fun \u0026lt;R, T\u0026gt; (suspend (R) -\u0026gt; T).startCoroutineCancellable(receiver: R, completion: Continuation\u0026lt;T\u0026gt;) = runSafely(completion) { createCoroutineUnintercepted(receiver, completion).intercepted().resumeCancellable(Unit) } private inline fun runSafely(completion: Continuation\u0026lt;*\u0026gt;, block: () -\u0026gt; Unit) { try { block() } catch (e: Throwable) { completion.resumeWith(Result.failure(e)) } } kotlin/coroutines/intrinsics/IntrinsicsJvm.kt\n(suspend R.() -\u0026gt; T).createCoroutineUnintercepted public actual fun \u0026lt;R, T\u0026gt; (suspend R.() -\u0026gt; T).createCoroutineUnintercepted( receiver: R, completion: Continuation\u0026lt;T\u0026gt; ): Continuation\u0026lt;Unit\u0026gt; { val probeCompletion = probeCoroutineCreated(completion) return if (this is BaseContinuationImpl) create(receiver, probeCompletion)//main,receiver和probeCompletion都是StandaloneCoroutine{Active}@7e4d11a  else { createCoroutineFromSuspendFunction(probeCompletion) { (this as Function2\u0026lt;R, Continuation\u0026lt;T\u0026gt;, Any?\u0026gt;).invoke(receiver, it) } } } // Suspension lambdas inherit from this class internal abstract class SuspendLambda( public override val arity: Int, completion: Continuation\u0026lt;Any?\u0026gt;? ) : ContinuationImpl(completion), FunctionBase\u0026lt;Any?\u0026gt;, SuspendFunction { kotlin协程编译产物 build/tmp/kotlin-classes/debug/com/xxx/CoroutineTest.class\n使用jd-gui打开,对比\nobject CoroutineTest { fun test() { GlobalScope.launch(Dispatchers.Main.immediate) { println(\u0026#34;I\u0026#39;m sleeping ... thread name = ${Thread.currentThread().name}\u0026#34;) delay(500L)//release current thread while suspend current coroutine  println(\u0026#34;I\u0026#39;m sleeping over ... thread name = ${Thread.currentThread().name}\u0026#34;) } println(\u0026#34;finished thread name = ${Thread.currentThread().name}\u0026#34;) } } 对应\npublic final class CoroutineTest { public final void test() { BuildersKt.launch$default((CoroutineScope)GlobalScope.INSTANCE, (CoroutineContext)Dispatchers.getMain().getImmediate(), null, new CoroutineTest$test$1(null), 2, null); Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); String str = \u0026#34;finished thread name = \u0026#34; + Thread.currentThread().getName(); boolean bool = false; System.out.println(str); } static final class CoroutineTest$test$1 extends SuspendLambda implements Function2\u0026lt;CoroutineScope, Continuation\u0026lt;? super Unit\u0026gt;, Object\u0026gt; { private CoroutineScope p$; Object L$0; int label; @Nullable public final Object invokeSuspend(@NotNull Object $result) { CoroutineScope $this$launch; String str; boolean bool; Object object = IntrinsicsKt.getCOROUTINE_SUSPENDED(); switch (this.label) { case 0: ResultKt.throwOnFailure($result); $this$launch = this.p$; Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); str = \u0026#34;I\u0026#39;m sleeping ... thread name = \u0026#34; + Thread.currentThread().getName(); bool = false; System.out.println(str); this.L$0 = $this$launch; this.label = 1; if (DelayKt.delay(500L, (Continuation)this) == object) return object; DelayKt.delay(500L, (Continuation)this); Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); str = \u0026#34;I\u0026#39;m sleeping over ... thread name = \u0026#34; + Thread.currentThread().getName(); bool = false; System.out.println(str); return Unit.INSTANCE; case 1: $this$launch = (CoroutineScope)this.L$0; ResultKt.throwOnFailure($result); Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); str = \u0026#34;I\u0026#39;m sleeping over ... thread name = \u0026#34; + Thread.currentThread().getName(); bool = false; System.out.println(str); return Unit.INSTANCE; } throw new IllegalStateException(\u0026#34;call to \u0026#39;resume\u0026#39; before \u0026#39;invoke\u0026#39; with coroutine\u0026#34;); } ContinuationImpl.intercepted() public actual fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.intercepted(): Continuation\u0026lt;T\u0026gt; = (this as? ContinuationImpl)?.intercepted() ?: this // State machines for named suspend functions extend from this class internal abstract class ContinuationImpl( completion: Continuation\u0026lt;Any?\u0026gt;?, private val _context: CoroutineContext? ) : BaseContinuationImpl(completion) { constructor(completion: Continuation\u0026lt;Any?\u0026gt;?) : this(completion, completion?.context) public override val context: CoroutineContext get() = _context!! @Transient private var intercepted: Continuation\u0026lt;Any?\u0026gt;? = null public fun intercepted(): Continuation\u0026lt;Any?\u0026gt; = //context是combineContext：[StandaloneCoroutine{Active}@7e4d11a, DefaultDispatcher]  //(context[ContinuationInterceptor]返回DefaultScheduler实例DefaultDispatcher  intercepted ?: (context[ContinuationInterceptor]?.interceptContinuation(this) ?: this) .also { intercepted = it } CoroutineDispatcher.interceptContinuation\npublic final override fun \u0026lt;T\u0026gt; interceptContinuation(continuation: Continuation\u0026lt;T\u0026gt;): Continuation\u0026lt;T\u0026gt; = DispatchedContinuation(this, continuation) DispatchedContinuation.resumeCancellable internal fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeCancellable(value: T) = when (this) { is DispatchedContinuation -\u0026gt; resumeCancellable(value) else -\u0026gt; resume(value) } inline fun resumeCancellable(value: T) { if (dispatcher.isDispatchNeeded(context)) { _state = value resumeMode = MODE_CANCELLABLE dispatcher.dispatch(context, this) } else { executeUnconfined(value, MODE_CANCELLABLE) { if (!resumeCancelled()) { resumeUndispatched(value) } } } } override fun dispatch(context: CoroutineContext, block: Runnable): Unit = try { coroutineScheduler.dispatch(block) } catch (e: RejectedExecutionException) { DefaultExecutor.dispatch(context, block) } fun dispatch(block: Runnable, taskContext: TaskContext = NonBlockingContext, fair: Boolean = false) { trackTask() // this is needed for virtual time support  val task = createTask(block, taskContext) // try to submit the task to the local queue and act depending on the result  when (submitToLocalQueue(task, fair)) { ADDED -\u0026gt; return NOT_ADDED -\u0026gt; { // try to offload task to global queue  if (!globalQueue.addLast(task)) {//main  // Global queue is closed in the last step of close/shutdown -- no more tasks should be accepted  throw RejectedExecutionException(\u0026#34;$schedulerNamewas terminated\u0026#34;) } requestCpuWorker() } else -\u0026gt; requestCpuWorker() // ask for help  } } fun addLast(element: E): Boolean { _cur.loop { cur -\u0026gt; when (cur.addLast(element)) { Core.ADD_SUCCESS -\u0026gt; return true Core.ADD_CLOSED -\u0026gt; return false Core.ADD_FROZEN -\u0026gt; _cur.compareAndSet(cur, cur.next()) // move to next  } } } 线程调度 jvmMain\\scheduling\\CoroutineScheduler.kt\ninternal inner class Worker private constructor() : Thread() { override fun run() { var wasIdle = false // local variable to avoid extra idleReset invocations when tasks repeatedly arrive  while (!isTerminated \u0026amp;\u0026amp; state != WorkerState.TERMINATED) { val task = findTask() if (task == null) { // Wait for a job with potential park  if (state == WorkerState.CPU_ACQUIRED) { cpuWorkerIdle() } else { blockingWorkerIdle() } wasIdle = true } else { // Note: read task.mode before running the task, because Task object will be reused after run  val taskMode = task.mode if (wasIdle) { idleReset(taskMode) wasIdle = false } beforeTask(taskMode, task.submissionTime) runSafely(task)//main  afterTask(taskMode) } } tryReleaseCpu(WorkerState.TERMINATED) } } internal fun findTask(): Task? { if (tryAcquireCpuPermit()) return findTaskWithCpuPermit() /* * If the local queue is empty, try to extract blocking task from global queue. * It\u0026#39;s helpful for two reasons: * 1) We won\u0026#39;t call excess park/unpark here and someone\u0026#39;s else CPU token won\u0026#39;t be transferred, * which is a performance win * 2) It helps with rare race when external submitter sends depending blocking tasks * one by one and one of the requested workers may miss CPU token */ return localQueue.poll() ?: globalQueue.removeFirstWithModeOrNull(TaskMode.PROBABLY_BLOCKING) } CoroutineScheduler.runSafely\nprivate fun runSafely(task: Task) { try { task.run() } catch (e: Throwable) { val thread = Thread.currentThread() thread.uncaughtExceptionHandler.uncaughtException(thread, e) } finally { unTrackTask() } } runTask resume过程参考visio类图\nresumewith\nDispatchedTask\u0026lt;in T\u0026gt;\npublic final override fun run() { val taskContext = this.taskContext try { val delegate = delegate as DispatchedContinuation\u0026lt;T\u0026gt; //continuation为BaseContinuationImpl子类，实现对第二层的代理  val continuation = delegate.continuation val context = continuation.context val job = if (resumeMode.isCancellableMode) context[Job] else null val state = takeState() // NOTE: Must take state in any case, even if cancelled  withCoroutineContext(context, delegate.countOrElement) { if (job != null \u0026amp;\u0026amp; !job.isActive) continuation.resumeWithException(job.getCancellationException()) else { val exception = getExceptionalResult(state) if (exception != null) continuation.*resumeWithStackTrace*(exception) else //调用resumeWith(Result.success(value))  continuation.resume(getSuccessfulResult(state))//main  } } } catch (e: Throwable) { throw DispatchException(\u0026#34;Unexpected exception running $this\u0026#34;, e) } finally { taskContext.afterTask() } SuspendLambda_resumeWith //BaseContinuationImpl //封装了协程的运算逻辑，用以协程的启动和恢复 public final override fun resumeWith(result: Result\u0026lt;Any?\u0026gt;) { // This loop unrolls recursion in current.resumeWith(param) to make saner and shorter stack traces on resume  var current = this var param = result while (true) { // Invoke \u0026#34;resume\u0026#34; debug probe on every resumed continuation, so that a debugging library infrastructure  // can precisely track what part of suspended callstack was already resumed  probeCoroutineResumed(current) with(current) { val completion = completion!! // fail fast when trying to resume continuation without completion  val outcome: Result\u0026lt;Any?\u0026gt; = try { val outcome = invokeSuspend(param)//main  if (outcome === COROUTINE_SUSPENDED) return Result.success(outcome) } catch (exception: Throwable) { Result.failure(exception) } releaseIntercepted() // this state machine instance is terminating  if (completion is BaseContinuationImpl) { // unrolling recursion via loop  current = completion param = outcome } else {//是AbstractCoroutine实例时  // top-level completion reached -- invoke and return  //completion为AbstractCoroutine实例，实现对第一层的代理  completion.resumeWith(outcome) return } } } } withContext public suspend fun \u0026lt;T\u0026gt; withContext( context: CoroutineContext, block: suspend CoroutineScope.() -\u0026gt; T ): T = suspendCoroutineUninterceptedOrReturn sc@ { uCont -\u0026gt; // compute new context  val oldContext = uCont.context val newContext = oldContext + context // always check for cancellation of new context  newContext.checkCompletion() // FAST PATH #1 -- new context is the same as the old one  if (newContext === oldContext) { val coroutine = ScopeCoroutine(newContext, uCont) // MODE_DIRECT  return@sc coroutine.startUndispatchedOrReturn(coroutine, block) } // FAST PATH #2 -- the new dispatcher is the same as the old one (something else changed)  // `equals` is used by design (see equals implementation is wrapper context like ExecutorCoroutineDispatcher)  if (newContext[ContinuationInterceptor] == oldContext[ContinuationInterceptor]) { val coroutine = UndispatchedCoroutine(newContext, uCont) // MODE_UNDISPATCHED  // There are changes in the context, so this thread needs to be updated  withCoroutineContext(newContext, null) { return@sc coroutine.startUndispatchedOrReturn(coroutine, block) } } // SLOW PATH -- use new dispatcher  val coroutine = DispatchedCoroutine(newContext, uCont) // MODE_CANCELLABLE,传递uCont用于在old dispatcher上resume  coroutine.initParentJob() block.startCoroutineCancellable(coroutine, coroutine)//该方法和launch时的主流程类似，恢复流程由DispatchedCoroutine指定  coroutine.getResult() } dispatched // Used by withContext when context dispatcher changes private class DispatchedCoroutine\u0026lt;in T\u0026gt;( context: CoroutineContext, uCont: Continuation\u0026lt;T\u0026gt; ) : ScopeCoroutine\u0026lt;T\u0026gt;(context, uCont) { 监听completion通知，执行resume internal open class ScopeCoroutine\u0026lt;in T\u0026gt;( context: CoroutineContext, @JvmField val uCont: Continuation\u0026lt;T\u0026gt; // unintercepted continuation ) : AbstractCoroutine\u0026lt;T\u0026gt;(context, true), CoroutineStackFrame { override fun afterCompletionInternal(state: Any?, mode: Int) { if (state is CompletedExceptionally) { val exception = if (mode == MODE_IGNORE) state.cause else recoverStackTrace(state.cause, uCont) uCont.resumeUninterceptedWithExceptionMode(exception, mode) } else { uCont.resumeUninterceptedMode(state as T, mode)//uCont是old，eg:Continuation at com.example.myapplication.coroutine.CoroutineTest$postItem$1.invokeSuspend(CoroutineTest.kt:55)  } } } internal fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeUninterceptedMode(value: T, mode: Int) { when (mode) { MODE_ATOMIC_DEFAULT -\u0026gt; intercepted().resume(value) MODE_CANCELLABLE -\u0026gt; intercepted().resumeCancellable(value) MODE_DIRECT -\u0026gt; resume(value) MODE_UNDISPATCHED -\u0026gt; withCoroutineContext(context, null) { resume(value) } MODE_IGNORE -\u0026gt; {} else -\u0026gt; error(\u0026#34;Invalid mode $mode\u0026#34;) } } resume\nundispatched internal fun \u0026lt;T, R\u0026gt; AbstractCoroutine\u0026lt;T\u0026gt;.startUndispatchedOrReturn(receiver: R, block: suspend R.() -\u0026gt; T): Any? { initParentJob() return undispatchedResult({ true }) { block.startCoroutineUninterceptedOrReturn(receiver, this) } } kotlin/coroutines/intrinsics/IntrinsicsJvm.kt\npublic actual inline fun \u0026lt;T\u0026gt; (suspend () -\u0026gt; T).startCoroutineUninterceptedOrReturn( completion: Continuation\u0026lt;T\u0026gt; ): Any? = (this as Function1\u0026lt;Continuation\u0026lt;T\u0026gt;, Any?\u0026gt;).invoke(completion) delay public suspend fun delay(timeMillis: Long) { if (timeMillis \u0026lt;= 0) return // don\u0026#39;t delay  return suspendCancellableCoroutine sc@ { cont: CancellableContinuation\u0026lt;Unit\u0026gt; -\u0026gt; cont.context.delay.scheduleResumeAfterDelay(timeMillis, cont) } } public suspend inline fun \u0026lt;T\u0026gt; suspendCancellableCoroutine( crossinline block: (CancellableContinuation\u0026lt;T\u0026gt;) -\u0026gt; Unit ): T = suspendCoroutineUninterceptedOrReturn { uCont -\u0026gt; val cancellable = CancellableContinuationImpl(uCont.intercepted(), resumeMode = MODE_CANCELLABLE) // NOTE: Before version 1.1.0 the following invocation was inlined here, so invocation of this  // method indicates that the code was compiled by kotlinx.coroutines \u0026lt; 1.1.0  // cancellable.initCancellability()  block(cancellable) cancellable.getResult() } main线程delay，执行block override fun scheduleResumeAfterDelay(timeMillis: Long, continuation: CancellableContinuation\u0026lt;Unit\u0026gt;) { val block = Runnable { with(continuation) { resumeUndispatched(Unit) } } handler.postDelayed(block, timeMillis.coerceAtMost(MAX_DELAY)) continuation.invokeOnCancellation { handler.removeCallbacks(block) } } 非main线程delay，执行block public override fun scheduleResumeAfterDelay(timeMillis: Long, continuation: CancellableContinuation\u0026lt;Unit\u0026gt;) { val timeNanos = delayToNanos(timeMillis) if (timeNanos \u0026lt; MAX_DELAY_NS) { val now = nanoTime() DelayedResumeTask(now + timeNanos, continuation).also { task -\u0026gt; continuation.disposeOnCancellation(task) schedule(now, task) } } } CancellableContinuation\u0026lt;*\u0026gt;.disposeOnCancellation(handle: DisposableHandle) public fun CancellableContinuation\u0026lt;*\u0026gt;.disposeOnCancellation(handle: DisposableHandle) = invokeOnCancellation(handler = DisposeOnCancel(handle).asHandler) private class DisposeOnCancel(private val handle: DisposableHandle) : CancelHandler() { override fun invoke(cause: Throwable?) = handle.dispose() } private inner class DelayedResumeTask( nanoTime: Long, private val cont: CancellableContinuation\u0026lt;Unit\u0026gt; ) : DelayedTask(nanoTime) { override fun run() { with(cont) { resumeUndispatched(Unit) } } override fun toString(): String = super.toString() + cont.toString() } internal abstract class DelayedTask( /** * This field can be only modified in [scheduleTask] before putting this DelayedTask * into heap to avoid overflow and corruption of heap data structure. */ @JvmField var nanoTime: Long ) : Runnable, Comparable\u0026lt;DelayedTask\u0026gt;, DisposableHandle, ThreadSafeHeapNode { @Synchronized final override fun dispose() { val heap = _heap if (heap === DISPOSED_TASK) return // already disposed  @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) (heap as? DelayedTaskQueue)?.remove(this) // remove if it is in heap (first)  _heap = DISPOSED_TASK // never add again to any heap  } } DefaultExecutor.schedule public fun schedule(now: Long, delayedTask: DelayedTask) { when (scheduleImpl(now, delayedTask)) { SCHEDULE_OK -\u0026gt; if (shouldUnpark(delayedTask)) unpark() SCHEDULE_COMPLETED -\u0026gt; reschedule(now, delayedTask) SCHEDULE_DISPOSED -\u0026gt; {} // do nothing -- task was already disposed  else -\u0026gt; error(\u0026#34;unexpected result\u0026#34;) } } getResult @PublishedApi internal fun getResult(): Any? { installParentCancellationHandler() if (trySuspend()) return COROUTINE_SUSPENDED // otherwise, onCompletionInternal was already invoked \u0026amp; invoked tryResume, and the result is in the state  val state = this.state if (state is CompletedExceptionally) throw recoverStackTrace(state.cause, this) // if the parent job was already cancelled, then throw the corresponding cancellation exception  // otherwise, there is a race is suspendCancellableCoroutine { cont -\u0026gt; ... } does cont.resume(...)  // before the block returns. This getResult would return a result as opposed to cancellation  // exception that should have happened if the continuation is dispatched for execution later.  if (resumeMode == MODE_CANCELLABLE) { val job = context[Job] if (job != null \u0026amp;\u0026amp; !job.isActive) { val cause = job.getCancellationException() cancelResult(state, cause) throw recoverStackTrace(cause, this) } } return getSuccessfulResult(state) } trySuspend释放线程 private const val UNDECIDED = 0 private const val SUSPENDED = 1 private const val RESUMED = 2 private fun trySuspend(): Boolean { _decision.loop { decision -\u0026gt; when (decision) { UNDECIDED -\u0026gt; if (this._decision.compareAndSet(UNDECIDED, SUSPENDED)) return true RESUMED -\u0026gt; return false else -\u0026gt; error(\u0026#34;Already suspended\u0026#34;) } } } main线程delay,恢复协程的后续执行 with(continuation) { resumeUndispatched(Unit) } /** * Calls the specified function [block] with the given [receiver] as its receiver and returns its result. */ @kotlin.internal.InlineOnly public inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R { return receiver.block() } commonMain/CancellableContinuationImpl.kt\noverride fun CoroutineDispatcher.resumeUndispatched(value: T) { val dc = delegate as? DispatchedContinuation resumeImpl(value, if (dc?.dispatcher === this) MODE_UNDISPATCHED else resumeMode) } // returns null when successfully dispatched resumed, CancelledContinuation if too late (was already cancelled) private fun resumeImpl(proposedUpdate: Any?, resumeMode: Int): CancelledContinuation? { _state.loop { state -\u0026gt; when (state) { is NotCompleted -\u0026gt; { if (!_state.compareAndSet(state, proposedUpdate)) return@loop // retry on cas failure  disposeParentHandle() dispatchResume(resumeMode)//main  return null } } } private fun dispatchResume(mode: Int) { if (tryResume()) return // completed before getResult invocation -- bail out  // otherwise, getResult has already commenced, i.e. completed later or in other thread  dispatch(mode) } tryResume private fun tryResume(): Boolean { _decision.loop { decision -\u0026gt; when (decision) { UNDECIDED -\u0026gt; if (this._decision.compareAndSet(UNDECIDED, RESUMED)) return true SUSPENDED -\u0026gt; return false else -\u0026gt; error(\u0026#34;Already resumed\u0026#34;) } } } DispatchedTask.dispatch internal fun \u0026lt;T\u0026gt; DispatchedTask\u0026lt;T\u0026gt;.dispatch(mode: Int = MODE_CANCELLABLE) { val delegate = this.delegate if (mode.isDispatchedMode \u0026amp;\u0026amp; delegate is DispatchedContinuation\u0026lt;*\u0026gt; \u0026amp;\u0026amp; mode.isCancellableMode == resumeMode.isCancellableMode) { // dispatch directly using this instance\u0026#39;s Runnable implementation  val dispatcher = delegate.dispatcher val context = delegate.context if (dispatcher.isDispatchNeeded(context)) { dispatcher.dispatch(context, this) } else { resumeUnconfined() } } else { resume(delegate, mode)//main  } } internal fun \u0026lt;T\u0026gt; DispatchedTask\u0026lt;T\u0026gt;.resume(delegate: Continuation\u0026lt;T\u0026gt;, useMode: Int) { // slow-path - use delegate  val state = takeState() val exception = getExceptionalResult(state) if (exception != null) { /* * Recover stacktrace for non-dispatched tasks. * We usually do not recover stacktrace in a `resume` as all resumes go through `DispatchedTask.run` * and we recover stacktraces there, but this is not the case for a `suspend fun main()` that knows nothing about * kotlinx.coroutines and DispatchedTask */ val recovered = if (delegate is DispatchedTask\u0026lt;*\u0026gt;) exception else recoverStackTrace(exception, delegate) delegate.resumeWithExceptionMode(recovered, useMode) } else { delegate.resumeMode(getSuccessfulResult(state), useMode)//main  } } internal fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeMode(value: T, mode: Int) { when (mode) { MODE_ATOMIC_DEFAULT -\u0026gt; resume(value) MODE_CANCELLABLE -\u0026gt; resumeCancellable(value) MODE_DIRECT -\u0026gt; resumeDirect(value) MODE_UNDISPATCHED -\u0026gt; (this as DispatchedContinuation).resumeUndispatched(value) MODE_IGNORE -\u0026gt; {} else -\u0026gt; error(\u0026#34;Invalid mode $mode\u0026#34;) } } inline fun resumeUndispatched(value: T) { //this: DispatchedContinuation[Main [immediate]...]  withCoroutineContext(context, countOrElement) { continuation.resume(value)//走后续的resume流程  } } public inline fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resume(value: T): Unit = resumeWith(Result.success(value)) //协程的恢复 override fun resumeWith(result: Result\u0026lt;T\u0026gt;) { val context = continuation.context val state = result.toState() if (dispatcher.isDispatchNeeded(context)) { _state = state resumeMode = MODE_ATOMIC_DEFAULT dispatcher.dispatch(context, this) } else { executeUnconfined(state, MODE_ATOMIC_DEFAULT) { withCoroutineContext(this.context, countOrElement) { continuation.resumeWith(result) } } } } 继续中间层的resume流程\nJob * A job has the following states: * * | **State** | [isActive] | [isCompleted] | [isCancelled] | * | -------------------------------- | ---------- | ------------- | ------------- | * | _New_ (optional initial state) | `false` | `false` | `false` | * | _Active_ (default initial state) | `true` | `false` | `false` | * | _Completing_ (transient state) | `true` | `false` | `false` | * | _Cancelling_ (transient state) | `false` | `false` | `true` | * | _Cancelled_ (final state) | `false` | `true` | `true` | * | _Completed_ (final state) | `false` | `true` | `false` | * ``` * wait children * +-----+ start +--------+ complete +-------------+ finish +-----------+ * | New | -----\u0026gt; | Active | ---------\u0026gt; | Completing | -------\u0026gt; | Completed | * +-----+ +--------+ +-------------+ +-----------+ * | cancel / fail | * | +----------------+ * | | * V V * +------------+ finish +-----------+ * | Cancelling | --------------------------------\u0026gt; | Cancelled | * +------------+ +-----------+ * ``` async async时不释放线程，也不挂起协程\nawait被调用时才释放线程，并挂起协程\npublic fun \u0026lt;T\u0026gt; CoroutineScope.async( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; T ): Deferred\u0026lt;T\u0026gt; { val newContext = newCoroutineContext(context) val coroutine = if (start.isLazy) LazyDeferredCoroutine(newContext, block) else DeferredCoroutine\u0026lt;T\u0026gt;(newContext, active = true) coroutine.start(start, coroutine, block) return coroutine } public interface Deferred\u0026lt;out T\u0026gt; : Job { public suspend fun await(): T ...... } private open class DeferredCoroutine\u0026lt;T\u0026gt;( parentContext: CoroutineContext, active: Boolean ) : AbstractCoroutine\u0026lt;T\u0026gt;(parentContext, active), Deferred\u0026lt;T\u0026gt;, SelectClause1\u0026lt;T\u0026gt; { override fun getCompleted(): T = getCompletedInternal() as T override suspend fun await(): T = awaitInternal() as T override val onAwait: SelectClause1\u0026lt;T\u0026gt; get() = this override fun \u0026lt;R\u0026gt; registerSelectClause1(select: SelectInstance\u0026lt;R\u0026gt;, block: suspend (T) -\u0026gt; R) = registerSelectClause1Internal(select, block) } awaitInternal internal suspend fun awaitInternal(): Any? { // fast-path -- check state (avoid extra object creation)  while (true) { // lock-free loop on state  val state = this.state if (state !is Incomplete) { // already complete -- just return result  if (state is CompletedExceptionally) { // Slow path to recover stacktrace  recoverAndThrow(state.cause) } return state.unboxState() } if (startInternal(state) \u0026gt;= 0) break // break unless needs to retry  } return awaitSuspend() // slow-path } private suspend fun awaitSuspend(): Any? = suspendCoroutineUninterceptedOrReturn { uCont -\u0026gt; val cont = AwaitContinuation(uCont.intercepted(), this) cont.disposeOnCancellation(invokeOnCompletion(ResumeAwaitOnCompletion(this, cont).asHandler)) cont.getResult() } invokeOnCompletion public final override fun invokeOnCompletion(handler: CompletionHandler): DisposableHandle = invokeOnCompletion(onCancelling = false, invokeImmediately = true, handler = handler) ResumeAwaitOnCompletion private class ResumeAwaitOnCompletion\u0026lt;T\u0026gt;( job: JobSupport, private val continuation: CancellableContinuationImpl\u0026lt;T\u0026gt; ) : JobNode\u0026lt;JobSupport\u0026gt;(job) { override fun invoke(cause: Throwable?) { val state = job.state assert { state !is Incomplete } if (state is CompletedExceptionally) { // Resume with exception in atomic way to preserve exception  continuation.resumeWithExceptionMode(state.cause, MODE_ATOMIC_DEFAULT) } else { // Resuming with value in a cancellable way (AwaitContinuation is configured for this mode).  @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) continuation.resume(state.unboxState() as T) } } override fun toString() = \u0026#34;ResumeAwaitOnCompletion[$continuation]\u0026#34; } Dispatchers.Main.immediate @JvmStatic //这里的dispatcher就是下面的HandlerContext实例 public actual val Main: MainCoroutineDispatcher get() = MainDispatcherLoader.dispatcher MainDispatcherLoader val dispatcher: MainCoroutineDispatcher = loadMainDispatcher() public abstract class MainCoroutineDispatcher : CoroutineDispatcher() { public abstract val immediate: MainCoroutineDispatcher } public sealed class HandlerDispatcher : MainCoroutineDispatcher(), Delay { public abstract override val immediate: HandlerDispatcher } internal class HandlerContext private constructor( private val handler: Handler, private val name: String?, private val invokeImmediately: Boolean ) : HandlerDispatcher(), Delay { @Volatile private var _immediate: HandlerContext? = if (invokeImmediately) this else null override val immediate: HandlerContext = _immediate ?: HandlerContext(handler, name, true).also { _immediate = it } override fun isDispatchNeeded(context: CoroutineContext): Boolean { return !invokeImmediately || Looper.myLooper() != handler.looper } 协程resume时根据dispatcher.isDispatchNeeded判断是否需要dispatch\nDispatchedContinuation inline fun resumeCancellable(value: T) { if (dispatcher.isDispatchNeeded(context)) {//main  _state = value resumeMode = MODE_CANCELLABLE dispatcher.dispatch(context, this) } else { executeUnconfined(value, MODE_CANCELLABLE) { if (!resumeCancelled()) { resumeUndispatched(value) } } } } CoroutineStackFrame 发生异常时用于恢复协程堆栈\ninternal actual typealias CoroutineStackFrame = kotlin.coroutines.jvm.internal.CoroutineStackFrame /** * Represents one frame in the coroutine call stack for debugger. * This interface is implemented by compiler-generated implementations of * [Continuation] interface. */ @SinceKotlin(\u0026#34;1.3\u0026#34;) public interface CoroutineStackFrame { /** * Returns a reference to the stack frame of the caller of this frame, * that is a frame before this frame in coroutine call stack. * The result is `null` for the first frame of coroutine. */ public val callerFrame: CoroutineStackFrame? /** * Returns stack trace element that correspond to this stack frame. * The result is `null` if the stack trace element is not available for this frame. * In this case, the debugger represents this stack frame using the * result of [toString] function. */ public fun getStackTraceElement(): StackTraceElement? } DispatchedTask.run\npublic final override fun run() { val taskContext = this.taskContext var fatalException: Throwable? = null withCoroutineContext(context, delegate.countOrElement) { val exception = getExceptionalResult(state) val job = if (resumeMode.isCancellableMode) context[Job] else null /* * Check whether continuation was originally resumed with an exception. * If so, it dominates cancellation, otherwise the original exception * will be silently lost. */ if (exception == null \u0026amp;\u0026amp; job != null \u0026amp;\u0026amp; !job.isActive) { val cause = job.getCancellationException() cancelResult(state, cause) continuation.resumeWithStackTrace(cause) } else { if (exception != null) continuation.resumeWithStackTrace(exception)//main  else continuation.resume(getSuccessfulResult(state)) } } } internal inline fun Continuation\u0026lt;*\u0026gt;.resumeWithStackTrace(exception: Throwable) { resumeWith(Result.failure(recoverStackTrace(exception, this))) } internal actual fun \u0026lt;E : Throwable\u0026gt; recoverStackTrace(exception: E, continuation: Continuation\u0026lt;*\u0026gt;): E { if (!RECOVER_STACK_TRACES || continuation !is CoroutineStackFrame) return exception return recoverFromStackFrame(exception, continuation) } private fun \u0026lt;E : Throwable\u0026gt; recoverFromStackFrame(exception: E, continuation: CoroutineStackFrame): E { /* * Here we are checking whether exception has already recovered stacktrace. * If so, we extract initial and merge recovered stacktrace and current one */ val (cause, recoveredStacktrace) = exception.causeAndStacktrace() // Try to create an exception of the same type and get stacktrace from continuation  val newException = tryCopyException(cause) ?: return exception val stacktrace = createStackTrace(continuation) private fun createStackTrace(continuation: CoroutineStackFrame): ArrayDeque\u0026lt;StackTraceElement\u0026gt; { val stack = ArrayDeque\u0026lt;StackTraceElement\u0026gt;() continuation.getStackTraceElement()?.let { stack.add(it) } var last = continuation while (true) { last = (last as? CoroutineStackFrame)?.callerFrame ?: break last.getStackTraceElement()?.let { stack.add(it) } } return stack } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/layoutinflater/layoutinflater/",
	"title": "LayoutInflater",
	"tags": [],
	"description": "",
	"content": "原理图 视图层级 AppCompatActivity.setContentView @Override public void setContentView(@LayoutRes int layoutResID) { getDelegate().setContentView(layoutResID); } AppCompatDelegateImpl.java\n@Override public void setContentView(int resId) { ensureSubDecor(); ViewGroup contentParent = mSubDecor.findViewById(android.R.id.content); contentParent.removeAllViews(); LayoutInflater.from(mContext).inflate(resId, contentParent); } installDecor,createSubDecor private void ensureSubDecor() { if (!mSubDecorInstalled) { mSubDecor = createSubDecor(); } } private ViewGroup createSubDecor() { // Now let\u0026#39;s make sure that the Window has installed its decor by retrieving it  //确保优先初始化 DecorView  mWindow.getDecorView();//PhoneWindow  ViewGroup subDecor = null; //根据不同的设置来对 subDecor 进行初始化  if (!mWindowNoTitle) { subDecor = title相关的view } else { if (mOverlayActionMode) { subDecor = (ViewGroup) inflater.inflate( R.layout.abc_screen_simple_overlay_action_mode, null); } else { subDecor = (ViewGroup) inflater.inflate(R.layout.abc_screen_simple, null); } } // Now set the Window\u0026#39;s content view with the decor  // 将 subDecor 添加到 DecorView 中  mWindow.setContentView(subDecor); return subDecor; } PhoneWindow.java\n@Override public final View getDecorView() { if (mDecor == null || mForceDecorInstall) { installDecor(); } return mDecor; } private void installDecor() { if (mDecor == null) { mDecor = generateDecor(-1); } else { mDecor.setWindow(this); } if (mContentParent == null) { mContentParent = generateLayout(mDecor); } } protected DecorView generateDecor(int featureId) { return new DecorView(context, featureId, this, getAttributes()); } protected ViewGroup generateLayout(DecorView decor) { ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT); return contentParent; } findViewById Window.java @Nullable public \u0026lt;T extends View\u0026gt; T findViewById(@IdRes int id) { return getDecorView().findViewById(id); } View.java @Nullable public final \u0026lt;T extends View\u0026gt; T findViewById(@IdRes int id) { if (id == NO_ID) { return null; } return findViewTraversal(id); } ViewGroup.java @Override protected \u0026lt;T extends View\u0026gt; T findViewTraversal(@IdRes int id) { if (id == mID) { return (T) this; } final View[] where = mChildren; final int len = mChildrenCount; for (int i = 0; i \u0026lt; len; i++) { View v = where[i]; if ((v.mPrivateFlags \u0026amp; PFLAG_IS_ROOT_NAMESPACE) == 0) { v = v.findViewById(id); if (v != null) { return (T) v; } } } return null; } LayoutInflater.from /** * Obtains the LayoutInflater from the given context. */ public static LayoutInflater from(Context context) { //对应的BinderServer是PhoneLayoutInflater,位于当前进程，不走ServiceManager获取  LayoutInflater LayoutInflater = (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE); return LayoutInflater; } Activity.java\n@Override public Object getSystemService(@ServiceName @NonNull String name) { if (WINDOW_SERVICE.equals(name)) { return mWindowManager; } else if (SEARCH_SERVICE.equals(name)) { ensureSearchManager(); return mSearchManager; } return super.getSystemService(name); } ContextThemeWrapper.java\n@Override public Object getSystemService(String name) { if (LAYOUT_INFLATER_SERVICE.equals(name)) { if (mInflater == null) { mInflater = LayoutInflater.from(getBaseContext()).cloneInContext(this); } return mInflater; } return getBaseContext().getSystemService(name); } ContextImpl.java\n@Override public Object getSystemService(String name) { return SystemServiceRegistry.getSystemService(this, name); } SystemServiceRegistry.java\nregisterService(Context.LAYOUT_INFLATER_SERVICE, LayoutInflater.class, new CachedServiceFetcher\u0026lt;LayoutInflater\u0026gt;() { @Override public LayoutInflater createService(ContextImpl ctx) { return new PhoneLayoutInflater(ctx.getOuterContext()); }}); PhoneLayoutInflater.inflate public class PhoneLayoutInflater extends LayoutInflater { public View inflate(@LayoutRes int resource, @Nullable ViewGroup root) { return inflate(resource, root, root != null); } public View inflate(@LayoutRes int resource, @Nullable ViewGroup root, boolean attachToRoot) { final Resources res = getContext().getResources(); final XmlResourceParser parser = res.getLayout(resource); return inflate(parser, root, attachToRoot); } public View inflate(XmlPullParser parser, @Nullable ViewGroup root, boolean attachToRoot) { // Temp is the root view that was found in the xml  final View temp = createViewFromTag(root, name, inflaterContext, attrs); // Inflate all children under temp against its context.  rInflateChildren(parser, temp, attrs, true); // We are supposed to attach all the views we found (int temp)  // to root. Do that now.  if (root != null \u0026amp;\u0026amp; attachToRoot) { root.addView(temp, params); } } createRootViewInXml rInflateChildren final void rInflateChildren(XmlPullParser parser, View parent, AttributeSet attrs, boolean finishInflate) throws XmlPullParserException, IOException { rInflate(parser, parent, parent.getContext(), attrs, finishInflate); } void rInflate(XmlPullParser parser, View parent, Context context, AttributeSet attrs, boolean finishInflate) throws XmlPullParserException, IOException { while (((type = parser.next()) != XmlPullParser.END_TAG || parser.getDepth() \u0026gt; depth) \u0026amp;\u0026amp; type != XmlPullParser.END_DOCUMENT) { final View view = createViewFromTag(parent, name, context, attrs); final ViewGroup viewGroup = (ViewGroup) parent; final ViewGroup.LayoutParams params = viewGroup.generateLayoutParams(attrs); rInflateChildren(parser, view, attrs, true); viewGroup.addView(view, params); } } createViewFromTag private View createViewFromTag(View parent, String name, Context context, AttributeSet attrs) { return createViewFromTag(parent, name, context, attrs, false); } View createViewFromTag(View parent, String name, Context context, AttributeSet attrs, boolean ignoreThemeAttr) { View view; if (mFactory2 != null) { view = mFactory2.onCreateView(parent, name, context, attrs); } else if (mFactory != null) { view = mFactory.onCreateView(name, context, attrs); } else { view = null; } if (view == null \u0026amp;\u0026amp; mPrivateFactory != null) { view = mPrivateFactory.onCreateView(parent, name, context, attrs); } if (view == null) { final Object lastContext = mConstructorArgs[0]; mConstructorArgs[0] = context; try { if (-1 == name.indexOf(\u0026#39;.\u0026#39;)) { view = onCreateView(parent, name, attrs); } else { view = createView(name, null, attrs); } } finally { mConstructorArgs[0] = lastContext; } } return view; } default Factory2\u0026ndash;\u0026gt;AppCompatDelegateImpl.java public final View onCreateView(View parent, String name, Context context, AttributeSet attrs) { return createView(parent, name, context, attrs); } @Override public View createView(View parent, final String name, @NonNull Context context, @NonNull AttributeSet attrs) { return mAppCompatViewInflater.createView(parent, name, context, attrs, inheritContext, IS_PRE_LOLLIPOP, /* Only read android:theme pre-L (L+ handles this anyway) */ true, /* Read read app:theme as a fallback at all times for legacy reasons */ VectorEnabledTintResources.shouldBeUsed() /* Only tint wrap the context if enabled */ ); final View createView(View parent, final String name, @NonNull Context context, @NonNull AttributeSet attrs, boolean inheritContext, boolean readAndroidTheme, boolean readAppTheme, boolean wrapContext) { // We need to \u0026#39;inject\u0026#39; our tint aware Views in place of the standard framework versions  switch (name) { case \u0026#34;TextView\u0026#34;: view = createTextView(context, attrs); verifyNotNull(view, name); break; case \u0026#34;ImageView\u0026#34;: view = createImageView(context, attrs); verifyNotNull(view, name); break; case \u0026#34;Button\u0026#34;: view = createButton(context, attrs); verifyNotNull(view, name); break; ...... } if (view == null \u0026amp;\u0026amp; originalContext != context) { // If the original context does not equal our themed context, then we need to manually  // inflate it using the name so that android:theme takes effect.  view = createViewFromTag(context, name, attrs); } } @NonNull protected AppCompatButton createButton(Context context, AttributeSet attrs) { return new AppCompatButton(context, attrs); } private View createViewFromTag(Context context, String name, AttributeSet attrs) { createViewByPrefix(context, name, null) } private View createViewByPrefix(Context context, String name, String prefix) throws ClassNotFoundException, InflateException { Constructor\u0026lt;? extends View\u0026gt; constructor = sConstructorMap.get(name); if (constructor == null) { // Class not found in the cache, see if it\u0026#39;s real, and try to add it  Class\u0026lt;? extends View\u0026gt; clazz = Class.forName( prefix != null ? (prefix + name) : name, false, context.getClassLoader()).asSubclass(View.class); constructor = clazz.getConstructor(sConstructorSignature); sConstructorMap.put(name, constructor); } constructor.setAccessible(true); return constructor.newInstance(mConstructorArgs); } public void setFactory2(Factory2 factory) { if (mFactorySet) { throw new IllegalStateException(\u0026#34;A factory has already been set on this LayoutInflater\u0026#34;); } mFactorySet = true; if (mFactory == null) { mFactory = mFactory2 = factory; } else { mFactory = mFactory2 = new FactoryMerger(factory, factory, mFactory, mFactory2); } } root.addView 参考 Android DecorView 与 Activity 绑定原理分析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/layoutinflater/",
	"title": "layoutinflater",
	"tags": [],
	"description": "",
	"content": "layoutinflater 探索总结layoutinflater知识\n LayoutInflater     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/leakcanary2source/",
	"title": "LeakCanary2Source",
	"tags": [],
	"description": "",
	"content": "Procedure graph TB HeapAnalyzer.analyze--\u0026gt;Hprof.open:HprofFile HeapAnalyzer.analyze--\u0026gt;HprofHeapGraph.indexHprof HeapAnalyzer.analyze--\u0026gt;FindLeakInput.analyzeGraph HprofHeapGraph.indexHprof--\u0026gt;reader.readHprofRecords--\u0026gt;|callback HprofRecord|indexBuilderListener.onHprofRecord--\u0026gt;UnsortedByteEntries(\u0026quot;UnsortedByteEntries,ScatterMap\u0026quot;) HprofHeapGraph.indexHprof--\u0026gt;indexBuilderListener.buildIndex--\u0026gt;|Sort entries by keys|SortedBytesMap--\u0026gt;HprofInMemoryIndex--\u0026gt;HprofHeapGraph FindLeakInput.analyzeGraph--\u0026gt;FindLeakInput.findLeaks FindLeakInput.findLeaks--\u0026gt;State.findPathsFromGcRoots:BFS--\u0026gt;|start by enqueueGcRoots|findObjectById(\u0026quot;graph.findObjectById\u0026quot;)--\u0026gt;readFieldsAndEnqueue Data Flow graph TB HprofFile--\u0026gt;HprofRecord HprofRecord--\u0026gt;UnsortedByteEntries(\u0026quot;UnsortedByteEntries(class,instance,objectArray,primitiveArray)\u0026quot;) UnsortedByteEntries--\u0026gt;|Sort entries by keys|SortedBytesMap(SortedBytesMap: get perform binarySearch) SortedBytesMap--\u0026gt;HprofInMemoryIndex SortedBytesMap--\u0026gt;|get return|ByteSubArray ByteSubArray--\u0026gt;|indexedObjectOrNull|IndexedObject IndexedObject--\u0026gt;|wrapIndexedObject|HeapObject HprofRecord--\u0026gt;ScatterMap(\u0026quot;ScatterMap(hprofStringCache, classNames)\u0026quot;) ScatterMap--\u0026gt;HprofInMemoryIndex HprofInMemoryIndex--\u0026gt;HprofHeapGraph LruCache:objectCache--\u0026gt;|cached when readObjectRecord|HprofHeapGraph //ScatterMap contains: classNames and hprofStringCache  // LRU cache size of 3000 is a sweet spot to balance hits vs memory usage. // This is based on running InstrumentationLeakDetectorTest a bunch of time on a // Pixel 2 XL API 28. Hit count was ~120K, miss count ~290K private val objectCache = LruCache\u0026lt;Long, ObjectRecord\u0026gt;(3000) HprofRecord Hierarchy graph LR HprofRecord--\u0026gt;StringRecord HprofRecord--\u0026gt;LoadClassRecord HprofRecord--\u0026gt;StackFrameRecord HprofRecord--\u0026gt;StackTraceRecord HprofRecord--\u0026gt;HeapDumpRecord HeapDumpRecord--\u0026gt;GcRootRecord HeapDumpRecord--\u0026gt;ObjectRecord ObjectRecord--\u0026gt;ClassDumpRecord ObjectRecord--\u0026gt;InstanceDumpRecord ObjectRecord--\u0026gt;ObjectArrayDumpRecord ObjectRecord--\u0026gt;PrimitiveArrayDumpRecord ReferencePathNode Hierarchy graph LR ReferencePathNode--\u0026gt;RootNode ReferencePathNode--\u0026gt;ChildNode RootNode--\u0026gt;LibraryLeakRootNode RootNode--\u0026gt;NormalRootNode ChildNode--\u0026gt;NormalNode:ContainsParent ChildNode--\u0026gt;LibraryLeakChildNode:ContainsParent /** * Analyzes heap dumps to look for leaks. */ HeapAnalyzer analyze /** * Searches the heap dump for leaking instances and then computes the shortest strong reference * path from those instances to the GC roots. */ fun analyze( heapDumpFile: File, leakingObjectFinder: LeakingObjectFinder, referenceMatchers: List\u0026lt;ReferenceMatcher\u0026gt; = emptyList(), computeRetainedHeapSize: Boolean = false, objectInspectors: List\u0026lt;ObjectInspector\u0026gt; = emptyList(), metadataExtractor: MetadataExtractor = MetadataExtractor.NO_OP, proguardMapping: ProguardMapping? = null ): HeapAnalysis { Hprof.open(heapDumpFile) .use { hprof -\u0026gt; val graph = HprofHeapGraph.indexHprof(hprof, proguardMapping) val helpers = FindLeakInput(graph, referenceMatchers, computeRetainedHeapSize, objectInspectors) helpers.analyzeGraph( metadataExtractor, leakingObjectFinder, heapDumpFile, analysisStartNanoTime ) } indexhprof\nFindLeakInput private class FindLeakInput( val graph: HeapGraph, val referenceMatchers: List\u0026lt;ReferenceMatcher\u0026gt;, val computeRetainedHeapSize: Boolean, val objectInspectors: List\u0026lt;ObjectInspector\u0026gt; ) FindLeakInput.analyzeGraph private fun FindLeakInput.analyzeGraph( metadataExtractor: MetadataExtractor, leakingObjectFinder: LeakingObjectFinder, heapDumpFile: File, analysisStartNanoTime: Long ): HeapAnalysisSuccess { listener.onAnalysisProgress(EXTRACTING_METADATA) val metadata = metadataExtractor.extractMetadata(graph) listener.onAnalysisProgress(FINDING_RETAINED_OBJECTS) val leakingObjectIds = leakingObjectFinder.findLeakingObjectIds(graph) val (applicationLeaks, libraryLeaks) = findLeaks(leakingObjectIds) return HeapAnalysisSuccess( heapDumpFile = heapDumpFile, createdAtTimeMillis = System.currentTimeMillis(), analysisDurationMillis = since(analysisStartNanoTime), metadata = metadata, applicationLeaks = applicationLeaks, libraryLeaks = libraryLeaks ) } FindLeakInput.findLeaks private fun FindLeakInput.findLeaks(leakingObjectIds: Set\u0026lt;Long\u0026gt;): Pair\u0026lt;List\u0026lt;ApplicationLeak\u0026gt;, List\u0026lt;LibraryLeak\u0026gt;\u0026gt; { val pathFinder = PathFinder(graph, listener, referenceMatchers) val pathFindingResults = pathFinder.findPathsFromGcRoots(leakingObjectIds, computeRetainedHeapSize) SharkLog.d { \u0026#34;Found ${leakingObjectIds.size}retained objects\u0026#34; } return buildLeakTraces(pathFindingResults) } findpathsfromgcroots\nPathFinder /** * Finds the shortest path from leaking references to a gc root, first ignoring references * identified as \u0026#34;to visit last\u0026#34; and then visiting them as needed if no path is * found. */ internal class PathFinder( private class State( val leakingObjectIds: Set\u0026lt;Long\u0026gt;, val sizeOfObjectInstances: Int, val computeRetainedHeapSize: Boolean ) { /** Set of objects to visit */ val toVisitQueue: Deque\u0026lt;ReferencePathNode\u0026gt; = ArrayDeque() /** * Objects to visit when [toVisitQueue] is empty. Should contain [JavaFrame] gc roots first, * then [LibraryLeakNode]. */ val toVisitLastQueue: Deque\u0026lt;ReferencePathNode\u0026gt; = ArrayDeque() /** * Enables fast checking of whether a node is already in the queue. */ val toVisitSet = HashSet\u0026lt;Long\u0026gt;() val toVisitLastSet = HashSet\u0026lt;Long\u0026gt;() val visitedSet = LongScatterSet() findPathsFromGcRoots fun findPathsFromGcRoots( leakingObjectIds: Set\u0026lt;Long\u0026gt;, computeRetainedHeapSize: Boolean ): PathFindingResults { listener.onAnalysisProgress(FINDING_PATHS_TO_RETAINED_OBJECTS) val sizeOfObjectInstances = determineSizeOfObjectInstances(graph) val state = State(leakingObjectIds, sizeOfObjectInstances, computeRetainedHeapSize) return state.findPathsFromGcRoots() } State /** * Map of objects to their leaking dominator. key: currentObjectId --\u0026gt; value: directDominatorObjectId * If an object has been added to [toVisitSet] or [visitedSet] and is missing from * [dominatedObjectIds] then it\u0026#39;s considered \u0026#34;undomitable\u0026#34; ie it is dominated by gc roots * and cannot be dominated by a leaking object. */ val dominatedObjectIds = LongLongScatterMap() State.findPathsFromGcRoots() //main algorithm to find the shortest path to GCRoot, BFS is useful because when the first time we visit leakObject, the shortest path is found. Use ChildNode to find the parent ReferencePathNode private fun State.findPathsFromGcRoots(): PathFindingResults { //iterate different type GcRoot and enqueue them into toVisitQueue or toVisitLastQueue  enqueueGcRoots() val shortestPathsToLeakingObjects = mutableListOf\u0026lt;ReferencePathNode\u0026gt;() visitingQueue@ while (queuesNotEmpty) { val node = poll() if (checkSeen(node)) { throw IllegalStateException( \u0026#34;Node $nodeobjectId=${node.objectId}should not be enqueued when already visited or enqueued\u0026#34; ) } if (node.objectId in leakingObjectIds) { shortestPathsToLeakingObjects.add(node) // Found all refs, stop searching (unless computing retained size)  if (shortestPathsToLeakingObjects.size == leakingObjectIds.size) { if (computeRetainedHeapSize) { listener.onAnalysisProgress(FINDING_DOMINATORS) } else { break@visitingQueue } } } when (val heapObject = graph.findObjectById(node.objectId)) { is HeapClass -\u0026gt; visitClassRecord(heapObject, node) is HeapInstance -\u0026gt; visitInstance(heapObject, node) is HeapObjectArray -\u0026gt; visitObjectArray(heapObject, node) } } return PathFindingResults(shortestPathsToLeakingObjects, dominatedObjectIds) } findobjectbyid\nState.visitInstance private fun State.visitInstance( instance: HeapInstance, parent: ReferencePathNode ) { val fieldNamesAndValues = instance.readFields() .filter { it.value.isNonNullReference }//only reference type need to be iterate, primitive is not.  .toMutableList() fieldNamesAndValues.sortBy { it.name } fieldNamesAndValues.forEach { field -\u0026gt; val objectId = field.value.asObjectId!! if (computeRetainedHeapSize) { updateDominatorWithSkips(parent.objectId, objectId) } val node = when (val referenceMatcher = fieldReferenceMatchers[field.name]) { null -\u0026gt; NormalNode( objectId = objectId, parent = parent, refFromParentType = INSTANCE_FIELD, refFromParentName = field.name ) is LibraryLeakReferenceMatcher -\u0026gt; LibraryLeakChildNode( objectId = objectId, parent = parent, refFromParentType = INSTANCE_FIELD, refFromParentName = field.name, matcher = referenceMatcher ) is IgnoredReferenceMatcher -\u0026gt; null } if (node != null) { enqueue(node) } } State.enqueue @Suppress(\u0026#34;ReturnCount\u0026#34;) private fun State.enqueue( node: ReferencePathNode ) { val visitLast = node is LibraryLeakNode || // We deprioritize thread objects because on Lollipop the thread local values are stored  // as a field.  (node is RootNode \u0026amp;\u0026amp; node.gcRoot is ThreadObject) || (node is NormalNode \u0026amp;\u0026amp; node.parent is RootNode \u0026amp;\u0026amp; node.parent.gcRoot is JavaFrame) if (toVisitLastSet.contains(node.objectId)) { // Already enqueued =\u0026gt; shorter or equal distance amongst library leak ref patterns.  if (visitLast) { return } else { toVisitQueue.add(node) toVisitSet.add(node.objectId) val nodeToRemove = toVisitLastQueue.first { it.objectId == node.objectId } toVisitLastQueue.remove(nodeToRemove) toVisitLastSet.remove(node.objectId) return } } val isLeakingObject = node.objectId in leakingObjectIds if (!isLeakingObject) { val skip = when (val graphObject = graph.findObjectById(node.objectId)) { is HeapClass -\u0026gt; false is HeapInstance -\u0026gt; when { graphObject.isPrimitiveWrapper -\u0026gt; true graphObject.instanceClassName == \u0026#34;java.lang.String\u0026#34; -\u0026gt; true graphObject.instanceClass.instanceByteSize \u0026lt;= sizeOfObjectInstances -\u0026gt; true else -\u0026gt; false } is HeapObjectArray -\u0026gt; when { graphObject.isPrimitiveWrapperArray -\u0026gt; true else -\u0026gt; false } is HeapPrimitiveArray -\u0026gt; true } if (skip) { return } } if (visitLast) { toVisitLastQueue.add(node) toVisitLastSet.add(node.objectId) } else { toVisitQueue.add(node) toVisitSet.add(node.objectId) } State.enqueueGcRoots() private fun State.enqueueGcRoots() { val gcRoots = sortedGcRoots() ...... } State.updateDominator private fun State.updateDominator(//contains very detail doc about the algorithm to generate dominator tree /** * A [HeapGraph] that reads from an indexed [Hprof]. Create a new instance with [indexHprof]. */ HprofHeapGraph constructor class HprofHeapGraph internal constructor( private val hprof: Hprof, private val index: HprofInMemoryIndex ) : HeapGraph { indexHprof companion object { fun indexHprof( hprof: Hprof, proguardMapping: ProguardMapping? = null, indexedGcRootTypes: Set\u0026lt;KClass\u0026lt;out GcRoot\u0026gt;\u0026gt; = setOf( JniGlobal::class, JavaFrame::class, JniLocal::class, MonitorUsed::class, NativeStack::class, StickyClass::class, ThreadBlock::class, // ThreadObject points to threads, which we need to find the thread that a JavaLocalPattern  // belongs to  ThreadObject::class, JniMonitor::class /* Not included here: VmInternal: Ignoring because we\u0026#39;ve got 150K of it, but is this the right thing to do? What\u0026#39;s VmInternal exactly? History does not go further than https://android.googlesource.com/platform/dalvik2/+/refs/heads/master/hit/src/com/android/hit/HprofParser.java#77  We should log to figure out what objects VmInternal points to. ReferenceCleanup: We used to keep it, but the name doesn\u0026#39;t seem like it should create a leak. Unknown: it\u0026#39;s unknown, should we care? We definitely don\u0026#39;t care about those for leak finding: InternedString, Finalizing, Debugger, Unreachable */ ) ): HeapGraph { val index = HprofInMemoryIndex.createReadingHprof(hprof, proguardMapping, indexedGcRootTypes) return HprofHeapGraph(hprof, index) } } createreadinghprof\nfindClassByName override fun findClassByName(className: String): HeapClass? { val classId = index.classId(className) return if (classId == null) { null } else { return findObjectById(classId) as HeapClass } } findObjectById override fun findObjectById(objectId: Long): HeapObject { return findObjectByIdOrNull(objectId) ?: throw IllegalArgumentException( \u0026#34;Object id $objectIdnot found in heap dump.\u0026#34; ) } findObjectByIdOrNull override fun findObjectByIdOrNull(objectId: Long): HeapObject? { if (objectId == javaLangObjectClass?.objectId) return javaLangObjectClass val indexedObject = index.indexedObjectOrNull(objectId) ?: return null return wrapIndexedObject(indexedObject, objectId) } indexedobjectornull\nwrapIndexedObject private fun wrapIndexedObject( indexedObject: IndexedObject, objectId: Long ): HeapObject { return when (indexedObject) { is IndexedClass -\u0026gt; HeapClass(this, indexedObject, objectId) is IndexedInstance -\u0026gt; { val isPrimitiveWrapper = index.primitiveWrapperTypes.contains(indexedObject.classId) HeapInstance(this, indexedObject, objectId, isPrimitiveWrapper) } is IndexedObjectArray -\u0026gt; { val isPrimitiveWrapperArray = index.primitiveWrapperTypes.contains(indexedObject.arrayClassId) HeapObjectArray(this, indexedObject, objectId, isPrimitiveWrapperArray) } is IndexedPrimitiveArray -\u0026gt; HeapPrimitiveArray(this, indexedObject, objectId) } } HprofInMemoryIndex createReadingHprof fun createReadingHprof( hprof: Hprof, proguardMapping: ProguardMapping?, indexedGcRootTypes: Set\u0026lt;KClass\u0026lt;out GcRoot\u0026gt;\u0026gt; ): HprofInMemoryIndex { val recordTypes = setOf( StringRecord::class, LoadClassRecord::class, ClassSkipContentRecord::class, InstanceSkipContentRecord::class, ObjectArraySkipContentRecord::class, PrimitiveArraySkipContentRecord::class, GcRootRecord::class ) val reader = hprof.reader // First pass to count and correctly size arrays once and for all.  var classCount = 0 var instanceCount = 0 var objectArrayCount = 0 var primitiveArrayCount = 0 reader.readHprofRecords(setOf( LoadClassRecord::class, InstanceSkipContentRecord::class, ObjectArraySkipContentRecord::class, PrimitiveArraySkipContentRecord::class ), OnHprofRecordListener { position, record -\u0026gt; when (record) { is LoadClassRecord -\u0026gt; classCount++ is InstanceSkipContentRecord -\u0026gt; instanceCount++ is ObjectArraySkipContentRecord -\u0026gt; objectArrayCount++ is PrimitiveArraySkipContentRecord -\u0026gt; primitiveArrayCount++ } }) hprof.moveReaderTo(reader.startPosition) val indexBuilderListener = Builder( reader.identifierByteSize == 8, hprof.fileLength, classCount, instanceCount, objectArrayCount, primitiveArrayCount, indexedGcRootTypes.map { it.java } .toSet() ) reader.readHprofRecords(recordTypes, indexBuilderListener) return indexBuilderListener.buildIndex(proguardMapping) readhprofrecords\nBuilder /** * Map of string id to string * This currently keeps all the hprof strings that we could care about: class names, * static field names and instance fields names */ // TODO Replacing with a radix trie reversed into a sparse array of long to trie leaf could save // memory. Can be stored as 3 arrays: array of keys, array of values which are indexes into // a large array of string bytes. Each \u0026#34;entry\u0026#34; consists of a size, the index of the previous // segment and then the segment content.  private val hprofStringCache = LongObjectScatterMap\u0026lt;String\u0026gt;() /** * class id to string id */ private val classNames = LongLongScatterMap(expectedElements = classCount) private val classIndex = UnsortedByteEntries( bytesPerValue = positionSize + identifierSize + 4, longIdentifiers = longIdentifiers, initialCapacity = classCount ) private val instanceIndex = UnsortedByteEntries( bytesPerValue = positionSize + identifierSize, longIdentifiers = longIdentifiers, initialCapacity = instanceCount ) private val objectArrayIndex = UnsortedByteEntries( bytesPerValue = positionSize + identifierSize, longIdentifiers = longIdentifiers, initialCapacity = objectArrayCount ) private val primitiveArrayIndex = UnsortedByteEntries( bytesPerValue = positionSize + 1, longIdentifiers = longIdentifiers, initialCapacity = primitiveArrayCount ) onHprofRecord override fun onHprofRecord( position: Long, record: HprofRecord ) { when (record) { is StringRecord -\u0026gt; { if (PRIMITIVE_WRAPPER_TYPES.contains(record.string)) { primitiveWrapperClassNames.add(record.id) } // JVM heap dumps use \u0026#34;/\u0026#34; for package separators (vs \u0026#34;.\u0026#34; for Android heap dumps)  hprofStringCache[record.id] = record.string.replace(\u0026#39;/\u0026#39;, \u0026#39;.\u0026#39;) } is LoadClassRecord -\u0026gt; { classNames[record.id] = record.classNameStringId if (primitiveWrapperClassNames.contains(record.classNameStringId)) { primitiveWrapperTypes.add(record.id) } } is GcRootRecord -\u0026gt; { val gcRoot = record.gcRoot if (gcRoot.id != ValueHolder.NULL_REFERENCE \u0026amp;\u0026amp; indexedGcRootsTypes.contains(gcRoot.javaClass) ) { gcRoots += gcRoot } } is ClassSkipContentRecord -\u0026gt; { classIndex.append(record.id)//write id in an entry  .apply {//write value bytes  writeTruncatedLong(position, positionSize) writeId(record.superclassId) writeInt(record.instanceSize) } } is InstanceSkipContentRecord -\u0026gt; { instanceIndex.append(record.id) .apply { writeTruncatedLong(position, positionSize) writeId(record.classId) } } is ObjectArraySkipContentRecord -\u0026gt; { objectArrayIndex.append(record.id) .apply { writeTruncatedLong(position, positionSize) writeId(record.arrayClassId) } } is PrimitiveArraySkipContentRecord -\u0026gt; { primitiveArrayIndex.append(record.id) .apply { writeTruncatedLong(position, positionSize) writeByte(record.type.ordinal.toByte()) } } } } buildIndex fun buildIndex( proguardMapping: ProguardMapping? ): HprofInMemoryIndex { val sortedInstanceIndex = instanceIndex.moveToSortedMap() val sortedObjectArrayIndex = objectArrayIndex.moveToSortedMap() val sortedPrimitiveArrayIndex = primitiveArrayIndex.moveToSortedMap() val sortedClassIndex = classIndex.moveToSortedMap() // Passing references to avoid copying the underlying data structures.  return HprofInMemoryIndex( positionSize, hprofStringCache, classNames, sortedClassIndex, sortedInstanceIndex, sortedObjectArrayIndex, sortedPrimitiveArrayIndex, gcRoots, proguardMapping, primitiveWrapperTypes ) } movetosortedmap\nindexedObjectOrNull fun indexedObjectOrNull(objectId: Long): IndexedObject? { var array: ByteSubArray? = classIndex[objectId] if (array != null) { return IndexedClass( position = array.readTruncatedLong(positionSize), superclassId = array.readId(), instanceSize = array.readInt() ) } array = instanceIndex[objectId] if (array != null) { return IndexedInstance( position = array.readTruncatedLong(positionSize), classId = array.readId() ) } array = objectArrayIndex[objectId] if (array != null) { return IndexedObjectArray( position = array.readTruncatedLong(positionSize), arrayClassId = array.readId() ) } array = primitiveArrayIndex[objectId] if (array != null) { return IndexedPrimitiveArray( position = array.readTruncatedLong(positionSize), primitiveType = PrimitiveType.values()[array.readByte() .toInt()] ) } return null } shark-hprof/src/main/java/shark/HprofReader.kt\nHprofReader readHprofRecords /** * Reads all hprof records from [source]. * Assumes the [reader] was has a source that currently points to the start position of hprof * records. */ @Suppress(\u0026#34;ComplexMethod\u0026#34;, \u0026#34;LongMethod\u0026#34;) fun readHprofRecords( recordTypes: Set\u0026lt;KClass\u0026lt;out HprofRecord\u0026gt;\u0026gt;, listener: OnHprofRecordListener ) { while (!exhausted()) { // type of the record  val tag = readUnsignedByte() // number of microseconds since the time stamp in the header  skip(intByteSize) // number of bytes that follow and belong to this record  val length = readUnsignedInt() when (tag) { STRING_IN_UTF8 -\u0026gt; { if (readStringRecord) { val recordPosition = position val id = readId() val stringLength = length - identifierByteSize val string = readUtf8(stringLength) val record = StringRecord(id, string) listener.onHprofRecord(recordPosition, record) } else { skip(length) } } LOAD_CLASS -\u0026gt; { if (readLoadClassRecord) { val recordPosition = position val classSerialNumber = readInt() val id = readId() val stackTraceSerialNumber = readInt() val classNameStringId = readId() reusedLoadClassRecord.apply { this.classSerialNumber = classSerialNumber this.id = id this.stackTraceSerialNumber = stackTraceSerialNumber this.classNameStringId = classNameStringId } listener.onHprofRecord(recordPosition, reusedLoadClassRecord) } else { skip(length) } } STACK_FRAME -\u0026gt; {} STACK_TRACE -\u0026gt; {} HEAP_DUMP, HEAP_DUMP_SEGMENT -\u0026gt; { val heapDumpStart = position var previousTag = 0 var previousTagPosition = 0L while (position - heapDumpStart \u0026lt; length) { val heapDumpTagPosition = position val heapDumpTag = readUnsignedByte()//position increase  when (heapDumpTag) { ROOT_UNKNOWN -\u0026gt; { if (readGcRootRecord) { val recordPosition = position val record = GcRootRecord(gcRoot = Unknown(id = readId())) listener.onHprofRecord(recordPosition, record) } else { skip(identifierByteSize)//position increase  } } ROOT_JNI_GLOBAL -\u0026gt; { if (readGcRootRecord) { val recordPosition = position val gcRootRecord = GcRootRecord(gcRoot = JniGlobal(id = readId(), jniGlobalRefId = readId())) listener.onHprofRecord(recordPosition, gcRootRecord) } else { skip(identifierByteSize + identifierByteSize) } } } HEAP_DUMP_END -\u0026gt; { if (readHeapDumpEndRecord) { val recordPosition = position val record = HeapDumpEndRecord listener.onHprofRecord(recordPosition, record) } } else -\u0026gt; { skip(length) } HprofRecord /** * A Hprof record. These data structure map 1:1 with how records are written in hprof files. */ sealed class HprofRecord { class StringRecord( val id: Long, val string: String ) : HprofRecord() class LoadClassRecord( classSerialNumber: Int, id: Long, stackTraceSerialNumber: Int, classNameStringId: Long ) : HprofRecord() { ...... ObjectRecord sealed class ObjectRecord : HeapDumpRecord() { class ClassDumpRecord( val id: Long, val stackTraceSerialNumber: Int, val superclassId: Long, val classLoaderId: Long, val signersId: Long, val protectionDomainId: Long, val instanceSize: Int, val staticFields: List\u0026lt;StaticFieldRecord\u0026gt;, val fields: List\u0026lt;FieldRecord\u0026gt; ) : ObjectRecord() { } class InstanceDumpRecord( val id: Long, val stackTraceSerialNumber: Int, val classId: Long, /** * Instance field values (this class, followed by super class, etc) */ val fieldValues: ByteArray ) : ObjectRecord() class ObjectArrayDumpRecord( val id: Long, val stackTraceSerialNumber: Int, val arrayClassId: Long, val elementIds: LongArray ) : ObjectRecord() sealed class PrimitiveArrayDumpRecord : ObjectRecord() { } /** * An object in the heap dump. */ HeapObject /** * This [HeapObject] as a [HeapClass] if it is one, or null otherwise */ val asClass: HeapClass? get() = if (this is HeapClass) this else null /** * This [HeapObject] as a [HeapInstance] if it is one, or null otherwise */ val asInstance: HeapInstance? get() = if (this is HeapInstance) this else null /** * A class in the heap dump. */ class HeapClass internal constructor( private val hprofGraph: HprofHeapGraph, private val indexedObject: IndexedClass, override val objectId: Long ) : HeapObject() { /** * Returns a [HeapField] object that reflects the specified declared * field of the class represented by this [HeapClass] object, or null if this field does not * exist. The [name] parameter specifies the simple name of the desired field. * * Also available as a convenience operator: [get] * * This may trigger IO reads. */ fun readStaticField(fieldName: String): HeapField? { for (fieldRecord in readRecord().staticFields) { if (hprofGraph.staticFieldName(objectId, fieldRecord) == fieldName) { return HeapField( this, hprofGraph.staticFieldName(objectId, fieldRecord), HeapValue(hprofGraph, fieldRecord.value) ) } } return null } } /** * An instance in the heap dump. */ class HeapInstance internal constructor( private val hprofGraph: HprofHeapGraph, internal val indexedObject: IndexedInstance, override val objectId: Long, /** * Whether this is an instance of a primitive wrapper type. */ val isPrimitiveWrapper: Boolean ) : HeapObject() { /** * Returns a [HeapField] object that reflects the specified declared * field of the instance represented by this [HeapInstance] object, or null if this field does * not exist. The [declaringClassName] specifies the class in which the desired field is * declared, and the [fieldName] parameter specifies the simple name of the desired field. * * Also available as a convenience operator: [get] * * This may trigger IO reads. */ fun readField( declaringClassName: String, fieldName: String ): HeapField? { return readFields().firstOrNull { field -\u0026gt; field.declaringClass.name == declaringClassName \u0026amp;\u0026amp; field.name == fieldName } } } readFields /** * The fields of this instance, as a sequence of [HeapField]. * * This may trigger IO reads. */ fun readFields(): Sequence\u0026lt;HeapField\u0026gt; { val fieldReader by lazy { hprofGraph.createFieldValuesReader(readRecord()) } return instanceClass.classHierarchy .map { heapClass -\u0026gt; heapClass.readRecord() .fields.asSequence() .map { fieldRecord -\u0026gt; val fieldName = hprofGraph.fieldName(heapClass.objectId, fieldRecord) val fieldValue = fieldReader.readValue(fieldRecord) HeapField(heapClass, fieldName, HeapValue(hprofGraph, fieldValue)) } } .flatten()//change two dimensional sequence into one dimensional } IndexedObject internal sealed class IndexedObject { abstract val position: Long class IndexedClass( override val position: Long, val superclassId: Long, val instanceSize: Int ) : IndexedObject() class IndexedInstance( override val position: Long, val classId: Long ) : IndexedObject() class IndexedObjectArray( override val position: Long, val arrayClassId: Long ) : IndexedObject() class IndexedPrimitiveArray( override val position: Long, primitiveType: PrimitiveType ) : IndexedObject() { private val primitiveTypeOrdinal: Byte = primitiveType.ordinal.toByte() val primitiveType: PrimitiveType get() = PrimitiveType.values()[primitiveTypeOrdinal.toInt()] } } UnsortedByteEntries /** * Wraps a byte array of entries where each entry is an id followed by bytes for the value. * `id` is a long if [longIdentifiers] is true and an int otherwise. Each entry has [bytesPerValue] * value bytes. Entries are appended into the array via [append]. Once done, the backing array * is sorted and turned into a [SortedBytesMap] by calling [moveToSortedMap]. */ internal class UnsortedByteEntries( private val bytesPerValue: Int, private val longIdentifiers: Boolean, private val initialCapacity: Int = 4, private val growthFactor: Double = 2.0 ) { private val bytesPerEntry = bytesPerValue + if (longIdentifiers) 8 else 4 private var entries: ByteArray? = null private val subArray = MutableByteSubArray() private var subArrayIndex = 0 private var assigned: Int = 0 private var currentCapacity = 0 append fun append( key: Long ): MutableByteSubArray { if (entries == null) { currentCapacity = initialCapacity entries = ByteArray(currentCapacity * bytesPerEntry) } else { if (currentCapacity == assigned) { val newCapacity = (currentCapacity * growthFactor).toInt() growEntries(newCapacity) currentCapacity = newCapacity } } assigned++ subArrayIndex = 0 subArray.writeId(key) return subArray } moveToSortedMap fun moveToSortedMap(): SortedBytesMap { if (assigned == 0) { return SortedBytesMap(longIdentifiers, bytesPerValue, ByteArray(0)) } val entries = entries!! // Sort entries by keys, which are ids of 4 or 8 bytes.  ByteArrayTimSort.sort(entries, 0, assigned, bytesPerEntry, object : ByteArrayComparator { override fun compare( entrySize: Int, o1Array: ByteArray, o1Index: Int, o2Array: ByteArray, o2Index: Int ): Int { return if (longIdentifiers) { readLong(o1Array, o1Index * entrySize) .compareTo( readLong(o2Array, o2Index * entrySize) ) } else { readInt(o1Array, o1Index * entrySize) .compareTo( readInt(o2Array, o2Index * entrySize) ) } } }) val sortedEntries = if (entries.size \u0026gt; assigned * bytesPerEntry) { entries.copyOf(assigned * bytesPerEntry) } else entries this.entries = null assigned = 0 return SortedBytesMap( longIdentifiers, bytesPerValue, sortedEntries ) } SortedBytesMap /** * A read only map of `id` =\u0026gt; `byte array` sorted by id, where `id` is a long if [longIdentifiers] * is true and an int otherwise. Each entry has a value byte array of size [bytesPerValue]. * * Instances are created by [UnsortedByteEntries] * * [get] and [contains] perform a binary search to locate a specific entry by key. */ internal class SortedBytesMap( private val longIdentifiers: Boolean, private val bytesPerValue: Int, private val sortedEntries: ByteArray ) { private val bytesPerKey = if (longIdentifiers) 8 else 4 private val bytesPerEntry = bytesPerKey + bytesPerValue private val size = sortedEntries.size / bytesPerEntry operator get operator fun get(key: Long): ByteSubArray? { val keyIndex = binarySearch(key) if (keyIndex \u0026lt; 0) { return null } val valueIndex = keyIndex * bytesPerEntry + bytesPerKey return ByteSubArray(sortedEntries, valueIndex, bytesPerValue, longIdentifiers) } binarySearch(二分查找) private fun binarySearch( key: Long ): Int { val startIndex = 0 val endIndex = size var lo = startIndex var hi = endIndex - 1 while (lo \u0026lt;= hi) { val mid = (lo + hi).ushr(1) val midVal = keyAt(mid) when { midVal \u0026lt; key -\u0026gt; lo = mid + 1 midVal \u0026gt; key -\u0026gt; hi = mid - 1 else -\u0026gt; return mid } } return lo.inv() } LongLongScatterMap getSlot /** * Being given a key looks it up in the map and returns the slot where element sits, so it later * can be retrieved with [getSlotValue]; return \u0026#39;-1\u0026#39; if element not found. * Why so complicated and not just make [get] return null if value not found? The reason is performance: * this approach prevents unnecessary boxing of the primitive long that would happen with nullable Long? */ fun getSlot(key: Long): Int { if (key == 0L) { return if (hasEmptyKey) mask + 1 else -1 } else { val keys = this.keys val mask = this.mask var slot = hashKey(key) and mask var existing = keys[slot] while (existing != 0L) { if (existing == key) { return slot } slot = slot + 1 and mask existing = keys[slot] } return -1 } } getSlotValue * Being given a slot of element retrieves it from the collection */ fun getSlotValue(slot: Int): Long = values[slot] "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/lifecycle/lifecycle/",
	"title": "Lifecycle",
	"tags": [],
	"description": "",
	"content": "设计图 https://developer.android.com/topic/libraries/architecture/lifecycle\n生命周期感知型组件的最佳做法  使界面控制器（Activity 和 Fragment）尽可能保持精简。它们不应试图获取自己的数据，而应使用 ViewModel 执行此操作，并观察 LiveData 对象以将更改体现到视图中。 设法编写数据驱动型界面，对于此类界面，界面控制器的责任是随着数据更改而更新视图，或者将用户操作通知给 ViewModel。 将数据逻辑放在 ViewModel 类中。ViewModel 应充当界面控制器与应用其余部分之间的连接器。不过要注意，ViewModel 不负责获取数据（例如，从网络获取）。但是，ViewModel 应调用相应的组件来获取数据，然后将结果提供给界面控制器。 使用数据绑定在视图与界面控制器之间维持干净的接口。这样一来，您可以使视图更具声明性，并尽量减少需要在 Activity 和 Fragment 中编写的更新代码。如果您更愿意使用 Java 编程语言执行此操作，请使用诸如 Butter Knife 之类的库，以避免样板代码并实现更好的抽象化。 如果界面很复杂，不妨考虑创建 presenter 类来处理界面的修改。这可能是一项艰巨的任务，但这样做可使界面组件更易于测试。 避免在 ViewModel 中引用 View 或 Activity 上下文。如果 ViewModel 存在的时间比 Activity 更长（在配置更改的情况下），Activity 将泄漏并且不会获得垃圾回收器的妥善处置。 使用 Kotlin 协程管理长时间运行的任务和其他可以异步运行的操作。  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/lifecycle/",
	"title": "lifecycle",
	"tags": [],
	"description": "",
	"content": "lifecycle 探索总结lifecycle知识\n Lifecycle     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/livedata/livedata/",
	"title": "LiveData",
	"tags": [],
	"description": "",
	"content": "类设计 androidx.lifecycle:lifecycle-livedata:2.0.0\nandroidx.lifecycle:lifecycle-livedata-core:2.0.0\nobserve private SafeIterableMap\u0026lt;Observer\u0026lt;? super T\u0026gt;, ObserverWrapper\u0026gt; mObservers = new SafeIterableMap\u0026lt;\u0026gt;(); observe @MainThread public void observe(@NonNull LifecycleOwner owner, @NonNull Observer\u0026lt;? super T\u0026gt; observer) { assertMainThread(\u0026#34;observe\u0026#34;); if (owner.getLifecycle().getCurrentState() == DESTROYED) { // ignore  return; } LifecycleBoundObserver wrapper = new LifecycleBoundObserver(owner, observer); ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing != null \u0026amp;\u0026amp; !existing.isAttachedTo(owner)) { throw new IllegalArgumentException(\u0026#34;Cannot add the same observer\u0026#34; + \u0026#34; with different lifecycles\u0026#34;); } if (existing != null) { return; } owner.getLifecycle().addObserver(wrapper); } LifecycleBoundObserver class LifecycleBoundObserver extends ObserverWrapper implements LifecycleEventObserver { final LifecycleOwner mOwner; @Override boolean shouldBeActive() { return mOwner.getLifecycle().getCurrentState().isAtLeast(STARTED); } @Override public void onStateChanged(@NonNull LifecycleOwner source, @NonNull Lifecycle.Event event) { if (mOwner.getLifecycle().getCurrentState() == DESTROYED) { removeObserver(mObserver); return; } activeStateChanged(shouldBeActive()); } observeForever @MainThread public void observeForever(@NonNull Observer\u0026lt;? super T\u0026gt; observer) { assertMainThread(\u0026#34;observeForever\u0026#34;); AlwaysActiveObserver wrapper = new AlwaysActiveObserver(observer); ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing instanceof LiveData.LifecycleBoundObserver) { throw new IllegalArgumentException(\u0026#34;Cannot add the same observer\u0026#34; + \u0026#34; with different lifecycles\u0026#34;); } if (existing != null) { return; } wrapper.activeStateChanged(true); } AlwaysActiveObserver private class AlwaysActiveObserver extends ObserverWrapper { @Override boolean shouldBeActive() { return true; } } updateValue postValue protected void postValue(T value) { boolean postTask; synchronized (mDataLock) { postTask = mPendingData == NOT_SET; mPendingData = value; } if (!postTask) { return; } ArchTaskExecutor.getInstance().postToMainThread(mPostValueRunnable); } private final Runnable mPostValueRunnable = new Runnable() { @Override public void run() { Object newValue; synchronized (mDataLock) { newValue = mPendingData; mPendingData = NOT_SET; } //noinspection unchecked  setValue((T) newValue); } }; setValue @MainThread protected void setValue(T value) { assertMainThread(\u0026#34;setValue\u0026#34;); mVersion++; mData = value; dispatchingValue(null);//null标识通知mObservers中的所有Observer } LifecycleBoundObserver.onStateChanged @Override public void onStateChanged(LifecycleOwner source, Lifecycle.Event event) { if (mOwner.getLifecycle().getCurrentState() == DESTROYED) { removeObserver(mObserver); return; } activeStateChanged(shouldBeActive()); } ObserverWrapper.activeStateChanged void activeStateChanged(boolean newActive) { if (newActive == mActive) { return; } //仅在active状态发生变化时才继续流程  // immediately set active state, so we\u0026#39;d never dispatch anything to inactive owner  mActive = newActive; boolean wasInactive = LiveData.this.mActiveCount == 0; LiveData.this.mActiveCount += mActive ? 1 : -1; if (wasInactive \u0026amp;\u0026amp; mActive) { onActive(); } if (LiveData.this.mActiveCount == 0 \u0026amp;\u0026amp; !mActive) { onInactive(); } if (mActive) {//仅仅在active时才dispatchValue  dispatchingValue(this);//通知当前observer  } } dispatchingValue //如果传递了参数ObserverWrapper，则对其considerNotify，否则对mObservers中的item进行considerNotify void dispatchingValue(@Nullable ObserverWrapper initiator) { if (mDispatchingValue) { mDispatchInvalidated = true; return; } mDispatchingValue = true; do { mDispatchInvalidated = false; if (initiator != null) { considerNotify(initiator); initiator = null; } else { for (Iterator\u0026lt;Map.Entry\u0026lt;Observer\u0026lt;? super T\u0026gt;, ObserverWrapper\u0026gt;\u0026gt; iterator = mObservers.iteratorWithAdditions(); iterator.hasNext(); ) { considerNotify(iterator.next().getValue()); if (mDispatchInvalidated) { break; } } } } while (mDispatchInvalidated); mDispatchingValue = false; } considerNotify private void considerNotify(ObserverWrapper observer) { if (!observer.mActive) { return; } // Check latest state b4 dispatch. Maybe it changed state but we didn\u0026#39;t get the event yet.  //  // we still first check observer.active to keep it as the entrance for events. So even if  // the observer moved to an active state, if we\u0026#39;ve not received that event, we better not  // notify for a more predictable notification order.  if (!observer.shouldBeActive()) { observer.activeStateChanged(false); return; } if (observer.mLastVersion \u0026gt;= mVersion) { return; } //only when mVersion \u0026gt; observer.mLastVersion  observer.mLastVersion = mVersion; //noinspection unchecked  observer.mObserver.onChanged((T) mData); } LifecycleBoundObserver.shouldBeActive @Override boolean shouldBeActive() { return mOwner.getLifecycle().getCurrentState().isAtLeast(STARTED); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/livedata/",
	"title": "livedata",
	"tags": [],
	"description": "",
	"content": "livedata 探索总结livedata知识\n LiveData     LiveData封装     MediatorLiveData     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/livedata/livedata%E5%B0%81%E8%A3%85/",
	"title": "LiveData封装",
	"tags": [],
	"description": "",
	"content": "https://developer.android.com/kotlin/ktx#livedata\nLiveData协程 @UseExperimental(ExperimentalTypeInference::class) fun \u0026lt;T\u0026gt; liveData( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, @BuilderInference block: suspend LiveDataScope\u0026lt;T\u0026gt;.() -\u0026gt; Unit ): LiveData\u0026lt;T\u0026gt; = CoroutineLiveData(context, timeoutInMs, block) CoroutineLiveData internal typealias Block\u0026lt;T\u0026gt; = suspend LiveDataScope\u0026lt;T\u0026gt;.() -\u0026gt; Unit internal class CoroutineLiveData\u0026lt;T\u0026gt;( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, block: Block\u0026lt;T\u0026gt; ) : MediatorLiveData\u0026lt;T\u0026gt;() { private var blockRunner: BlockRunner\u0026lt;T\u0026gt;? private var emittedSource: EmittedSource? = null init { // use an intermediate supervisor job so that if we cancel individual block runs due to losing  // observers, it won\u0026#39;t cancel the given context as we only cancel w/ the intention of possibly  // relaunching using the same parent context.  val supervisorJob = SupervisorJob(context[Job]) // The scope for this LiveData where we launch every block Job.  // We default to Main dispatcher but developer can override it.  // The supervisor job is added last to isolate block runs.  val scope = CoroutineScope(Dispatchers.Main.immediate + context + supervisorJob) blockRunner = BlockRunner( liveData = this, block = block, timeoutInMs = timeoutInMs, scope = scope ) { blockRunner = null } } } onActive override fun onActive() { super.onActive() blockRunner?.maybeRun() } BlockRunner.maybeRun @MainThread fun maybeRun() { cancellationJob?.cancel() cancellationJob = null if (runningJob != null) { return } runningJob = scope.launch { val liveDataScope = LiveDataScopeImpl(liveData, coroutineContext) block(liveDataScope) onDone() } } onInactive override fun onInactive() { super.onInactive() blockRunner?.cancel() } BlockRunner.cancel @MainThread fun cancel() { if (cancellationJob != null) { error(\u0026#34;Cancel call cannot happen without a maybeRun\u0026#34;) } cancellationJob = scope.launch(Dispatchers.Main.immediate) { delay(timeoutInMs) if (!liveData.hasActiveObservers()) { // one last check on active observers to avoid any race condition between starting  // a running coroutine and cancelation  runningJob?.cancel() runningJob = null } } } LiveDataScope interface LiveDataScope\u0026lt;T\u0026gt; { suspend fun emit(value: T) suspend fun emitSource(source: LiveData\u0026lt;T\u0026gt;): DisposableHandle val latestValue: T? } internal class LiveDataScopeImpl\u0026lt;T\u0026gt;( internal var target: CoroutineLiveData\u0026lt;T\u0026gt;, context: CoroutineContext ) : LiveDataScope\u0026lt;T\u0026gt; { override val latestValue: T? get() = target.value // use `liveData` provided context + main dispatcher to communicate with the target  // LiveData. This gives us main thread safety as well as cancellation cooperation  private val coroutineContext = context + Dispatchers.Main.immediate override suspend fun emitSource(source: LiveData\u0026lt;T\u0026gt;): DisposableHandle = withContext(coroutineContext) { return@withContext target.emitSource(source) } override suspend fun emit(value: T) = withContext(coroutineContext) { target.clearSource() target.value = value } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/handler/looper/",
	"title": "Looper",
	"tags": [],
	"description": "",
	"content": "原理总结 Looper就是对epoll系统调用的封装层，屏蔽外部对epoll的直接使用\nLooper addFd int Looper::addFd(int fd, int ident, int events, Looper_callbackFunc callback, void* data) { // use SimpleLooperCallback as adapter from handleEvent to callback function  return addFd(fd, ident, events, callback ? new SimpleLooperCallback(callback) : NULL, data); } int Looper::addFd(int fd, int ident, int events, const sp\u0026lt;LooperCallback\u0026gt;\u0026amp; callback, void* data) { if (!callback.get()) { if (! mAllowNonCallbacks) { ALOGE(\u0026#34;Invalid attempt to set NULL callback but not allowed for this looper.\u0026#34;); return -1; } if (ident \u0026lt; 0) { ALOGE(\u0026#34;Invalid attempt to set NULL callback with ident \u0026lt; 0.\u0026#34;); return -1; } } else { ident = POLL_CALLBACK; } Request request; request.fd = fd; request.ident = ident; request.events = events; request.seq = mNextRequestSeq++; request.callback = callback; request.data = data; struct epoll_event eventItem; request.initEventItem(\u0026amp;eventItem); ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex \u0026lt; 0) { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, fd, \u0026amp; eventItem); mRequests.add(fd, request); } else { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_MOD, fd, \u0026amp; eventItem); } } Request::initEventItem void Looper::Request::initEventItem(struct epoll_event* eventItem) const { int epollEvents = 0; if (events \u0026amp; EVENT_INPUT) epollEvents |= EPOLLIN; if (events \u0026amp; EVENT_OUTPUT) epollEvents |= EPOLLOUT; memset(eventItem, 0, sizeof(epoll_event)); // zero out unused members of data field union  eventItem-\u0026gt;events = epollEvents; eventItem-\u0026gt;data.fd = fd; } pollOnce int Looper::pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) { int result = 0; for (;;) { while (mResponseIndex \u0026lt; mResponses.size()) { const Response\u0026amp; response = mResponses.itemAt(mResponseIndex++); int ident = response.request.ident; if (ident \u0026gt;= 0) { int fd = response.request.fd; int events = response.events; void* data = response.request.data; if (outFd != NULL) *outFd = fd; if (outEvents != NULL) *outEvents = events; if (outData != NULL) *outData = data; return ident; } } if (result != 0) { if (outFd != NULL) *outFd = 0; if (outEvents != NULL) *outEvents = 0; if (outData != NULL) *outData = NULL; return result; } result = pollInner(timeoutMillis); } } pollInner int Looper::pollInner(int timeoutMillis) { // Poll.  int result = POLL_WAKE; mResponses.clear(); mResponseIndex = 0; struct epoll_event eventItems[EPOLL_MAX_EVENTS]; int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_EVENTS, timeoutMillis); for (int i = 0; i \u0026lt; eventCount; i++) { int fd = eventItems[i].data.fd; uint32_t epollEvents = eventItems[i].events; if (fd == mWakeEventFd) { if (epollEvents \u0026amp; EPOLLIN) { awoken(); } } else { ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex \u0026gt;= 0) { int events = 0; if (epollEvents \u0026amp; EPOLLIN) events |= EVENT_INPUT; if (epollEvents \u0026amp; EPOLLOUT) events |= EVENT_OUTPUT; if (epollEvents \u0026amp; EPOLLERR) events |= EVENT_ERROR; if (epollEvents \u0026amp; EPOLLHUP) events |= EVENT_HANGUP; pushResponse(events, mRequests.valueAt(requestIndex)); } } } //1：处理C层发送的消息  // Invoke pending message callbacks.  mNextMessageUptime = LLONG_MAX; while (mMessageEnvelopes.size() != 0) { nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); const MessageEnvelope\u0026amp; messageEnvelope = mMessageEnvelopes.itemAt(0); if (messageEnvelope.uptime \u0026lt;= now) { // Remove the envelope from the list.  // We keep a strong reference to the handler until the call to handleMessage  // finishes. Then we drop it so that the handler can be deleted *before*  // we reacquire our lock.  { // obtain handler  sp\u0026lt;MessageHandler\u0026gt; handler = messageEnvelope.handler; Message message = messageEnvelope.message; mMessageEnvelopes.removeAt(0); mSendingMessage = true; mLock.unlock(); handler-\u0026gt;handleMessage(message); } // release handler  mLock.lock(); mSendingMessage = false; result = POLL_CALLBACK; } else { // The last message left at the head of the queue determines the next wakeup time.  mNextMessageUptime = messageEnvelope.uptime; break; } } //2：回调通过addFd添加进来的监听  // Invoke all response callbacks.  for (size_t i = 0; i \u0026lt; mResponses.size(); i++) { Response\u0026amp; response = mResponses.editItemAt(i); if (response.request.ident == POLL_CALLBACK) { int fd = response.request.fd; int events = response.events; void* data = response.request.data; // Invoke the callback. Note that the file descriptor may be closed by  // the callback (and potentially even reused) before the function returns so  // we need to be a little careful when removing the file descriptor afterwards.  int callbackResult = response.request.callback-\u0026gt;handleEvent(fd, events, data);//回调flutter在MessageLoopAndroid构造方法中设置的callback监听  if (callbackResult == 0) {//callback方法返回0时表示需要移除该fd监听  removeFd(fd, response.request.seq); } // Clear the callback reference in the response structure promptly because we  // will not clear the response vector itself until the next poll.  response.request.callback.clear(); result = POLL_CALLBACK; } } return result;//3：:返回之后回到java层的死循环处处理java层消息 } pushResponse void Looper::pushResponse(int events, const Request\u0026amp; request) { Response response; response.events = events; response.request = request; mResponses.push(response); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/livedata/mediatorlivedata/",
	"title": "MediatorLiveData",
	"tags": [],
	"description": "",
	"content": "MutableLiveData public class MutableLiveData\u0026lt;T\u0026gt; extends LiveData\u0026lt;T\u0026gt; { /** * Creates a MutableLiveData initialized with the given {@code value}. * * @param value initial value */ public MutableLiveData(T value) { super(value); } /** * Creates a MutableLiveData with no value assigned to it. */ public MutableLiveData() { super(); } @Override public void postValue(T value) { super.postValue(value); } @Override public void setValue(T value) { super.setValue(value); } } MediatorLiveData public class MediatorLiveData\u0026lt;T\u0026gt; extends MutableLiveData\u0026lt;T\u0026gt; { private SafeIterableMap\u0026lt;LiveData\u0026lt;?\u0026gt;, Source\u0026lt;?\u0026gt;\u0026gt; mSources = new SafeIterableMap\u0026lt;\u0026gt;(); addSource @MainThread public \u0026lt;S\u0026gt; void addSource(@NonNull LiveData\u0026lt;S\u0026gt; source, @NonNull Observer\u0026lt;? super S\u0026gt; onChanged) { Source\u0026lt;S\u0026gt; e = new Source\u0026lt;\u0026gt;(source, onChanged); Source\u0026lt;?\u0026gt; existing = mSources.putIfAbsent(source, e); if (existing != null \u0026amp;\u0026amp; existing.mObserver != onChanged) { throw new IllegalArgumentException( \u0026#34;This source was already added with the different observer\u0026#34;); } if (existing != null) { return; } if (hasActiveObservers()) { e.plug(); } } removeSource @MainThread public \u0026lt;S\u0026gt; void removeSource(@NonNull LiveData\u0026lt;S\u0026gt; toRemote) { Source\u0026lt;?\u0026gt; source = mSources.remove(toRemote); if (source != null) { source.unplug(); } } onActive @CallSuper @Override protected void onActive() { for (Map.Entry\u0026lt;LiveData\u0026lt;?\u0026gt;, Source\u0026lt;?\u0026gt;\u0026gt; source : mSources) { source.getValue().plug(); } } onInactive @CallSuper @Override protected void onInactive() { for (Map.Entry\u0026lt;LiveData\u0026lt;?\u0026gt;, Source\u0026lt;?\u0026gt;\u0026gt; source : mSources) { source.getValue().unplug(); } } Source private static class Source\u0026lt;V\u0026gt; implements Observer\u0026lt;V\u0026gt; { final LiveData\u0026lt;V\u0026gt; mLiveData; final Observer\u0026lt;? super V\u0026gt; mObserver; int mVersion = START_VERSION; Source(LiveData\u0026lt;V\u0026gt; liveData, final Observer\u0026lt;? super V\u0026gt; observer) { mLiveData = liveData; mObserver = observer; } void plug() { mLiveData.observeForever(this); } void unplug() { mLiveData.removeObserver(this); } @Override public void onChanged(@Nullable V v) { if (mVersion != mLiveData.getVersion()) { mVersion = mLiveData.getVersion(); mObserver.onChanged(v); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/messageloop/",
	"title": "MessageLoop",
	"tags": [],
	"description": "",
	"content": "TaskRunners::TaskRunners(std::string label, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; platform, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; gpu, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; ui, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; io) : label_(std::move(label)), platform_(std::move(platform)), gpu_(std::move(gpu)), ui_(std::move(ui)), io_(std::move(io)) {} ThreadHost::ThreadHost /// The collection of all the threads used by the engine. ThreadHost enum Type { Platform = 1 \u0026lt;\u0026lt; 0, UI = 1 \u0026lt;\u0026lt; 1, GPU = 1 \u0026lt;\u0026lt; 2, IO = 1 \u0026lt;\u0026lt; 3, }; std::unique_ptr\u0026lt;fml::Thread\u0026gt; platform_thread; std::unique_ptr\u0026lt;fml::Thread\u0026gt; ui_thread; std::unique_ptr\u0026lt;fml::Thread\u0026gt; gpu_thread; std::unique_ptr\u0026lt;fml::Thread\u0026gt; io_thread; ThreadHost(std::string name_prefix, uint64_t type_mask); ThreadHost::ThreadHost(std::string name_prefix, uint64_t mask) { if (mask \u0026amp; ThreadHost::Type::Platform) { platform_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.platform\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::UI) { ui_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.ui\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::GPU) { gpu_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.gpu\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::IO) { io_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.io\u0026#34;); } } Thread::Thread Thread std::unique_ptr\u0026lt;std::thread\u0026gt; thread_; fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; task_runner_; Thread::Thread(const std::string\u0026amp; name) : joined_(false) { fml::AutoResetWaitableEvent latch; fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; runner; thread_ = std::make_unique\u0026lt;std::thread\u0026gt;([\u0026amp;latch, \u0026amp;runner, name]() -\u0026gt; void { SetCurrentThreadName(name); fml::MessageLoop::EnsureInitializedForCurrentThread(); auto\u0026amp; loop = MessageLoop::GetCurrent(); runner = loop.GetTaskRunner(); latch.Signal(); loop.Run(); }); latch.Wait(); task_runner_ = runner; } tls_message_loop.reset(new MessageLoop()); MessageLoop fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop_; fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; task_runner_; FML_THREAD_LOCAL ThreadLocalUniquePtr\u0026lt;MessageLoop\u0026gt; tls_message_loop; void MessageLoop::EnsureInitializedForCurrentThread() { if (tls_message_loop.get() != nullptr) { // Already initialized.  return; } tls_message_loop.reset(new MessageLoop()); } MessageLoop::MessageLoop() : loop_(MessageLoopImpl::Create()), task_runner_(fml::MakeRefCounted\u0026lt;fml::TaskRunner\u0026gt;(loop_)) { } MessageLoop\u0026amp; MessageLoop::GetCurrent() { auto* loop = tls_message_loop.get(); return *loop; } void MessageLoop::Run() { loop_-\u0026gt;DoRun(); } TaskRunner::TaskRunner //TaskRunner  fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop_; TaskRunner::TaskRunner(fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop) : loop_(std::move(loop)) {} MessageLoopImpl::Create MessageLoopImpl // Exposed for the embedder shell which allows clients to poll for events  // instead of dedicating a thread to the message loop.  friend class MessageLoop; fml::RefPtr\u0026lt;MessageLoopTaskQueues\u0026gt; task_queue_; TaskQueueId queue_id_; fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; MessageLoopImpl::Create() { #if OS_MACOSX  return fml::MakeRefCounted\u0026lt;MessageLoopDarwin\u0026gt;(); #elif OS_ANDROID  return fml::MakeRefCounted\u0026lt;MessageLoopAndroid\u0026gt;(); #elif OS_FUCHSIA  return fml::MakeRefCounted\u0026lt;MessageLoopFuchsia\u0026gt;(); #elif OS_LINUX  return fml::MakeRefCounted\u0026lt;MessageLoopLinux\u0026gt;(); #elif OS_WIN  return fml::MakeRefCounted\u0026lt;MessageLoopWin\u0026gt;(); #else  return nullptr; #endif } void MessageLoopImpl::DoRun() { if (terminated_) { // Message loops may be run only once.  return; } // Allow the implementation to do its thing.  Run();//main  // The loop may have been implicitly terminated. This can happen if the  // implementation supports termination via platform specific APIs or just  // error conditions. Set the terminated flag manually.  terminated_ = true; // The message loop is shutting down. Check if there are expired tasks. This  // is the last chance for expired tasks to be serviced. Make sure the  // terminated flag is already set so we don\u0026#39;t accrue additional tasks now.  RunExpiredTasksNow(); // When the message loop is in the process of shutting down, pending tasks  // should be destructed on the message loop\u0026#39;s thread. We have just returned  // from the implementations |Run| method which we know is on the correct  // thread. Drop all pending tasks on the floor.  task_queue_-\u0026gt;DisposeTasks(queue_id_); } MessageLoopAndroid::Run MessageLoopAndroid fml::UniqueObject\u0026lt;ALooper*, UniqueLooperTraits\u0026gt; looper_; fml::UniqueFD timer_fd_; MessageLoopAndroid::MessageLoopAndroid() : looper_(AcquireLooperForThread()), timer_fd_(::timerfd_create(kClockType, TFD_NONBLOCK | TFD_CLOEXEC)), running_(false) { static const int kWakeEvents = ALOOPER_EVENT_INPUT; ALooper_callbackFunc read_event_fd = [](int, int events, void* data) -\u0026gt; int {//在epoll_wait被唤醒之后会回调本callback  if (events \u0026amp; kWakeEvents) { reinterpret_cast\u0026lt;MessageLoopAndroid*\u0026gt;(data)-\u0026gt;OnEventFired(); } return 1; // continue receiving callbacks  }; int add_result = ::ALooper_addFd(looper_.get(), // looper  timer_fd_.get(), // fd  ALOOPER_POLL_CALLBACK, // ident  kWakeEvents, // events  read_event_fd, // callback  this // baton  ); /*此处是通过android中的ndk工具实现loop消息机制，对于1.ui, 1.gpu, 1.io线程会创建native的loop，对于main线程会复用Android原生的native loop。 ALooper_forThread：获取当前线程的loop，对应Looper::getForThread()，通过该线程key向TLS来查询是否存在已创建的c++层的loop ALooper_prepare：创建新的loop，对应Looper::prepare()，在TLS中记录着该线程为key，loop为value的数据。 ALooper_acquire: 获取loop的引用，对应looper-\u0026gt;incStrong()，也就是将引用计数加1；*/ static ALooper* AcquireLooperForThread() { ALooper* looper = ALooper_forThread(); if (looper == nullptr) { // No looper has been configured for the current thread. Create one and  // return the same.  looper = ALooper_prepare(0); } // The thread already has a looper. Acquire a reference to the same and return  // it.  ALooper_acquire(looper); return looper; } //frameworks/base/native/android/looper.cpp struct ALooper;//存在的价值是不希望调用者直接调用Looper的方法，只能调用Alooper开头的指定方法,提供封装性 /** * ALooper * * A looper is the state tracking an event loop for a thread. * Loopers do not define event structures or other such things; rather * they are a lower-level facility to attach one or more discrete objects * listening for an event. An \u0026#34;event\u0026#34; here is simply data available on * a file descriptor: each attached object has an associated file descriptor, * and waiting for \u0026#34;events\u0026#34; means (internally) polling on all of these file * descriptors until one or more of them have data available. * * A thread can have only one ALooper associated with it. */ typedef struct ALooper ALooper; 32static inline ALooper* Looper_to_ALooper(Looper* looper) { 33 return reinterpret_cast\u0026lt;ALooper*\u0026gt;(looper); 34} ALooper* ALooper_forThread() { return Looper_to_ALooper(Looper::getForThread().get()); } ALooper* ALooper_prepare(int opts) { return Looper_to_ALooper(Looper::prepare(opts).get()); } void ALooper_acquire(ALooper* looper) { ALooper_to_Looper(looper)-\u0026gt;incStrong((void*)ALooper_acquire); } void ALooper_release(ALooper* looper) { ALooper_to_Looper(looper)-\u0026gt;decStrong((void*)ALooper_acquire); } 78int ALooper_addFd(ALooper* looper, int fd, int ident, int events, 79 ALooper_callbackFunc callback, void* data) { 80 return ALooper_to_Looper(looper)-\u0026gt;addFd(fd, ident, events, callback, data); 81} 82 83int ALooper_removeFd(ALooper* looper, int fd) { 84 return ALooper_to_Looper(looper)-\u0026gt;removeFd(fd); 85} void MessageLoopAndroid::Run() { FML_DCHECK(looper_.get() == ALooper_forThread()); running_ = true; while (running_) { int result = ::ALooper_pollOnce(-1, // infinite timeout  nullptr, // out fd,  nullptr, // out events,  nullptr // out data  ); if (result == ALOOPER_POLL_TIMEOUT || result == ALOOPER_POLL_ERROR) { // This handles the case where the loop is terminated using ALooper APIs.  running_ = false; } } } 52int ALooper_pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) { 53 sp\u0026lt;Looper\u0026gt; looper = Looper::getForThread(); 54 if (looper == NULL) { 55 ALOGE(\u0026#34;ALooper_pollOnce: No looper for this thread!\u0026#34;); 56 return ALOOPER_POLL_ERROR; 57 } 58 59 IPCThreadState::self()-\u0026gt;flushCommands(); 60 return looper-\u0026gt;pollOnce(timeoutMillis, outFd, outEvents, outData); 61} TaskRunner::PostTask void TaskRunner::PostTask(const fml::closure\u0026amp; task) { loop_-\u0026gt;PostTask(task, fml::TimePoint::Now()); } void TaskRunner::PostTaskForTime(const fml::closure\u0026amp; task, fml::TimePoint target_time) { loop_-\u0026gt;PostTask(task, target_time); } void TaskRunner::PostDelayedTask(const fml::closure\u0026amp; task, fml::TimeDelta delay) { loop_-\u0026gt;PostTask(task, fml::TimePoint::Now() + delay); } MessageLoopImpl::PostTask void MessageLoopImpl::PostTask(const fml::closure\u0026amp; task, fml::TimePoint target_time) { task_queue_-\u0026gt;RegisterTask(queue_id_, task, target_time); } MessageLoopTaskQueues::RegisterTask //MessageLoopTaskQueues void MessageLoopTaskQueues::RegisterTask(TaskQueueId queue_id, const fml::closure\u0026amp; task, fml::TimePoint target_time) { std::scoped_lock queue_lock(GetMutex(queue_id)); size_t order = order_++; const auto\u0026amp; queue_entry = queue_entries_[queue_id]; queue_entry-\u0026gt;delayed_tasks.push({order, task, target_time}); TaskQueueId loop_to_wake = queue_id; if (queue_entry-\u0026gt;subsumed_by != _kUnmerged) { loop_to_wake = queue_entry-\u0026gt;subsumed_by; } WakeUpUnlocked(loop_to_wake, queue_entry-\u0026gt;delayed_tasks.top().GetTargetTime()); } void MessageLoopTaskQueues::WakeUpUnlocked(TaskQueueId queue_id, fml::TimePoint time) const { if (queue_entries_.at(queue_id)-\u0026gt;wakeable) { queue_entries_.at(queue_id)-\u0026gt;wakeable-\u0026gt;WakeUp(time); } } void MessageLoopAndroid::WakeUp(fml::TimePoint time_point) { bool result = TimerRearm(timer_fd_.get(), time_point); FML_DCHECK(result); } //TimerRearm bool TimerRearm(int fd, fml::TimePoint time_point) { uint64_t nano_secs = time_point.ToEpochDelta().ToNanoseconds(); // \u0026#34;0\u0026#34; will disarm the timer, desired behavior is to immediately  // trigger the timer.  if (nano_secs \u0026lt; 1) { nano_secs = 1; } struct itimerspec spec = {}; spec.it_value.tv_sec = (time_t)(nano_secs / NSEC_PER_SEC); spec.it_value.tv_nsec = nano_secs % NSEC_PER_SEC; spec.it_interval = spec.it_value; // single expiry.  int result = ::timerfd_settime(fd, TFD_TIMER_ABSTIME, \u0026amp;spec, nullptr); return result == 0; } int timerfd_settime(int ufc, int flags, const struct itimerspec* utmr, struct itimerspec* otmr) { return syscall(__NR_timerfd_settime, ufc, flags, utmr, otmr);//通过系统调用__NR_timerfd_settime来设置定时唤醒。 } looper唤醒之后的回调处理 void MessageLoopAndroid::OnEventFired() { if (TimerDrain(timer_fd_.get())) { RunExpiredTasksNow(); }} void MessageLoopImpl::RunExpiredTasksNow() { FlushTasks(FlushType::kAll); } void MessageLoopImpl::FlushTasks(FlushType type) { TRACE_EVENT0(\u0026#34;fml\u0026#34;, \u0026#34;MessageLoop::FlushTasks\u0026#34;); std::vector\u0026lt;fml::closure\u0026gt; invocations; //遍历整个延迟任务队列，将时间已到期的任务加入invocations  task_queue_-\u0026gt;GetTasksToRunNow(queue_id_, type, invocations); for (const auto\u0026amp; invocation : invocations) { invocation(); std::vector\u0026lt;fml::closure\u0026gt; observers = task_queue_-\u0026gt;GetObserversToNotify(queue_id_); for (const auto\u0026amp; observer : observers) {//queue的observers被逐个调用  observer(); } } } 其他 ThreadHost初始化\n[-\u0026gt; flutter/shell/common/thread_host.cc] ThreadHost::ThreadHost(std::string name_prefix, uint64_t mask) { if (mask \u0026amp; ThreadHost::Type::Platform) { platform_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.platform\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::UI) { //创建线程 [见小节2.2]  ui_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.ui\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::GPU) { gpu_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.gpu\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::IO) { io_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.io\u0026#34;); } } TaskRunner初始化\n[-\u0026gt; flutter/fml/task_runner.cc] TaskRunner::TaskRunner(fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop) : loop_(std::move(loop)) {} Flutter引擎启动过程，会创建UI/GPU/IO这3个线程，并且会为每个线程依次创建MessageLoop对象，启动后处于epoll_wait等待状态。对于Flutter的消息机制跟Android原生的消息机制有很多相似之处，都有消息(或者任务)、消息队列以及Looper，有一点不同的是Android有一个Handler类，用于发送消息以及执行回调方法，相对应Flutter中有着相近功能的便是TaskRunner。\n上图是从源码中提炼而来的任务处理流程，比官方流程图更容易理解一些复杂流程的时序问题，后续会专门讲解个中原由。Flutter的任务队列处理机制跟Android的消息队列处理相通，只不过Flutter分为Task和MicroTask两种类型，引擎和Dart虚拟机的事件以及Future都属于Task，Dart层执行scheduleMicrotask()所产生的属于Microtask。\n每次Flutter引擎在消费任务时调用FlushTasks()方法，遍历整个延迟任务队列delayed_tasks_，将已到期的任务加入task队列，然后开始处理任务。\n Step 1: 检查task，当task队列不为空，先执行一个task； Step 2: 检查microTask，当microTask不为空，则执行microTask；不断循环Step 2 直到microTask队列为空，再回到执行Step 1；  可简单理解为先处理完所有的Microtask，然后再处理Task。因为scheduleMicrotask()方法的调用自身就处于一个Task，执行完当前的task，也就意味着马上执行该Microtask。\n了解了其工作机制，再来看看这4个Task Runner的具体工作内容。\n Platform Task Runner：运行在Android或者iOS的主线程，尽管阻塞该线程并不会影响Flutter渲染管道，平台线程建议不要执行耗时操作；否则可能触发watchdog来结束该应用。比如Android、iOS都是使用平台线程来传递用户输入事件，一旦平台线程被阻塞则会引起手势事件丢失。 UI Task Runner: 运行在ui线程，比如1.ui，用于引擎执行root isolate中的所有Dart代码，执行渲染与处理Vsync信号，将widget转换生成Layer Tree。除了渲染之外，还有处理Native Plugins消息、Timers、Microtasks等工作； GPU Task Runner：运行在gpu线程，比如1.gpu，用于将Layer Tree转换为具体GPU指令，执行设备GPU相关的skia调用，转换相应平台的绘制方式，比如OpenGL, vulkan, metal等。每一帧的绘制需要UI Runner和GPU Runner配合完成，任何一个环节延迟都可能导致掉帧； IO Task Runner：运行在io线程，比如1.io，前3个Task Runner都不允许执行耗时操作，该Runner用于将图片从磁盘读取出来，解压转换为GPU可识别的格式后，再上传给GPU线程。为了能访问GPU，IO Runner跟GPU Runner的Context在同一个ShareGroup。比如ui.image通过异步调用让IO Runner来异步加载图片，该线程不能执行其他耗时操作，否则可能会影响图片加载的性能。  深入理解Flutter消息机制\n深入理解Flutter异步Future机制\n深入理解Flutter的Isolate创建过程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/methodchannel/",
	"title": "MethodChannel",
	"tags": [],
	"description": "",
	"content": "整体设计 graph TB Dart(DartFramework)--\u0026gt;|await|Engine--\u0026gt;|GetPlatformTaskRunner-\u0026gt;PostTask|PlatformC++--\u0026gt;PlatformJava PlatformJava--\u0026gt;PlatformC++ PlatformC++--\u0026gt;|ui_task_runner_-\u0026gt;PostTask|Engine--\u0026gt;Dart 注册监听MethodChannel().setMethodCallHandler((call, result) -\u0026gt; {}) class MainActivity() : FlutterActivity() { private val CHANNEL = \u0026#34;samples.flutter.dev/battery\u0026#34; override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) GeneratedPluginRegistrant.registerWith(this) MethodChannel(flutterView, CHANNEL).setMethodCallHandler { call, result -\u0026gt; // Note: this method is invoked on the main thread.  if (call.method == \u0026#34;getBatteryLevel\u0026#34;) { val batteryLevel = getBatteryLevel()//android平台api调用获取  if (batteryLevel != -1) { result.success(batteryLevel) } else { result.error(\u0026#34;UNAVAILABLE\u0026#34;, \u0026#34;Battery level not available.\u0026#34;, null) } } else { result.notImplemented() } } MethodChannel.java\nprivate final BinaryMessenger messenger; public MethodChannel(BinaryMessenger messenger, String name) { this(messenger, name, StandardMethodCodec.INSTANCE); } public MethodChannel(BinaryMessenger messenger, String name, MethodCodec codec) { this.messenger = messenger; this.name = name; this.codec = codec; } @UiThread public void setMethodCallHandler(@Nullable MethodChannel.MethodCallHandler handler) { this.messenger.setMessageHandler(this.name, handler == null ? null : new MethodChannel.IncomingMethodCallHandler(handler)); } interface BinaryMessenger @UiThread void setMessageHandler(@NonNull String var1, @Nullable BinaryMessenger.BinaryMessageHandler var2); FlutterView extends SurfaceView implements BinaryMessenger, TextureRegistry { @UiThread public void setMessageHandler(String channel, BinaryMessageHandler handler) { this.mNativeView.setMessageHandler(channel, handler); } } FlutterNativeView implements BinaryMessenger @UiThread public void setMessageHandler(String channel, BinaryMessageHandler handler) { this.dartExecutor.setMessageHandler(channel, handler); } DartExecutor implements BinaryMessenger @NonNull private final DartMessenger messenger; @UiThread public void setMessageHandler(@NonNull String channel, @Nullable BinaryMessageHandler handler) { this.messenger.setMessageHandler(channel, handler); } DartMessenger.setMessageHandler DartMessenger //platform注册监听 public void setMessageHandler(@NonNull String channel, @Nullable BinaryMessageHandler handler) { if (handler == null) { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Removing handler for channel \u0026#39;\u0026#34; + channel + \u0026#34;\u0026#39;\u0026#34;); this.messageHandlers.remove(channel); } else { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Setting handler for channel \u0026#39;\u0026#34; + channel + \u0026#34;\u0026#39;\u0026#34;); this.messageHandlers.put(channel, handler); } } IncomingMethodCallHandler.onMessage private final class IncomingMethodCallHandler implements BinaryMessageHandler { private final MethodChannel.MethodCallHandler handler; IncomingMethodCallHandler(MethodChannel.MethodCallHandler handler) { this.handler = handler; } @UiThread public void onMessage(ByteBuffer message, final BinaryReply reply) { MethodCall call = MethodChannel.this.codec.decodeMethodCall(message);//ByteBuffer to Object  try { this.handler.onMethodCall(call, new MethodChannel.Result() { public void success(Object result) { reply.reply(MethodChannel.this.codec.encodeSuccessEnvelope(result));//object to ByteBuffer  } public void error(String errorCode, String errorMessage, Object errorDetails) { reply.reply(MethodChannel.this.codec.encodeErrorEnvelope(errorCode, errorMessage, errorDetails)); } public void notImplemented() { reply.reply((ByteBuffer)null); } }); } catch (RuntimeException var5) { Log.e(\u0026#34;MethodChannel#\u0026#34; + MethodChannel.this.name, \u0026#34;Failed to handle method call\u0026#34;, var5); reply.reply(MethodChannel.this.codec.encodeErrorEnvelope(\u0026#34;error\u0026#34;, var5.getMessage(), (Object)null)); } 发起调用methodChannel.invokeMethod static const platform = const MethodChannel(\u0026#39;samples.flutter.dev/battery\u0026#39;); try { final int result = await platform.invokeMethod(\u0026#39;getBatteryLevel\u0026#39;); batteryLevel = \u0026#39;Battery level at $result% .\u0026#39;; } on PlatformException catch (e) { batteryLevel = \u0026#34;Failed to get battery level: \u0026#39;${e.message}\u0026#39;.\u0026#34;; } const MethodChannel(this.name, [this.codec = const StandardMethodCodec(), this.binaryMessenger = defaultBinaryMessenger ]) /// The logical channel on which communication happens, not null.  final String name; /// The message codec used by this channel, not null.  final MethodCodec codec; /// The messenger used by this channel to send platform messages.  ///  /// The messenger may not be null.  final BinaryMessenger binaryMessenger; /// The default instance of [BinaryMessenger].  ///  /// This is used to send messages from the application to the platform, and  /// keeps track of which handlers have been registered on each channel so  /// it may dispatch incoming messages to the registered handler.  const BinaryMessenger defaultBinaryMessenger = _DefaultBinaryMessenger._(); @optionalTypeArgs Future\u0026lt;T\u0026gt; invokeMethod\u0026lt;T\u0026gt;(String method, [ dynamic arguments ]) async { final ByteData result = await binaryMessenger.send( name, codec.encodeMethodCall(MethodCall(method, arguments)), ); final T typedResult = codec.decodeEnvelope(result); return typedResult; ByteData result = await binaryMessenger.send /// A messenger which sends binary data across the Flutter platform barrier.  ///  /// This class also registers handlers for incoming messages.*  BinaryMessenger /// Send a binary message to the platform plugins on the given channel.  /// Returns a [Future] which completes to the received response, undecoded,  /// in binary form.  Future\u0026lt;ByteData\u0026gt; send(String channel, ByteData message); _DefaultBinaryMessenger /// A function which takes a platform message and asynchronously returns an encoded response. typedef MessageHandler = Future\u0026lt;ByteData\u0026gt; Function(ByteData message); // Mock handlers that intercept and respond to outgoing messages.  // This is static so that this class can have a const constructor. static final Map\u0026lt;String, MessageHandler\u0026gt; _mockHandlers = \u0026lt;String, MessageHandler\u0026gt;{}; @override Future\u0026lt;ByteData\u0026gt; send(String channel, ByteData message) { final MessageHandler handler = _mockHandlers[channel]; if (handler != null) return handler(message); return _sendPlatformMessage(channel, message); } Future\u0026lt;ByteData\u0026gt; _sendPlatformMessage(String channel, ByteData message) { final Completer\u0026lt;ByteData\u0026gt; completer = Completer\u0026lt;ByteData\u0026gt;(); ui.window.sendPlatformMessage(channel, message, (ByteData reply) { try { completer.complete(reply); } return completer.future; SendPlatformMessage Window /// Sends a message to a platform-specific plugin.  ///  /// The `name` parameter determines which plugin receives the message. The  /// `data` parameter contains the message payload and is typically UTF-8  /// encoded JSON but can be arbitrary data. If the plugin replies to the  /// message, `callback` will be called with the response.  void sendPlatformMessage(String name, ByteData data, PlatformMessageResponseCallback callback) { final String error = _sendPlatformMessage(name, _zonedPlatformMessageResponseCallback(callback), data); if (error != null) throw Exception(error); String _sendPlatformMessage(String name, PlatformMessageResponseCallback callback, ByteData data) native \u0026#39;Window_sendPlatformMessage\u0026#39;; Window.cc\nvoid Window::RegisterNatives(tonic::DartLibraryNatives* natives) { natives-\u0026gt;Register({ {\u0026#34;Window_sendPlatformMessage\u0026#34;, _SendPlatformMessage, 4, true}, void _SendPlatformMessage(Dart_NativeArguments args) { tonic::DartCallStatic(\u0026amp;SendPlatformMessage, args); } Dart_Handle SendPlatformMessage(Dart_Handle window, const std::string\u0026amp; name, Dart_Handle callback, Dart_Handle data_handle) { dart_state-\u0026gt;window()-\u0026gt;client()-\u0026gt;HandlePlatformMessage return Dart_Null(); Engine\nvoid Engine::HandlePlatformMessage(fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { if (message-\u0026gt;channel() == kAssetChannel) { HandleAssetPlatformMessage(std::move(message)); } else { delegate_.OnEngineHandlePlatformMessage(std::move(message)); } } class Delegate { //--------------------------------------------------------------------------  /// @brief When the Flutter application has a message to send to the  /// underlying platform, the message needs to be forwarded to  /// the platform on the the appropriate thread (via the platform  /// task runner). The engine delegates this task to the shell  /// via this method.  ///  /// @see `PlatformView::HandlePlatformMessage`  ///  /// @param[in] message The message from the Flutter application to send to  /// the underlying platform.  ///  virtual void OnEngineHandlePlatformMessage( fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) = 0; Shell\nconst TaskRunners task_runners_; const TaskRunners\u0026amp; Shell::GetTaskRunners() const {return task_runners_;} Shell::Shell(DartVMRef vm, TaskRunners task_runners, Settings settings) : task_runners_(std::move(task_runners)), Shell::OnEngineHandlePlatformMessage // |Engine::Delegate| void Shell::OnEngineHandlePlatformMessage( fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { FML_DCHECK(is_setup_); FML_DCHECK(task_runners_.GetUITaskRunner()-\u0026gt;RunsTasksOnCurrentThread()); if (message-\u0026gt;channel() == kSkiaChannel) { HandleEngineSkiaMessage(std::move(message)); return; } task_runners_.GetPlatformTaskRunner()-\u0026gt;PostTask( [view = platform_view_-\u0026gt;GetWeakPtr(), message = std::move(message)]() { if (view) { view-\u0026gt;HandlePlatformMessage(std::move(message)); } }); } void PlatformView::HandlePlatformMessage(fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { if (auto response = message-\u0026gt;response()) response-\u0026gt;CompleteEmpty(); } PlatformViewAndroid::HandlePlatformMessage // |PlatformView| void PlatformViewAndroid::HandlePlatformMessage( FlutterViewHandlePlatformMessage(env, view.obj(), java_channel.obj(), message_array.obj(), response_id); shell\\platform\\android\\platform_view_android_jni.cc\nbool PlatformViewAndroid::Register(JNIEnv* env) { g_flutter_jni_class = new fml::jni::ScopedJavaGlobalRef\u0026lt;jclass\u0026gt;( env, env-\u0026gt;FindClass(\u0026#34;io/flutter/embedding/engine/FlutterJNI\u0026#34;)); if (g_flutter_jni_class-\u0026gt;is_null()) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to find FlutterJNI Class.\u0026#34;; return false; } g_handle_platform_message_method = env-\u0026gt;GetMethodID(g_flutter_jni_class-\u0026gt;obj(), \u0026#34;handlePlatformMessage\u0026#34;, \u0026#34;(Ljava/lang/String;[BI)V\u0026#34;); static jmethodID g_handle_platform_message_method = nullptr; void FlutterViewHandlePlatformMessage(JNIEnv* env, jobject obj, jstring channel, jobject message, jint responseId) { env-\u0026gt;CallVoidMethod(obj, g_handle_platform_message_method, channel, message, responseId); FML_CHECK(CheckException(env)); } FlutterJNI\n// Called by native. private void handlePlatformMessage(@NonNull String channel, byte[] message, int replyId) { if (this.platformMessageHandler != null) { this.platformMessageHandler.handleMessageFromDart(channel, message, replyId); } } PlatformMessageHandler\nvoid handleMessageFromDart(@NonNull String var1, @Nullable byte[] var2, int var3); void handlePlatformMessageResponse(int var1, @Nullable byte[] var2); DartMessenger.handleMessageFromDart @NonNull private final Map\u0026lt;String, BinaryMessageHandler\u0026gt; messageHandlers; //由dart发起调用 public void handleMessageFromDart(@NonNull String channel, @Nullable byte[] message, int replyId) { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Received message from Dart over channel \u0026#39;\u0026#34; + channel + \u0026#34;\u0026#39;\u0026#34;); BinaryMessageHandler handler = (BinaryMessageHandler)this.messageHandlers.get(channel); if (handler != null) { try { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Deferring to registered handler to process message.\u0026#34;); ByteBuffer buffer = message == null ? null : ByteBuffer.wrap(message); handler.onMessage(buffer, new DartMessenger.Reply(this.flutterJNI, replyId)); } catch (Exception var6) { Log.e(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Uncaught exception in binary message listener\u0026#34;, var6); this.flutterJNI.invokePlatformMessageEmptyResponseCallback(replyId); } } else { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;No registered handler for message. Responding to Dart with empty reply message.\u0026#34;); this.flutterJNI.invokePlatformMessageEmptyResponseCallback(replyId); } } 消息回复 Reply.reply DartMessenger private static class Reply implements BinaryReply { @NonNull private final FlutterJNI flutterJNI; private final int replyId; private final AtomicBoolean done = new AtomicBoolean(false); Reply(@NonNull FlutterJNI flutterJNI, int replyId) { this.flutterJNI = flutterJNI; this.replyId = replyId; } public void reply(@Nullable ByteBuffer reply) { if (this.done.getAndSet(true)) { throw new IllegalStateException(\u0026#34;Reply already submitted\u0026#34;); } else { if (reply == null) { this.flutterJNI.invokePlatformMessageEmptyResponseCallback(this.replyId); } else { this.flutterJNI.invokePlatformMessageResponseCallback(this.replyId, reply, reply.position()); } FlutterJNI\n@UiThread public void invokePlatformMessageResponseCallback(int responseId, @Nullable ByteBuffer message, int position) { this.ensureRunningOnMainThread(); if (this.isAttached()) { this.nativeInvokePlatformMessageResponseCallback(this.nativePlatformViewId, responseId, message, position); } else { Log.w(\u0026#34;FlutterJNI\u0026#34;, \u0026#34;Tried to send a platform message response, but FlutterJNI was detached from native C++. Could not send. Response ID: \u0026#34; + responseId); } private native void nativeInvokePlatformMessageResponseCallback(long var1, int var3, @Nullable ByteBuffer var4, int var5); shell\\platform\\android\\platform_view_android_jni.cc\nbool RegisterApi(JNIEnv* env) { static const JNINativeMethod flutter_jni_methods[] = { // Start of methods from FlutterJNI  { .name = \u0026#34;nativeInvokePlatformMessageResponseCallback\u0026#34;, .signature = \u0026#34;(JILjava/nio/ByteBuffer;I)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;InvokePlatformMessageResponseCallback), }, static void InvokePlatformMessageResponseCallback(JNIEnv* env, jobject jcaller, jlong shell_holder, jint responseId, jobject message, jint position) { ANDROID_SHELL_HOLDER-\u0026gt;GetPlatformView() -\u0026gt;InvokePlatformMessageResponseCallback(env, //  responseId, //  message, //  position //  ); } PlatformViewAndroid::InvokePlatformMessageResponseCallback void PlatformViewAndroid::InvokePlatformMessageResponseCallback( JNIEnv* env, jint response_id, jobject java_response_data, jint java_response_position) { if (!response_id) return; auto it = pending_responses_.find(response_id); if (it == pending_responses_.end()) return; uint8_t* response_data = static_cast\u0026lt;uint8_t*\u0026gt;(env-\u0026gt;GetDirectBufferAddress(java_response_data)); std::vector\u0026lt;uint8_t\u0026gt; response = std::vector\u0026lt;uint8_t\u0026gt;( response_data, response_data + java_response_position); auto message_response = std::move(it-\u0026gt;second); pending_responses_.erase(it); message_response-\u0026gt;Complete( std::make_unique\u0026lt;fml::DataMapping\u0026gt;(std::move(response))); } PlatformMessageResponseDart::Complete void PlatformMessageResponseDart::Complete(std::unique_ptr\u0026lt;fml::Mapping\u0026gt; data) { if (callback_.is_empty()) return; FML_DCHECK(!is_complete_); is_complete_ = true; ui_task_runner_-\u0026gt;PostTask(fml::MakeCopyable( [callback = std::move(callback_), data = std::move(data)]() mutable { std::shared_ptr\u0026lt;tonic::DartState\u0026gt; dart_state = callback.dart_state().lock(); if (!dart_state) return; tonic::DartState::Scope scope(dart_state); Dart_Handle byte_buffer = WrapByteData(std::move(data)); tonic::DartInvoke(callback.Release(), {byte_buffer});//调用SendPlatformMessage的第三个参数闭包  })); } sendplatformmessage\nMethodCodec ByteBuffer encodeMethodCall(MethodCall methodCall); MethodCall decodeMethodCall(ByteBuffer methodCall); ByteBuffer encodeSuccessEnvelope(Object result); Object decodeEnvelope(ByteBuffer envelope); StandardMethodCodec\n@Override public MethodCall decodeMethodCall(ByteBuffer methodCall) { methodCall.order(ByteOrder.nativeOrder()); final Object method = messageCodec.readValue(methodCall); final Object arguments = messageCodec.readValue(methodCall); if (method instanceof String \u0026amp;\u0026amp; !methodCall.hasRemaining()) { return new MethodCall((String) method, arguments); } throw new IllegalArgumentException(\u0026#34;Method call corrupted\u0026#34;); } @Override public ByteBuffer encodeSuccessEnvelope(Object result) { final ExposedByteArrayOutputStream stream = new ExposedByteArrayOutputStream(); stream.write(0); messageCodec.writeValue(stream, result); final ByteBuffer buffer = ByteBuffer.allocateDirect(stream.size()); buffer.put(stream.buffer(), 0, stream.size()); return buffer; } 其他 Flutter和原生之间的平台通道实践与原理\n深入理解Flutter的Platform Channel机制\nMethodChannel的执行流程涉及到主线程和UI线程的交互，代码从Dart到C++再到Java层，执行完相应逻辑后原路返回，从Java层到C++层再到Dart层。\n[小节3.5] Shell::OnEngineHandlePlatformMessage 将任务发送给主线程\n[-\u0026gt; flutter/shell/common/shell.cc] constexpr char kSkiaChannel[] = \u0026#34;flutter/skia\u0026#34;; void Shell::OnEngineHandlePlatformMessage( fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { if (message-\u0026gt;channel() == kSkiaChannel) { HandleEngineSkiaMessage(std::move(message)); return; } //[见小节3.6]  task_runners_.GetPlatformTaskRunner()-\u0026gt;PostTask( [view = platform_view_-\u0026gt;GetWeakPtr(), message = std::move(message)]() { if (view) { view-\u0026gt;HandlePlatformMessage(std::move(message)); } }); } //将HandlePlatformMessage的工作交给主线程的PlatformTaskRunner来处理，对于PlatformView在Android平台的实例为PlatformViewAndroid。 [小节6.5] PlatformMessageResponseDart::Complete 将任务发送给UI线程\n[-\u0026gt; flutter/lib/ui/window/platform_message_response_dart.cc] void PlatformMessageResponseDart::Complete(std::unique_ptr\u0026lt;fml::Mapping\u0026gt; data) { is_complete_ = true; //post到UI线程来执行  ui_task_runner_-\u0026gt;PostTask(fml::MakeCopyable( [callback = std::move(callback_), data = std::move(data)]() mutable { std::shared_ptr\u0026lt;tonic::DartState\u0026gt; dart_state = callback.dart_state().lock(); tonic::DartState::Scope scope(dart_state); Dart_Handle byte_buffer = WrapByteData(std::move(data)); //[见小节6.6]  tonic::DartInvoke(callback.Release(), {byte_buffer}); })); } //到此就发生了线程切换操作，将任务post到UI线程的UITaskRunner来执行。 "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/mmkv/mmkv/",
	"title": "MMKV",
	"tags": [],
	"description": "",
	"content": "参考 https://github.com/Tencent/MMKV/wiki/android_ipc\nhttps://github.com/Tencent/MMKV/wiki/design\n原理总结 MMKV 本质上是将文件 mmap 到内存块中，将新增的 key-value 统统 append 到内存中；到达边界后，进行重整回写以腾出空间，空间还是不够的话，就 double 内存空间；对于内存文件中可能存在的重复键值，MMKV 只选用最后写入的作为有效键值。\n状态同步 写指针的同步 我们可以在每个进程内部缓存自己的写指针，然后在写入键值的同时，还要把最新的写指针位置也写到 mmap 内存中；这样每个进程只需要对比一下缓存的指针与 mmap 内存的写指针，如果不一样，就说明其他进程进行了写操作。事实上 MMKV 原本就在文件头部保存了有效内存的大小，这个数值刚好就是写指针的内存偏移量，我们可以重用这个数值来校对写指针。\n内存重整的感知 考虑使用一个单调递增的序列号，每次发生内存重整，就将序列号递增。将这个序列号也放到 mmap 内存中，每个进程内部也缓存一份，只需要对比序列号是否一致，就能够知道其他进程是否触发了内存重整。\n内存增长的感知 事实上 MMKV 在内存增长之前，会先尝试通过内存重整来腾出空间，重整后还不够空间才申请新的内存。所以内存增长可以跟内存重整一样处理。至于新的内存大小，可以通过查询文件大小来获得，无需在 mmap 内存另外存放。\n挑选进程锁  文件锁，优点是天然 robust，缺点是不支持递归加锁，也不支持读写锁升级/降级，需要自行实现。 pthread_mutex，优点是 pthread 库支持递归加锁，也支持读写锁升级/降级，缺点是不 robust，需要自行清理。  文件锁 到这里我们已经完成了数据的多进程同步工作，是时候回头处理锁事了，亦即前面提到的递归锁和锁升级/降级。\n递归锁 意思是如果一个进程/线程已经拥有了锁，那么后续的加锁操作不会导致卡死，并且解锁也不会导致外层的锁被解掉。对于文件锁来说，前者是满足的，后者则不然。因为文件锁是状态锁，没有计数器，无论加了多少次锁，一个解锁操作就全解掉。只要用到子函数，就非常需要递归锁。\n锁升级/降级 锁升级是指将已经持有的共享锁，升级为互斥锁，亦即将读锁升级为写锁；锁降级则是反过来。文件锁支持锁升级，但是容易死锁：假如 A、B 进程都持有了读锁，现在都想升级到写锁，就会陷入相互等待的困境，发生死锁。另外，由于文件锁不支持递归锁，也导致了锁降级无法进行，一降就降到没有锁。\n为了解决递归锁和锁升级/降级这两个难题，需要对文件锁(系统调用flock)进行封装，增加读锁、写锁计数器。处理逻辑如下表：\n   读锁计数器 写锁计数器 加读锁 加写锁 解读锁 解写锁     0 0 加读锁 加写锁 - -   0 1 +1 +1 - 解写锁   0 N +1 +1 - -1   1 0 +1 解读锁再加写锁 解读锁 -   1 1 +1 +1 -1 加读锁   1 N +1 +1 -1 -1   N 0 +1 解读锁再加写锁 -1 -   N 1 +1 +1 -1 加读锁   N N +1 +1 -1 -1    需要注意的地方有两点：\n 加写锁时，如果当前已经持有读锁，那么先尝试加写锁，try_lock 失败说明其他进程持有了读锁，我们需要先将自己的读锁释放掉，再进行加写锁操作，以避免死锁的发生。(这里的死锁指的是：本进程先加了读锁，之后又尝试加写锁，而这个写锁要等到前面那个读锁释放之后才能加上，而这是不可能的，因此造成死锁)。 解写锁时，假如之前曾经持有读锁，那么我们不能直接释放掉写锁，这样会导致读锁也解了。我们应该加一个读锁，将锁降级。  graph LR 加读锁--\u0026gt;直接加 加写锁--\u0026gt;非首次加写锁,直接+1 加写锁--\u0026gt;首次加写锁,如果有读锁,需要先unlock,防止死锁 解读锁--\u0026gt;直接解 解写锁--\u0026gt;写锁数量大于1直接-1 解写锁--\u0026gt;写锁数量为1,如果有读锁,加读锁锁降级,避免解写锁时读锁也解了,锁失效 MMKV initialize public static String initialize(String rootDir, LibLoader loader, MMKVLogLevel logLevel) { if (loader != null) { if (BuildConfig.FLAVOR.equals(\u0026#34;SharedCpp\u0026#34;)) { loader.loadLibrary(\u0026#34;c++_shared\u0026#34;); } loader.loadLibrary(\u0026#34;mmkv\u0026#34;); } else { if (BuildConfig.FLAVOR.equals(\u0026#34;SharedCpp\u0026#34;)) { System.loadLibrary(\u0026#34;c++_shared\u0026#34;); } System.loadLibrary(\u0026#34;mmkv\u0026#34;); } jniInitialize(rootDir, logLevel2Int(logLevel)); MMKV.rootDir = rootDir; return MMKV.rootDir; } loadLibrary\njniinitialize\nregisterContentChangeNotify // content change notification of other process // trigger by getXXX() or setXXX() or checkContentChangedByOuterProcess() private static MMKVContentChangeNotification gContentChangeNotify; public static void registerContentChangeNotify(MMKVContentChangeNotification notify) { gContentChangeNotify = notify; setWantsContentChangeNotify(gContentChangeNotify != null); } setwantscontentchangenotify\nonContentChangedByOuterProcess private static void onContentChangedByOuterProcess(String mmapID) { if (gContentChangeNotify != null) { gContentChangeNotify.onContentChangedByOuterProcess(mmapID); } } defaultMMKV public static MMKV defaultMMKV() { long handle = getDefaultMMKV(SINGLE_PROCESS_MODE, null); return checkProcessMode(handle, \u0026#34;DefaultMMKV\u0026#34;, SINGLE_PROCESS_MODE); } native-bridge.cpp JNI_OnLoad extern \u0026#34;C\u0026#34; JNIEXPORT JNICALL jint JNI_OnLoad(JavaVM *vm, void *reserved) { g_currentJVM = vm; JNIEnv *env; if (vm-\u0026gt;GetEnv(reinterpret_cast\u0026lt;void **\u0026gt;(\u0026amp;env), JNI_VERSION_1_6) != JNI_OK) { return -1; } static const char *clsName = \u0026#34;com/tencent/mmkv/MMKV\u0026#34;; jclass instance = env-\u0026gt;FindClass(clsName); g_cls = reinterpret_cast\u0026lt;jclass\u0026gt;(env-\u0026gt;NewGlobalRef(instance)); int ret = registerNativeMethods(env, g_cls); return JNI_VERSION_1_6; } registerNativeMethods static int registerNativeMethods(JNIEnv *env, jclass cls) { return env-\u0026gt;RegisterNatives(cls, g_methods, sizeof(g_methods) / sizeof(g_methods[0])); } jniInitialize MMKV_JNI void jniInitialize(JNIEnv *env, jobject obj, jstring rootDir, jint logLevel) { const char *kstr = env-\u0026gt;GetStringUTFChars(rootDir, nullptr); if (kstr) { MMKV::initializeMMKV(kstr, (MMKVLogLevel) logLevel); env-\u0026gt;ReleaseStringUTFChars(rootDir, kstr); } } setWantsContentChangeNotify MMKV_JNI void setWantsContentChangeNotify(JNIEnv *env, jclass type, jboolean notify) { if (notify == JNI_TRUE) { MMKV::registerContentChangeHandler(onContentChangedByOuterProcess); } else { MMKV::unRegisterContentChangeHandler(); } } registercontentchangehandler\nonContentChangedByOuterProcess_n static void onContentChangedByOuterProcess(const std::string \u0026amp;mmapID) { auto currentEnv = getCurrentEnv(); if (currentEnv \u0026amp;\u0026amp; g_callbackOnContentChange) { jstring str = string2jstring(currentEnv, mmapID); currentEnv-\u0026gt;CallStaticVoidMethod(g_cls, g_callbackOnContentChange, str); } } g_callbackOnContentChange\ngetDefaultMMKV MMKV_JNI jlong getDefaultMMKV(JNIEnv *env, jobject obj, jint mode, jstring cryptKey) { MMKV *kv = nullptr; if (cryptKey) { string crypt = jstring2string(env, cryptKey); if (crypt.length() \u0026gt; 0) { kv = MMKV::defaultMMKV((MMKVMode) mode, \u0026amp;crypt); } } if (!kv) { kv = MMKV::defaultMMKV((MMKVMode) mode, nullptr); } return (jlong) kv; } getMMKVWithID MMKV_JNI jlong getMMKVWithID(JNIEnv *env, jobject, jstring mmapID, jint mode, jstring cryptKey, jstring rootPath) { string str = jstring2string(env, mmapID); kv = MMKV::mmkvWithID(str, DEFAULT_MMAP_SIZE, (MMKVMode) mode, \u0026amp;crypt, \u0026amp;path); return (jlong) kv; } mmkvwithid\nMMKV.cpp initializeMMKV void MMKV::initializeMMKV(const MMKVPath_t \u0026amp;rootDir, MMKVLogLevel logLevel) { g_currentLogLevel = logLevel; ThreadLock::ThreadOnce(\u0026amp;once_control, initialize); g_rootDir = rootDir; mkPath(g_rootDir); } initialize void initialize() { g_instanceDic = new unordered_map\u0026lt;string, MMKV *\u0026gt;; g_instanceLock = new ThreadLock(); g_instanceLock-\u0026gt;initialize(); mmkv::DEFAULT_MMAP_SIZE = mmkv::getPageSize(); } registerContentChangeHandler void MMKV::registerContentChangeHandler(mmkv::ContentChangeHandler handler) { g_contentChangeHandler = handler; } defaultMMKV MMKV *MMKV::defaultMMKV(MMKVMode mode, string *cryptKey) { #ifndef MMKV_ANDROID  return mmkvWithID(DEFAULT_MMAP_ID, mode, cryptKey); #else  return mmkvWithID(DEFAULT_MMAP_ID, DEFAULT_MMAP_SIZE, mode, cryptKey); #endif } mmkvWithID MMKV *MMKV::mmkvWithID(const string \u0026amp;mmapID, int size, MMKVMode mode, string *cryptKey, string *rootPath) { SCOPED_LOCK(g_instanceLock); auto mmapKey = mmapedKVKey(mmapID, rootPath); auto itr = g_instanceDic-\u0026gt;find(mmapKey); if (itr != g_instanceDic-\u0026gt;end()) { MMKV *kv = itr-\u0026gt;second; return kv; } auto kv = new MMKV(mmapID, size, mode, cryptKey, rootPath); (*g_instanceDic)[mmapKey] = kv; return kv; } MMKV() MMKV::MMKV(const string \u0026amp;mmapID, int size, MMKVMode mode, string *cryptKey, string *rootPath) : m_mmapID(mmapedKVKey(mmapID, rootPath)) // historically Android mistakenly use mmapKey as mmapID  , m_path(mappedKVPathWithID(m_mmapID, mode, rootPath)) , m_crcPath(crcPathWithID(m_mmapID, mode, rootPath)) , m_dic(nullptr) , m_dicCrypt(nullptr) , m_file(new MemoryFile(m_path, size, (mode \u0026amp; MMKV_ASHMEM) ? MMFILE_TYPE_ASHMEM : MMFILE_TYPE_FILE)) , m_metaFile(new MemoryFile(m_crcPath, DEFAULT_MMAP_SIZE, m_file-\u0026gt;m_fileType)) , m_metaInfo(new MMKVMetaInfo()) , m_crypter(nullptr) , m_lock(new ThreadLock()) , m_fileLock(new FileLock(m_metaFile-\u0026gt;getFd(), (mode \u0026amp; MMKV_ASHMEM))) , m_sharedProcessLock(new InterProcessLock(m_fileLock, SharedLockType)) , m_exclusiveProcessLock(new InterProcessLock(m_fileLock, ExclusiveLockType)) , m_isInterProcess((mode \u0026amp; MMKV_MULTI_PROCESS) != 0 || (mode \u0026amp; CONTEXT_MODE_MULTI_PROCESS) != 0) { m_actualSize = 0; m_output = nullptr; // force use fcntl(), otherwise will conflict with MemoryFile::reloadFromFile()  m_fileModeLock = new FileLock(m_file-\u0026gt;getFd(), true); m_sharedProcessModeLock = new InterProcessLock(m_fileModeLock, SharedLockType); m_exclusiveProcessModeLock = nullptr; # ifndef MMKV_DISABLE_CRYPT  if (cryptKey \u0026amp;\u0026amp; cryptKey-\u0026gt;length() \u0026gt; 0) { m_dicCrypt = new MMKVMapCrypt(); m_crypter = new AESCrypt(cryptKey-\u0026gt;data(), cryptKey-\u0026gt;length()); } else # endif  { m_dic = new MMKVMap(); } m_needLoadFromFile = true; m_hasFullWriteback = false; m_crcDigest = 0; m_sharedProcessLock-\u0026gt;m_enable = m_isInterProcess; m_exclusiveProcessLock-\u0026gt;m_enable = m_isInterProcess; // sensitive zone  { SCOPED_LOCK(m_sharedProcessLock); loadFromFile(); } } loadFromFile void MMKV::loadFromFile() { if (!m_file-\u0026gt;isFileValid()) { m_file-\u0026gt;reloadFromFile(); } auto ptr = (uint8_t *) m_file-\u0026gt;getMemory(); if (loadFromFile \u0026amp;\u0026amp; m_actualSize \u0026gt; 0) { MMBuffer inputBuffer(ptr + Fixed32Size, m_actualSize, MMBufferNoCopy); } MemoryFile reloadFromFile void MemoryFile::reloadFromFile() { m_fd = open(m_name.c_str(), O_RDWR | O_CREAT | O_CLOEXEC, S_IRWXU); FileLock fileLock(m_fd); InterProcessLock lock(\u0026amp;fileLock, ExclusiveLockType); SCOPED_LOCK(\u0026amp;lock); mmkv::getFileSize(m_fd, m_size); // round up to (n * pagesize)  if (m_size \u0026lt; DEFAULT_MMAP_SIZE || (m_size % DEFAULT_MMAP_SIZE != 0)) { size_t roundSize = ((m_size / DEFAULT_MMAP_SIZE) + 1) * DEFAULT_MMAP_SIZE; truncate(roundSize); } else { auto ret = mmap(); if (!ret) { doCleanMemoryCache(true); } } } mmap bool MemoryFile::mmap() { m_ptr = (char *) ::mmap(m_ptr, m_size, PROT_READ | PROT_WRITE, MAP_SHARED, m_fd, 0); if (m_ptr == MAP_FAILED) { MMKVError(\u0026#34;fail to mmap [%s], %s\u0026#34;, m_name.c_str(), strerror(errno)); m_ptr = nullptr; return false; } return true; } getMemory void *getMemory() { return m_ptr; } FileLock FileLock::FileLock(MMKVFileHandle_t fd, bool isAshmem) : m_fd(fd), m_sharedLockCount(0), m_exclusiveLockCount(0), m_isAshmem(isAshmem) { m_lockInfo.l_type = F_WRLCK; m_lockInfo.l_start = 0; m_lockInfo.l_whence = SEEK_SET; m_lockInfo.l_len = 0; m_lockInfo.l_pid = 0; } lock bool FileLock::lock(LockType lockType) { return doLock(lockType, true); } doLock bool FileLock::doLock(LockType lockType, bool wait, bool *tryAgain) { if (lockType == SharedLockType) { // don\u0026#39;t want shared-lock to break any existing locks  if (m_sharedLockCount \u0026gt; 0 || m_exclusiveLockCount \u0026gt; 0) { m_sharedLockCount++; return true; } } else { // don\u0026#39;t want exclusive-lock to break existing exclusive-locks  if (m_exclusiveLockCount \u0026gt; 0) { m_exclusiveLockCount++; return true; } // prevent deadlock  if (m_sharedLockCount \u0026gt; 0) { unLockFirstIfNeeded = true; } } auto ret = platformLock(lockType, wait, unLockFirstIfNeeded, tryAgain); if (ret) { if (lockType == SharedLockType) { m_sharedLockCount++; } else { m_exclusiveLockCount++; } } return ret; } unlock bool FileLock::unlock(LockType lockType) { if (lockType == SharedLockType) { if (m_sharedLockCount == 0) { return false; } // don\u0026#39;t want shared-lock to break any existing locks  if (m_sharedLockCount \u0026gt; 1 || m_exclusiveLockCount \u0026gt; 0) { m_sharedLockCount--; return true; } } else { if (m_exclusiveLockCount == 0) { return false; } if (m_exclusiveLockCount \u0026gt; 1) { m_exclusiveLockCount--; return true; } // restore shared-lock when all exclusive-locks are done  if (m_sharedLockCount \u0026gt; 0) { unlockToSharedLock = true; } } auto ret = platformUnLock(unlockToSharedLock); if (ret) { if (lockType == SharedLockType) { m_sharedLockCount--; } else { m_exclusiveLockCount--; } } return ret; } platformLock bool FileLock::platformLock(LockType lockType, bool wait, bool unLockFirstIfNeeded, bool *tryAgain) { if (m_isAshmem) { return ashmemLock(lockType, wait, unLockFirstIfNeeded, tryAgain); } auto realLockType = LockType2FlockType(lockType); auto cmd = wait ? realLockType : (realLockType | LOCK_NB); if (unLockFirstIfNeeded) { // try lock  auto ret = flock(m_fd, realLockType | LOCK_NB); if (ret == 0) { return true; } // let\u0026#39;s be gentleman: unlock my shared-lock to prevent deadlock  ret = flock(m_fd, LOCK_UN); if (ret != 0) { MMKVError(\u0026#34;fail to try unlock first fd=%d, ret=%d, error:%s\u0026#34;, m_fd, ret, strerror(errno)); } } auto ret = flock(m_fd, cmd); ...... } platformUnLock bool FileLock::platformUnLock(bool unlockToSharedLock) { if (m_isAshmem) { return ashmemUnLock(unlockToSharedLock); } int cmd = unlockToSharedLock ? LOCK_SH : LOCK_UN; auto ret = flock(m_fd, cmd); } InterProcessLock InterProcessLock(FileLock *fileLock, LockType lockType) : m_fileLock(fileLock), m_lockType(lockType), m_enable(true) { MMKV_ASSERT(m_fileLock); } lock void lock() { if (m_enable) { m_fileLock-\u0026gt;lock(m_lockType); } } unlock void unlock() { if (m_enable) { m_fileLock-\u0026gt;unlock(m_lockType); } } ScopedLock explicit ScopedLock(T *oLock) : m_lock(oLock) { MMKV_ASSERT(m_lock); lock(); } ~ScopedLock() { unlock(); m_lock = nullptr; } lock unLock template \u0026lt;typename T\u0026gt; class ScopedLock { T *m_lock; void lock() { if (m_lock) { m_lock-\u0026gt;lock(); } } void unlock() { if (m_lock) { m_lock-\u0026gt;unlock(); } } } ThreadLock.cpp ThreadOnce pthread_once用来确保在C++下多线程并发时，callback只调用一次，可用于C++中的单例模式\npthread_once实现简析\nvoid ThreadLock::ThreadOnce(ThreadOnceToken_t *onceToken, void (*callback)()) { pthread_once(onceToken, callback); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/mmkv/",
	"title": "mmkv",
	"tags": [],
	"description": "",
	"content": "mmkv 探索总结mmkv知识\n MMKV     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/oom/",
	"title": "OOM",
	"tags": [],
	"description": "",
	"content": "OOM原因分析 要定位OOM问题，首先需要弄明白Android中有哪些原因会导致OOM，Android中导致OOM的原因主要可以划分为以下几个类型：\nAndroid 虚拟机最终抛出OutOfMemoryError的代码位于/art/runtime/thread.cc。\nvoid Thread::ThrowOutOfMemoryError(const char* msg) 参数 msg 携带了 OOM 时的错误信息 下面两个地方都会调用上面方法抛出OutOfMemoryError错误，这也是Android中发生OOM的主要原因。\n堆内存分配失败 系统源码文件：/art/runtime/gc/heap.cc\nvoid Heap::ThrowOutOfMemoryError(Thread* self, size_t byte_count, AllocatorType allocator_type) 抛出时的错误信息： oss \u0026lt;\u0026lt; \u0026#34;Failed to allocate a \u0026#34; \u0026lt;\u0026lt; byte_count \u0026lt;\u0026lt; \u0026#34; byte allocation with \u0026#34; \u0026lt;\u0026lt; total_bytes_free \u0026lt;\u0026lt; \u0026#34; free bytes and \u0026#34; \u0026lt;\u0026lt; PrettySize(GetFreeMemoryUntilOOME()) \u0026lt;\u0026lt; \u0026#34; until OOM\u0026#34;; 这是在进行堆内存分配时抛出的OOM错误，这里也可以细分成两种不同的类型：\n 为对象分配内存时达到进程的内存上限。由Runtime.getRuntime.MaxMemory()可以得到Android中每个进程被系统分配的内存上限，当进程占用内存达到这个上限时就会发生OOM，这也是Android中最常见的OOM类型。 没有足够大小的连续地址空间。这种情况一般是进程中存在大量的内存碎片导致的，其堆栈信息会比第一种OOM堆栈多出一段信息：failed due to fragmentation (required continguous free “\u0026laquo; required_bytes \u0026laquo; “ bytes for a new buffer where largest contiguous free ” \u0026laquo; largest_continuous_free_pages \u0026laquo; “ bytes)”; 其详细代码在art/runtime/gc/allocator/rosalloc.cc中，这里不作详述。  创建线程失败 系统源码文件：/art/runtime/thread.cc\nvoid Thread::CreateNativeThread(JNIEnv* env, jobject java_peer, size_t stack_size, bool is_daemon) 抛出时的错误信息： \u0026#34;Could not allocate JNI Env\u0026#34; 或者 StringPrintf(\u0026#34;pthread_create (%s stack) failed: %s\u0026#34;, PrettySize(stack_size).c_str(), strerror(pthread_create_result))); 这是创建线程时抛出的OOM错误，且有多种错误信息。源码这里不展开详述了，下面是根据源码整理的Android中创建线程的步骤，其中两个关键节点是创建JNIEnv结构体和创建线程，而这两步均有可能抛出OOM。\n创建JNI失败 创建JNIEnv可以归为两个步骤：\n 通过Andorid的匿名共享内存（Anonymous Shared Memory）分配 4KB（一个page）内核态内存。 再通过Linux的mmap调用映射到用户态虚拟内存地址空间。  第一步创建匿名共享内存时，需要打开/dev/ashmem文件，所以需要一个FD（文件描述符）。此时，如果创建的FD数已经达到上限，则会导致创建JNIEnv失败，抛出错误信息如下：\nE/art: ashmem_create_region failed for \u0026#39;indirect ref table\u0026#39;: Too many open files java.lang.OutOfMemoryError: Could not allocate JNI Env at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:730) 第二步调用mmap时，如果进程虚拟内存地址空间耗尽，也会导致创建JNIEnv失败，抛出错误信息如下：\nE/art: Failed anonymous mmap(0x0, 8192, 0x3, 0x2, 116, 0): Operation not permitted. See process maps in the log. java.lang.OutOfMemoryError: Could not allocate JNI Env at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:1063) 创建线程失败 创建线程也可以归纳为两个步骤：\n 调用mmap分配栈内存。这里mmap flag中指定了MAP_ANONYMOUS，即匿名内存映射。这是在Linux中分配大块内存的常用方式。其分配的是虚拟内存，对应页的物理内存并不会立即分配，而是在用到的时候触发内核的缺页中断，然后中断处理函数再分配物理内存。 调用clone方法进行线程创建。  第一步分配栈内存失败是由于进程的虚拟内存不足，抛出错误信息如下：\nW/libc: pthread_create failed: couldn\u0026#39;t allocate 1073152-bytes mapped space: Out of memory W/tch.crowdsourc: Throwing OutOfMemoryError with VmSize 4191668 kB \u0026#34;pthread_create (1040KB stack) failed: Try again\u0026#34; java.lang.OutOfMemoryError: pthread_create (1040KB stack) failed: Try again at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:753) 第二步clone方法失败是因为线程数超出了限制，抛出错误信息如下：\nW/libc: pthread_create failed: clone failed: Out of memory W/art: Throwing OutOfMemoryError \u0026#34;pthread_create (1040KB stack) failed: Out of memory\u0026#34; java.lang.OutOfMemoryError: pthread_create (1040KB stack) failed: Out of memory at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:1078) 线程监控 常见的 OOM 情况大多数是因为内存泄漏或申请大量内存造成的，比较少见的有下面这种跟线程相关情况，但在我们 crash 系统上有时能发现一些这样的问题。\njava.lang.OutOfMemoryError: pthread_create (1040KB stack) failed: Out of memory 原因分析\nOutOfMemoryError 这种异常根本原因在于申请不到足够的内存造成的，直接的原因是在创建线程时初始 stack size 的时候，分配不到内存导致的。这个异常是在 /art/runtime/thread.cc 中线程初始化的时候 throw 出来的。\nvoid Thread::CreateNativeThread(JNIEnv* env, jobject java_peer, size_t stack_size, bool is_daemon) { ... int pthread_create_result = pthread_create( \u0026amp;new_pthread, \u0026amp;attr, Thread::CreateCallback, child_thread); if (pthread_create_result != 0) { env-\u0026gt;SetLongField(java_peer, WellKnownClasses::java_lang_Thread_nativePeer, 0); { std::string msg(StringPrintf(\u0026#34;pthread_create (%s stack) failed: %s\u0026#34;, PrettySize(stack_size).c_str(), strerror(pthread_create_result))); ScopedObjectAccess soa(env); soa.Self()-\u0026gt;ThrowOutOfMemoryError(msg.c_str()); } } } 调用这个 pthread_create 的方法去 clone 一个线程，如果返回 pthread_create_result 不为 0，则代表初始化失败。什么情况下会初始化失败，pthread_create 的具体逻辑是在 /bionic/libc/bionic/pthread_create.cpp 中完成：\nint pthread_create(pthread_t* thread_out, pthread_attr_t const* attr, void* (*start_routine)(void*), void* arg) { ... pthread_internal_t* thread = NULL; void* child_stack = NULL; int result = __allocate_thread(\u0026amp;thread_attr, \u0026amp;thread, \u0026amp;child_stack); if (result != 0) { return result; } ... } static int __allocate_thread(pthread_attr_t* attr, pthread_internal_t** threadp, void** child_stack) { size_t mmap_size; uint8_t* stack_top; ... attr-\u0026gt;stack_base = __create_thread_mapped_space(mmap_size, attr-\u0026gt;guard_size); if (attr-\u0026gt;stack_base == NULL) { return EAGAIN; // EAGAIN != 0  } ... return 0; } 可以看到每个线程初始化都需要 mmap 一定的 stack size，在默认的情况下一般初始化一个线程需要 mmap 1M 左右的内存空间，在 32bit 的应用中有 4g 的 vmsize，实际能使用的有 3g+，按这种估算，一个进程最大能创建的线程数可达 3000+，当然这是理想的情况，在 linux 中对每个进程可创建的线程数也有一定的限制（/proc/pid/limits）而实际测试中，我们也发现不同厂商对这个限制也有所不同，而且当超过系统进程线程数限制时，同样会抛出这个类型的 OOM。\n可见对线程数量的限制，可以一定程度避免 OOM 的发生。所以我们也开始对微信的线程数进行了监控统计。\n监控上报\n我们在灰度版本中通过一个定时器 10 分钟 dump 出应用所有的线程，当线程数超过一定阈值时，将当前的线程上报并预警，通过对这种异常情况的捕捉，我们发现微信在某些特殊场景下，确实存在线程泄漏以及短时间内线程暴增，导致线程数过大（500+）的情况，这种情况下再创建线程往往容易出现 OOM。\n在定位并解决这几个问题后，我们的 crash 系统和厂商的反馈中这种类型 OOM 确实降低了不少。所以监控线程数，收敛线程也成为我们降低 OOM 的有效手段之一。\n堆内存不足 Android中最常见的OOM就是Java堆内存不足，对于堆内存不足导致的OOM问题，发生Crash时的堆栈信息往往只是“压死骆驼的最后一根稻草”，它并不能有效帮助我们准确地定位到问题。\n堆内存分配失败，通常说明进程中大部分的内存已经被占用了，且不能被垃圾回收器回收，一般来说此时内存占用都存在一些问题，例如内存泄漏等。要想定位到问题所在，就需要知道进程中的内存都被哪些对象占用，以及这些对象的引用链路。而这些信息都可以在Java内存快照文件中得到，调用Debug.dumpHprofData(String fileName)函数就可以得到当前进程的Java内存快照文件（即HPROF文件）。所以，关键在于要获得进程的内存快照，由于dump函数比较耗时，在发生OOM之后再去执行dump操作，很可能无法得到完整的内存快照文件。\n线上分析 首先，我们介绍几个基本概念：\n Dominator：从GC Roots到达某一个对象时，必须经过的对象，称为该对象的Dominator。例如在上图中，B就是E的Dominator，而B却不是F的Dominator。Dominator用于计算RetainSize,一旦object的dominator被释放，那么自身也会被释放。上图黄色node为dominator tree ShallowSize：对象自身占用的内存大小，不包括它引用的对象。 RetainSize：对象自身的ShallowSize和对象所支配的（可直接或间接引用到的）对象的ShallowSize总和，就是该对象GC之后能回收的内存总和。例如上图中，D的RetainSize就是D、H、I三者的ShallowSize之和。  Object Reference graph to Dominator Tree Conversion\nJVM在进行GC的时候会进行可达性分析，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是可回收的。\nGithub上有一个开源项目HAHA库，用于自动解析和分析Java内存快照文件（即HPROF文件）。下面是HAHA库的分析步骤：\nHAHA库 退出率定义 经过认真思考，我们认识到从前忽略了一个重要的基本事实，即应用的启动数和应用的退出数是守恒的。每次启动必然会有对应的退出，只要将所有的退出类型都枚举出来并监控上报，且总数能和启动数吻合，就能覆盖所有的稳定性问题。 基于以上思想，我们提出了退出率的概念，将退出分为以下十大类，每一类的退出率定义为 退出次数 / 启动次数。\n图4\n其中前五种退出类型是显著影响用户体验的问题，需要重点关注，crash(不含OOM)和OOM对应的是开头提到的通用指标；前台系统强杀指的是设备总内存紧张，应用在前台被系统强杀，比如iOS的jetsam，android的low memory killer，也包括其他一些资源问题，比如上文讲的wakeups；watchdog指的是卡顿引起的系统强杀，典型的即为iOS的watchdog和android的ANR；exit指的是我们主动在代码中自杀，通常情况下不应该有这样的逻辑存在。后五种退出类型绝大多数情况下是正常的退出行为，对用户体验无影响，我们只关注其中异常的情况，比如UI错乱导致的用户强杀，危险代码导致的系统重启等。\nAndroid OOM治理 图9\n回顾前文，OOM在稳定性重点关注问题中的占比非常高，和占比最高的前台系统强杀也有很高的相关性，而OOM问题的定位又特别困难，通常需要投入大量的人力和时间，进行人工复现，灰度收集数据，提交记录二分法暴力验证等等。占比高又定位困难，可以说OOM治理是稳定性治理皇冠上的明珠。 提到OOM，肯定绕不开神器LeakCanary，其原理也是面试题中的常客，作为Android内存泄漏监控的开创者，多年来一直为广大app保驾护航，解决了OOM治理从0到1的问题。那么直接接入LeakCanary上线不香么？还真不行，LeakCanary虽然非常优秀，但也存在以下几点硬伤：\n 无法线上部署  主动触发GC，造成卡顿 Dump内存镜像造成app冻结 解析镜像成功率低 不具备上报能力   适用范围有限  只能定位Activity\u0026amp;Fragment泄漏 无法定位大对象、频繁分配等问题   自动化程度低  需要人工埋点 无法对问题聚类    既然没有现成的轮子可用，只能自己动手，丰衣足食，经过一番努力，我们打造了一套可以线上部署、兼顾线下、配置灵活、适用范围广泛、高度自动化，埋点、监控、解析、上报、分发、跟进、报警一站式服务的闭环监控系统。\n图10\n其核心流程为三部分：\n 监控OOM，发生问题时触发内存镜像的采集，以便进一步分析问题 采集内存镜像，学名堆转储，将内存数据拷贝到文件中，以下简称dump hprof 解析镜像文件，对泄漏、超大对象等我们关注的对象进行可达性分析，解析出其到GC root的引用链以解决问题  为完成这样一套监控系统，我们攻克了以下技术难题\n 监控  主动触发GC，会造成卡顿   采集  Dump hprof，会造成app冻结 Hprof文件过大   解析  解析耗时过长 解析本身有OOM风险    接下来我们一一展开分析。\n解决GC卡顿 为什么LeakCanary需要主动触发GC呢？LeakCanary监控泄漏利用了弱引用的特性，为Activity创建弱引用，当Activity对象变成弱可达时(没有强引用)，弱引用会被加入到引用队列中，通过在Activity.onDestroy()后连续触发两次GC，并检查引用队列，可以判定Activity是否发生了泄漏。但频繁的GC会造成用户可感知的卡顿，为解决这一问题，我们设计了全新的监控模块，通过无性能损耗的内存阈值监控来触发镜像采集，具体策略如下：\n Java堆内存/线程数/文件描述符数突破阈值触发采集 Java堆上涨速度突破阈值触发采集 发生OOM时如果策略1、2未命中 触发采集 泄漏判定延迟至解析时  阈值监控只要在子线程定期获取关注的几个内存指标即可，性能损耗可以忽略不计；内存快速上涨用来定位对象频繁分配的问题；OOM作为最后兜底的策略，走到这里说明我们的阈值设计有漏洞，没有拦截住所有可能触发OOM的场景；最后，我们将对象是否泄漏的判断延迟到了解析时。还是以Activity为例，我们并不需要在运行时判定其是否泄漏，Activity有一个成员变mDestroyed，在onDestory时会被置为true，只要解析时发现有可达且mDestroyed为true的Activity，即可判定为泄漏(由于时序问题，这里可能有极小概率会发生误判，但不影响我们解决问题)，其他关注的对象可以根据其特点设计规则。用一张图总结：\n图11\n解决Dump hprof冻结app Dump hprof是通过虚拟机提供的API dumpHprofData实现的，这个过程会**“冻结”**整个应用进程，造成数秒甚至数十秒内用户无法操作，这也是LeakCanary无法线上部署的最主要原因，如果能将这一过程优化至用户无感知，将会给OOM治理带来很大的想象空间。\n面对这样一个问题，我们将其拆解，自然而然产生2个疑问： 1.为什么dumpHprofData会冻结app，虚拟机的实现原理是什么？ 2.这个过程能异步吗？ 我们来看dumpHprofData的虚拟机内部实现 art/runtime/hprof/hprof.cc\n// If \u0026#34;direct_to_ddms\u0026#34; is true, the other arguments are ignored, and data is sent directly to DDMS. // If \u0026#34;fd\u0026#34; is \u0026gt;= 0, the output will be written to that file descriptor. // Otherwise, \u0026#34;filename\u0026#34; is used to create an output file. void DumpHeap(const char* filename, int fd, bool direct_to_ddms) { CHECK(filename != nullptr); Thread* self = Thread::Current(); // Need to take a heap dump while GC isn\u0026#39;t running. See the comment in Heap::VisitObjects().  // Also we need the critical section to avoid visiting the same object twice. See b/34967844  gc::ScopedGCCriticalSection gcs(self, gc::kGcCauseHprof, gc::kCollectorTypeHprof); ScopedSuspendAll ssa(__FUNCTION__, true /* long suspend */); Hprof hprof(filename, fd, direct_to_ddms); hprof.Dump(); } 可以看到在dump前，通过ScopedSuspendAll(构造函数中执行SuspendAll)执行了暂停所有java线程的操作，以防止在dump的过程中java堆发生变化，当dump结束后通过ScopedSuspendAll析构函数进行ResumeAll。\n解决了第一个问题，接下来看第二个问题，既然要冻结所有线程，子线程异步处理是没有意义的，那么在子进程中处理呢？Android的内核是定制过的Linux， 而Linux fork子进程有一个著名的COW(Copy-on-write，写时复制)机制，即为了节省fork子进程的内存消耗和耗时，fork出的子进程并不会copy父进程的内存，而是和父进程共享内存空间。那么如何做到进程隔离呢，父子进程只在发生内存写入操作时，系统才会分配新的内存为写入方保留单独的拷贝，这就相当于子进程保留了fork瞬间时父进程的内存镜像，且后续父进程对内存的修改不会影响子进程，想到这里我们豁然开朗。说干就干，我们写了一个demo来验证这个思路，很快就遇到了棘手的新问题：dump前需要暂停所有java线程，而子进程只保留父进程执行fork操作的线程，在子进程中执行SuspendAll触发暂停是永远等不到其他线程返回结果的(详见thread_list.cc中行SuspendAll的实现，这里不展开讲了)，经过仔细分析SuspendAll的过程，我们发现，可以先在主进程执行SuspendAll，使ThreadList中保存的所有线程状态为suspend，之后fork，子进程共享父进程的ThreadList全局变量，可以欺骗虚拟机，使其以为全部线程已经完成了暂停操作，接下来子进程就可以愉快的dump hprof了，而父进程可以立刻执行ResumeAll恢复运行。\n这里有一个小技巧，SuspendAll没有对外暴露Java层的API，我们可以通过C层间接暴露的art::Dbg::SuspendVM来调用，dlsym拿到“_ZN3art3Dbg9SuspendVMEv”的地址调用即可，ResumeAll同理，注意这个函数在android 11以后已经被去除了，需要另行适配。Android 7之后对linker做了限制（即dlopen系统库失效），快手自研了kwai-linker组件，通过caller address替换和dl_iterate_phdr解析绕过了这一限制。 至此，我们完美解决了dump hprof冻结app的问题，用一张图总结：\n图12\n解决hprof文件过大 Hprof文件通常比较大，分析OOM时遇到500M以上的hprof文件并不稀奇，文件的大小，与dump成功率、dump速度、上传成功率负相关，且大文件额外浪费用户大量的磁盘空间和流量。我们因此想到了对hprof进行裁剪，只保留分析OOM必须的数据，另外，裁剪还有数据脱敏的好处，只上传内存中类与对象的组织结构，并不上传真实的业务数据（诸如字符串、byte数组等含有具体数据的内容），保护用户隐私。\n开发镜像裁剪，有两个衡量指标：一是裁剪率，即在不影响问题分析的前提下，裁剪掉的内容要足够多；二是裁剪性能损耗，如果性能不达标引发耗电、成功率低引入新的问题，就会使得内存镜像获取得不偿失。\n照例，我们将问题拆解：\n hprof存的内容都是些什么？数据如何组织的？哪些可以裁掉？ 内存中的数据结构和hprof文件二进制协议的映射关系？ 如何裁剪？  想要了解hprof的数据组织方式，推荐阅读openjdk官方文档[2]，Android在此基础上做了一些扩展，这里简要介绍一下核心内容：\n 文件按byte by byte顺序存储，u1,u2,u4分别代表1字节，2字节，4字节。 总体分为两部分，Header和Record，Header记录hprof的元信息，Record分很多条目，每一条有一个单独的TAG代表类型。  我们关注的Record类型主要是HEAP DUMP，其中又分五个子类，分别为GC ROOT、CLASS DUMP、INSTANCE DUMP、OBJECT ARRAY DUMP、PRIMITIVE ARRAY DUMP。图13以PRIMITIVE ARRAY DUMP(基本类型数组)为例展示Record中包含的信息，其他类型请查阅官方文档。内存中绝大部分数据是PRIMITIVE ARRAY DUMP，通常占据80%以上，而我们分析OOM只关系对象的大小和引用关系，并不关心内容，因此这部分是我们裁剪的突破口。\n图13\nAndroid对数据类型做了扩展，增加了一些GC ROOT\n// Android.  HPROF_HEAP_DUMP_INFO = 0xfe, HPROF_ROOT_INTERNED_STRING = 0x89, HPROF_ROOT_FINALIZING = 0x8a, // Obsolete.  HPROF_ROOT_DEBUGGER = 0x8b, HPROF_ROOT_REFERENCE_CLEANUP = 0x8c, // Obsolete.  HPROF_ROOT_VM_INTERNAL = 0x8d, HPROF_ROOT_JNI_MONITOR = 0x8e, HPROF_UNREACHABLE = 0x90, // Obsolete.  HPROF_PRIMITIVE_ARRAY_NODATA_DUMP = 0xc3, // Obsolete. 还有一个HEAP_DUMP_INFO，这里面保存的是堆空间(heap space)的类型，Android对堆空间做了划分，我们只关注HPROF_HEAP_APP即可，其余也是可以裁剪掉的，可以参考Android Studio中Memory Profiler的处理[3]。\nenum HprofHeapId { HPROF_HEAP_DEFAULT = 0, HPROF_HEAP_ZYGOTE = \u0026#39;Z\u0026#39;, HPROF_HEAP_APP = \u0026#39;A\u0026#39;, HPROF_HEAP_IMAGE = \u0026#39;I\u0026#39;, }; 接下来讨论如何裁剪，裁剪有两种办法，第一种是在dump完成后的hprof文件基础上裁剪，性能比较差，对磁盘空间要求也比较高，第二种是在dump的过程中实时裁剪，我们自然想要实现第二种。看一下Record写入的过程，先执行StartNewRecord，然后通过AddU1/U4/U8写入内存buffer，最后执行EndRecord将buffer写入文件。\nvoid StartNewRecord(uint8_t tag, uint32_t time) { if (length_ \u0026gt; 0) { EndRecord(); } DCHECK_EQ(length_, 0U); AddU1(tag); AddU4(time); AddU4(0xdeaddead); // Length, replaced on flush.  started_ = true; } void EndRecord() { // Replace length in header.  if (started_) { UpdateU4(sizeof(uint8_t) + sizeof(uint32_t), length_ - sizeof(uint8_t) - 2 * sizeof(uint32_t)); } HandleEndRecord(); sum_length_ += length_; max_length_ = std::max(max_length_, length_); length_ = 0; started_ = false; } void HandleFlush(const uint8_t* buffer, size_t length) override { if (!errors_) { errors_ = !fp_-\u0026gt;WriteFully(buffer, length); } } 这个过程中有两个hook点可以选择，一是hook AddUx，在写入buffer的过程中裁剪，二是hook write，在写入文件过程中裁剪。最终我们选择了方案二，理由是AddUx调用比较频繁，判断逻辑复杂容易出现兼容性问题，而write是public API，且只在Record写入文件的时候调用一次，厂商不会魔改相关实现，从hook原理上来讲，hook外部调用的PLT/GOT hook也比hook内部调用的inline hook要稳定得多。\n用一张图总结裁剪的流程：\n图14\n解决hprof解析的耗时与OOM 解析hprof文件，对关键对象进行可达性分析，得到引用链，是我们解决OOM最核心的一步，之前的监控和dump都是为解析做铺垫。解析分两种，一种是上传hprof文件由server解析，另一种是在客户端解析后上传报告(通常只有几KB)。最终我们选择了端上解析，这样做有两个好处：\n 节省用户流量 利用用户闲时算力，降低server压力，这样也符合分布式计算理念。  照例，我们依然将问题拆解：\n 哪些对象需要分析，全部分析性能开销太大，很难在端上完成，并且问题没有重点也不利于解决。 性能优化，作为一个debug组件，要在不影响用户体验的情况下完成解析，对性能有非常高的要求。  关键对象判定 回顾前文，我们只解析关键对象的引用链，并写入分析报告中上传，判定的准确性和覆盖度决定了分析的质量。\n我们将关键对象分为两类，一类是根据规则可以判断出对象已经泄露，且持有大量资源的，另外一类是对象shallow / retained size 超过阈值。\nActivity/fragment泄露判定即为第一种: 对于强可达的activity对象，其mDestroyed值为true时(onDestroy时赋值)，判定已经泄露。类似的，对于fragment，当mCalled值为true且mFragmentManager为null时，判定已经泄露 。 我们可以用同样的思路合理制定规则，来处理我们核心的业务组件，比如无处不在的presenter。\nBitmap/window/array/sufacetexture判定为第二种 检查bitmap/texture的数量、宽高、window数量、array长度等等是否超过阈值，再结合hprof中的相关业务信息，比如屏幕大小，view大小等进行判定。\n性能优化 一开始我们尝试了LeakCanary的解析引擎HAHA(Android Studio解析引擎perlib的Android移植版)，解析过程中非常容易OOM，且解析速度极慢，500M的hprof文件，内存峰值达到2G，绝大多数Andriod设备的Java堆内存上限只有512M，即使顶配的macbook解析耗时都在3分钟以上，如此性能，在端上解析成功率低到发指。一度使我们想放弃现有的轮子，用C重写解析库，恰好此时LeakCanary发布了新的解析引擎shark[4]，号称内存峰值可以降低10倍，解析速度可以提升6倍。我们实验了一下，发现小的demo hprof基本能达到其宣称的性能，线上真实环境拿到的包含百万级对象hprof文件，性能会急剧下降，分析时间突破10分钟。因此，我们需要进一步优化，优化之前，先来研究一下HAHA和shark的原理。\n为什么HAHA内存峰值高，速度慢呢，概括起来主要是以下几点：\n 没做懒加载，hprof内容全部load到内存里。 domanitor tree[5]全量计算，实际上我们只关心关键对象的retained size。 频繁触发GC，java的集合类没有针对计算密集型任务做优化，含有大量冗余的装箱、拆箱、扩容、拷贝等操作，大量创建对象，频繁触发GC，GC反过来进一步降低对象分配速度，陷入恶性循环。  Shark是如何优化的呢？ Shark是LeakCanary 2.0推出的全新解析组件，其设计思想详见作者的介绍[6]，主要做了以下几项优化：\n 索引，shark低内存开销的最根本原因就是通过索引做到了内存懒加载，遍历hprof时存储对象在hprof中的位置，并为其建立索引方便按需解析。 数据结构上做了深度优化，主要是使用了更高效的map，有2个：第一是对于key和value都是基础类型或字符串的使用hppc做map，第二是对于value不是基本类型的，使用SortedBytesMap存储内容。  具体的索引有：实例索引、类索引、字符串索引、类名索引、数组索引：\n/** * This class is not thread safe, should be used from a single thread. */ internal class HprofInMemoryIndex private constructor( private val positionSize: Int, private val hprofStringCache: LongObjectScatterMap\u0026lt;String\u0026gt;, private val classNames: LongLongScatterMap, private val classIndex: SortedBytesMap, private val instanceIndex: SortedBytesMap, private val objectArrayIndex: SortedBytesMap, private val primitiveArrayIndex: SortedBytesMap, private val gcRoots: List\u0026lt;GcRoot\u0026gt;, private val proguardMapping: ProguardMapping?, val primitiveWrapperTypes: Set\u0026lt;Long\u0026gt; ) { /** * Code from com.carrotsearch.hppc.LongLongScatterMap copy pasted, inlined and converted to Kotlin. * * See https://github.com/carrotsearch/hppc . */ class LongLongScatterMap constructor(expectedElements: Int = 4) { /** * A read only map of `id` =\u0026gt; `byte array` sorted by id, where `id` is a long if [longIdentifiers] * is true and an int otherwise. Each entry has a value byte array of size [bytesPerValue]. * * Instances are created by [UnsortedByteEntries] * * [get] and [contains] perform a binary search to locate a specific entry by key. */ internal class SortedBytesMap( private val longIdentifiers: Boolean, private val bytesPerValue: Int, private val sortedEntries: ByteArray ) { 复制代码 所谓hppc是High Performance Primitive Collection[7]的缩写，shark使用kotlin将其重写了。hppc只支持基本类型，所以没有了装、拆箱的性能损耗，相关集合操作也做了大量优化，其benchmark可以参考[8]。\n再来看一下一个普通的对象在虚拟机中的内存开销有多大（ps:这还只是截图了一部分，一个int4个字节，1个long8个字节）：\n图15\n前文提到，基于shark在解析大hprof时，性能依然不够理想，需要做进一步的优化。 先来分析一下shark的使用场景和我们解析需求的差异：\n LeakCanary中shark只用于解析单一泄漏对象的引用链，而我们要分析大量对象的引用链。 Shark对于结果的要求非常精准，而我们是线上大数据分析，允许丢弃个别对象的引用链。 Shark对于镜像中的对象所有字段都进行解析，用于查询字段的值，而我们并不关心基础类型的值。  经过一番探索与实践，中途还去研究了MAT的源码，我们对其主要做了以下几点优化：\n GC root剪枝，由于我们搜索Path to GC Root时，是从GC Root自顶向下BFS，如JavaFrame、MonitorUsed等此类GC Root可以直接剪枝。 基本类型、基本类型数组不搜索、不解析。 同类对象超过阈值时不再搜索。 增加预处理，缓存每个类的所有递归super class，减少重复计算。 将object ID的类型从long修改为int，Android虚拟机的object ID大小只有32位，目前shark里使用的都是long来存储的，OOM时百万级对象的情况下，可以节省10M内存。  另外，还有几项实验中的调优项：\n 将shark改用c++重写，从GC日志来看，大hprof解析时，GC还是十分频繁的，改用c++会降低这部分开销。 扩大okio segment池的大小，空间换时间，用更多的内存、来提升高频访问解析对象的性能。  经过以上优化，将解析时间在shark的基础上优化了2倍以上，内存峰值控制在100M以内。 用一张图总结解析的流程：\n图16\n分发与跟进 解析结果上传到server以后，还要做反混淆，聚类等工作。通过关键对象以及引用链，将问题聚合后自动分发给研发同学，分发的原则是引用链中最近提交代码的owner。图17\u0026amp;18摘录了跟进系统的关键信息:\n图17\n图18\n参考 https://github.com/KwaiAppTeam/KOOM\n快手客户端稳定性体系建设_查看Android部分\n抖音 Android 性能优化系列：Java 内存优化篇\n西瓜视频稳定性治理体系建设一：Tailor 原理及实践\n//Matrix ResourceCanary没有解决dump hprof慢的问题，无法在线上使用\nhttps://github.com/Tencent/matrix/wiki/Matrix-Android-ResourceCanary\nProbe：Android线上OOM问题定位组件\nhttps://www.eclipse.org/mat/\nhttps://git.eclipse.org/c/mat/org.eclipse.mat.git\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/runtime_visitroots/",
	"title": "Runtime_VisitRoots",
	"tags": [],
	"description": "",
	"content": "art/runtime/runtime.cc\nRuntime::VisitRoots void Runtime::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) { VisitNonConcurrentRoots(visitor, flags); VisitConcurrentRoots(visitor, flags); } VisitNonConcurrentRoots void Runtime::VisitNonConcurrentRoots(RootVisitor* visitor, VisitRootFlags flags) { VisitThreadRoots(visitor, flags); VisitNonThreadRoots(visitor); } VisitThreadRoots void Runtime::VisitThreadRoots(RootVisitor* visitor, VisitRootFlags flags) { thread_list_-\u0026gt;VisitRoots(visitor, flags); } art/runtime/thread_list.cc\nThreadList::VisitRoots void ThreadList::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) const { MutexLock mu(Thread::Current(), *Locks::thread_list_lock_); for (const auto\u0026amp; thread : list_) { thread-\u0026gt;VisitRoots(visitor, flags); } } art/runtime/thread.cc\nThread::VisitRoots void Thread::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) { if ((flags \u0026amp; VisitRootFlags::kVisitRootFlagPrecise) != 0) { VisitRoots\u0026lt;/* kPrecise */ true\u0026gt;(visitor); } else { VisitRoots\u0026lt;/* kPrecise */ false\u0026gt;(visitor); } } //define the meaning of enum RootType template \u0026lt;bool kPrecise\u0026gt; void Thread::VisitRoots(RootVisitor* visitor) { const pid_t thread_id = GetThreadId(); visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.opeer, RootInfo(kRootThreadObject, thread_id)); if (tlsPtr_.exception != nullptr \u0026amp;\u0026amp; tlsPtr_.exception != GetDeoptimizationException()) { visitor-\u0026gt;VisitRoot(reinterpret_cast\u0026lt;mirror::Object**\u0026gt;(\u0026amp;tlsPtr_.exception), RootInfo(kRootNativeStack, thread_id)); } if (tlsPtr_.async_exception != nullptr) { visitor-\u0026gt;VisitRoot(reinterpret_cast\u0026lt;mirror::Object**\u0026gt;(\u0026amp;tlsPtr_.async_exception), RootInfo(kRootNativeStack, thread_id)); } visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.monitor_enter_object, RootInfo(kRootNativeStack, thread_id)); tlsPtr_.jni_env-\u0026gt;VisitJniLocalRoots(visitor, RootInfo(kRootJNILocal, thread_id)); tlsPtr_.jni_env-\u0026gt;VisitMonitorRoots(visitor, RootInfo(kRootJNIMonitor, thread_id)); HandleScopeVisitRoots(visitor, thread_id); if (tlsPtr_.debug_invoke_req != nullptr) { tlsPtr_.debug_invoke_req-\u0026gt;VisitRoots(visitor, RootInfo(kRootDebugger, thread_id)); } ...... // Visit roots on this thread\u0026#39;s stack  RuntimeContextType context; RootCallbackVisitor visitor_to_callback(visitor, thread_id); ReferenceMapVisitor\u0026lt;RootCallbackVisitor, kPrecise\u0026gt; mapper(this, \u0026amp;context, visitor_to_callback); mapper.template WalkStack\u0026lt;StackVisitor::CountTransitions::kNo\u0026gt;(false); for (instrumentation::InstrumentationStackFrame\u0026amp; frame : *GetInstrumentationStack()) { visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;frame.this_object_, RootInfo(kRootVMInternal, thread_id)); } } VisitNonThreadRoots void Runtime::VisitNonThreadRoots(RootVisitor* visitor) { java_vm_-\u0026gt;VisitRoots(visitor); sentinel_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); pre_allocated_OutOfMemoryError_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); pre_allocated_NoClassDefFoundError_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); verifier::MethodVerifier::VisitStaticRoots(visitor); VisitTransactionRoots(visitor); } VisitConcurrentRoots void Runtime::VisitConcurrentRoots(RootVisitor* visitor, VisitRootFlags flags) { intern_table_-\u0026gt;VisitRoots(visitor, flags); class_linker_-\u0026gt;VisitRoots(visitor, flags); heap_-\u0026gt;VisitAllocationRecords(visitor); if ((flags \u0026amp; kVisitRootFlagNewRoots) == 0) { // Guaranteed to have no new roots in the constant roots.  VisitConstantRoots(visitor); } Dbg::VisitRoots(visitor); } art/runtime/gc_root.h\nRootType enum RootType { kRootUnknown = 0, kRootJNIGlobal, kRootJNILocal, kRootJavaFrame, kRootNativeStack, kRootStickyClass, //contains mirror class  kRootThreadBlock, kRootMonitorUsed, kRootThreadObject, kRootInternedString, kRootFinalizing, // used for HPROF\u0026#39;s conversion to HprofHeapTag  kRootDebugger, kRootReferenceCleanup, // used for HPROF\u0026#39;s conversion to HprofHeapTag  kRootVMInternal, kRootJNIMonitor, }; art/runtime/gc_root.h\nRootVisitor VisitRootIfNonNull // Single root version, not overridable. ALWAYS_INLINE void VisitRootIfNonNull(mirror::Object** root, const RootInfo\u0026amp; info) REQUIRES_SHARED(Locks::mutator_lock_) { if (*root != nullptr) { VisitRoot(root, info); } } // Single root version, not overridable. ALWAYS_INLINE void VisitRoot(mirror::Object** root, const RootInfo\u0026amp; info) REQUIRES_SHARED(Locks::mutator_lock_) { VisitRoots(\u0026amp;root, 1, info); } SingleRootVisitor // Only visits roots one at a time, doesn\u0026#39;t handle updating roots. Used when performance isn\u0026#39;t critical. class SingleRootVisitor : public RootVisitor { VisitRoots void VisitRoots(mirror::Object*** roots, size_t count, const RootInfo\u0026amp; info) OVERRIDE REQUIRES_SHARED(Locks::mutator_lock_) { for (size_t i = 0; i \u0026lt; count; ++i) { VisitRoot(*roots[i], info); } } art/runtime/jni_env_ext.h\njni_env_ext.h VisitJniLocalRoots void VisitJniLocalRoots(RootVisitor* visitor, const RootInfo\u0026amp; root_info) REQUIRES_SHARED(Locks::mutator_lock_) { locals_.VisitRoots(visitor, root_info); } art/runtime/java_vm_ext.cc\njava_vm_ext.cc VisitRoots void JavaVMExt::VisitRoots(RootVisitor* visitor) { Thread* self = Thread::Current(); ReaderMutexLock mu(self, *Locks::jni_globals_lock_); globals_.VisitRoots(visitor, RootInfo(kRootJNIGlobal)); // The weak_globals table is visited by the GC itself (because it mutates the table). } art/runtime/gc/heap-visit-objects-inl.h\nHeap VisitObjectsPaused template \u0026lt;typename Visitor\u0026gt; inline void Heap::VisitObjectsPaused(Visitor\u0026amp;\u0026amp; visitor) { Thread* self = Thread::Current(); Locks::mutator_lock_-\u0026gt;AssertExclusiveHeld(self); VisitObjectsInternalRegionSpace(visitor); VisitObjectsInternal(visitor); } VisitObjectsInternalRegionSpace // Visit objects in the region spaces. template \u0026lt;typename Visitor\u0026gt; inline void Heap::VisitObjectsInternalRegionSpace(Visitor\u0026amp;\u0026amp; visitor) { region_space_-\u0026gt;Walk(visitor); } VisitObjectsInternal // Visit objects in the other spaces. template \u0026lt;typename Visitor\u0026gt; inline void Heap::VisitObjectsInternal(Visitor\u0026amp;\u0026amp; visitor) { if (bump_pointer_space_ != nullptr) { // Visit objects in bump pointer space.  bump_pointer_space_-\u0026gt;Walk(visitor); } for (auto* it = allocation_stack_-\u0026gt;Begin(), *end = allocation_stack_-\u0026gt;End(); it \u0026lt; end; ++it) { mirror::Object* const obj = it-\u0026gt;AsMirrorPtr(); visitor(obj); } { ReaderMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); GetLiveBitmap()-\u0026gt;Visit\u0026lt;Visitor\u0026gt;(visitor); } art/runtime/gc/accounting/heap_bitmap-inl.h\nHeapBitmap Visit template \u0026lt;typename Visitor\u0026gt; inline void HeapBitmap::Visit(Visitor\u0026amp;\u0026amp; visitor) { for (const auto\u0026amp; bitmap : continuous_space_bitmaps_) { bitmap-\u0026gt;VisitMarkedRange(bitmap-\u0026gt;HeapBegin(), bitmap-\u0026gt;HeapLimit(), visitor); } for (const auto\u0026amp; bitmap : large_object_bitmaps_) { bitmap-\u0026gt;VisitMarkedRange(bitmap-\u0026gt;HeapBegin(), bitmap-\u0026gt;HeapLimit(), visitor); } } art/runtime/mirror/object-refvisitor-inl.h\nObject VisitReferences template \u0026lt;bool kVisitNativeRoots, VerifyObjectFlags kVerifyFlags, ReadBarrierOption kReadBarrierOption, typename Visitor, typename JavaLangRefVisitor\u0026gt; inline void Object::VisitReferences(const Visitor\u0026amp; visitor, const JavaLangRefVisitor\u0026amp; ref_visitor) { ObjPtr\u0026lt;Class\u0026gt; klass = GetClass\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;(); visitor(this, ClassOffset(), false); const uint32_t class_flags = klass-\u0026gt;GetClassFlags\u0026lt;kVerifyNone\u0026gt;(); if (LIKELY(class_flags == kClassFlagNormal)) { DCHECK((!klass-\u0026gt;IsVariableSize\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;())); VisitInstanceFieldsReferences\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;(klass, visitor); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/sharedpreferences/sharedpreferences/",
	"title": "SharedPreferences",
	"tags": [],
	"description": "",
	"content": "1、加载/初始化 维护spName\u0026ndash;\u0026gt;file,file\u0026ndash;\u0026gt;sharedPreferencesImpl两个ArrayMap内存缓存 ContextImpl.java\n@Override public SharedPreferences getSharedPreferences(String name, int mode) { File file; synchronized (ContextImpl.class) { if (mSharedPrefsPaths == null) { mSharedPrefsPaths = new ArrayMap\u0026lt;\u0026gt;(); } file = mSharedPrefsPaths.get(name); if (file == null) { file = getSharedPreferencesPath(name); mSharedPrefsPaths.put(name, file); } } return getSharedPreferences(file, mode); } @Override public SharedPreferences getSharedPreferences(File file, int mode) { SharedPreferencesImpl sp; synchronized (ContextImpl.class) { final ArrayMap\u0026lt;File, SharedPreferencesImpl\u0026gt; cache = getSharedPreferencesCacheLocked(); sp = cache.get(file); if (sp == null) { checkMode(mode); sp = new SharedPreferencesImpl(file, mode); cache.put(file, sp); return sp; } } return sp; } SharedPreferencesImpl构造方法切子线程loadFromDisk,得到Map\u0026lt;String, Object\u0026gt; mMap SharedPreferencesImpl.java\nSharedPreferencesImpl(File file, int mode) { mFile = file; mBackupFile = makeBackupFile(file); mMode = mode; mLoaded = false; mMap = null; mThrowable = null; startLoadFromDisk(); } private void startLoadFromDisk() { new Thread(\u0026#34;SharedPreferencesImpl-load\u0026#34;) { public void run() { loadFromDisk(); } }.start(); } private void loadFromDisk() { synchronized (mLock) { if (mLoaded) { return; } if (mBackupFile.exists()) { mFile.delete(); mBackupFile.renameTo(mFile); } } str = new BufferedInputStream(new FileInputStream(mFile), 16 * 1024); map = (Map\u0026lt;String, Object\u0026gt;) XmlUtils.readMapXml(str); synchronized (mLock) { mLoaded = true; mThrowable = thrown; // It\u0026#39;s important that we always signal waiters, even if we\u0026#39;ll make  // them fail with an exception. The try-finally is pretty wide, but  // better safe than sorry.  try { mMap = map; } catch (Throwable t) { mThrowable = t; } finally { mLock.notifyAll(); } } edit: wait util loaded @Override public Editor edit() { // TODO: remove the need to call awaitLoadedLocked() when  // requesting an editor. will require some work on the  // Editor, but then we should be able to do:  //  // context.getSharedPreferences(..).edit().putString(..).apply()  //  // ... all without blocking.  synchronized (mLock) { awaitLoadedLocked(); } return new EditorImpl(); } @GuardedBy(\u0026#34;mLock\u0026#34;) private void awaitLoadedLocked() { while (!mLoaded) { try { mLock.wait(); } catch (InterruptedException unused) { } } } putXxx: mModified.put(key, value) @Override public Editor putString(String key, @Nullable String value) { synchronized (mEditorLock) { mModified.put(key, value); return this; } } 2、编辑提交 2.1、 commit()流程 @Override public boolean commit() { MemoryCommitResult mcr = commitToMemory(); SharedPreferencesImpl.this.enqueueDiskWrite(mcr, null /* sync write on this thread okay */); try { mcr.writtenToDiskLatch.await(); } catch (InterruptedException e) { return false; } notifyListeners(mcr); return mcr.writeToDiskResult; } 2.1.1 commitToMemory // Returns true if any changes were made  private MemoryCommitResult commitToMemory() { long memoryStateGeneration; List\u0026lt;String\u0026gt; keysModified = null; Set\u0026lt;OnSharedPreferenceChangeListener\u0026gt; listeners = null; Map\u0026lt;String, Object\u0026gt; mapToWriteToDisk; synchronized (SharedPreferencesImpl.this.mLock) { mapToWriteToDisk = mMap; synchronized (mEditorLock) { for (Map.Entry\u0026lt;String, Object\u0026gt; e : mModified.entrySet()) { String k = e.getKey(); Object v = e.getValue(); // \u0026#34;this\u0026#34; is the magic value for a removal mutation. In addition,  // setting a value to \u0026#34;null\u0026#34; for a given key is specified to be  // equivalent to calling remove on that key.  if (v == this || v == null) { if (!mapToWriteToDisk.containsKey(k)) { continue; } mapToWriteToDisk.remove(k); } else { if (mapToWriteToDisk.containsKey(k)) { Object existingValue = mapToWriteToDisk.get(k); if (existingValue != null \u0026amp;\u0026amp; existingValue.equals(v)) { continue; } } mapToWriteToDisk.put(k, v); } changesMade = true; } return new MemoryCommitResult(memoryStateGeneration, keysModified, listeners, mapToWriteToDisk); } } 2.2.2 enqueueDiskWrite private void enqueueDiskWrite(final MemoryCommitResult mcr, final Runnable postWriteRunnable) { final boolean isFromSyncCommit = (postWriteRunnable == null); final Runnable writeToDiskRunnable = new Runnable() { @Override public void run() { synchronized (mWritingToDiskLock) { writeToFile(mcr, isFromSyncCommit); } synchronized (mLock) { mDiskWritesInFlight--; } if (postWriteRunnable != null) { postWriteRunnable.run(); } } }; // Typical #commit() path with fewer allocations, doing a write on  // the current thread.  if (isFromSyncCommit) { boolean wasEmpty = false; synchronized (mLock) { wasEmpty = mDiskWritesInFlight == 1; } if (wasEmpty) { writeToDiskRunnable.run(); return; } } QueuedWork.queue(writeToDiskRunnable, !isFromSyncCommit); } QueuedWork.queue  当apply()方式提交的时候，默认消息会延迟发送100毫秒，避免频繁的磁盘写入操作。 当commit()方式，调用QueuedWork的queue()时，会立即向handler()发送Message。  /** Delay for delayed runnables, as big as possible but low enough to be barely perceivable */ private static final long DELAY = 100; public static void queue(Runnable work, boolean shouldDelay) { Handler handler = getHandler(); synchronized (sLock) { sWork.add(work); if (shouldDelay \u0026amp;\u0026amp; sCanDelay) { handler.sendEmptyMessageDelayed(QueuedWorkHandler.MSG_RUN, DELAY); } else { handler.sendEmptyMessage(QueuedWorkHandler.MSG_RUN); } } } /** * Lazily create a handler on a separate thread. */ private static Handler getHandler() { synchronized (sLock) { if (sHandler == null) { HandlerThread handlerThread = new HandlerThread(\u0026#34;queued-work-looper\u0026#34;, Process.THREAD_PRIORITY_FOREGROUND); handlerThread.start(); sHandler = new QueuedWorkHandler(handlerThread.getLooper()); } return sHandler; } } private static class QueuedWorkHandler extends Handler { static final int MSG_RUN = 1; QueuedWorkHandler(Looper looper) { super(looper); } public void handleMessage(Message msg) { if (msg.what == MSG_RUN) { processPendingWork(); } } } private static void processPendingWork() { long startTime = 0; synchronized (sProcessingWork) { LinkedList\u0026lt;Runnable\u0026gt; work; synchronized (sLock) { work = (LinkedList\u0026lt;Runnable\u0026gt;) sWork.clone(); sWork.clear(); // Remove all msg-s as all work will be processed now  getHandler().removeMessages(QueuedWorkHandler.MSG_RUN); } if (work.size() \u0026gt; 0) { for (Runnable w : work) { w.run(); } } } } writeToFile private void writeToFile(MemoryCommitResult mcr, boolean isFromSyncCommit) { boolean fileExists = mFile.exists(); // Rename the current file so it may be used as a backup during the next read  if (fileExists) { boolean backupFileExists = mBackupFile.exists(); if (!backupFileExists) { if (!mFile.renameTo(mBackupFile)) { Log.e(TAG, \u0026#34;Couldn\u0026#39;t rename file \u0026#34; + mFile + \u0026#34; to backup file \u0026#34; + mBackupFile); mcr.setDiskWriteResult(false, false); return; } } else { mFile.delete(); } } // Attempt to write the file, delete the backup and return true as atomically as  // possible. If any exception occurs, delete the new file; next time we will restore  // from the backup.  try { FileOutputStream str = createFileOutputStream(mFile); XmlUtils.writeMapXml(mcr.mapToWriteToDisk, str); FileUtils.sync(str); str.close(); // Writing was successful, delete the backup file if there is one.  mBackupFile.delete(); mcr.setDiskWriteResult(true, true); void setDiskWriteResult(boolean wasWritten, boolean result) { this.wasWritten = wasWritten; writeToDiskResult = result; writtenToDiskLatch.countDown(); } 2.2、 apply()流程 public void apply() { final MemoryCommitResult mcr = commitToMemory(); final Runnable awaitCommit = new Runnable() { @Override public void run() { try { mcr.writtenToDiskLatch.await(); } catch (InterruptedException ignored) { } } }; QueuedWork.addFinisher(awaitCommit); Runnable postWriteRunnable = new Runnable() { @Override public void run() { awaitCommit.run(); QueuedWork.removeFinisher(awaitCommit); } }; SharedPreferencesImpl.this.enqueueDiskWrite(mcr, postWriteRunnable); notifyListeners(mcr); } 2.2.1 commitToMemory 2.2.2 enqueueDiskWrite 2.3 主线程堵塞ANR waitToFinish，processPendingWork  You don\u0026rsquo;t need to worry about Android component lifecycles and their interaction with apply() writing to disk. The framework makes sure in-flight disk writes from apply() complete before switching states.\n //QueuedWork.java  public static void waitToFinish() { ... processPendingWork();//执行文件写入磁盘操作  .... } private static void processPendingWork() { long startTime = 0; .... if (work.size() \u0026gt; 0) { for (Runnable w : work) { w.run(); } ... } waitToFinish()会将，储存在QueuedWork的操作一并处理掉。什么时候呢？在Activiy的 onPause()、BroadcastReceiver的onReceive()以及Service的onStartCommand()方法之前都会调用waitToFinish()。大家知道这些方法都是执行在主线程中，一旦waitToFinish()执行超时，就会跑出ANR。\n至于waitToFinish调用具体时机，查看ActivityThread.java类文件。这里只是说本质原理\n线程安全 多操作线程安全 为了保证SharedPreferences是线程安全的，Google的设计者一共使用了3把锁：\n对于简单的 读操作 而言，我们知道其原理是读取内存中mMap的值并返回，那么为了保证线程安全，只需要加一把锁保证mMap的线程安全即可：\nmMap相关的mLock锁 public String getString(String key, @Nullable String defValue) { synchronized (mLock) { String v = (String)mMap.get(key); return v != null ? v : defValue; } } 写操作线程安全 对于写操作而言，每次putXXX()并不能立即更新在mMap中，这是理所当然的，如果开发者没有调用apply()方法，那么这些数据的更新理所当然应该被抛弃掉，但是如果直接更新在mMap中，那么数据就难以恢复。\n因此，Editor本身也应该持有一个mEditorMap对象，用于存储数据的更新；只有当调用apply()时，才尝试将mEditorMap与mMap进行合并，以达到数据更新的目的。\n因此，这里我们还需要另外一把锁保证mEditorMap的线程安全，笔者认为，不和mMap公用同一把锁的原因是，在apply()被调用之前，getXXX和putXXX理应是没有冲突的。\n代码实现参考如下：\nEditorImpl相关的mEditorLock锁 public final class EditorImpl implements Editor { @Override public Editor putString(String key, String value) { synchronized (mEditorLock) { mEditorMap.put(key, value); return this; } } } 而当真正需要执行apply()进行写操作时，mEditorMap与mMap进行合并，这时必须通过2把锁保证mEditorMap与mMap的线程安全，保证mMap最终能够更新成功，最终向对应的xml文件中进行更新。\n文件的更新理所当然也需要加一把锁：\n写文件时的锁mWritingToDiskLock // SharedPreferencesImpl.EditorImpl.enqueueDiskWrite() synchronized (mWritingToDiskLock) { writeToFile(mcr, isFromSyncCommit); } 最终，我们一共通过使用了3把锁，对整个写操作的线程安全进行了保证。\n 篇幅限制，本文不对源码进行详细引申，有兴趣的读者可参考 SharedPreferencesImpl.EditorImpl 类的apply()源码。\n 3、跨进程操作的解决方案 //ContextImpl private void checkMode(int mode) { if (getApplicationInfo().targetSdkVersion \u0026gt;= Build.VERSION_CODES.N) { if ((mode \u0026amp; MODE_WORLD_READABLE) != 0) { throw new SecurityException(\u0026#34;MODE_WORLD_READABLE no longer supported\u0026#34;); } if ((mode \u0026amp; MODE_WORLD_WRITEABLE) != 0) { throw new SecurityException(\u0026#34;MODE_WORLD_WRITEABLE no longer supported\u0026#34;); } } } Andorid 7.0及以上会抛出异常，Sharepreferences不再支持多进程模式。多进程共享文件会出现问题的本质在于，因为不同进程，所以线程同步会失效。要解决这个问题，可尝试跨进程解决方案，如ContentProvider、AIDL、AIDL、Service。\n4、替代方案 MMKV Jetpack DataStore 5、 小结 通过本文我们了解了SharedPreferences的基本原理。再回头看看文章开头的那几个问题，是不是有答案了。\n commit()方法和apply()方法的区别：commit()方法是同步的有返回结果，同步保证使用Countdownlatch，即使同步但不保证往磁盘的写入是发生在当前线程的。apply()方法是异步的具体发生在QueuedWork中，里面维护了一个单线程去执行磁盘写入操作。 commit()和apply()方法其实都是Block主线程。commit()只要在主线程调用就会堵塞主线程;apply（）方法磁盘写入操作虽然是异步的，但是当组件(Activity Service BroadCastReceiver)这些系统组件特定状态转换的时候，会把QueuedWork中未完成的那些磁盘写入操作放在主线程执行，且如果比较耗时会产生ANR。 跨进程操作，需要借助Android平台常规的IPC手段（如，AIDL ContentProvider等来封装一层sp数据处理流程）来完成。 替代解决方案:看4。  6. 参考 SharedPreferences灵魂拷问之原理\n官方也无力回天？“SharedPreferences 存在什么问题？”\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/sharedpreferences/",
	"title": "sharedpreferences",
	"tags": [],
	"description": "",
	"content": "sharedpreferences 探索总结sharedpreferences知识\n SharedPreferences     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/alloc_gc/space/",
	"title": "Space",
	"tags": [],
	"description": "",
	"content": "类设计 ART虚拟机提供了多种内存分配手段，它们分别由LargeObjectSpace、BumpPointerSpace、ZygoteSpace、RegionSpace、DlMallocSpace和RosAllocSpace六个类(叶子节点)来实现。ImageSpace用于.art文件的加载\nclassDiagram class Space { +GetNames() +Contains() +IsImageSpace() +IsMallocSpace() +isZygoteSpace() +isBumpPointerSpace() +IsRegionSpace() } class AllocSpace { +GetByteAllocated() +GetObjectsAllocated() +Alloc() +AllocThreadSafe() +Free() +FreeList() } Space \u0026lt;|-- ContinuousSpace ContinuousSpace \u0026lt;|-- MemMapSpace MemMapSpace \u0026lt;|-- ImageSpace MemMapSpace \u0026lt;|-- ContinuousMemMapAllocSpace AllocSpace \u0026lt;|-- ContinuousMemMapAllocSpace AllocSpace \u0026lt;|-- LargeObjectSpace Space \u0026lt;|-- DiscontinuousSpace DiscontinuousSpace \u0026lt;|-- LargeObjectSpace ContinuousMemMapAllocSpace \u0026lt;|-- BumpPointerSpace ContinuousMemMapAllocSpace \u0026lt;|-- RegionSpace ContinuousMemMapAllocSpace \u0026lt;|-- ZygoteSpace ContinuousMemMapAllocSpace \u0026lt;|-- MallocSpace MallocSpace \u0026lt;|-- DlMallocSpace MallocSpace \u0026lt;|-- RosAllocSpace LargeObjectSpace \u0026lt;|-- LargeObjectMapSpace LargeObjectSpace \u0026lt;|-- FreeListSpace SpaceBitmap space_bitmap(-inl).h\nstatic constexpr int kBitsPerIntPtrT = sizeof(intptr_t) * kBitsPerByte; // System page size. We check this against sysconf(_SC_PAGE_SIZE) at runtime, but use a simple // compile-time constant so the compiler can generate better code. static constexpr int kPageSize = 4096; // Required object alignment static constexpr size_t kObjectAlignment = 8; static constexpr size_t kLargeObjectAlignment = kPageSize; typedef SpaceBitmap\u0026lt;kObjectAlignment\u0026gt; ContinuousSpaceBitmap; typedef SpaceBitmap\u0026lt;kLargeObjectAlignment\u0026gt; LargeObjectBitmap; template\u0026lt;size_t kAlignment\u0026gt; class SpaceBitmap { // Backing storage for bitmap.  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map_; // This bitmap itself, word sized for efficiency in scanning.  uintptr_t* const bitmap_begin_; Set(const mirror::Object* obj) bool Set(const mirror::Object* obj) ALWAYS_INLINE { return Modify\u0026lt;true\u0026gt;(obj);//obj是一个内存地址。Modify本身是又是一个模板函数 } Modify(const mirror::Object* obj) inline bool SpaceBitmap\u0026lt;kAlignment\u0026gt;::Modify(const mirror::Object* obj) { uintptr_t addr = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(obj); //offset是obj和heap_begin_（内存基地址）的偏移量  const uintptr_t offset = addr - heap_begin_; //先计算这个偏移量落在哪个字节中  const size_t index = OffsetToIndex(offset); //再计算这个偏移量落在字节的哪个比特位上  const uintptr_t mask = OffsetToMask(offset); //用index取出位图对应的字节（注意，位图存储空间是以字节为单位的，而不是以比特位为单位）  uintptr_t* address = \u0026amp;bitmap_begin_[index];//main  uintptr_t old_word = *address; if (kSetBit) {//kSetBit为true的话，表示往位图中存储某个地址  if ((old_word \u0026amp; mask) == 0) {//如果该比特位还未设置，才设置  *address = old_word | mask;//设置mask比特位  } } else { //取消mask比特位，这相当于从位图中去除对应位置所保存的地址  *address = old_word \u0026amp; ~mask; } return (old_word \u0026amp; mask) != 0; } // \u0026lt;offset\u0026gt; is the difference from .base to a pointer address.  // \u0026lt;index\u0026gt; is the index of .bits that contains the bit representing  // \u0026lt;offset\u0026gt;.  static constexpr size_t OffsetToIndex(size_t offset) { return (offset / kAlignment) / kBitsPerIntPtrT;//先对齐  } template\u0026lt;typename T\u0026gt; static constexpr T IndexToOffset(T index) { return static_cast\u0026lt;T\u0026gt;(index * kAlignment * kBitsPerIntPtrT); } // Bits are packed in the obvious way.  static constexpr uintptr_t OffsetToMask(uintptr_t offset) { return (static_cast\u0026lt;size_t\u0026gt;(1)) \u0026lt;\u0026lt; ((offset / kAlignment) % kBitsPerIntPtrT); } Walk(ObjectCallback* callback, void* arg) template\u0026lt;size_t kAlignment\u0026gt; void SpaceBitmap\u0026lt;kAlignment\u0026gt;::Walk(ObjectCallback* callback, void* arg) { //注意这个函数的参数，callback是回调函数，每次从位图中确定一个对象的地址后将回调它,main  uintptr_t end = OffsetToIndex(HeapLimit() - heap_begin_ - 1); uintptr_t* bitmap_begin = bitmap_begin_; for (uintptr_t i = 0; i \u0026lt;= end; ++i) { uintptr_t w = bitmap_begin[i]; if (w != 0) { uintptr_t ptr_base = IndexToOffset(i) + heap_begin_; do { const size_t shift = CTZ(w);//w中末尾为0的个数，也就是第一个值为1的索引位  //计算该索引位所存储的对象地址值，注意下面代码行中计算对象地址的公式  mirror::Object* obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(ptr_base + shift * kAlignment); (*callback)(obj, arg);//回调callback，arg是传入的参数  w ^= (static_cast\u0026lt;uintptr_t\u0026gt;(1)) \u0026lt;\u0026lt; shift;//清除该索引位的1，继续循环  } while (w != 0); } } } space.h\nSpace class Space { protected: std::string name_; //表示一个Space对象的名称  /*GcRetentionPolicy是一个枚举变量，其定义如下： enum GcRetentionPolicy { //下面这个枚举值表示本空间无需GC kGcRetentionPolicyNeverCollect, //每次GC都需要回收本空间的垃圾对象 kGcRetentionPolicyAlwaysCollect, //只在full GC的时候回收本空间的垃圾对象 kGcRetentionPolicyFullCollect, } */ GcRetentionPolicy gc_retention_policy_; ...... }; ContinuousSpace Continuous spaces have bitmaps, and an address range. Although not required, objects within continuous spaces can be marked in the card table.\n// Address at which the space begins. //ContinuousSpace代表一块内存地址连续的空间，begin_为该内存空间的起始地址  uint8_t* Begin() const { return begin_; } // Current address at which the space ends, which may vary as the space is filled.  //可以将end_看作水位线。如果一个ContinuousSpace对象可分配内存的话，那么end_表示  //当前内存分配到哪了。end_最大不能超过下面的limit_成员变量  uint8_t* End() const { return end_.LoadRelaxed(); } // The end of the address range covered by the space. //limit_是这块内存空间的末尾地址。end_不能超过limit_  uint8_t* Limit() const { return limit_; } public: //Capacity函数返回该空间的容量，值为limit_- begin_  virtual size_t Capacity() const { return Limit() - Begin(); } //Size函数返回该空间当前使用了多少，值为end_- begin_。  size_t Size() const { return End() - Begin(); } } MemMapSpace class MemMapSpace : public ContinuousSpace { protected: std::unique_ptr\u0026lt;MemMap\u0026gt;mem_map_;//该成员变量指向所管理的MemMap对象 } ContinuousMemMapAllocSpace Used by the heap compaction interface to enable copying from one type of alloc space to another.\nclass ContinuousMemMapAllocSpace : public MemMapSpace, public AllocSpace { protected: /*ContinuousSpaceBitmap为数据类型别名，其定义如下： typedef SpaceBitmap\u0026lt;kObjectAlignment\u0026gt; ContinuousSpaceBitmap; kObjectAlignment取值为8。下文将解释这三个成员变量的取值情况。*/ std::unique_ptr\u0026lt;accounting::ContinuousSpaceBitmap\u0026gt;live_bitmap_; std::unique_ptr\u0026lt;accounting::ContinuousSpaceBitmap\u0026gt;mark_bitmap_; std::unique_ptr\u0026lt;accounting::ContinuousSpaceBitmap\u0026gt;temp_bitmap_; } BumpPointerSpace   Sequential Allocation或Linear Allocation, 正因为BumpPointerSpace采用了如此简单的内存分配算法，所以它压根就不能释放某一次所分配的内存（和ZygoteSpace一样，Free等函数没有真正的实现），而只支持一次性释放所有已分配的内存（实现了AllocSpace的Clear函数）。\n  BumpPointer-Space非常适合做线程本地内存分配——Thread Local Allocation Blocks，简写为TLAB，它代表一块专属某个线程的内存资源\n  Create // A bump pointer space allocates by incrementing a pointer, it doesn\u0026#39;t provide a free // implementation as its intended to be evacuated. BumpPointerSpace* BumpPointerSpace::Create(const std::string\u0026amp; name, size_t capacity, uint8_t* requested_begin) { capacity = RoundUp(capacity, kPageSize); std::string error_msg; //创建MemMap对象  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map(MemMap::MapAnonymous(name.c_str(), requested_begin, capacity,...)); ..... return new BumpPointerSpace(name, mem_map.release()); } BumpPointerSpace::BumpPointerSpace(const std::string\u0026amp; name, MemMap* mem_map) : ContinuousMemMapAllocSpace(name, mem_map, mem_map-\u0026gt;Begin(), mem_map-\u0026gt;Begin(), mem_map-\u0026gt;End(),GcRetentionPolicyAlwaysCollect), growth_end_(mem_map-\u0026gt;End()),//内存资源的尾部。分配的内存不允许超过该位置  objects_allocated_(0),//创建了多少个mirror Object对象  bytes_allocated_(0), //分配了多少字节的内存  block_lock_(\u0026#34;Block lock\u0026#34;, kBumpPointerSpaceBlockLock), main_block_size_(0),//main_block_size_和num_blocks_的作用见下文代码分析  num_blocks_(0) { } Alloc Alloc用于为某个mirror Object对象分配所需的内存。 inline mirror::Object* BumpPointerSpace::Alloc(Thread*, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { /* Alloc函数的原型由AllocSpace类定义，其参数的含义为： self：第一个参数。代表调用线程的线程对象，由于BumpPointerSpace没有使用这个参数， 所以上面的参数列表中并没有它（注意，第一个参数有参数类型，但没有参数名）。 num_bytes:第二个参数。此次内存分配所需的内存大小 bytes_allocated：实际分配了多少内存。它是一个输出参数。如果内存分配成功的话，该参数 大于或等于num_bytes。有一些内存分配算法会在实际所需内存大小上额外多分配一些内存用以 存储该算法所需的特殊信息。 usable_size：输出参数。如上文所说，实际分配的内存可能比所需内存要多。该变量表示所分配 的内存资源中可被外界使用的大小。显然，如果内存分配成功的话，该变量大于或等于num_bytes。 bytes_tl_bulk_allocated：它和thread local内存分配有关，其作用见下文代码分析。 另外，Alloc函数返回值的类型为mirror Object*。所以，Alloc就是用于为一个 Java Object对象（虚拟机中对应一个mirror Object对象）分配所需内存的函数。 */ //num_bytes按8字节向上对齐（kAlignment为8）  num_bytes = RoundUp(num_bytes, kAlignment); mirror::Object* ret = AllocNonvirtual(num_bytes);//main  //设置返回值参数  if (LIKELY(ret != nullptr)) { //BumpPointerSpace内存分配算法无需额外信息。所以实际分配内存大小就是num_bytes  //当然，num_bytes已经按8字节向上对齐  *bytes_allocated = num_bytes; if (usable_size != nullptr) { *usable_size = num_bytes; } *bytes_tl_bulk_allocated = num_bytes; } return ret; } AllocNonvirtual inline mirror::Object* BumpPointerSpace::AllocNonvirtual(size_t num_bytes) { //具体的内存分配由下面这个函数完成  mirror::Object* ret = AllocNonvirtualWithoutAccounting(num_bytes); if (ret != nullptr) { /*objects_allocated_和bytes_allocated_的类型为AtomicInteger，可在多个线程中实现原子操作。其中； objects_allocated_：表示当前所分配的Object对象的个数。 bytes_allocated_：当前所分配的总内存大小。 下面的FetchAndAddSequentiallyConsistent函数为原子操作，相当于做加法。 */ objects_allocated_.FetchAndAddSequentiallyConsistent(1); bytes_allocated_.FetchAndAddSequentiallyConsistent(num_bytes); } return ret; } AllocNonvirtualWithoutAccounting inline mirror::Object* BumpPointerSpace::AllocNonvirtualWithoutAccounting( size_t num_bytes) { uint8_t* old_end; uint8_t* new_end; /*end_类型为Atomic\u0026lt;uint8_t*\u0026gt;，它是ContinuousSpace类的成员变量，它表示上一次内 存分配的末尾位置。也就是Bump Pointer的位置。BumpPointerSpace构造函数中，该成员变 量取值等于内存的起始位置。由于BumpPointerSpace的分配算法很简单，所以只需使用原子变量 即可实现多线程并发操作。 */ do { old_end = end_.LoadRelaxed();//获取当前末尾位置  new_end = old_end + num_bytes;//计算新的末尾位置  if (UNLIKELY(new_end \u0026gt;growth_end_)) {//如果超过内存资源的大小，则返回空指针  return nullptr; } } while (!end_.CompareExchangeWeakSequentiallyConsistent( old_end, new_end)); //while循环退出后，end_将指向最新的末尾位置new_end。此次内存分配得到的内存起始地址为old_end,main  return reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(old_end); } AllocNewTlab //AllocNewTlab：当ART虚拟机决定从调用线程的本地存储空间中分配内存时将调用此函数。 bool BumpPointerSpace::AllocNewTlab(Thread* self, size_t bytes) { //注意参数，self代表调用线程，bytes代表此次内存分配的大小  MutexLock mu(Thread::Current(), block_lock_); //先释放self线程原来的TLAB（Thread Local Allocation Buffer），TLAB其实就代表一块内存  RevokeThreadLocalBuffersLocked(self); uint8_t* start = AllocBlock(bytes);//main  if (start == nullptr) { return false; } //设置self线程的TLAB，起始位置为start，结束位置为start+bytes。TLAB的详情见下文介绍。  self-\u0026gt;SetTlab(start, start + bytes); return true; } AllocBlock // Returns the start of the storage. uint8_t* BumpPointerSpace::AllocBlock(size_t bytes) { bytes = RoundUp(bytes, kAlignment); /*num_blocks_表示当前分配了多少内存块。每次调用AllocBlock都对应一个内存块。 BumpPointerSpace中，这样的内存块由BlockHeader数据结构来描述，其内容为： struct BlockHeader { size_t size_; //内存块总大小 size_t unused_; //还剩多少空余内存 }; */ //如果是第一次分配内存块，则需要设置main_block_size_的值。UpdateMainBlock  //的实现很简单，就是将当前已经分配的内存大小（由end_减去begin_）赋值给main_block_size_  if (!num_blocks_) { UpdateMainBlock();//内部的代码为：main_block_size_ = Size();  } //分配内存，在原来所需内存大小的基础上加上BlockHeader结构体所需内存  uint8_t* storage = reinterpret_cast\u0026lt;uint8_t*\u0026gt;( AllocNonvirtualWithoutAccounting(bytes + sizeof(BlockHeader)));//main  if (LIKELY(storage != nullptr)) { BlockHeader* header = reinterpret_cast\u0026lt;BlockHeader*\u0026gt;(storage); header-\u0026gt;size_ = bytes;//设置BlockHeader的信息。  storage += sizeof(BlockHeader);//返回给外部使用者的内存不包括BlockHeader部分  ++num_blocks_;//num_blocks_递增1  } return storage; } Free(Thread*, mirror::Object*) size_t Free(Thread*, mirror::Object*) OVERRIDE { return 0;//直接返回0，说明BumpPointerSpace不能释放某一个Object所占据的内存 } Clear void BumpPointerSpace::Clear() { if (!kMadviseZeroes) {//Linux平台上该值为true。  memset(Begin(), 0, Limit() - Begin());//将对应内存资源的内容清零  } //下面这个函数的作用和上面代码中调用memset清零内存空间的效果类似，我们在11.4.7节中介绍过它  madvise(Begin(), Limit() - Begin(), MADV_DONTNEED), -1); SetEnd(Begin());//设置end_等于begin_。  //所有相关成员变量恢复为初值  objects_allocated_.StoreRelaxed(0); bytes_allocated_.StoreRelaxed(0); growth_end_ = Limit(); { MutexLock mu(Thread::Current(), block_lock_); num_blocks_ = 0; main_block_size_ = 0; } Walk(ObjectCallback* callback, void* arg) void BumpPointerSpace::Walk(ObjectCallback* callback, void* arg) { uint8_t* pos = Begin(); uint8_t* end = End(); uint8_t* main_end = pos; { { MutexLock mu(Thread::Current(), block_lock_); if (num_blocks_ == 0) { UpdateMainBlock();//计算main block的大小。  } main_end = Begin() + main_block_size_; if (num_blocks_ == 0) { end = main_end; } } //先遍历main block  while (pos \u0026lt; main_end) { mirror::Object* obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(pos); /*判断这个obj是不是真实存在。从内存角度来说obj本身是存在的，因为上面代码中obj直 接由内存地址转换而来。所以obj肯定不为空指针。但obj可能并不是真正的对象。下面的 GetClass函数将获取该obj对应的klass_（该对象所属的类）。如果为空，说明obj并 不存在。对BumpPointerSpace使用的内存分配算法而言，也就没必要继续遍历了。 所以下面的if条件满足后，函数就直接返回了。*/ if (obj-\u0026gt;GetClass\u0026lt;kDefaultVerifyFlags, kWithoutReadBarrier\u0026gt;() == nullptr) { return;} else { callback(obj, arg);//调用callback,main  //获取下一个对象的位置，  pos = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(GetNextObject(obj));//main  } } //如果还有其他线程的TLAB的话，则继续遍历。此时就需要考虑BlockHeader的存在了  while (pos \u0026lt; end) { BlockHeader* header = reinterpret_cast\u0026lt;BlockHeader*\u0026gt;(pos); size_t block_size = header-\u0026gt;size_; pos += sizeof(BlockHeader); mirror::Object* obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(pos); const mirror::Object* end_obj = reinterpret_cast\u0026lt;const mirror::Object*\u0026gt;(pos + block_size); while (obj \u0026lt; end_obj \u0026amp;\u0026amp; obj-\u0026gt;GetClass\u0026lt;kDefaultVerifyFlags, kWithoutReadBarrier\u0026gt;() != nullptr) { callback(obj, arg); obj = GetNextObject(obj); } pos += block_size; } } GetNextObject(mirror::Object* obj) mirror::Object* BumpPointerSpace::GetNextObject(mirror::Object* obj) { //obj表示当前所遍历的object对象的地址。那么，下一个对象的地址就是obj+obj的大小。  const uintptr_t position = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(obj) + obj-\u0026gt;SizeOf(); //按8字节对齐  return reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(RoundUp(position, kAlignment)); } GetBytesAllocated uint64_t BumpPointerSpace::GetBytesAllocated() { //由图13-2可知，bytes_allocated_表示main block部分所分配的内存大小  uint64_t total = static_cast\u0026lt;uint64_t\u0026gt;(bytes_allocated_.LoadRelaxed()); Thread* self = Thread::Current(); ...... /*如果有多个线程使用TLAB，则需要计算它们的TLAB大小。 */ std::list\u0026lt;Thread*\u0026gt;thread_list = Runtime::Current()-\u0026gt;GetThreadList()-\u0026gt;GetList(); ...... if (num_blocks_ \u0026gt; 0) { for (Thread* thread : thread_list) { total += thread-\u0026gt;GetThreadLocalBytesAllocated();//Thread GetThreadLocalBytesAllocated返回值就是tlsPtr_.thread_local_end减去 tlsPtr_.thread_local_start的差。  } } return total; } RegionSpace  RegionSpace的内存分配算法比BumpPointerSpace稍微高级一点。它先将内存资源划分成一个个固定大小（由kRegionSize指定，默认为1MB）的内存块。每一个内存块由一个Region对象表示。进行内存分配时，先找到满足要求的Region，然后从这个Region中分配资源。  class RegionSpace FINAL : public ContinuousMemMapAllocSpace { ...... //枚举变量RegionType用于描述内存块的类型。有些内容需要结合内存回收的相关知识才能理解，  //此处暂且不表  enum class RegionType : uint8_t { kRegionTypeAll, kRegionTypeFromSpace, kRegionTypeUnevacFromSpace, kRegionTypeToSpace, kRegionTypeNone, }; //枚举变量RegionState用于描述内存块的内存分配状态。  enum class RegionState : uint8_t { kRegionStateFree, //内存块还未分配过内存  kRegionStateAllocated, //内存块分配过一些内存  /*如果需要分配比如3.5MB空间的话，则需要动用四个内存块。第一个内存块的状态将设置为 kRegionStateLarge，表示该Region为一个超过kRegionSize大小的内存的起始部分。 后面三个内存块的状态均为kRegionStateLargeTail。注意，第四个内存块将只用到0.5MB 的空间，剩下的0.5MB空间不能再用于内存分配。 */ kRegionStateLarge, kRegionStateLargeTail, }; } Create RegionSpace* RegionSpace::Create(const std::string\u0026amp; name, size_t capacity, uint8_t* requested_begin) { capacity = RoundUp(capacity, kRegionSize);//按1MB大小向上对齐  std::string error_msg; //创建一个MemMap对象  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map(MemMap::MapAnonymous(name.c_str(), requested_begin, capacity, ...)); ...... //创建RegionSpace对象  return new RegionSpace(name, mem_map.release()); } RegionSpace::RegionSpace(const std::string\u0026amp; name, MemMap* mem_map) : ContinuousMemMapAllocSpace(name, mem_map, mem_map-\u0026gt;Begin(), mem_map-\u0026gt;End(), mem_map-\u0026gt;End(),kGcRetentionPolicyAlwaysCollect), region_lock_(\u0026#34;Region lock\u0026#34;, kRegionSpaceRegionLock), time_(1U) { size_t mem_map_size = mem_map-\u0026gt;Size(); //计算有多少个Region,main  num_regions_ = mem_map_size / kRegionSize;//1MB  num_non_free_regions_ = 0U;//该成员变量表示已经占有的内存块个数  //创建Region数组  regions_.reset(new Region[num_regions_]); uint8_t* region_addr = mem_map-\u0026gt;Begin(); //初始化regions_数组的成员  for (size_t i = 0; i \u0026lt; num_regions_; ++i, region_addr += kRegionSize) { //构造Region对象。region_addr表示该区域的起始地址，region_addr+kRegionSize  //为该内存区域的尾部地址  regions_[i] = Region(i, region_addr, region_addr + kRegionSize); } //full_region_表示一个内存资源不足的内存块，其用法见下文代码分析  full_region_ = Region(); //current_region_指向当前正在用的内存块,main  current_region_ = \u0026amp;full_region_; //evac_region_成员变量的含义需要配合内存回收相关知识才能理解，我们后文碰到时再介绍  evac_region_ = nullptr; } Alloc inline mirror::Object* RegionSpace::Alloc(Thread*, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //按8字节向上对齐  num_bytes = RoundUp(num_bytes, kAlignment); return AllocNonvirtual\u0026lt;false\u0026gt;(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } template\u0026lt;bool kForEvac\u0026gt; inline mirror::Object* RegionSpace::AllocNonvirtual(size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //AllocNonvirtual函数有一个模板参数kForEvac。该参数和内存回收有关。我们先不讨论它。  //Alloc调用AllocNonvirtual时，kForEvac取值为false  mirror::Object* obj; //如果所需内存小于kRegionSize，则从当前的region对象中分配  if (LIKELY(num_bytes \u0026lt;= kRegionSize)) { if (!kForEvac) { //调用Region的Alloc函数。由RegionSpace的Create函数可知，current_region_  //最初是指向full_region_的。所以，下面的Alloc肯定返回nullptr  obj = current_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  } else {//如果kForEvac为true，则从evac_region_指向的Region中分配  obj = evac_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } //如果obj创建成功，则返回它  if (LIKELY(obj != nullptr)) { return obj; } //如果执行到这，表明上面的内存分配失败。注意，上面的代码中并未使用锁同步。现在，  //我们需要重新尝试分配（因为有可能别的线程设置了current_region_，使得它指向  //一个新的内存块，而这个内存块里说不定就有空闲的内存资源）  MutexLock mu(Thread::Current(), region_lock_); //具体的内存分配代码和上面完全一样  if (!kForEvac) { obj = current_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  } else { obj = evac_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } if (LIKELY(obj != nullptr)) { return obj; } //如果此时内存还分配失败（说明其他线程没有更新current_region_），则我们需要自己  //来遍历regions_数组以找到一个空闲的内存块,main  if (!kForEvac) { /*RegionSpace的用法和Copying垃圾回收方法有关，该方法要求预留一半的内存作为 fromspace。所以，在下面的if条件中，如果已经被占用的内存块个数超过总内存块个数的 一半，则不再允许内存分配。*/ if ((num_non_free_regions_ + 1) * 2 \u0026gt;num_regions_) { return nullptr;} //遍历内存块，找到一个空闲的内存块  for (size_t i = 0; i \u0026lt;num_regions_; ++i) { Region* r = \u0026amp;regions_[i];//main  //Region IsFree返回region state_成员变量的值。regions_数组中各个Region  //对象的state_初值为kRegionStateFree，表示内存块还未分配过内存  if (r-\u0026gt;IsFree()) { //Region Unfree设置state_的值为kRegionStateAllocated，同时设置  //type_为kRegionTypeToSpace  r-\u0026gt;Unfree(time_); r-\u0026gt;SetNewlyAllocated(); ++num_non_free_regions_; obj = r-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  current_region_ = r;//更新current_region_  return obj; } } } else { //kForEvac为true的处理 ...... } AllocNewTlab bool RegionSpace::AllocNewTlab(Thread* self) { MutexLock mu(self, region_lock_); RevokeThreadLocalBuffersLocked(self); //同Alloc函数里的注释一样，我们要预留一半的空间  if ((num_non_free_regions_ + 1) * 2 \u0026gt; num_regions_) { return false; } //找到一个空闲的Region对象  for (size_t i = 0; i \u0026lt; num_regions_; ++i) { Region* r = \u0026amp;regions_[i]; if (r-\u0026gt;IsFree()) { r-\u0026gt;Unfree(time_); ++num_non_free_regions_; r-\u0026gt;SetTop(r-\u0026gt;End()); //将这个Region和对应的线程关联起来,main  r-\u0026gt;is_a_tlab_ = true; r-\u0026gt;thread_ = self; //对线程而言，它只需要关注TLAB是否存在。如果存在的话，这块内存有多大。线程并不关心  //内存是由哪个Space以何种方式提供。  self-\u0026gt;SetTlab(r-\u0026gt;Begin(), r-\u0026gt;End()); return true; } } return false; } Free(Thread*, mirror::Object*) size_t Free(Thread*, mirror::Object*) OVERRIDE { UNIMPLEMENTED(FATAL);//不能释放单个对象所分配的内存  return 0; } Clear void RegionSpace::Clear() { MutexLock mu(Thread::Current(), region_lock_); //遍历regions_数组  for (size_t i = 0; i \u0026lt; num_regions_; ++i) { Region* r = \u0026amp;regions_[i]; if (!r-\u0026gt;IsFree()) { --num_non_free_regions_; } r-\u0026gt;Clear();//调用Region Clear  } current_region_ = \u0026amp;full_region_; evac_region_ = \u0026amp;full_region_; } Walk(ObjectCallback* callback, void* arg) void Walk(ObjectCallback* callback, void* arg) { WalkInternal\u0026lt;false\u0026gt;(callback, arg); } RegionSpace::Region class Region { public: Region() //idx_为内存块在RegionSpace regions_数组中的索引  : idx_(static_cast\u0026lt;size_t\u0026gt;(-1)), //begin_和end_代表内存资源的起始位置，top_为内存分配的水位线  begin_(nullptr), top_(nullptr), end_(nullptr), state_(RegionState::kRegionStateAllocated), type_(RegionType::kRegionTypeToSpace), //objects_allocated_表示创建了多少个Object对象，  objects_allocated_(0), ...... //is_a_tlab_表示该内存块是否被用作TLAB，thread_表示用它作TLAB的线程  is_a_tlab_(false), thread_(nullptr) { //RegionSpace构造函数中，full_region_成员变量通过这个构造函数来创建  } //RegionSpace构造函数中，regions_数组中的Region元素通过下面这个构造函数来创建  Region(size_t idx, uint8_t* begin, uint8_t* end) : idx_(idx), begin_(begin), top_(begin), end_(end), state_(RegionState::kRegionStateFree), type_(RegionType::kRegionTypeNone), ...... {} } Alloc inline mirror::Object* RegionSpace::Region::Alloc(size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //atomic_top指向当前内存分配的位置  Atomic\u0026lt;uint8_t*\u0026gt;* atomic_top = reinterpret_cast\u0026lt;Atomic\u0026lt;uint8_t*\u0026gt;*\u0026gt;(\u0026amp;top_); uint8_t* old_top; uint8_t* new_top; //更新分配后的内存位置  do { old_top = atomic_top-\u0026gt;LoadRelaxed(); new_top = old_top + num_bytes; if (UNLIKELY(new_top \u0026gt; end_)) { return nullptr; } } while (!atomic_top-\u0026gt;CompareExchangeWeakSequentiallyConsistent( old_top, new_top)); reinterpret_cast\u0026lt;Atomic\u0026lt;uint64_t\u0026gt;*\u0026gt;(\u0026amp;objects_allocated_)-\u0026gt; FetchAndAddSequentiallyConsistent(1); *bytes_allocated = num_bytes; if (usable_size != nullptr) { *usable_size = num_bytes; } *bytes_tl_bulk_allocated = num_bytes; return reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(old_top); } Clear void Clear() { top_ = begin_; state_ = RegionState::kRegionStateFree; type_ = RegionType::kRegionTypeNone; objects_allocated_ = 0; alloc_time_ = 0; live_bytes_ = static_cast\u0026lt;size_t\u0026gt;(-1); if (!kMadviseZeroes) {memset(begin_, 0, end_ - begin_);} madvise(begin_, end_ - begin_, MADV_DONTNEED); is_newly_allocated_ = false; is_a_tlab_ = false; thread_ = nullptr; } MallocSpace MallocSpace::MallocSpace(const std::string\u0026amp; name, MemMap* mem_map, ....., bool create_bitmaps,.....) : ContinuousMemMapAllocSpace(name, mem_map,.... kGcRetentionPolicyAlwaysCollect), ...... { //DlMallocSpace和RosAllocSpace创建时均设置create_bitmaps为true  if (create_bitmaps) { //bitmap_index_是一个全局静态变量，用于给位图对象命名  size_t bitmap_index = bitmap_index_++; ...... /*创建live_bitmap_和mark_bitmap_。我们不关心它们的命名。这两个位图对象覆盖的内存 范围从MemMap Begin开始，大小是MemMap Size（NonGrowthLimitCapacity函数内部 调用MemMap Size）。简单点说，live_bitmap_和mark_bitmap_位图对象所包含的位图数 组恰好覆盖了这个MallocSpace所关联的MemMap内存空间。*/ live_bitmap_.reset(accounting::ContinuousSpaceBitmap::Create(...,Begin(),NonGrowthLimitCapacity())); mark_bitmap_.reset(accounting::ContinuousSpaceBitmap::Create(..., Begin(), NonGrowthLimitCapacity())); heap.cc\nHeap::CreateMallocSpaceFromMemMap space::MallocSpace* Heap::CreateMallocSpaceFromMemMap(MemMap* mem_map, size_t initial_size, size_t growth_limit, size_t capacity, const char* name, bool can_move_objects) { /*注意参数，mem_map代表一块内存空间，内存的分配和释放均是在它上面发生的。 initial_size为内存空间初始分配大小。 growth_limit为最大的内存可分配位置，而capacity则为实际内存空间的容量。 growth_limit可以动态调整，但是不能超过capacity。 can_move_objects参数的含义和一种垃圾回收的算法有关。我们以后碰到相关代码时再 来介绍它。 */ space::MallocSpace* malloc_space = nullptr; if (kUseRosAlloc) {//编译常量，默认为true，即ART优先使用rosalloc  //kDefaultStartingSize为编译常量，大小为4K。下面将创建RosAllocSpace对象  //low_memory_mode_表示是否为低内存模式。只有RosAllocSpace支持该模式  malloc_space = space::RosAllocSpace::CreateFromMemMap( mem_map, name, kDefaultStartingSize, initial_size, growth_limit,apacity,low_memory_mode_,can_move_objects); } else { //使用DlMallocSpace。它不支持low memory模式  malloc_space = space::DlMallocSpace::CreateFromMemMap(mem_map, name, kDefaultStartingSize,initial_size, growth_limit, capacity, can_move_objects); } //kUseRememberedSet值为true，下面这段if代码的相关知识留待13.8节介绍  if (collector::SemiSpace::kUseRememberedSet\u0026amp;\u0026amp; non_moving_space_ != main_space_) { //创建一个RememberedSet对象。详情见13.8节的内容  accounting::RememberedSet* rem_set = new accounting::RememberedSet(std::string(name) + \u0026#34; remembered set\u0026#34;, this, malloc_space); AddRememberedSet(rem_set); } malloc_space-\u0026gt;SetFootprintLimit(malloc_space-\u0026gt;Capacity()); return malloc_space; } dlmalloc_space.cc\nDlMallocSpace Create DlMallocSpace* DlMallocSpace::Create(const std::string\u0026amp; name, size_t initial_size, size_t growth_limit, size_t capacity, uint8_t* requested_begin, bool can_move_objects) { uint64_t start_time = 0; size_t starting_size = kPageSize; //先创建内存资源  MemMap* mem_map = CreateMemMap(name, starting_size, \u0026amp;initial_size, \u0026amp;growth_limit, \u0026amp;capacity, requested_begin); //再创建DlMallocSpace对象。CreateFromMemMap的代码见下文  DlMallocSpace* space = CreateFromMemMap(......); return space; } CreateFromMemMap DlMallocSpace* DlMallocSpace::CreateFromMemMap(MemMap* mem_map, const std::string\u0026amp; name, size_t starting_size, size_t initial_size, size_t growth_limit, size_t capacity, bool can_move_objects) { //内部调用dlmalloc的接口，starting_size为初始大小，initial_size为dlmalloc的  //limit水位线。CreateMspace返回的mspace为dlmalloc内部使用的结构，外界用void*  //作为它的数据类型,main  void* mspace = CreateMspace(mem_map-\u0026gt;Begin(), starting_size, initial_size); .... uint8_t* end = mem_map-\u0026gt;Begin() + starting_size; //调用mprotect保护从starting_size水位线到capacity这段内存，后续将根据需要进行调整  if (capacity - starting_size \u0026gt; 0) { CHECK_MEMORY_CALL(mprotect, (end, capacity - starting_size, PROT_NONE),name); } uint8_t* begin = mem_map-\u0026gt;Begin(); if (Runtime::Current()-\u0026gt;IsRunningOnMemoryTool()) { ...... } else {//构造DlMallocSpace对象，它的参数比较多。将mspace传给DlMallocSPace,main  return new DlMallocSpace(mem_map, initial_size, name, mspace, begin, end, begin + capacity,growth_limit, can_move_objects, starting_size); } } void* DlMallocSpace::CreateMspace(void* begin, size_t morecore_start, size_t initial_size) { errno = 0; //create_mspace_with_base和mspace_set_footprint_limit均是dlmalloc的API  void* msp = create_mspace_with_base(begin, morecore_start, false); if (msp != nullptr) { mspace_set_footprint_limit(msp, initial_size); } ...... return msp; } rosalloc_space.cc\nRosAllocSpace Create RosAllocSpace* RosAllocSpace::Create(const std::string\u0026amp; name, size_t initial_size, size_t growth_limit, size_t capacity, uint8_t* requested_begin, bool low_memory_mode, bool can_move_objects) { uint64_t start_time = 0; //kDefaultStartingSize取值为一个内存页的大小，对x86 32位平台而言，其值为4KB  size_t starting_size = Heap::kDefaultStartingSize; //先创建一个MemMap对象  MemMap* mem_map = CreateMemMap(name, starting_size, \u0026amp;initial_size, \u0026amp;growth_limit, \u0026amp;capacity, requested_begin); //再创建RosAllocSpace对象  RosAllocSpace* space = CreateFromMemMap(......); return space; } CreateFromMemMap RosAllocSpace* RosAllocSpace::CreateFromMemMap(MemMap* mem_map, const std::string\u0026amp; name, size_t starting_size, size_t initial_size,size_t growth_limit, size_t capacity, bool low_memory_mode, bool can_move_objects) { bool running_on_memory_tool = Runtime::Current()-\u0026gt;IsRunningOnMemoryTool(); //CreateRosAlloc将创建rosallc对象,main  allocator::RosAlloc* rosalloc = CreateRosAlloc( mem_map-\u0026gt;Begin(), starting_size, initial_size, capacity, low_memory_mode, running_on_memory_tool); uint8_t* end = mem_map-\u0026gt;Begin() + starting_size; uint8_t* begin = mem_map-\u0026gt;Begin(); if (running_on_memory_tool) { ...... } else {//构造一个RosAllocSpace对象。RosAllocSpace构造函数和  //DlMallocSpace构造函数类似，都很简单，笔者不拟介绍它。  return new RosAllocSpace(mem_map, initial_size, name, rosalloc,...); } } allocator::RosAlloc* RosAllocSpace::CreateRosAlloc(void* begin, size_t morecore_start,size_t initial_size, size_t maximum_size, bool low_memory_mode,....) { errno = 0; //new一个RosAlloc对象，它就是rosalloc模块。低内存模式将影响rosalloc内存释放的算法  allocator::RosAlloc* rosalloc = new art::gc::allocator::RosAlloc( begin, morecore_start, maximum_size, low_memory_mode ? art::gc::allocator::RosAlloc::kPageReleaseModeAll : art::gc::allocator::RosAlloc::kPageReleaseModeSizeAndEnd, running_on_memory_tool); if (rosalloc != nullptr) { rosalloc-\u0026gt;SetFootprintLimit(initial_size); } ...... return rosalloc; } RosAlloc::RosAlloc(void* base, size_t capacity, size_t max_capacity, PageReleaseMode page_release_mode, bool running_on_memory_tool, size_t page_release_size_threshold) : base_(reinterpret_cast\u0026lt;uint8_t*\u0026gt;(base)), footprint_(capacity), capacity_(capacity), max_capacity_(max_capacity), ...... { .... /*图13-4、图13-5中的bracketSizes、headSizes和numOfPages等数组均为RosAlloc态 的静成员变量。下面的Initialize函数将初始化它们。初始化的结果已经绘制在图13-4、 图13-5中了。感兴趣的读者可自行研究该函数的代码。*/ if (!initialized_) { Initialize(); } //创建同步锁，一共42个。当从不同粒度的内存资源池中分配内存时将使用不同的同步锁  //对象进行保护。这样处理的好处是可提高内存分配的并发效率  for (size_t i = 0; i \u0026lt;kNumOfSizeBrackets; i++) { size_bracket_lock_names_[i] = StringPrintf(\u0026#34;an rosalloc size bracket %d lock\u0026#34;, static_cast\u0026lt;int\u0026gt;(i)); size_bracket_locks_[i] = new Mutex( size_bracket_lock_names_[i].c_str(), kRosAllocBracketLock); /*current_runs_为Run*定长数组，元素个数为42。下面的代码将设置数组的内容都指向 dedicated_full_run_。dedicated_full_run_是RosAlloc的静态成员变量，类型为 Run*。它代表一块没有内存可供分配的资源池。一般而言，可以将current_runs_各个元素 设置为nullptr。但使用current_runs_的地方就需要判断其元素是否为nullptr。所以， 此处的做法是将current_runs_各成员指向这个无法分配资源的Run对象。这样就可以消除 空指针的判断。而代码处理dedicated_full_run_时就和处理其他那些正常的资源分配殆尽的 Run对象一样即可，后续我们将看到相关的代码。*/ current_runs_[i] = dedicated_full_run_; } size_t num_of_pages = footprint_ / kPageSize; size_t max_num_of_pages = max_capacity_ / kPageSize; std::string error_msg; //创建page_map_mem_map_ MemMap对象，参考图13-6  page_map_mem_map_.reset(MemMap::MapAnonymous(\u0026#34;rosalloc page map\u0026#34;, nullptr, RoundUp(max_num_of_pages, kPageSize),.....)); //page_map_mem_map_基地址是page_map_  page_map_ = page_map_mem_map_-\u0026gt;Begin(); page_map_size_ = num_of_pages;//该RosAlloc所管理的内存页有多大，参考图13-6  max_page_map_size_ = max_num_of_pages;//内存最大有多少个内存页  //free_page_run_size_map_为vector数组，类型为size_t。其作用我们下文再介绍  free_page_run_size_map_.resize(num_of_pages); //将base_强转成一个FreePageRun对象，可参考图13-6  FreePageRun* free_pages = reinterpret_cast\u0026lt;FreePageRun*\u0026gt;(base_); //设置本free_pages对象的大小并释放相关内存页。最开始时base_所对应的内存块全部  //都是空闲的，所以第一个free_pages的大小为capacity_  free_pages-\u0026gt;SetByteSize(this, capacity_);//main  free_pages-\u0026gt;ReleasePages(this);//释放本free_pages所包含的内存,main  //free_page_runs_为set\u0026lt;FreePageRun*\u0026gt;容器  free_page_runs_.insert(free_pages); } RosAlloc::FreePageRun::SetByteSize\nvoid SetByteSize(RosAlloc* rosalloc, size_t byte_size) { /*下面两行代码的含义如下： 先得到本FreePageRun的基地址fpr_base。根据上面RosAlloc的构造函数可知，FreePageRun 对象是将base_内存块上的地址强制转换数据类型得到的。 ToPageMapIndex函数用于返回fpr_base在page_map_中的索引号。参考图13-6可知，page_map_ 一个元素代表base_中一个内存页。所以，ToPageMapIndex的实现就很容易想到了，即用fpr_base- base_，然后除以内存页大小即可算出该FreePageRun对象对应哪个内存页 */ uint8_t* fpr_base = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(this); size_t pm_idx = rosalloc-\u0026gt;ToPageMapIndex(fpr_base); //free_page_run_size_map_是一个数组，下面将设置对应索引的元素的值，  //用于表示对应FreePageRun对象所管理的内存空间大小  rosalloc-\u0026gt;free_page_run_size_map_[pm_idx] = byte_size; } RosAlloc::FreePageRun::ReleasePages\nvoid ReleasePages(RosAlloc* rosalloc) { uint8_t* start = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(this); //ByteSize函数是上文SetByteSize函数的对应，用于返回free_page_run_size_map_  //对应元素的值。在RosAlloc构造函数调用流程中，byte_size返回为capacity_  size_t byte_size = ByteSize(rosalloc); //ShouldReleasePages判断是否需要释放内存页。我们下文再介绍它  if (ShouldReleasePages(rosalloc)) { //直接看下面这个函数。start表示本FreePageRun对象在base_内存块中的起始位置  rosalloc-\u0026gt;ReleasePageRange(start, start + byte_size);//main  } } RosAlloc::ReleasePageRange\nsize_t RosAlloc::ReleasePageRange(uint8_t* start, uint8_t* end) { //start和end参数用于指明要释放的内存的起始和终点位置  //清零这段内存  if (!kMadviseZeroes) { memset(start, 0, end - start);} CHECK_EQ(madvise(start, end - start, MADV_DONTNEED), 0); //调用者只是指明了内存段的起始和终点位置，我们需要将这个位置转换为RosAlloc内部的  //内存页位置  size_t pm_idx = ToPageMapIndex(start);//返回start位置对应的内存页索引号  size_t reclaimed_bytes = 0; //返回end位置对应的内存页索引号  const size_t max_idx = pm_idx + (end - start) / kPageSize; for (; pm_idx \u0026lt; max_idx; ++pm_idx) { /*图13-6中曾说过，page_map_保存base_中各内存页的状态，kPageMapEmpty即为其中的 一种状态。内存页的初始状态为kPageMapReleased，表示内存在系统中还未分配。 kPageMapEmpty表示内存可以被回收。 */ if (page_map_[pm_idx] == kPageMapEmpty) { reclaimed_bytes += kPageSize;//reclaimed_bytes表示此次回收的内存大小  page_map_[pm_idx] = kPageMapReleased;//设置对应内存页的状态  } } return reclaimed_bytes; } AllocCommon inline mirror::Object* RosAllocSpace::AllocCommon(Thread* self, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { size_t rosalloc_bytes_allocated = 0; size_t rosalloc_usable_size = 0; size_t rosalloc_bytes_tl_bulk_allocated = 0; ...... //调用RosAlloc的Alloc函数分配内存。我们下文会详细介绍rosalloc内存分配算法  mirror::Object* result = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;( rosalloc_-\u0026gt;Alloc\u0026lt;kThreadSafe\u0026gt;(self, num_bytes, \u0026amp;rosalloc_bytes_allocated, \u0026amp;rosalloc_usable_size, \u0026amp;rosalloc_bytes_tl_bulk_allocated)); ...... return result; } rosalloc.h\nRosAlloc::Alloc template\u0026lt;bool kThreadSafe\u0026gt; inline ALWAYS_INLINE void* RosAlloc::Alloc(Thread* self, size_t size, size_t* bytes_allocated,size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //Alloc是一个模板函数，包含模板参数kThreadSafe，默认值为true。ART虚拟机中  //绝大部分情况下该模板参数都使用这个默认的true。我们重点介绍它的处理情况  //kLargeSizeThreshold为2KB。如果所需的内存超过2KB，则使用AllocLargeObject  //来处理。AllocLargeObject将留给读者自行阅读  if (UNLIKELY(size \u0026gt;kLargeSizeThreshold)) { return AllocLargeObject(self, size, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } void* m; //我们将着重介绍kThreadSafe为true的情况  if (kThreadSafe) { m = AllocFromRun(self, size, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  } else { .....//kThreadSafe为false的情况，读者在学完本节的基础上可自行研究它  } return m; } RosAlloc::AllocFromRun RosAlloc原理图 //RosAllocSpace //kNumOfSizeBrackets值为42,描述每种slot所支持的内存分配粒度  static size_t bracketSizes[kNumOfSizeBrackets]; //numOfPages则记录了每种slot对应的内存资源有多少（以4KB字节为单位）  static size_t numOfPages[kNumOfSizeBrackets]; 一个Run对应一种粒度(一行)\nRosAllc::AllocFromRun流程图 graph TB SizeToIndex(\u0026quot;size_t idx = SizeToIndexAndBracketSize(size, \u0026amp;bracket_size)\u0026quot;)--\u0026gt;indexBelow16{\u0026quot;idx \u0026lt; 16?\u0026quot;} indexBelow16--\u0026gt;|yes|getRosAllocRun(\u0026quot;Run* thread_local_run = self-\u0026gt;GetRosAllocRun(idx)\u0026quot;) getRosAllocRun--\u0026gt;AllocSlot(\u0026quot;slot_addr = thread_local_run-\u0026gt;AllocSlot();\u0026quot;) AllocSlot--\u0026gt;slotAddrIsNull{\u0026quot;slot_addr == nullptr?\u0026quot;} slotAddrIsNull--\u0026gt;|yes|RefillRun(\u0026quot;thread_local_run = RefillRun(self, idx);\u0026quot;) RefillRun--\u0026gt;AllocSlot2(\u0026quot;slot_addr = thread_local_run-\u0026gt;AllocSlot();\u0026quot;) indexBelow16--\u0026gt;|no|AllocFromCurrentRunUnlocked(\u0026quot;slot_addr = AllocFromCurrentRunUnlocked(self, idx);\u0026quot;) void* RosAlloc::AllocFromRun(Thread* self, size_t size, size_t* bytes_allocated,size_t* usable_size, size_t* bytes_tl_bulk_allocated) { size_t bracket_size; /*SizeToIndexAndBracketSize将根据调用者所期望分配的内存大小来决定使用哪种粒度的资源池 （idx表示索引号）以及这种资源池中slot的大小（由bracket_size决定）。*/ size_t idx = SizeToIndexAndBracketSize(size, \u0026amp;bracket_size);//main  void* slot_addr; //kNumThreadLocalSizeBrackets取值为16。由图13-4可知，idx小于16的话，对应的内  //存分配粒度最大不超过128字节。所以，下面if条件满足的话，说明所要分配的内存大小小于  //128字节  if (LIKELY(idx\u0026lt;kNumThreadLocalSizeBrackets)) { /*如果所需内存不超过128字节，我们会尝试从线程本地内存资源池中分配内存。注意，线程本地存储 内存池并不是前文提到的TLAB。但它和TLAB含义类似。只不过Thread类对rosalloc有单独的支持。下面的Thread GetRosAllocRun函数将返回tlsPtr_.rosalloc_runs数组对应索引的元 素。读者回顾7.5.2.1节可知，tlsPtr_有一个rosalloc_runs数组，包含16个元素，它们初始 化都指向RosAlloc的dedicated_full_run_对象。 这段if代码块表示当我们所需要的内存小于128字节时，RosAlloc将尝试从调用线程所拥有的本地 资源池中分配内存，这样就不需要同步锁的保护了，如此可提高内存分配的速度。 注意，由于初始值都指向dedicated_full_run_，下面的代码执行时将无须判断thread_local_ run是否为nullptr。*/ Run* thread_local_run = reinterpret_cast\u0026lt;Run*\u0026gt;(self-\u0026gt;GetRosAllocRun(idx)); //tlsPtr_ rosallc_runs默认取值也是dedicated_full_run_，在这个Run对象中没有可分配内  //的内存资源。所以，首次调用下面的AllocSlot必然返回nullptr，表明当前这个Run中没有空闲存了  slot_addr = thread_local_run-\u0026gt;AllocSlot(); if (UNLIKELY(slot_addr == nullptr)) { /*如果slot_addr为空指针，说明thread_local_run这个Run中没有空余内存。 下面我们就需要解决这个问题。此时就需要同步锁的保护了。但我们只需要使用目标索引的同步 锁就行了。比如，分配8字节内存不够用时，我们就用保护8字节资源的同步锁。如此，它就不会 和保护其他内存资源的同步锁竞争，从而可提高内存分配速度。*/ MutexLock mu(self, *size_bracket_locks_[idx]); bool is_all_free_after_merge; /*参考图13-5，Run中有thread_local_free_list_和free_list_两个用于管理空闲slot 的SlotFreeList对象。MergeThreadLocalFreeListToFreeList函数将thread_local_ free_list_里的空闲资源合并到free_list_。 对于dedicate_full_run_来说，合并它们后，空闲资源并不会增加，所以该函数返回false。 请读者阅读掌握本章内容后再自行研究下面这个函数。*/ if (thread_local_run-\u0026gt;MergeThreadLocalFreeListToFreeList( \u0026amp;is_all_free_after_merge)) {...... } else {//MergeThreadLocalFreeListToFreeList返回false的情况  ...... //RefillRun是重点，它将给idx所对应的Run对象添加内存资源，所以叫Refill  thread_local_run = RefillRun(self, idx);//main  ..... //将thread_local_run设置为调用线程的线程本地内存资源池  thread_local_run-\u0026gt;SetIsThreadLocal(true); self-\u0026gt;SetRosAllocRun(idx, thread_local_run); } //bytes_tl_bulk_allocated表示本资源池中剩余的内存  *bytes_tl_bulk_allocated = thread_local_run-\u0026gt;NumberOfFreeSlots() * bracket_size; //重新分配资源。AllocSlot非常简单，就是从free_list_中返回一个Slot对象。  slot_addr = thread_local_run-\u0026gt;AllocSlot();//main  } else {//slot_addr不为nullptr的处理  *bytes_tl_bulk_allocated = 0; } *bytes_allocated = bracket_size; *usable_size = bracket_size; } else { /*当所需内存超过128字节时，将从RosAlloc内部的资源池中分配。这个时候也需要 同步锁来保护了。当然，如上面代码一样，不同大小的资源池会使用不同的同步锁来保护。 AllocFromCurrentRunUnlocked将从RosAlloc的current_runs_[idx]中进行分配。 如果current_runs_[idx]对应的资源池内存资源不足，将会调用RefillRun给对应的资源池重新加满内存资源。*/ MutexLock mu(self, *size_bracket_locks_[idx]); slot_addr = AllocFromCurrentRunUnlocked(self, idx);//main  if (LIKELY(slot_addr != nullptr)) { *bytes_allocated = bracket_size; *usable_size = bracket_size; *bytes_tl_bulk_allocated = bracket_size; } } return slot_addr; } RosAlloc::RefillRun RosAlloc::Run* RosAlloc::RefillRun(Thread* self, size_t idx) { ......//这里还有一段处理，读者以后可自行研究这段代码  return AllocRun(self, idx);//我们看这个函数 } RosAlloc::Run* RosAlloc::AllocRun(Thread* self, size_t idx) { RosAlloc::Run* new_run = nullptr; { MutexLock mu(self, lock_); /*AllocPages函数将从base_所在的内存中分配一段内存空间。这内存空间对外由一个Run 对象来管理。该空间的大小（以4KB为单位）由numOfPages[idx]决定。kPageMapRun 是内存页状态中的一种。 */ new_run = reinterpret_cast\u0026lt;Run*\u0026gt;(AllocPages(self, numOfPages[idx], kPageMapRun));//main  } if (LIKELY(new_run != nullptr)) { new_run-\u0026gt;size_bracket_idx_ = idx; .....//清理这块内存资源池  //初始化Run对象中的free_list_成员。  new_run-\u0026gt;InitFreeList(); } return new_run; } RosAlloc::AllocPages void* RosAlloc::AllocPages(Thread* self, size_t num_pages, uint8_t page_map_type) { //AllocPages是以内存页为单位进行分配的  lock_.AssertHeld(self); FreePageRun* res = nullptr;//RosAlloc借助FreePageRun来管理内存分配  //req_bytes_size是以字节为单位的内存大小  const size_t req_byte_size = num_pages * kPageSize; //free_pages_runs_为Set\u0026lt;FreePageRun*\u0026gt;，第一个元素在RosAlloc构造函数中添加，  //这个元素位于base_，所包含的空闲内存大小为capacity_。  for (auto it = free_page_runs_.begin(); it != free_page_runs_.end(); ) { FreePageRun* fpr = *it; size_t fpr_byte_size = fpr-\u0026gt;ByteSize(this); //如果当前的FreePageRun对象所管理的空闲内存资源比所需内存要多，则对当前fpr对象进行拆分  if (req_byte_size \u0026lt;= fpr_byte_size) { free_page_runs_.erase(it++);//当前fpr对象从容器中移除  if (req_byte_size \u0026lt; fpr_byte_size) { //新的fpr对象为当前fpr对象的起始位置+待分配内存大小  FreePageRun* remainder = reinterpret_cast\u0026lt;FreePageRun*\u0026gt;(reinterpret_cast\u0026lt;uint8_t*\u0026gt;(fpr) + req_byte_size); //新fpr对象所管理的空闲内存资源大小等于原fpr的大小减去此次分配的内存大小  remainder-\u0026gt;SetByteSize(this, fpr_byte_size - req_byte_size); free_page_runs_.insert(remainder);//把新的fpr对象加入容器  //更新原fpr对象所管理的内存资源大小，它将作为返回值返回给调用者  fpr-\u0026gt;SetByteSize(this, req_byte_size); } res = fpr; break; } else { ++it; } } /*如果free_page_runs_中没有合适的FreePageRun对象，则考虑是否需要进行扩容。 base_所在的内存块初始设置的大小是capacity_，当前可用的大小由footprint_ base_所在的内存块初始设置的大小是capacity_，当前可用的大小由footprint_控制。如果footprint_小于capacity_，则还能继续扩容。这部分代码比较复杂，建议读者 学完本节后再自行阅读它*/ ...... if (LIKELY(res != nullptr)) { //更新内存页的状态信息。page_map_idx表示res这块新分配内存所对应的状态信息所在数组的索引  size_t page_map_idx = ToPageMapIndex(res); switch (page_map_type) { case kPageMapRun: //如上文所述，page_map_保存了base_内存页的状态信息。如果一次分配了多个内存页的话，  //第一个内存页的状态将设置为kPageMapRun，其余内存页的状态为kPageMapRunPart  page_map_[page_map_idx] = kPageMapRun; for (size_t i = 1; i \u0026lt; num_pages; i++) { page_map_[page_map_idx + i] = kPageMapRunPart; } break; ...... } return res; } InitFreeList void InitFreeList() { const uint8_t idx = size_bracket_idx_; const size_t bracket_size = bracketSizes[idx]; const size_t bracket_size = bracketSizes[idx]; /*结合图13-5可知，FirstSlot函数这个Run中第一个slot的位置。代码中，一个slot由Slot类 表示。Slot内部有一个next_成员变量，指向下一个Slot对象。所以，一个Run中的Slot对象可 构成一个链表来管理。*/ Slot* first_slot = FirstSlot(); /*LastSlot返回Run中最后一个Slot的位置。free_list_是Run的成员变量，其数据类型 为SlotFreeList\u0026lt;false\u0026gt;，它是RosAlloc实现的一个用于管理Slot的容器。下面的for 循环将把图13-5 Run中的Slot对象通过free_list_管理起来。虽然下面的代码是从末尾 Slot向前遍历，但最终结果就是free_list_ head_指向第一个Slot对象。而Run中的所有 Slot对象又通过上面提到的Slot next_成员变量构成一个链表。 */ for (Slot* slot = LastSlot(); slot \u0026gt;= first_slot; slot = slot-\u0026gt;Left(bracket_size)) { free_list_.Add(slot); } } RosAlloc::Run::AllocSlot inline void* RosAlloc::Run::AllocSlot() { /*Remove将free_list_中移除head_所指向的那个Slot单元。从这一点可以看出，Run对Slot的管 理是比较简单的。就是通过一个链表把Slot单元管理起来，每次要分配的时候取链表的头部返回给 外界。*/ Slot* slot = free_list_.Remove(); ..... return slot; } // Compute numOfSlots and slotOffsets.  for (size_t i = 0; i \u0026lt; kNumOfSizeBrackets; i++) { size_t bracket_size = bracketSizes[i]; size_t run_size = kPageSize * numOfPages[i]; size_t max_num_of_slots = run_size / bracket_size; // Search for the maximum number of slots that allows enough space  // for the header.  for (int s = max_num_of_slots; s \u0026gt;= 0; s--) { size_t tmp_slots_size = bracket_size * s; if (tmp_slots_size + tmp_header_size \u0026lt;= run_size) { // Found the right number of slots, that is, there was enough  // space for the header (including the bit maps.)  num_of_slots = s; header_size = tmp_header_size; break; } Free size_t RosAllocSpace::Free(Thread* self, mirror::Object* ptr) { .... return rosalloc_-\u0026gt;Free(self, ptr);//调用RosAlloc的Free函数释放内存 } DiscontinuousSpace class DiscontinuousSpace : public Space { protected: /*LargeObjectBitmap为类型别名，其定义如下： typedef SpaceBitmap\u0026lt;kLargeObjectAlignment\u0026gt;LargeObjectBitmap; kLargeObjectAlignment为常量，值为内存页的大小（4KB）。SpaceBitmap的详情可回顾 7.6.1.1.1节的内容。简单来说，SpaceBitmap是一个位图数组，该数组以比特位为元素： (1) 数组的每一位对应一段内存空间中一个内存单元的位置。内存单元的大小等于模板参数的值。 比如上面的kLargeObjectAlignment表示以一个内存单元大小为4KB (2) 如果位图数组某个元素取值为1，则表明对应的内存单元中有内容。如果为0，则表示对应的内存单元没有内容。比如，我们在内存单元中创建了一个对象时，就需要修改位图数组中对应比特位元素的值为1。*/ std::unique_ptr\u0026lt;accounting::LargeObjectBitmap\u0026gt;live_bitmap_; std::unique_ptr\u0026lt;accounting::LargeObjectBitmap\u0026gt;mark_bitmap_; } DiscontinuousSpace::DiscontinuousSpace(const std::string\u0026amp; name, GcRetentionPolicy gc_retention_policy) : Space(name, gc_retention_policy) { const size_t capacity = static_cast\u0026lt;size_t\u0026gt;(std::numeric_limits\u0026lt;uint32_t\u0026gt;::max()); live_bitmap_.reset(accounting::LargeObjectBitmap::Create(\u0026#34;large live objects\u0026#34;, nullptr, capacity)); mark_bitmap_.reset(accounting::LargeObjectBitmap::Create(\u0026#34;large marked objects\u0026#34;, nullptr, capacity)); } LargeObjectMapSpace LargeObjectMapSpace* LargeObjectMapSpace::Create(const std::string\u0026amp; name) { if (Runtime::Current()-\u0026gt;IsRunningOnMemoryTool()) {......} else {//构造一个LargeObjectMapSpace对象。其构造函数非常简单  return new LargeObjectMapSpace(name); } } Alloc mirror::Object* LargeObjectMapSpace::Alloc(Thread* self, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { std::string error_msg; //这就是LargeObjectMapSpace的内存分配算法，直接创建一个MemMap对象  MemMap* mem_map = MemMap::MapAnonymous(\u0026#34;large object space allocation\u0026#34;, nullptr, num_bytes, PROT_READ | PROT_WRITE, true, false, \u0026amp;error_msg); //将这块内存映射空间的基地址转换为返回值的类型  mirror::Object* const obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;( mem_map-\u0026gt;Begin()); MutexLock mu(self, lock_); /*large_objects_是LargeObjectMapSpace的成员变量，类型为 AllocationTrackingSafeMap\u0026lt;mirror::Object*, LargeObject, kAllocatorTagLOSMaps\u0026gt;。读者不要被这个看起来很复杂的数据结构吓到， AllocationTrakingSafeMap其实就是一个map，key的类型是Object*，value的类型是 LargeObject。LargeObject是LargeObjectMapSpace中的内部类，用于保存该内存映射 空间所对应的MemMap对象。 */ large_objects_.Put(obj, LargeObject {mem_map, false}); ......//其他一些处理，略过  return obj; } thread.h\nThread //虽然tlsPtr_是我们的老熟人了，但它还有一些成员变量的含义在前面的章节中没有介绍 struct PACKED(sizeof(void*)) tls_ptr_sized_values { ...... //下面这个变量表示TLAB上分配了多个对象  size_t thread_local_objects; //指明TLAB的起始位置  uint8_t* thread_local_start; /*指明TLAB当前所分配的内存位置，它位于thread_local_start和thread_local_end 之间。[thread_local_start,thead_local_pos)这部分空间属于已经分配的内存， [thead_local_pos,thread_local_end)这部分为空闲待分配的内存。*/ uint8_t* thread_local_pos; uint8_t* thread_local_end;//指明TLAB的末尾位置  ...... } tlsPtr_; SetTlab void Thread::SetTlab(uint8_t* start, uint8_t* end) { tlsPtr_.thread_local_start = start; tlsPtr_.thread_local_pos = tlsPtr_.thread_local_start; tlsPtr_.thread_local_end = end; tlsPtr_.thread_local_objects = 0; } AllocTlab inline mirror::Object* Thread::AllocTlab(size_t bytes) { ++tlsPtr_.thread_local_objects; mirror::Object* ret = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(tlsPtr_.thread_local_pos); tlsPtr_.thread_local_pos += bytes;//更新内存水位线即可  return ret; } TLAB设计思路 "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/thread/stacktraceelement/",
	"title": "StackTraceElement",
	"tags": [],
	"description": "",
	"content": "9.0.0_r3\nThrowable.getStackTrace public StackTraceElement[] getStackTrace() { return getOurStackTrace().clone(); } private synchronized StackTraceElement[] getOurStackTrace() { // Initialize stack trace field with information from // backtrace if this is the first call to this method // // Android-changed: test explicitly for equality with // STACK_TRACE_ELEMENT if (stackTrace == libcore.util.EmptyArray.STACK_TRACE_ELEMENT || (stackTrace == null \u0026amp;\u0026amp; backtrace != null) /* Out of protocol state */) { stackTrace = nativeGetStackTrace(backtrace);//main  backtrace = null; } return stackTrace; } /art/runtime/native/java_lang_Throwable.cc\nnamespace art { static jobjectArray Throwable_nativeGetStackTrace(JNIEnv* env, jclass, jobject javaStackState) { ScopedFastNativeObjectAccess soa(env); return Thread::InternalStackTraceToStackTraceElementArray(soa, javaStackState); } Thread.getStackTrace public StackTraceElement[] getStackTrace() { StackTraceElement ste[] = VMStack.getThreadStackTrace(this); return ste != null ? ste : EmptyArray.STACK_TRACE_ELEMENT; } 61 /** 62 * Retrieves the stack trace from the specified thread. 63 * 64 * @param t 65 * thread of interest 66 * @return an array of stack trace elements, or null if the thread 67 * doesn′t have a stack trace (e.g. because it exited) 68 */ 69 @FastNative 70 native public static StackTraceElement[] getThreadStackTrace(Thread t); static jobjectArray VMStack_getThreadStackTrace(JNIEnv* env, jclass, jobject javaThread) { ScopedFastNativeObjectAccess soa(env); auto fn = [](Thread* thread, const ScopedFastNativeObjectAccess\u0026amp; soaa) REQUIRES_SHARED(Locks::mutator_lock_) -\u0026gt; jobject { return thread-\u0026gt;CreateInternalStackTrace\u0026lt;false\u0026gt;(soaa); }; jobject trace = GetThreadStack(soa, javaThread, fn); if (trace == nullptr) { return nullptr; } return Thread::InternalStackTraceToStackTraceElementArray(soa, trace); } /art/runtime/thread.cc\nThread::InternalStackTraceToStackTraceElementArray jobjectArray Thread::InternalStackTraceToStackTraceElementArray( const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject internal, jobjectArray output_array, int* stack_depth) { // Decode the internal stack trace into the depth, method trace and PC trace.  // Subtract one for the methods and PC trace.  int32_t depth = soa.Decode\u0026lt;mirror::Array\u0026gt;(internal)-\u0026gt;GetLength() - 1; ClassLinker* const class_linker = Runtime::Current()-\u0026gt;GetClassLinker(); jobjectArray result; if (output_array != nullptr) { // Reuse the array we were given.  result = output_array; // ...adjusting the number of frames we\u0026#39;ll write to not exceed the array length.  const int32_t traces_length = soa.Decode\u0026lt;mirror::ObjectArray\u0026lt;mirror::StackTraceElement\u0026gt;\u0026gt;(result)-\u0026gt;GetLength(); depth = std::min(depth, traces_length); } else { // Create java_trace array and place in local reference table  mirror::ObjectArray\u0026lt;mirror::StackTraceElement\u0026gt;* java_traces = class_linker-\u0026gt;AllocStackTraceElementArray(soa.Self(), depth); if (java_traces == nullptr) { return nullptr; } result = soa.AddLocalReference\u0026lt;jobjectArray\u0026gt;(java_traces); } if (stack_depth != nullptr) { *stack_depth = depth; } for (int32_t i = 0; i \u0026lt; depth; ++i) { ObjPtr\u0026lt;mirror::ObjectArray\u0026lt;mirror::Object\u0026gt;\u0026gt; decoded_traces = soa.Decode\u0026lt;mirror::Object\u0026gt;(internal)-\u0026gt;AsObjectArray\u0026lt;mirror::Object\u0026gt;(); // Methods and dex PC trace is element 0.  DCHECK(decoded_traces-\u0026gt;Get(0)-\u0026gt;IsIntArray() || decoded_traces-\u0026gt;Get(0)-\u0026gt;IsLongArray()); ObjPtr\u0026lt;mirror::PointerArray\u0026gt; const method_trace = ObjPtr\u0026lt;mirror::PointerArray\u0026gt;::DownCast(MakeObjPtr(decoded_traces-\u0026gt;Get(0))); // Prepare parameters for StackTraceElement(String cls, String method, String file, int line)  ArtMethod* method = method_trace-\u0026gt;GetElementPtrSize\u0026lt;ArtMethod*\u0026gt;(i, kRuntimePointerSize); uint32_t dex_pc = method_trace-\u0026gt;GetElementPtrSize\u0026lt;uint32_t\u0026gt;( i + method_trace-\u0026gt;GetLength() / 2, kRuntimePointerSize); //main  ObjPtr\u0026lt;mirror::StackTraceElement\u0026gt; obj = CreateStackTraceElement(soa, method, dex_pc); if (obj == nullptr) { return nullptr; } // We are called from native: use non-transactional mode.  soa.Decode\u0026lt;mirror::ObjectArray\u0026lt;mirror::StackTraceElement\u0026gt;\u0026gt;(result)-\u0026gt;Set\u0026lt;false\u0026gt;(i, obj); } return result; } static ObjPtr\u0026lt;mirror::StackTraceElement\u0026gt; CreateStackTraceElement( const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, ArtMethod* method, uint32_t dex_pc) REQUIRES_SHARED(Locks::mutator_lock_) { int32_t line_number; StackHandleScope\u0026lt;3\u0026gt; hs(soa.Self()); auto class_name_object(hs.NewHandle\u0026lt;mirror::String\u0026gt;(nullptr)); auto source_name_object(hs.NewHandle\u0026lt;mirror::String\u0026gt;(nullptr)); if (method-\u0026gt;IsProxyMethod()) { line_number = -1; class_name_object.Assign(method-\u0026gt;GetDeclaringClass()-\u0026gt;GetName()); // source_name_object intentionally left null for proxy methods  } else { line_number = method-\u0026gt;GetLineNumFromDexPC(dex_pc); // Allocate element, potentially triggering GC  // TODO: reuse class_name_object via Class::name_?  const char* descriptor = method-\u0026gt;GetDeclaringClassDescriptor(); CHECK(descriptor != nullptr); std::string class_name(PrettyDescriptor(descriptor)); class_name_object.Assign( mirror::String::AllocFromModifiedUtf8(soa.Self(), class_name.c_str())); if (class_name_object == nullptr) { soa.Self()-\u0026gt;AssertPendingOOMException(); return nullptr; } const char* source_file = method-\u0026gt;GetDeclaringClassSourceFile(); if (line_number == -1) { // Make the line_number field of StackTraceElement hold the dex pc.  // source_name_object is intentionally left null if we failed to map the dex pc to  // a line number (most probably because there is no debug info). See b/30183883.  line_number = dex_pc; } else { if (source_file != nullptr) { source_name_object.Assign(mirror::String::AllocFromModifiedUtf8(soa.Self(), source_file)); if (source_name_object == nullptr) { soa.Self()-\u0026gt;AssertPendingOOMException(); return nullptr; } } } } const char* method_name = method-\u0026gt;GetInterfaceMethodIfProxy(kRuntimePointerSize)-\u0026gt;GetName(); CHECK(method_name != nullptr); Handle\u0026lt;mirror::String\u0026gt; method_name_object( hs.NewHandle(mirror::String::AllocFromModifiedUtf8(soa.Self(), method_name))); if (method_name_object == nullptr) { return nullptr; } return mirror::StackTraceElement::Alloc(soa.Self(), class_name_object, method_name_object, source_name_object, line_number); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/startup/",
	"title": "startup",
	"tags": [],
	"description": "",
	"content": "startup 探索总结startup知识\n startup     startup_dart_framework     startup_embedder_framwwork     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/startup/startup/",
	"title": "startup",
	"tags": [],
	"description": "",
	"content": "Flutter 安卓平台源码剖析\nFlutter启动流程源码分析\n深入理解Flutter引擎启动\u0026ndash;详细\nFlutter作为一款跨平台的框架，可以运行在Android、iOS等平台，Android为例讲解如何从Android应用启动流程中衔接到Flutter框架，如何启动Flutter引擎的启动流程。 熟悉Android的开发者，应该都了解APP启动过程，会执行Application和Activity的初始化，并调用它们的onCreate()方法。那么FlutterApplication和FlutterActivity的onCreate()方法是连接Native和Flutter的枢纽。\n FlutterApplication.java的onCreate过程：初始化配置文件/加载libflutter.so/注册JNI方法； FlutterActivity.java的onCreate过程：创建FlutterView、Engine, Dart虚拟机、Isolate、taskRunner等对象，最终执行执行到Dart的main()方法，执行runApp(Widget app)来处理整个Dart业务代码。  深入理解Flutter应用启动\u0026ndash;runApp(Widget app)方法开始\nrunApp(MyApp)是flutter应用开始真正执行业务逻辑代码的起点，整个过程主要工作：\n WidgetsFlutterBinding初始化：这是一个单例模式，负责创建WidgetsFlutterBinding对象，WidgetsFlutterBinding继承抽象类BindingBase，并且附带7个mixin，初始化渲染、语义化、绘制、平台消息以及手势等一系列操作； attachRootWidget：遍历挂载整个视图树，并建立Widget、Element、RenderObject之间的连接与关系，此处Element的具体类型为RenderObjectToWidgetElement； scheduleWarmUpFrame：调度预热帧，执行帧绘制方法handleBeginFrame和handleDrawFrame。  从WidgetsFlutterBinding是单例模式，从小节[2.4]得WidgetsBinding的renderViewElement记录着唯一的RenderObjectToWidgetElement对象，从小节[2.3.2]可知RendererBinding的renderView记录着唯一的RenderView对象；也就是说每个flutter应用创建的Root Widget跟Element、RenderObject一一对应，且单例唯一。\nMyApp是用户定义的根Widget，为了建立三棵树的关系，RenderObjectToWidgetAdapter起到重要的桥接功能，该类的createElement方法创建RenderObjectToWidgetElement对象，createRenderObject()方法获取的是RenderView。\n "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/startup/startup_dart_framework/",
	"title": "startup_dart_framework",
	"tags": [],
	"description": "",
	"content": "类设计 runApp main.dart\nvoid main() =\u0026gt; runApp(MyApp()); widgets/binding.dart\nvoid runApp(Widget app) { WidgetsFlutterBinding.ensureInitialized() ..attachRootWidget(app) ..scheduleWarmUpFrame(); } WidgetsFlutterBinding.ensureInitialized() /// A concrete binding for applications based on the Widgets framework. /// This is the glue that binds the framework to the Flutter engine.  class WidgetsFlutterBinding extends BindingBase with GestureBinding, ServicesBinding, SchedulerBinding, PaintingBinding, SemanticsBinding, RendererBinding, WidgetsBinding { /// Returns an instance of the [WidgetsBinding], creating and  /// initializing it if necessary. If one is created, it will be a  /// [WidgetsFlutterBinding]. If one was previously initialized, then  /// it will at least implement [WidgetsBinding].  ///  /// You only need to call this method if you need the binding to be  /// initialized before calling [runApp].  ///  /// In the `flutter_test` framework, [testWidgets] initializes the  /// binding instance to a [TestWidgetsFlutterBinding], not a  /// [WidgetsFlutterBinding].  static WidgetsBinding ensureInitialized() { if (WidgetsBinding.instance == null) WidgetsFlutterBinding(); return WidgetsBinding.instance; } } /// Default abstract constructor for bindings.  ///  /// First calls [initInstances] to have bindings initialize their  /// instance pointers and other state, then calls  /// [initServiceExtensions] to have bindings initialize their  /// observatory service extensions, if any.  BindingBase() { initInstances(); initServiceExtensions(); } SchedulerBinding.initInstances @override void initInstances() { super.initInstances(); _instance = this; window.onBeginFrame = _handleBeginFrame; window.onDrawFrame = _handleDrawFrame; ensureVisualUpdate void ensureVisualUpdate() { switch (schedulerPhase) { case SchedulerPhase.idle: case SchedulerPhase.postFrameCallbacks: scheduleFrame(); return; case SchedulerPhase.transientCallbacks: case SchedulerPhase.midFrameMicrotasks: case SchedulerPhase.persistentCallbacks: return; }} RendererBinding.initInstances PipelineOwner() @override void initInstances() { super.initInstances(); _instance = this; _pipelineOwner = PipelineOwner( onNeedVisualUpdate: ensureVisualUpdate, onSemanticsOwnerCreated: _handleSemanticsOwnerCreated, onSemanticsOwnerDisposed: _handleSemanticsOwnerDisposed, ); initRenderView(); addPersistentFrameCallback(_handlePersistentFrameCallback); initRenderView /// Creates a [RenderView] object to be the root of the  /// [RenderObject] rendering tree, and initializes it so that it  /// will be rendered when the engine is next ready to display a  /// frame.  ///  /// Called automatically when the binding is created.  void initRenderView() { assert(renderView == null); renderView = RenderView(configuration: createViewConfiguration(), window: window); renderView.scheduleInitialFrame(); } /// Bootstrap the rendering pipeline by scheduling the first frame.  ///  /// This should only be called once, and must be called before changing  /// [configuration]. It is typically called immediately after calling the  /// constructor.  void scheduleInitialFrame() { scheduleInitialLayout(); scheduleInitialPaint(_updateMatricesAndCreateNewRootLayer());//配置TransformLayer  owner.requestVisualUpdate(); } _handlePersistentFrameCallback void _handlePersistentFrameCallback(Duration timeStamp) { drawFrame(); } drawFrame /// Pump the rendering pipeline to generate a frame.  ///  /// This method is called by [handleDrawFrame], which itself is called  /// automatically by the engine when it is time to lay out and paint a frame.  ///  /// Each frame consists of the following phases: /// 1. The animation phase /// 2. Microtasks /// 3. The layout phase /// 4. The compositing bits phase /// 5. The paint phase /// 6. The compositing phase /// 7. The semantics phase /// 8. The finalization phase  @protected void drawFrame() { assert(renderView != null); pipelineOwner.flushLayout(); pipelineOwner.flushCompositingBits(); pipelineOwner.flushPaint(); renderView.compositeFrame(); // this sends the bits to the GPU  pipelineOwner.flushSemantics(); // this also sends the semantics to the OS.  } WidgetsBinding.initInstances @override void initInstances() { super.initInstances(); _instance = this; buildOwner.onBuildScheduled = _handleBuildScheduled; drawFrame /// Pump the build and rendering pipeline to generate a frame.  ///  /// This method is called by [handleDrawFrame], which itself is called  /// automatically by the engine when when it is time to lay out and paint a  /// frame. @override void drawFrame() { if (renderViewElement != null) buildOwner.buildScope(renderViewElement); super.drawFrame(); } _handleBuildScheduled void _handleBuildScheduled() { ensureVisualUpdate();} attachRootWidget /// The glue between the widgets layer and the Flutter engine.  mixin WidgetsBinding on BindingBase, SchedulerBinding, GestureBinding, RendererBinding, SemanticsBinding { /// Takes a widget and attaches it to the [renderViewElement], creating it if  /// necessary.  ///  /// This is called by [runApp] to configure the widget tree.  ///  /// See also [RenderObjectToWidgetAdapter.attachToRenderTree].  void attachRootWidget(Widget rootWidget) { _renderViewElement = RenderObjectToWidgetAdapter\u0026lt;RenderBox\u0026gt;( container: renderView, debugShortDescription: \u0026#39;[root]\u0026#39;, child: rootWidget, ).attachToRenderTree(buildOwner, renderViewElement); } /// A bridge from a [RenderObject] to an [Element] tree. class RenderObjectToWidgetAdapter\u0026lt;T extends RenderObject\u0026gt; extends RenderObjectWidget { /// Inflate this widget and actually set the resulting [RenderObject] as the  /// child of [container].  ///  /// If `element` is null, this function will create a new element. Otherwise,  /// the given element will have an update scheduled to switch to this widget.  ///  /// Used by [runApp] to bootstrap applications.  RenderObjectToWidgetElement\u0026lt;T\u0026gt; attachToRenderTree(BuildOwner owner, [ RenderObjectToWidgetElement\u0026lt;T\u0026gt; element ]) { if (element == null) { owner.lockState(() { element = createElement(); assert(element != null); element.assignOwner(owner); }); owner.buildScope(element, () {//main  element.mount(null, null); }); } else { element._newWidget = this; element.markNeedsBuild(); } return element; } } mixing SchedulerBinding\nscheduleWarmUpFrame void scheduleWarmUpFrame() { handleBeginFrame(null); handleDrawFrame(); if (hadScheduledFrame) scheduleFrame(); } handleBeginFrame void handleBeginFrame(Duration rawTimeStamp) { assert(schedulerPhase == SchedulerPhase.idle); _hasScheduledFrame = false; try { // TRANSIENT FRAME CALLBACKS  Timeline.startSync(\u0026#39;Animate\u0026#39;, arguments: timelineWhitelistArguments); _schedulerPhase = SchedulerPhase.transientCallbacks; final Map\u0026lt;int, _FrameCallbackEntry\u0026gt; callbacks = _transientCallbacks; _transientCallbacks = \u0026lt;int, _FrameCallbackEntry\u0026gt;{}; callbacks.forEach((int id, _FrameCallbackEntry callbackEntry) { if (!_removedIds.contains(id)) _invokeFrameCallback(callbackEntry.callback, _currentFrameTimeStamp, callbackEntry.debugStack); }); _removedIds.clear(); } finally { _schedulerPhase = SchedulerPhase.midFrameMicrotasks; } handleDrawFrame /// Called by the engine to produce a new frame. void handleDrawFrame() {//将会调用drawFrame // PERSISTENT FRAME CALLBACKS  _schedulerPhase = SchedulerPhase.persistentCallbacks; for (FrameCallback callback in _persistentCallbacks) _invokeFrameCallback(callback, _currentFrameTimeStamp); // POST-FRAME CALLBACKS  _schedulerPhase = SchedulerPhase.postFrameCallbacks; final List\u0026lt;FrameCallback\u0026gt; localPostFrameCallbacks = List\u0026lt;FrameCallback\u0026gt;.from(_postFrameCallbacks); _postFrameCallbacks.clear(); for (FrameCallback callback in localPostFrameCallbacks) _invokeFrameCallback(callback, _currentFrameTimeStamp); void _invokeFrameCallback(FrameCallback callback, Duration timeStamp, [ StackTrace callbackStack ]) { callback(timeStamp); /// If necessary, schedules a new frame by calling [Window.scheduleFrame]. void scheduleFrame() { if (_hasScheduledFrame || !_framesEnabled) return; ensureFrameCallbacksRegistered(); window.scheduleFrame(); _hasScheduledFrame = true; } /// Ensures callbacks for `window.onBeginFrame` and `window.onDrawFrame` are registered.  @protected void ensureFrameCallbacksRegistered() { window.onBeginFrame ??= _handleBeginFrame; window.onDrawFrame ??= _handleDrawFrame; } 其他 Window /// The most basic interface to the host operating system\u0026rsquo;s user interface.\nscheduleFrame /// Requests that, at the next appropriate opportunity, the [onBeginFrame]  /// and [onDrawFrame] callbacks be invoked.  void scheduleFrame() native \u0026#39;Window_scheduleFrame\u0026#39;; /// A callback that is invoked to notify the application that it is an  /// appropriate time to provide a scene using the [SceneBuilder] API and the  /// [render] method. When possible, this is driven by the hardware VSync  /// signal. This is only called if [scheduleFrame] has been called since the  /// last time this callback was invoked.  /// The [onDrawFrame] callback is invoked immediately after [onBeginFrame],  /// after draining any microtasks (e.g. completions of any [Future]s) queued  /// by the [onBeginFrame] handler.  FrameCallback get onBeginFrame =\u0026gt; _onBeginFrame; set onBeginFrame(FrameCallback callback) { _onBeginFrame = callback; VoidCallback get onDrawFrame =\u0026gt; _onDrawFrame; set onDrawFrame(VoidCallback callback) { render /// Updates the application\u0026#39;s rendering on the GPU with the newly provided  /// [Scene]. This function must be called within the scope of the  /// [onBeginFrame] or [onDrawFrame] callbacks being invoked.  /// To record graphical operations, first create a [PictureRecorder], then  /// construct a [Canvas], passing that [PictureRecorder] to its constructor.  /// After issuing all the graphical operations, call the  /// [PictureRecorder.endRecording] function on the [PictureRecorder] to obtain  /// the final [Picture] that represents the issued graphical operations.  ///  /// Next, create a [SceneBuilder], and add the [Picture] to it using  /// [SceneBuilder.addPicture]. With the [SceneBuilder.build] method you can  /// then obtain a [Scene] object, which you can display to the user via this  /// [render] function.  void render(Scene scene) native \u0026#39;Window_render\u0026#39;; PipelineOwner /// The pipeline owner manages the rendering pipeline.  /// The [RendererBinding] holds the pipeline owner for the render objects that  /// are visible on screen. You can create other pipeline owners to manage  /// off-screen objects, which can flush their pipelines independently of the  /// on-screen render objects.  PipelineOwner /// The unique object managed by this pipeline that has no parent.  ///  /// This object does not have to be a [RenderObject].  AbstractNode get rootNode =\u0026gt; _rootNode; AbstractNode _rootNode; List\u0026lt;RenderObject\u0026gt; _nodesNeedingLayout = \u0026lt;RenderObject\u0026gt;[]; List\u0026lt;RenderObject\u0026gt; _nodesNeedingPaint = \u0026lt;RenderObject\u0026gt;[]; final List\u0026lt;RenderObject\u0026gt; _nodesNeedingCompositingBitsUpdate = \u0026lt;RenderObject\u0026gt;[]; final VoidCallback onNeedVisualUpdate; requestVisualUpdate /// Used to notify the pipeline owner that an associated render object wishes  /// to update its visual appearance.  void requestVisualUpdate() { if (onNeedVisualUpdate != null) onNeedVisualUpdate(); } flushLayout /// Update the layout information for all dirty render objects.  void flushLayout() { while (_nodesNeedingLayout.isNotEmpty) { final List\u0026lt;RenderObject\u0026gt; dirtyNodes = _nodesNeedingLayout; _nodesNeedingLayout = \u0026lt;RenderObject\u0026gt;[]; for (RenderObject node in dirtyNodes..sort((RenderObject a, RenderObject b) =\u0026gt; a.depth - b.depth)) { if (node._needsLayout \u0026amp;\u0026amp; node.owner == this) node._layoutWithoutResize(); } flushCompositingBits /// Updates the [RenderObject.needsCompositing] bits.  void flushCompositingBits() { _nodesNeedingCompositingBitsUpdate.sort((RenderObject a, RenderObject b) =\u0026gt; a.depth - b.depth); for (RenderObject node in _nodesNeedingCompositingBitsUpdate) { if (node._needsCompositingBitsUpdate \u0026amp;\u0026amp; node.owner == this) node._updateCompositingBits(); } _nodesNeedingCompositingBitsUpdate.clear(); flushPaint /// Update the display lists for all render objects.  ///  /// This function is one of the core stages of the rendering pipeline.  /// Painting occurs after layout and before the scene is recomposited so that  /// scene is composited with up-to-date display lists for every render object.  ///  /// See [RendererBinding] for an example of how this function is used.  void flushPaint() { final List\u0026lt;RenderObject\u0026gt; dirtyNodes = _nodesNeedingPaint; _nodesNeedingPaint = \u0026lt;RenderObject\u0026gt;[]; // Sort the dirty nodes in reverse order (deepest first).  for (RenderObject node in dirtyNodes..sort((RenderObject a, RenderObject b) =\u0026gt; b.depth - a.depth)) { assert(node._layer != null); if (node._needsPaint \u0026amp;\u0026amp; node.owner == this) { if (node._layer.attached) { PaintingContext.repaintCompositedChild(node);//main  } else { node._skippedPaintingOnLayer(); } } RenderObjectToWidgetAdapter /// A bridge from a [RenderObject] to an [Element] tree. class RenderObjectToWidgetAdapter\u0026lt;T extends RenderObject\u0026gt; extends RenderObjectWidget /// The widget below this widget in the tree.  ///  /// {@macro flutter.widgets.child}  final Widget child; /// The [RenderObject] that is the parent of the [Element] created by this widget.  final RenderObjectWithChildMixin\u0026lt;T\u0026gt; container; @override RenderObjectToWidgetElement\u0026lt;T\u0026gt; createElement() =\u0026gt; RenderObjectToWidgetElement\u0026lt;T\u0026gt;(this); @override RenderObjectWithChildMixin\u0026lt;T\u0026gt; createRenderObject(BuildContext context) =\u0026gt; container; RenderObjectToWidgetElement\u0026lt;T\u0026gt; attachToRenderTree(BuildOwner owner, [ RenderObjectToWidgetElement\u0026lt;T\u0026gt; element ]) {} RootRenderObjectElement /// The element at the root of the tree.  ///  /// Only root elements may have their owner set explicitly. All other  /// elements inherit their owner from their parent.  RootRenderObjectElement extends RenderObjectElement mount @override void mount(Element parent, dynamic newSlot) { // Root elements should never have parents.  assert(parent == null); assert(newSlot == null); super.mount(parent, newSlot); } RenderObjectToWidgetElement RenderObjectToWidgetElement\u0026lt;T extends RenderObject\u0026gt; { Element _child; @override RenderObjectWithChildMixin\u0026lt;T\u0026gt; get renderObject =\u0026gt; super.renderObject; } mount @override void mount(Element parent, dynamic newSlot) { assert(parent == null); super.mount(parent, newSlot);//1将自己挂在父节点上  _rebuild();//2：通过调用updateChild逐个将child挂在自己上 } update @override void update(RenderObjectToWidgetAdapter\u0026lt;T\u0026gt; newWidget) { super.update(newWidget); assert(widget == newWidget); _rebuild(); } _rebuild void _rebuild() { _child = updateChild(_child, widget.child, _rootChildSlot); insertChildRenderObject @override void insertChildRenderObject(RenderObject child, dynamic slot) { renderObject.child = child; } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/startup/startup_embedder_framwwork/",
	"title": "startup_embedder_framwwork",
	"tags": [],
	"description": "",
	"content": "FlutterApplication.onCreate /** * Flutter implementation of {@link android.app.Application}, managing * application-level global initializations. */ //FlutterApplication @CallSuper public void onCreate() { super.onCreate(); FlutterMain.startInitialization(this); } /** FlutterMain * Starts initialization of the native system. * @param applicationContext The Android application context. */ public static void startInitialization(@NonNull Context applicationContext) { if (isRunningInRobolectricTest) { return; } FlutterLoader.getInstance().startInitialization(applicationContext); } FlutterLoader.startInitialization() /** Finds Flutter resources in an application APK and also loads Flutter\u0026#39;s native library.*/ //FlutterLoader  /** * Starts initialization of the native system. * @param applicationContext The Android application context. */ public void startInitialization(@NonNull Context applicationContext) { startInitialization(applicationContext, new Settings()); } /**Starts initialization of the native system. * \u0026lt;p\u0026gt; * This loads the Flutter engine\u0026#39;s native library to enable subsequent JNI calls. This also starts locating and unpacking Dart resources packaged in the app\u0026#39;s APK. * \u0026lt;p\u0026gt;*/ public void startInitialization(@NonNull Context applicationContext, @NonNull Settings settings) { if (Looper.myLooper() != Looper.getMainLooper()) { throw new IllegalStateException(\u0026#34;startInitialization must be called on the main thread\u0026#34;); } initConfig(applicationContext); initResources(applicationContext); System.loadLibrary(\u0026#34;flutter\u0026#34;);//flutter so源码位于engine\\shell\\platform\\android下的BUILD.gn配置  VsyncWaiter .getInstance((WindowManager) applicationContext.getSystemService(Context.WINDOW_SERVICE)) .init(); long initTimeMillis = SystemClock.uptimeMillis() - initStartTimestampMillis; FlutterJNI.nativeRecordStartTimestamp(initTimeMillis); } System.loadLibrary(\u0026ldquo;flutter\u0026rdquo;) //engine/shell/platform/android/library_loader.cc  // This is called by the VM when the shared library is first loaded. // flutter so的初始化 JNIEXPORT jint JNI_OnLoad(JavaVM* vm, void* reserved) { // Initialize the Java VM. //Android进程在由zygote fork过程中已创建了JavaVM，每一个进程对应一个JavaVM。在这里只是将当前进程的JavaVM实例保存在静态变量，再将当前线程和JavaVM建立关联，获取JNIEnv实例，每个线程对应一个JNIEnv实例  fml::jni::InitJavaVM(vm); JNIEnv* env = fml::jni::AttachCurrentThread(); bool result = false; //注册c和java层双向调用的函数信息  // Register FlutterMain.  result = flutter::FlutterMain::Register(env); // Register PlatformView  result = flutter::PlatformViewAndroid::Register(env); // Register VSyncWaiter.  result = flutter::VsyncWaiterAndroid::Register(env); return JNI_VERSION_1_4; } //engine/shell/platform/android/flutter_main.cc bool FlutterMain::Register(JNIEnv* env) { static const JNINativeMethod methods[] = { { .name = \u0026#34;nativeInit\u0026#34;, .signature = \u0026#34;(Landroid/content/Context;[Ljava/lang/String;Ljava/\u0026#34; \u0026#34;lang/String;Ljava/lang/String;Ljava/lang/String;)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;Init), }, { .name = \u0026#34;nativeRecordStartTimestamp\u0026#34;, .signature = \u0026#34;(J)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;RecordStartTimestamp), }, }; jclass clazz = env-\u0026gt;FindClass(\u0026#34;io/flutter/embedding/engine/FlutterJNI\u0026#34;); return env-\u0026gt;RegisterNatives(clazz, methods, fml::size(methods)) == 0; } VsyncWaiter.init //VsyncWaiter  private VsyncWaiter(@NonNull WindowManager windowManager) { this.windowManager = windowManager; } private final FlutterJNI.AsyncWaitForVsyncDelegate asyncWaitForVsyncDelegate = new FlutterJNI.AsyncWaitForVsyncDelegate() { @Override public void asyncWaitForVsync(long cookie) { Choreographer.getInstance().postFrameCallback(new Choreographer.FrameCallback() { @Override public void doFrame(long frameTimeNanos) { float fps = windowManager.getDefaultDisplay().getRefreshRate(); long refreshPeriodNanos = (long) (1000000000.0 / fps); FlutterJNI.nativeOnVsync(frameTimeNanos, frameTimeNanos + refreshPeriodNanos, cookie); } }); } }; public void init() { FlutterJNI.setAsyncWaitForVsyncDelegate(asyncWaitForVsyncDelegate); // TODO(mattcarroll): look into moving FPS reporting to a plugin  float fps = windowManager.getDefaultDisplay().getRefreshRate(); FlutterJNI.setRefreshRateFPS(fps); } //FlutterJNI  public static void setAsyncWaitForVsyncDelegate(@Nullable AsyncWaitForVsyncDelegate delegate) { asyncWaitForVsyncDelegate = delegate; } // Called by native.  private static void asyncWaitForVsync(final long cookie) { if (asyncWaitForVsyncDelegate != null) { asyncWaitForVsyncDelegate.asyncWaitForVsync(cookie); } else { throw new IllegalStateException(\u0026#34;An AsyncWaitForVsyncDelegate must be registered with FlutterJNI before asyncWaitForVsync() is invoked.\u0026#34;); } } public static native void nativeOnVsync(long frameTimeNanos, long frameTargetTimeNanos, long cookie); public static void setRefreshRateFPS(float refreshRateFPS) { FlutterJNI.refreshRateFPS = refreshRateFPS; } public static native void nativeRecordStartTimestamp(long initTimeMillis); FlutterActivity.onCreate FlutterActivity extends Activity implements FlutterView.Provider, PluginRegistry, ViewFactory { private final FlutterActivityDelegate delegate = new FlutterActivityDelegate(this, this); // These aliases ensure that the methods we forward to the delegate adhere  // to relevant interfaces versus just existing in FlutterActivityDelegate.  private final FlutterActivityEvents eventDelegate = delegate; private final FlutterView.Provider viewProvider = delegate; private final PluginRegistry pluginRegistry = delegate; public FlutterActivity() { this.eventDelegate = this.delegate; this.viewProvider = this.delegate; this.pluginRegistry = this.delegate; } /** * Returns the Flutter view used by this activity; will be null before * {@link #onCreate(Bundle)} is called. */ public FlutterView getFlutterView() { return this.viewProvider.getFlutterView();} } protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); this.eventDelegate.onCreate(savedInstanceState); } public final class FlutterActivityDelegate implements FlutterActivityEvents, FlutterView.Provider,PluginRegistry { private FlutterView flutterView; private final Activity activity; public FlutterActivityDelegate(Activity activity, FlutterActivityDelegate.ViewFactory viewFactory) { this.activity = (Activity)Preconditions.checkNotNull(activity); this.viewFactory = (FlutterActivityDelegate.ViewFactory)Preconditions.checkNotNull(viewFactory); } public FlutterView getFlutterView() { return this.flutterView; } // The implementation of PluginRegistry forwards to flutterView.  @Override public boolean hasPlugin(String key) { return flutterView.getPluginRegistry().hasPlugin(key); } @Override public Registrar registrarFor(String pluginKey) { return flutterView.getPluginRegistry().registrarFor(pluginKey); } } public void onCreate(Bundle savedInstanceState) { FlutterMain.ensureInitializationComplete(this.activity.getApplicationContext(), args); this.flutterView = this.viewFactory.createFlutterView(this.activity); if (this.flutterView == null) { FlutterNativeView nativeView = this.viewFactory.createFlutterNativeView(); this.flutterView = new FlutterView(this.activity, (AttributeSet)null, nativeView); this.flutterView.setLayoutParams(matchParent); this.activity.setContentView(this.flutterView); } if (loadIntent(activity.getIntent())) { return; } String appBundlePath = FlutterMain.findAppBundlePath(); if (appBundlePath != null) { runBundle(appBundlePath); } FlutterLoader.ensureInitializationComplete /** FlutterMain * Blocks until initialization of the native system has completed. * \u0026lt;p\u0026gt; * Calling this method multiple times has no effect.*/ public static void ensureInitializationComplete(@NonNull Context applicationContext, @Nullable String[] args) { if (isRunningInRobolectricTest) { return; } FlutterLoader.getInstance().ensureInitializationComplete(applicationContext, args); } /** FlutterLoader * Blocks until initialization of the native system has completed. */ public void ensureInitializationComplete(@NonNull Context applicationContext, @Nullable String[] args) { FlutterJNI.nativeInit(applicationContext, shellArgs.toArray(new String[0]), kernelPath, appStoragePath, engineCachesPath); public static native void nativeInit() new FlutterView //FlutterView extends SurfaceView public FlutterView(Context context, AttributeSet attrs, FlutterNativeView nativeView) { if (nativeView == null) { this.mNativeView = new FlutterNativeView(activity.getApplicationContext());//main  } else { this.mNativeView = nativeView; } this.mNativeView.attachViewAndActivity(this, activity); this.mSurfaceCallback = new Callback() { public void surfaceCreated(SurfaceHolder holder) { FlutterView.this.assertAttached(); FlutterView.this.mNativeView.getFlutterJNI().onSurfaceCreated(holder.getSurface());//main  } public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) { FlutterView.this.assertAttached(); FlutterView.this.mNativeView.getFlutterJNI().onSurfaceChanged(width, height); } public void surfaceDestroyed(SurfaceHolder holder) { FlutterView.this.assertAttached(); FlutterView.this.mNativeView.getFlutterJNI().onSurfaceDestroyed(); } }; this.getHolder().addCallback(this.mSurfaceCallback); this.navigationChannel = new NavigationChannel(this.dartExecutor); this.keyEventChannel = new KeyEventChannel(this.dartExecutor); this.lifecycleChannel = new LifecycleChannel(this.dartExecutor); this.localizationChannel = new LocalizationChannel(this.dartExecutor); this.platformChannel = new PlatformChannel(this.dartExecutor); this.systemChannel = new SystemChannel(this.dartExecutor); this.settingsChannel = new SettingsChannel(this.dartExecutor); public FlutterNativeView(@NonNull Context context, boolean isBackgroundView) { mContext = context; mPluginRegistry = new FlutterPluginRegistry(this, context); mFlutterJNI = new FlutterJNI(); mFlutterJNI.addIsDisplayingFlutterUiListener(flutterUiDisplayListener); this.dartExecutor = new DartExecutor(mFlutterJNI, context.getAssets()); mFlutterJNI.addEngineLifecycleListener(new EngineLifecycleListenerImpl()); attach(this, isBackgroundView); assertAttached(); } private void attach(FlutterNativeView view, boolean isBackgroundView) { mFlutterJNI.attachToNative(isBackgroundView); dartExecutor.onAttachedToJNI(); } attachToNative /** * Attaches this {@code FlutterJNI} instance to Flutter\u0026#39;s native engine, which allows * for communication between Android code and Flutter\u0026#39;s platform agnostic engine. * \u0026lt;p\u0026gt; * This method must not be invoked if {@code FlutterJNI} is already attached to native. */ @UiThread public void attachToNative(boolean isBackgroundView) { ensureRunningOnMainThread(); ensureNotAttachedToNative(); nativePlatformViewId = nativeAttach(this, isBackgroundView); } private void ensureNotAttachedToNative() { if (nativePlatformViewId != null) { throw new RuntimeException(\u0026#34;Cannot execute operation because FlutterJNI is attached to native.\u0026#34;); }} } private native long nativeAttach(@NonNull FlutterJNI flutterJNI, boolean isBackgroundView); //engine/shell/platform/android/platform_view_android_jni.cc bool RegisterApi(JNIEnv* env) { static const JNINativeMethod flutter_jni_methods[] = { // Start of methods from FlutterJNI  { .name = \u0026#34;nativeAttach\u0026#34;, .signature = \u0026#34;(Lio/flutter/embedding/engine/FlutterJNI;Z)J\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;AttachJNI), }, { .name = \u0026#34;nativeRunBundleAndSnapshotFromLibrary\u0026#34;, .signature = \u0026#34;(JLjava/lang/String;Ljava/lang/String;\u0026#34; \u0026#34;Ljava/lang/String;Landroid/content/res/AssetManager;)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;RunBundleAndSnapshotFromLibrary), }, } // Called By Java static jlong AttachJNI(JNIEnv* env, jclass clazz, jobject flutterJNI, jboolean is_background_view) { fml::jni::JavaObjectWeakGlobalRef java_object(env, flutterJNI); auto shell_holder = std::make_unique\u0026lt;AndroidShellHolder\u0026gt;( FlutterMain::Get().GetSettings(), java_object, is_background_view); if (shell_holder-\u0026gt;IsValid()) { return reinterpret_cast\u0026lt;jlong\u0026gt;(shell_holder.release()); } else { return 0; } } AndroidShellHolder::AndroidShellHolder //engine/shell/platform/android/android_shell_holder  ThreadHost thread_host_; fml::WeakPtr\u0026lt;PlatformViewAndroid\u0026gt; platform_view_; std::unique_ptr\u0026lt;Shell\u0026gt; shell_; AndroidShellHolder::AndroidShellHolder( flutter::Settings settings, fml::jni::JavaObjectWeakGlobalRef java_object, bool is_background_view) : settings_(std::move(settings)), java_object_(java_object) { if (is_background_view) { thread_host_ = {thread_label, ThreadHost::Type::UI}; } else { thread_host_ = {thread_label, ThreadHost::Type::UI | ThreadHost::Type::GPU | ThreadHost::Type::IO};//main  } fml::WeakPtr\u0026lt;PlatformViewAndroid\u0026gt; weak_platform_view; Shell::CreateCallback\u0026lt;PlatformView\u0026gt; on_create_platform_view = //main  [is_background_view, java_object, \u0026amp;weak_platform_view](Shell\u0026amp; shell) { std::unique_ptr\u0026lt;PlatformViewAndroid\u0026gt; platform_view_android; platform_view_android = std::make_unique\u0026lt;PlatformViewAndroid\u0026gt;( shell, // delegate  shell.GetTaskRunners(), // task runners  java_object, // java object handle for JNI interop  shell.GetSettings() .enable_software_rendering // use software rendering  ); weak_platform_view = platform_view_android-\u0026gt;GetWeakPtr(); return platform_view_android; }; Shell::CreateCallback\u0026lt;Rasterizer\u0026gt; on_create_rasterizer = [](Shell\u0026amp; shell) {//main  return std::make_unique\u0026lt;Rasterizer\u0026gt;(shell, shell.GetTaskRunners()); }; // The current thread will be used as the platform thread. Ensure that the  // message loop is initialized.  fml::MessageLoop::EnsureInitializedForCurrentThread(); fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; platform_runner = fml::MessageLoop::GetCurrent().GetTaskRunner(); gpu_runner = thread_host_.gpu_thread-\u0026gt;GetTaskRunner(); ui_runner = thread_host_.ui_thread-\u0026gt;GetTaskRunner(); io_runner = thread_host_.io_thread-\u0026gt;GetTaskRunner(); //main  flutter::TaskRunners task_runners(thread_label, // label  platform_runner, // platform  gpu_runner, // gpu  ui_runner, // ui  io_runner // io  ); //main  shell_ = Shell::Create(task_runners, // task runners  GetDefaultWindowData(), // window data  settings_, // settings  on_create_platform_view, // platform view create callback  on_create_rasterizer // rasterizer create callback  ); platform_view_ = weak_platform_view; Shell::Create class Shell final : public PlatformView::Delegate, public Animator::Delegate, public Engine::Delegate, public Rasterizer::Delegate, public ServiceProtocol::Handler { template \u0026lt;class T\u0026gt; using CreateCallback = std::function\u0026lt;std::unique_ptr\u0026lt;T\u0026gt;(Shell\u0026amp;)\u0026gt;; std::unique_ptr\u0026lt;Shell\u0026gt; Shell::Create( TaskRunners task_runners, const WindowData window_data, Settings settings, Shell::CreateCallback\u0026lt;PlatformView\u0026gt; on_create_platform_view, Shell::CreateCallback\u0026lt;Rasterizer\u0026gt; on_create_rasterizer) { PerformInitializationTasks(settings); PersistentCache::SetCacheSkSL(settings.cache_sksl); auto vm = DartVMRef::Create(settings);//main  FML_CHECK(vm) \u0026lt;\u0026lt; \u0026#34;Must be able to initialize the VM.\u0026#34;; auto vm_data = vm-\u0026gt;GetVMData(); //main  return Shell::Create(std::move(task_runners), //  std::move(window_data), //  std::move(settings), //  vm_data-\u0026gt;GetIsolateSnapshot(), // isolate snapshot  on_create_platform_view, //  on_create_rasterizer, //  std::move(vm) //  ); dart_vm_lifecycle.cc\nDartVMRef::Create DartVMRef DartVMRef::Create(Settings settings, fml::RefPtr\u0026lt;DartSnapshot\u0026gt; vm_snapshot, fml::RefPtr\u0026lt;DartSnapshot\u0026gt; isolate_snapshot) { std::scoped_lock lifecycle_lock(gVMMutex); // If there is already a running VM in the process, grab a strong reference to it.  if (auto vm = gVM.lock()) { FML_DLOG(WARNING) \u0026lt;\u0026lt; \u0026#34;Attempted to create a VM in a process where one was \u0026#34; \u0026#34;already running. Ignoring arguments for current VM \u0026#34; \u0026#34;create call and reusing the old VM.\u0026#34;; // There was already a running VM in the process,  return DartVMRef{std::move(vm)}; } ...... // If there is no VM in the process. Initialize one, hold the weak reference  // and pass a strong reference to the caller.  auto isolate_name_server = std::make_shared\u0026lt;IsolateNameServer\u0026gt;(); auto vm = DartVM::Create(std::move(settings), //  std::move(vm_snapshot), //  std::move(isolate_snapshot), //  isolate_name_server //  ); gVMData = vm-\u0026gt;GetVMData(); gVMServiceProtocol = vm-\u0026gt;GetServiceProtocol(); gVMIsolateNameServer = isolate_name_server; gVM = vm; if (settings.leak_vm) { gVMLeak = new std::shared_ptr\u0026lt;DartVM\u0026gt;(vm); } return DartVMRef{std::move(vm)}; std::unique_ptr\u0026lt;Shell\u0026gt; Shell::Create( TaskRunners task_runners, const WindowData window_data, Settings settings, fml::RefPtr\u0026lt;const DartSnapshot\u0026gt; isolate_snapshot, const Shell::CreateCallback\u0026lt;PlatformView\u0026gt;\u0026amp; on_create_platform_view, const Shell::CreateCallback\u0026lt;Rasterizer\u0026gt;\u0026amp; on_create_rasterizer, DartVMRef vm) { PerformInitializationTasks(settings); PersistentCache::SetCacheSkSL(settings.cache_sksl); fml::AutoResetWaitableEvent latch; std::unique_ptr\u0026lt;Shell\u0026gt; shell; fml::TaskRunner::RunNowOrPostTask( task_runners.GetPlatformTaskRunner(),//main  fml::MakeCopyable([\u0026amp;latch, //  vm = std::move(vm), //  \u0026amp;shell, //  task_runners = std::move(task_runners), //  window_data, //  settings, //  isolate_snapshot = std::move(isolate_snapshot), //  on_create_platform_view, //  on_create_rasterizer //  ]() mutable { shell = CreateShellOnPlatformThread(std::move(vm), std::move(task_runners), //  window_data, //  settings, //  std::move(isolate_snapshot), //  on_create_platform_view, //  on_create_rasterizer //  ); latch.Signal(); })); latch.Wait(); return shell; std::unique_ptr\u0026lt;Shell\u0026gt; Shell::CreateShellOnPlatformThread( DartVMRef vm, TaskRunners task_runners, const WindowData window_data, Settings settings, fml::RefPtr\u0026lt;const DartSnapshot\u0026gt; isolate_snapshot, const Shell::CreateCallback\u0026lt;PlatformView\u0026gt;\u0026amp; on_create_platform_view, const Shell::CreateCallback\u0026lt;Rasterizer\u0026gt;\u0026amp; on_create_rasterizer) { auto shell = std::unique_ptr\u0026lt;Shell\u0026gt;(new Shell(std::move(vm), task_runners, settings)); // Create the rasterizer on the GPU thread. ...... // Create the platform view on the platform thread (this thread).  auto platform_view = on_create_platform_view(*shell.get()); // Ask the platform view for the vsync waiter. This will be used by the engine  // to create the animator.  auto vsync_waiter = platform_view-\u0026gt;CreateVSyncWaiter(); // Create the IO manager on the IO thread. The IO manager must be initialized  // first because it has state that the other subsystems depend on. It must  // first be booted and the necessary references obtained to initialize the  // other subsystems. ...... // Create the engine on the UI thread.  std::promise\u0026lt;std::unique_ptr\u0026lt;Engine\u0026gt;\u0026gt; engine_promise; auto engine_future = engine_promise.get_future(); fml::TaskRunner::RunNowOrPostTask( shell-\u0026gt;GetTaskRunners().GetUITaskRunner(),//main  fml::MakeCopyable([\u0026amp;engine_promise, //  shell = shell.get(), //  \u0026amp;dispatcher_maker, //  \u0026amp;window_data, //  isolate_snapshot = std::move(isolate_snapshot), //  vsync_waiter = std::move(vsync_waiter), //  \u0026amp;weak_io_manager_future, //  \u0026amp;snapshot_delegate_future, //  \u0026amp;unref_queue_future //  ]() mutable { TRACE_EVENT0(\u0026#34;flutter\u0026#34;, \u0026#34;ShellSetupUISubsystem\u0026#34;); const auto\u0026amp; task_runners = shell-\u0026gt;GetTaskRunners(); // The animator is owned by the UI thread but it gets its vsync pulses  // from the platform.  auto animator = std::make_unique\u0026lt;Animator\u0026gt;(*shell, task_runners, std::move(vsync_waiter)); engine_promise.set_value(std::make_unique\u0026lt;Engine\u0026gt;(//main  *shell, //  dispatcher_maker, //  *shell-\u0026gt;GetDartVM(), //  std::move(isolate_snapshot), //  task_runners, //  window_data, //  shell-\u0026gt;GetSettings(), //  std::move(animator), //  weak_io_manager_future.get(), //  unref_queue_future.get(), //  snapshot_delegate_future.get() //  )); })); if (!shell-\u0026gt;Setup(std::move(platform_view), //main  engine_future.get(), //  rasterizer_future.get(), //  io_manager_future.get()) //  ) { return nullptr; } return shell; Engine::Engine Engine::Engine(Delegate\u0026amp; delegate, const PointerDataDispatcherMaker\u0026amp; dispatcher_maker, DartVM\u0026amp; vm, fml::RefPtr\u0026lt;const DartSnapshot\u0026gt; isolate_snapshot, TaskRunners task_runners, const WindowData window_data, Settings settings, std::unique_ptr\u0026lt;Animator\u0026gt; animator, fml::WeakPtr\u0026lt;IOManager\u0026gt; io_manager, fml::RefPtr\u0026lt;SkiaUnrefQueue\u0026gt; unref_queue, fml::WeakPtr\u0026lt;SnapshotDelegate\u0026gt; snapshot_delegate) : delegate_(delegate), settings_(std::move(settings)), animator_(std::move(animator)), activity_running_(true), have_surface_(false), image_decoder_(task_runners, vm.GetConcurrentWorkerTaskRunner(), io_manager), task_runners_(std::move(task_runners)), weak_factory_(this) { // Runtime controller is initialized here because it takes a reference to this  // object as its delegate. The delegate may be called in the constructor and  // we want to be fully initilazed by that point.  runtime_controller_ = std::make_unique\u0026lt;RuntimeController\u0026gt;( ...... pointer_data_dispatcher_ = dispatcher_maker(*this); Shell::Shell(DartVMRef vm, TaskRunners task_runners, Settings settings) { // Install service protocol handlers. ...... bool Shell::Setup(std::unique_ptr\u0026lt;PlatformView\u0026gt; platform_view, std::unique_ptr\u0026lt;Engine\u0026gt; engine, std::unique_ptr\u0026lt;Rasterizer\u0026gt; rasterizer, std::unique_ptr\u0026lt;ShellIOManager\u0026gt; io_manager) { ...... } activity.setContentView(flutterView) \u0026hellip;\u0026hellip;\nrunBundle(appBundlePath) private void runBundle(String appBundlePath) { if (!flutterView.getFlutterNativeView().isApplicationRunning()) { FlutterRunArguments args = new FlutterRunArguments(); args.bundlePath = appBundlePath; args.entrypoint = \u0026#34;main\u0026#34;; flutterView.runFromBundle(args);//main  } } public void runFromBundle(FlutterRunArguments args) { assertAttached(); preRun(); mNativeView.runFromBundle(args);//main  postRun(); } public void runFromBundle(FlutterRunArguments args) { mFlutterJNI.runBundleAndSnapshotFromLibrary(//main  args.bundlePath, args.entrypoint, args.libraryPath, mContext.getResources().getAssets() ); applicationIsRunning = true; /** FlutterJNI * Executes a Dart entrypoint. * \u0026lt;p\u0026gt; * This can only be done once per JNI attachment because a Dart isolate can only be * entered once. */ @UiThread public void runBundleAndSnapshotFromLibrary( @NonNull String bundlePath, @Nullable String entrypointFunctionName, @Nullable String pathToEntrypointFunction, @NonNull AssetManager assetManager ) { ensureRunningOnMainThread(); ensureAttachedToNative(); nativeRunBundleAndSnapshotFromLibrary( nativePlatformViewId, bundlePath, entrypointFunctionName, pathToEntrypointFunction, assetManager ); } //engine/shell/platform/android/platform_view_android_jni.cc static void RunBundleAndSnapshotFromLibrary(JNIEnv* env, jobject jcaller, jlong shell_holder, jstring jBundlePath, jstring jEntrypoint, jstring jLibraryUrl, jobject jAssetManager) { auto asset_manager = std::make_shared\u0026lt;flutter::AssetManager\u0026gt;(); ...... RunConfiguration config(std::move(isolate_configuration), std::move(asset_manager)); { auto entrypoint = fml::jni::JavaStringToString(env, jEntrypoint); auto libraryUrl = fml::jni::JavaStringToString(env, jLibraryUrl); if ((entrypoint.size() \u0026gt; 0) \u0026amp;\u0026amp; (libraryUrl.size() \u0026gt; 0)) { config.SetEntrypointAndLibrary(std::move(entrypoint), std::move(libraryUrl)); } else if (entrypoint.size() \u0026gt; 0) { config.SetEntrypoint(std::move(entrypoint)); } } ANDROID_SHELL_HOLDER-\u0026gt;Launch(std::move(config));//main AndroidShellHolder::Launch //engine/shell/platform/android/android_shell_holder void AndroidShellHolder::Launch(RunConfiguration config) { if (!IsValid()) { return; } shell_-\u0026gt;RunEngine(std::move(config)); } Shell::RunEngine void Shell::RunEngine(RunConfiguration run_configuration) { RunEngine(std::move(run_configuration), nullptr); } void Shell::RunEngine( RunConfiguration run_configuration, const std::function\u0026lt;void(Engine::RunStatus)\u0026gt;\u0026amp; result_callback) { ...... fml::TaskRunner::RunNowOrPostTask( task_runners_.GetUITaskRunner(),//main  fml::MakeCopyable( [run_configuration = std::move(run_configuration), weak_engine = weak_engine_, result]() mutable { if (!weak_engine) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not launch engine with configuration - no engine.\u0026#34;; result(Engine::RunStatus::Failure); return; } auto run_result = weak_engine-\u0026gt;Run(std::move(run_configuration));//main  if (run_result == flutter::Engine::RunStatus::Failure) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not launch engine with configuration.\u0026#34;; } result(run_result); })); Engine::Run Engine::RunStatus Engine::Run(RunConfiguration configuration) { auto isolate_launch_status = PrepareAndLaunchIsolate(std::move(configuration)); Engine::RunStatus Engine::PrepareAndLaunchIsolate( RunConfiguration configuration) { if (configuration.GetEntrypointLibrary().empty()) { if (!isolate-\u0026gt;Run(configuration.GetEntrypoint(),//main  settings_.dart_entrypoint_args)) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not run the isolate.\u0026#34;; return RunStatus::Failure; } } DartIsolate::Run bool DartIsolate::Run(const std::string\u0026amp; entrypoint_name, const std::vector\u0026lt;std::string\u0026gt;\u0026amp; args, const fml::closure\u0026amp; on_run) { auto user_entrypoint_function = Dart_GetField(Dart_RootLibrary(), tonic::ToDart(entrypoint_name.c_str())); auto entrypoint_args = tonic::ToDart(args); if (!InvokeMainEntrypoint(user_entrypoint_function, entrypoint_args)) {//main  return false; } static bool InvokeMainEntrypoint(Dart_Handle user_entrypoint_function, Dart_Handle args) { Dart_Handle start_main_isolate_function = tonic::DartInvokeField(Dart_LookupLibrary(tonic::ToDart(\u0026#34;dart:isolate\u0026#34;)), \u0026#34;_getStartMainIsolateFunction\u0026#34;, {}); if (tonic::LogIfError(tonic::DartInvokeField( Dart_LookupLibrary(tonic::ToDart(\u0026#34;dart:ui\u0026#34;)), \u0026#34;_runMainZoned\u0026#34;, {start_main_isolate_function, user_entrypoint_function, args}))) {//main  FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not invoke the main entrypoint.\u0026#34;; return false; } return true; _runMainZoned //hooks.dart @pragma(\u0026#39;vm:entry-point\u0026#39;) // ignore: unused_element void _runMainZoned(Function startMainIsolateFunction,//main  Function userMainFunction,//main  List\u0026lt;String\u0026gt; args) { startMainIsolateFunction((){ runZoned\u0026lt;void\u0026gt;(() { if (userMainFunction is _BinaryFunction) { // This seems to be undocumented but supported by the command line VM.  // Let\u0026#39;s do the same in case old entry-points are ported to Flutter.  (userMainFunction as dynamic)(args, \u0026#39;\u0026#39;); } else if (userMainFunction is _UnaryFunction) { (userMainFunction as dynamic)(args); } else { userMainFunction(); } }, onError: (Object error, StackTrace stackTrace) { _reportUnhandledException(error.toString(), stackTrace.toString()); }); }, null); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/supporttoandroidx/",
	"title": "supportToAndroidx",
	"tags": [],
	"description": "",
	"content": "升级背景 为了升级公司客户端架构，促进更高效的开发效率，减少模板代码并提升稳定性，需要基础仓库从support迁移到androidx，并提供相应的升级方案以及基于androidx的基础组件。\n模块拆分方式命名   不依赖support/androidx的模块称为pure模块\n  依赖support的称为support模块\n  依赖androidx的称为androidx模块\n  升级方案  module内部，将原本的基础仓库old base module拆分为base_support + base_pure两个模块，剥离support依赖。其中base_pure模块拆分到一个单独的project中，而base_support项目需要新增base_androidx branch，分开两个branch迭代，并通过cherrypick进行修改同步，同时分别发布独立的maven。 old base module所依赖的模块，也需要按照1的方式进行拆分。同时pure模块只能依赖pure模块,非pure模块可以依赖对应的非pure模块和pure模块 pure模块的单测test模块是support或者androidx都没关系，不影响发版仓库中的内容 androidx利用灰度版本去进行测试  包依赖关系 graph TB app_support--\u0026gt;base_support app_support--\u0026gt;base_pure app_androidx--\u0026gt;base_androidx app_androidx--\u0026gt;base_pure base_support--\u0026gt;xxx_pure base_pure--\u0026gt;xxx_pure base_support--\u0026gt;xxx_support base_androidx--\u0026gt;xxx_androidx base_androidx--\u0026gt;xxx_pure 升级步骤 https://developer.android.google.cn/jetpack/androidx/migrate?hl=zh-cn\nhttps://medium.com/androiddevelopers/migrating-to-androidx-tip-tricks-and-guidance-88d5de238876\n是时候迁移至 AndroidX 了！\ngraph LR olderSupport--\u0026gt;|APIchanges|28.0.0Support--\u0026gt;|namespaceChanges|androidx1.0  创建新分支准备迁移，停止同步进行的新功能开发和重构，防止冲突 在old base module中搜索support进行处理,去除不必要的support库依赖 support升级到28，这是因为，1.0.0 版本的 AndroidX 工件是与支持库 28.0.0 工件等效的二进制文件。 编译和测试用例通过 配置android.useAndroidX=true android.enableJetifier=true 更新依赖的仓库到支持androidx的版本 迁移到androidx: AS操作 Refactor \u0026gt; Migrate to AndroidX  基于androidx的后续基础架构封装 新架构单独封装一个独立的module(使用androidx)，提供基础能力\n 基础View组件(Activity,Fragment,View等)，支持DataBinding的能力选择 基础ViewModel组件 基础Repository组件 新架构组件的使用规范和样例 startup启动组件 后台任务调度执行组件 datastore组件替代现有的sharedPreference 其他jetpack组件，按需封装提供  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E6%BA%90%E7%A0%81%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95/syscall%E6%9F%A5%E6%89%BE%E6%96%B9%E5%BC%8F/",
	"title": "Syscall查找方式",
	"tags": [],
	"description": "",
	"content": "Android9.0采用如下Tips3,4进行定位\nTips 1： 用户空间的方法xxx，对应系统调用层方法则是sys_xxx； Tips 2： unistd.h文件记录着系统调用中断号的信息。(搜索__SYSCALL找到unistd.d文件位置) /* kernel/signal.c */ __SYSCALL(__NR_kill, sys_kill) Tips 3： 宏定义SYSCALL_DEFINEx(xxx,…)，展开后对应的方法则是sys_xxx； Tips 4： 方法参数的个数x，对应于SYSCALL_DEFINEx。 kill(int pid, int sig)方法共两个参数，则对应方法于SYSCALL_DEFINE2(kill,...)，进入signal.c文件，再次搜索关键字，便能看到方法： include/linux/syscalls.h\nsyscalls.h #define SYSCALL_DEFINE1(name, ...) SYSCALL_DEFINEx(1, _##name, __VA_ARGS__) #define SYSCALL_DEFINE2(name, ...) SYSCALL_DEFINEx(2, _##name, __VA_ARGS__) #define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__) #define SYSCALL_DEFINE4(name, ...) SYSCALL_DEFINEx(4, _##name, __VA_ARGS__) #define SYSCALL_DEFINE5(name, ...) SYSCALL_DEFINEx(5, _##name, __VA_ARGS__) #define SYSCALL_DEFINE6(name, ...) SYSCALL_DEFINEx(6, _##name, __VA_ARGS__)  #define SYSCALL_DEFINEx(x, sname, ...)\t\\ SYSCALL_METADATA(sname, x, __VA_ARGS__)\t\\ __SYSCALL_DEFINEx(x, sname, __VA_ARGS__)  #define __SYSCALL_DEFINEx(x, name, ...)\t\\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))\t\\ __attribute__((alias(__stringify(SyS##name))));\t\\ static inline long SYSC##name(__MAP(x,__SC_DECL,__VA_ARGS__));\t\\ asmlinkage long SyS##name(__MAP(x,__SC_LONG,__VA_ARGS__));\t\\ asmlinkage long SyS##name(__MAP(x,__SC_LONG,__VA_ARGS__))\t\\ {\t\\ long ret = SYSC##name(__MAP(x,__SC_CAST,__VA_ARGS__));\t\\ __MAP(x,__SC_TEST,__VA_ARGS__);\t\\ __PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__));\t\\ return ret;\t\\ }\t\\ static inline long SYSC##name(__MAP(x,__SC_DECL,__VA_ARGS__)) fs/ioctl.c\nioctl kgdb调试堆栈 #0 binder_ioctl (filp=0xffff8800618f6a00, cmd=3224396289, arg=3463711848) at drivers/android/binder.c:4738 #1 0xffffffff803873fe in C_SYSC_ioctl (arg32=\u0026lt;optimized out\u0026gt;, cmd=\u0026lt;optimized out\u0026gt;, fd=\u0026lt;optimized out\u0026gt;) at fs/compat_ioctl.c:1592 #2 compat_SyS_ioctl (fd=46, cmd=3224396289, arg32=3463711848) at fs/compat_ioctl.c:1544 #3 0xffffffff80201a69 in do_syscall_32_irqs_on (regs=\u0026lt;optimized out\u0026gt;) at arch/x86/entry/common.c:392 #4 do_fast_syscall_32 (regs=0xffff880052e33f58) at arch/x86/entry/common.c:459 #5 0xffffffff80941c75 in entry_SYSENTER_compat () at arch/x86/entry/entry_64_compat.S:126 #6 0x0000000000000000 in ?? () frame 2 compat_SyS_ioctl对应COMPAT_SYSCALL_DEFINE3(ioctl, \u0026hellip;),实现和下述SYSCALL_DEFINE3类似\nSYSCALL_DEFINE3(ioctl, unsigned int, fd, unsigned int, cmd, unsigned long, arg) { int error; struct fd f = fdget(fd); if (!f.file) return -EBADF; error = security_file_ioctl(f.file, cmd, arg); if (!error) error = do_vfs_ioctl(f.file, fd, cmd, arg); fdput(f); return error; } vfs_ioctl /** * vfs_ioctl - call filesystem specific ioctl methods * @filp:\topen file to invoke ioctl method on * @cmd:\tioctl command to execute * @arg:\tcommand-specific argument for ioctl * * Invokes filesystem specific -\u0026gt;unlocked_ioctl, if one exists; otherwise * returns -ENOTTY. * * Returns 0 on success, -errno on error. */ static long vfs_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { int error = -ENOTTY; if (!filp-\u0026gt;f_op-\u0026gt;unlocked_ioctl) goto out; error = filp-\u0026gt;f_op-\u0026gt;unlocked_ioctl(filp, cmd, arg); if (error == -ENOIOCTLCMD) error = -ENOTTY; out: return error; } drivers/android/binder.c\n.unlocked_ioctl = binder_ioctl static const struct file_operations binder_fops = { .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .compat_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release, }; drivers/staging/android/ashmem.c\nashmem ashmem_fops static const struct file_operations ashmem_fops = { .owner = THIS_MODULE, .open = ashmem_open, .release = ashmem_release, .read = ashmem_read, .llseek = ashmem_llseek, .mmap = ashmem_mmap, .unlocked_ioctl = ashmem_ioctl, #ifdef CONFIG_COMPAT \t.compat_ioctl = compat_ashmem_ioctl, #endif }; static struct miscdevice ashmem_misc = { .minor = MISC_DYNAMIC_MINOR, .name = \u0026#34;ashmem\u0026#34;, .fops = \u0026amp;ashmem_fops, }; static int __init ashmem_init(void) { int ret; ashmem_area_cachep = kmem_cache_create(\u0026#34;ashmem_area_cache\u0026#34;, sizeof(struct ashmem_area), 0, 0, NULL); ashmem_range_cachep = kmem_cache_create(\u0026#34;ashmem_range_cache\u0026#34;, sizeof(struct ashmem_range), 0, 0, NULL); ret = misc_register(\u0026amp;ashmem_misc); register_shrinker(\u0026amp;ashmem_shrinker); return 0; } device_initcall(ashmem_init); fs/eventpoll.c\nepoll_wait kgdb调试堆栈 #0 ep_poll (ep=0xffff88006ac71180, events=0xcab7adb8, maxevents=16, timeout=0) at fs/eventpoll.c:1599 #1 0xffffffff8037b095 in SYSC_epoll_wait (timeout=\u0026lt;optimized out\u0026gt;, maxevents=\u0026lt;optimized out\u0026gt;, events=\u0026lt;optimized out\u0026gt;, epfd=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:2009 #2 SyS_epoll_wait (epfd=\u0026lt;optimized out\u0026gt;, events=\u0026lt;optimized out\u0026gt;, maxevents=16, timeout=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:1974 #3 0xffffffff8037b148 in SYSC_epoll_pwait (sigsetsize=\u0026lt;optimized out\u0026gt;, sigmask=\u0026lt;optimized out\u0026gt;, timeout=\u0026lt;optimized out\u0026gt;, maxevents=\u0026lt;optimized out\u0026gt;, events=\u0026lt;optimized out\u0026gt;, epfd=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:2040 #4 SyS_epoll_pwait (epfd=38, events=3401035192, maxevents=16, timeout=0, sigmask=0, sigsetsize=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:2020 #5 0xffffffff80201a69 in do_syscall_32_irqs_on (regs=\u0026lt;optimized out\u0026gt;) at arch/x86/entry/common.c:392 #6 do_fast_syscall_32 (regs=0xffff88006175bf58) at arch/x86/entry/common.c:459 #7 0xffffffff80941c75 in entry_SYSENTER_compat () at arch/x86/entry/entry_64_compat.S:126 #8 0x0000000000000000 in ?? () frame 2 SyS_epoll_wait对应下述方法:\n/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). */ SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { include/linux/fs.h\nstruct file struct file { union { struct llist_node\tfu_llist; struct rcu_head fu_rcuhead; } f_u; struct path\tf_path; struct inode\t*f_inode;\t/* cached value */ const struct file_operations\t*f_op; /* * Protects f_ep_links, f_flags. * Must not be taken from IRQ context. */ spinlock_t\tf_lock; atomic_long_t\tf_count; unsigned int f_flags; fmode_t\tf_mode; struct mutex\tf_pos_lock; loff_t\tf_pos; struct fown_struct\tf_owner; const struct cred\t*f_cred; struct file_ra_state\tf_ra; u64\tf_version; #ifdef CONFIG_SECURITY \tvoid\t*f_security; #endif \t/* needed for tty driver, and maybe others */ void\t*private_data; #ifdef CONFIG_EPOLL \t/* Used by fs/eventpoll.c to link all the hooks to this file */ struct list_head\tf_ep_links; struct list_head\tf_tfile_llink; #endif /* #ifdef CONFIG_EPOLL */\tstruct address_space\t*f_mapping; } __attribute__((aligned(4)));\t/* lest something weird decides that 2 is OK */ 参考 http://gityuan.com/2016/05/21/syscall/\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/jni/systemloadlibrary/",
	"title": "SystemLoadLibrary",
	"tags": [],
	"description": "",
	"content": "Runtime.getRuntime().load /** * Loads the native library specified by the filename argument. The filename * argument must be an absolute path name. * (for example * \u0026lt;code\u0026gt;Runtime.getRuntime().load(\u0026#34;/home/avh/lib/libX11.so\u0026#34;);\u0026lt;/code\u0026gt;). */ public void load(String filename) { load0(VMStack.getStackClass1(), filename); } synchronized void load0(Class\u0026lt;?\u0026gt; fromClass, String filename) { if (!(new File(filename).isAbsolute())) { throw new UnsatisfiedLinkError(\u0026#34;Expecting an absolute path of the library: \u0026#34; + filename); } String error = nativeLoad(filename, fromClass.getClassLoader()); if (error != null) { throw new UnsatisfiedLinkError(error); } } java/lang/System.java\nSystem.loadLibrary /** * Loads the native library specified by the \u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; * argument. The \u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; argument must not contain any platform * specific prefix, file extension or path. If a native library * called \u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; is statically linked with the VM, then the * JNI_OnLoad_\u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; function exported by the library is invoked. * See the JNI Specification for more details. * * Otherwise, the libname argument is loaded from a system library * location and mapped to a native library image in an implementation- * dependent manner. **/ public static void loadLibrary(String libname) { Runtime.getRuntime().loadLibrary0(VMStack.getCallingClassLoader(), libname); } java/lang/Runtime.java\nsynchronized void loadLibrary0(ClassLoader loader, String libname) { String libraryName = libname; if (loader != null) { String filename = loader.findLibrary(libraryName); if (filename == null) { // It\u0026#39;s not necessarily true that the ClassLoader used  // System.mapLibraryName, but the default setup does, and it\u0026#39;s  // misleading to say we didn\u0026#39;t find \u0026#34;libMyLibrary.so\u0026#34; when we  // actually searched for \u0026#34;liblibMyLibrary.so.so\u0026#34;.  throw new UnsatisfiedLinkError(loader + \u0026#34; couldn\u0026#39;t find \\\u0026#34;\u0026#34; + System.mapLibraryName(libraryName) + \u0026#34;\\\u0026#34;\u0026#34;); } String error = nativeLoad(filename, loader); if (error != null) { throw new UnsatisfiedLinkError(error); } return; } String filename = System.mapLibraryName(libraryName); List\u0026lt;String\u0026gt; candidates = new ArrayList\u0026lt;String\u0026gt;(); String lastError = null; for (String directory : getLibPaths()) {//getLibPaths return /system/lib/  String candidate = directory + filename; candidates.add(candidate); if (IoUtils.canOpenReadOnly(candidate)) { String error = nativeLoad(candidate, loader); if (error == null) { return; // We successfully loaded the library. Job done.  } lastError = error; } } if (lastError != null) { throw new UnsatisfiedLinkError(lastError); } throw new UnsatisfiedLinkError(\u0026#34;Library \u0026#34; + libraryName + \u0026#34; not found; tried \u0026#34; + candidates); } BaseDexClassLoader.findLibrary @Override public String findLibrary(String name) { return pathList.findLibrary(name); } DexPathList.findLibrary /** * Finds the named native code library on any of the library * directories pointed at by this instance. This will find the * one in the earliest listed directory, ignoring any that are not * readable regular files. * * @return the complete path to the library or {@code null} if no * library was found */ public String findLibrary(String libraryName) { String fileName = System.mapLibraryName(libraryName);//xxx--\u0026gt;libxxx.so  //[0] --\u0026gt; directory \u0026#34;/data/app/com.example.myapplication-sj3RwTZhmeZrfbRZIori-w==/lib/x86\u0026#34;  //[1] --\u0026gt; zip file \u0026#34;/data/app/com.example.myapplication-sj3RwTZhmeZrfbRZIori-w==/base.apk\u0026#34;, dir \u0026#34;lib/x86\u0026#34;  //[2] --\u0026gt; directory \u0026#34;/system/lib\u0026#34;;  //[3] --\u0026gt; directory \u0026#34;/vendor/lib\u0026#34;  for (NativeLibraryElement element : nativeLibraryPathElements) { String path = element.findNativeLibrary(fileName); if (path != null) { return path; } } return null; } NativeLibraryElement.findNativeLibrary /** * Element of the native library path */ /*package*/ static class NativeLibraryElement { /** A file denoting a directory or zip file. */ private final File path; /** If path denotes a zip file, this denotes a base path inside the zip.*/ private final String zipDir; private ClassPathURLStreamHandler urlHandler; private boolean initialized; public String findNativeLibrary(String name) { maybeInit(); if (zipDir == null) { String entryPath = new File(path, name).getPath();// /data/app/com.example.myapplication-sj3RwTZhmeZrfbRZIori-w==/lib/x86/libxhcore.so  if (IoUtils.canOpenReadOnly(entryPath)) { return entryPath; } } else if (urlHandler != null) { // Having a urlHandler means the element has a zip file.  // In this case Android supports loading the library iff  // it is stored in the zip uncompressed.  String entryName = zipDir + \u0026#39;/\u0026#39; + name; if (urlHandler.isEntryStored(entryName)) { return path.getPath() + zipSeparator + entryName; } } return null; } } //IoUtils /** * Do not use. This is for System.loadLibrary use only. * * Checks whether {@code path} can be opened read-only. Similar to File.exists, but doesn\u0026#39;t * require read permission on the parent, so it\u0026#39;ll work in more cases, and allow you to * remove read permission from more directories. Everyone else should just open(2) and then * use the fd, but the loadLibrary API is broken by its need to ask ClassLoaders where to * find a .so rather than just calling dlopen(3). */ public static boolean canOpenReadOnly(String path) { try { // Use open(2) rather than stat(2) so we require fewer permissions. http://b/6485312.  FileDescriptor fd = Libcore.os.open(path, O_RDONLY, 0); Libcore.os.close(fd); return true; } catch (ErrnoException errnoException) { return false; } } nativeLoad private static native String nativeLoad(String filename, ClassLoader loader); libcore/ojluni/src/main/native/Runtime.c\nRuntime_nativeLoad JNIEXPORT jstring JNICALL Runtime_nativeLoad(JNIEnv* env, jclass ignored, jstring javaFilename, jobject javaLoader) { return JVM_NativeLoad(env, javaFilename, javaLoader); } art/openjdkjvm/OpenjdkJvm.cc\nJVM_NativeLoad JNIEXPORT jstring JVM_NativeLoad(JNIEnv* env, jstring javaFilename, jobject javaLoader) { ScopedUtfChars filename(env, javaFilename); if (filename.c_str() == NULL) { return NULL; } std::string error_msg; { art::JavaVMExt* vm = art::Runtime::Current()-\u0026gt;GetJavaVM(); bool success = vm-\u0026gt;LoadNativeLibrary(env, filename.c_str(), javaLoader, \u0026amp;error_msg); if (success) { return nullptr; } } // Don\u0026#39;t let a pending exception from JNI_OnLoad cause a CheckJNI issue with NewStringUTF.  env-\u0026gt;ExceptionClear(); return env-\u0026gt;NewStringUTF(error_msg.c_str()); } art/runtime/java_vm_ext.cc\nJavaVMExt::LoadNativeLibrary bool JavaVMExt::LoadNativeLibrary(JNIEnv* env, const std::string\u0026amp; path, jobject class_loader, std::string* error_msg) { // See if we\u0026#39;ve already loaded this library. If we have, and the class loader  // matches, return successfully without doing anything.  SharedLibrary* library; Thread* self = Thread::Current(); { MutexLock mu(self, *Locks::jni_libraries_lock_); library = libraries_-\u0026gt;Get(path);//libraries_ 中存储了所有已经加载了libraries的map，其中key是so全路径string，value是SharedLibrary*  } if (library != nullptr) { return xxx } // Retrieve the library path from the classloader, if necessary.  ScopedLocalRef\u0026lt;jstring\u0026gt; library_path(env, GetLibrarySearchPath(env, class_loader)); Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); const char* path_str = path.empty() ? nullptr : path.c_str(); bool needs_native_bridge = false; void* handle = android::OpenNativeLibrary(env, runtime_-\u0026gt;GetTargetSdkVersion(), path_str, class_loader, library_path.get(), \u0026amp;needs_native_bridge, error_msg); if (handle == nullptr) { VLOG(jni) \u0026lt;\u0026lt; \u0026#34;dlopen(\\\u0026#34;\u0026#34; \u0026lt;\u0026lt; path \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;, RTLD_NOW) failed: \u0026#34; \u0026lt;\u0026lt; *error_msg; return false; } bool created_library = false; { // Create SharedLibrary ahead of taking the libraries lock to maintain lock ordering.  std::unique_ptr\u0026lt;SharedLibrary\u0026gt; new_library( new SharedLibrary(env, self, path, handle, needs_native_bridge, class_loader, class_loader_allocator)); MutexLock mu(self, *Locks::jni_libraries_lock_); library = libraries_-\u0026gt;Get(path); if (library == nullptr) { // We won race to get libraries_lock.  library = new_library.release(); libraries_-\u0026gt;Put(path, library);//path为so的全路径名  created_library = true; } } bool was_successful = false; void* sym = library-\u0026gt;FindSymbol(\u0026#34;JNI_OnLoad\u0026#34;, nullptr); if (sym == nullptr) { VLOG(jni) \u0026lt;\u0026lt; \u0026#34;[No JNI_OnLoad found in \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; path \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;]\u0026#34;; was_successful = true; } else { ...... VLOG(jni) \u0026lt;\u0026lt; \u0026#34;[Calling JNI_OnLoad in \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; path \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;]\u0026#34;; typedef int (*JNI_OnLoadFn)(JavaVM*, void*); JNI_OnLoadFn jni_on_load = reinterpret_cast\u0026lt;JNI_OnLoadFn\u0026gt;(sym); int version = (*jni_on_load)(this, nullptr);//调用自定义.cpp的JNI_OnLoad method  if (version == JNI_ERR) { StringAppendF(error_msg, \u0026#34;JNI_ERR returned from JNI_OnLoad in \\\u0026#34;%s\\\u0026#34;\u0026#34;, path.c_str()); } else if (JavaVMExt::IsBadJniVersion(version)) { StringAppendF(error_msg, \u0026#34;Bad JNI version returned from JNI_OnLoad in \\\u0026#34;%s\\\u0026#34;: %d\u0026#34;, path.c_str(), version); // It\u0026#39;s unwise to call dlclose() here, but we can mark it  // as bad and ensure that future load attempts will fail.  // We don\u0026#39;t know how far JNI_OnLoad got, so there could  // be some partially-initialized stuff accessible through  // newly-registered native method calls. We could try to  // unregister them, but that doesn\u0026#39;t seem worthwhile.  } else { was_successful = true; } library-\u0026gt;SetResult(was_successful); return was_successful; } system/core/libnativeloader/native_loader.cpp\nOpenNativeLibrary void* OpenNativeLibrary(JNIEnv* env, int32_t target_sdk_version, const char* path, jobject class_loader, jstring library_path, bool* needs_native_bridge, std::string* error_msg) { #if defined(__ANDROID__)  UNUSED(target_sdk_version); if (class_loader == nullptr) { *needs_native_bridge = false; return dlopen(path, RTLD_NOW); } std::lock_guard\u0026lt;std::mutex\u0026gt; guard(g_namespaces_mutex); NativeLoaderNamespace ns; if (!g_namespaces-\u0026gt;FindNamespaceByClassLoader(env, class_loader, \u0026amp;ns)) { // This is the case where the classloader was not created by ApplicationLoaders  // In this case we create an isolated not-shared namespace for it.  if (!g_namespaces-\u0026gt;Create(env, target_sdk_version, class_loader, false /* is_shared */, false /* is_for_vendor */, library_path, nullptr, \u0026amp;ns, error_msg)) { return nullptr; } } if (ns.is_android_namespace()) { android_dlextinfo extinfo; extinfo.flags = ANDROID_DLEXT_USE_NAMESPACE; extinfo.library_namespace = ns.get_android_ns(); void* handle = android_dlopen_ext(path, RTLD_NOW, \u0026amp;extinfo); if (handle == nullptr) { *error_msg = dlerror(); } *needs_native_bridge = false; return handle; } else { void* handle = NativeBridgeLoadLibraryExt(path, RTLD_NOW, ns.get_native_bridge_ns()); if (handle == nullptr) { *error_msg = NativeBridgeGetError(); } *needs_native_bridge = true; return handle; } bool FindNamespaceByClassLoader(JNIEnv* env, jobject class_loader, NativeLoaderNamespace* ns) { auto it = std::find_if(namespaces_.begin(), namespaces_.end(), [\u0026amp;](const std::pair\u0026lt;jweak, NativeLoaderNamespace\u0026gt;\u0026amp; value) { return env-\u0026gt;IsSameObject(value.first, class_loader); }); if (it != namespaces_.end()) { if (ns != nullptr) { *ns = it-\u0026gt;second; } return true; } return false; } bool is_android_namespace() const { return native_bridge_ns_ == nullptr; } external/libcxx/include/algorithm\n// find_if template \u0026lt;class _InputIterator, class _Predicate\u0026gt; inline _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR_AFTER_CXX17 _InputIterator find_if(_InputIterator __first, _InputIterator __last, _Predicate __pred) { for (; __first != __last; ++__first) if (__pred(*__first)) break; return __first; } bionic/libdl/libdl.cpp\nandroid_dlopen_ext __attribute__((__weak__)) void* android_dlopen_ext(const char* filename, int flag, const android_dlextinfo* extinfo) { const void* caller_addr = __builtin_return_address(0); return __loader_android_dlopen_ext(filename, flag, extinfo, caller_addr); } FindSymbol // No mutator lock since dlsym may block for a while if another thread is doing dlopen. void* FindSymbol(const std::string\u0026amp; symbol_name, const char* shorty = nullptr) REQUIRES(!Locks::mutator_lock_) { return NeedsNativeBridge() ? FindSymbolWithNativeBridge(symbol_name.c_str(), shorty) : FindSymbolWithoutNativeBridge(symbol_name.c_str()); } // No mutator lock since dlsym may block for a while if another thread is doing dlopen. void* FindSymbolWithoutNativeBridge(const std::string\u0026amp; symbol_name) REQUIRES(!Locks::mutator_lock_) { CHECK(!NeedsNativeBridge()); return dlsym(handle_, symbol_name.c_str()); } bionic/libdl/libdl.cpp\ndlsym __attribute__((__weak__)) void* dlsym(void* handle, const char* symbol) { const void* caller_addr = __builtin_return_address(0); return __loader_dlsym(handle, symbol, caller_addr); } JNI_OnLoad JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM *vm, void *reserved) { } art/runtime/jni_internal.cc\nRegisterNatives static jint RegisterNatives(JNIEnv* env, jclass java_class, const JNINativeMethod* methods, jint method_count) { ScopedObjectAccess soa(env); StackHandleScope\u0026lt;1\u0026gt; hs(soa.Self()); Handle\u0026lt;mirror::Class\u0026gt; c = hs.NewHandle(soa.Decode\u0026lt;mirror::Class\u0026gt;(java_class)); for (jint i = 0; i \u0026lt; method_count; ++i) { const char* name = methods[i].name; const char* sig = methods[i].signature; const void* fnPtr = methods[i].fnPtr; bool is_fast = false; // Notes about fast JNI calls:  //  // On a normal JNI call, the calling thread usually transitions  // from the kRunnable state to the kNative state. But if the  // called native function needs to access any Java object, it  // will have to transition back to the kRunnable state.  //  // There is a cost to this double transition. For a JNI call  // that should be quick, this cost may dominate the call cost.  //  // On a fast JNI call, the calling thread avoids this double  // transition by not transitioning from kRunnable to kNative and  // stays in the kRunnable state.  //  // There are risks to using a fast JNI call because it can delay  // a response to a thread suspension request which is typically  // used for a GC root scanning, etc. If a fast JNI call takes a  // long time, it could cause longer thread suspension latency  // and GC pauses.  //  // Thus, fast JNI should be used with care. It should be used  // for a JNI call that takes a short amount of time (eg. no  // long-running loop) and does not block (eg. no locks, I/O,  // etc.)  //  // A \u0026#39;!\u0026#39; prefix in the signature in the JNINativeMethod  // indicates that it\u0026#39;s a fast JNI call and the runtime omits the  // thread state transition from kRunnable to kNative at the  // entry.  if (*sig == \u0026#39;!\u0026#39;) { is_fast = true; ++sig; } // Note: the right order is to try to find the method locally  // first, either as a direct or a virtual method. Then move to  // the parent.  ArtMethod* m = nullptr; for (ObjPtr\u0026lt;mirror::Class\u0026gt; current_class = c.Get(); current_class != nullptr; current_class = current_class-\u0026gt;GetSuperClass()) { // Search first only comparing methods which are native.  m = FindMethod\u0026lt;true\u0026gt;(current_class.Ptr(), name, sig); if (m != nullptr) { break; } // Search again comparing to all methods, to find non-native methods that match.  m = FindMethod\u0026lt;false\u0026gt;(current_class.Ptr(), name, sig); if (m != nullptr) { break; } } const void* final_function_ptr = m-\u0026gt;RegisterNative(fnPtr); } } art_method.cc\nArtMethod::RegisterNative const void* ArtMethod::RegisterNative(const void* native_method) { CHECK(IsNative()) \u0026lt;\u0026lt; PrettyMethod(); CHECK(native_method != nullptr) \u0026lt;\u0026lt; PrettyMethod(); void* new_native_method = nullptr; Runtime::Current()-\u0026gt;GetRuntimeCallbacks()-\u0026gt;RegisterNativeMethod(this, native_method, /*out*/\u0026amp;new_native_method); SetEntryPointFromJni(new_native_method); return new_native_method; } SetEntryPointFromJni void SetEntryPointFromJni(const void* entrypoint) { DCHECK(IsNative()); SetEntryPointFromJniPtrSize(entrypoint, kRuntimePointerSize); } ALWAYS_INLINE void SetEntryPointFromJniPtrSize(const void* entrypoint, PointerSize pointer_size) { SetDataPtrSize(entrypoint, pointer_size); } ALWAYS_INLINE void SetDataPtrSize(const void* data, PointerSize pointer_size) { DCHECK(IsImagePointerSize(pointer_size)); SetNativePointer(DataOffset(pointer_size), data, pointer_size);//DataOffset,对应ArtMethod的data_字段 } static MemberOffset EntryPointFromJniOffset(PointerSize pointer_size) { return DataOffset(pointer_size); } static MemberOffset DataOffset(PointerSize pointer_size) { return MemberOffset(PtrSizedFieldsOffset(pointer_size) + OFFSETOF_MEMBER( PtrSizedFields, data_) / sizeof(void*) * static_cast\u0026lt;size_t\u0026gt;(pointer_size)); } static MemberOffset EntryPointFromQuickCompiledCodeOffset(PointerSize pointer_size) { return MemberOffset(PtrSizedFieldsOffset(pointer_size) + OFFSETOF_MEMBER( PtrSizedFields, entry_point_from_quick_compiled_code_) / sizeof(void*)//对应ArtMethod的entry_point_from_quick_compiled_code_字段  * static_cast\u0026lt;size_t\u0026gt;(pointer_size)); } art/runtime/runtime_callbacks.cc\nRuntimeCallbacks::RegisterNativeMethod void RuntimeCallbacks::RegisterNativeMethod(ArtMethod* method, const void* in_cur_method, /*out*/void** new_method) { void* cur_method = const_cast\u0026lt;void*\u0026gt;(in_cur_method); *new_method = cur_method; for (MethodCallback* cb : method_callbacks_) { cb-\u0026gt;RegisterNativeMethod(method, cur_method, new_method); if (*new_method != nullptr) { cur_method = *new_method; } } } art/openjdkjvmti/ti_method.cc\nti_method.cc.RegisterNativeMethod void RegisterNativeMethod(art::ArtMethod* method, const void* cur_method, /*out*/void** new_method) OVERRIDE REQUIRES_SHARED(art::Locks::mutator_lock_) { if (event_handler-\u0026gt;IsEventEnabledAnywhere(ArtJvmtiEvent::kNativeMethodBind)) { ...... } } 参考 【Android】动态链接库so的加载原理\nhttps://github.com/KeepSafe/ReLinker\nhttps://github.com/facebook/SoLoader\njava.lang.UnsatisfiedLinkError 的解决办法\n其他 bionic/linker/linker.cpp\nlinker.cpp load_library static bool load_library(android_namespace_t* ns, LoadTask* task, LoadTaskList* load_tasks, int rtld_flags, const std::string\u0026amp; realpath, bool search_linked_namespaces) { "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/systemserversource/",
	"title": "SystemServerSource",
	"tags": [],
	"description": "",
	"content": "main /** * The main entry point from zygote. */ public static void main(String[] args) { new SystemServer().run(); } run private void run() { // The system server should never make non-oneway calls  Binder.setWarnOnBlocking(true); // Ensure binder calls into the system always run at foreground priority.  BinderInternal.disableBackgroundScheduling(true); // Increase the number of binder threads in system_server  BinderInternal.setMaxThreads(sMaxBinderThreads); // Prepare the main looper thread (this thread).  android.os.Process.setThreadPriority( android.os.Process.THREAD_PRIORITY_FOREGROUND); android.os.Process.setCanSelfBackground(false); Looper.prepareMainLooper(); startBootstrapServices(); startCoreServices(); startOtherServices(); // Loop forever.  Looper.loop(); throw new RuntimeException(\u0026#34;Main thread loop unexpectedly exited\u0026#34;); } startOtherServices private void startOtherServices() { traceBeginAndSlog(\u0026#34;StartInputManagerService\u0026#34;); inputManager = new InputManagerService(context); traceEnd(); traceBeginAndSlog(\u0026#34;StartWindowManagerService\u0026#34;); // WMS needs sensor service ready  ConcurrentUtils.waitForFutureNoInterrupt(mSensorServiceStart, START_SENSOR_SERVICE); mSensorServiceStart = null; wm = WindowManagerService.main(context, inputManager, mFactoryTestMode != FactoryTest.FACTORY_TEST_LOW_LEVEL, !mFirstBoot, mOnlyCore, new PhoneWindowManager()); ServiceManager.addService(Context.WINDOW_SERVICE, wm, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL | DUMP_FLAG_PROTO); ServiceManager.addService(Context.INPUT_SERVICE, inputManager, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL); } "
},
{
	"uri": "https://huanle19891345.github.io/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/thread/",
	"title": "thread",
	"tags": [],
	"description": "",
	"content": "thread 探索总结thread知识\n StackTraceElement     ThreadState     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/handler/threadlocal/",
	"title": "ThreadLocal",
	"tags": [],
	"description": "",
	"content": "ThreadLocal模型 graph LR thread--\u0026gt;threadLocalMap threadLocalMap--\u0026gt;entry1 threadLocalMap--\u0026gt;entry2 threadLocalMap--\u0026gt;entryLooper threadLocalMap--\u0026gt;entryxxx entry1--\u0026gt;key=threadlocal1,value=T1 entry2--\u0026gt;key=threadlocal2,value=T2 entryLooper--\u0026gt;LooperEntry(key=threadlocal_Looper,value=Looper) LooperEntry--\u0026gt;MessageQueue  线性探测解决hash冲突 超过默认长度(16)的2/3时rehash减少hash冲突，扩容一倍 threadlocal作为key保存在entry中时是WeakReference，在被回收时清除记录，因此需要外部定义TheadLocal实例的地方配置为static，否则在外部回收threadlocal时，threadlocalmap中的entry也会被清理掉 lazy模式，只有添加第一个 元素时才通过createMap创建ThreadLocalMap  Thread /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; /* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ThreadLocal threadLocalHashCode public class ThreadLocal\u0026lt;T\u0026gt; { /** * ThreadLocals rely on per-thread linear-probe hash maps attached * to each thread (Thread.threadLocals and * inheritableThreadLocals). The ThreadLocal objects act as keys, * searched via threadLocalHashCode. This is a custom hash code * (useful only within ThreadLocalMaps) that eliminates collisions * in the common case where consecutively constructed ThreadLocals * are used by the same threads, while remaining well-behaved in * less common cases. */ private final int threadLocalHashCode = nextHashCode(); private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() { return nextHashCode.getAndAdd(HASH_INCREMENT); } set /** * Sets the current thread\u0026#39;s copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the {@link #initialValue} * method to set the values of thread-locals. * * @param value the value to be stored in the current thread\u0026#39;s copy of * this thread-local. */ public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } get /** * Returns the value in the current thread\u0026#39;s copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the {@link #initialValue} method. * * @return the current thread\u0026#39;s value of this thread-local */ public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; return result; } } return setInitialValue(); } setInitialValue private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } initialValue /** * Returns the current thread\u0026#39;s \u0026#34;initial value\u0026#34; for this * thread-local variable. This method will be invoked the first * time a thread accesses the variable with the {@link #get} * method, unless the thread previously invoked the {@link #set} * method, in which case the {@code initialValue} method will not * be invoked for the thread. Normally, this method is invoked at * most once per thread, but it may be invoked again in case of * subsequent invocations of {@link #remove} followed by {@link #get}. * * \u0026lt;p\u0026gt;This implementation simply returns {@code null}; if the * programmer desires thread-local variables to have an initial * value other than {@code null}, {@code ThreadLocal} must be * subclassed, and this method overridden. Typically, an * anonymous inner class will be used. * * @return the initial value for this thread-local */ protected T initialValue() { return null; } createMap void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } ThreadLocalMap static class ThreadLocalMap { /** Construct a new map initially containing (firstKey, firstValue). * ThreadLocalMaps are constructed lazily, so we only create * one when we have at least one entry to put in it. */ ThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode \u0026amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); } } Entry /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as \u0026#34;stale entries\u0026#34; in the code that follows. */ static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } table /** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * Set the resize threshold to maintain at worst a 2/3 load factor. */ private void setThreshold(int len) { threshold = len * 2 / 3; } getEntry /** * Get the entry associated with key. This method * itself handles only the fast path: a direct hit of existing * key. It otherwise relays to getEntryAfterMiss. This is * designed to maximize performance for direct hits, in part * by making this method readily inlinable. * * @param key the thread local object * @return the entry associated with key, or null if no such */ private Entry getEntry(ThreadLocal\u0026lt;?\u0026gt; key) { int i = key.threadLocalHashCode \u0026amp; (table.length - 1); Entry e = table[i]; if (e != null \u0026amp;\u0026amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); } getEntryAfterMiss /** * Version of getEntry method for use when key is not found in * its direct hash slot. * * @param key the thread local object * @param i the table index for key\u0026#39;s hash code * @param e the entry at table[i] * @return the entry associated with key, or null if no such */ private Entry getEntryAfterMiss(ThreadLocal\u0026lt;?\u0026gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null; } nextIndex /** * Increment i modulo len. */ private static int nextIndex(int i, int len) { return ((i + 1 \u0026lt; len) ? i + 1 : 0); } set /** * Set the value associated with key. * * @param key the thread local object * @param value the value to be set */ private void set(ThreadLocal\u0026lt;?\u0026gt; key, Object value) { // We don\u0026#39;t use a fast path as with get() because it is at  // least as common to use set() to create new entries as  // it is to replace existing ones, in which case, a fast  // path would fail more often than not.  Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode \u0026amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) \u0026amp;\u0026amp; sz \u0026gt;= threshold) rehash(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/thread/threadstate/",
	"title": "ThreadState",
	"tags": [],
	"description": "",
	"content": "浅析android 线程状态 java的6种线程状态定义在/java/lang/Thread.java中:\nhttps://docs.oracle.com/javase/7/docs/api/java/lang/Thread.State.html\n//Thread.java public class Thread implements Runnable { ... public enum State { /** * The thread has been created, but has never been started. */ NEW, /** * The thread may be run. */ RUNNABLE, /** * The thread is blocked and waiting for a lock. */ BLOCKED, /** * The thread is waiting. */ WAITING, /** * The thread is waiting for a specified amount of time. */ TIMED_WAITING, /** * The thread has been terminated. */ TERMINATED } ... } 在VMThread.java中, 可以看到下面的代码， native thread有10种状态, 对应着java thread的6种状态.\n//VMThread.java  /** * Holds a mapping from native Thread statuses to Java one. Required for * translating back the result of getStatus(). */ static final Thread.State[] STATE_MAP = new Thread.State[] { Thread.State.TERMINATED, // ZOMBIE  Thread.State.RUNNABLE, // RUNNING  Thread.State.TIMED_WAITING, // TIMED_WAIT  Thread.State.BLOCKED, // MONITOR  Thread.State.WAITING, // WAIT  Thread.State.NEW, // INITIALIZING  Thread.State.NEW, // STARTING  Thread.State.RUNNABLE, // NATIVE  Thread.State.WAITING, // VMWAIT  Thread.State.RUNNABLE // SUSPENDED  }; 在之前的文章中， 已经分析了android thread的底层实现其实就是linux下的pthread. 我们再看一下native层的Thread.cpp, 有这段代码:\nconst char* dvmGetThreadStatusStr(ThreadStatus status) { switch (status) { case THREAD_ZOMBIE: return \u0026#34;ZOMBIE\u0026#34;; case THREAD_RUNNING: return \u0026#34;RUNNABLE\u0026#34;; case THREAD_TIMED_WAIT: return \u0026#34;TIMED_WAIT\u0026#34;; case THREAD_MONITOR: return \u0026#34;MONITOR\u0026#34;; case THREAD_WAIT: return \u0026#34;WAIT\u0026#34;; case THREAD_INITIALIZING: return \u0026#34;INITIALIZING\u0026#34;; case THREAD_STARTING: return \u0026#34;STARTING\u0026#34;; case THREAD_NATIVE: return \u0026#34;NATIVE\u0026#34;; case THREAD_VMWAIT: return \u0026#34;VMWAIT\u0026#34;; case THREAD_SUSPENDED: return \u0026#34;SUSPENDED\u0026#34;; default: return \u0026#34;UNKNOWN\u0026#34;; } } 实际上， 写入traces.txt中的线程状态值就是这个函数返回的字符串. 所以我们就知道了如下的事实:\n\u0026#34;main\u0026#34; prio=5 tid=1 MONITOR 其实就是java中的BLOCKED状态. \u0026#34;Timer-0\u0026#34; daemon prio=5 tid=23 TIMED_WAIT 其实就是java中的TIMED_WAITING状态 \u0026#34;QMThreadPool #3\u0026#34; daemon prio=3 tid=22 WAIT 其实就是java中的WAITING状态 \u0026#34;WifiManager\u0026#34; prio=5 tid=20 NATIVE 其实就是java中的RUNNABLE状态 \u0026#34;Signal Catcher\u0026#34; daemon prio=5 tid=3 RUNNABLE 其实就是java中的RUNNABLE状态 "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/touch/touch/",
	"title": "Touch",
	"tags": [],
	"description": "",
	"content": "原理图 graph TB PointerDownEvent--\u0026gt;|hitTest|HitTestResult--\u0026gt;HitTestTarget1 HitTestResult--\u0026gt;|handleEvent|RawGestureDetectorState._handlePointerDown--\u0026gt;|addPointer_event|gestureRecognizer1 HitTestResult--\u0026gt;HitTestTargetXxx HitTestResult--\u0026gt;|handleEvent|GestureBinding.handleEvent--\u0026gt;pointerRouter.route_event GestureBinding.handleEvent--\u0026gt;|Down?|gestureArena.close GestureBinding.handleEvent--\u0026gt;|Up?|gestureArena.sweep RawGestureDetectorState._handlePointerDown--\u0026gt;|addPointer_event|gestureRecognizerXxx--\u0026gt;pointerRouter.addRoute gestureRecognizerXxx--\u0026gt;gestureArena.add PointerOtherEvent--\u0026gt;|dispatchEvent|HitTestResult 类设计 GestureBinding.initInstances /// A binding for the gesture subsystem. //mixin GestureBinding on BindingBase implements HitTestable, HitTestDispatcher, HitTestTarget @override void initInstances() { super.initInstances(); _instance = this; window.onPointerDataPacket = _handlePointerDataPacket; } GestureBinding._handlePointerDataPacket void _handlePointerDataPacket(ui.PointerDataPacket packet) { // We convert pointer data to logical pixels so that e.g. the touch slop can be  // defined in a device-independent manner.  _pendingPointerEvents.addAll(PointerEventConverter.expand(packet.data, window.devicePixelRatio)); if (!locked) _flushPointerEventQueue(); } void _flushPointerEventQueue() { assert(!locked); while (_pendingPointerEvents.isNotEmpty) _handlePointerEvent(_pendingPointerEvents.removeFirst()); } GestureBinding._handlePointerEvent void _handlePointerEvent(PointerEvent event) { HitTestResult hitTestResult; if (event is PointerDownEvent || event is PointerSignalEvent) { assert(!_hitTests.containsKey(event.pointer)); hitTestResult = HitTestResult(); hitTest(hitTestResult, event.position);//main  if (event is PointerDownEvent) { _hitTests[event.pointer] = hitTestResult; } } else if (event is PointerUpEvent || event is PointerCancelEvent) { hitTestResult = _hitTests.remove(event.pointer); } else if (event.down) { // Because events that occur with the pointer down (like  // PointerMoveEvents) should be dispatched to the same place that their  // initial PointerDownEvent was, we want to re-use the path we found when  // the pointer went down, rather than do hit detection each time we get  // such an event.  hitTestResult = _hitTests[event.pointer]; } if (hitTestResult != null || event is PointerHoverEvent || event is PointerAddedEvent || event is PointerRemovedEvent) { dispatchEvent(event, hitTestResult);//main  } hitTest RendererBinding.hitTest //GestureBinding /// Determine which [HitTestTarget] objects are located at a given position.  @override // from HitTestable  void hitTest(HitTestResult result, Offset position) { result.add(HitTestEntry(this)); } //mixin RendererBinding on BindingBase, ServicesBinding, SchedulerBinding, GestureBinding, SemanticsBinding, HitTestable { @override void hitTest(HitTestResult result, Offset position) { assert(renderView != null); renderView.hitTest(result, position: position); super.hitTest(result, position); } RenderView.hitTest //class RenderView extends RenderObject with RenderObjectWithChildMixin\u0026lt;RenderBox\u0026gt; { /// Determines the set of render objects located at the given position. bool hitTest(HitTestResult result, { Offset position }) { if (child != null) child.hitTest(BoxHitTestResult.wrap(result), position: position); result.add(HitTestEntry(this)); return true; } RenderBox.hitTest //RenderBox /// Determines the set of render objects located at the given position.  bool hitTest(BoxHitTestResult result, { @required Offset position }) { if (_size.contains(position)) { if (hitTestChildren(result, position: position) || hitTestSelf(position)) { result.add(BoxHitTestEntry(this, position)); return true; } } return false; /// Override this method to check whether any children are located at the  /// given position.  /// Used by [hitTest]. If you override [hitTest] and do not call this  /// function, then you don\u0026#39;t need to implement this function. @protected bool hitTestChildren(BoxHitTestResult result, { Offset position }) =\u0026gt; false; /// Override this method if this render object can be hit even if its  /// children were not hit.  /// The caller is responsible for transforming [position] from global  /// coordinates to its location relative to the origin of this [RenderBox].  /// This [RenderBox] is responsible for checking whether the given position is  /// within its bounds.  /// Used by [hitTest]. If you override [hitTest] and do not call this  /// function, then you don\u0026#39;t need to implement this function.  @protected bool hitTestSelf(Offset position) =\u0026gt; false; dispatchEvent /// Dispatch an event to a hit test result\u0026#39;s path. @override // from HitTestDispatcher  void dispatchEvent(PointerEvent event, HitTestResult hitTestResult) { // No hit test information implies that this is a hover or pointer  // add/remove event.  if (hitTestResult == null) { pointerRouter.route(event); return; } for (HitTestEntry entry in hitTestResult.path) { try { entry.target.handleEvent(event.transformed(entry.transform), entry);//main  } catch (exception, stack) { } } } handleEvent RenderPointerListener.handleEvent renderpointerlistener\nGestureBinding.handleEvent @override // from HitTestTarget  void handleEvent(PointerEvent event, HitTestEntry entry) { pointerRouter.route(event); if (event is PointerDownEvent) { gestureArena.close(event.pointer); } else if (event is PointerUpEvent) { gestureArena.sweep(event.pointer); } else if (event is PointerSignalEvent) { pointerSignalResolver.resolve(event); } } PointerRouter.route(event) /// A routing table for [PointerEvent] events.  /// Calls the routes registered for this pointer event.  ///  /// Routes are called in the order in which they were added to the  /// PointerRouter object.  void route(PointerEvent event) { final Map\u0026lt;PointerRoute, Matrix4?\u0026gt;? routes = _routeMap[event.pointer]; final Map\u0026lt;PointerRoute, Matrix4?\u0026gt; copiedGlobalRoutes = Map\u0026lt;PointerRoute, Matrix4?\u0026gt;.from(_globalRoutes); if (routes != null) { _dispatchEventToRoutes( event, routes, Map\u0026lt;PointerRoute, Matrix4?\u0026gt;.from(routes), ); } _dispatchEventToRoutes(event, _globalRoutes, copiedGlobalRoutes); } gestureArena.close /// Prevents new members from entering the arena.  /// Called after the framework has finished dispatching the pointer down event.  void close(int pointer) { final _GestureArena state = _arenas[pointer]; if (state == null) return; // This arena either never existed or has been resolved.  state.isOpen = false; _tryToResolveArena(pointer, state); } void _tryToResolveArena(int pointer, _GestureArena state) { assert(_arenas[pointer] == state); assert(!state.isOpen); if (state.members.length == 1) { scheduleMicrotask(() =\u0026gt; _resolveByDefault(pointer, state)); } else if (state.members.isEmpty) { _arenas.remove(pointer); } else if (state.eagerWinner != null) { _resolveInFavorOf(pointer, state, state.eagerWinner); } } void _resolveByDefault(int pointer, _GestureArena state) { if (!_arenas.containsKey(pointer)) return; // Already resolved earlier.  final List\u0026lt;GestureArenaMember\u0026gt; members = state.members; assert(members.length == 1); _arenas.remove(pointer); state.members.first.acceptGesture(pointer); } void _resolveInFavorOf(int pointer, _GestureArena state, GestureArenaMember member) { _arenas.remove(pointer); for (GestureArenaMember rejectedMember in state.members) { if (rejectedMember != member) rejectedMember.rejectGesture(pointer); } member.acceptGesture(pointer); } gestureArena.sweep /// Forces resolution of the arena, giving the win to the first member.  ///  /// Sweep is typically after all the other processing for a [PointerUpEvent]  /// have taken place. It ensures that multiple passive gestures do not cause a  /// stalemate that prevents the user from interacting with the app.  ///  /// Recognizers that wish to delay resolving an arena past [PointerUpEvent]  /// should call [hold] to delay sweep until [release] is called.  void sweep(int pointer) { final _GestureArena? state = _arenas[pointer]; if (state == null) return; // This arena either never existed or has been resolved.  assert(!state.isOpen); if (state.isHeld) { state.hasPendingSweep = true; assert(_debugLogDiagnostic(pointer, \u0026#39;Delaying sweep\u0026#39;, state)); return; // This arena is being held for a long-lived member.  } _arenas.remove(pointer); if (state.members.isNotEmpty) { // First member wins.  assert(_debugLogDiagnostic(pointer, \u0026#39;Winner: ${state.members.first}\u0026#39;)); state.members.first.acceptGesture(pointer); // Give all the other members the bad news.  for (int i = 1; i \u0026lt; state.members.length; i++) state.members[i].rejectGesture(pointer); } } GestureDetector /// A widget that detects gestures.  /// If this widget has a child, it defers to that child for its sizing behavior. /// If it does not have a child, it grows to fit the parent instead.  GestureDetector extends StatelessWidget { /// The widget below this widget in the tree.  final Widget child; GestureDetector({ Key key, this.child, this.onTapDown, this.onTapUp, this.onTap, this.onTapCancel, this.onSecondaryTapDown, this.onSecondaryTapUp, this.onSecondaryTapCancel, this.onDoubleTap, this.onLongPress, this.onLongPressStart, this.onLongPressMoveUpdate, this.onLongPressUp, this.onLongPressEnd, this.onVerticalDragDown, this.onVerticalDragStart, this.onVerticalDragUpdate, this.onVerticalDragEnd, this.onVerticalDragCancel, this.onHorizontalDragDown, this.onHorizontalDragStart, this.onHorizontalDragUpdate, this.onHorizontalDragEnd, this.onHorizontalDragCancel, this.onForcePressStart, this.onForcePressPeak, this.onForcePressUpdate, this.onForcePressEnd, this.onPanDown, this.onPanStart, this.onPanUpdate, this.onPanEnd, this.onPanCancel, this.onScaleStart, this.onScaleUpdate, this.onScaleEnd, this.behavior, this.excludeFromSemantics = false, this.dragStartBehavior = DragStartBehavior.start, }) } @override Widget build(BuildContext context) { final Map\u0026lt;Type, GestureRecognizerFactory\u0026gt; gestures = \u0026lt;Type, GestureRecognizerFactory\u0026gt;{}; if ( onTapDown != null || onTapUp != null || onTap != null || onTapCancel != null || onSecondaryTapDown != null || onSecondaryTapUp != null || onSecondaryTapCancel != null ) { gestures[TapGestureRecognizer] = GestureRecognizerFactoryWithHandlers\u0026lt;TapGestureRecognizer\u0026gt;(//main  () =\u0026gt; TapGestureRecognizer(debugOwner: this), (TapGestureRecognizer instance) { instance ..onTapDown = onTapDown ..onTapUp = onTapUp ..onTap = onTap ..onTapCancel = onTapCancel ..onSecondaryTapDown = onSecondaryTapDown ..onSecondaryTapUp = onSecondaryTapUp ..onSecondaryTapCancel = onSecondaryTapCancel; }, ); } ...... return RawGestureDetector( gestures: gestures, behavior: behavior, excludeFromSemantics: excludeFromSemantics, child: child, ); GestureRecognizerFactoryWithHandlers /// Factory for creating gesture recognizers.  ///  /// `T` is the type of gesture recognizer this class manages.  ///  /// Used by [RawGestureDetector.gestures].  GestureRecognizerFactory\u0026lt;T extends GestureRecognizer\u0026gt; { /// Must return an instance of T.  T constructor(); } /// Factory for creating gesture recognizers that delegates to callbacks. GestureRecognizerFactoryWithHandlers\u0026lt;T extends GestureRecognizer\u0026gt; { /// Signature for closures that implement [GestureRecognizerFactory.constructor].  typedef GestureRecognizerFactoryConstructor\u0026lt;T extends GestureRecognizer\u0026gt; = T Function(); /// Signature for closures that implement [GestureRecognizerFactory.initializer].  typedef GestureRecognizerFactoryInitializer\u0026lt;T extends GestureRecognizer\u0026gt; = void Function(T instance); /// Creates a gesture recognizer factory with the given callbacks.  ///  /// The arguments must not be null.  const GestureRecognizerFactoryWithHandlers(this._constructor, this._initializer) final GestureRecognizerFactoryConstructor\u0026lt;T\u0026gt; _constructor; final GestureRecognizerFactoryInitializer\u0026lt;T\u0026gt; _initializer; @override T constructor() =\u0026gt; _constructor(); @override void initializer(T instance) =\u0026gt; _initializer(instance); } RawGestureDetector /// A widget that detects gestures described by the given gesture\u2028/// factories. RawGestureDetector extends StatefulWidget { /// The gestures that this widget will attempt to recognize.  ///  /// This should be a map from [GestureRecognizer] subclasses to  /// [GestureRecognizerFactory] subclasses specialized with the same type.  final Map\u0026lt;Type, GestureRecognizerFactory\u0026gt; gestures; /// The widget below this widget in the tree.  final Widget child; @override RawGestureDetectorState createState() =\u0026gt; RawGestureDetectorState(); } RawGestureDetectorState RawGestureDetectorState extends State\u0026lt;RawGestureDetector\u0026gt; { @override Widget build(BuildContext context) { Widget result = Listener(//main  onPointerDown: _handlePointerDown, behavior: widget.behavior ?? _defaultBehavior, child: widget.child, ); if (!widget.excludeFromSemantics) result = _GestureSemantics( child: result, assignSemantics: _updateSemanticsForRenderObject, ); return result; } } _handlePointerDown void _handlePointerDown(PointerDownEvent event) { assert(_recognizers != null); for (GestureRecognizer recognizer in _recognizers.values) recognizer.addPointer(event); } Listener /// A widget that calls callbacks in response to common pointer events.  /// Rather than listening for raw pointer events, consider listening for  /// higher-level gestures using [GestureDetector].  /// If it has a child, this widget defers to the child for sizing behavior. If  /// it does not have a child, it grows to fit the parent instead. Listener extends StatelessWidget { const Listener({ Key key, this.onPointerDown, this.onPointerMove, this.onPointerUp, this.onPointerCancel, this.onPointerSignal, this.behavior = HitTestBehavior.deferToChild, Widget child, }) @override Widget build(BuildContext context) { Widget result = _child; result = _PointerListener( onPointerDown: onPointerDown, onPointerUp: onPointerUp, onPointerMove: onPointerMove, onPointerCancel: onPointerCancel, onPointerSignal: onPointerSignal, behavior: behavior, child: result, ); return result; } _PointerListener _PointerListener extends SingleChildRenderObjectWidget { final PointerDownEventListener onPointerDown; final PointerMoveEventListener onPointerMove; final PointerUpEventListener onPointerUp; final PointerCancelEventListener onPointerCancel; final PointerSignalEventListener onPointerSignal; final HitTestBehavior behavior; @override RenderPointerListener createRenderObject(BuildContext context) { return RenderPointerListener( onPointerDown: onPointerDown, onPointerMove: onPointerMove, onPointerUp: onPointerUp, onPointerCancel: onPointerCancel, onPointerSignal: onPointerSignal, behavior: behavior, ); } } RenderPointerListener /// Calls callbacks in response to common pointer events.  /// It responds to events that can construct gestures, such as when the  /// pointer is pressed, moved, then released or canceled.  RenderPointerListener extends RenderProxyBoxWithHitTestBehavior { /// Called when a pointer comes into contact with the screen (for touch  /// pointers), or has its button pressed (for mouse pointers) at this widget\u0026#39;s  /// location.  PointerDownEventListener onPointerDown; /// Called when a pointer that triggered an [onPointerDown] changes position.  PointerMoveEventListener onPointerMove; /// Called when a pointer that triggered an [onPointerDown] is no longer in  /// contact with the screen.  PointerUpEventListener onPointerUp; /// Called when the input from a pointer that triggered an [onPointerDown] is  /// no longer directed towards this receiver.  PointerCancelEventListener onPointerCancel; /// Called when a pointer signal occurs over this object.  PointerSignalEventListener onPointerSignal; @override void handleEvent(PointerEvent event, HitTestEntry entry) { assert(debugHandleEvent(event, entry)); if (onPointerDown != null \u0026amp;\u0026amp; event is PointerDownEvent) return onPointerDown(event); if (onPointerMove != null \u0026amp;\u0026amp; event is PointerMoveEvent) return onPointerMove(event); if (onPointerUp != null \u0026amp;\u0026amp; event is PointerUpEvent) return onPointerUp(event); if (onPointerCancel != null \u0026amp;\u0026amp; event is PointerCancelEvent) return onPointerCancel(event); if (onPointerSignal != null \u0026amp;\u0026amp; event is PointerSignalEvent) return onPointerSignal(event); } } _handlepointerdown\nGestureRecognizer addPointer_event /// Registers a new pointer that might be relevant to this gesture detector. void addPointer(PointerDownEvent event) { _pointerToKind[event.pointer] = event.kind; if (isPointerAllowed(event)) { addAllowedPointer(event);//main  } else { handleNonAllowedPointer(event); } } /// Registers a new pointer that\u0026#39;s been checked to be allowed by this gesture recognizer.  ///  /// Subclasses of [GestureRecognizer] are supposed to override this method  /// instead of [addPointer] because [addPointer] will be called for each  /// pointer being added while [addAllowedPointer] is only called for pointers  /// that are allowed by this recognizer.  @protected void addAllowedPointer(PointerDownEvent event) { } PrimaryPointerGestureRecognizer.addAllowedPointer //PrimaryPointerGestureRecognizer  @override void addAllowedPointer(PointerDownEvent event) { startTrackingPointer(event.pointer, event.transform);//main  if (state == GestureRecognizerState.ready) { state = GestureRecognizerState.possible; primaryPointer = event.pointer; initialPosition = OffsetPair(local: event.localPosition, global: event.position); if (deadline != null) _timer = Timer(deadline, () =\u0026gt; didExceedDeadlineWithEvent(event)); } } OneSequenceGestureRecognizer.startTrackingPointer /// Causes events related to the given pointer ID to be routed to this recognizer. @protected void startTrackingPointer(int pointer, [Matrix4 transform]) { //事件传递的最后一站其实就是GestureBinding.handleEvent方法，到最后就是调用pointer.route方法路由事件，所以还要调用GestureRecognizer的handleEvent方法。  GestureBinding.instance.pointerRouter.addRoute(pointer, handleEvent, transform);//main  _trackedPointers.add(pointer); assert(!_entries.containsValue(pointer)); _entries[pointer] = _addPointerToArena(pointer);//main  } /// Called when a pointer event is routed to this recognizer.  @protected void handleEvent(PointerEvent event); pointerRouter.addRoute /// Adds a route to the routing table.  ///  /// Whenever this object routes a [PointerEvent] corresponding to  /// pointer, call route.  ///  /// Routes added reentrantly within [PointerRouter.route] will take effect when  /// routing the next event.  void addRoute(int pointer, PointerRoute route, [Matrix4? transform]) { final Map\u0026lt;PointerRoute, Matrix4?\u0026gt; routes = _routeMap.putIfAbsent( pointer, () =\u0026gt; \u0026lt;PointerRoute, Matrix4?\u0026gt;{}, ); assert(!routes.containsKey(route)); routes[route] = transform; } OneSequenceGestureRecognizer._addPointerToArena GestureArenaEntry _addPointerToArena(int pointer) { if (_team != null) return _team.add(pointer, this); return GestureBinding.instance.gestureArena.add(pointer, this);//main  } GestureArenaManager add /// The first member to accept or the last member to not reject wins. GestureArenaManager { //每组point操作(一次down-\u0026gt;move-\u0026gt;up)对应一个竞技场地_GestureArena，  //每个竞技场地_GestureArena对应多个Recognizer同场竞技  final Map\u0026lt;int, _GestureArena\u0026gt; _arenas = \u0026lt;int, _GestureArena\u0026gt;{}; /// Adds a new member (e.g., gesture recognizer) to the arena.  GestureArenaEntry add(int pointer, GestureArenaMember member) { final _GestureArena state = _arenas.putIfAbsent(pointer, () { return _GestureArena();//main  }); state.add(member); return GestureArenaEntry._(this, pointer, member);//main  } } 参考 HitTestResult /// The result of performing a hit test. /// An unmodifiable list of [HitTestEntry] objects recorded during the hit test.  ///  /// The first entry in the path is the most specific, typically the one at  /// the leaf of tree being hit tested. Event propagation starts with the most  /// specific (i.e., first) entry and proceeds in order through the path.  Iterable\u0026lt;HitTestEntry\u0026gt; get path =\u0026gt; _path; final List\u0026lt;HitTestEntry\u0026gt; _path; add /// Add a [HitTestEntry] to the path.  ///  /// The new entry is added at the end of the path, which means entries should  /// be added in order from most specific to least specific, typically during an  /// upward walk of the tree being hit tested.  void add(HitTestEntry entry) { _path.add(entry); } HitTestEntry /// Data collected during a hit test about a specific [HitTestTarget].  ///  /// Subclass this object to pass additional information from the hit test phase  /// to the event propagation phase.  /// Creates a hit test entry.  HitTestEntry(this.target); /// The [HitTestTarget] encountered during the hit test.  final HitTestTarget target; HitTestTarget /// An object that can handle events. HitTestTarget { /// Override this method to receive events.  void handleEvent(PointerEvent event, HitTestEntry entry); } PointerEvent.pointer abstract class PointerEvent with Diagnosticable { /// Unique identifier for the pointer, not reused. Changes for each new  /// pointer down event.  final int pointer; } https://flutter.dev/docs/development/ui/advanced/gestures\n十三、全面深入触摸和滑动原理· Flutter 完整开发实战详解系列\n事实上并不是所有的控件的 RenderObject 子类都会处理 handleEvent ，大部分时候，只有带有 RenderPointerListener (RenderObject) / Listener (Widget) 的才会处理 handleEvent 事件，并且从上述源码可以看出，handleEvent 的执行是不会被拦截打断的。\nFlutter中的事件流和手势简析\nHitTestResult中的路径顺序一般就是：\n目标节点\u0026ndash;\u0026gt;父节点\u0026ndash;\u0026gt;根节点\u0026ndash;\u0026gt;GestureBinding\n接着PointerDown，PointerMove，PointerUp，PointerCancel等事件分发，都根据这个顺序来遍历调用它们的handleEvent方法\nFlutter触摸事件(1)\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/touch/",
	"title": "touch",
	"tags": [],
	"description": "",
	"content": "touch 探索总结touch知识\n Touch     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/input/toucheventnative/",
	"title": "touchEventNative",
	"tags": [],
	"description": "",
	"content": "原理图 SystemServer startOtherServices private void startOtherServices() { inputManager = new InputManagerService(context); wm = WindowManagerService.main(context, inputManager, mFactoryTestMode != FactoryTest.FACTORY_TEST_LOW_LEVEL, !mFirstBoot, mOnlyCore, new PhoneWindowManager()); ServiceManager.addService(Context.WINDOW_SERVICE, wm, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL | DUMP_FLAG_PROTO); ServiceManager.addService(Context.INPUT_SERVICE, inputManager, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL); ...... inputManager.setWindowManagerCallbacks(wm.getInputMonitor()); inputManager.start(); } InputManagerService public class InputManagerService extends IInputManager.Stub { public InputManagerService(Context context) { this.mContext = context; this.mHandler = new InputManagerHandler(DisplayThread.get().getLooper()); mPtr = nativeInit(this, mContext, mHandler.getLooper().getQueue()); } } start public void start() { Slog.i(TAG, \u0026#34;Starting input manager\u0026#34;); nativeStart(mPtr); } registerInputChannel public void registerInputChannel(InputChannel inputChannel, InputWindowHandle inputWindowHandle) { nativeRegisterInputChannel(mPtr, inputChannel, inputWindowHandle, false); } frameworks/base/services/core/jni/com_android_server_input_InputManagerService.cpp\ncom_android_server_input_InputManagerService nativeInit static jlong nativeInit(JNIEnv* env, jclass /* clazz */, jobject serviceObj, jobject contextObj, jobject messageQueueObj) { sp\u0026lt;MessageQueue\u0026gt; messageQueue = android_os_MessageQueue_getMessageQueue(env, messageQueueObj); NativeInputManager* im = new NativeInputManager(contextObj, serviceObj, messageQueue-\u0026gt;getLooper()); im-\u0026gt;incStrong(0); return reinterpret_cast\u0026lt;jlong\u0026gt;(im); } nativeStart static void nativeStart(JNIEnv* env, jclass /* clazz */, jlong ptr) { NativeInputManager* im = reinterpret_cast\u0026lt;NativeInputManager*\u0026gt;(ptr); status_t result = im-\u0026gt;getInputManager()-\u0026gt;start(); } nativeRegisterInputChannel static void nativeRegisterInputChannel(JNIEnv* env, jclass /* clazz */, jlong ptr, jobject inputChannelObj, jobject inputWindowHandleObj, jboolean monitor) { NativeInputManager* im = reinterpret_cast\u0026lt;NativeInputManager*\u0026gt;(ptr); status_t status = im-\u0026gt;registerInputChannel( env, inputChannel, inputWindowHandle, monitor); } frameworks/base/services/core/jni/com_android_server_input_InputManagerService.cpp\nNativeInputManager NativeInputManager::NativeInputManager(jobject contextObj, jobject serviceObj, const sp\u0026lt;Looper\u0026gt;\u0026amp; looper) : mLooper(looper), mInteractive(true) { sp\u0026lt;EventHub\u0026gt; eventHub = new EventHub(); mInputManager = new InputManager(eventHub, this, this); } registerInputChannel status_t NativeInputManager::registerInputChannel(JNIEnv* /* env */, const sp\u0026lt;InputChannel\u0026gt;\u0026amp; inputChannel, const sp\u0026lt;InputWindowHandle\u0026gt;\u0026amp; inputWindowHandle, bool monitor) { ATRACE_CALL(); return mInputManager-\u0026gt;getDispatcher()-\u0026gt;registerInputChannel( inputChannel, inputWindowHandle, monitor); } frameworks/native/services/inputflinger/InputManager.cpp\nInputManager InputManager::InputManager( const sp\u0026lt;EventHubInterface\u0026gt;\u0026amp; eventHub, const sp\u0026lt;InputReaderPolicyInterface\u0026gt;\u0026amp; readerPolicy, const sp\u0026lt;InputDispatcherPolicyInterface\u0026gt;\u0026amp; dispatcherPolicy) { mDispatcher = new InputDispatcher(dispatcherPolicy); mReader = new InputReader(eventHub, readerPolicy, mDispatcher); initialize(); } initialize void InputManager::initialize() { mReaderThread = new InputReaderThread(mReader); mDispatcherThread = new InputDispatcherThread(mDispatcher); } start status_t InputManager::start() { status_t result = mDispatcherThread-\u0026gt;run(\u0026#34;InputDispatcher\u0026#34;, PRIORITY_URGENT_DISPLAY); result = mReaderThread-\u0026gt;run(\u0026#34;InputReader\u0026#34;, PRIORITY_URGENT_DISPLAY); return OK; } frameworks/native/services/inputflinger/EventHub.cpp\nEventHub EventHub EventHub::EventHub(void) : { mEpollFd = epoll_create(EPOLL_SIZE_HINT); mINotifyFd = inotify_init(); int result = inotify_add_watch(mINotifyFd, DEVICE_PATH, IN_DELETE | IN_CREATE); struct epoll_event eventItem; memset(\u0026amp;eventItem, 0, sizeof(eventItem)); eventItem.events = EPOLLIN; eventItem.data.u32 = EPOLL_ID_INOTIFY; result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mINotifyFd, \u0026amp;eventItem); int wakeFds[2]; result = pipe(wakeFds); mWakeReadPipeFd = wakeFds[0]; mWakeWritePipeFd = wakeFds[1]; result = fcntl(mWakeReadPipeFd, F_SETFL, O_NONBLOCK); result = fcntl(mWakeWritePipeFd, F_SETFL, O_NONBLOCK); eventItem.data.u32 = EPOLL_ID_WAKE; result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeReadPipeFd, \u0026amp;eventItem); } getEvents size_t EventHub::getEvents(int timeoutMillis, RawEvent* buffer, size_t bufferSize) { for (;;) { // Grab the next input event.  bool deviceChanged = false; while (mPendingEventIndex \u0026lt; mPendingEventCount) { const struct epoll_event\u0026amp; eventItem = mPendingEventItems[mPendingEventIndex++]; if (eventItem.data.u32 == EPOLL_ID_INOTIFY) { if (eventItem.events \u0026amp; EPOLLIN) { mPendingINotify = true; } continue; } ...... if (mPendingINotify \u0026amp;\u0026amp; mPendingEventIndex \u0026gt;= mPendingEventCount) { mPendingINotify = false; readNotifyLocked(); } } int pollResult = epoll_wait(mEpollFd, mPendingEventItems, EPOLL_MAX_EVENTS, timeoutMillis); } readNotifyLocked status_t EventHub::readNotifyLocked() { res = read(mINotifyFd, event_buf, sizeof(event_buf)); } frameworks/native/services/inputflinger/InputReader.cpp\nInputReaderThread threadLoop bool InputReaderThread::threadLoop() { mReader-\u0026gt;loopOnce(); return true; } frameworks/native/services/inputflinger/InputReader.cpp\nInputReader InputReader::InputReader(const sp\u0026lt;EventHubInterface\u0026gt;\u0026amp; eventHub, const sp\u0026lt;InputReaderPolicyInterface\u0026gt;\u0026amp; policy, const sp\u0026lt;InputListenerInterface\u0026gt;\u0026amp; listener) : mContext(this), mEventHub(eventHub), mPolicy(policy), { mQueuedListener = new QueuedInputListener(listener); } threadLoop bool InputReaderThread::threadLoop() { mReader-\u0026gt;loopOnce(); return true; } loopOnce void InputReader::loopOnce() { size_t count = mEventHub-\u0026gt;getEvents(timeoutMillis, mEventBuffer, EVENT_BUFFER_SIZE); if (count) { processEventsLocked(mEventBuffer, count); } // Flush queued events out to the listener.  // This must happen outside of the lock because the listener could potentially call  // back into the InputReader\u0026#39;s methods, such as getScanCodeState, or become blocked  // on another thread similarly waiting to acquire the InputReader lock thereby  // resulting in a deadlock. This situation is actually quite plausible because the  // listener is actually the input dispatcher, which calls into the window manager,  // which occasionally calls into the input reader.  mQueuedListener-\u0026gt;flush(); } getevents\nflush\nframeworks/native/services/inputflinger/InputListener.cpp\nQueuedInputListener flush void QueuedInputListener::flush() { size_t count = mArgsQueue.size(); for (size_t i = 0; i \u0026lt; count; i++) { NotifyArgs* args = mArgsQueue[i]; args-\u0026gt;notify(mInnerListener); delete args; } mArgsQueue.clear(); } NotifyMotionArgs notify void NotifyMotionArgs::notify(const sp\u0026lt;InputListenerInterface\u0026gt;\u0026amp; listener) const { listener-\u0026gt;notifyMotion(this); } notifymotion\nframeworks/native/services/inputflinger/InputDispatcher.cpp\nInputDispatcher threadLoop bool InputDispatcherThread::threadLoop() { mDispatcher-\u0026gt;dispatchOnce(); return true; } dispatchOnce void InputDispatcher::dispatchOnce() { // Run a dispatch loop if there are no pending commands.  // The dispatch loop might enqueue commands to run afterwards.  if (!haveCommandsLocked()) { dispatchOnceInnerLocked(\u0026amp;nextWakeupTime); } // Wait for callback or timeout or wake. (make sure we round up, not down)  nsecs_t currentTime = now(); int timeoutMillis = toMillisecondTimeoutDelay(currentTime, nextWakeupTime); mLooper-\u0026gt;pollOnce(timeoutMillis);//registerInputChannel时通过Looper.wake()唤醒线程 } notifyMotion void InputDispatcher::notifyMotion(const NotifyMotionArgs* args) { if (needWake) { mLooper-\u0026gt;wake(); } } dispatchOnceInnerLocked void InputDispatcher::dispatchOnceInnerLocked(nsecs_t* nextWakeupTime) { case EventEntry::TYPE_MOTION: { MotionEntry* typedEntry = static_cast\u0026lt;MotionEntry*\u0026gt;(mPendingEvent); if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; isAppSwitchDue) { dropReason = DROP_REASON_APP_SWITCH; } if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; isStaleEventLocked(currentTime, typedEntry)) { dropReason = DROP_REASON_STALE; } if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; mNextUnblockedEvent) { dropReason = DROP_REASON_BLOCKED; } done = dispatchMotionLocked(currentTime, typedEntry, \u0026amp;dropReason, nextWakeupTime); break; } dispatchMotionLocked bool InputDispatcher::dispatchMotionLocked( nsecs_t currentTime, MotionEntry* entry, DropReason* dropReason, nsecs_t* nextWakeupTime) { dispatchEventLocked(currentTime, entry, inputTargets); return true; } dispatchEventLocked void InputDispatcher::dispatchEventLocked(nsecs_t currentTime, EventEntry* eventEntry, const Vector\u0026lt;InputTarget\u0026gt;\u0026amp; inputTargets) { for (size_t i = 0; i \u0026lt; inputTargets.size(); i++) { const InputTarget\u0026amp; inputTarget = inputTargets.itemAt(i); ssize_t connectionIndex = getConnectionIndexLocked(inputTarget.inputChannel); if (connectionIndex \u0026gt;= 0) { sp\u0026lt;Connection\u0026gt; connection = mConnectionsByFd.valueAt(connectionIndex); prepareDispatchCycleLocked(currentTime, connection, eventEntry, \u0026amp;inputTarget); } } prepareDispatchCycleLocked void InputDispatcher::prepareDispatchCycleLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection, EventEntry* eventEntry, const InputTarget* inputTarget) { enqueueDispatchEntriesLocked(currentTime, connection, splitMotionEntry, inputTarget); } enqueueDispatchEntriesLocked void InputDispatcher::enqueueDispatchEntriesLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection, EventEntry* eventEntry, const InputTarget* inputTarget) { bool wasEmpty = connection-\u0026gt;outboundQueue.isEmpty(); ...... // If the outbound queue was previously empty, start the dispatch cycle going.  if (wasEmpty \u0026amp;\u0026amp; !connection-\u0026gt;outboundQueue.isEmpty()) { startDispatchCycleLocked(currentTime, connection); } } startDispatchCycleLocked void InputDispatcher::startDispatchCycleLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection) { EventEntry* eventEntry = dispatchEntry-\u0026gt;eventEntry; switch (eventEntry-\u0026gt;type) { case EventEntry::TYPE_KEY: { KeyEntry* keyEntry = static_cast\u0026lt;KeyEntry*\u0026gt;(eventEntry); // Publish the key event.  status = connection-\u0026gt;inputPublisher.publishKeyEvent(dispatchEntry-\u0026gt;seq, keyEntry-\u0026gt;deviceId, keyEntry-\u0026gt;source, dispatchEntry-\u0026gt;resolvedAction, dispatchEntry-\u0026gt;resolvedFlags, keyEntry-\u0026gt;keyCode, keyEntry-\u0026gt;scanCode, keyEntry-\u0026gt;metaState, keyEntry-\u0026gt;repeatCount, keyEntry-\u0026gt;downTime, keyEntry-\u0026gt;eventTime); break; } case EventEntry::TYPE_MOTION: { // Publish the motion event.  status = connection-\u0026gt;inputPublisher.publishMotionEvent(dispatchEntry-\u0026gt;seq, motionEntry-\u0026gt;deviceId, motionEntry-\u0026gt;source, motionEntry-\u0026gt;displayId, dispatchEntry-\u0026gt;resolvedAction, motionEntry-\u0026gt;actionButton, dispatchEntry-\u0026gt;resolvedFlags, motionEntry-\u0026gt;edgeFlags, motionEntry-\u0026gt;metaState, motionEntry-\u0026gt;buttonState, xOffset, yOffset, motionEntry-\u0026gt;xPrecision, motionEntry-\u0026gt;yPrecision, motionEntry-\u0026gt;downTime, motionEntry-\u0026gt;eventTime, motionEntry-\u0026gt;pointerCount, motionEntry-\u0026gt;pointerProperties, usingCoords); break; } publishmotionevent\nhandleReceiveCallback int InputDispatcher::handleReceiveCallback(int fd, int events, void* data) { InputDispatcher* d = static_cast\u0026lt;InputDispatcher*\u0026gt;(data); ssize_t connectionIndex = d-\u0026gt;mConnectionsByFd.indexOfKey(fd); sp\u0026lt;Connection\u0026gt; connection = d-\u0026gt;mConnectionsByFd.valueAt(connectionIndex); if (!(events \u0026amp; (ALOOPER_EVENT_ERROR | ALOOPER_EVENT_HANGUP))) { if (!(events \u0026amp; ALOOPER_EVENT_INPUT)) {//仅仅对ALOOPER_EVENT_INPUT事件类型进行处理  ALOGW(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received spurious callback for unhandled poll event. \u0026#34; \u0026#34;events=0x%x\u0026#34;, connection-\u0026gt;getInputChannelName().c_str(), events); return 1; } nsecs_t currentTime = now(); bool gotOne = false; status_t status; for (;;) { uint32_t seq; bool handled; status = connection-\u0026gt;inputPublisher.receiveFinishedSignal(\u0026amp;seq, \u0026amp;handled); if (status) { break; } d-\u0026gt;finishDispatchCycleLocked(currentTime, connection, seq, handled); gotOne = true; } if (gotOne) { d-\u0026gt;runCommandsLockedInterruptible(); if (status == WOULD_BLOCK) { return 1; } } }   Input系统—InputReader线程：通过EventHub从/dev/input节点获取事件，转换成EventEntry事件加入到InputDispatcher的mInboundQueue。\n  Input系统—InputDispatcher线程：从mInboundQueue队列取出事件，转换成DispatchEntry事件加入到connection的outboundQueue队列。再然后开始处理分发事件，取出outbound队列，放入waitQueue.\n  Input系统—UI线程\n：创建socket pair，分别位于”InputDispatcher”线程和focused窗口所在进程的UI主线程，可相互通信。\n UI主线程：通过setFdEvents()， 监听socket客户端，收到消息后回调NativeInputEventReceiver();【见小节2.1】 “InputDispatcher”线程： 通过IMS.registerInputChannel()，监听socket服务端，收到消息后回调handleReceiveCallback；【见小节3.1】    前面文章都是介绍了两个线程InputReader和InputDispatcher的工作过程。在InputDispatcher的过程讲到 调用InputChanel通过socket与远程进程通信，本文便展开讲解这个socket是如何建立的。\n对于InputReader和InputDispatcher都是运行在system_server进程； 用户点击的界面往往可能是某一个app，而每个app一般地都运行在自己的进程，这里就涉及到跨进程通信，app进程是如何与system进程建立通信。\nframeworks/native/libs/input/InputTransport.cpp\nInputPublisher publishMotionEvent status_t InputPublisher::publishMotionEvent( uint32_t seq,...... { return mChannel-\u0026gt;sendMessage(\u0026amp;msg); } InputConsumer sendFinishedSignal status_t InputConsumer::sendFinishedSignal(uint32_t seq, bool handled) { return sendUnchainedFinishedSignal(seq, handled); } sendUnchainedFinishedSignal status_t InputConsumer::sendUnchainedFinishedSignal(uint32_t seq, bool handled) { InputMessage msg; msg.header.type = InputMessage::TYPE_FINISHED; msg.body.finished.seq = seq; msg.body.finished.handled = handled; return mChannel-\u0026gt;sendMessage(\u0026amp;msg); } InputChannel(两个Socket实现双向监听) sendMessage status_t InputChannel::sendMessage(const InputMessage* msg) { size_t msgLength = msg-\u0026gt;size(); ssize_t nWrite; do { nWrite = ::send(mFd, msg, msgLength, MSG_DONTWAIT | MSG_NOSIGNAL); } while (nWrite == -1 \u0026amp;\u0026amp; errno == EINTR); Socket/Channel SystemServer进程 [-\u0026gt; WindowManagerService.java]\npublic int addWindow(Session session, IWindow client, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, InputChannel outInputChannel) { inputChannels数组：\n inputChannels[0]所对应的InputChannel名称的后缀为(server); inputChannels[1]所对应的InputChannel名称的后缀为(client)；  其中：\n 服务端inputChannels[0]保存到WindowState的mInputChannel； 客户端inputChannels[1]传递给outInputChannel，最终传递给ViewRootImpl的mInputChannel；  [-\u0026gt; InputTransport.cpp]\nstatus_t InputChannel::openInputChannelPair(const String8\u0026amp; name, sp\u0026lt;InputChannel\u0026gt;\u0026amp; outServerChannel, sp\u0026lt;InputChannel\u0026gt;\u0026amp; outClientChannel) { int sockets[2]; //真正创建socket对的地方【核心】  if (socketpair(AF_UNIX, SOCK_SEQPACKET, 0, sockets)) { ... return result; } int bufferSize = SOCKET_BUFFER_SIZE; //32k  setsockopt(sockets[0], SOL_SOCKET, SO_SNDBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[0], SOL_SOCKET, SO_RCVBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[1], SOL_SOCKET, SO_SNDBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[1], SOL_SOCKET, SO_RCVBUF, \u0026amp;bufferSize, sizeof(bufferSize)); String8 serverChannelName = name; serverChannelName.append(\u0026#34; (server)\u0026#34;); //创建InputChannel对象  outServerChannel = new InputChannel(serverChannelName, sockets[0]); String8 clientChannelName = name; clientChannelName.append(\u0026#34; (client)\u0026#34;); //创建InputChannel对象  outClientChannel = new InputChannel(clientChannelName, sockets[1]); return OK; } 该方法主要功能:\n 创建socket pair; (非阻塞式的socket) 设置两个socket的接收和发送的buffer上限为32KB; 创建client和server的Native层InputChannel对象;  sockets[0]所对应的InputChannel名称的后缀为(server); sockets[1]所对应的InputChannel名称的后缀为(client)    创建InputChannel对象位于文件InputTransport.cpp，如下：\nInputChannel::InputChannel(const String8\u0026amp; name, int fd) : mName(name), mFd(fd) { //将socket设置成非阻塞方式  int result = fcntl(mFd, F_SETFL, O_NONBLOCK); } frameworks/native/services/inputflinger/InputDispatcher.cpp\nregisterInputChannel status_t InputDispatcher::registerInputChannel(const sp\u0026lt;InputChannel\u0026gt;\u0026amp; inputChannel, const sp\u0026lt;InputWindowHandle\u0026gt;\u0026amp; inputWindowHandle, bool monitor) { { AutoMutex _l(mLock); ... //创建Connection[见小节2.8.4]  sp\u0026lt;Connection\u0026gt; connection = new Connection(inputChannel, inputWindowHandle, monitor); int fd = inputChannel-\u0026gt;getFd();//fd为socket fd  mConnectionsByFd.add(fd, connection); ... //将该fd添加到Looper监听[见小节2.8.5]  mLooper-\u0026gt;addFd(fd, 0, ALOOPER_EVENT_INPUT, handleReceiveCallback, this); } mLooper-\u0026gt;wake(); //connection改变, 则唤醒looper  return OK; } 将新创建的connection保存到mConnectionsByFd成员变量，“InputDispatcher”线程的Looper添加对socket服务端的监听功能； 当该socket有消息时便会唤醒该线程工作。\nViewRootImpl的setView()过程:\n 创建socket pair，作为InputChannel:  socket服务端保存到system_server中的WindowState的mInputChannel； socket客户端通过binder传回到远程进程的UI主线程ViewRootImpl的mInputChannel；   IMS.registerInputChannel()注册InputChannel，监听socket服务端：  Loop便是“InputDispatcher”线程的Looper; 回调方法handleReceiveCallback。    Socket/Channel app进程 [-\u0026gt; android_view_InputEventReceiver.cpp]\nvoid NativeInputEventReceiver::setFdEvents(int events) { if (mFdEvents != events) { mFdEvents = events; int fd = mInputConsumer.getChannel()-\u0026gt;getFd();//channel提供fd  if (events) { //将socket客户端的fd添加到主线程的消息池【见小节3.6.1】  mMessageQueue-\u0026gt;getLooper()-\u0026gt;addFd(fd, 0, events, this, NULL);//fd可读时触发本类的handleEvent回调  } else { mMessageQueue-\u0026gt;getLooper()-\u0026gt;removeFd(fd); } } } 此处的Looper便是UI主线程的Looper，将socket客户端的fd添加到UI线程的Looper来监听，回调方法为NativeInputEventReceiver。\n首先，通过openInputChannelPair来创建socket pair，作为InputChannel:\n socket服务端保存到system_server中的WindowState的mInputChannel； socket客户端通过binder传回到远程进程的UI主线程ViewRootImpl的mInputChannel(inputChannel是binder调用的out参数)；  紧接着，完成了两个线程的epoll监听工作：\n [小节2.8]IMS.registerInputChannel(): “InputDispatcher”线程监听socket服务端，收到消息后回调InputDispatcher.handleReceiveCallback()； [小节3.6]setFdEvents(): UI主线程监听socket客户端，收到消息后回调NativeInputEventReceiver.handleEvent().  system/core/libutils/Looper.cpp\nLooper.cpp pollInner int Looper::pollInner(int timeoutMillis) { // Invoke all response callbacks.  for (size_t i = 0; i \u0026lt; mResponses.size(); i++) { // Invoke the callback. Note that the file descriptor may be closed by  // the callback (and potentially even reused) before the function returns so  // we need to be a little careful when removing the file descriptor afterwards.  int callbackResult = response.request.callback-\u0026gt;handleEvent(fd, events, data); } } frameworks/base/core/jni/android_view_InputEventReceiver.cpp\nNativeInputEventReceiver handleEvent int NativeInputEventReceiver::handleEvent(int receiveFd, int events, void* data) { if (events \u0026amp; ALOOPER_EVENT_INPUT) { JNIEnv* env = AndroidRuntime::getJNIEnv(); status_t status = consumeEvents(env, false /*consumeBatches*/, -1, NULL); mMessageQueue-\u0026gt;raiseAndClearException(env, \u0026#34;handleReceiveCallback\u0026#34;); return status == OK || status == NO_MEMORY ? 1 : 0; } } consumeEvents status_t NativeInputEventReceiver::consumeEvents(JNIEnv* env, bool consumeBatches, nsecs_t frameTime, bool* outConsumedBatch) { for (;;) { uint32_t seq; InputEvent* inputEvent; int32_t displayId; status_t status = mInputConsumer.consume(\u0026amp;mInputEventFactory, consumeBatches, frameTime, \u0026amp;seq, \u0026amp;inputEvent, \u0026amp;displayId); jobject inputEventObj; switch (inputEvent-\u0026gt;getType()) { case AINPUT_EVENT_TYPE_KEY: if (kDebugDispatchCycle) { ALOGD(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received key event.\u0026#34;, getInputChannelName().c_str()); } inputEventObj = android_view_KeyEvent_fromNative(env, static_cast\u0026lt;KeyEvent*\u0026gt;(inputEvent)); break; case AINPUT_EVENT_TYPE_MOTION: { if (kDebugDispatchCycle) { ALOGD(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received motion event.\u0026#34;, getInputChannelName().c_str()); } MotionEvent* motionEvent = static_cast\u0026lt;MotionEvent*\u0026gt;(inputEvent); if ((motionEvent-\u0026gt;getAction() \u0026amp; AMOTION_EVENT_ACTION_MOVE) \u0026amp;\u0026amp; outConsumedBatch) { *outConsumedBatch = true; } inputEventObj = android_view_MotionEvent_obtainAsCopy(env, motionEvent); break; } default: assert(false); // InputConsumer should prevent this from ever happening  inputEventObj = NULL; } if (inputEventObj) { env-\u0026gt;CallVoidMethod(receiverObj.get(), gInputEventReceiverClassInfo.dispatchInputEvent, seq, inputEventObj, displayId); } InputEventReceiver dispatchInputEvent // Called from native code.  @SuppressWarnings(\u0026#34;unused\u0026#34;) private void dispatchInputEvent(int seq, InputEvent event, int displayId) { mSeqMap.put(event.getSequenceNumber(), seq); onInputEvent(event, displayId); } finishInputEvent public final void finishInputEvent(InputEvent event, boolean handled) { nativeFinishInputEvent(mReceiverPtr, seq, handled); } frameworks/base/core/jni/android_view_InputEventReceiver.cpp\nandroid_view_InputEventReceiver nativeFinishInputEvent static void nativeFinishInputEvent(JNIEnv* env, jclass clazz, jlong receiverPtr, jint seq, jboolean handled) { sp\u0026lt;NativeInputEventReceiver\u0026gt; receiver = reinterpret_cast\u0026lt;NativeInputEventReceiver*\u0026gt;(receiverPtr); status_t status = receiver-\u0026gt;finishInputEvent(seq, handled); } finishInputEvent status_t NativeInputEventReceiver::finishInputEvent(uint32_t seq, bool handled) { status_t status = mInputConsumer.sendFinishedSignal(seq, handled); } sendfinishedsignal\n参考 \u0026laquo;深入理解Android : 卷3 第五章 输入系统\u0026raquo;\nInput系统—事件处理全过程\nInput系统—ANR原理分析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/viewmodel/viewmodel/",
	"title": "ViewModel",
	"tags": [],
	"description": "",
	"content": "类设计 基于androidx.lifecycle:lifecycle-viewmodel:2.1.0\n保存viewModelStore handleDestroyActivity ActivityThread.java\n@Override public void handleDestroyActivity(IBinder token, boolean finishing, int configChanges, boolean getNonConfigInstance, String reason) {//转屏时传递的getNonConfigInstance为true  ActivityClientRecord r = performDestroyActivity(token, finishing, configChanges, getNonConfigInstance, reason); } handledestroyactivity由来\n/** Core implementation of activity destroy call. */ ActivityClientRecord performDestroyActivity(IBinder token, boolean finishing, int configChanges, boolean getNonConfigInstance, String reason) { ActivityClientRecord r = mActivities.get(token); Class\u0026lt;? extends Activity\u0026gt; activityClass = null; if (r != null) { if (finishing) { r.activity.mFinished = true; } performPauseActivityIfNeeded(r, \u0026#34;destroy\u0026#34;); if (!r.stopped) { callActivityOnStop(r, false /* saveState */, \u0026#34;destroy\u0026#34;); } if (getNonConfigInstance) { r.lastNonConfigurationInstances = r.activity.retainNonConfigurationInstances(); } r.lastNonConfigurationInstances.activity.custom\ninto r.lastNonConfigurationInstances.activity.viewModelStore 其中的activity也是一个NonConfigurationInstances实例\nNonConfigurationInstances retainNonConfigurationInstances() { Object activity = onRetainNonConfigurationInstance(); NonConfigurationInstances nci = new NonConfigurationInstances(); nci.activity = activity; return nci; } /** * Retain all appropriate non-config state. You can NOT * override this yourself! Use a {@link androidx.lifecycle.ViewModel} if you want to * retain your own non config state. */ @Override @Nullable public final Object onRetainNonConfigurationInstance() { Object custom = onRetainCustomNonConfigurationInstance();//保存用户自定义数据，可重写  ViewModelStore viewModelStore = mViewModelStore; if (viewModelStore == null) { // No one called getViewModelStore(), so see if there was an existing  // ViewModelStore from our last NonConfigurationInstance  NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { viewModelStore = nc.viewModelStore; } } if (viewModelStore == null \u0026amp;\u0026amp; custom == null) { return null; } NonConfigurationInstances nci = new NonConfigurationInstances(); nci.custom = custom; nci.viewModelStore = viewModelStore; return nci; } 恢复viewModelStore 从ActivityClientRecord中提取保存mLastNonConfigurationInstances LaunchActivityItem.java\npublic void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { ActivityClientRecord r = new ActivityClientRecord(token, mIntent, mIdent, mInfo, mOverrideConfig, mCompatInfo, mReferrer, mVoiceInteractor, mState, mPersistentState, mPendingResults, mPendingNewIntents, mIsForward, mProfilerInfo, client);//这里并没有初始化lastNonConfigurationInstances  client.handleLaunchActivity(r, pendingActions, null /* customIntent */); } ActivityThread.java\npublic Activity handleLaunchActivity(ActivityClientRecord r, PendingTransactionActions pendingActions, Intent customIntent) { final Activity a = performLaunchActivity(r, customIntent); } /** Core implementation of activity launch. */ private Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) { activity.attach(appContext, this, getInstrumentation(), r.token, r.ident, app, r.intent, r.activityInfo, title, r.parent, r.embeddedID, r.lastNonConfigurationInstances, config, r.referrer, r.voiceInteractor, window, r.configCallback); r.lastNonConfigurationInstances = null; } Activity.java\nfinal void attach(Context context, ActivityThread aThread, Instrumentation instr, IBinder token, int ident, Application application, Intent intent, ActivityInfo info, CharSequence title, Activity parent, String id, NonConfigurationInstances lastNonConfigurationInstances, Configuration config, String referrer, IVoiceInteractor voiceInteractor, Window window, ActivityConfigCallback activityConfigCallback) { attachBaseContext(context); mLastNonConfigurationInstances = lastNonConfigurationInstances; } 从lastNonConfigurationInstance中提取并保存mViewModelStore ComponentActivity.java\npublic ViewModelStore getViewModelStore() { if (mViewModelStore == null) { NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { // Restore the ViewModelStore from NonConfigurationInstances  mViewModelStore = nc.viewModelStore; } if (mViewModelStore == null) { mViewModelStore = new ViewModelStore(); } } return mViewModelStore; } public Object getLastNonConfigurationInstance() { return mLastNonConfigurationInstances != null ? mLastNonConfigurationInstances.activity : null; } 使用mViewModelStore ViewModelProvider /** * Creates {@code ViewModelProvider}, which will create {@code ViewModels} via the given * {@code Factory} and retain them in the given {@code store}. * * @param store {@code ViewModelStore} where ViewModels will be stored. * @param factory factory a {@code Factory} which will be used to instantiate * new {@code ViewModels} */ public ViewModelProvider(@NonNull ViewModelStore store, @NonNull Factory factory) { mFactory = factory; mViewModelStore = store; } Factory public interface Factory { /** * Creates a new instance of the given {@code Class}. * \u0026lt;p\u0026gt; * * @param modelClass a {@code Class} whose instance is requested * @param \u0026lt;T\u0026gt; The type parameter for the ViewModel. * @return a newly created ViewModel */ @NonNull \u0026lt;T extends ViewModel\u0026gt; T create(@NonNull Class\u0026lt;T\u0026gt; modelClass); } KeyedFactory abstract static class KeyedFactory implements Factory { public abstract \u0026lt;T extends ViewModel\u0026gt; T create(@NonNull String key, @NonNull Class\u0026lt;T\u0026gt; modelClass); @NonNull @Override public \u0026lt;T extends ViewModel\u0026gt; T create(@NonNull Class\u0026lt;T\u0026gt; modelClass) { throw new UnsupportedOperationException(\u0026#34;create(String, Class\u0026lt;?\u0026gt;) must be called on \u0026#34; + \u0026#34;implementaions of KeyedFactory\u0026#34;); } } get public \u0026lt;T extends ViewModel\u0026gt; T get(@NonNull Class\u0026lt;T\u0026gt; modelClass) { String canonicalName = modelClass.getCanonicalName(); return get(DEFAULT_KEY + \u0026#34;:\u0026#34; + canonicalName, modelClass); } public \u0026lt;T extends ViewModel\u0026gt; T get(@NonNull String key, @NonNull Class\u0026lt;T\u0026gt; modelClass) { ViewModel viewModel = mViewModelStore.get(key); if (modelClass.isInstance(viewModel)) { //noinspection unchecked  return (T) viewModel; } if (mFactory instanceof KeyedFactory) { viewModel = ((KeyedFactory) (mFactory)).create(key, modelClass); } else { viewModel = (mFactory).create(modelClass); } mViewModelStore.put(key, viewModel); //noinspection unchecked  return (T) viewModel; } ViewModelStore private final HashMap\u0026lt;String, ViewModel\u0026gt; mMap = new HashMap\u0026lt;\u0026gt;(); final void put(String key, ViewModel viewModel) { ViewModel oldViewModel = mMap.put(key, viewModel); if (oldViewModel != null) { oldViewModel.onCleared(); } } final ViewModel get(String key) { return mMap.get(key); } public final void clear() { for (ViewModel vm : mMap.values()) { vm.clear(); } mMap.clear(); } } ViewModel private final Map\u0026lt;String, Object\u0026gt; mBagOfTags = new HashMap\u0026lt;\u0026gt;(); protected void onCleared() { } final void clear() { mCleared = true; if (mBagOfTags != null) { synchronized (mBagOfTags) { for (Object value : mBagOfTags.values()) { // see comment for the similar call in setTagIfAbsent  closeWithRuntimeException(value); } } } onCleared(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/viewmodel/",
	"title": "viewmodel",
	"tags": [],
	"description": "",
	"content": "viewmodel 探索总结viewmodel知识\n ViewModel     ViewModel封装     数据保存和恢复     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/viewmodel/viewmodel%E5%B0%81%E8%A3%85/",
	"title": "ViewModel封装",
	"tags": [],
	"description": "",
	"content": "ViewModel初始化精简 https://stackoverflow.com/questions/58106707/how-does-kotlin-use-this-by-delegate-to-instantiate-the-viewmodel\nby viewModels(...) is part of fragment-ktx library, it\u0026rsquo;s a convienience short hand for creating a lazy delegate obtaining ViewModels.\n// creates lazy delegate for obtaining zero-argument MyViewModel private val viewModel : MyViewModel by viewModels() // it\u0026#39;s functionally equal to: private val viewModel by lazy { ViewModelProvider(this).get(MyViewModel::class.java) } // with factory: private val viewModel : MyViewModel by viewModels { getViewModelFactory() } // is equal to: private val viewModel by lazy { ViewModelProvider(this, getViewModelFactory()).get(MyViewModel::class.java) } ComponentActivity.viewModels @MainThread inline fun \u0026lt;reified VM : ViewModel\u0026gt; ComponentActivity.viewModels( noinline factoryProducer: (() -\u0026gt; Factory)? = null ): Lazy\u0026lt;VM\u0026gt; { val factoryPromise = factoryProducer ?: { defaultViewModelProviderFactory } return ViewModelLazy(VM::class, { viewModelStore }, factoryPromise) } ViewModelLazy class ViewModelLazy\u0026lt;VM : ViewModel\u0026gt; ( private val viewModelClass: KClass\u0026lt;VM\u0026gt;, private val storeProducer: () -\u0026gt; ViewModelStore, private val factoryProducer: () -\u0026gt; ViewModelProvider.Factory ) : Lazy\u0026lt;VM\u0026gt; { private var cached: VM? = null override val value: VM get() { val viewModel = cached return if (viewModel == null) { val factory = factoryProducer() val store = storeProducer() ViewModelProvider(store, factory).get(viewModelClass.java).also { cached = it } } else { viewModel } } override fun isInitialized() = cached != null } JVM target 1.8 Cannot inline bytecode built with JVM target 1.8 into bytecode that is being built with JVM target 1.6. Please specify proper \u0026lsquo;-jvm-target\u0026rsquo; option\nhttps://stackoverflow.com/questions/48988778/cannot-inline-bytecode-built-with-jvm-target-1-8-into-bytecode-that-is-being-bui\n解决方式：\nandroid { kotlinOptions { jvmTarget = JavaVersion.VERSION_1_8.toString() } } viewModelScope原理 public ComponentActivity() { getLifecycle().addObserver(new LifecycleEventObserver() { @Override public void onStateChanged(@NonNull LifecycleOwner source, @NonNull Lifecycle.Event event) { if (event == Lifecycle.Event.ON_DESTROY) { if (!isChangingConfigurations()) { getViewModelStore().clear(); } } } }); } viewModelStore.clear /** * Clears internal storage and notifies ViewModels that they are no longer used. */ public final void clear() { for (ViewModel vm : mMap.values()) { vm.clear(); } mMap.clear(); } viewModel.clear @MainThread final void clear() { mCleared = true; // Since clear() is final, this method is still called on mock objects  // and in those cases, mBagOfTags is null. It\u0026#39;ll always be empty though  // because setTagIfAbsent and getTag are not final so we can skip  // clearing it  if (mBagOfTags != null) { synchronized (mBagOfTags) { for (Object value : mBagOfTags.values()) { // see comment for the similar call in setTagIfAbsent  closeWithRuntimeException(value); } } } onCleared(); } private static void closeWithRuntimeException(Object obj) { if (obj instanceof Closeable) { try { ((Closeable) obj).close(); } catch (IOException e) { throw new RuntimeException(e); } } } coroutineContext.cancel private const val JOB_KEY = \u0026#34;androidx.lifecycle.ViewModelCoroutineScope.JOB_KEY\u0026#34; /** * [CoroutineScope] tied to this [ViewModel]. * This scope will be canceled when ViewModel will be cleared, i.e [ViewModel.onCleared] is called * * This scope is bound to * [Dispatchers.Main.immediate][kotlinx.coroutines.MainCoroutineDispatcher.immediate] */ val ViewModel.viewModelScope: CoroutineScope get() { val scope: CoroutineScope? = this.getTag(JOB_KEY) if (scope != null) { return scope } return setTagIfAbsent(JOB_KEY, CloseableCoroutineScope(SupervisorJob() + Dispatchers.Main.immediate)) } internal class CloseableCoroutineScope(context: CoroutineContext) : Closeable, CoroutineScope { override val coroutineContext: CoroutineContext = context override fun close() { coroutineContext.cancel() } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/vsync/",
	"title": "Vsync",
	"tags": [],
	"description": "",
	"content": "原理图 Vsync App进程 graph TB DisplayEventDispatcher::scheduleVsync--\u0026gt;eventConnection.requestNextVsync sequenceDiagram participant JavaDispalyEventReveiver participant NativeDisplayEventReceiver participant Looper participant BitTube NativeDisplayEventReceiver-\u0026gt;\u0026gt;+Looper: looper.addFd Looper--\u0026gt;\u0026gt;-NativeDisplayEventReceiver: fd可读 NativeDisplayEventReceiver-\u0026gt;\u0026gt;+NativeDisplayEventReceiver: handleEvent NativeDisplayEventReceiver-\u0026gt;\u0026gt;-BitTube: recvObjects BitTube--\u0026gt;\u0026gt;NativeDisplayEventReceiver: return NativeDisplayEventReceiver-\u0026gt;\u0026gt;JavaDispalyEventReveiver:dispatchVsnc frameworks/base/libs/androidfw/DisplayEventDispatcher.cpp\nDisplayEventDispatcher.cpp initialize status_t DisplayEventDispatcher::initialize() { status_t result = mReceiver.initCheck(); int rc = mLooper-\u0026gt;addFd(mReceiver.getFd(), 0, Looper::EVENT_INPUT, this, NULL); return OK; } handleEvent int DisplayEventDispatcher::handleEvent(int, int events, void*) { // Drain all pending events, keep the last vsync.  nsecs_t vsyncTimestamp; int32_t vsyncDisplayId; uint32_t vsyncCount; if (processPendingEvents(\u0026amp;vsyncTimestamp, \u0026amp;vsyncDisplayId, \u0026amp;vsyncCount)) { dispatchVsync(vsyncTimestamp, vsyncDisplayId, vsyncCount); } return 1; // keep the callback } scheduleVsync status_t DisplayEventDispatcher::scheduleVsync() { if (!mWaitingForVsync) { // Drain all pending events.  if (processPendingEvents(\u0026amp;vsyncTimestamp, \u0026amp;vsyncDisplayId, \u0026amp;vsyncCount)) { this, ns2ms(static_cast\u0026lt;nsecs_t\u0026gt;(vsyncTimestamp))); } status_t status = mReceiver.requestNextVsync(); mWaitingForVsync = true; } return OK; } frameworks/native/libs/gui/DisplayEventReceiver.cpp\nDisplayEventReceiver.cpp sp\u0026lt;IDisplayEventConnection\u0026gt; mEventConnection; std::unique_ptr\u0026lt;gui::BitTube\u0026gt; mDataChannel; DisplayEventReceiver() /* * DisplayEventReceiver creates and registers an event connection with * SurfaceFlinger. VSync events are disabled by default. Call setVSyncRate * or requestNextVsync to receive them. * Other events start being delivered immediately. */ DisplayEventReceiver::DisplayEventReceiver(ISurfaceComposer::VsyncSource vsyncSource) { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService()); if (sf != NULL) { mEventConnection = sf-\u0026gt;createDisplayEventConnection(vsyncSource); if (mEventConnection != NULL) { mDataChannel = std::make_unique\u0026lt;gui::BitTube\u0026gt;(); mEventConnection-\u0026gt;stealReceiveChannel(mDataChannel.get()); } } } getFd int DisplayEventReceiver::getFd() const { if (mDataChannel == NULL) return NO_INIT; return mDataChannel-\u0026gt;getFd(); } getEvents ssize_t DisplayEventReceiver::getEvents(DisplayEventReceiver::Event* events, size_t count) { return DisplayEventReceiver::getEvents(mDataChannel.get(), events, count); } ssize_t DisplayEventReceiver::getEvents(gui::BitTube* dataChannel, Event* events, size_t count) { return gui::BitTube::recvObjects(dataChannel, events, count); } requestNextVsync status_t DisplayEventReceiver::requestNextVsync() { if (mEventConnection != NULL) { mEventConnection-\u0026gt;requestNextVsync(); return NO_ERROR; } return NO_INIT; } frameworks/native/libs/gui/BitTube.cpp\nBitTube getFd int BitTube::getFd() const { return mReceiveFd; } frameworks/native/libs/gui/SurfaceComposerClient.cpp\nframeworks/native/libs/gui/include/private/gui/ComposerService.h\nComposerService // This holds our connection to the composer service (i.e. SurfaceFlinger). // If the remote side goes away, we will re-establish the connection. // Users of this class should not retain the value from // getComposerService() for an extended period. class ComposerService : public Singleton\u0026lt;ComposerService\u0026gt; { sp\u0026lt;ISurfaceComposer\u0026gt; mComposerService; sp\u0026lt;IBinder::DeathRecipient\u0026gt; mDeathObserver; } getComposerService // Get a connection to the Composer Service. This will block until  // a connection is established. /*static*/ sp\u0026lt;ISurfaceComposer\u0026gt; ComposerService::getComposerService() { ComposerService\u0026amp; instance = ComposerService::getInstance(); Mutex::Autolock _l(instance.mLock); if (instance.mComposerService == NULL) { ComposerService::getInstance().connectLocked(); assert(instance.mComposerService != NULL); } return instance.mComposerService; } connectLocked void ComposerService::connectLocked() { const String16 name(\u0026#34;SurfaceFlinger\u0026#34;); while (getService(name, \u0026amp;mComposerService) != NO_ERROR) {//get SurfaceFlinger Service  usleep(250000); } assert(mComposerService != NULL); // Create the death listener.  class DeathObserver : public IBinder::DeathRecipient { ComposerService\u0026amp; mComposerService; virtual void binderDied(const wp\u0026lt;IBinder\u0026gt;\u0026amp; who) { ALOGW(\u0026#34;ComposerService remote (surfaceflinger) died [%p]\u0026#34;, who.unsafe_get()); mComposerService.composerServiceDied(); } public: explicit DeathObserver(ComposerService\u0026amp; mgr) : mComposerService(mgr) { } }; mDeathObserver = new DeathObserver(*const_cast\u0026lt;ComposerService*\u0026gt;(this)); IInterface::asBinder(mComposerService)-\u0026gt;linkToDeath(mDeathObserver); } composerServiceDied void ComposerService::composerServiceDied() { Mutex::Autolock _l(mLock); mComposerService = NULL; mDeathObserver = NULL; } frameworks/native/libs/binder/include/binder/IServiceManager.h\nIServiceManager getService template\u0026lt;typename INTERFACE\u0026gt; status_t getService(const String16\u0026amp; name, sp\u0026lt;INTERFACE\u0026gt;* outService) { const sp\u0026lt;IServiceManager\u0026gt; sm = defaultServiceManager(); if (sm != NULL) { *outService = interface_cast\u0026lt;INTERFACE\u0026gt;(sm-\u0026gt;getService(name)); if ((*outService) != NULL) return NO_ERROR; } return NAME_NOT_FOUND; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/vsync_surfaceflinger/",
	"title": "Vsync_SurfaceFlinger",
	"tags": [],
	"description": "",
	"content": "Android-SurfaceFlinger启动与绘图原理\n创建 HWComposer 对象(通过 HAL 层的 HWComposer 硬件模块 或 软件模拟产生 Vsync 信号)，现在的 Android 系统基本上都可以看成是通过硬件 HWComposer 产生 Vsync 信号，而不使用软件模拟，所以下面解析都只谈及硬件 HWComposer 的 Vsync 信号；\nChoreographer 会通过上面创建的 APP 延时源 mEventThreadSource 对象及其对应的 EventThread 线程来监听同步模拟发出的 Vsync 信号，然后进行绘制(measure/layout/draw)操作。具体逻辑见 Android-Choreographer原理。\nSurfaceFlinger类设计 graph TB SurfaceFlinger--\u0026gt;BnSurfaceComposer--\u0026gt;BnInterface BnSurfaceComposer--\u0026gt;ISurfaceComposer ISurfaceComposer--\u0026gt;IInterface BnInterface--\u0026gt;BBinder--\u0026gt;IBinder system/core/rootdir/init.rc\ninit.rc on property:vold.decrypt=trigger_restart_framework stop surfaceflinger start surfaceflinger # A/B update verifier that marks a successful boot. exec_start update_verifier class_start main class_start late_start frameworks/native/services/surfaceflinger/surfaceflinger.rc\nsurfaceflinger.rc service surfaceflinger /system/bin/surfaceflinger class core animation user system group graphics drmrpc readproc onrestart restart zygote writepid /dev/stune/foreground/tasks socket pdx/system/vr/display/client stream 0666 system graphics u:object_r:pdx_display_client_endpoint_socket:s0 socket pdx/system/vr/display/manager stream 0666 system graphics u:object_r:pdx_display_manager_endpoint_socket:s0 socket pdx/system/vr/display/vsync stream 0666 system graphics u:object_r:pdx_display_vsync_endpoint_socket:s0 frameworks/native/services/surfaceflinger/main_surfaceflinger.cpp\nmain_surfaceflinger.cpp main int main(int, char**) { // When SF is launched in its own process, limit the number of  // binder threads to 4.  ProcessState::self()-\u0026gt;setThreadPoolMaxThreadCount(4); // start the thread pool  sp\u0026lt;ProcessState\u0026gt; ps(ProcessState::self()); ps-\u0026gt;startThreadPool(); // instantiate surfaceflinger  sp\u0026lt;SurfaceFlinger\u0026gt; flinger = new SurfaceFlinger(); setpriority(PRIO_PROCESS, 0, PRIORITY_URGENT_DISPLAY); set_sched_policy(0, SP_FOREGROUND); // initialize before clients can connect  flinger-\u0026gt;init(); // publish surface flinger  sp\u0026lt;IServiceManager\u0026gt; sm(defaultServiceManager()); sm-\u0026gt;addService(String16(SurfaceFlinger::getServiceName()), flinger, false, IServiceManager::DUMP_FLAG_PRIORITY_CRITICAL); // run surface flinger in this thread  flinger-\u0026gt;run(); return 0; } frameworks/native/services/surfaceflinger/SurfaceFlinger.h\nSurfaceFlinger SurfaceFlinger class SurfaceFlinger : public BnSurfaceComposer, public PriorityDumper, private IBinder::DeathRecipient, private HWC2::ComposerCallback { // these are thread safe  mutable std::unique_ptr\u0026lt;MessageQueue\u0026gt; mEventQueue{std::make_unique\u0026lt;impl::MessageQueue\u0026gt;()}; VSyncModulator mVsyncModulator; DispSync mPrimaryDispSync; using CreateBufferQueueFunction = std::function\u0026lt;void(sp\u0026lt;IGraphicBufferProducer\u0026gt;* /* outProducer */, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* /* outConsumer */, bool /* consumerIsSurfaceFlinger */)\u0026gt;; CreateBufferQueueFunction mCreateBufferQueue; using CreateNativeWindowSurfaceFunction = std::function\u0026lt;std::unique_ptr\u0026lt;NativeWindowSurface\u0026gt;(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp;)\u0026gt;; CreateNativeWindowSurfaceFunction mCreateNativeWindowSurface; } SurfaceFlinger::SurfaceFlinger(SurfaceFlinger::SkipInitializationTag) : BnSurfaceComposer(), Display(false), ...... mMainThreadId(std::this_thread::get_id()), mCreateBufferQueue(\u0026amp;BufferQueue::createBufferQueue), mCreateNativeWindowSurface(\u0026amp;impl::NativeWindowSurface::create) {} onFirstRef void SurfaceFlinger::onFirstRef() { mEventQueue-\u0026gt;init(this); } init void SurfaceFlinger::init() { // start the EventThread  mEventThreadSource = std::make_unique\u0026lt;DispSyncSource\u0026gt;(\u0026amp;mPrimaryDispSync, SurfaceFlinger::vsyncPhaseOffsetNs, true, \u0026#34;app\u0026#34;); mEventThread = std::make_unique\u0026lt;impl::EventThread\u0026gt;(mEventThreadSource.get(), [this]() { resyncWithRateLimit(); }, impl::EventThread::InterceptVSyncsCallback(), \u0026#34;appEventThread\u0026#34;); mSfEventThreadSource = std::make_unique\u0026lt;DispSyncSource\u0026gt;(\u0026amp;mPrimaryDispSync, SurfaceFlinger::sfVsyncPhaseOffsetNs, true, \u0026#34;sf\u0026#34;); mSFEventThread = std::make_unique\u0026lt;impl::EventThread\u0026gt;(mSfEventThreadSource.get(), [this]() { resyncWithRateLimit(); }, [this](nsecs_t timestamp) { mInterceptor-\u0026gt;saveVSyncEvent(timestamp); mEventQueue-\u0026gt;setEventThread(mSFEventThread.get()); mVsyncModulator.setEventThread(mSFEventThread.get()); // Get a RenderEngine for the given display / config (can\u0026#39;t fail)  getBE().mRenderEngine = RE::impl::RenderEngine::create(HAL_PIXEL_FORMAT_RGBA_8888, hasWideColorDisplay ? RE::RenderEngine::WIDE_COLOR_SUPPORT : 0); getBE().mHwc.reset( new HWComposer(std::make_unique\u0026lt;Hwc2::impl::Composer\u0026gt;(getBE().mHwcServiceName))); getBE().mHwc-\u0026gt;registerCallback(this, getBE().mComposerSequenceId); mEventControlThread = std::make_unique\u0026lt;impl::EventControlThread\u0026gt;( [this](bool enabled) { setVsyncEnabled(HWC_DISPLAY_PRIMARY, enabled); }); // set initial conditions (e.g. unblank default device)  initializeDisplays(); } onVsyncReceived void SurfaceFlinger::onVsyncReceived(int32_t sequenceId, hwc2_display_t displayId, int64_t timestamp) { Mutex::Autolock lock(mStateLock); // Ignore any vsyncs from a previous hardware composer.  if (sequenceId != getBE().mComposerSequenceId) { return; } int32_t type; if (!getBE().mHwc-\u0026gt;onVsync(displayId, timestamp, \u0026amp;type)) { return; } bool needsHwVsync = false; { // Scope for the lock  Mutex::Autolock _l(mHWVsyncLock); if (type == DisplayDevice::DISPLAY_PRIMARY \u0026amp;\u0026amp; mPrimaryHWVsyncEnabled) { needsHwVsync = mPrimaryDispSync.addResyncSample(timestamp); } } if (needsHwVsync) { enableHardwareVsync(); } else { disableHardwareVsync(false); } } disableHardwareVsync void SurfaceFlinger::disableHardwareVsync(bool makeUnavailable) { Mutex::Autolock _l(mHWVsyncLock); if (mPrimaryHWVsyncEnabled) { //eventControl(HWC_DISPLAY_PRIMARY, SurfaceFlinger::EVENT_VSYNC, false);  mEventControlThread-\u0026gt;setVsyncEnabled(false); mPrimaryDispSync.endResync(); mPrimaryHWVsyncEnabled = false; } if (makeUnavailable) { mHWVsyncAvailable = false; } } run void SurfaceFlinger::run() { do { waitForEvent(); } while (true); } waitForEvent void SurfaceFlinger::waitForEvent() { mEventQueue-\u0026gt;waitMessage(); } onMessageReceived void SurfaceFlinger::onMessageReceived(int32_t what) { switch (what) { case MessageQueue::INVALIDATE: { bool refreshNeeded = handleMessageTransaction(); refreshNeeded |= handleMessageInvalidate(); refreshNeeded |= mRepaintEverything; if (refreshNeeded) { // Signal a refresh if a transaction modified the window state,  // a new buffer was latched, or if HWC has requested a full  // repaint  signalRefresh();//call handleMessageRefresh()  } break; } case MessageQueue::REFRESH: { handleMessageRefresh(); break; } } } handleMessageRefresh void SurfaceFlinger::handleMessageRefresh() { ATRACE_CALL(); mRefreshPending = false; nsecs_t refreshStartTime = systemTime(SYSTEM_TIME_MONOTONIC); preComposition(refreshStartTime); rebuildLayerStacks(); setUpHWComposer(); doDebugFlashRegions(); doTracing(\u0026#34;handleRefresh\u0026#34;); logLayerStats(); doComposition(); postComposition(refreshStartTime); mPreviousPresentFence = getBE().mHwc-\u0026gt;getPresentFence(HWC_DISPLAY_PRIMARY); mHadClientComposition = false; for (size_t displayId = 0; displayId \u0026lt; mDisplays.size(); ++displayId) { const sp\u0026lt;DisplayDevice\u0026gt;\u0026amp; displayDevice = mDisplays[displayId]; mHadClientComposition = mHadClientComposition || getBE().mHwc-\u0026gt;hasClientComposition(displayDevice-\u0026gt;getHwcDisplayId()); } mVsyncModulator.onRefreshed(mHadClientComposition); mLayersWithQueuedFrames.clear(); } createDisplayEventConnection sp\u0026lt;IDisplayEventConnection\u0026gt; SurfaceFlinger::createDisplayEventConnection( ISurfaceComposer::VsyncSource vsyncSource) { if (vsyncSource == eVsyncSourceSurfaceFlinger) { return mSFEventThread-\u0026gt;createEventConnection(); } else { return mEventThread-\u0026gt;createEventConnection(); } } resyncWithRateLimit void SurfaceFlinger::resyncWithRateLimit() { static constexpr nsecs_t kIgnoreDelay = ms2ns(500); // No explicit locking is needed here since EventThread holds a lock while calling this method  static nsecs_t sLastResyncAttempted = 0; const nsecs_t now = systemTime(); if (now - sLastResyncAttempted \u0026gt; kIgnoreDelay) { resyncToHardwareVsync(false); } sLastResyncAttempted = now; } resyncToHardwareVsync void SurfaceFlinger::resyncToHardwareVsync(bool makeAvailable) { Mutex::Autolock _l(mHWVsyncLock); if (makeAvailable) { mHWVsyncAvailable = true; } else if (!mHWVsyncAvailable) { // Hardware vsync is not currently available, so abort the resync  // attempt for now  return; } const auto\u0026amp; activeConfig = getBE().mHwc-\u0026gt;getActiveConfig(HWC_DISPLAY_PRIMARY); const nsecs_t period = activeConfig-\u0026gt;getVsyncPeriod(); mPrimaryDispSync.reset(); mPrimaryDispSync.setPeriod(period); if (!mPrimaryHWVsyncEnabled) { mPrimaryDispSync.beginResync(); //eventControl(HWC_DISPLAY_PRIMARY, SurfaceFlinger::EVENT_VSYNC, true);  mEventControlThread-\u0026gt;setVsyncEnabled(true); mPrimaryHWVsyncEnabled = true; } } setVsyncEnabled void SurfaceFlinger::setVsyncEnabled(int disp, int enabled) { getHwComposer().setVsyncEnabled(disp, enabled ? HWC2::Vsync::Enable : HWC2::Vsync::Disable); } frameworks/native/libs/gui/include/gui/ISurfaceComposer.h\nVsyncSource enum VsyncSource { eVsyncSourceApp = 0, eVsyncSourceSurfaceFlinger = 1 }; ComposerCallbackBridge :IComposerCallback ComposerCallback* mCallback; onVsync Return\u0026lt;void\u0026gt; onVsync(Hwc2::Display display, int64_t timestamp) override { mCallback-\u0026gt;onVsyncReceived(mSequenceId, display, timestamp); return Void(); } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\nDispSyncSource DispSync* mDispSync; Mutex mCallbackMutex; // Protects the following  VSyncSource::Callback* mCallback = nullptr; onDispSyncEvent virtual void onDispSyncEvent(nsecs_t when) { VSyncSource::Callback* callback; { Mutex::Autolock lock(mCallbackMutex); callback = mCallback; if (mTraceVsync) { mValue = (mValue + 1) % 2; ATRACE_INT(mVsyncEventLabel.string(), mValue); } } if (callback != nullptr) { callback-\u0026gt;onVSyncEvent(when); } } frameworks/native/services/surfaceflinger/EventThread.cpp\nEventThread class EventThread : public android::EventThread, private VSyncSource::Callback { class Connection : public BnDisplayEventConnection { public: explicit Connection(EventThread* eventThread); virtual ~Connection(); virtual status_t postEvent(const DisplayEventReceiver::Event\u0026amp; event); // count \u0026gt;= 1 : continuous event. count is the vsync rate  // count == 0 : one-shot event that has not fired  // count ==-1 : one-shot event that fired this round / disabled  int32_t count; private: virtual void onFirstRef(); status_t stealReceiveChannel(gui::BitTube* outChannel) override; status_t setVsyncRate(uint32_t count) override; void requestNextVsync() override; // asynchronous  EventThread* const mEventThread; gui::BitTube mChannel; }; EventThread() EventThread::EventThread(VSyncSource* src, ResyncWithRateLimitCallback resyncWithRateLimitCallback, InterceptVSyncsCallback interceptVSyncsCallback, const char* threadName) : mVSyncSource(src), mResyncWithRateLimitCallback(resyncWithRateLimitCallback), mInterceptVSyncsCallback(interceptVSyncsCallback) { for (auto\u0026amp; event : mVSyncEvent) { event.header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; event.header.id = 0; event.header.timestamp = 0; event.vsync.count = 0; } mThread = std::thread(\u0026amp;EventThread::threadMain, this); pthread_setname_np(mThread.native_handle(), threadName); pid_t tid = pthread_gettid_np(mThread.native_handle()); // Use SCHED_FIFO to minimize jitter  constexpr int EVENT_THREAD_PRIORITY = 2; struct sched_param param = {0}; param.sched_priority = EVENT_THREAD_PRIORITY; if (pthread_setschedparam(mThread.native_handle(), SCHED_FIFO, \u0026amp;param) != 0) { ALOGE(\u0026#34;Couldn\u0026#39;t set SCHED_FIFO for EventThread\u0026#34;); } set_sched_policy(tid, SP_FOREGROUND); } threadMain void EventThread::threadMain() NO_THREAD_SAFETY_ANALYSIS { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mMutex); while (mKeepRunning) { DisplayEventReceiver::Event event; Vector\u0026lt;sp\u0026lt;EventThread::Connection\u0026gt; \u0026gt; signalConnections; signalConnections = waitForEventLocked(\u0026amp;lock, \u0026amp;event); // dispatch events to listeners...  const size_t count = signalConnections.size(); for (size_t i = 0; i \u0026lt; count; i++) { const sp\u0026lt;Connection\u0026gt;\u0026amp; conn(signalConnections[i]); // now see if we still need to report this event  status_t err = conn-\u0026gt;postEvent(event); } } } waitForEventLocked // This will return when (1) a vsync event has been received, and (2) there was // at least one connection interested in receiving it when we started waiting. Vector\u0026lt;sp\u0026lt;EventThread::Connection\u0026gt; \u0026gt; EventThread::waitForEventLocked( std::unique_lock\u0026lt;std::mutex\u0026gt;* lock, DisplayEventReceiver::Event* event) { ...... if (!timestamp \u0026amp;\u0026amp; !eventPending) { // wait for something to happen  if (waitForVSync) { // This is where we spend most of our time, waiting  // for vsync events and new client registrations.  //  // If the screen is off, we can\u0026#39;t use h/w vsync, so we  // use a 16ms timeout instead. It doesn\u0026#39;t need to be  // precise, we just need to keep feeding our clients.  //  // We don\u0026#39;t want to stall if there\u0026#39;s a driver bug, so we  // use a (long) timeout when waiting for h/w vsync, and  // generate fake events when necessary.  bool softwareSync = mUseSoftwareVSync; auto timeout = softwareSync ? 16ms : 1000ms; if (mCondition.wait_for(*lock, timeout) == std::cv_status::timeout) { if (!softwareSync) { ALOGW(\u0026#34;Timed out waiting for hw vsync; faking it\u0026#34;); } // FIXME: how do we decide which display id the fake  // vsync came from ?  mVSyncEvent[0].header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; mVSyncEvent[0].header.id = DisplayDevice::DISPLAY_PRIMARY; mVSyncEvent[0].header.timestamp = systemTime(SYSTEM_TIME_MONOTONIC); mVSyncEvent[0].vsync.count++; } } else { // Nobody is interested in vsync, so we just want to sleep.  // h/w vsync should be disabled, so this will wait until we  // get a new connection, or an existing connection becomes  // interested in receiving vsync again.  mCondition.wait(*lock); } // here we\u0026#39;re guaranteed to have a timestamp and some connections to signal  // (The connections might have dropped out of mDisplayEventConnections  // while we were asleep, but we\u0026#39;ll still have strong references to them.)  return signalConnections; } onVSyncEvent void EventThread::onVSyncEvent(nsecs_t timestamp) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); mVSyncEvent[0].header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; mVSyncEvent[0].header.id = 0; mVSyncEvent[0].header.timestamp = timestamp; mVSyncEvent[0].vsync.count++; mCondition.notify_all();//唤醒EventThread线程 } Connection::postEvent status_t EventThread::Connection::postEvent(const DisplayEventReceiver::Event\u0026amp; event) { ssize_t size = DisplayEventReceiver::sendEvents(\u0026amp;mChannel, \u0026amp;event, 1); return size \u0026lt; 0 ? status_t(size) : status_t(NO_ERROR); } createEventConnection sp\u0026lt;BnDisplayEventConnection\u0026gt; EventThread::createEventConnection() const { return new Connection(const_cast\u0026lt;EventThread*\u0026gt;(this)); } Connection::stealReceiveChannel /* * stealReceiveChannel() returns a BitTube to receive events from. Only the receive file * descriptor of outChannel will be initialized, and this effectively \u0026#34;steals\u0026#34; the receive * channel from the remote end (such that the remote end can only use its send channel). */ status_t EventThread::Connection::stealReceiveChannel(gui::BitTube* outChannel) { outChannel-\u0026gt;setReceiveFd(mChannel.moveReceiveFd()); return NO_ERROR; } Connection::requestNextVsync void EventThread::Connection::requestNextVsync() { mEventThread-\u0026gt;requestNextVsync(this); } requestNextVsync void EventThread::requestNextVsync(const sp\u0026lt;EventThread::Connection\u0026gt;\u0026amp; connection) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); if (mResyncWithRateLimitCallback) { mResyncWithRateLimitCallback();//callback resyncWithRateLimit in SurfaceFlinger  } if (connection-\u0026gt;count \u0026lt; 0) { connection-\u0026gt;count = 0; mCondition.notify_all(); } } frameworks/native/services/surfaceflinger/EventControlThread.cpp\nEventControlThread setVsyncEnabled void EventControlThread::setVsyncEnabled(bool enabled) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); mVsyncEnabled = enabled; mCondition.notify_all(); } threadMain // Unfortunately std::unique_lock gives warnings with -Wthread-safety void EventControlThread::threadMain() NO_THREAD_SAFETY_ANALYSIS { auto keepRunning = true; auto currentVsyncEnabled = false; while (keepRunning) { mSetVSyncEnabled(currentVsyncEnabled); std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mMutex); mCondition.wait(lock, [this, currentVsyncEnabled, keepRunning]() NO_THREAD_SAFETY_ANALYSIS { return currentVsyncEnabled != mVsyncEnabled || keepRunning != mKeepRunning; }); currentVsyncEnabled = mVsyncEnabled; keepRunning = mKeepRunning; } } frameworks/native/libs/gui/DisplayEventReceiver.cpp\nDisplayEventReceiver sendEvents ssize_t DisplayEventReceiver::sendEvents(gui::BitTube* dataChannel, Event const* events, size_t count) { return gui::BitTube::sendObjects(dataChannel, events, count); } frameworks/native/libs/gui/BitTube.cpp\nBitTube // Socket buffer size. The default is typically about 128KB, which is much larger than we really // need. So we make it smaller. static const size_t DEFAULT_SOCKET_BUFFER_SIZE = 4 * 1024; BitTube() BitTube::BitTube(size_t bufsize) { init(bufsize, bufsize); } init void BitTube::init(size_t rcvbuf, size_t sndbuf) { int sockets[2]; if (socketpair(AF_UNIX, SOCK_SEQPACKET, 0, sockets) == 0) { size_t size = DEFAULT_SOCKET_BUFFER_SIZE; setsockopt(sockets[0], SOL_SOCKET, SO_RCVBUF, \u0026amp;rcvbuf, sizeof(rcvbuf)); setsockopt(sockets[1], SOL_SOCKET, SO_SNDBUF, \u0026amp;sndbuf, sizeof(sndbuf)); // since we don\u0026#39;t use the \u0026#34;return channel\u0026#34;, we keep it small...  setsockopt(sockets[0], SOL_SOCKET, SO_SNDBUF, \u0026amp;size, sizeof(size)); setsockopt(sockets[1], SOL_SOCKET, SO_RCVBUF, \u0026amp;size, sizeof(size)); fcntl(sockets[0], F_SETFL, O_NONBLOCK); fcntl(sockets[1], F_SETFL, O_NONBLOCK); mReceiveFd.reset(sockets[0]); mSendFd.reset(sockets[1]); } else { mReceiveFd.reset(); ALOGE(\u0026#34;BitTube: pipe creation failed (%s)\u0026#34;, strerror(errno)); } } sendObjects ssize_t BitTube::sendObjects(BitTube* tube, void const* events, size_t count, size_t objSize) { const char* vaddr = reinterpret_cast\u0026lt;const char*\u0026gt;(events); ssize_t size = tube-\u0026gt;write(vaddr, count * objSize); // ALOGE_IF(size\u0026lt;0, \u0026#34;error %d sending %d events\u0026#34;, size, count);  return size \u0026lt; 0 ? size : size / static_cast\u0026lt;ssize_t\u0026gt;(objSize); } write ssize_t BitTube::write(void const* vaddr, size_t size) { ssize_t err, len; do { len = ::send(mSendFd, vaddr, size, MSG_DONTWAIT | MSG_NOSIGNAL); // cannot return less than size, since we\u0026#39;re using SOCK_SEQPACKET  err = len \u0026lt; 0 ? errno : 0; } while (err == EINTR); return err == 0 ? len : -err; } recvObjects ssize_t BitTube::recvObjects(BitTube* tube, void* events, size_t count, size_t objSize) { char* vaddr = reinterpret_cast\u0026lt;char*\u0026gt;(events); ssize_t size = tube-\u0026gt;read(vaddr, count * objSize); // ALOGE_IF(size\u0026lt;0, \u0026#34;error %d receiving %d events\u0026#34;, size, count);  return size \u0026lt; 0 ? size : size / static_cast\u0026lt;ssize_t\u0026gt;(objSize); } rameworks/native/services/surfaceflinger/DispSync.cpp\nDispSync // mThread is the thread from which all the callbacks are called.  sp\u0026lt;DispSyncThread\u0026gt; mThread; init void DispSync::init(bool hasSyncFramework, int64_t dispSyncPresentTimeOffset) { mThread-\u0026gt;run(\u0026#34;DispSync\u0026#34;, PRIORITY_URGENT_DISPLAY + PRIORITY_MORE_FAVORABLE); reset(); beginResync(); } addResyncSample bool DispSync::addResyncSample(nsecs_t timestamp) { updateModelLocked(); } updateModelLocked void DispSync::updateModelLocked() { mThread-\u0026gt;updateModel(mPeriod, mPhase, mReferenceTime); } frameworks/native/services/surfaceflinger/DispSync.cpp\nDispSyncThread class DispSyncThread : public Thread { Vector\u0026lt;EventListener\u0026gt; mEventListeners; } threadLoop virtual bool threadLoop() { status_t err; nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); while (true) { targetTime = computeNextEventTimeLocked(now); bool isWakeup = false; if (now \u0026lt; targetTime) { if (kTraceDetailedInfo) ATRACE_NAME(\u0026#34;DispSync waiting\u0026#34;); if (targetTime == INT64_MAX) { ALOGV(\u0026#34;[%s] Waiting forever\u0026#34;, mName); err = mCond.wait(mMutex); } else { ALOGV(\u0026#34;[%s] Waiting until %\u0026#34; PRId64, mName, ns2us(targetTime)); err = mCond.waitRelative(mMutex, targetTime - now); } } callbackInvocations = gatherCallbackInvocationsLocked(now); if (callbackInvocations.size() \u0026gt; 0) { fireCallbackInvocations(callbackInvocations); } } } gatherCallbackInvocationsLocked Vector\u0026lt;CallbackInvocation\u0026gt; gatherCallbackInvocationsLocked(nsecs_t now) { Vector\u0026lt;CallbackInvocation\u0026gt; callbackInvocations; nsecs_t onePeriodAgo = now - mPeriod; for (size_t i = 0; i \u0026lt; mEventListeners.size(); i++) { nsecs_t t = computeListenerNextEventTimeLocked(mEventListeners[i], onePeriodAgo); if (t \u0026lt; now) { CallbackInvocation ci; ci.mCallback = mEventListeners[i].mCallback; ci.mEventTime = t; callbackInvocations.push(ci); mEventListeners.editItemAt(i).mLastEventTime = t; } } return callbackInvocations; } fireCallbackInvocations void fireCallbackInvocations(const Vector\u0026lt;CallbackInvocation\u0026gt;\u0026amp; callbacks) { for (size_t i = 0; i \u0026lt; callbacks.size(); i++) { callbacks[i].mCallback-\u0026gt;onDispSyncEvent(callbacks[i].mEventTime); } } updateModel void updateModel(nsecs_t period, nsecs_t phase, nsecs_t referenceTime) { Mutex::Autolock lock(mMutex); mPeriod = period; mPhase = phase; mReferenceTime = referenceTime; mCond.signal(); } frameworks/native/services/surfaceflinger/MessageQueue.h\nMessageQueue namespace impl { class MessageQueue final : public android::MessageQueue { class Handler : public MessageHandler { enum { eventMaskInvalidate = 0x1, eventMaskRefresh = 0x2, eventMaskTransaction = 0x4 }; MessageQueue\u0026amp; mQueue; int32_t mEventMask; public: explicit Handler(MessageQueue\u0026amp; queue) : mQueue(queue), mEventMask(0) {} virtual void handleMessage(const Message\u0026amp; message); void dispatchRefresh(); void dispatchInvalidate(); }; friend class Handler; sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; sp\u0026lt;Looper\u0026gt; mLooper; android::EventThread* mEventThread; sp\u0026lt;IDisplayEventConnection\u0026gt; mEvents; gui::BitTube mEventTube; sp\u0026lt;Handler\u0026gt; mHandler; } init void MessageQueue::init(const sp\u0026lt;SurfaceFlinger\u0026gt;\u0026amp; flinger) { mFlinger = flinger; mLooper = new Looper(true);//system/core/include/utils/Looper.h  mHandler = new Handler(*this); } setEventThread void MessageQueue::setEventThread(android::EventThread* eventThread) { if (mEventThread == eventThread) { return; } if (mEventTube.getFd() \u0026gt;= 0) { mLooper-\u0026gt;removeFd(mEventTube.getFd()); } mEventThread = eventThread; mEvents = eventThread-\u0026gt;createEventConnection(); mEvents-\u0026gt;stealReceiveChannel(\u0026amp;mEventTube); mLooper-\u0026gt;addFd(mEventTube.getFd(), 0, Looper::EVENT_INPUT, MessageQueue::cb_eventReceiver, this); } waitMessage void MessageQueue::waitMessage() { do { IPCThreadState::self()-\u0026gt;flushCommands(); int32_t ret = mLooper-\u0026gt;pollOnce(-1); switch (ret) { case Looper::POLL_WAKE: case Looper::POLL_CALLBACK: continue; case Looper::POLL_ERROR: ALOGE(\u0026#34;Looper::POLL_ERROR\u0026#34;); continue; case Looper::POLL_TIMEOUT: // timeout (should not happen)  continue; default: // should not happen  ALOGE(\u0026#34;Looper::pollOnce() returned unknown status %d\u0026#34;, ret); continue; } } while (true); } cb_eventReceiver int MessageQueue::cb_eventReceiver(int fd, int events, void* data) { MessageQueue* queue = reinterpret_cast\u0026lt;MessageQueue*\u0026gt;(data); return queue-\u0026gt;eventReceiver(fd, events); } eventReceiver int MessageQueue::eventReceiver(int /*fd*/, int /*events*/) { ssize_t n; DisplayEventReceiver::Event buffer[8]; while ((n = DisplayEventReceiver::getEvents(\u0026amp;mEventTube, buffer, 8)) \u0026gt; 0) { for (int i = 0; i \u0026lt; n; i++) { if (buffer[i].header.type == DisplayEventReceiver::DISPLAY_EVENT_VSYNC) { mHandler-\u0026gt;dispatchInvalidate(); break; } } } return 1; } Handler::dispatchInvalidate void MessageQueue::Handler::dispatchInvalidate() { if ((android_atomic_or(eventMaskInvalidate, \u0026amp;mEventMask) \u0026amp; eventMaskInvalidate) == 0) { mQueue.mLooper-\u0026gt;sendMessage(this, Message(MessageQueue::INVALIDATE)); } } Handler::handleMessage void MessageQueue::Handler::handleMessage(const Message\u0026amp; message) { switch (message.what) { case INVALIDATE: android_atomic_and(~eventMaskInvalidate, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; case REFRESH: android_atomic_and(~eventMaskRefresh, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; } } frameworks/native/services/surfaceflinger/DisplayHardware/HWC2.h\nComposerCallback // Implement this interface to receive hardware composer events. // // These callback functions will generally be called on a hwbinder thread, but // when first registering the callback the onHotplugReceived() function will // immediately be called on the thread calling registerCallback(). // // All calls receive a sequenceId, which will be the value that was supplied to // HWC2::Device::registerCallback(). It\u0026#39;s used to help differentiate callbacks // from different hardware composer instances. class ComposerCallback { public: virtual void onHotplugReceived(int32_t sequenceId, hwc2_display_t display, Connection connection) = 0; virtual void onRefreshReceived(int32_t sequenceId, hwc2_display_t display) = 0; virtual void onVsyncReceived(int32_t sequenceId, hwc2_display_t display, int64_t timestamp) = 0; virtual ~ComposerCallback() = default; };  frameworks/native/libs/gui/IGraphicBufferProducer.cpp\nIGraphicBufferProducer.cpp queueBuffer virtual status_t queueBuffer(int buf, const QueueBufferInput\u0026amp; input, QueueBufferOutput* output) { Parcel data, reply; data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor()); data.writeInt32(buf); data.write(input); status_t result = remote()-\u0026gt;transact(QUEUE_BUFFER, data, \u0026amp;reply); return result; } onTransact status_t BnGraphicBufferProducer::onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { switch(code) { case QUEUE_BUFFER: { CHECK_INTERFACE(IGraphicBufferProducer, data, reply); int buf = data.readInt32(); QueueBufferInput input(data); QueueBufferOutput output; status_t result = queueBuffer(buf, input, \u0026amp;output); reply-\u0026gt;write(output); reply-\u0026gt;writeInt32(result); return NO_ERROR; } │79 status_t MonitoredProducer::queueBuffer(int slot, const QueueBufferInput\u0026amp; input, │80 QueueBufferOutput* output) { \u0026gt;│81 return mProducer-\u0026gt;queueBuffer(slot, input, output); │82 } │83 │750 status_t BufferQueueProducer::queueBuffer(int slot, │751 const QueueBufferInput \u0026amp;input, QueueBufferOutput *output) { \u0026gt;│977 frameAvailableListener-\u0026gt;onFrameAvailable(item); │46 void BufferQueue::ProxyConsumerListener::onFrameAvailable( │47 const BufferItem\u0026amp; item) { │48 sp\u0026lt;ConsumerListener\u0026gt; listener(mConsumerListener.promote()); │49 if (listener != NULL) { \u0026gt;│50 listener-\u0026gt;onFrameAvailable(item); │51 } │52 } │104 void ConsumerBase::onFrameAvailable(const BufferItem\u0026amp; item) { │105 CB_LOGV(\u0026#34;onFrameAvailable\u0026#34;); │106 │107 sp\u0026lt;FrameAvailableListener\u0026gt; listener; │108 { // scope for the lock  │109 Mutex::Autolock lock(mFrameAvailableMutex); │110 listener = mFrameAvailableListener.promote(); │111 } │112 │113 if (listener != NULL) { │114 CB_LOGV(\u0026#34;actually calling onFrameAvailable\u0026#34;); \u0026gt;│115 listener-\u0026gt;onFrameAvailable(item); │116 } │117 } │723 // ---------------------------------------------------------------------------  │724 // Interface implementation for SurfaceFlingerConsumer::ContentsChangedListener  │725 // ---------------------------------------------------------------------------  │726 │727 void BufferLayer::onFrameAvailable(const BufferItem\u0026amp; item) { │728 // Add this buffer from our internal queue tracker  │729 { // Autolock scope B+\u0026gt;│730 Mutex::Autolock lock(mQueueItemLock); "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B8%B2%E6%9F%93/widget/",
	"title": "Widget",
	"tags": [],
	"description": "",
	"content": "graph LR State--\u0026gt;|持有|Widget Element--\u0026gt;|持有|State Element--\u0026gt;|持有|Widget Build 触发State.build时机 graph LR after_initState--\u0026gt;State.build after_didUpdateWidget--\u0026gt;State.build after_setState--\u0026gt;State.build after_dependencyChange--\u0026gt;State.build after_deactiveAndReinsertIntoTree--\u0026gt;State.build 挂载树核心方法调用 graph LR mount--\u0026gt;_firstBuild--\u0026gt;reBuild--\u0026gt;performRebuild--\u0026gt;|1|build--\u0026gt;|stateless|StatelessWidget.build build--\u0026gt;|stateful|State.build buildOwner.buildScope--\u0026gt;reBuild performRebuild--\u0026gt;|2|updateChild updateChild--\u0026gt;|优先更新而非重新创建child|canUpdate{\u0026quot;canUpdate?\u0026quot;}--\u0026gt;|yes|child.updateWithNewWidget; canUpdate--\u0026gt;|no|inflateWidgetForNewChildElement--\u0026gt;mount 挂载树挂载过程 graph TB parentElement--\u0026gt;|2:performRebuild|currentElement currentElement--\u0026gt;|1:mount|parentElement currentElement--\u0026gt;|3:buildMyWidget|currentElement currentElement--\u0026gt;|4:newWidget.createElement|childElement childElement--\u0026gt;|5:mount|currentElement 类设计 State.setState //State\u0026lt;T extends StatefulWidget\u0026gt; /** setState方法标记对应的element需要build 如果当前位于一帧内例如点击(input处理+动画+drawFrame)，在调用setState方法之后会触发drawFrame进而触发reBuild 如果当前不位于一帧内，则会策划一次frame*/ @protected void setState(VoidCallback fn) { final dynamic result = fn() as dynamic; _element.markNeedsBuild(); } Element.markNeedsBuild /// Marks the element as dirty and adds it to the global list of widgets to  /// rebuild in the next frame.  ///  /// Since it is inefficient to build an element twice in one frame,  /// applications and widgets should be structured so as to only mark  /// widgets dirty during event handlers before the frame begins, not during  /// the build itself.  void markNeedsBuild() { _dirty = true; owner.scheduleBuildFor(this); } //WidgetsBinding.initInstance时会初始化buildOwner.onBuildScheduled = _handleBuildScheduled;  /// Adds an element to the dirty elements list so that it will be rebuilt /// when [WidgetsBinding.drawFrame] calls [buildScope]. void scheduleBuildFor(Element element) { if (!_scheduledFlushDirtyElements \u0026amp;\u0026amp; onBuildScheduled != null) { //如果当前不在一次整体frame流程中，则会调用onBuildScheduled,eq:_handleBuildScheduled策划一次frame  _scheduledFlushDirtyElements = true; onBuildScheduled(); } _dirtyElements.add(element); element._inDirtyList = true; } void _handleBuildScheduled() { ensureVisualUpdate();//may call scheduleFrame(); } 调用WidgetsBinding.drawFrame\ndrawframe\nbuildOwner.buildScope(renderViewElement); /// Establishes a scope for updating the widget tree, and calls the given  /// `callback`, if any. Then, builds all the elements that were marked as  /// dirty using [scheduleBuildFor], in depth order.  /// The dirty list is processed after `callback` returns, building all the  /// elements that were marked as dirty using [scheduleBuildFor], in depth  /// order. If elements are marked as dirty while this method is running, they  /// must be deeper than the `context` node, and deeper than any  /// previously-built node in this pass.  /// To flush the current dirty list without performing any other work, this  /// function can be called with no callback. This is what the framework does  /// each frame, in [WidgetsBinding.drawFrame].  void buildScope(Element context, [ VoidCallback callback ]) { callback(); _dirtyElements.sort(Element._sort); _dirtyElementsNeedsResorting = false; int dirtyCount = _dirtyElements.length; int index = 0; while (index \u0026lt; dirtyCount) { _dirtyElements[index].rebuild(); } } Elements.rebuild /// Called by the [BuildOwner] when [BuildOwner.scheduleBuildFor] has been  /// called to mark this element dirty, by [mount] when the element is first  /// built, and by [update] when the widget has changed.  void rebuild() { performRebuild(); } ComponentElements.performRebuild /// Calls the [StatelessWidget.build] method of the [StatelessWidget] object  /// (for stateless widgets) or the [State.build] method of the [State] object  /// (for stateful widgets) and then updates the widget tree.  ///  /// Called automatically during [mount] to generate the first build, and by  /// [rebuild] when the element needs updating.  @override void performRebuild() { built = build(); _child = updateChild(_child, built, slot); } ComponentElements.build /// Subclasses should override this function to actually call the appropriate  /// `build` function (e.g., [StatelessWidget.build] or [State.build]) for  /// their widget.  @protected Widget build(); Element.updateChild /// Update the given child with the given new configuration.  ///  /// This method is the core of the widgets system. It is called each time we  /// are to add, update, or remove a child based on an updated configuration.  // | | **newWidget == null** | **newWidget != null** |  /// | :-----------------: | :--------------------- | :---------------------- |  /// | **child == null** | Returns null. | Returns new [Element]. |  /// | **child != null** | Old child is removed, returns null. | Old child updated if possible, returns child or new [Element].  @protected Element updateChild(Element child, Widget newWidget, dynamic newSlot) { if(canUpdate) { child.update(newWidget); } else { return inflateWidget(newWidget, newSlot); } } Element.update(newWidget) inflateWidget /// Create an element for the given widget and add it as a child of this element in the given slot. @protected Element inflateWidget(Widget newWidget, dynamic newSlot) { final Element newChild = newWidget.createElement(); newChild.mount(this, newSlot); return newChild; } newChild.mount(this, newSlot); //Element /// Add this element to the tree in the given slot of the given parent.  ///  /// The framework calls this function when a newly created element is added to  /// the tree for the first time. Use this method to initialize state that  /// depends on having a parent. State that is independent of the parent can  /// more easily be initialized in the constructor.  ///  /// This method transitions the element from the \u0026#34;initial\u0026#34; lifecycle state to  /// the \u0026#34;active\u0026#34; lifecycle state. @mustCallSuper void mount(Element parent, dynamic newSlot) { _parent = parent; _slot = newSlot; _depth = _parent != null ? _parent.depth + 1 : 1; _active = true; if (parent != null) // Only assign ownership if the parent is non-null  _owner = parent.owner; if (widget.key is GlobalKey) { final GlobalKey key = widget.key; key._register(this); } _updateInheritance(); assert(() { _debugLifecycleState = _ElementLifecycle.active; return true; }()); } //ComponentElement @override void mount(Element parent, dynamic newSlot) { super.mount(parent, newSlot); _firstBuild(); } RenderObjectElement.mount @override void mount(Element parent, dynamic newSlot) { super.mount(parent, newSlot); _renderObject = widget.createRenderObject(this);//main  attachRenderObject(newSlot);//main  _dirty = false; } widget.createRenderObject \u0026hellip;\u0026hellip;\nattachRenderObject @override void attachRenderObject(dynamic newSlot) { _slot = newSlot; _ancestorRenderObjectElement = _findAncestorRenderObjectElement(); _ancestorRenderObjectElement?.insertChildRenderObject(renderObject, newSlot);//main  final ParentDataElement\u0026lt;RenderObjectWidget\u0026gt; parentDataElement = _findAncestorParentDataElement(); if (parentDataElement != null) _updateParentData(parentDataElement.widget); } RenderObjectElement _findAncestorRenderObjectElement() { Element ancestor = _parent; while (ancestor != null \u0026amp;\u0026amp; ancestor is! RenderObjectElement) ancestor = ancestor._parent; return ancestor; } ParentDataElement\u0026lt;RenderObjectWidget\u0026gt; _findAncestorParentDataElement() { Element ancestor = _parent; while (ancestor != null \u0026amp;\u0026amp; ancestor is! RenderObjectElement) { if (ancestor is ParentDataElement\u0026lt;RenderObjectWidget\u0026gt;) return ancestor; ancestor = ancestor._parent; } return null; } RenderObjectElement.update(renderObjectWidget) @override void update(covariant RenderObjectWidget newWidget) { super.update(newWidget); widget.updateRenderObject(this, renderObject);//内部可能会markNeedsLayout或markNeedsPaint进行更新重绘  _dirty = false; } PipelineOwner.flushLayout \u0026ndash;\u0026gt;RenderObject._layoutWithoutResize;\nvoid _layoutWithoutResize() { performLayout(); markNeedsSemanticsUpdate(); markNeedsPaint(); } RenderFlex.performLayout /// Displays its children in a one-dimensional array. @override void performLayout() { while (child != null) { //配置childParentData供自己使用  final FlexParentData childParentData = child.parentData; //对child进行layout  child.layout(innerConstraints, parentUsesSize: true); allocatedSize += _getMainSize(child); crossSize = math.max(crossSize, _getCrossSize(child)); } //设置自己的size size = constraints.constrain(Size(idealSize, crossSize)); RenderObject.layout /// The parent\u0026#39;s [performLayout] method should call the [layout] of all its  /// children unconditionally. void layout(Constraints constraints, { bool parentUsesSize = false }) { RenderObject relayoutBoundary; if (!parentUsesSize || sizedByParent || constraints.isTight || parent is! RenderObject) { relayoutBoundary = this; } else { final RenderObject parent = this.parent; relayoutBoundary = parent._relayoutBoundary; } if (!_needsLayout \u0026amp;\u0026amp; constraints == _constraints \u0026amp;\u0026amp; relayoutBoundary == _relayoutBoundary) { return; } _constraints = constraints; _relayoutBoundary = relayoutBoundary; if (sizedByParent) { performResize(); } performLayout();//single child\u0026#39;s performLayout  markNeedsSemanticsUpdate(); _needsLayout = false; markNeedsPaint();//main RenderObject.markNeedsPaint /// Mark this render object as having changed its visual appearance.  /// * [RepaintBoundary], to scope a subtree of render objects to their own  /// layer, thus limiting the number of nodes that [markNeedsPaint] must mark  /// dirty.  void markNeedsPaint() { if (_needsPaint) return; _needsPaint = true; if (isRepaintBoundary) { // If we always have our own layer, then we can just repaint  // ourselves without involving any other nodes.  assert(_layer is OffsetLayer); if (owner != null) { owner._nodesNeedingPaint.add(this); owner.requestVisualUpdate(); } } else if (parent is RenderObject) { final RenderObject parent = this.parent; parent.markNeedsPaint(); } else { if (owner != null) owner.requestVisualUpdate(); } } PipelineOwner.flushCompositingBits \u0026ndash;\u0026gt;renderObject._updateCompositingBits();\nrenderObject._updateCompositingBits void _updateCompositingBits() { if (!_needsCompositingBitsUpdate) return; final bool oldNeedsCompositing = _needsCompositing; _needsCompositing = false; visitChildren((RenderObject child) { child._updateCompositingBits(); if (child.needsCompositing) _needsCompositing = true; }); if (isRepaintBoundary || alwaysNeedsCompositing) _needsCompositing = true; if (oldNeedsCompositing != _needsCompositing) markNeedsPaint(); _needsCompositingBitsUpdate = false; } PipelineOwner.flushPaint \u0026ndash;\u0026gt;PaintingContext.repaintCompositedChild(renderObject)\nPaintingContext.repaintCompositedChild(renderObject) /// A place to paint.  ///  /// Rather than holding a canvas directly, [RenderObject]s paint using a painting  /// context. The painting context has a [Canvas], which receives the  /// individual draw operations, and also has functions for painting child  /// render objects.  PaintingContext{} static void repaintCompositedChild(RenderObject child, { bool debugAlsoPaintedParent = false }) { assert(child._needsPaint); _repaintCompositedChild( child, debugAlsoPaintedParent: debugAlsoPaintedParent, ); } static void _repaintCompositedChild( RenderObject child, { bool debugAlsoPaintedParent = false, PaintingContext childContext, }) { assert(child.isRepaintBoundary); OffsetLayer childLayer = child._layer; if (childLayer == null) { child._layer = childLayer = OffsetLayer(); } else { assert(childLayer is OffsetLayer); childLayer.removeAllChildren(); } childContext ??= PaintingContext(child._layer, child.paintBounds); child._paintWithContext(childContext, Offset.zero);//main  // Double-check that the paint method did not replace the layer (the first  // check is done in the [layer] setter itself).  assert(identical(childLayer, child._layer)); childContext.stopRecordingIfNeeded(); renderObject._paintWithContext void _paintWithContext(PaintingContext context, Offset offset) { if (_needsLayout) return; _needsPaint = false; paint(context, offset);//main } RenderFlex.paint @override void paint(PaintingContext context, Offset offset) { if (!_hasOverflow) { defaultPaint(context, offset);//main  return; } // There\u0026#39;s no point in drawing the children if we\u0026#39;re empty.  if (size.isEmpty) return; // We have overflow. Clip it.  context.pushClipRect(needsCompositing, offset, Offset.zero \u0026amp; size, defaultPaint); paintOverflowIndicator(context, offset, Offset.zero \u0026amp; size, overflowChildRect, overflowHints: debugOverflowHints); /// Paints each child by walking the child list forwards.  void defaultPaint(PaintingContext context, Offset offset) { ChildType child = firstChild; while (child != null) { final ParentDataType childParentData = child.parentData; context.paintChild(child, childParentData.offset + offset);//main  child = childParentData.nextSibling; } } PaintingContext.paintChild /// Paint a child [RenderObject].  ///  /// If the child has its own composited layer, the child will be composited  /// into the layer subtree associated with this painting context. Otherwise,  /// the child will be painted into the current PictureLayer for this context.  /// 只有绘制边界节点才有layer。render tree的根节点renderView也是一个绘制边界 //将所有的repaintBoundary按照tree结构生成LayerTree，并用各自的offsetLayer去绘制自己和自己的children  void paintChild(RenderObject child, Offset offset) { if (child.isRepaintBoundary) { stopRecordingIfNeeded(); _compositeChild(child, offset); } else { child._paintWithContext(this, offset); } void _startRecording() { assert(!_isRecording); _currentLayer = PictureLayer(estimatedBounds);//main  _recorder = ui.PictureRecorder(); _canvas = Canvas(_recorder); _containerLayer.append(_currentLayer); } @protected @mustCallSuper void stopRecordingIfNeeded() { if (!_isRecording) return; _currentLayer.picture = _recorder.endRecording();//main  _currentLayer = null; _recorder = null; _canvas = null; void _compositeChild(RenderObject child, Offset offset) { // Create a layer for our child, and paint the child into it.  // paint 是 deepest first，因此tree底部的一条repaint boundary绘制完成后，_needsPaint为false，不会重复绘制，但要求对应的layer挂到layerTree上  if (child._needsPaint) { repaintCompositedChild(child, debugAlsoPaintedParent: true); } assert(child._layer is OffsetLayer); final OffsetLayer childOffsetLayer = child._layer; childOffsetLayer.offset = offset; appendLayer(child._layer); renderView.compositeFrame /// The root of the render tree. RenderView { /// Uploads the composited layer tree to the engine.  /// Actually causes the output of the rendering pipeline to appear on screen.  void compositeFrame() { final ui.SceneBuilder builder = ui.SceneBuilder(); final ui.Scene scene = layer.buildScene(builder);//main  if (automaticSystemUiAdjustment) _updateSystemChrome(); _window.render(scene);//执行render()将layer树发送给GPU线程,main  scene.dispose(); } ContainerLayer.buildScene /// A composited layer that has a list of children. // ContainerLayer  /// Consider this layer as the root and build a scene (a tree of layers)  /// in the engine.  // The reason this method is in the `ContainerLayer` class rather than  // `PipelineOwner` or other singleton level is because this method can be used  // both to render the whole layer tree (e.g. a normal application frame) and  // to render a subtree (e.g. `OffsetLayer.toImage`).  ui.Scene buildScene(ui.SceneBuilder builder) { updateSubtreeNeedsAddToScene(); addToScene(builder); // Clearing the flag _after_ calling `addToScene`, not _before_. This is  // because `addToScene` calls children\u0026#39;s `addToScene` methods, which may  // mark this layer as dirty.  _needsAddToScene = false; final ui.Scene scene = builder.build(); return scene; } @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { addChildrenToScene(builder, layerOffset); } /// Uploads all of this layer\u0026#39;s children to the engine. void addChildrenToScene(ui.SceneBuilder builder, [ Offset childOffset = Offset.zero ]) { Layer child = firstChild; while (child != null) { if (childOffset == Offset.zero) { child._addToSceneWithRetainedRendering(builder); } else { child.addToScene(builder, childOffset); } child = child.nextSibling; } } PictureLayer.addToScene @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { builder.addPicture(layerOffset, picture, isComplexHint: isComplexHint, willChangeHint: willChangeHint);//main  } OffsetLayer.addToScene /// A layer that is displayed at an offset from its parent layer. OffsetLayer { @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { // Skia has a fast path for concatenating scale/translation only matrices.  // Hence pushing a translation-only transform layer should be fast. For  // retained rendering, we don\u0026#39;t want to push the offset down to each leaf  // node. Otherwise, changing an offset layer on the very high level could  // cascade the change to too many leaves.  engineLayer = builder.pushOffset(layerOffset.dx + offset.dx, layerOffset.dy + offset.dy, oldLayer: _engineLayer);//main  addChildrenToScene(builder);//main  builder.pop(); } } TransformLayer.addToScene /// A composited layer that applies a given transformation matrix to its  /// children.  ///  /// This class inherits from [OffsetLayer] to make it one of the layers that  /// can be used at the root of a [RenderObject] hierarchy.  TransformLayer { @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { assert(transform != null); _lastEffectiveTransform = transform; final Offset totalOffset = offset + layerOffset; if (totalOffset != Offset.zero) { _lastEffectiveTransform = Matrix4.translationValues(totalOffset.dx, totalOffset.dy, 0.0) ..multiply(_lastEffectiveTransform); } engineLayer = builder.pushTransform(_lastEffectiveTransform.storage, oldLayer: _engineLayer); addChildrenToScene(builder);//main  builder.pop(); } } 其他 RenderObject markNeedsLayout void markNeedsLayout() { if (_needsLayout) { return; } if (_relayoutBoundary != this) { markParentNeedsLayout(); } else { _needsLayout = true; if (owner != null) { owner._nodesNeedingLayout.add(this); owner.requestVisualUpdate(); } } dropChild @override void dropChild(RenderObject child) { super.dropChild(child); markNeedsLayout(); markNeedsCompositingBitsUpdate(); markNeedsSemanticsUpdate(); } SemanticsConfiguration /// Describes the semantic information associated with the owning  /// [RenderObject].  ///  /// The information provided in the configuration is used to generate the  /// semantics tree.  SemanticsConfiguration "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/",
	"title": "zygote",
	"tags": [],
	"description": "",
	"content": "zygote 探索总结zygote知识\n SystemServerSource     ZygoteSource     Zygote进程     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/zygotesource/",
	"title": "ZygoteSource",
	"tags": [],
	"description": "",
	"content": "原理图 ZygoteInit.main public static void main(String argv[]) { ZygoteServer zygoteServer = new ZygoteServer(); for (int i = 1; i \u0026lt; argv.length; i++) { if (\u0026#34;start-system-server\u0026#34;.equals(argv[i])) { startSystemServer = true; } else if (\u0026#34;--enable-lazy-preload\u0026#34;.equals(argv[i])) { enableLazyPreload = true; } else if (argv[i].startsWith(ABI_LIST_ARG)) { abiList = argv[i].substring(ABI_LIST_ARG.length()); } else if (argv[i].startsWith(SOCKET_NAME_ARG)) { socketName = argv[i].substring(SOCKET_NAME_ARG.length()); } else { throw new RuntimeException(\u0026#34;Unknown command line argument: \u0026#34; + argv[i]); } } zygoteServer.registerServerSocketFromEnv(socketName); if (startSystemServer) { Runnable r = forkSystemServer(abiList, socketName, zygoteServer); // {@code r == null} in the parent (zygote) process, and {@code r != null} in the  // child (system_server) process.  if (r != null) { r.run(); return; } } Log.i(TAG, \u0026#34;Accepting command socket connections\u0026#34;); // The select loop returns early in the child process after a fork and  // loops forever in the zygote.  caller = zygoteServer.runSelectLoop(abiList); // We\u0026#39;re in the child process and have exited the select loop. Proceed to execute the  // command.  if (caller != null) { caller.run(); } } forkSystemServer private static Runnable forkSystemServer(String abiList, String socketName, ZygoteServer zygoteServer) { /* Request to fork the system server process */ pid = Zygote.forkSystemServer( parsedArgs.uid, parsedArgs.gid, parsedArgs.gids, parsedArgs.runtimeFlags, null, parsedArgs.permittedCapabilities, parsedArgs.effectiveCapabilities); /* For child process */ if (pid == 0) { if (hasSecondZygote(abiList)) { waitForSecondaryZygote(socketName); } zygoteServer.closeServerSocket(); return handleSystemServerProcess(parsedArgs); } /** @return 0 if this is the child, pid of the child * if this is the parent, or -1 on error. */ public static int forkSystemServer(int uid, int gid, int[] gids, int runtimeFlags, int[][] rlimits, long permittedCapabilities, long effectiveCapabilities) { int pid = nativeForkSystemServer( uid, gid, gids, runtimeFlags, rlimits, permittedCapabilities, effectiveCapabilities); // Enable tracing as soon as we enter the system_server.  if (pid == 0) { Trace.setTracingEnabled(true, runtimeFlags); } return pid; } SystemServer handleSystemServerProcess /** * Finish remaining work for the newly forked system server process. */ private static Runnable handleSystemServerProcess(ZygoteConnection.Arguments parsedArgs) { ClassLoader cl = null; if (systemServerClasspath != null) { cl = createPathClassLoader(systemServerClasspath, parsedArgs.targetSdkVersion); Thread.currentThread().setContextClassLoader(cl); } /* * Pass the remaining arguments to SystemServer. */ return ZygoteInit.zygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, cl); } zygoteInit public static final Runnable zygoteInit(int targetSdkVersion, String[] argv, ClassLoader classLoader) { Slog.d(RuntimeInit.TAG, \u0026#34;RuntimeInit: Starting application from zygote\u0026#34;); RuntimeInit.commonInit(); ZygoteInit.nativeZygoteInit(); return RuntimeInit.applicationInit(targetSdkVersion, argv, classLoader); } RuntimeInit.commonInit @UnsupportedAppUsage protected static final void commonInit() { /* * set handlers; these apply to all threads in the VM. Apps can replace * the default handler, but not the pre handler. */ LoggingHandler loggingHandler = new LoggingHandler(); RuntimeHooks.setUncaughtExceptionPreHandler(loggingHandler); Thread.setDefaultUncaughtExceptionHandler(new KillApplicationHandler(loggingHandler)); } frameworks/base/core/jni/AndroidRuntime.cpp\nnativeZygoteInit static void com_android_internal_os_ZygoteInit_nativeZygoteInit(JNIEnv* env, jobject clazz) { gCurRuntime-\u0026gt;onZygoteInit(); } frameworks/base/cmds/app_process/app_main.cpp\nvirtual void onZygoteInit() { sp\u0026lt;ProcessState\u0026gt; proc = ProcessState::self(); ALOGV(\u0026#34;App process: starting thread pool.\\n\u0026#34;); proc-\u0026gt;startThreadPool(); } RuntimeInit.applicationInit protected static Runnable applicationInit(int targetSdkVersion, String[] argv, ClassLoader classLoader) { // If the application calls System.exit(), terminate the process  // immediately without running any shutdown hooks. It is not possible to  // shutdown an Android application gracefully. Among other things, the  // Android runtime shutdown hooks close the Binder driver, which can cause  // leftover running threads to crash before the process actually exits.  nativeSetExitWithoutCleanup(true); // We want to be fairly aggressive about heap utilization, to avoid  // holding on to a lot of memory that isn\u0026#39;t needed.  VMRuntime.getRuntime().setTargetHeapUtilization(0.75f); VMRuntime.getRuntime().setTargetSdkVersion(targetSdkVersion); final Arguments args = new Arguments(argv); // The end of of the RuntimeInit event (see #zygoteInit).  Trace.traceEnd(Trace.TRACE_TAG_ACTIVITY_MANAGER); // Remaining arguments are passed to the start class\u0026#39;s static main  return findStaticMain(args.startClass, args.startArgs, classLoader); } //ActivityThread的全类名由AMS startProcess时写入到socket，zygoteServer再读取，传递过来 protected static Runnable findStaticMain(String className, String[] argv, ClassLoader classLoader) { cl = Class.forName(className, true, classLoader); Method m; m = cl.getMethod(\u0026#34;main\u0026#34;, new Class[] { String[].class }); return new MethodAndArgsCaller(m, argv); ZygoteServer runSelectLoop /** * Runs the zygote process\u0026#39;s select loop. Accepts new connections as * they happen, and reads commands from connections one spawn-request\u0026#39;s * worth at a time. */ Runnable runSelectLoop(String abiList) { ArrayList\u0026lt;FileDescriptor\u0026gt; fds = new ArrayList\u0026lt;FileDescriptor\u0026gt;(); ArrayList\u0026lt;ZygoteConnection\u0026gt; peers = new ArrayList\u0026lt;ZygoteConnection\u0026gt;(); fds.add(mServerSocket.getFileDescriptor()); peers.add(null); while (true) { StructPollfd[] pollFds = new StructPollfd[fds.size()]; for (int i = 0; i \u0026lt; pollFds.length; ++i) { pollFds[i] = new StructPollfd(); pollFds[i].fd = fds.get(i); pollFds[i].events = (short) POLLIN; } try { Os.poll(pollFds, -1); } catch (ErrnoException ex) { throw new RuntimeException(\u0026#34;poll failed\u0026#34;, ex); } for (int i = pollFds.length - 1; i \u0026gt;= 0; --i) { if ((pollFds[i].revents \u0026amp; POLLIN) == 0) { continue; } if (i == 0) { ZygoteConnection newPeer = acceptCommandPeer(abiList); peers.add(newPeer); fds.add(newPeer.getFileDesciptor()); } else { try { ZygoteConnection connection = peers.get(i); final Runnable command = connection.processOneCommand(this); } } } } ZygoteConnection.processOneCommand /** * Reads one start command from the command socket. If successful, a child is forked and a * {@code Runnable} that calls the childs main method (or equivalent) is returned in the child * process. {@code null} is always returned in the parent process (the zygote). */ Runnable processOneCommand(ZygoteServer zygoteServer) { args = readArgumentList();//读取socket数据，解析启动参数  parsedArgs = new Arguments(args); pid = Zygote.forkAndSpecialize(parsedArgs.uid, parsedArgs.gid, parsedArgs.gids, parsedArgs.runtimeFlags, rlimits, parsedArgs.mountExternal, parsedArgs.seInfo, parsedArgs.niceName, fdsToClose, fdsToIgnore, parsedArgs.startChildZygote, parsedArgs.instructionSet, parsedArgs.appDataDir); if (pid == 0) { // in child  zygoteServer.setForkChild(); zygoteServer.closeServerSocket(); IoUtils.closeQuietly(serverPipeFd); serverPipeFd = null; return handleChildProc(parsedArgs, descriptors, childPipeFd, parsedArgs.startChildZygote); } else { // In the parent. A pid \u0026lt; 0 indicates a failure and will be handled in  // handleParentProc.  IoUtils.closeQuietly(childPipeFd); childPipeFd = null; handleParentProc(pid, descriptors, serverPipeFd); return null; } ChildProcess handleChildProc private Runnable handleChildProc(Arguments parsedArgs, FileDescriptor[] descriptors, FileDescriptor pipeFd, boolean isZygote) { if (!isZygote) { return ZygoteInit.zygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, null /* classLoader */); } else { return ZygoteInit.childZygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, null /* classLoader */); } zygoteInit zygoteinit\n参考 \u0026laquo;深入理解Android 卷1 4.4.1ActivityManagerService发送请求\u0026gt;\nZygote为什么使用Socket不用Binder fork()不支持多线程，如果使用Binder则fork()时可能会丢弃binder线程池中的任务或造成死锁，而通过socket进行单线程可以解决这个问题\n安全性?\nRuntimeInit.main //没啥机会调用到\n@UnsupportedAppUsage public static final void main(String[] argv) { enableDdms(); commonInit(); /* * Now that we\u0026#39;re running in interpreted code, call back into native code * to run the system. */ nativeFinishInit(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/zygote%E8%BF%9B%E7%A8%8B/",
	"title": "Zygote进程",
	"tags": [],
	"description": "",
	"content": "What is the Zygote copy-on-write heap?\nAll \u0026ldquo;Zygote-based\u0026rdquo; processes have memory pages that are identical among them.\nThose pages are not copied, instead everything is linked to the same memory page. This reduces the amount on RAM used by all the \u0026ldquo;Zygote-based\u0026rdquo; processes.\nIf one of those process writes new data into such a page the page is automatically copied before the write actually takes place (because otherwise the memory of all forks would be changed).\nThis mechanism is called copy-on-write.\nhttps://en.wikipedia.org/wiki/Copy-on-write\nCopy-on-write From Wikipedia, the free encyclopedia\nCopy-on-write (CoW or COW), sometimes referred to as implicit sharing[1] or shadowing,[2] is a resource-management technique used in computer programming to efficiently implement a \u0026ldquo;duplicate\u0026rdquo; or \u0026ldquo;copy\u0026rdquo; operation on modifiable resources.[3] If a resource is duplicated but not modified, it is not necessary to create a new resource; the resource can be shared between the copy and the original. Modifications must still create a copy, hence the technique: the copy operation is deferred to the first write. By sharing resources in this way, it is possible to significantly reduce the resource consumption of unmodified copies, while adding a small overhead to resource-modifying operations.\nIn virtual memory management Copy-on-write finds its main use in sharing the virtual memory of operating system processes, in the implementation of the fork system call. Typically, the process does not modify any memory and immediately executes a new process, replacing the address space entirely. Thus, it would be wasteful to copy all of the process\u0026rsquo;s memory during a fork, and instead the copy-on-write technique is used.\nCopy-on-write can be implemented efficiently using the page table by marking certain pages of memory as read-only and keeping a count of the number of references to the page. When data is written to these pages, the kernel intercepts the write attempt and allocates a new physical page, initialized with the copy-on-write data, although the allocation can be skipped if there is only one reference. The kernel then updates the page table with the new (writable) page, decrements the number of references, and performs the write. The new allocation ensures that a change in the memory of one process is not visible in another\u0026rsquo;s.\nIn multithreaded systems, COW can be implemented without the use of traditional locking and instead use compare-and-swap to increment or decrement the internal reference counter. Since the original resource will never be altered, it can safely be copied by multiple threads (after the reference count was increased) without the need of performance-expensive locking such as mutexes.\nAndroid性能优化之系统资源预加载的思考\nZygote fork内存分配\nEach app process is forked from an existing process called Zygote. The Zygote process starts when the system boots and loads common framework code and resources (such as activity themes). To start a new app process, the system forks the Zygote process then loads and runs the app\u0026rsquo;s code in the new process. This approach allows most of the RAM pages allocated for framework code and resources to be shared across all app processes.\nMost static data is mmapped into a process. This technique allows data to be shared between processes, and also allows it to be paged out when needed. Example static data include: Dalvik code (by placing it in a pre-linked .odex file for direct mmapping), app resources (by designing the resource table to be a structure that can be mmapped and by aligning the zip entries of the APK), and traditional project elements like native code in .so files.\nn many places, Android shares the same dynamic RAM across processes using explicitly allocated shared memory regions (either with ashmem or gralloc). For example, window surfaces use shared memory between the app and screen compositor, and cursor buffers use shared memory between the content provider and client.\n初识Zygote进程\n第4章 深入理解 Zygote\n4.4 Zygote的分裂 前文已经讲道，Zygote分裂出嫡长子system_server后，就通过runSelectLoopMode等待并处理来自客户的消息，那么，谁会向Zygote发送消息呢？这里，以一个Activity的启动为例，具体分析Zygote是如何分裂和繁殖的。\n4.4.1 ActivityManagerService发送请求 ActivityManagerService也是由SystemServer创建的。假设通过startActivit来启动一个新的Activity，而这个Activity附属于一个还未启动的进程，那么这个进程该如何启动呢？先来看看ActivityManagerService中的startProcessLocked函数，代码如下所示：\n4.4.2 有求必应之响应请求 前面有一节，题目叫“有求必应之等待请求”，那么这一节“有求必应之响应请求”会回到ZygoteInit。下面就看看它是如何处理请求的。\nZygote分裂子进程后，自己将在handleParentProc中做一些扫尾工作，然后继续等待请求进行下一次分裂。\n这个android.app.ActivityThread类，实际上是Android中apk程序所对应的进程，它的main函数就是apk程序的main函数。从这个类的命名（android.app）中也可以看出些端倪。\n通过这一节的分析，读者可以想到，Android系统运行的那些apk程序，其父都是zygote。这一点，可以通过adb shell登录后，用ps命令查看进程和父进程号来确认。\n4.4.3 关于 Zygote分裂的总结\n源码分析 — ActivityThread(一)之main()的调用 (Android应用进程的孵化)\n小结： Zygote响应请求的流程\n Zygote 进程调用 ZygoteInit.runSelectLoop() 开启一个轮训器； SystemServer 进程发送消息到 Zygote ，在 ZygoteConnection.readArgumentList() 中接收消息； Zygote 通过 fork 创建子进程； 子进程调用android.app.ActivityThread.main() 方法；  其实，这个原理跟 Handler 的 Looper 原理很像，Looper开启一个轮训器，不断的从 MessageQueue 中获取最新的 Message，进而处理这个消息； 而在 ZygoteInit.runSelectLoop() 也是启动一个轮训器，从指定的 Socket 中读取数据，然后进行处理；\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/",
	"title": "内存优化",
	"tags": [],
	"description": "",
	"content": "内存优化 探索总结内存优化知识\n DumpHprof     Hprof_binary_dump_format     LeakCanary2Source     OOM     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%8A%A8%E7%94%BB/",
	"title": "动画",
	"tags": [],
	"description": "",
	"content": "动画 探索总结动画知识\n 动画     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%8A%A8%E7%94%BB/%E5%8A%A8%E7%94%BB/",
	"title": "动画",
	"tags": [],
	"description": "",
	"content": "类设计 原理图 AnimationController() /// An [AnimationController] needs a [TickerProvider], which is configured using  /// the `vsync` argument on the constructor.  ///  /// The [TickerProvider] interface describes a factory for [Ticker] objects. A  /// [Ticker] is an object that knows how to register itself with the  /// [SchedulerBinding] and fires a callback every frame. The  /// [AnimationController] class uses a [Ticker] to step through the animation  /// that it controls.  class AnimationController extends Animation\u0026lt;double\u0026gt; with AnimationEagerListenerMixin, AnimationLocalListenersMixin, AnimationLocalStatusListenersMixin AnimationController({ double value, this.duration, this.reverseDuration, this.debugLabel, this.lowerBound = 0.0, this.upperBound = 1.0, this.animationBehavior = AnimationBehavior.normal, @required TickerProvider vsync, }) : assert(lowerBound != null), assert(upperBound != null), assert(upperBound \u0026gt;= lowerBound), assert(vsync != null), _direction = _AnimationDirection.forward { _ticker = vsync.createTicker(_tick); _internalSetValue(value ?? lowerBound); } vsync.createTicker(_tick) SingleTickerProviderStateMixin.createTicker //mixin SingleTickerProviderStateMixin\u0026lt;T extends StatefulWidget\u0026gt; on State\u0026lt;T\u0026gt; implements TickerProvider @override Ticker createTicker(TickerCallback onTick) { _ticker = Ticker(onTick, debugLabel: kDebugMode ? \u0026#39;created by $this\u0026#39; : null); // We assume that this is called from initState, build, or some sort of  // event handler, and that thus TickerMode.of(context) would return true. We  // can\u0026#39;t actually check that here because if we\u0026#39;re in initState then we\u0026#39;re  // not allowed to do inheritance checks yet.  return _ticker; _internalSetValue void _internalSetValue(double newValue) { _value = newValue.clamp(lowerBound, upperBound); if (_value == lowerBound) { _status = AnimationStatus.dismissed; } else if (_value == upperBound) { _status = AnimationStatus.completed; } else { _status = (_direction == _AnimationDirection.forward) ? AnimationStatus.forward : AnimationStatus.reverse; } } forward /// Starts running this animation forwards (towards the end). TickerFuture forward({ double from }) { _direction = _AnimationDirection.forward; if (from != null) value = from; return _animateToInternal(upperBound);//main } _animateToInternal TickerFuture _animateToInternal(double target, { Duration duration, Curve curve = Curves.linear }) { double scale = 1.0; ...... Duration simulationDuration = duration; if (simulationDuration == null) { final double range = upperBound - lowerBound; final double remainingFraction = range.isFinite ? (target - _value).abs() / range : 1.0; final Duration directionDuration = (_direction == _AnimationDirection.reverse \u0026amp;\u0026amp; reverseDuration != null) ? reverseDuration : this.duration; simulationDuration = directionDuration * remainingFraction; } else if (target == value) { // Already at target, don\u0026#39;t animate.  simulationDuration = Duration.zero; } stop(); ...... return _startSimulation(_InterpolationSimulation(_value, target, simulationDuration, curve, scale));//main stop void stop({ bool canceled = true }) { _simulation = null; _lastElapsedDuration = null; _ticker.stop(canceled: canceled); //Ticker /// Stops calling this [Ticker]\u0026#39;s callback. void stop({ bool canceled = false }) { if (!isActive) return; final TickerFuture localFuture = _future; _future = null; _startTime = null; unscheduleTick(); if (canceled) { localFuture._cancel(this); } else { localFuture._complete(); } } /// Cancels the frame callback that was requested by [scheduleTick], if any. @protected void unscheduleTick() { if (scheduled) { SchedulerBinding.instance.cancelFrameCallbackWithId(_animationId); _animationId = null; } _startSimulation TickerFuture _startSimulation(Simulation simulation) { _simulation = simulation; _lastElapsedDuration = Duration.zero; _value = simulation.x(0.0).clamp(lowerBound, upperBound); final TickerFuture result = _ticker.start();//main  _status = (_direction == _AnimationDirection.forward) ? AnimationStatus.forward : AnimationStatus.reverse; _checkStatusChanged(); return result; Ticker.start /// Starts the clock for this [Ticker]. If the ticker is not [muted], then this  /// also starts calling the ticker\u0026#39;s callback once per animation frame.  TickerFuture start() { _future = TickerFuture._(); if (shouldScheduleTick) { scheduleTick();//main  } if (SchedulerBinding.instance.schedulerPhase.index \u0026gt; SchedulerPhase.idle.index \u0026amp;\u0026amp; SchedulerBinding.instance.schedulerPhase.index \u0026lt; SchedulerPhase.postFrameCallbacks.index) _startTime = SchedulerBinding.instance.currentFrameTimeStamp; return _future; scheduleTick /// Schedules a tick for the next frame.  ///  /// This should only be called if [shouldScheduleTick] is true.  @protected void scheduleTick({ bool rescheduling = false }) { assert(!scheduled); assert(shouldScheduleTick); _animationId = SchedulerBinding.instance.scheduleFrameCallback(_tick, rescheduling: rescheduling);//main, callback method: _tick  } SchedulerBinding.scheduleFrame int scheduleFrameCallback(FrameCallback callback, { bool rescheduling = false }) { scheduleFrame(); _nextFrameCallbackId += 1; _transientCallbacks[_nextFrameCallbackId] = _FrameCallbackEntry(callback, rescheduling: rescheduling); return _nextFrameCallbackId; } void scheduleFrame() { if (_hasScheduledFrame || !_framesEnabled) return; window.scheduleFrame(); _hasScheduledFrame = true; } //Window void scheduleFrame() native \u0026#39;Window_scheduleFrame\u0026#39;; Ticker frameCallback method _tick void _tick(Duration timeStamp) { _animationId = null; _startTime ??= timeStamp; _onTick(timeStamp - _startTime); // The onTick callback may have scheduled another tick already, for  // example by calling stop then start again.  if (shouldScheduleTick) scheduleTick(rescheduling: true); } AnimationController._tick void _tick(Duration elapsed) { _lastElapsedDuration = elapsed; final double elapsedInSeconds = elapsed.inMicroseconds.toDouble() / Duration.microsecondsPerSecond; assert(elapsedInSeconds \u0026gt;= 0.0); _value = _simulation.x(elapsedInSeconds).clamp(lowerBound, upperBound);//main, update value  if (_simulation.isDone(elapsedInSeconds)) { _status = (_direction == _AnimationDirection.forward) ? AnimationStatus.completed : AnimationStatus.dismissed; stop(canceled: false); } notifyListeners(); _checkStatusChanged(); } _InterpolationSimulation.x(double timeInSeconds) class _InterpolationSimulation extends Simulation final double _durationInSeconds; final double _begin; final double _end; final Curve _curve; @override double x(double timeInSeconds) { final double t = (timeInSeconds / _durationInSeconds).clamp(0.0, 1.0); if (t == 0.0) return _begin; else if (t == 1.0) return _end; else return _begin + (_end - _begin) * _curve.transform(t); } Animatable.animate /// Returns a new [Animation] that is driven by the given animation but that  /// takes on values determined by this object.  ///  /// Essentially this returns an [Animation] that automatically applies the  /// [evaluate] method to the parent\u0026#39;s value.  ///  /// See also:  ///  /// * [AnimationController.drive], which does the same thing from the  /// opposite starting point.  Animation\u0026lt;T\u0026gt; animate(Animation\u0026lt;double\u0026gt; parent) { return _AnimatedEvaluation\u0026lt;T\u0026gt;(parent, this); } _AnimatedEvaluation.getValue _AnimatedEvaluation\u0026lt;T\u0026gt; extends Animation\u0026lt;T\u0026gt; with AnimationWithParentMixin\u0026lt;double\u0026gt; { @override final Animation\u0026lt;double\u0026gt; parent; final Animatable\u0026lt;T\u0026gt; _evaluatable; @override T get value =\u0026gt; _evaluatable.evaluate(parent); } Animatable.evaluate T evaluate(Animation\u0026lt;double\u0026gt; animation) =\u0026gt; transform(animation.value); T transform(double t); /// A linear interpolation between a beginning and ending value. Tween\u0026lt;T extends dynamic\u0026gt; extends Animatable\u0026lt;T\u0026gt; { /// Returns the interpolated value for the current value of the given animation.  @override T transform(double t) { if (t == 0.0) return begin; if (t == 1.0) return end; return lerp(t); } /// Returns the value this variable has at the given animation clock value.  @protected T lerp(double t) { return begin + (end - begin) * t; } } Demo import \u0026#39;package:flutter/animation.dart\u0026#39;; import \u0026#39;package:flutter/material.dart\u0026#39;; void main() =\u0026gt; runApp(LogoApp()); { _LogoAppState createState() =\u0026gt; _LogoAppState(); } class _LogoAppState extends State\u0026lt;LogoApp\u0026gt; { class _LogoAppState extends State\u0026lt;LogoApp\u0026gt; with SingleTickerProviderStateMixin { Animation\u0026lt;double\u0026gt; animation; AnimationController controller; @override void initState() { super.initState(); controller = AnimationController(duration: const Duration(seconds: 2), vsync: this); animation = Tween\u0026lt;double\u0026gt;(begin: 0, end: 300).animate(controller) ..addListener(() { setState(() { // The state that has changed here is the animation object’s value.  }); }); controller.forward(); } @override Widget build(BuildContext context) { return Center( child: Container( margin: EdgeInsets.symmetric(vertical: 10), height: 300, width: 300, height: animation.value, width: animation.value, child: FlutterLogo(), ), ); } @override void dispose() { controller.dispose(); super.dispose(); } } AnimatedWidget /// A widget that rebuilds when the given [Listenable] changes value. abstract class AnimatedWidget extends StatefulWidget { /// Creates a widget that rebuilds when the given listenable changes.  ///  /// The [listenable] argument is required.  const AnimatedWidget({ Key key, @required this.listenable, }) /// Subclasses typically do not override this method.  @override _AnimatedState createState() =\u0026gt; _AnimatedState(); class _AnimatedState extends State\u0026lt;AnimatedWidget\u0026gt; { @override void initState() { super.initState(); widget.listenable.addListener(_handleChange); } @override void dispose() { widget.listenable.removeListener(_handleChange); super.dispose(); } void _handleChange() { setState(() { // The listenable\u0026#39;s state is our build state, and it changed already.  }); } AnimatedBuilder /// A general-purpose widget for building animations. class AnimatedBuilder extends AnimatedWidget { /// Creates an animated builder.  ///  /// The [animation] and [builder] arguments must not be null.  const AnimatedBuilder({ Key key, @required Listenable animation, @required this.builder, this.child, }) 参考 https://flutter.dev/docs/development/ui/animations\n深入理解Flutter动画原理\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/ashmem/%E5%8C%BF%E5%90%8D%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98ashmem/",
	"title": "匿名共享内存Ashmem",
	"tags": [],
	"description": "",
	"content": "原理图 sequenceDiagram sharedMemory-\u0026gt;\u0026gt;+ashmem_dev: 1: ashmem_create_region ashmem_dev-\u0026gt;\u0026gt;ashmem_dev : fd = __ashmem_open() 创建ashmem_area放入file-\u0026gt;private_data ashmem_dev-\u0026gt;\u0026gt;ashmem_dev: ioctl(fd, ASHMEM_SET_NAME, buf) ashmem_dev-\u0026gt;\u0026gt;ashmem_dev: ioctl(fd, ASHMEM_SET_SIZE, size) ashmem_dev-\u0026gt;\u0026gt;-sharedMemory: fd sharedMemory-\u0026gt;\u0026gt;+Os : 2: mmap Os-\u0026gt;\u0026gt;-ashmem : ashmem_mmap ashmem-\u0026gt;\u0026gt;+shmem: vmfile = shmem_file_setup shmem-\u0026gt;\u0026gt;shmem: shmem_get_inode shmem-\u0026gt;\u0026gt;-shmem: alloc_file ashmem-\u0026gt;\u0026gt;shmem: shmem_set_file sharedMemory-\u0026gt;\u0026gt;ashmem_dev: 3: native_write ashmem_dev-\u0026gt;\u0026gt;ashmem: unpinned \u0026amp;\u0026amp; ashmem_pin_region ashmem_dev-\u0026gt;\u0026gt;shmem: env-\u0026gt;GetByteArrayRegion shmem-\u0026gt;\u0026gt;+shmem: shmem_fault shmem-\u0026gt;\u0026gt;-shmem: shmem_getpage分配真实物理页 ashmem_dev-\u0026gt;\u0026gt;ashmem: ashmem_unpin_region MemoryFile public MemoryFile(String name, int length) throws IOException { try { mSharedMemory = SharedMemory.create(name, length); mMapping = mSharedMemory.mapReadWrite(); } catch (ErrnoException ex) { ex.rethrowAsIOException(); } } SharedMemory create public static @NonNull SharedMemory create(@Nullable String name, int size) throws ErrnoException { return new SharedMemory(nCreate(name, size)); } nCreate\nSharedMemory::cons private SharedMemory(FileDescriptor fd) { mFileDescriptor = fd; mSize = nGetSize(mFileDescriptor); mMemoryRegistration = new MemoryRegistration(mSize); mCleaner = Cleaner.create(mFileDescriptor, new Closer(mFileDescriptor, mMemoryRegistration)); } mapReadWrite public @NonNull ByteBuffer mapReadWrite() throws ErrnoException { return map(OsConstants.PROT_READ | OsConstants.PROT_WRITE, 0, mSize); } map public @NonNull ByteBuffer map(int prot, int offset, int length) throws ErrnoException { checkOpen(); validateProt(prot); //mmap  long address = Os.mmap(0, length, prot, OsConstants.MAP_SHARED, mFileDescriptor, offset); boolean readOnly = (prot \u0026amp; OsConstants.PROT_WRITE) == 0; Runnable unmapper = new Unmapper(address, length, mMemoryRegistration.acquire()); return new DirectByteBuffer(length, address, mFileDescriptor, unmapper, readOnly); } Os public static long mmap(long address, long byteCount, int prot, int flags, FileDescriptor fd, long offset) throws ErrnoException { // BlockGuardOs extends ForwardingOs中被代理的Os的mmap,也就是Linux的mmap  return Libcore.os.mmap(address, byteCount, prot, flags, fd, offset); } Libcore public final class Libcore { private Libcore() { } /** * Direct access to syscalls. Code should strongly prefer using {@link #os} * unless it has a strong reason to bypass the helpful checks/guards that it * provides. */ public static Os rawOs = new Linux(); /** * Access to syscalls with helpful checks/guards. */ public static Os os = new BlockGuardOs(rawOs); } Linux mmap public native long mmap(long address, long byteCount, int prot, int flags, FileDescriptor fd, long offset) throws ErrnoException; frameworks/base/core/jni/android_os_SharedMemory.cpp\nandroid_os_SharedMemory SharedMemory_create static jobject SharedMemory_create(JNIEnv* env, jobject, jstring jname, jint size) { // Name is optional so we can\u0026#39;t use ScopedUtfChars for this as it throws NPE on null  const char* name = jname ? env-\u0026gt;GetStringUTFChars(jname, nullptr) : nullptr; int fd = ashmem_create_region(name, size); // Capture the error, if there is one, before calling ReleaseStringUTFChars  int err = fd \u0026lt; 0 ? errno : 0; if (name) { env-\u0026gt;ReleaseStringUTFChars(jname, name); } return jniCreateFileDescriptor(env, fd); } libnativehelper/JNIHelp.cpp\nJNIHelp jniCreateFileDescriptor jobject jniCreateFileDescriptor(C_JNIEnv* env, int fd) { JNIEnv* e = reinterpret_cast\u0026lt;JNIEnv*\u0026gt;(env); if (fileDescriptorInitMethod == nullptr) { InitFieldsAndMethods(e); } jobject fileDescriptor = (*env)-\u0026gt;NewObject(e, JniConstants::fileDescriptorClass, fileDescriptorInitMethod); // NOTE: NewObject ensures that an OutOfMemoryError will be seen by the Java  // caller if the alloc fails, so we just return NULL when that happens.  if (fileDescriptor != NULL) { jniSetFileDescriptorOfFD(env, fileDescriptor, fd); } return fileDescriptor; } system/core/libcutils/ashmem-dev.cpp\nashmem-dev #define ASHMEM_DEVICE \u0026#34;/dev/ashmem\u0026#34; ashmem_create_region /* * ashmem_create_region - creates a new ashmem region and returns the file * descriptor, or \u0026lt;0 on error * * `name\u0026#39; is an optional label to give the region (visible in /proc/pid/maps) * `size\u0026#39; is the size of the region, in page-aligned bytes */ int ashmem_create_region(const char *name, size_t size) { int ret, save_errno; int fd = __ashmem_open(); if (fd \u0026lt; 0) { return fd; } if (name) { char buf[ASHMEM_NAME_LEN] = {0}; strlcpy(buf, name, sizeof(buf)); ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_NAME, buf)); } ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_SIZE, size)); return fd; } __ashmem_open static int __ashmem_open() { int fd; pthread_mutex_lock(\u0026amp;__ashmem_lock); fd = __ashmem_open_locked(); pthread_mutex_unlock(\u0026amp;__ashmem_lock); return fd; } __ashmem_open_locked /* logistics of getting file descriptor for ashmem */ static int __ashmem_open_locked() { int ret; struct stat st; int fd = TEMP_FAILURE_RETRY(open(ASHMEM_DEVICE, O_RDWR | O_CLOEXEC)); if (fd \u0026lt; 0) { return fd; } ret = TEMP_FAILURE_RETRY(fstat(fd, \u0026amp;st)); __ashmem_rdev = st.st_rdev; return fd; } drivers/staging/android/ashmem.c\nashmem.c #define ASHMEM_NAME_DEF\t\u0026#34;dev/ashmem\u0026#34; ashmem_open static int ashmem_open(struct inode *inode, struct file *file) { struct ashmem_area *asma; int ret; ret = generic_file_open(inode, file); if (unlikely(ret)) return ret; asma = kmem_cache_zalloc(ashmem_area_cachep, GFP_KERNEL); if (unlikely(!asma)) return -ENOMEM; INIT_LIST_HEAD(\u0026amp;asma-\u0026gt;unpinned_list); memcpy(asma-\u0026gt;name, ASHMEM_NAME_PREFIX, ASHMEM_NAME_PREFIX_LEN); asma-\u0026gt;prot_mask = PROT_MASK; file-\u0026gt;private_data = asma; return 0; } ashmem_mmap static int ashmem_mmap(struct file *file, struct vm_area_struct *vma) { struct ashmem_area *asma = file-\u0026gt;private_data; int ret = 0; if (!asma-\u0026gt;file) { char *name = ASHMEM_NAME_DEF; struct file *vmfile; if (asma-\u0026gt;name[ASHMEM_NAME_PREFIX_LEN] != \u0026#39;\\0\u0026#39;) name = asma-\u0026gt;name; /* ... and allocate the backing shmem file */ //shmem_file_setup是原生linux的共享内存机制,匿名共享内存其实就是在Linux共享内存的基础上做了改进 \tvmfile = shmem_file_setup(name, asma-\u0026gt;size, vma-\u0026gt;vm_flags); if (IS_ERR(vmfile)) { ret = PTR_ERR(vmfile); goto out; } vmfile-\u0026gt;f_mode |= FMODE_LSEEK; asma-\u0026gt;file = vmfile; } get_file(asma-\u0026gt;file); if (vma-\u0026gt;vm_flags \u0026amp; VM_SHARED) shmem_set_file(vma, asma-\u0026gt;file); else { if (vma-\u0026gt;vm_file) fput(vma-\u0026gt;vm_file); vma-\u0026gt;vm_file = asma-\u0026gt;file; } return ret; } mm/shmem.c\nshmem.c shmem_file_setup /** * shmem_file_setup - get an unlinked file living in tmpfs * @name: name for dentry (to be seen in /proc/\u0026lt;pid\u0026gt;/maps * @size: size to be set for the file * @flags: VM_NORESERVE suppresses pre-accounting of the entire object size */ struct file *shmem_file_setup(const char *name, loff_t size, unsigned long flags) { return __shmem_file_setup(name, size, flags, 0); } __shmem_file_setup static struct file *__shmem_file_setup(const char *name, loff_t size, unsigned long flags, unsigned int i_flags) { inode = shmem_get_inode(sb, NULL, S_IFREG | S_IRWXUGO, 0, flags);//分配inode，分配成功就好比建立了文件，也许并未存在真实文件映射  res = alloc_file(\u0026amp;path, FMODE_WRITE | FMODE_READ, \u0026amp;shmem_file_operations); return res; } shmem_set_file void shmem_set_file(struct vm_area_struct *vma, struct file *file) { if (vma-\u0026gt;vm_file) fput(vma-\u0026gt;vm_file); vma-\u0026gt;vm_file = file; vma-\u0026gt;vm_ops = \u0026amp;shmem_vm_ops; } //TODO shmem_vm_ops结构体的定义是下面两者中的哪一种，通过debug确定\nstatic const struct vm_operations_struct shmem_vm_ops = { .fault\t= shmem_fault, .map_pages\t= filemap_map_pages, #ifdef CONFIG_NUMA \t.set_policy = shmem_set_policy, .get_policy = shmem_get_policy, #endif }; #define shmem_vm_ops\tgeneric_file_vm_ops  const struct vm_operations_struct generic_file_vm_ops = { .fault\t= filemap_fault, .map_pages\t= filemap_map_pages, .page_mkwrite\t= filemap_page_mkwrite, }; 参考 Android匿名共享内存（Ashmem）原理\nAndroid系统匿名共享内存（Anonymous Shared Memory）C++调用接口分析（1）\n"
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/%E5%8D%8F%E7%A8%8B/",
	"title": "协程",
	"tags": [],
	"description": "",
	"content": "协程 探索总结协程知识\n kotlin协程     kotlin协程Source     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%90%8E%E5%8F%B0%E4%BB%BB%E5%8A%A1/",
	"title": "后台任务",
	"tags": [],
	"description": "",
	"content": "后台任务 探索总结后台任务知识\n 后台任务处理     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%90%8E%E5%8F%B0%E4%BB%BB%E5%8A%A1/%E5%90%8E%E5%8F%B0%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86/",
	"title": "后台任务处理",
	"tags": [],
	"description": "",
	"content": "https://developer.android.com/guide/background/\n图 1. 此决策树可帮助您确定哪个类别最适合您的后台任务。\n推荐的解决方案 下面几部分将介绍针对各个后台任务类型的推荐解决方案。\n即时任务 对于应在用户离开特定作用域或完成某项互动时结束的任务，我们建议使用 Kotlin 协程。许多 Android KTX 库都包含适用于常见应用组件（如 ViewModel）和常见应用生命周期的现成可用的协程作用域。\n如果您是 Java 编程语言用户，请参阅 Android 上的线程处理，了解推荐的选项。\n对于应立即执行并需要继续处理的任务，即使用户将应用放在后台运行或重启设备，我们也建议使用 WorkManager 并利用其对长时间运行的任务的支持。\n在特定情况下（例如使用媒体播放或主动导航功能时），您可能希望直接使用前台服务。\n延期任务 凡是不直接与用户互动相关且日后可随时运行的任务，都可以延期执行。建议为延期任务使用 WorkManager 解决方案。\n如果您希望某些可延期异步任务即使在应用退出或设备重启后仍能正常运行，使用 WorkManager 可以轻松地调度这些任务。如需了解如何调度这些类型的任务，请参阅 WorkManager 相关文档。\n精确任务 需要在精确时间点执行的任务可以使用 AlarmManager。\n如需详细了解 AlarmManager，请参阅设置重复闹铃时间。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/",
	"title": "启动流程",
	"tags": [],
	"description": "",
	"content": "启动流程 探索总结启动流程知识\n ART启动流程     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/",
	"title": "基础数据结构",
	"tags": [],
	"description": "",
	"content": "dex文件里class_def ArtField 一个ArtField对象仅仅是代表一个Java类的成员变量，但它自己并不提供空间来存储这个Java成员变量的内容。Class LinkFields时我们将看到这个Java成员变量所需的存储空间在什么地方\n.... private： GcRoot\u0026lt;mirror::Class\u0026gt; declaring_class_; //该成员变量在哪个类中被定义  uint32_t access_flags_; //该成员变量的访问标记  //该成员变量在dex文件中field_ids数组中的索引，注意，它是由图8-7中encoded_field结  //构体中field_idx_diff计算而来  uint32_t field_dex_idx_; //如果ArtField所代表的成员变量是类的静态成员变量，则下面的offset_代表是该变量实际的存储  //空间在图8-13里Class内存布局中的起始位置。如果是非静态成员变量，则offset_指向图8-13中  //Object内存布局里对应的位置。  uint32_t offset_; ArtMethod 7.0\n...... protected: //下面这四个成员变量的解释可参考图8-7  GcRoot\u0026lt;mirror::Class\u0026gt; declaring_class_; //本函数在哪个类中声明  uint32_t access_flags_; uint32_t dex_code_item_offset_; //表示某个方法在dex文件method_ids数组中的索引  uint32_t dex_method_index_; //与ArtField的field_index_类似，下面这个成员变量和Class类如何管理它的成员函数有关。  //如果这个ArtMethod对应的是一个static或direct函数，则method_index_是指向定义它的类的methods_中的索引。 //如果这个ArtMethod是virtual函数，则method_index_是指向它的VTable中的索引。注意，可能多个类的VTable都包含该//ArtMethod对象（比如Object的那11个方法），所以要保证这个method_index_在不同VTable中都有相同的值——这也是//LinkMethods中那三个函数比较复杂的原因。  uint16_t method_index_; //热度。函数每被调用一次，该值递增1。一旦超过某个阈值，该函数可能就需要被编译成本地方法以加  //快执行速度了。  uint16_t hotness_count_; struct PACKED(4) PtrSizedFields { //指向declaring_class_-\u0026gt;dex_cache_的resolved_methods_成员，详情需结合下文对Dex-Cache的介绍。  ArtMethod** dex_cache_resolved_methods_; //指针的指针，指向declaring_class_-\u0026gt;dex_cache_的dex_cache_resolved_types_成员，详情需结合下文对DexCache的介绍  GcRoot\u0026lt;mirror::Class\u0026gt;* dex_cache_resolved_types_; //下面两个变量是函数指针，它们是一个ArtMethod对象代表的Java方法的入口函数地址。  //我们后续章节介绍Java代码执行的时候再来讨论它  void* entry_point_from_jni_; // Method dispatch from quick compiled code invokes this pointer which may cause bridging into  // the interpreter.  void* entry_point_from_quick_compiled_code_; } ptr_sized_fields_; } 9.0上的差异\n// Must be the last fields in the method.  struct PtrSizedFields { // Depending on the method type, the data is  // - native method: pointer to the JNI function registered to this method  // or a function to resolve the JNI function,  // - conflict method: ImtConflictTable,  // - abstract/interface method: the single-implementation if any,  // - proxy method: the original interface method or constructor,  // - other methods: the profiling data.  void* data_; // Method dispatch from quick compiled code invokes this pointer which may cause bridging into  // the interpreter.  void* entry_point_from_quick_compiled_code_; } ptr_sized_fields_; DexCache ..... private: HeapReference\u0026lt;Object\u0026gt; dex_; //dex文件对应的路径  HeapReference\u0026lt;String\u0026gt; location_; //实际为DexFile*，指向所关联的那个Dex文件。  uint64_t dex_file_; /*实际为ArtField**，指向ArtField*数组，成员的数据类型为ArtField*。该数组存储了一个Dex 文件中定义的所有类的成员变量。另外，只有那些经解析后得到的ArtField对象才会存到这个数组里。 该字段和Dex文件里的field_ids数组有关。 */ uint64_t resolved_fields_; /*实际为ArtMethod**，指向ArtMethod*数组，成员的数据类型为ArtMethod*。该数组存储了一个 Dex文件中定义的所有类的成员函数。另外，只有那些经解析后得到的ArtMethod对象才会存到这 个数组里。该字段和Dex文件里的method_ids数组有关。 */ uint64_t resolved_methods_; /*实际为GCRoot\u0026lt;Class\u0026gt;*，指向GcRoot\u0026lt;Class\u0026gt;数组，成员的数据类型为GcRoot\u0026lt;Class\u0026gt;（本质 质上就是mirror::Class*）,它存储的内容直接指向dex文件里用到的或自定义数据类型所对应的Class对象。它存储该dex文件里使用的数据类型信息数组。该字段和Dex文件里的type_ids数组有关。 */ uint64_t resolved_types_; /*实际为GCRoot\u0026lt;String\u0026gt;*，指向GcRoot\u0026lt;String\u0026gt;数组，包括该dex文件里使用的字符串信息数组。 注意，GcRoot\u0026lt;String\u0026gt;本质上就是mirror::String*。该字段和Dex文件的string_ids数组有关 */ uint64_t strings_; //下面四个变量分别表示上述四个数组的长度  uint32_t num_resolved_fields_; uint32_t num_resolved_methods_; uint32_t num_resolved_types_; uint32_t num_strings_; }; class Class : public Object public: /*下面这个枚举变量用于描述类的状态。上文曾介绍过，一个类从dex文件里被加载到最终能被使 用将经历很多个操作步骤。这些操作并不是连续执行的，而是可能被分散在不同的地方以不同的时 机来执行不同的操作。所以，需要过类的状态来描述某个类当前处于什么阶段，这样便可知道下一 步需要做什么工作。Class对象创建之初，其状态为kStatusNotReady，最终可正常使用的状 态为kStatusInitialized。下文分析类加载的相关代码时，读者可看到状态是如何转变的。 */ enum Status { kStatusRetired = -2, kStatusError = -1, kStatusNotReady = 0, kStatusIdx = 1, kStatusLoaded = 2, kStatusResolving = 3, kStatusResolved = 4, kStatusVerifying = 5, kStatusRetryVerificationAtRuntime = 6, kStatusVerifyingAtRuntime = 7, kStatusVerified = 8, kStatusInitializing = 9, kStatusInitialized = 10, kStatusMax = 11, }; //加载本类的ClassLoader对象，如果为空，则为bootstrap system loader  HeapReference\u0026lt;ClassLoader\u0026gt; class_loader_; //下面这个成员变量对数组类才有意义，用于表示数组元素的类型。比如，对String[][][]类而  //言，component_type_代表String[][]。本章后文介绍数组类的时候还会讨论它。  HeapReference\u0026lt;Class\u0026gt; component_type_; //该类缓存在哪个DexCahce对象中。注意，有些类是由虚拟机直接创建的，而不是从Dex文件里  //读取的。比如基础数据类型。这种情况下dex_cache_取值为空。  HeapReference\u0026lt;DexCache\u0026gt; dex_cache_; /*结合图8-6可知，IfTable从ObjectArray\u0026lt;Object\u0026gt;派生，所以它实际上是一个数组容器。 为什么不直接使用它的父类ObjectArray\u0026lt;Object\u0026gt;呢？根据ART虚拟机的设计，IfTable中 的一个索引位置其实包含两项内容，第一项是该类所实现的接口类的Class对象，第二项则是 和第一项接口类有关的接口函数信息。笔者先用伪代码来描述IfTable中索引x对应的内容： 第一项内容：具体位置为iftable_内部数组[x+0]，元素类型为Class*，代表某个接口类 第二项内容：具体位置为iftable_内部数组[x+1]，元素类型为PointArray*。如图8-6可知， PointArray也是一个数组。其具体内容我们下文再详述。 另外，对类A而言，它的iftable_所包含的信息来自于如下三个方面： （1）类A自己所实现的接口类。 （2）类A从父类（direct superclass）那里获取的信息。 （3）类A从接口父类（direct super interface）那里获取的信息。 笔者先不介绍上面所谓的信息具体是什么，下文将对IfTable的元素构成做详细代码分析。 */ HeapReference\u0026lt;IfTable\u0026gt; iftable_; //本类的类名  HeapReference\u0026lt;String\u0026gt; name_; //代表父类。如果本类代表Object或基础数据类型，则该成员变量为空  HeapReference\u0026lt;Class\u0026gt; super_class_; /*virtual methods table。它指向一个PointArray数组，元素的类型为ArtMethod*。 这个vtable_的内容很丰富，下面的章节会详细介绍它。 */ HeapReference\u0026lt;PointerArray\u0026gt; vtable_; //类的访问标志。该字段的低16位可虚拟机自行定义使用  uint32_t access_flags_; uint64_t dex_cache_strings_; //指向DexCache的strings_成员变量实际为LengthPrefixedArray\u0026lt;ArtField\u0026gt;，代表本  //类声明的非静态成员变量。注意，这个LengthPrefixedArray的元素类型是ArtField，不  //是ArtField*。  uint64_t ifields_; /*下面这三个变量需配合使用。其中，methods_实际为LengthPrefixedArray\u0026lt;ArtMethod\u0026gt;， 代表该类自己定义的成员函数。它包括类里定义的virtual和direct的成员函数，也包括从接 口类中继承得到的默认函数以及所谓的miranda函数（下文将介绍接口类的默认实现函数以及 miranda函数）。methods_中元素排列如下： （1）[0,virtual_methods_offset_)为本类包含的direct成员函数 （2）[virtual_methods_offset_,copied_methods_offset_)为本类包含的virtual 成员函数 （3）[copied_methods_offset_,...)为剩下的诸如miranda函数等内容 */ uint64_t methods_; uint16_t copied_methods_offset_; uint16_t virtual_methods_offset_; uint64_t sfields_; //同ifields_类似，只不过保存的是本类的静态成员变量  uint32_t class_flags_; //虚拟机内部使用  uint32_t class_size_; //当分配一个类对象时，用于说明这个类对象所需的内存大小  pid_t clinit_thread_id_; //代表执行该类初始化函数的线程ID  int32_t dex_class_def_idx_; //本类在dex文件中class_defs数组对应元素的索引  int32_t dex_type_idx_; //本类在dex文件里type_ids中的索引  //下面两个成员变量表示本类定义的引用类型的非静态和静态成员变量的个数  uint32_t num_reference_instance_fields_; uint32_t num_reference_static_fields_; //该类的实例所占据的内存大小。也就是我们在Java层new一个该类的实例时，这个实例所需的内存大小  uint32_t object_size_; /*下面这个变量的低16位存储的是Primitive::Type枚举值，其定义如下： enum Type { kPrimNot = 0, kPrimBoolean, kPrimByte, kPrimChar, kPrimShort, kPrimInt, kPrimLong, kPrimFloat, kPrimDouble, kPrimVoid, kPrimInt, kPrimLong, kPrimFloat, kPrimDouble, kPrimVoid, kPrimLast = kPrimVoid }; 其中，kPrimNot表示非基础数据类型，即它代表引用类型。 primitive_type_的高16位另有作用，后文碰到再述 */ uint32_t primitive_type_; //下面这个变量指向一个内存地址，该地址中存储的是一个位图，它和Class中用于表示引用类型  //的非静态成员变量的信息（ifields）有关。  uint32_t reference_instance_offsets_; Status status_; //类的状态  /*特别注意。虽然下面三个成员变量定义在注释语句中，但实际的Class对象内存空间可能包含 对应的内容，笔者称之为Class的隐含成员变量。它们的取值情况我们下文会详细介绍*/ /*Embedded Imtable（内嵌Interface Method Table）,是一个固定大小的数组。数组元素 的类型为ImTableEntry，但代码中并不存在这样的数据类型。实际上，下面这个隐含成员变量 的声明可用 ArtMethod* embedded_imtable_[0]来表示 */ //ImTableEntry embedded_imtable_[0];  /*Embedded Vtable（内嵌Virtual Table），是一个非固定大小的数组。数组元素为VTable- Entry，但代码中也不存在这样的数据类型。和上面的embedded_imtable_类似，它的声明 也可用ArtMethod* embedded_vtable_[0]来表示 */。 //VTableEntry embedded_vtable_[0];  //下面这个数组存储Class中的静态成员变量的信息  //uint32_t fields_[0];  //再次请读者注意，以上三个隐含成员变量的内容将在下文介绍。  //指向代表java/lang/Class的类对象。注意，它是static类型，它不是隐含成员变量  static GcRoot\u0026lt;Class\u0026gt; java_lang_Class_; }; "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/",
	"title": "多进程",
	"tags": [],
	"description": "",
	"content": "多进程 探索总结多进程知识\n binder    BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理      mmkv    MMKV      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%80%E5%87%BA/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8/",
	"title": "应用启动",
	"tags": [],
	"description": "",
	"content": "原理图 上述流程4——5之间还有一个过程，即当ActivityManagerService调用attachApplicationLocked时会跨进程调用thread.bindApplication通知应用进程发消息并调用handleBindApplication，内部会第一次初始化应用进程的mResources和mClassLoader给LoadedApk\nActivity.startActivity public void startActivityForResult(@RequiresPermission Intent intent, int requestCode, @Nullable Bundle options) { if (mParent == null) { options = transferSpringboardActivityOptions(options); Instrumentation.ActivityResult ar = mInstrumentation.execStartActivity( this, mMainThread.getApplicationThread(), mToken, this, intent, requestCode, options); } } Instrumentation.execStartActivity public ActivityResult execStartActivity( Context who, IBinder contextThread, IBinder token, Activity target, Intent intent, int requestCode, Bundle options) { IApplicationThread whoThread = (IApplicationThread) contextThread; int result = ActivityManager.getService() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target != null ? target.mEmbeddedID : null, requestCode, 0, null, options); ActivityManager.getService().startActivity public static IActivityManager getService() { return IActivityManagerSingleton.get(); } private static final Singleton\u0026lt;IActivityManager\u0026gt; IActivityManagerSingleton = new Singleton\u0026lt;IActivityManager\u0026gt;() { @Override protected IActivityManager create() { final IBinder b = ServiceManager.getService(Context.ACTIVITY_SERVICE); final IActivityManager am = IActivityManager.Stub.asInterface(b); return am; } }; public abstract class Singleton\u0026lt;T\u0026gt; { private T mInstance; protected abstract T create(); public final T get() { synchronized (this) { if (mInstance == null) { mInstance = create(); } return mInstance; } } } ActivityManagerService.startActivity @Override public final int startActivity(IApplicationThread caller, String callingPackage, Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, Bundle bOptions) { return startActivityAsUser(caller, callingPackage, intent, resolvedType, resultTo, resultWho, requestCode, startFlags, profilerInfo, bOptions, UserHandle.getCallingUserId()); } public final int startActivityAsUser(IApplicationThread caller, String callingPackage, Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, Bundle bOptions, int userId, boolean validateIncomingUser) { enforceNotIsolatedCaller(\u0026#34;startActivity\u0026#34;); userId = mActivityStartController.checkTargetUser(userId, validateIncomingUser, Binder.getCallingPid(), Binder.getCallingUid(), \u0026#34;startActivityAsUser\u0026#34;); // TODO: Switch to user app stacks here.  return mActivityStartController.obtainStarter(intent, \u0026#34;startActivityAsUser\u0026#34;) .setCaller(caller) .setCallingPackage(callingPackage) .setResolvedType(resolvedType) .setResultTo(resultTo) .setResultWho(resultWho) .setRequestCode(requestCode) .setStartFlags(startFlags) .setProfilerInfo(profilerInfo) .setActivityOptions(bOptions) .setMayWait(userId) .execute(); } /** * Starts an activity based on the request parameters provided earlier. * @return The starter result. */ int execute() { return startActivity(mRequest.caller, mRequest.intent, mRequest.ephemeralIntent, mRequest.resolvedType, mRequest.activityInfo,......; } private int startActivity(IApplicationThread caller, Intent intent, Intent ephemeralIntent,......) { ActivityRecord r = new ActivityRecord(mService, callerApp, callingPid, callingUid, callingPackage, intent, resolvedType, aInfo, mService.getGlobalConfiguration(), resultRecord, resultWho, requestCode, componentSpecified, voiceSession != null, mSupervisor, checkedOptions, sourceRecord); return startActivity(r, sourceRecord, voiceSession, voiceInteractor, startFlags, true /* doResume */, checkedOptions, inTask, outActivity); } private int startActivity(final ActivityRecord r, ActivityRecord sourceRecord, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, int startFlags, boolean doResume, ActivityOptions options, TaskRecord inTask, ActivityRecord[] outActivity) { int result = START_CANCELED; try { result = startActivityUnchecked(r, sourceRecord, voiceSession, voiceInteractor, startFlags, doResume, options, inTask, outActivity); private int startActivityUnchecked(final ActivityRecord r, ActivityRecord sourceRecord, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, int startFlags, boolean doResume, ActivityOptions options, TaskRecord inTask, ActivityRecord[] outActivity) { final TaskRecord taskToAffiliate = (mLaunchTaskBehind \u0026amp;\u0026amp; mSourceRecord != null) ? mSourceRecord.getTask() : null; // Should this be considered a new task?  int result = START_SUCCESS; if (mStartActivity.resultTo == null \u0026amp;\u0026amp; mInTask == null \u0026amp;\u0026amp; !mAddingToTask \u0026amp;\u0026amp; (mLaunchFlags \u0026amp; FLAG_ACTIVITY_NEW_TASK) != 0) { newTask = true; result = setTaskFromReuseOrCreateNewTask(taskToAffiliate, topStack); } else if (mSourceRecord != null) { result = setTaskFromSourceRecord(); } else if (mInTask != null) { result = setTaskFromInTask(); } else { // This not being started from an existing activity, and not part of a new task...  // just put it in the top task, though these days this case should never happen.  setTaskToCurrentTopOrCreateNewTask(); } mSupervisor.resumeFocusedStackTopActivityLocked(mTargetStack, mStartActivity,mOptions); boolean resumeFocusedStackTopActivityLocked( ActivityStack targetStack, ActivityRecord target, ActivityOptions targetOptions) { final ActivityRecord r = mFocusedStack.topRunningActivityLocked(); if (r == null || !r.isState(RESUMED)) { mFocusedStack.resumeTopActivityUncheckedLocked(null, null); } return false; } boolean resumeTopActivityUncheckedLocked(ActivityRecord prev, ActivityOptions options) { boolean result = false; try { // Protect against recursion.  mStackSupervisor.inResumeTopActivity = true; result = resumeTopActivityInnerLocked(prev, options); } finally { mStackSupervisor.inResumeTopActivity = false; } return result; } @GuardedBy(\u0026#34;mService\u0026#34;) private boolean resumeTopActivityInnerLocked(ActivityRecord prev, ActivityOptions options) { mStackSupervisor.startSpecificActivityLocked(next, true, false); } void startSpecificActivityLocked(ActivityRecord r, boolean andResume, boolean checkConfig) { // Is this activity\u0026#39;s application already running?  ProcessRecord app = mService.getProcessRecordLocked(r.processName, r.info.applicationInfo.uid, true); if (app != null \u0026amp;\u0026amp; app.thread != null) { //进程已经启动  try { if ((r.info.flags\u0026amp;ActivityInfo.FLAG_MULTIPROCESS) == 0 || !\u0026#34;android\u0026#34;.equals(r.info.packageName)) { // Don\u0026#39;t add this if it is a platform component that is marked  // to run in multiple processes, because this is actually  // part of the framework so doesn\u0026#39;t make sense to track as a  // separate apk in the process.  app.addPackage(r.info.packageName, r.info.applicationInfo.longVersionCode, mService.mProcessStats); } realStartActivityLocked(r, app, andResume, checkConfig); return; } } //启动应用进程  mService.startProcessLocked(r.processName, r.info.applicationInfo, true, 0, \u0026#34;activity\u0026#34;, r.intent.getComponent(), false, false, true); } startProcessLocked @GuardedBy(\u0026#34;this\u0026#34;) final ProcessRecord startProcessLocked(String processName, ApplicationInfo info, boolean knownToBeDead, int intentFlags, String hostingType, ComponentName hostingName, boolean allowWhileBooting, boolean isolated, boolean keepIfLarge) { return startProcessLocked(processName, info, knownToBeDead, intentFlags, hostingType, hostingName, allowWhileBooting, isolated, 0 /* isolatedUid */, keepIfLarge, null /* ABI override */, null /* entryPoint */, null /* entryPointArgs */, null /* crashHandler */); } @GuardedBy(\u0026#34;this\u0026#34;) final ProcessRecord startProcessLocked(String processName, ApplicationInfo info, boolean knownToBeDead, int intentFlags, String hostingType, ComponentName hostingName, boolean allowWhileBooting, boolean isolated, int isolatedUid, boolean keepIfLarge, String abiOverride, String entryPoint, String[] entryPointArgs, Runnable crashHandler) { ProcessRecord app; if (app == null) { app = newProcessRecordLocked(info, processName, isolated, isolatedUid); } final boolean success = startProcessLocked(app, hostingType, hostingNameStr, abiOverride); return success ? app : null; } @GuardedBy(\u0026#34;this\u0026#34;) private final boolean startProcessLocked(ProcessRecord app, String hostingType, String hostingNameStr, String abiOverride) { return startProcessLocked(app, hostingType, hostingNameStr, false /* disableHiddenApiChecks */, abiOverride); } /** * @return {@code true} if process start is successful, false otherwise. */ @GuardedBy(\u0026#34;this\u0026#34;) private final boolean startProcessLocked(ProcessRecord app, String hostingType, String hostingNameStr, boolean disableHiddenApiChecks, String abiOverride) { ...... return startProcessLocked(hostingType, hostingNameStr, entryPoint, app, uid, gids, runtimeFlags, mountExternal, seInfo, requiredAbi, instructionSet, invokeWith, startTime); } @GuardedBy(\u0026#34;this\u0026#34;) private boolean startProcessLocked(String hostingType, String hostingNameStr, String entryPoint, ProcessRecord app, int uid, int[] gids, int runtimeFlags, int mountExternal, String seInfo, String requiredAbi, String instructionSet, String invokeWith, long startTime) { final ProcessStartResult startResult = startProcess(hostingType, entryPoint, app, uid, gids, runtimeFlags, mountExternal, seInfo, requiredAbi, instructionSet, invokeWith, startTime); } private ProcessStartResult startProcess(String hostingType, String entryPoint, ProcessRecord app, int uid, int[] gids, int runtimeFlags, int mountExternal, String seInfo, String requiredAbi, String instructionSet, String invokeWith, long startTime) { startResult = Process.start(entryPoint, app.processName, uid, uid, gids, runtimeFlags, mountExternal, app.info.targetSdkVersion, seInfo, requiredAbi, instructionSet, app.info.dataDir, invokeWith, new String[] {PROC_START_SEQ_IDENT + app.startSeq}); } public static final ZygoteProcess zygoteProcess = new ZygoteProcess(ZYGOTE_SOCKET, SECONDARY_ZYGOTE_SOCKET); public static final ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { return zygoteProcess.start(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, zygoteArgs); } frameworks/base/core/java/android/os/ZygoteProcess.java\nZygoteProcess.start /** * The name of the socket used to communicate with the primary zygote. */ private final LocalSocketAddress mSocket; /** * The name of the secondary (alternate ABI) zygote socket. */ private final LocalSocketAddress mSecondarySocket; public final Process.ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { return startViaZygote(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, false /* startChildZygote */, zygoteArgs); private Process.ProcessStartResult startViaZygote(final String processClass, final String niceName, final int uid, final int gid, final int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, boolean startChildZygote, String[] extraArgs) throws ZygoteStartFailedEx { synchronized(mLock) { return zygoteSendArgsAndGetResult(openZygoteSocketIfNeeded(abi), argsForZygote); } } openZygoteSocketIfNeeded /** * Tries to open socket to Zygote process if not already open. If * already open, does nothing. May block and retry. Requires that mLock be held. */ @GuardedBy(\u0026#34;mLock\u0026#34;) private ZygoteState openZygoteSocketIfNeeded(String abi) throws ZygoteStartFailedEx { if (primaryZygoteState == null || primaryZygoteState.isClosed()) { primaryZygoteState = ZygoteState.connect(mSocket); } if (primaryZygoteState.matches(abi)) { return primaryZygoteState; } // The primary zygote didn\u0026#39;t match. Try the secondary.  if (secondaryZygoteState == null || secondaryZygoteState.isClosed()) { secondaryZygoteState = ZygoteState.connect(mSecondarySocket); } if (secondaryZygoteState.matches(abi)) { return secondaryZygoteState; } public static ZygoteState connect(LocalSocketAddress address) throws IOException { DataInputStream zygoteInputStream = null; BufferedWriter zygoteWriter = null; final LocalSocket zygoteSocket = new LocalSocket(); zygoteSocket.connect(address); //inputStream，读取Zygote发来的数据  zygoteInputStream = new DataInputStream(zygoteSocket.getInputStream()); //outputStream,写入socket数据  zygoteWriter = new BufferedWriter(new OutputStreamWriter(zygoteSocket.getOutputStream()), 256); String abiListString = getAbiList(zygoteWriter, zygoteInputStream); return new ZygoteState(zygoteSocket, zygoteInputStream, zygoteWriter, Arrays.asList(abiListString.split(\u0026#34;,\u0026#34;))); } /** * Queries the zygote for the list of ABIS it supports. */ @GuardedBy(\u0026#34;mLock\u0026#34;) private static String getAbiList(BufferedWriter writer, DataInputStream inputStream) throws IOException { // Each query starts with the argument count (1 in this case)  writer.write(\u0026#34;1\u0026#34;); // ... followed by a new-line.  writer.newLine(); // ... followed by our only argument.  writer.write(\u0026#34;--query-abi-list\u0026#34;); writer.newLine(); writer.flush(); // The response is a length prefixed stream of ASCII bytes.  int numBytes = inputStream.readInt(); byte[] bytes = new byte[numBytes]; inputStream.readFully(bytes); return new String(bytes, StandardCharsets.US_ASCII); } zygoteSendArgsAndGetResult /** * Sends an argument list to the zygote process, which starts a new child * and returns the child\u0026#39;s pid. Please note: the present implementation * replaces newlines in the argument list with spaces. * * @throws ZygoteStartFailedEx if process start failed for any reason */ @GuardedBy(\u0026#34;mLock\u0026#34;) private static Process.ProcessStartResult zygoteSendArgsAndGetResult( ZygoteState zygoteState, ArrayList\u0026lt;String\u0026gt; args) throws ZygoteStartFailedEx { /** * See com.android.internal.os.SystemZygoteInit.readArgumentList() * Presently the wire format to the zygote process is: * a) a count of arguments (argc, in essence) * b) a number of newline-separated argument strings equal to count * * After the zygote process reads these it will write the pid of * the child or -1 on failure, followed by boolean to * indicate whether a wrapper process was used. */ final BufferedWriter writer = zygoteState.writer; final DataInputStream inputStream = zygoteState.inputStream; writer.write(Integer.toString(args.size())); writer.newLine(); for (int i = 0; i \u0026lt; sz; i++) { String arg = args.get(i); writer.write(arg); writer.newLine(); } writer.flush(); // Should there be a timeout on this?  Process.ProcessStartResult result = new Process.ProcessStartResult(); // Always read the entire result from the input stream to avoid leaving  // bytes in the stream for future process starts to accidentally stumble  // upon.  result.pid = inputStream.readInt(); result.usingWrapper = inputStream.readBoolean(); return result; Zygote启动AppProcess 参考\nActivityThread.main final ApplicationThread mAppThread = new ApplicationThread(); Looper.prepareMainLooper(); public static void main(String[] args) { Looper.prepareMainLooper(); } IActivityManager.attachApplication ActivityThread thread = new ActivityThread(); thread.attach(false, startSeq); private void attach(boolean system, long startSeq) { RuntimeInit.setApplicationObject(mAppThread.asBinder()); final IActivityManager mgr = ActivityManager.getService(); try { mgr.attachApplication(mAppThread, startSeq); } catch (RemoteException ex) { throw ex.rethrowFromSystemServer(); } } Looper.loop() Looper.loop(); ActivityManagerService.attachApplication @Override public final void attachApplication(IApplicationThread thread, long startSeq) { synchronized (this) { int callingPid = Binder.getCallingPid(); final int callingUid = Binder.getCallingUid(); final long origId = Binder.clearCallingIdentity(); attachApplicationLocked(thread, callingPid, callingUid, startSeq); Binder.restoreCallingIdentity(origId); } } @GuardedBy(\u0026#34;this\u0026#34;) private final boolean attachApplicationLocked(IApplicationThread thread, int pid, int callingUid, long startSeq) { AppDeathRecipient adr = new AppDeathRecipient(app, pid, thread); thread.asBinder().linkToDeath(adr, 0); app.deathRecipient = adr; thread.bindApplication(....) StackSupervisor.attachApplicationLocked(app)//realStartActivityLocked  } linkToDeath配置AppDeathRecipient监听appDeath private final class AppDeathRecipient implements IBinder.DeathRecipient { final ProcessRecord mApp; final int mPid; final IApplicationThread mAppThread; @Override public void binderDied() { synchronized(ActivityManagerService.this) { appDiedLocked(mApp, mPid, mAppThread, true); } } } thread.bindApplication class ApplicationThread { public final void bindApplication(String processName, ApplicationInfo appInfo, List\u0026lt;ProviderInfo\u0026gt; providers, ComponentName instrumentationName, ProfilerInfo profilerInfo, Bundle instrumentationArgs, IInstrumentationWatcher instrumentationWatcher, IUiAutomationConnection instrumentationUiConnection, int debugMode, boolean enableBinderTracking, boolean trackAllocation, boolean isRestrictedBackupMode, boolean persistent, Configuration config, CompatibilityInfo compatInfo, Map services, Bundle coreSettings, String buildSerial, boolean autofillCompatibilityEnabled) { sendMessage(H.BIND_APPLICATION, data); } public void handleMessage(Message msg) { switch (msg.what) { case BIND_APPLICATION: AppBindData data = (AppBindData)msg.obj; handleBindApplication(data); break; private void handleBindApplication(AppBindData data) { data.info = getPackageInfoNoCheck(data.appInfo, data.compatInfo); app = data.info.makeApplication(data.restrictedBackupMode, null); installContentProviders(app, data.providers); mInstrumentation.callApplicationOnCreate(app); } getPackageInfo初始化LoadedApk @Override public final LoadedApk getPackageInfoNoCheck(ApplicationInfo ai, CompatibilityInfo compatInfo) { return getPackageInfo(ai, compatInfo, null, false, true, false); } private LoadedApk getPackageInfo(ApplicationInfo aInfo, CompatibilityInfo compatInfo, ClassLoader baseLoader, boolean securityViolation, boolean includeCode, boolean registerPackage) { packageInfo = new LoadedApk(this, aInfo, compatInfo, baseLoader, securityViolation, includeCode \u0026amp;\u0026amp; (aInfo.flags\u0026amp;ApplicationInfo.FLAG_HAS_CODE) != 0, registerPackage); } LoadedApk.makeApplication public Application makeApplication(boolean forceDefaultAppClass, Instrumentation instrumentation) { if (mApplication != null) { return mApplication; } java.lang.ClassLoader cl = getClassLoader(); ContextImpl appContext = ContextImpl.createAppContext(mActivityThread, this); app = mActivityThread.mInstrumentation.newApplication(cl, appClass, appContext); appContext.setOuterContext(app); } public ClassLoader getClassLoader() { synchronized (this) { if (mClassLoader == null) { createOrUpdateClassLoaderLocked(null /*addedPaths*/); } return mClassLoader; } } public Application newApplication(ClassLoader cl, String className, Context context) throws InstantiationException, IllegalAccessException, ClassNotFoundException { Application app = getFactory(context.getPackageName()) .instantiateApplication(cl, className); app.attach(context); return app; } private AppComponentFactory getFactory(String pkg) { if (pkg == null) { Log.e(TAG, \u0026#34;No pkg specified, disabling AppComponentFactory\u0026#34;); return AppComponentFactory.DEFAULT; } if (mThread == null) { Log.e(TAG, \u0026#34;Uninitialized ActivityThread, likely app-created Instrumentation,\u0026#34; + \u0026#34; disabling AppComponentFactory\u0026#34;, new Throwable()); return AppComponentFactory.DEFAULT; } LoadedApk apk = mThread.peekPackageInfo(pkg, true); // This is in the case of starting up \u0026#34;android\u0026#34;.  if (apk == null) apk = mThread.getSystemContext().mPackageInfo; return apk.getAppFactory(); } AppComponentFactory.instantiateApplication public @NonNull Application instantiateApplication(@NonNull ClassLoader cl, @NonNull String className) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (Application) cl.loadClass(className).newInstance(); } Application.attach /* package */ final void attach(Context context) { attachBaseContext(context); mLoadedApk = ContextImpl.getImpl(context).mPackageInfo; } installContentProviders mInstrumentation.callApplicationOnCreate public void callApplicationOnCreate(Application app) { app.onCreate(); } realStartActivityLocked boolean attachApplicationLocked(ProcessRecord app) throws RemoteException { realStartActivityLocked(activity, app, top == activity /* andResume */, true /* checkConfig */)) } Create activity launch transaction final boolean realStartActivityLocked(ActivityRecord r, ProcessRecord app, boolean andResume, boolean checkConfig) throws RemoteException { // Create activity launch transaction.  final ClientTransaction clientTransaction = ClientTransaction.obtain(app.thread, r.appToken); clientTransaction.addCallback(LaunchActivityItem.obtain(new Intent(r.intent), System.identityHashCode(r), r.info, // TODO: Have this take the merged configuration instead of separate global  // and override configs.  mergedConfiguration.getGlobalConfiguration(), mergedConfiguration.getOverrideConfiguration(), r.compat, r.launchedFromPackage, task.voiceInteractor, app.repProcState, r.icicle, r.persistentState, results, newIntents, mService.isNextTransitionForward(), profilerInfo)); // Set desired final state.  final ActivityLifecycleItem lifecycleItem; if (andResume) { lifecycleItem = ResumeActivityItem.obtain(mService.isNextTransitionForward()); } else { lifecycleItem = PauseActivityItem.obtain(); } clientTransaction.setLifecycleStateRequest(lifecycleItem); // Schedule transaction.  mService.getLifecycleManager().scheduleTransaction(clientTransaction); } /** * Schedule a transaction, which may consist of multiple callbacks and a lifecycle request. * @param transaction A sequence of client transaction items. * @throws RemoteException * * @see ClientTransaction */ void scheduleTransaction(ClientTransaction transaction) throws RemoteException { final IApplicationThread client = transaction.getClient(); transaction.schedule(); if (!(client instanceof Binder)) { // If client is not an instance of Binder - it\u0026#39;s a remote call and at this point it is  // safe to recycle the object. All objects used for local calls will be recycled after  // the transaction is executed on client in ActivityThread.  transaction.recycle(); } } ClientTransaction.java\n/** Get the target client of the transaction. */ public IApplicationThread getClient() { return mClient; } /** * Schedule the transaction after it was initialized. It will be send to client and all its * individual parts will be applied in the following sequence: * 1. The client calls {@link #preExecute(ClientTransactionHandler)}, which triggers all work * that needs to be done before actually scheduling the transaction for callbacks and * lifecycle state request. * 2. The transaction message is scheduled. * 3. The client calls {@link TransactionExecutor#execute(ClientTransaction)}, which executes * all callbacks and necessary lifecycle transitions. */ public void schedule() throws RemoteException { mClient.scheduleTransaction(this); } @Override public void scheduleTransaction(ClientTransaction transaction) throws RemoteException { ActivityThread.this.scheduleTransaction(transaction); } public final class ActivityThread extends ClientTransactionHandler { } /** * Defines operations that a {@link android.app.servertransaction.ClientTransaction} or its items * can perform on client. * @hide */ public abstract class ClientTransactionHandler { // Schedule phase related logic and handlers.  /** Prepare and schedule transaction for execution. */ void scheduleTransaction(ClientTransaction transaction) { transaction.preExecute(this); sendMessage(ActivityThread.H.EXECUTE_TRANSACTION, transaction); } case EXECUTE_TRANSACTION: final ClientTransaction transaction = (ClientTransaction) msg.obj; mTransactionExecutor.execute(transaction); if (isSystem()) { // Client transactions inside system process are recycled on the client side  // instead of ClientLifecycleManager to avoid being cleared before this  // message is handled.  transaction.recycle(); } // TODO(lifecycler): Recycle locally scheduled transactions.  break; public void execute(ClientTransaction transaction) { final IBinder token = transaction.getActivityToken(); executeCallbacks(transaction); } /** Cycle through all states requested by callbacks and execute them at proper times. */ @VisibleForTesting public void executeCallbacks(ClientTransaction transaction) { final List\u0026lt;ClientTransactionItem\u0026gt; callbacks = transaction.getCallbacks(); final int size = callbacks.size(); for (int i = 0; i \u0026lt; size; ++i) { final ClientTransactionItem item = callbacks.get(i); item.execute(mTransactionHandler, token, mPendingActions); LaunchActivityItem.execute @Override public void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { Trace.traceBegin(TRACE_TAG_ACTIVITY_MANAGER, \u0026#34;activityStart\u0026#34;); ActivityClientRecord r = new ActivityClientRecord(token, mIntent, mIdent, mInfo, mOverrideConfig, mCompatInfo, mReferrer, mVoiceInteractor, mState, mPersistentState, mPendingResults, mPendingNewIntents, mIsForward, mProfilerInfo, client); //ActivityThread实例  client.handleLaunchActivity(r, pendingActions, null /* customIntent */); Trace.traceEnd(TRACE_TAG_ACTIVITY_MANAGER); } newActivity activity.attach mInstrumentation.callActivityOnCreate 记录ActivityClientRecord /** * Extended implementation of activity launch. Used when server requests a launch or relaunch. */ @Override public Activity handleLaunchActivity(ActivityClientRecord r, PendingTransactionActions pendingActions, Intent customIntent) { final Activity a = performLaunchActivity(r, customIntent); } /** Core implementation of activity launch. */ private Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) { ContextImpl appContext = createBaseContextForActivity(r); Activity activity = null; java.lang.ClassLoader cl = appContext.getClassLoader(); activity = mInstrumentation.newActivity(cl, component.getClassName(), r.intent); r.intent.setExtrasClassLoader(cl); r.intent.prepareToEnterProcess(); if (r.state != null) { r.state.setClassLoader(cl); } Application app = r.packageInfo.makeApplication(false, mInstrumentation); appContext.setOuterContext(activity); activity.attach(appContext, this, getInstrumentation(), r.token, r.ident, app, r.intent, r.activityInfo, title, r.parent, r.embeddedID, r.lastNonConfigurationInstances, config, r.referrer, r.voiceInteractor, window, r.configCallback); mInstrumentation.callActivityOnCreate(activity, r.state); r.activity = activity; r.setState(ON_CREATE); mActivities.put(r.token, r); } public Activity newActivity(ClassLoader cl, String className, Intent intent) throws InstantiationException, IllegalAccessException, ClassNotFoundException { String pkg = intent != null \u0026amp;\u0026amp; intent.getComponent() != null ? intent.getComponent().getPackageName() : null; return getFactory(pkg).instantiateActivity(cl, className, intent); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%80%E5%87%BA/",
	"title": "应用启动退出",
	"tags": [],
	"description": "",
	"content": "应用启动退出 探索总结应用启动退出知识\n 应用启动     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/jni/%E5%BC%82%E5%B8%B8/",
	"title": "异常",
	"tags": [],
	"description": "",
	"content": "解释执行异常抛出和处理 被抛出的异常对象赋值给Thread tlsPtr_exception的成员变量，异常投递的工作就算完成；\n接下来就是异常处理的过程。以switch/case方式来解释执行的代码中，下面这个宏用于判断是否有异常发生并处理它。\nDex_instruction_list.h\n#define DEX_INSTRUCTION_LIST(V) \\ V(0x27, THROW, \u0026#34;throw\u0026#34;, k11x, false, kIndexNone, kThrow, kVerifyRegA) \\ interpreter_switch_impl.cc\nExecuteSwitchImpl template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; JValue ExecuteSwitchImpl(......) { ......　//该函数详情见10.2.3.1节  do { dex_pc = inst-\u0026gt;GetDexPc(insns); ...... inst_data = inst-\u0026gt;Fetch16(0); switch (inst-\u0026gt;Opcode(inst_data)) { //switch/case方式执行不同的dex指令  ...... case Instruction::THROW: { //抛异常  PREAMBLE(); Object* exception = shadow_frame.GetVRegReference( inst-\u0026gt;VRegA_11x(inst_data)); if (UNLIKELY(exception == nullptr)) { //Throw抛出的异常对象为空，则重新抛一个空指针异常  ThrowNullPointerException(\u0026#34;throw with null exception\u0026#34;); } else if (.....) {.....} else { /*注意：Thread tlsPtr_有一个名为exception的成员变量，其类型为Throwable*。 其他代码逻辑要检查是否有异常发生的话，只要判断tlsPtr_exception是否为nullptr 即可。如果tlsPtr_ exception不为空指针，则表明有异常发生。 下面的SetException函数将把抛出的异常对象赋值给tlsPtr_exception*///main  self-\u0026gt;SetException(exception-\u0026gt;AsThrowable()); } HANDLE_PENDING_EXCEPTION(); //检查是否有异常发生，并做对应处理。main  break; } ..... } HANDLE_PENDING_EXCEPTION define HANDLE_PENDING_EXCEPTION() \\ do { \\ self-\u0026gt;AllowThreadSuspension(); \\ /*下面这个函数用于从当前正在执行的方法里找到对应的catch处理语句，如果能处理所抛出 的异常，则返回异常处理对应的dex指令码的位置*/ uint32_t found_dex_pc = FindNextInstructionFollowingException(self,\\ shadow_frame, inst-\u0026gt;GetDexPc(insns), instrumentation); \\ //如果本方法无法处理这个异常，则要退出整个方法的执行  if (found_dex_pc == DexFile::kDexNoIndex) { \\ ......\\ } \\ return JValue(); /* 退出本方法的执行，调用者将继续检查并处理异常 */ \\ } else { \\ //如果本方法catch住了所抛出的异常，则找到对应的处理指令  int32_t displacement = static_cast\u0026lt;int32_t\u0026gt;(found_dex_pc) - \\static_cast\u0026lt;int32_t\u0026gt;(dex_pc); \\ inst = inst-\u0026gt;RelativeAt(displacement); \\ } \\ } while (false) interpreter_common.cc\nFindNextInstructionFollowingException uint32_t FindNextInstructionFollowingException( Thread* self, ShadowFrame\u0026amp; shadow_frame, uint32_t dex_pc, const instrumentation::Instrumentation* instrumentation) { self-\u0026gt;VerifyStack(); StackHandleScope\u0026lt;2\u0026gt; hs(self); Handle\u0026lt;mirror::Throwable\u0026gt; exception(hs.NewHandle(self-\u0026gt;GetException())); ...... bool clear_exception = false; //调用ArtMethod的FindCatchBlock。  uint32_t found_dex_pc = shadow_frame.GetMethod()-\u0026gt;FindCatchBlock( hs.NewHandle(exception-\u0026gt;GetClass()), dex_pc, \u0026amp;clear_exception); if (found_dex_pc == DexFile::kDexNoIndex \u0026amp;\u0026amp; instrumentation != nullptr) { //如果本方法无法处理这个异常，则表示要进行栈回溯。此时将触发Instrumentation的  //MethodUnwindEvent函数  instrumentation-\u0026gt;MethodUnwindEvent(self, shadow_frame.GetThisObject(), shadow_frame.GetMethod(), dex_pc); } else {......} return found_dex_pc; } ArtMethod::FindCatchBlock art_quick_to_interpreter_bridge quick_entrypoints_x86.S\nRETURN_OR_DELIVER_PENDING_EXCEPTION MACRO0(RETURN_OR_DELIVER_PENDING_EXCEPTION) #检查Thread tlsPtr_ exception变量是否为空，如果不为空，则跳转到DELIVER_PENDING_EXCEPTION宏处,main  cmpl MACRO_LITERAL(0),%fs:THREAD_EXCEPTION_OFFSET jne 1f ret 1: DELIVER_PENDING_EXCEPTION #异常处理宏 END_MACRO DELIVER_PENDING_EXCEPTION MACRO0(DELIVER_PENDING_EXCEPTION) #异常处理宏定义  #该宏内部将设置tlsPtr_ managed_stack top_quick_frame_的值  SETUP_SAVE_ALL_CALLEE_SAVE_FRAME ebx, ebx subl MACRO_LITERAL(12), %esp pushl %fs:THREAD_SELF_OFFSET #调用artDeliverPendingExceptionFromCode函数,main  call SYMBOL(artDeliverPendingExceptionFromCode) UNREACHABLE END_MACRO quick_throw_entrypoints.cc\nextern \u0026#34;C\u0026#34; NO_RETURN void artDeliverPendingExceptionFromCode(Thread* self) { ScopedQuickEntrypointChecks sqec(self); self-\u0026gt;QuickDeliverException(); //调用Thread QuickDeliverException函数 } 机器码异常抛出和处理 code_generator_x86.cc\nvoid InstructionCodeGeneratorX86::VisitThrow(HThrow* instruction) { codegen_-\u0026gt;InvokeRuntime(QUICK_ENTRY_POINT(pDeliverException), instruction, instruction-\u0026gt;GetDexPc(), nullptr); CheckEntrypointTypes\u0026lt;kQuickDeliverException, void, mirror::Object*\u0026gt;(); } quick_entrypoints_x86.S\nart_quick_deliver_exception ONE_ARG_RUNTIME_EXCEPTION art_quick_deliver_exception, \\ artDeliverExceptionFromCode #调用C++层artDeliverExceptionFromCode //ONE_ARG_RUNTIME_EXCEPTION是一个宏，其内部调用SETUP_SAVE_CALLEE_SAVE_FRAME， //由于artDeliverExceptionFromCode位于虚拟机执行层，所以需要设置tlsPtr_managed_stack top_quick_frame_ MACRO2(ONE_ARG_RUNTIME_EXCEPTION, c_name, cxx_name) DEFINE_FUNCTION VAR(c_name) SETUP_SAVE_ALL_CALLEE_SAVE_FRAME ebx, ebx mov %esp, %ecx // Outgoing argument set up subl MACRO_LITERAL(8), %esp pushl %fs:THREAD_SELF_OFFSET PUSH eax call CALLVAR(cxx_name) UNREACHABLE END_FUNCTION VAR(c_name) END_MACRO quick_throw_entrypoints.cc\nartDeliverExceptionFromCode extern \u0026#34;C\u0026#34; NO_RETURN void artDeliverExceptionFromCode( mirror::Throwable* exception, Thread* self){ ScopedQuickEntrypointChecks sqec(self); if (exception == nullptr) { self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/NullPointerException;\u0026#34;, \u0026#34;throw with null exception\u0026#34;); } else { self-\u0026gt;SetException(exception); //设置tlsPtr_ exception  } self-\u0026gt;QuickDeliverException(); //还是调用Thread类的QuickDeliverException } thread.cc\nQuickDeliverException void Thread::QuickDeliverException() { mirror::Throwable* exception = GetException(); //判断是否为Deoptimize相关的异常。此处不讨论Deoptimize的情况，所以  //is_deoptimization为false  bool is_deoptimization = (exception == GetDeoptimizationException()); if (!is_deoptimization) { instrumentation::Instrumentation* instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); if (instrumentation-\u0026gt;HasExceptionCaughtListeners() \u0026amp;\u0026amp; IsExceptionThrownByCurrentMethod(exception)) { StackHandleScope\u0026lt;1\u0026gt; hs(this); HandleWrapper\u0026lt;mirror::Throwable\u0026gt; h_exception(hs.NewHandleWrapper( \u0026amp;exception)); instrumentation-\u0026gt;ExceptionCaughtEvent(this, exception); } ...... } ClearException(); QuickExceptionHandler exception_handler(this, is_deoptimization); if (is_deoptimization) { //DeoptimizeStack函数的详情见10.4.2.2节  exception_handler.DeoptimizeStack(); } else { //FindCatch非常关键，它将找到异常处理处的指令位置（pc）,main  exception_handler.FindCatch(exception); } exception_handler.UpdateInstrumentationStack(); exception_handler.DoLongJump(); //跳转到异常处理对应的地址 } quick_exception_handler.cc\nQuickExceptionHandler::FindCatch void QuickExceptionHandler::FindCatch(mirror::Throwable* exception) { StackHandleScope\u0026lt;1\u0026gt; hs(self_); Handle\u0026lt;mirror::Throwable\u0026gt; exception_ref(hs.NewHandle(exception)); //关键类  CatchBlockStackVisitor visitor(self_, context_, \u0026amp;exception_ref, this); visitor.WalkStack(true); //输入参数为true  if (clear_exception_) {} else { self_-\u0026gt;SetException(exception_ref.Get()); } //如果异常处理的代码位于机器码中，则再补充设置一些信息。这部分内容和机器码编译有一些关系，建  //议读者暂时不要理会  if (*handler_quick_frame_ != nullptr \u0026amp;\u0026amp; handler_method_header_ != nullptr \u0026amp;\u0026amp; handler_method_header_-\u0026gt;IsOptimized()) { SetCatchEnvironmentForOptimizedHandler(\u0026amp;visitor); } } class CatchBlockStackVisitor FINAL : public StackVisitor { ...... bool VisitFrame() (Locks::mutator_lock_) {//main  /*获取当前正在访问的方法。根据图10-14所示，我们依次会访问到Runtime ArtMethod、方法B、方 法A。最后将进入虚拟机执行X1。 */ ArtMethod* method = GetMethod(); exception_handler_-\u0026gt;SetHandlerFrameDepth(GetFrameDepth()); //如果method为空，表示当前所访问的方法为虚拟机执行层  if (method == nullptr) { /*①注意，如果if条件满足，则表明栈回溯到了虚拟机执行层，这时我们不能再继续回溯虚拟机执行层的函数了，只能先jump回（Quick-ExceptionHandler的主要功能就是long jump，即长跳转到目标指令位置）X1调用方法A的返回处。*/ exception_handler_-\u0026gt;SetHandlerQuickFramePc(GetCurrentQuickFramePc());//返回X1中方法A的返回地址  exception_handler_-\u0026gt;SetHandlerQuickFrame(GetCurrentQuickFrame()); exception_handler_-\u0026gt;SetHandlerMethodHeader( GetCurrentOatQuickMethodHeader()); uint32_t next_dex_pc; ArtMethod* next_art_method; /*GetNextMethodAndDexPc函数内部也会做WalkStack进行栈回溯操作，找到紧挨着当前 虚拟机执行层中的上一个方法。在图10-14中，X1往上没有调用者了，所以下面这个函数 返回false。如果X1之上还有调用者，则返回那个函数的一些信息。 */ bool has_next = GetNextMethodAndDexPc(\u0026amp;next_art_method, \u0026amp;next_dex_pc); exception_handler_-\u0026gt;SetHandlerDexPc(next_dex_pc); exception_handler_-\u0026gt;SetHandlerMethod(next_art_method); ...... return false; // End stack walk.  } //略过Runtime ArtMethod  if (method-\u0026gt;IsRuntimeMethod()) { return true; } /*从method中catch语句中找到是否有能处理该异常的地方。该函数和解释执行层中的FindNextInstruc- tionFollowingException函数类似，请读者自行阅读它。假设图10-14中的方法B、方法A均无法 处理此异常，则HandleTryItems将返回true *///main  return HandleTryItems(method); } 应用层异常处理 AndroidRuntime\nAndroidRuntime::start void AndroidRuntime::start(const char* className, const Vector\u0026lt;String8\u0026gt;\u0026amp; options, bool zygote){ JniInvocation jni_invocation; jni_invocation.Init(NULL); JNIEnv* env; //启动虚拟机  if (startVm(\u0026amp;mJavaVM, \u0026amp;env, zygote) != 0) { return; } ...... char* slashClassName = toSlashClassName(className); jclass startClass = env-\u0026gt;FindClass(slashClassName); if (startClass == NULL) {..... } else { //假设startMeth是图10-14中的方法A  jmethodID startMeth = env-\u0026gt;GetStaticMethodID(startClass, \u0026#34;main\u0026#34;, \u0026#34;([Ljava/lang/String;)V\u0026#34;); if (startMeth == NULL) {......} else { /*下面的CallStaciVoidMethod将触发图10-14的虚拟机执行X1，其内部调用方法 A。根据上文所述，Thread QuickDeliverException的执行完后，longjmp将跳 转到X1调用方法A返回后的指令处，就好像方法A执行完了一样（实际上没有）。 所以，下面的CallStaticVoidMethod将返回。 main*/ env-\u0026gt;CallStaticVoidMethod(startClass, startMeth, strArray); } } free(slashClassName); if (mJavaVM-\u0026gt;DetachCurrentThread() != JNI_OK)//main  ALOGW(\u0026#34;Warning: unable to detach main thread\\n\u0026#34;); if (mJavaVM-\u0026gt;DestroyJavaVM() != 0) ALOGW(\u0026#34;Warning: VM did not shut down cleanly\\n\u0026#34;); java_vm_ext.cc\nDetachCurrentThread static jint DetachCurrentThread(JavaVM* vm) { ...... JavaVMExt* raw_vm = reinterpret_cast\u0026lt;JavaVMExt*\u0026gt;(vm); Runtime* runtime = raw_vm-\u0026gt;GetRuntime(); runtime-\u0026gt;DetachCurrentThread(); //内部将调用当前线程的Destroy方法,main  return JNI_OK; } Thread.cc\nThread::Destroy void Thread::Destroy() { Thread* self = this; ...... if (tlsPtr_.opeer != nullptr) { ScopedObjectAccess soa(self); //调用为该线程设置的UncaughtExceptionHandler对象。感兴趣的读者可自行研究该函数。main  HandleUncaughtExceptions(soa); RemoveFromThreadGroup(soa); } ...... } Thread::HandleUncaughtExceptions void Thread::HandleUncaughtExceptions(ScopedObjectAccess\u0026amp; soa) { if (!IsExceptionPending()) { return; } ScopedLocalRef\u0026lt;jobject\u0026gt; peer(tlsPtr_.jni_env, soa.AddLocalReference\u0026lt;jobject\u0026gt;(tlsPtr_.opeer)); ScopedThreadStateChange tsc(this, kNative); // Get and clear the exception.  ScopedLocalRef\u0026lt;jthrowable\u0026gt; exception(tlsPtr_.jni_env, tlsPtr_.jni_env-\u0026gt;ExceptionOccurred()); tlsPtr_.jni_env-\u0026gt;ExceptionClear(); // If the thread has its own handler, use that.  ScopedLocalRef\u0026lt;jobject\u0026gt; handler(tlsPtr_.jni_env, tlsPtr_.jni_env-\u0026gt;GetObjectField(peer.get(), WellKnownClasses::java_lang_Thread_uncaughtHandler)); if (handler.get() == nullptr) { // Otherwise use the thread group\u0026#39;s default handler.  handler.reset(tlsPtr_.jni_env-\u0026gt;GetObjectField(peer.get(), WellKnownClasses::java_lang_Thread_group)); } // Call the handler.  tlsPtr_.jni_env-\u0026gt;CallVoidMethod(handler.get(), WellKnownClasses::java_lang_Thread__UncaughtExceptionHandler_uncaughtException, peer.get(), exception.get()); // If the handler threw, clear that exception too.  tlsPtr_.jni_env-\u0026gt;ExceptionClear(); } Jni.h / jni_internal.cc\nExceptionOccurred /* * C++ object wrapper. * * This is usually overlaid on a C struct whose first element is a * JNINativeInterface*. We rely somewhat on compiler behavior. */ struct _JNIEnv { jthrowable ExceptionOccurred() { return functions-\u0026gt;ExceptionOccurred(this); } static jthrowable ExceptionOccurred(JNIEnv* env) { ScopedObjectAccess soa(env); mirror::Object* exception = soa.Self()-\u0026gt;GetException(); return soa.AddLocalReference\u0026lt;jthrowable\u0026gt;(exception); } Thread.cc\ntlsPtr_.jni_env { ... // Every thread may have an associated JNI environment  JNIEnvExt* jni_env; } tlsPtr_; GetException mirror::Throwable* GetException() const SHARED_REQUIRES(Locks::mutator_lock_) { return tlsPtr_.exception; } IsExceptionPending bool IsExceptionPending() const { return tlsPtr_.exception != nullptr; } Thread.java.uncaughtExceptionHandler // null unless explicitly set  private volatile UncaughtExceptionHandler uncaughtExceptionHandler; ThreadGroup.java.uncaughtException public void uncaughtException(Thread t, Throwable e) { if (parent != null) { parent.uncaughtException(t, e); } else { Thread.UncaughtExceptionHandler ueh = Thread.getDefaultUncaughtExceptionHandler(); if (ueh != null) { ueh.uncaughtException(t, e); } else if (!(e instanceof ThreadDeath)) { System.err.print(\u0026#34;Exception in thread \\\u0026#34;\u0026#34; \\+ t.getName() + \u0026#34;\\\u0026#34; \u0026#34;); e.printStackTrace(System.err); } } } Thread.java.defaultUncaughtExceptionHandler // null unless explicitly set  private static volatile UncaughtExceptionHandler defaultUncaughtExceptionHandler; "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/",
	"title": "性能优化",
	"tags": [],
	"description": "",
	"content": "性能优化 探索总结性能优化知识\n 内存优化    DumpHprof     Hprof_binary_dump_format     LeakCanary2Source     OOM      "
},
{
	"uri": "https://huanle19891345.github.io/en/",
	"title": "技术探索总结",
	"tags": [],
	"description": "",
	"content": "技术探索总结 探索客户端技术背后的原理细节\nAOSP研究方式  android    jetpack    arch    databinding    Databinding    lifecycle    Lifecycle    livedata    LiveData   LiveData封装   MediatorLiveData    viewmodel    ViewModel   ViewModel封装   数据保存和恢复     supportToAndroidx      性能优化    内存优化    DumpHprof     Hprof_binary_dump_format     LeakCanary2Source     OOM       系统机制原理    ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Looper     ThreadLocal      input    touchEventNative      kernel    kernel      layoutinflater    LayoutInflater      sharedpreferences    SharedPreferences      thread    StackTraceElement     ThreadState      zygote    SystemServerSource     ZygoteSource     Zygote进程      后台任务    后台任务处理      多进程    binder    BinderClient   BinderDeath   BinderKernel   BinderServer   BinderServiceManager   Binder原理    mmkv    MMKV     应用启动退出    应用启动      源码研究方法    Syscall查找方式      系统绘制    Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制       虚拟机    alloc_gc    Alloc     AllocRelated     GC     GC_ConcurrentCopying     GC_MarkCompact     GC_MS_CMS     GC_Semi_Space     Runtime_VisitRoots     Space      ART_Lock     jni    C启动Java     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常     解释执行7_0      启动流程    ART启动流程      基础数据结构     混合编译_运行    JVM_JIT     混合编译_运行      类加载    Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层      类编译    dex2oat        kotlin    协程    kotlin协程     kotlin协程Source       跨平台    flutter    engine    Engine      startup    startup     startup_dart_framework     startup_embedder_framwwork      touch    Touch      动画    动画      混合开发    FlutterBoost     混合开发      渲染    Widget     渲染      路由    路由      通信    MessageLoop     MethodChannel        "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/viewmodel/%E6%95%B0%E6%8D%AE%E4%BF%9D%E5%AD%98%E5%92%8C%E6%81%A2%E5%A4%8D/",
	"title": "数据保存和恢复",
	"tags": [],
	"description": "",
	"content": "转屏场景 数据保存 android/app/servertransaction/ActivityRelaunchItem.java\n@Override public void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { client.handleRelaunchActivity(mActivityClientRecord, pendingActions); } ActivityThread.java\n@Override public void handleRelaunchActivity(ActivityClientRecord tmp, PendingTransactionActions pendingActions) { handleRelaunchActivityInner(r, configChanges, tmp.pendingResults, tmp.pendingIntents, pendingActions, tmp.startsNotResumed, tmp.overrideConfig, \u0026#34;handleRelaunchActivity\u0026#34;); } private void handleRelaunchActivityInner(ActivityClientRecord r, int configChanges, List\u0026lt;ResultInfo\u0026gt; pendingResults, List\u0026lt;ReferrerIntent\u0026gt; pendingIntents, PendingTransactionActions pendingActions, boolean startsNotResumed, Configuration overrideConfig, String reason) { // Preserve last used intent, it may be set from Activity#setIntent().  final Intent customIntent = r.activity.mIntent; // Need to ensure state is saved.  if (!r.paused) { performPauseActivity(r, false, reason, null /* pendingActions */); } if (!r.stopped) { callActivityOnStop(r, true /* saveState */, reason); } handleDestroyActivity(r.token, false, configChanges, true, reason);//getNonConfigInstance传递true，非转屏正常启动Activity时传递false  r.activity = null; handleLaunchActivity(r, pendingActions, customIntent); } private void callActivityOnStop(ActivityClientRecord r, boolean saveState, String reason) { // Before P onSaveInstanceState was called before onStop, starting with P it\u0026#39;s  // called after. Before Honeycomb state was always saved before onPause.  final boolean shouldSaveState = saveState \u0026amp;\u0026amp; !r.activity.mFinished \u0026amp;\u0026amp; r.state == null \u0026amp;\u0026amp; !r.isPreHoneycomb(); final boolean isPreP = r.isPreP(); if (shouldSaveState \u0026amp;\u0026amp; isPreP) { callActivityOnSaveInstanceState(r); } r.activity.performStop(false /*preserveWindow*/, reason); private void callActivityOnSaveInstanceState(ActivityClientRecord r) { r.state = new Bundle(); r.state.setAllowFds(false); mInstrumentation.callActivityOnSaveInstanceState(r.activity, r.state);//r.state记录Bundle这个Parcelable数据 } public void callActivityOnSaveInstanceState(Activity activity, Bundle outState) { activity.performSaveInstanceState(outState); } final void performSaveInstanceState(Bundle outState) { onSaveInstanceState(outState); } 数据恢复 @Override public void handleStartActivity(ActivityClientRecord r, PendingTransactionActions pendingActions) { mInstrumentation.callActivityOnRestoreInstanceState(activity, r.state); } public void callActivityOnRestoreInstanceState(Activity activity, Bundle savedInstanceState) { activity.performRestoreInstanceState(savedInstanceState); } final void performRestoreInstanceState(Bundle savedInstanceState) { onRestoreInstanceState(savedInstanceState); } 其他 ActivityClientRecord /** Activity client record, used for bookkeeping for the real {@link Activity} instance. */ public static final class ActivityClientRecord { public IBinder token; Activity activity; Window window; Activity.NonConfigurationInstances lastNonConfigurationInstances; Bundle state; ...... } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/",
	"title": "混合开发",
	"tags": [],
	"description": "",
	"content": "混合开发 探索总结混合开发知识\n FlutterBoost     混合开发     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/",
	"title": "混合开发",
	"tags": [],
	"description": "",
	"content": "Flutter和native混合开发 Binding to native C/C++ code using dart:ffi\nWriting custom platform-specific code Writing custom platform-specific code\nFlutter’s platform-specific API support does not rely on code generation, but rather on a flexible message passing style:\n The Flutter portion of the app sends messages to its host, the iOS or Android portion of the app, over a platform channel.  static const platform = const MethodChannel(\u0026#39;samples.flutter.dev/battery\u0026#39;); try { final int result = await platform.invokeMethod(\u0026#39;getBatteryLevel\u0026#39;); batteryLevel = \u0026#39;Battery level at $result% .\u0026#39;; } on PlatformException catch (e) { batteryLevel = \u0026#34;Failed to get battery level: \u0026#39;${e.message}\u0026#39;.\u0026#34;; }  The host listens on the platform channel, and receives the message. It then calls into any number of platform-specific APIs—using the native programming language—and sends a response back to the client, the Flutter portion of the app.  class MainActivity() : FlutterActivity() { private val CHANNEL = \u0026#34;samples.flutter.dev/battery\u0026#34; override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) GeneratedPluginRegistrant.registerWith(this) MethodChannel(flutterView, CHANNEL).setMethodCallHandler { call, result -\u0026gt; // Note: this method is invoked on the main thread.  if (call.method == \u0026#34;getBatteryLevel\u0026#34;) { val batteryLevel = getBatteryLevel()//android平台api调用获取  if (batteryLevel != -1) { result.success(batteryLevel) } else { result.error(\u0026#34;UNAVAILABLE\u0026#34;, \u0026#34;Battery level not available.\u0026#34;, null) } } else { result.notImplemented() } } Messages and responses are passed asynchronously, to ensure the user interface remains responsive.\nPlatform Channel用于Flutter与Native之间的消息传递，整个过程的消息与响应是异步执行，不会阻塞用户界面。Flutter引擎框架已完成桥接的通道，这样开发者只需在Native层编写定制的Android/iOS代码，即可在Dart代码中直接调用，这也就是Flutter Plugin插件的一种形式。\nSeparate platform-specific code from UI code\nIf you expect to use your platform-specific code in multiple Flutter apps, it can be useful to separate the code into a platform plugin located in a directory outside your main application. See developing packages for details.\nPublish platform-specific code as a package\nTo share your platform-specific code with other developers in the Flutter ecosystem, see publishing packages.\n google官方混合开发方案 https://github.com/flutter/flutter/wiki/Add-Flutter-to-existing-apps\n来了！Flutter混合开发专题一\n原生和Flutter交互\n//从安卓原生页面跳转到FlutterDemoActivity页面使用如下方法将routeName传递过去： Intent intent = new Intent(this, FlutterDemoActivity.class); Bundle bundle = new Bundle(); bundle.putString(\u0026#34;routeName\u0026#34;, \u0026#34;first\u0026#34;); intent.putExtras(bundle); startActivity(intent); //flutter_host_android工程的java源码包下新建一个FlutterDemoActivity类，onCreate方法中的实现如下： public static final String CHANNEL_NAME = \u0026#34;com.flutterbus/demo\u0026#34;; @Override protected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); // 获取由上一个页面传过来的routeName  String routeName = \u0026#34;\u0026#34;; Intent intent = getIntent(); if (intent != null \u0026amp;\u0026amp; intent.getExtras() != null) { routeName = intent.getExtras().getString(\u0026#34;routeName\u0026#34;); } // 根据指定routeName创建FlutterView用来展示对应dart中的Widget  FlutterView flutterView = Flutter.createView(this, this.getLifecycle(), routeName); // 创建Platform Channel用来和Flutter层进行交互  new MethodChannel(flutterView, CHANNEL_NAME).setMethodCallHandler(new MethodChannel.MethodCallHandler() { @Override public void onMethodCall(MethodCall methodCall, MethodChannel.Result result) { methodCall(methodCall, result); } }); setContentView(flutterView); } /** * 处理dart层传来的方法调用 */ private void methodCall(MethodCall call, MethodChannel.Result result) { if (call.method.equals(\u0026#34;gotoNativePage\u0026#34;)) { startActivity(new Intent(this, NativeActivity.class)); result.success(true); } else { result.notImplemented(); } } //routeName在Flutter端是如何起到作用的呢，可以看下Flutter module中dart代码: void main() =\u0026gt; runApp(_widgetForRoute(window.defaultRouteName)); Widget _widgetForRoute(String route) { switch (route) { case \u0026#39;first\u0026#39;: return MyApp(); case \u0026#39;second\u0026#39;: return MyApp(); default: return Center( child: Text(\u0026#39;Unknown route: $route\u0026#39;, textDirection: TextDirection.ltr), ); } } java中创建FlutterView时其实就是将routeName设置为window的defaultRouteName，这样在dart端运行的时候就会根据defaultRouteName来展示对应的Widget了。而上面java层我们定义了Platform Channel，这样Flutter端就可以在dart层通过MethodChannel传递消息给java层从而实现两端的交互。\nstatic final String channelName = \u0026#34;com.flutterbus/demo\u0026#34;; Future\u0026lt;Null\u0026gt; jumpToNativePage() async { MethodChannel methodChannel = MethodChannel(channelName); await methodChannel.invokeMethod(\u0026#34;gotoNativePage\u0026#34;); } 至此，安卓原生工程集成Flutter就完成了，后续我们想用Flutter实现UI界面都可以在Flutter module工程中编写，原生想跳转到指定Flutter页面设置好routeName即可，dart的main函数会根据routeName来跳转到不同的Widget。\n总结\n以上就是官方提供的混合开发方案了，这个方案有一个巨大的缺点，就是在原生和Flutter页面叠加跳转时内存不断增大，因为FlutterView和FlutterViewController每次跳转都会新建一个对象，从而Embedder层的AndroidShellHolder和FlutterEngine都会创建新对象，UI Thread、IO Thread、GPU Thread和Shell都创建新的对象，唯独共享的只有DartVM对象，但是RootIsolate也是独立的，所以Flutter页面之前的数据不能共享，这样就很难将一些全局性的公用数据保存在Flutter中，所以这套方案比较适合开发不带有共享数据的独立页面，但是页面又不能太多，因为创建的Flutter页面越多内存就会暴增，尤其是在iOS上还有内存泄露的问题。\nAdd-to-App 如果您想要体验 Add-to-App 功能，请参阅文档或浏览我们的示例项目，我们在这些项目中展示了多种集成场景。\nAdd-to-App 文档 https://flutter.dev/docs/development/add-to-app\nhttps://flutter.dev/docs/development/add-to-app/android/project-setup\nhttps://flutter.dev/docs/development/add-to-app/android/add-flutter-screen\n示例项目 https://github.com/flutter/samples/tree/master/add_to_app\nFlutterEngineCache Note: To warm up a FlutterEngine, you must execute a Dart entrypoint. Keep in mind that the moment executeDartEntrypoint() is invoked, your Dart entrypoint method begins executing. If your Dart entrypoint invokes runApp() to run a Flutter app, then your Flutter app behaves as if it were running in a window of zero size until this FlutterEngine is attached to a FlutterActivity, FlutterFragment, or FlutterView. Make sure that your app behaves appropriately between the time you warm it up and the time you display Flutter content.\nNote: When using a cached FlutterEngine, that FlutterEngine outlives any FlutterActivity or FlutterFragment that displays it. Keep in mind that Dart code begins executing as soon as you pre-warm the FlutterEngine, and continues executing after the destruction of your FlutterActivity/FlutterFragment. To stop executing and clear resources, obtain your FlutterEngine from the FlutterEngineCache and destroy the FlutterEngine with FlutterEngine.destroy().\nNote: Runtime performance isn’t the only reason that you might pre-warm and cache a FlutterEngine. A pre-warmed FlutterEngine executes Dart code independent from a FlutterActivity, which allows such a FlutterEngine to be used to execute arbitrary Dart code at any moment. Non-UI application logic can be executed in a FlutterEngine, like networking and data caching, and in background behavior within a Service or elsewhere. When using a FlutterEngine to execute behavior in the background, be sure to adhere to all Android restrictions on background execution.\n同一个engine内部切换具体显示内容的方式 By setting the initial route of the navigation channel, the associated FlutterEngine displays the desired route upon initial execution of the runApp() Dart function.\nChanging the initial route property of the navigation channel after the initial execution of runApp() has no effect. ==Developers who would like to use the same FlutterEngine between different Activitys and Fragments and switch the route between those displays need to setup a method channel and explicitly instruct their Dart code to change Navigator routes.==\n FlutterFragment // With a new FlutterEngine. val flutterFragment = FlutterFragment.withNewEngine() .initialRoute(\u0026#34;myInitialRoute/\u0026#34;) .build() Note: FlutterFragment’s initial route property has no effect when a pre-warmed FlutterEngine is used because the pre-warmed FlutterEngine already chose an initial route. The initial route can be chosen explicitly when pre-warming a FlutterEngine.\nFlutterFragment flutterFragment = FlutterFragment.withNewEngine() .dartEntrypoint(\u0026#34;mySpecialEntrypoint\u0026#34;) .build(); Note: FlutterFragment’s Dart entrypoint property has no effect when a pre-warmed FlutterEngine is used because the pre-warmed FlutterEngine already executed a Dart entrypoint. The Dart entrypoint can be chosen explicitly when pre-warming a FlutterEngine.\n https://github.com/alibaba/flutter_boost\n已开源|码上用它开始Flutter混合开发——FlutterBoost\nFlutter混合开发二-FlutterBoost使用介绍\nflutterboost1.0到2.0，我一共做了这几件事\u0026hellip;\nFlutterBoost集成  Demo同级目录创建一个Flutter module项目，取名为flutter_boost_module，将Flutter module项目引入集成到原生项目中，集成方式参考《Flutter混合开发专题一》 Flutter module项目集成FlutterBoost,在flutter_boost_module项目的pubspec.yaml文件中添加依赖插件配置dependencies:flutter_boost: ^0.0.411,配置完成后执行flutter packages get命令下载依赖插件到本地 引入FlutterBoost的安卓工程代码了，在app目录下的build.gradle中添加以下项目依赖implementation project(':flutter_boost') Flutter module项目使用FlutterBoost,在main方法中运行的rootWidget中注册页面  @override void initState() { super.initState(); FlutterBoost.singleton.registerPageBuilders({ \u0026#39;flutterbus://flutterFirstPage\u0026#39;: (pageName, params, _) { print(\u0026#34;first flutterPage params:$params\u0026#34;); ... return FirstPage(); }, \u0026#39;flutterbus://flutterSecondPage\u0026#39;: (pageName, params, _) { print(\u0026#34;second flutterPage params:$params\u0026#34;); ... return SecondPage(); }, }); FlutterBoost.handleOnStartPage(); } @override Widget build(BuildContext context) { return MaterialApp( title: \u0026#39;Flutter Boost example\u0026#39;, builder: FlutterBoost.init(), home: Container()); } 安卓原生项目中使用FlutterBoost,Flutter引擎加载及FlutterBoostPlugin初始化  public static void init(final Application app) { //此处必须启动初始化，主要是载入Flutter引擎文件  FlutterMain.startInitialization(app); FlutterBoostPlugin.init(new IPlatform() { @Override public Application getApplication() { return app; } @Override public Activity getMainActivity() { return MainActivity.sRef.get(); } @Override public boolean isDebug() { return true; } @Override public boolean startActivity(Context context, String url, int requestCode) { Debuger.log(\u0026#34;startActivity url=\u0026#34;+url); return PageRouter.openPageByUrl(context,url,requestCode); } @Override public Map getSettings() { return null; } }); } Flutter页面对应Native容器,FlutterBoost初始化完成之后，针对Flutter中的页面我们需要在原生中创建对应的Native容器，即FlutterBoost中定义的Container，可以是Activity也可以是Fragment，这里我们使用Activity实现.  FlutterBoost已经为我们实现好了Activity类型的容器BoostFlutterActivity，该类实现了IFlutterViewContainer接口，我们自定义容器时只需要继承该Activity并实现三个方法即可，其中\n  getContainerName即是容器的名称，和Flutter层注册PageBuilder相对应；\n  getContainerParams为该容器需要传递给Flutter层对应Widget的参数，页面跳转接收的参数传递给Flutter页面就是在这里处理，需要将数据包装到Map中；\n  onRegisterPlugins是为该页面注册插件；\n   页面跳转路由\n  Native页面跳转Flutter页面\n  Native页面跳转Flutter页面其实就是打开一个Flutter页面对应的Native容器，我们可以根据路由来进行跳转操作\nFlutter页面跳转Native页面  我们只需要在Flutter端使用FlutterBoost提供的方法进行跳转即可，比如我需要从FirstWidget跳转到FirstNativeActivity页面，该页面对应的url为“flutterbus://nativeFirstPage”，我们可以执行以下代码\nFlutterBoost.singleton.openPage(\u0026#34;flutterbus://nativeFirstPage\u0026#34;, { \u0026#34;query\u0026#34;: {\u0026#34;description\u0026#34;: \u0026#34;大家好，我来自First Flutter页面!!!!!!!!\u0026#34;} }); 其中query对应的值是要传递给下一个页面的参数，不需要也可以不传。\nFlutter页面跳转Flutter页面，两种方式：  FlutterBoost\nFlutterBoost.singleton.openPage(\u0026#34;flutterbus://flutterSecondPage\u0026#34;, {}); Navigator\nNavigator.of(context).push(MaterialPageRoute(builder: (context){ return SecondPage(enterType: 1,); })); 如果两种跳转方式混合使用会在页面返回时出现一定的问题，因为FlutterBoost提供了关闭当前页面的方法FlutterBoost.singleton.closePageForContext(context);，而使用Navigator跳转的话该方法是不起作用的，所以我们在Widget页面中定义了enterType来区分，默认使用FlutterBoost的跳转方式，如果使用Navigator跳转Flutter Widget页面，则需要传入enterType=1，这样在返回当前页面时使用如下方法进行处理\nvoid exitPage(BuildContext context) { if (enterType == 0) { FlutterBoost.singleton.closePageForContext(context); } else { Navigator.pop(context); } } 页面跳转的返回值问题   https://github.com/alibaba-flutter/flutter-boot\nflutter-boot介绍\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/",
	"title": "混合编译_运行",
	"tags": [],
	"description": "",
	"content": "混合编译_运行 探索总结混合编译_运行知识\n JVM_JIT     混合编译_运行     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/",
	"title": "混合编译_运行",
	"tags": [],
	"description": "",
	"content": "How ART works ART uses ahead-of-time (AOT) compilation, and starting in Android 7.0 (Nougat or N), it uses a hybrid ==combination of AOT, just-in-time (JIT) compilation, and profile-guided compilation==. The combination of all these compilation modes is ==configurable== and will be discussed in this section. As an example, Pixel devices are configured with the following compilation flow:\n An application is initially installed without any AOT compilation. The first few times the application runs, it will be ==interpreted, and methods frequently executed will be JIT compiled==. When the device is idle and charging, ==a compilation daemon runs to AOT-compile frequently used code based on a profile generated during the first runs==. The next restart of an application will use the ==profile-guided code and avoid doing JIT compilation at runtime for methods already compiled. Methods that get JIT-compiled during the new runs will be added to the profile, which will then be picked up by the compilation daemon==.  JIT和AOT共存\n 应用在安装的时候dex不会再被编译 App运行时,dex文件先通过解析器被直接执行，热点函数会被识别并被JIT编译后存储在 jit code cache 中并生成profile文件以记录热点函数的信息。以供AOT编译时生成机器码 手机进入 IDLE（空闲） 或者 Charging（充电） 状态的时候，系统会扫描 App 目录下的 profile 文件并执行 AOT 过程进行编译。  ART comprises a compiler (the dex2oat tool) and a runtime (libart.so) that is loaded for starting the Zygote. The dex2oat tool takes an APK file and generates one or more compilation artifact files that the runtime loads. The number of files, their extensions, and names are subject to change across releases, but as of the Android O release, the files being generated are:\n .vdex: contains the uncompressed DEX code of the APK, with some additional metadata to speed up verification. .odex: contains AOT compiled code for methods in the APK. .art (optional): contains ART internal representations of some strings and classes listed in the APK, used to speed application startup.  Compilation options Compilation options for ART are of two categories:\n System ROM configuration: what code gets AOT-compiled when building a system image. Runtime configuration: how ART compiles and runs ==applications== on a device.  One core ART option to configure these two categories is compiler filters. Compiler filters drive how ART compiles DEX code and is an option passed to the dex2oat tool. Starting in Android O, there are four officially supported filters:\n verify: only run DEX code verification. quicken: run DEX code verification and optimize some DEX instructions to get better interpreter performance. speed: run DEX code verification and AOT-compile all methods. speed-profile: run DEX code verification and AOT-compile methods listed in a profile file.  Runtime configuration Jit options Package manager options Dex2oat options Implementing ART Just-In-Time (JIT) Compiler https://source.android.com/devices/tech/dalvik/jit-compiler\nAndroid runtime (ART) includes a just-in-time (JIT) compiler with code profiling that continually improves the performance of Android applications as they run. ==The JIT compiler complements ART\u0026rsquo;s current ahead-of-time (AOT) compiler and improves runtime performance, saves storage space, and speeds application and system updates.== It also improves upon the AOT compiler by avoiding system slowdown during automatic application updates or recompilation of applications during over-the-air (OTA) updates.\nAlthough JIT and AOT use the same compiler with a similar set of optimizations, the generated code might not be identical. ==JIT makes use of runtime type information, can do better inlining, and makes on stack replacement (OSR) compilation possible==, all of which generates slightly different code.\nJIT architecture Figure 1. JIT architecture.\nJIT compilation JIT compilation involves the following activities:\nFigure 2. Profile-guided compilation.\n The user runs the app, which then triggers ART to load the .dex file.   If the .oat file (the AOT binary for the .dex file) is available, ART uses it directly. Although .oat files are generated regularly, they don\u0026rsquo;t always contain compiled code (AOT binary). If the .oat file does not contain compiled code, ART runs through JIT and the interpreter to execute the .dex file.  JIT is enabled for any application that is not compiled according to the speed compilation filter (which says \u0026ldquo;compile as much as you can from the app\u0026rdquo;). The JIT profile data is dumped to a file in a system directory that only the application can access. The AOT compilation (dex2oat) daemon parses that file to drive its compilation.  JIT workflow  华为公布的方舟编译器到底对安卓软件生态会有多大影响？\nAndroid 平台的绝大多数应用是使用 Java 语言写的，CPU 只能理解汇编指令，无法直接识别 Java语言的虚拟机指令；为了让 CPU 能运行 Java语言编写的程序，一般有两种办法：\n  「计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决」引入一个中间层，这个中间层负责 Java代码的执行，然后这个中间层本身编译为 ==CPU 能理解的汇编指令==，也就是 CPU -\u0026gt; 中间层 -\u0026gt; Java 代码。如果这个中间层采用 Java 语言直接作为输入，理解一句 Java 语句就把Java语言翻译一下让CPU 执行一段，我们一般称这种模式为「解释执行」。毋庸置疑这种方式效率是相当低效的。\n  直接把 Java 语言翻译成==CPU能理解的机器语言==。这里又有两种方式： 在程序运行之前直接把 Java 代码编译为机器语言。这种模式我们称之为 AOT （Ahead of time）编译。 在程序运行起来之后，实时地把 Java 语言编译为机器语言然后执行。这种模式称之为 JIT（Just in time） 编译。\n  背景介绍完了回到 Android 平台上面，Android 平台分为几个阶段：\n 在 Android 5.0 正式采用 ART 之前，Android 采用的是 解释执行 + 辣鸡 JIT 的方式执行 Java代码。在这个阶段是货真价实的「边解释边执行」的模式，代码效率相当低下，再加上那时候同样辣鸡的 GC （垃圾回收），Android 用起来真是惨不忍睹。 Android 5.0 ～ Android 6.0 。Google 推出了 ART （Android Runtime）来解决之前的 Java 代码执行效率问题。这个阶段采用的是完全 AOT 模式；Android 应用在安装的时候，系统会把所有Java代码提前编译为机器码。这种模式有两个缺点不能忍：   安装速度巨慢。即使是现在吊炸天的 855 采用 AOT 模式编译一下安装包比较大的应用（如支付宝）可能就要一分钟。那个时候的 CPU 可不如现在，安装一个应用都让你等得头皮发麻。更要命的时候，系统 OTA 开机会对所有的应用执行 AOT 操作，这时候你的开机速度可能要半个小时。。。 占用磁盘空间，Java 代码编译为机器码之后体积会急剧膨胀。  Android 7.0 ～ 现在。Google做了很大的改进，基于这样一个事实：我们使用一个应用的时候，基本每个人只使用它一小部分功能，为什么要把所有代码全编译呢？只编译你经常用的那部分代码不就 OK 了，这样安装的时候啥也不干速度飞快，等你用的时候系统就能知道哪部分代码经常被执行，把这部分代码编译为机器码，运行起来速度也快。于是 Google 又引入了 JIT，这时候的执行模式是 AOT + JIT + 解释执行。    应用安装的时候不执行 AOT 编译，安装速度飞快。初次使用应用的时候没有机器码，因此只能解释执行。\n  应用运行起来之后，系统收集经常被运行的代码的信息，做两件事：1）在必要的时候在运行时直接把 Java 代码编译为机器码 （JIT），然后使用机器码执行提高运行效率。2）把这个「经常被运行的代码信息保存起来」\n  设备空闲的时候，系统拿出应用运行时候保存的「热点代码信息」直接把这些代码编译为机器码 （AOT）\n  关于 Android 7.0 系统的演进可以参阅这里：http://s3.amazonaws.com/connect.linaro.org/las16/Presentations/Tuesday/LAS16-201%20-%20ART%20JIT%20in%20Android%20N.pdf\n  8.0上改进了解释器，解释模式执行效率大幅提升；\nAndroid 9.0上提供了预先放置热点代码的方式，应用在安装的时候就能知道常用代码会被提前编译。可以看到，当前 Android 平台的执行模式在空间占用+安装速度+运行速度上已经达到了一个很好的平衡。\n 回到华为的这个方舟编译器上面，现在的 Android 是边解释边执行的吗？可以说是，也可以说不是。上面我已经提到了，现在的 Android 是 解释执行 + 还算可以的JIT + AOT 的模式。并且，你也可以手动把应用的代码全部提前编译达到完全 AOT 的效果（很多答案里面提到的 AOT 就是说的这种）；不过这属于开倒车，Google 肯定不会这么做。这样做效果有多大呢？这个我有发言权。之前在支付宝做性能优化的时候，我干过这么一回事：让应用在后台运行的时候请求系统直接采用 everything 模式编译支付宝，本地测试启动速度有爆炸性提升（30%~50%）；但是灰度测试的时候效果不明显，为什么呢？其一是后台全编译运行成功率低，其二是系统的 JIT + 后台 AOT 不是吃素的；考虑到耗电/占空间的问题压根没上线。所以如果华为只是简单地用这种方式去避免所谓的「边解释边执行」那就相当滴 low，但是按照 GPU Turbo这种黑科技来看，我觉得不太可能是这个。 除了 Android 系统的这种 AOT 之外，难道没有别的办法了吗？我不负责任地猜测一下，方舟编译器是不是在Android 应用打包成APK的时候，直接把 Java 代码编译为了机器码？注意这个跟Android系统的那个 AOT 是不样的，系统是在应用安装或者系统空闲的时候做编译；这种方式你下载到的安装包就是编译好的了，不需要系统动手。如果是第一种，辣鸡华为。如果是第二种，吊炸天！！！当然还有别的可能，不管咋样，静待开源 ：）  9102年了，还不知道android为什么卡？\nAndroid 源码分析（十） Dalvik 虚拟机创建过程\n虚拟机 理解Android虚拟机体系结构\n4.2 Dalvik类加载器 一个dex文件需要类加载器加载原生类和Java类，然后通过解释器根据指令集对Dalvik字节码进行解释和执行。Dalvik类加载器使用mmap函数，将dex文件映射到内存中，通过普通的内存读取操作即可访问dex文件，然后解析dex文件内容并加载其中的类到哈希表中。\n4.2.1 解析dex 总的来说，dex文件可以抽象为三个部分：头部、索引、数据。通过头部可以知道索引的位置和数目，以及数据区的起始位置。将dex文件映射到内存后，Dalvik会调用dexFileParse函数对其进行分析，分析的结果放到DexFile数据结构中。DexFile中的baseAddr指向映射区的起始位置，pClassDefs指向class索引的起始位置。为了加快class的查找速度，还创建一个哈希表，对class名字进行哈希并生成索引。\n4.2.2 加载class 解析工作完成后就进行class的加载，加载的类需要用ClassObject数据结构来存储。\ntypedef struct Object { ClassObject* clazz; // 类型对象  Lock lock; // 锁对象 } Object; 其中clazz指向ClassObject对象，还包含一个Lock对象。如果其它线程想要获取它的锁，只有等这个线程释放。Dalvik每加载一个class都会对应一个ClassObject对象，加载过程会在内存中分配几个区域，分别存放directMethod, virtualMethod, sfield, ifield。这些信息从dex文件的数据区中读取。字段Field的定义如下：\nstruct Field { ClassObject* clazz; //所属类型  const char* name; // 变量名称  const char* signature; // 如“Landroid/os/Debug;”  u4 accessFlags; // 访问标记  #ifdef PROFILE_FIELD_ACCESS  u4 gets; u4 puts; #endif }; 待得到class索引后，实际的加载由loadClassFromDex来完成。首先它会读取class的具体数据，分别加载directMethod, virtualMethod, ifield和sfield，然后为ClassObject数据结构分配内存，并读取dex文件的相关信息。加载完成后，将加载的class通过dvmAddClassToHash函数放入哈希表，以方便下次查找；最后，通过dvmLinkClass查找该类的超类，如果有接口类则加载相应的接口类。\n4.3 Dalvik解释器 对于任何虚拟机来说，解释器无疑是核心的部分，所有的Java字节码都经过解释器解释执行。由于Dalvik解释器的效率很重要，Android分别实现了C语言版和各种汇编语言版的解释器。解释器通常是循环执行，需要一个入口函数调用处理程序执行第一条指令，而后每条指令执行时引出下一条指令，通过函数指针调用处理程序。\n5 Android的启动 启动电源，加载引导程序到RAM BootLoader引导 Linux Kernel启动 Init进程创建 Init fork出Zygote进程，Zygote进程创建虚拟机；创建系统服务 Android Home Launcher启动 华为新贵！方舟编译器的荣光和使命\n第一个命门\nJava的“虚拟机”\n前面提到，Java为了能够实现跨平台操作，便借助虚拟机来调度硬件平台资源。在虚拟机里，还需要集成翻译器或者编译器，来将Java的字节码（即中间代码）解释成机器听得懂的机器语言，或者直接编译成机器直接执行的010101的机器码。\n2008年，Android 1.0刚发布的时候，使用的是一个叫Dalvik的虚拟机，里面集成了一个解释器，每次用户在安卓手机上运行APP时，就会叫醒这个解释器，来给安卓的硬件解释APP想要干嘛。这就相当于新闻发布会，发言人讲一句自己的母语，然后再由专业翻译将其翻译成外国记者听得懂的语言，效率非常低下，一个小时可能也问不了几个问题。\n谷歌意识到这个问题严重拖了安卓手机的后腿，所以通过一年多的努力，在2010年中发布了2.2版本，引入了JIT(Just in Time，即时编译)机制。JIT比较聪明，当用户在安卓手机运行APP时，会同时将用户经常使用的功能编译为机器能直接执行的010101机器码，不用每一句每一句的去翻译。当出现不常用的功能时，再把解释器叫起来翻译。\nJIT虽然变聪明了一点，但是每次启动APP都要先编译一次，不能一劳永逸。加上Dalvik虚拟机性能比较落后，所以谷歌在2014年10月推出了Android 5.0版本，将虚拟机从Dalvik替代成ART（Android Run Time），同时把JIT的编译器替代成AOT (Ahead of Time)。意思就是说，APP在下载后安装到手机上时同时把能编译的代码先编译成机器听得懂的101010。剩下不太好翻译的代码，就在用户使用时再叫醒解释器来翻译。AOT相比JIT的好处，就是不用每次打开APP都需要先编译一遍。但是，坏处就是用户安装APP的时间有点长。\n越来越多的用户吐槽为什么安装一个APP也慢吞吞。于是，谷歌在2017年Android 7.0又做了一点改进，安装时先不编译中间代码，而是在用户空闲时将能够编译成机器码的那部分代码，通过AOT编译器先静态编译了。如果AOT还没来得及编译或者不能编译，再叫醒JIT+解释器两个难兄难弟来顶住。这种机制，相当于用时间换空间，既缩短了用户安装APP的等待时间，又将虚拟机里编译器和解释器能做的优化提升到最大效率了。\n很多人以为华为方舟编译器就是Android 7.0的ART虚拟机，其实不然。\n无论是编译器还是解释器，只是在虚拟机上打补丁。手机上的虚拟机+编译器+解释器本身不仅占用硬件资源，还无法最大发挥软件运行性能。正因如此，所以绝大部分手机厂商只能无奈的通过简单粗暴提升安卓手机的内存和存储空间，来弥补虚拟机的弊端。\n这就是安卓的第一个命门，虚拟机先天不足。\n参考 https://source.android.com/devices/tech/dalvik/\nhttps://source.android.com/devices/tech/dalvik/configure\nUsing Profile-Guided Optimization (PGO)\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B8%B2%E6%9F%93/",
	"title": "渲染",
	"tags": [],
	"description": "",
	"content": "渲染 探索总结渲染知识\n Widget     渲染     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B8%B2%E6%9F%93/%E6%B8%B2%E6%9F%93/",
	"title": "渲染",
	"tags": [],
	"description": "",
	"content": "绘制渲染 三棵树 Widget Tree，Element Tree 以及 RenderObject Tree 。根据它们的功能我将它翻译成模型树，状态树和渲染树，也正是通过这三棵树维护起了整个应用的视图数据。\n开发者通过Widget配置，Framework通过比对Widget配置来更新Element，最后调度RenderObject Tree完成布局排列和绘制。\n Widget Tree  存放属性的描述信息，更像是一个Model。同一个Widget可以同时描述多个渲染树中的节点，但是它是不可修改的，因此它只会被创建或销毁。\nWidget是为Element描述需要的配置， 负责创建Element，决定Element是否需要更新。Flutter Framework通过差分算法比对Widget树前后的变化，决定Element的State是否改变。当重建Widget树后并未发生改变， 则Element不会触发重绘，则就是Widget树的重建并不一定会触发Element树的重建。\n Element Tree  存放上下文状态信息，同时持有 Widget和RenderObject的引用。像是一个Controller控制着状态的更新(initial, mount,amount,activate,deactivate,update)。\nElement表示Widget配置树的特定位置的一个实例，同时持有Widget和RenderObject，负责管理Widget配置和RenderObject渲染。Element状态由Flutter Framework管理， 开发人员只需更改Widget即可。\n RenderObject Tree  实现了layout和paint事件，是最终渲染的View视图。\nRenderObject表示渲染树的一个对象，负责真正的渲染工作，比如测量大小、位置、绘制等都由RenderObject完成。\n渲染库（Rendering） Flutter的控件树在实际显示时会转换成对应的渲染对象（RenderObject）树来实现布局和绘制操作。渲染库主要提供的功能类有：\nabstract class RendererBinding extends BindingBase with ServicesBinding, SchedulerBinding, HitTestable { ... } abstract class RenderObject extends AbstractNode with DiagnosticableTreeMixin implements HitTestTarget { abstract class RenderBox extends RenderObject { ... } class RenderParagraph extends RenderBox { ... } class RenderImage extends RenderBox { ... } class RenderFlex extends RenderBox with ContainerRenderObjectMixin\u0026lt;RenderBox, FlexParentData\u0026gt;, RenderBoxContainerDefaultsMixin\u0026lt;RenderBox, FlexParentData\u0026gt;, DebugOverflowIndicatorMixin { ... } RendererBinding是渲染树和Flutter引擎的胶水层，负责管理帧重绘、窗口尺寸和渲染相关参数变化的监听。\nRenderObject渲染树中所有节点的基类，定义了布局、绘制和合成相关的接口。\nRenderBox和其三个常用的子类RenderParagraph、RenderImage、RenderFlex则是具体布局和绘制逻辑的实现类。\n控件树中的每个控件通过实现RenderObjectWidget#createRenderObject(BuildContext context) → RenderObject方法来创建对应的不同类型的RenderObject对象，组成渲染对象树。\n 渲染机制—UI线程 Flutter渲染机制—UI线程\u0026ndash;详细\n渲染机制—GPU线程 Flutter渲染机制—GPU线程\u0026ndash;详细\nFlutter 视图绘制\nFlutter有别于其他跨平台开发的一大特点是它自带UI组件和渲染器，而不是通过一些Bridge去做平台适配。其中自带UI组件在Flutter的Framework层而渲染器在Engine层，那么Google工程师面临的问题是如何尽可能快的（在VSync信号间隔内）完成这次传递？\nFlutter app只有在状态发生变化的时候需要触发渲染流水线。当你的app什么都不做的时候是不需要重新渲染页面的。所以，Vsync信号需要Flutter app去调度。比如我们都知道如果你的某个页面需要发生变化的时候有可能会调用State.setState()，这个调用Flutter框架最终会发起一个调度Vsync信号的请求给底层。然后底层会在Vsync信号到来的时候驱动渲染流水线开始运作，最后把新的页面显示到屏幕上。\n从UI绘制的整体流程来看,从用户的输入①到界面上动画的进度更新②，然后开始视图数据的build③，通过Layout④来确定视图的Position和Size，接下来是视图数据的Paint⑤和Composite⑥，最后是将合成后的视图数据进行\u0026quot;光栅化\u0026quot;处理使它真正的变成一个个像素填充的数据并提交给GPU。\n整个渲染流水线是运行在UI线程里的，以Vsync信号为驱动，在框架渲染完成之后会输出layer tree。 layer tree被送入engine，engine会把layer tree调度到GPU线程，在GPU线程内合成（compsite）layer tree，然后由Skia 2D渲染引擎渲染后送入GPU显示。\nFlutter只关心向 GPU提供视图数据，GPU的 VSync信号同步到 UI线程，UI线程使用 Dart来构建抽象的视图结构，这份数据结构在 GPU线程进行图层合成，视图数据提供给 Skia引擎渲染为 GPU数据，这些数据通过 OpenGL或者 Vulkan提供给 GPU。\nGPU线程通过skia向GPU硬件绘制一帧的数据，GPU将帧信息保存到FrameBuffer里面，然后视频控制器会根据VSync信号从FrameBuffer取帧数据传递给显示器，从而显示出最终的画面。\nAnimate 遍历_transientCallbacks，执行动画回调方法；\nBuild 在这个阶段Flutter，在这个阶段那些需要被重新构建的Widget会在此时被重新构建。也就是我们熟悉的StatelessWidget.build()或者State.build()被调用的时候。\n对于dirty的元素会执行build构造，没有dirty元素则不会执行，对应于buildScope()\nLayout 布局的计算\n计算渲染对象的大小和位置，此时是RenderObject.performLayout()被调用的时候。\n对应于flushLayout()，这个过程可能会嵌套再调用build操作；\n因为Flutter极大地简化了布局的逻辑，所以整个布局过程中只需要深度遍历一次：\n渲染对象树中的每个对象都会在布局过程中接受父对象的Constraints参数，决定自己的大小，然后父对象就可以按照自己的逻辑决定各个子对象的位置，完成布局过程。子对象不存储自己在容器中的位置，所以在它的位置发生改变时并不需要重新布局或者绘制。子对象的位置信息存储在它自己的parentData字段中，但是该字段由它的父对象负责维护，自身并不关心该字段的内容。同时也因为这种简单的布局逻辑，Flutter可以在某些节点设置布局边界（Relayout boundary），即当边界内的任何对象发生重新布局时，不会影响边界外的对象，反之亦然：\nCompositing bits 更新具有脏合成位的任何渲染对象， 对应于flushCompositingBits()；\nPaint 将绘制命令记录到Layer， 对应于flushPaint()；\n访问需要绘制的任何渲染对象，在此阶段，渲染对象有机会将绘制命令记录到[PictureLayer]，并构建其他合成的[Layer]\n布局的绘制，此时是RenderObject.paint()被调用的时候\n布局完成后，我们开始真正的绘制。它与layout不同点在于，layout是先有child的size再有parent的size，draw是先绘制parent再child。 布局完成后，渲染对象树中的每个节点都有了明确的尺寸和位置，Flutter会把所有对象绘制到不同的图层上：\n因为绘制节点时也是深度遍历，可以看到第二个节点在绘制它的背景和前景不得不绘制在不同的图层上，因为第四个节点切换了图层（因为“4”节点是一个需要独占一个图层的内容，比如视频），而第六个节点也一起绘制到了红色图层。这样会导致第二个节点的前景（也就是“5”）部分需要重绘时，和它在逻辑上毫不相干但是处于同一图层的第六个节点也必须重绘。为了避免这种情况，Flutter提供了另外一个“重绘边界”的概念：\n在进入和走出重绘边界时，Flutter会强制切换新的图层，这样就可以避免边界内外的互相影响。典型的应用场景就是ScrollView，当滚动内容重绘时，一般情况下其他内容是不需要重绘的。虽然重绘边界可以在任何节点手动设置，但是一般不需要我们来实现，Flutter提供的控件默认会在需要设置的地方自动设置。\nFlutter框架分析（七）\u0026ndash; 绘制\n函数markNeedsPaint()首先做的是把自己的标志位_needsPaint设置为true。然后会向上查找最近的一个isRepaintBoundary为true的祖先节点。直到找到这样的节点，才会把这个节点加入到_nodesNeedingPaint列表中，也就是说，并不是任意一个需要重绘的RenderObject就会被加入这个列表，而是往上找直到找到最近的一个isRepaintBoundary为true才会放入这个列表，换句话说，这个列表里只有isRepaintBoundary为true这种类型的节点。也就是说重绘的起点是从“重绘边界”开始的。\n这里的_layer属性就是我们之前说的图层，这个属性只有绘制边界的RenderObject才会有值。一般的RenderObject这个属性是null。\nCompositing 将Compositing bits发送给GPU， 对应于compositeFrame()；\n setState更新 Flutter的setState更新原理和流程\n深入理解setState更新机制\n可见，setState()过程主要工作是记录所有的脏元素，添加到BuildOwner对象的_dirtyElements成员变量，然后调用scheduleFrame来注册Vsync回调。当下一次vsync信号的到来时会执行handleBeginFrame()和handleDrawFrame()来更新UI。\nState lifecycle\nFlutter性能优化之局部刷新 利用GlobalKey\nclass _TestWidgetState extends State\u0026lt;TestWidget\u0026gt; { int _count=0; GlobalKey\u0026lt;TextWidgetState\u0026gt; textKey = GlobalKey(); @override Widget build(BuildContext context) { return Center( child: Column( mainAxisAlignment: MainAxisAlignment.center, children: \u0026lt;Widget\u0026gt;[ TextWidget(textKey),///需要更新的Text ButtonWidget( onPressed: () { ///点击button，调用TextWidget的onPressed方法 ///在TextWidget的onPressed中单独调用TextWidget的setState， _count++; textKey.currentState.onPressed(_count); },  Flutter视图绘制(2)\u0026ndash;android绘制流程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E6%BA%90%E7%A0%81%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95/",
	"title": "源码研究方法",
	"tags": [],
	"description": "",
	"content": "源码研究方法 探索总结源码研究方法知识\n Syscall查找方式     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E7%BB%98%E5%88%B6/",
	"title": "硬件加速绘制",
	"tags": [],
	"description": "",
	"content": "硬件加速绘制 Android硬件加速过程分析\n理解Android硬件加速原理的小白文\nAndroid硬件加速原理与实现\n总结：\n CPU更擅长复杂逻辑控制，而GPU得益于大量ALU和并行结构设计，更擅长数学运算。 页面由各种基础元素（DisplayList）构成，渲染时需要进行大量浮点运算。 硬件加速条件下，CPU用于控制复杂绘制逻辑，构建或更新DisplayList；GPU用于完成图形计算，渲染DisplayList。 硬件加速条件下，刷新界面尤其是播放动画时，CPU只重建或更新必要的DisplayList，进一步提高渲染效率。   软硬件加速的区别 软硬件加速的区别主要是==图形的绘制究竟是GPU来处理还是CPU，如果是GPU==，就认为是硬件加速绘制，反之，软件绘制。\n不仅仅限定在绘制方面，绘制之前，在如何构建绘制区域上，硬件加速也做出了很大优化，因此硬件加速特性可以从下面两部分来分析：\n ==前期策略：如何构建需要绘制的区域== ==后期绘制：单独渲染线程，依赖GPU进行绘制==  无论是软件绘制还是硬件加速，==绘制内存的分配都是类似的，都是需要请求SurfaceFlinger服务分配一块内存==，只不过硬件加速有可能从FrameBuffer硬件缓冲区直接分配内存（SurfaceFlinger一直这么干的），==两者的绘制都是在APP端，绘制完成之后同样需要通知SurfaceFlinger进行合成，在这个流程上没有任何区别==，真正的区别在于在APP端如何完成UI数据绘制\n软件绘制同硬件加速的区别主要是在绘制上，内存分配、图层合成等整体流程是一样的，只不过硬件加速相比软件绘制算法更加合理，同时采用单独的渲染线程，减轻了主线程的负担。\n软件绘制跟硬件加速的分歧点 ViewRootImpl.java\nprivate void draw(boolean fullRedrawNeeded) { ... if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { //关键点1 是否开启硬件加速  if (mAttachInfo.mHardwareRenderer != null \u0026amp;\u0026amp; mAttachInfo.mHardwareRenderer.isEnabled()) { ... dirty.setEmpty(); mBlockResizeBuffer = false; //关键点2 硬件加速绘制  mAttachInfo.mHardwareRenderer.draw(mView, mAttachInfo, this); } else { ... //关键点3 软件绘制  if (!drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty)) { return; } ... 其实到这里软件绘制跟硬件加速的分歧点已经找到了，就是ViewRootImpl在draw的时候，如果需要硬件加速就利用 HardwareRenderer进行draw，否则走软件绘制流程，drawSoftware其实很简单，利用Surface.lockCanvas，向SurfaceFlinger申请一块匿名共享内存内存分配，同时获取一个普通的SkiaCanvas，用于调用Skia库，进行图形绘制，\nprivate boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty) { final Canvas canvas; try { //关键点1  canvas = mSurface.lockCanvas(dirty); .. //关键点2 绘制  mView.draw(canvas); .. //关键点3 通知SurfaceFlinger进行图层合成  surface.unlockCanvasAndPost(canvas); } ... return true; } 默认情况下Skia的绘制没有采用GPU渲染的方式（虽然Skia也能用GPU渲染），也就说默认drawSoftware工作完全由CPU来完成，不会牵扯到GPU的操作，但是8.0之后，Google逐渐加重了Skia，开始让Skia接手OpenGL，间接统一调用，将来还可能是Skia同Vulkan的结合，不过这里不是重点。重点看下HardwareRenderer所进行的硬件加速绘制。\nHardwareRenderer硬件加速绘制模型 开头说过，硬件加速绘制包括两个阶段：==构建阶段+绘制阶段==，所谓构建就是递归遍历所有视图，将需要的操作缓存下来，之后再交给单独的Render线程利用OpenGL渲染。在Android硬件加速框架中，==View视图被抽象成RenderNode节点==，==View中的绘制都会被抽象成一个个DrawOp（DisplayListOp）==，比如View中drawLine，构建中就会被抽象成一个DrawLintOp，drawBitmap操作会被抽象成DrawBitmapOp，==每个子View的绘制被抽象成DrawRenderNodeOp，每个DrawOp有对应的OpenGL绘制命令，同时内部也握着绘图所需要的数据==。如下所示：\n如此以来，==每个View不仅仅握有自己DrawOp List，同时还拿着子View的绘制入口，如此递归==，便能够统计到所有的绘制Op，很多分析都称==为Display List==，源码中也是这么来命名类的，不过这里其实更像是一个树，而不仅仅是List，示意如下：\n构建完成后，就可以==将这个绘图Op树交给Render线程进行绘制==，这里是同软件绘制很不同的地方，软件绘制时，View一般都在主线程中完成绘制，而硬件加速，除非特殊要求，一般都是在单独线程中完成绘制，如此以来就分担了主线程很多压力，提高了UI线程的响应速度。\nAndroid硬件加速（二）-RenderThread与OpenGL GPU渲染\n利用HardwareRenderer构建DrawOp集 HardwareRenderer是整个硬件加速绘制的入口，实现是一个ThreadedRenderer对象，从名字能看出，ThreadedRenderer应该跟一个Render线程息息相关，不过ThreadedRenderer是在UI线程中创建的，那么与UI线程也必定相关，其主要作用：\n ==在UI线程中完成DrawOp集构建== ==负责跟渲染线程通信==  可见ThreadedRenderer的作用是很重要的，简单看一下实现：\nThreadedRenderer(Context context, boolean translucent) { ... //新建native node  long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); //新建NativeProxy  mNativeProxy = nCreateProxy(translucent, rootNodePtr); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } 从上面代码看出，ThreadedRenderer中有一个==RootNode==用来标识整个DrawOp树的根节点，有个这个根节点就可以访问所有的绘制Op，同时还有个==RenderProxy对象，这个对象就是用来跟渲染线程进行通信的句柄==，看一下其构造函数：\nRenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()) , mContext(nullptr) { SETUP_TASK(createContext); args-\u0026gt;translucent = translucent; args-\u0026gt;rootRenderNode = rootRenderNode; args-\u0026gt;thread = \u0026amp;mRenderThread; args-\u0026gt;contextFactory = contextFactory; mContext = (CanvasContext*) postAndWait(task); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext); } 从RenderThread::getInstance()可以看出，==RenderThread是一个单例线程==，也就是说，每个进程最多只有一个硬件渲染线程，这样就不会存在多线程并发访问冲突问题。下面就接着看ThreadedRenderer的draw函数，如何构建渲染Op树：\nThreadedRenderer::draw @Override void draw(View view, AttachInfo attachInfo, HardwareDrawCallbacks callbacks) { attachInfo.mIgnoreDirtyState = true; final Choreographer choreographer = attachInfo.mViewRootImpl.mChoreographer; choreographer.mFrameInfo.markDrawStart(); //关键点1：构建View的DrawOp树  updateRootDisplayList(view, callbacks); //关键点2：通知RenderThread线程绘制  int syncResult = nSyncAndDrawFrame(mNativeProxy, frameInfo, frameInfo.length); ... } 关键点1 updateRootDisplayList，构建RootDisplayList，其实就是构建View的DrawOp树，==updateRootDisplayList会进而调用根View的updateDisplayListIfDirty，让其递归子View的updateDisplayListIfDirty，从而完成DrawOp树的创==建，简述一下流程：\nupdateRootDisplayList private void updateRootDisplayList(View view, HardwareDrawCallbacks callbacks) { updateViewTreeDisplayList(view); if (mRootNodeNeedsUpdate || !mRootNode.isValid()) { //获取DisplayListCanvas, 利用View的RenderNode获取一个DisplayListCanvas  DisplayListCanvas canvas = mRootNode.start(mSurfaceWidth, mSurfaceHeight); try { //利用canvas缓存Op, 利用DisplayListCanvas构建并缓存所有的DrawOp  final int saveCount = canvas.save(); canvas.translate(mInsetLeft, mInsetTop); callbacks.onHardwarePreDraw(canvas); canvas.insertReorderBarrier(); canvas.drawRenderNode(view.updateDisplayListIfDirty()); canvas.insertInorderBarrier(); callbacks.onHardwarePostDraw(canvas); canvas.restoreToCount(saveCount); mRootNodeNeedsUpdate = false; } finally { //将所有Op填充到RootRenderNode, 将DisplayListCanvas缓存的DrawOp填充到RenderNode  mRootNode.end(canvas); } } } View.java递归构建DrawOp @NonNull public RenderNode updateDisplayListIfDirty() { final RenderNode renderNode = mRenderNode; ... // start 获取一个 DisplayListCanvas 用于绘制 硬件加速  final DisplayListCanvas canvas = renderNode.start(width, height); try { // 是否是textureView  final HardwareLayer layer = getHardwareLayer(); if (layer != null \u0026amp;\u0026amp; layer.isValid()) { canvas.drawHardwareLayer(layer, 0, 0, mLayerPaint); } else if (layerType == LAYER_TYPE_SOFTWARE) { // 是否强制软件绘制  buildDrawingCache(true); Bitmap cache = getDrawingCache(true); if (cache != null) { canvas.drawBitmap(cache, 0, 0, mLayerPaint); } } else { // 如果仅仅是ViewGroup，并且自身不用绘制，直接递归子View  if ((mPrivateFlags \u0026amp; PFLAG_SKIP_DRAW) == PFLAG_SKIP_DRAW) { dispatchDraw(canvas); } else { //调用自己draw，如果是ViewGroup会递归子View  draw(canvas); } } } finally { //缓存构建Op  renderNode.end(canvas); setDisplayListProperties(renderNode); } } return renderNode; } ViewGroup::dispatchDraw @Override protected void dispatchDraw(Canvas canvas) { boolean usingRenderNodeProperties = canvas.isRecordingFor(mRenderNode); final int childrenCount = mChildrenCount; final View[] children = mChildren; int flags = mGroupFlags; for (int i = 0; i \u0026lt; childrenCount; i++) { final int childIndex = getAndVerifyPreorderedIndex(childrenCount, i, customOrder); final View child = getAndVerifyPreorderedView(preorderedList, children, childIndex); if ((child.mViewFlags \u0026amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) { more |= drawChild(canvas, child, drawingTime); } } } protected boolean drawChild(Canvas canvas, View child, long drawingTime) { return child.draw(canvas, this, drawingTime); } View::draw boolean draw(Canvas canvas, ViewGroup parent, long drawingTime) { boolean drawingWithRenderNode = mAttachInfo != null \u0026amp;\u0026amp; mAttachInfo.mHardwareAccelerated \u0026amp;\u0026amp; hardwareAcceleratedCanvas; if (drawingWithRenderNode) { renderNode = updateDisplayListIfDirty(); } } drawLine 假如在View onDraw中，有个drawLine，这里就会调用DisplayListCanvas的drawLine函数，DisplayListCanvas及RenderNode类图大概如下 DisplayListCanvas的drawLine函数最终会进入DisplayListCanvas.cpp的drawLine，\nvoid DisplayListCanvas::drawLines(const float* points, int count, const SkPaint\u0026amp; paint) { points = refBuffer\u0026lt;float\u0026gt;(points, count); addDrawOp(new (alloc()) DrawLinesOp(points, count, refPaint(\u0026amp;paint))); } 可以看到，这里构建了一个DrawLinesOp，并添加到DisplayListCanvas的缓存列表中去，如此递归便可以完成DrawOp树的构建，在构建后利用RenderNode的end函数，将DisplayListCanvas中的数据缓存到RenderNode中去：\npublic void end(DisplayListCanvas canvas) { canvas.onPostDraw(); long renderNodeData = canvas.finishRecording(); //将DrawOp缓存到RenderNode中去  nSetDisplayListData(mNativeRenderNode, renderNodeData); // canvas 回收掉]  canvas.recycle(); mValid = true; } RenderThread渲染UI到Graphic Buffer DrawOp树构建完毕后，UI线程利用RenderProxy向RenderThread线程发送一个DrawFrameTask任务请求，RenderThread被唤醒，开始渲染，大致流程如下：\n 首先进行DrawOp的==合并== 接着绘制特殊的Layer 最后==绘制其余所有的DrawOpList== 调用swapBuffers将前面已经绘制好的图形缓冲区提交给Surface Flinger合成和显示。  syncAndDrawFrame static int android_view_ThreadedRenderer_syncAndDrawFrame(JNIEnv* env, jobject clazz, jlong proxyPtr, jlongArray frameInfo, jint frameInfoSize) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); env-\u0026gt;GetLongArrayRegion(frameInfo, 0, frameInfoSize, proxy-\u0026gt;frameInfo()); return proxy-\u0026gt;syncAndDrawFrame(); } RenderProxy::syncAndDrawFrame int RenderProxy::syncAndDrawFrame() { return mDrawFrameTask.drawFrame(); } DrawFrameTask::drawFrame int DrawFrameTask::drawFrame() { postAndWait(); return mSyncResult; } DrawFrameTask::postAndWait void DrawFrameTask::postAndWait() { AutoMutex _lock(mLock); mRenderThread-\u0026gt;queue().post([this]() { run(); }); mSignal.wait(mLock); } DrawFrameTask::run void DrawFrameTask::run() { canUnblockUiThread = syncFrameState(info); // Grab a copy of everything we need  CanvasContext* context = mContext; // From this point on anything in \u0026#34;this\u0026#34; is *UNSAFE TO ACCESS*  if (canUnblockUiThread) { unblockUiThread(); } if (CC_LIKELY(canDrawThisFrame)) { context-\u0026gt;draw(); } else { // wait on fences so tasks don\u0026#39;t overlap next frame  context-\u0026gt;waitOnFences(); } if (!canUnblockUiThread) { unblockUiThread(); } } CanvasContext::draw void CanvasContext::draw() { mCurrentFrameInfo-\u0026gt;markIssueDrawCommandsStart(); Frame frame = mRenderPipeline-\u0026gt;getFrame(); SkRect windowDirty = computeDirtyRect(frame, \u0026amp;dirty); bool drew = mRenderPipeline-\u0026gt;draw(frame, windowDirty, dirty, mLightGeometry, \u0026amp;mLayerUpdateQueue, mContentDrawBounds, mOpaque, mWideColorGamut, mLightInfo, mRenderNodes, \u0026amp;(profiler())); bool didSwap = mRenderPipeline-\u0026gt;swapBuffers(frame, drew, windowDirty, mCurrentFrameInfo, \u0026amp;requireSwap); } 绘制内存的由来 DrawOp树的构建只是在普通的==用户内存==中，而部分数据对于SurfaceFlinger都是不可见的，之后又绘制到==共享内存==中的数据才会被SurfaceFlinger合成，之前分析过软件绘制的共享内存是来自匿名共享内存，那么硬件加速的共享内存来自何处呢？到这里可能要倒回去看看ViewRootImpl\nprivate void performTraversals() { ... if (mAttachInfo.mHardwareRenderer != null) { try { hwInitialized = mAttachInfo.mHardwareRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { mSurface.allocateBuffers(); } } catch (OutOfResourcesException e) { handleOutOfResourcesException(e); return; } } .... /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } 对于硬件加速的场景，请求SurfaceFlinger内存分配的时机会稍微提前，而不是像软件绘制，由Surface的lockCanvas发起，主要目的是：预先分配slot位置，避免在渲染的时候再申请，一是避免分配失败，浪费了CPU之前的准备工作，二是也可以将渲染线程个工作简化，减少延时。不过，还是会存在另一个问题，一个APP进程，==同一时刻会有多个Surface绘图界面，但是渲染线程只有一个，那么究竟渲染那个呢==？这个时候就需要将Surface与渲染线程（上下文）绑定。\nSurface与渲染线程（上下文）绑定 static jboolean android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;ANativeWindow\u0026gt; window = android_view_Surface_getNativeWindow(env, jsurface); return proxy-\u0026gt;initialize(window); } 首先通过android_view_Surface_getNativeWindowSurface获取Surface，在Native层,Surface对应一个ANativeWindow,接着，通过RenderProxy类的成员函数initialize将前面获得的ANativeWindow绑定到RenderThread\nbool RenderProxy::initialize(const sp\u0026lt;ANativeWindow\u0026gt;\u0026amp; window) { SETUP_TASK(initialize); args-\u0026gt;context = mContext; args-\u0026gt;window = window.get(); return (bool) postAndWait(task); } 仍旧是向渲染线程发送消息，让其绑定当前Window，其实就是调用CanvasContext的initialize函数，让绘图上下文绑定绘图内存：\nbool CanvasContext::initialize(ANativeWindow* window) { setSurface(window); if (mCanvas) return false; mCanvas = new OpenGLRenderer(mRenderThread.renderState()); mCanvas-\u0026gt;initProperties(); return true; } CanvasContext通过setSurface将当前要渲染的Surface绑定到到RenderThread中，大概流程是通过eglApi获得一个EGLSurface，EGLSurface封装了一个绘图表面，进而，==通过eglApi将EGLSurface设定为当前渲染窗口==，并将绘图内存等信息进行同步，==之后通过RenderThread绘制的时候才能知道是在哪个窗口上进行绘制==。之后，再创建一个OpenGLRenderer对象，后面执行OpenGL相关操作的时候，其实就是通过OpenGLRenderer来进行的。\n合并操作和绘制 真正调用OpenGL绘制之前还有一些合并操作，这是Android硬件加速做的优化，回过头继续走draw流程，其实就是走OpenGLRenderer的drawRenderNode进行递归处理：\nvoid OpenGLRenderer::drawRenderNode(RenderNode* renderNode, Rect\u0026amp; dirty, int32_t replayFlags) { ... \u0026lt;!--构建deferredList--\u0026gt; DeferredDisplayList deferredList(mState.currentClipRect(), avoidOverdraw); DeferStateStruct deferStruct(deferredList, *this, replayFlags); \u0026lt;!--合并及分组--\u0026gt; renderNode-\u0026gt;defer(deferStruct, 0); \u0026lt;!--绘制layer--\u0026gt; flushLayers(); startFrame(); \u0026lt;!--绘制 DrawOp树--\u0026gt; deferredList.flush(*this, dirty); ... } 先看下renderNode-\u0026gt;defer(deferStruct, 0)，合并操作，DrawOp树并不是直接被绘制的，而是首先通过DeferredDisplayList进行一个合并优化，这个是Android硬件加速中采用的一种优化手段，不仅可以减少不必要的绘制，还可以将相似的绘制集中处理，提高绘制速度。\nvoid RenderNode::defer(DeferStateStruct\u0026amp; deferStruct, const int level) { DeferOperationHandler handler(deferStruct, level); issueOperations\u0026lt;DeferOperationHandler\u0026gt;(deferStruct.mRenderer, handler); } RenderNode::defer其实内含递归操作，比如，如果当前RenderNode代表DecorView，它就会递归所有的子View进行合并优化处理\n合并及优化的流程及算法，其实主要就是根据DrawOp树构建DeferedDisplayList。在合并过程中，DrawOp被分为两种：需要合的与不需要合并的，并分别缓存在不同的列表中，\n 无法合并的按照类型分别存放在Batch*mBatchLookup[kOpBatch_Count]中 可以合并的按照类型及MergeID存储到TinyHashMap\u0026lt;mergeid_t, DrawBatch*\u0026gt;mMergingBatches[kOpBatch_Count]中  合并之后，DeferredDisplayList Vector\u0026lt;Batch * \u0026gt; mBatches 包含全部整合后的绘制命令，之后渲染即可，需要注意的是这里的合并并不是多个变一个，只是做了一个集合，主要是方便使用各资源纹理等，比如绘制文字的时候，需要根据文字的纹理进行渲染，而这个时候就需要查询文字的纹理坐标系，合并到一起方便统一处理，一次渲染，减少资源加载的浪费。\n它的主要特点是==在另一个Render线程使用OpenGL进行绘制==，这个是它最重要的特点。而mBatches中所有的DrawOp都会通过OpenGL被绘制到GraphicBuffer中，最后通过swapBuffers通知SurfaceFlinger合成。\n "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E7%B1%BB%E5%8A%A0%E8%BD%BD/",
	"title": "类加载",
	"tags": [],
	"description": "",
	"content": "类加载 探索总结类加载知识\n Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E7%B1%BB%E5%8A%A0%E8%BD%BD/%E7%B1%BB%E5%8A%A0%E8%BD%BD/",
	"title": "类加载",
	"tags": [],
	"description": "",
	"content": "动态加载dex和so https://alibaba.github.io/atlas/update/principle.html\nPathClassLoader自身负责主Apk的类和c库的查找路口；其parent BootClassloader负责framework sdk的内容的查找。\nPathClassLoader本身也是一个class，继承了BaseDexClassLoader（同DexClassLoader），里面查找过程在DexPathList里面实现（如下图） \u0026gt;\nDexPathList最终通过DexFile去loadClass，DexPathList可以理解为持有者DexFile以及nativeLibrary目录，再查找的时候遍历这些对象，直到找到需要的类或者c库，那么动态部署的方式就是把新修改的内容添加到这些对象的最前面，从而使得查找的过程中新修改的内容能够提前找到从而替换原有的（如下图）\nBaseDexClassLoader构造方法 private final DexPathList pathList; /** \\* Constructs an instance. \\* Note that all the *.jar and *.apk files from {@code dexPath} might be \\* first extracted in-memory before the code is loaded. This can be avoided \\* by passing raw dex files (*.dex) in the {@code dexPath}. * \\* @param dexPath the list of jar/apk files containing classes and \\* resources, delimited by {@code File.pathSeparator}, which \\* defaults to {@code \u0026#34;:\u0026#34;} on Android. \\* @param optimizedDirectory this parameter is deprecated and has no effect \\* @param librarySearchPath the list of directories containing native \\* libraries, delimited by {@code File.pathSeparator}; may be \\* {@code null} \\* @param parent the parent class loader */ public BaseDexClassLoader(String dexPath, File optimizedDirectory, String librarySearchPath, ClassLoader parent) { super(parent); this.pathList = new DexPathList(this, dexPath, librarySearchPath, null); if (reporter != null) { reporter.report(this.pathList.getDexPaths()); } } DexPathList构造方法 /** class definition context */ private final ClassLoader definingContext; /** \\* List of dex/resource (class path) elements. \\* Should be called pathElements, but the Facebook app uses reflection \\* to modify \u0026#39;dexElements\u0026#39; (http://b/7726934). */ private Element[] dexElements;//dexElements：描述defingContext ClassLoader所加载的dex文件  private final Element[] nativeLibraryPathElements; //ClassLoader除了加载类之外，加载native动态库的工作也可由它来完成。下面这个变量描述了definingContext ClassLoader可从哪几个目录中搜索目标动态库 private final List\u0026lt;File\u0026gt; nativeLibraryDirectories; /** \\* Constructs an instance. * \\* @param definingContext the context in which any as-yet unresolved \\* classes should be defined \\* @param dexPath list of dex/resource path elements, separated by \\* {@code File.pathSeparator} \\* @param librarySearchPath list of native library directory path elements, \\* separated by {@code File.pathSeparator} \\* @param optimizedDirectory directory where optimized {@code .dex} files \\* should be found and written to, or {@code null} to use the default \\* system directory for same */ public DexPathList(ClassLoader definingContext, String dexPath, String librarySearchPath, File optimizedDirectory) { // save dexPath for BaseDexClassLoader  this.dexElements = makeDexElements(splitDexPath(dexPath), optimizedDirectory, suppressedExceptions, definingContext); DexPathList.makePathElements private static Element[] makePathElements(List\u0026lt;File\u0026gt; files, File optimizedDirectory, List\u0026lt;IOException\u0026gt; suppressedExceptions) { return makeDexElements(files, optimizedDirectory, suppressedExceptions, null); /** \\* Makes an array of dex/resource path elements, one per element of \\* the given array. */ private static Element[] makeDexElements(List\u0026lt;File\u0026gt; files, File optimizedDirectory, List\u0026lt;IOException\u0026gt; suppressedExceptions, ClassLoader loader) { Element[] elements = new Element[files.size()]; int elementsPos = 0; for (File file : files) { if (name.endsWith(DEX_SUFFIX)) { // Raw dex file (not inside a zip/jar).  try { DexFile dex = loadDexFile(file, optimizedDirectory, loader, elements); if (dex != null) { elements[elementsPos++] = new Element(dex, null); } } return elements; Element构造方法 /** \\* Element of the dex/resource path. Note: should be called DexElement, but apps reflect on \\* this. */ /*package*/ static class Element { /** \\* A file denoting a zip file (in case of a resource jar or a dex jar), or a directory \\* (only when dexFile is null). */ private final File path; private final DexFile dexFile; /** \\* Element encapsulates a dex file. This may be a plain dex file (in which case dexZipPath \\* should be null), or a jar (in which case dexZipPath should denote the zip file). */ public Element(DexFile dexFile, File dexZipPath) { this.dexFile = dexFile; this.path = dexZipPath; } /** \\* Constructs a {@code DexFile} instance, as appropriate depending on whether \\* {@code optimizedDirectory} is {@code null}. An application image file may be associated with the {@code loader} if it is not null. */ private static DexFile loadDexFile(File file, File optimizedDirectory, ClassLoader loader, Element[] elements) throws IOException { if (optimizedDirectory == null) { return new DexFile(file, loader, elements); } else { String optimizedPath = optimizedPathFor(file, optimizedDirectory); return DexFile.loadDex(file.getPath(), optimizedPath, 0, loader, elements); } } DexFile.loadDex static DexFile loadDex(String sourcePathName, String outputPathName, int flags, ClassLoader loader, DexPathList.Element[] elements) throws IOException { return new DexFile(sourcePathName, outputPathName, flags, loader, elements); } DexFile构造方法 /* \\* Private version with class loader argument. * \\* @param file \\* the File object referencing the actual DEX file \\* @param loader \\* the class loader object creating the DEX file object \\* @param elements \\* the temporary dex path list elements from DexPathList.makeElements */ DexFile(File file, ClassLoader loader, DexPathList.Element[] elements) throws IOException { this(file.getPath(), loader, elements); } DexFile(String fileName, ClassLoader loader, DexPathList.Element[] elements) throws IOException { mCookie = openDexFile(fileName, null, 0, loader, elements); mInternalCookie = mCookie; mFileName = fileName; //System.out.println(\u0026#34;DEX FILE cookie is \u0026#34; + mCookie + \u0026#34; fileName=\u0026#34; + fileName);  } /* \\* Open a DEX file. The value returned is a magic VM cookie. On \\* failure, an IOException is thrown. */ private static Object openDexFile(String sourceName, String outputName, int flags, ClassLoader loader, DexPathList.Element[] elements) throws IOException { // Use absolute paths to enable the use of relative paths when testing on host.  return openDexFileNative(new File(sourceName).getAbsolutePath(), (outputName == null)? null: new File(outputName).getAbsolutePath(), flags, loader, elements); } /art/runtime/native/dalvik_system_DexFile.cc\n267static jobject DexFile_openDexFileNative(JNIEnv* env, 268 jclass, 269 jstring javaSourceName, 270 jstring javaOutputName ATTRIBUTE_UNUSED, 271 jint flags ATTRIBUTE_UNUSED, 272 jobject class_loader, 273 jobjectArray dex_elements) { ScopedUtfChars sourceName(env, javaSourceName); 279 Runtime* const runtime = Runtime::Current(); 280 ClassLinker* linker = runtime-\u0026gt;GetClassLinker(); 281 std::vector\u0026lt;std::unique_ptr\u0026lt;const DexFile\u0026gt;\u0026gt; dex_files; 282 std::vector\u0026lt;std::string\u0026gt; error_msgs; 283 const OatFile* oat_file = nullptr; //main 285 dex_files = runtime-\u0026gt;GetOatFileManager().OpenDexFilesFromOat(sourceName.c_str(), 286 class_loader, 287 dex_elements, 288 /*out*/ \u0026amp;oat_file, 289 /*out*/ \u0026amp;error_msgs); 291 if (!dex_files.empty()) { 292 jlongArray array = ConvertDexFilesToJavaArray(env, oat_file, dex_files); 293 if (array == nullptr) { 294 ScopedObjectAccess soa(env); 295 for (auto\u0026amp; dex_file : dex_files) { 296 if (linker-\u0026gt;IsDexFileRegistered(soa.Self(), *dex_file)) { 297 dex_file.release(); 298 } 299 } 300 } 301 return array; /art/runtime/oat_file_manager.h or cc\nOatFileManager::OpenDexFilesFromOat 84 // Finds or creates the oat file holding dex_location. Then loads and returns 85 // all corresponding dex files (there may be more than one dex file loaded 86 // in the case of multidex). 87 // This may return the original, unquickened dex files if the oat file could 88 // not be generated. 89 // 90 // Returns an empty vector if the dex files could not be loaded. In this 91 // case, there will be at least one error message returned describing why no 92 // dex files could not be loaded. The \u0026#39;error_msgs\u0026#39; argument must not be 93 // null, regardless of whether there is an error or not. 94 // 95 // This method should not be called with the mutator_lock_ held, because it 96 // could end up starving GC if we need to generate or relocate any oat files. 394std::vector\u0026lt;std::unique_ptr\u0026lt;const DexFile\u0026gt;\u0026gt; OatFileManager::OpenDexFilesFromOat( 395 const char* dex_location, 396 jobject class_loader, 397 jobjectArray dex_elements, 398 const OatFile** out_oat_file, 399 std::vector\u0026lt;std::string\u0026gt;* error_msgs) { 404 // Verify we aren\u0026#39;t holding the mutator lock, which could starve GC if we 405 // have to generate or relocate an oat file. 406 Thread* const self = Thread::Current(); 407 Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); 408 Runtime* const runtime = Runtime::Current(); 410 std::unique_ptr\u0026lt;ClassLoaderContext\u0026gt; context; 411 // If the class_loader is null there\u0026#39;s not much we can do. This happens if a dex files is loaded 412 // directly with DexFile APIs instead of using class loaders. 413 if (class_loader == nullptr) { 416 context = nullptr; 417 } else { 418 context = ClassLoaderContext::CreateContextForClassLoader(class_loader, dex_elements); 419 } 420 421 OatFileAssistant oat_file_assistant(dex_location, 422 kRuntimeISA, 423 !runtime-\u0026gt;IsAotCompiler(), 424 only_use_system_oat_files_); 437 if (!oat_file_assistant.IsUpToDate()) { //main oat_file_assistant.MakeUpToDate(/*profile_changed*/ false, 452 actual_context, 453 /*out*/ \u0026amp;error_msg) /art/libdexfile/dex/dex_file.h\nclass DexFile 63// Dex file is the API that exposes native dex files (ordinary dex files) and CompactDex. 64// Originally, the dex file format used by ART was mostly the same as APKs. The only change was 65// quickened opcodes and layout optimizations. 66// Since ART needs to support both native dex files and CompactDex files, the DexFile interface 67// provides an abstraction to facilitate this. 68class DexFile { 83 // Raw header_item. 84 struct Header { 85 uint8_t magic_[8] = {}; 86 uint32_t checksum_ = 0; // See also location_checksum_ 87 uint8_t signature_[kSha1DigestSize] = {}; 88 uint32_t file_size_ = 0; // size of entire file 89 uint32_t header_size_ = 0; // offset to start of next section 90 uint32_t endian_tag_ = 0; 91 uint32_t link_size_ = 0; // unused 92 uint32_t link_off_ = 0; // unused 93 uint32_t map_off_ = 0; // unused 94 uint32_t string_ids_size_ = 0; // number of StringIds 95 uint32_t string_ids_off_ = 0; // file offset of StringIds array 96 uint32_t type_ids_size_ = 0; // number of TypeIds, we don\u0026#39;t support more than 65535 97 uint32_t type_ids_off_ = 0; // file offset of TypeIds array 98 uint32_t proto_ids_size_ = 0; // number of ProtoIds, we don\u0026#39;t support more than 65535 99 uint32_t proto_ids_off_ = 0; // file offset of ProtoIds array 100 uint32_t field_ids_size_ = 0; // number of FieldIds 101 uint32_t field_ids_off_ = 0; // file offset of FieldIds array 102 uint32_t method_ids_size_ = 0; // number of MethodIds 103 uint32_t method_ids_off_ = 0; // file offset of MethodIds array 104 uint32_t class_defs_size_ = 0; // number of ClassDefs 105 uint32_t class_defs_off_ = 0; // file offset of ClassDef array 106 uint32_t data_size_ = 0; // size of data section 107 uint32_t data_off_ = 0; // file offset of data section 108 109 // Decode the dex magic version 110 uint32_t GetVersion() const; 111 }; /art/runtime/oat_file_assistant.cc\nOatFileAssistant::MakeUpToDate 251OatFileAssistant::MakeUpToDate(bool profile_changed, 252 ClassLoaderContext* class_loader_context, 253 std::string* error_msg) { 262 OatFileInfo\u0026amp; info = GetBestInfo(); 273 switch (info.GetDexOptNeeded( 274 target, profile_changed, /*downgrade*/ false, class_loader_context)) { 275 case kNoDexOptNeeded: 276 return kUpdateSucceeded; 277 278 // TODO: For now, don\u0026#39;t bother with all the different ways we can call 279 // dex2oat to generate the oat file. Always generate the oat file as if it 280 // were kDex2OatFromScratch. 281 case kDex2OatFromScratch: 282 case kDex2OatForBootImage: 283 case kDex2OatForRelocation: 284 case kDex2OatForFilter: 285 return GenerateOatFileNoChecks(info, target, class_loader_context, error_msg); 286 } OatFileAssistant::GenerateOatFileNoChecks 698OatFileAssistant::ResultOfAttemptToUpdate OatFileAssistant::GenerateOatFileNoChecks( 699 OatFileAssistant::OatFileInfo\u0026amp; info, 700 CompilerFilter::Filter filter, 701 const ClassLoaderContext* class_loader_context, 702 std::string* error_msg) { 717 const std::string\u0026amp; oat_file_name = *info.Filename(); 718 const std::string\u0026amp; vdex_file_name = GetVdexFilename(oat_file_name); 43 Dex2oatFileWrapper vdex_file_wrapper(OS::CreateEmptyFile(vdex_file_name.c_str())); 744 File* vdex_file = vdex_file_wrapper.GetFile(); 759 Dex2oatFileWrapper oat_file_wrapper(OS::CreateEmptyFile(oat_file_name.c_str())); 760 File* oat_file = oat_file_wrapper.GetFile(); 773 std::vector\u0026lt;std::string\u0026gt; args; 774 args.push_back(\u0026#34;--dex-file=\u0026#34; + dex_location_); 775 args.push_back(\u0026#34;--output-vdex-fd=\u0026#34; + std::to_string(vdex_file-\u0026gt;Fd())); 776 args.push_back(\u0026#34;--oat-fd=\u0026#34; + std::to_string(oat_file-\u0026gt;Fd())); 777 args.push_back(\u0026#34;--oat-location=\u0026#34; + oat_file_name); 778 args.push_back(\u0026#34;--compiler-filter=\u0026#34; + CompilerFilter::NameOfFilter(filter)); 779 const std::string dex2oat_context = class_loader_context == nullptr 780 ? OatFile::kSpecialSharedLibrary 781 : class_loader_context-\u0026gt;EncodeContextForDex2oat(/*base_dir*/ \u0026#34;\u0026#34;); 782 args.push_back(\u0026#34;--class-loader-context=\u0026#34; + dex2oat_context); 784 if (!Dex2Oat(args, error_msg)) {//main 785 return kUpdateFailed; 786 } 787 788 if (vdex_file-\u0026gt;FlushCloseOrErase() != 0) { 789 *error_msg = \u0026#34;Unable to close vdex file \u0026#34; + vdex_file_name; 790 return kUpdateFailed; 791 } 792 793 if (oat_file-\u0026gt;FlushCloseOrErase() != 0) { 794 *error_msg = \u0026#34;Unable to close oat file \u0026#34; + oat_file_name; 795 return kUpdateFailed; 796 } 804 return kUpdateSucceeded; OatFileAssistant::Dex2Oat 807bool OatFileAssistant::Dex2Oat(const std::vector\u0026lt;std::string\u0026gt;\u0026amp; args, 808 std::string* error_msg) { 816 std::vector\u0026lt;std::string\u0026gt; argv; 817 argv.push_back(runtime-\u0026gt;GetCompilerExecutable()); 849 argv.insert(argv.end(), args.begin(), args.end()); 850 851 std::string command_line(android::base::Join(argv, \u0026#39; \u0026#39;)); 852 return Exec(argv, error_msg); /art/runtime/runtime.h\n723std::string Runtime::GetCompilerExecutable() const { 724 if (!compiler_executable_.empty()) { 725 return compiler_executable_; 726 } 727 std::string compiler_executable(GetAndroidRoot()); //getenv(\u0026#34;ANDROID_ROOT\u0026#34;) 728 compiler_executable += (kIsDebugBuild ? \u0026#34;/bin/dex2oatd\u0026#34; : \u0026#34;/bin/dex2oat\u0026#34;); //位于设备system/bin/dex2oat 729 return compiler_executable; 730} /art/dex2oat/dex2oat.cc\n3176int main(int argc, char** argv) { 3177 int result = static_cast\u0026lt;int\u0026gt;(art::Dex2oat(argc, argv)); 3184 return result; 3185} 具体参考类编译原理\nclassLoader.loadClass 方法调用时机 对于APPComponentFactory子类，LoadedApk进行调用 对于application和四大组件由instrumentation调用APPComponentFactory进行调用 对于view，由LayoutInflator在createView方法中进行调用 对于其他自定义类，由jvm进行调用 Class objects for array classes are not created by class loaders, but are created automatically as required by the Java runtime. The class loader for an array class, as returned by Class#getClassLoader() is the same as the class loader for its element type; if the element type is a primitive type, then the array class has no class loader.\nprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { // First, check if the class has already been loaded  Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found  // from the non-null parent class loader  } if (c == null) { // If still not found, then invoke findClass in order  // to find the class.  c = findClass(name);//main  } } return c; @Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { return Class.classForName(name, false, null); } /** Called after security checks have been made. */ @FastNative static native Class\u0026lt;?\u0026gt; classForName(String className, boolean shouldInitialize, ClassLoader classLoader) throws ClassNotFoundException; BootClassLoader.findClass class BootClassLoader extends ClassLoader { //BootClassLoader采用了单例构造的方式。所以一个Java进程只存在一个BootClassLoader对象  private static BootClassLoader instance; //Loader没有可委托的其他加载器了。  public BootClassLoader() { super(null); } //加载目标类，下文将分析其代码。  protected Class\u0026lt;?\u0026gt; findClass(String name) ... { return Class.classForName(name, false, null); } } art/runtime/native/java_lang_Class.cc\n// \u0026#34;name\u0026#34; is in \u0026#34;binary name\u0026#34; format, e.g. \u0026#34;dalvik.system.Debug$1\u0026#34;. static jclass Class_classForName(JNIEnv* env, jclass, jstring javaName, jboolean initialize,jobject javaLoader) { //注意传入的参数，javaName为JLS规范里定义的类名（如java.lang.String），  //initialize为false，javaLoader为false  ScopedFastNativeObjectAccess soa(env); ScopedUtfChars name(env, javaName); ...... //转成JVM规范使用的类名，如Ljava/lang/String;  std::string descriptor(DotToDescriptor(name.c_str())); StackHandleScope\u0026lt;2\u0026gt; hs(soa.Self()); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle( soa.Decode\u0026lt;mirror::ClassLoader*\u0026gt;(javaLoader))); ClassLinker* class_linker = Runtime::Current()-\u0026gt;GetClassLinker(); Handle\u0026lt;mirror::Class\u0026gt; c( hs.NewHandle(class_linker-\u0026gt;FindClass(soa.Self(),//main  descriptor.c_str(), class_loader))); ...... if (initialize) { //initialize为false的话，将只加载和链接目标类，不初始化它  class_linker-\u0026gt;EnsureInitialized(soa.Self(), c, true, true); } return soa.AddLocalReference\u0026lt;jclass\u0026gt;(c.Get()); } BaseDexClassLoader.findClass @Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { List\u0026lt;Throwable\u0026gt; suppressedExceptions = new ArrayList\u0026lt;Throwable\u0026gt;(); Class c = pathList.findClass(name, suppressedExceptions); return c; DexPathList.findClass /** \\* Finds the named class in one of the dex files pointed at by \\* this instance. This will find the one in the earliest listed \\* path element. If the class is found but has not yet been \\* defined, then this method will define it in the defining \\* context that this instance was constructed with. * \\* @param name of class to find \\* @param suppressed exceptions encountered whilst finding the class \\* @return the named class or {@code null} if the class is not \\* found in any of the dex files */ public Class\u0026lt;?\u0026gt; findClass(String name, List\u0026lt;Throwable\u0026gt; suppressed) { for (Element element : dexElements) { Class\u0026lt;?\u0026gt; clazz = element.findClass(name, definingContext, suppressed); if (clazz != null) { return clazz; } } public Class\u0026lt;?\u0026gt; findClass(String name, ClassLoader definingContext, List\u0026lt;Throwable\u0026gt; suppressed) { return dexFile != null ? dexFile.loadClassBinaryName(name, definingContext, suppressed) : null; } /libcore/dalvik/src/main/java/dalvik/system/DexFile.java\nDexFile.defineClass /** \\* See {@link #loadClass(String, ClassLoader)}. \\* This takes a \u0026#34;binary\u0026#34; class name to better match ClassLoader semantics. */ public Class loadClassBinaryName(String name, ClassLoader loader, List\u0026lt;Throwable\u0026gt; suppressed) { return defineClass(name, loader, mCookie, this, suppressed); } private static Class defineClass(String name, ClassLoader loader, Object cookie, DexFile dexFile, List\u0026lt;Throwable\u0026gt; suppressed) { Class result = null; try { result = defineClassNative(name, loader, cookie, dexFile); art/runtime/native/dalvik_system_DexFile.cc\nstatic jclass DexFile_defineClassNative(JNIEnv* env, jclass, jstring javaName, jobject javaLoader, jobject cookie, jobject dexFile) { ObjPtr\u0026lt;mirror::Class\u0026gt; result = class_linker-\u0026gt;DefineClass(soa.Self(), descriptor.c_str(), hash, class_loader, *dex_file, *dex_class_def); // Add the used dex file. This only required for the DexFile.loadClass API since normal  // class loaders already keep their dex files live.  class_linker-\u0026gt;InsertDexFileInToClassLoader(soa.Decode\u0026lt;mirror::Object\u0026gt;(dexFile), class_loader.Get()); PathClassLoader和DexClassLoader区别 两种ClassLoader区别在于DexClassLoader可以加载外置卡中的apk，而PathClassLoader用于加载已安装的apk，构造参数里只有优化路径的参数差异，PathClassLoader传入的是null，而DexClassLoader是可以传入的，这个差异最终是在oat_file_assistant.cc这个文件里的MakeUpToDate方法中进行判断处理，如果noDexOptNeeded(已安装apk)则直接返回，否则(未安装的apk)会进行Dex2Oat过程，这个过程需要这个优化路径，否则无法加载\n总结 https://www.jianshu.com/p/2216554d3291\nBaseDexClassLoader 的构造函数中创建一个DexPathList实例，DexPathList的构造函数会创建一个dexElements 数组\nBaseDexClassLoader 在findclass方法中调用了pathList.findClass，这个方法中会遍历dexpathlist中的dexElements数组，如果DexFile不为空那么调用DexFile类的loadClassBinaryName方法返回Class实例。\nTinker进行热修复的流程为：\n新dex与旧dex通过dex差分算法生成差异包 patch.dex\n将patch dex下发到客户端，客户端将patch dex与旧dex合成为新的全量dex\n将合成后的全量dex 插入到dex elements前面(此部分和QQ空间机制类似)，完成修复\n可见，Tinker和QQ空间方案最大的不同是，Tinker 下发新旧DEX的差异包，然后将差异包和旧包合成新dex之后进行dex的全量替换，这样也就避免了QQ空间中的插桩操作。\nhttps://blog.csdn.net/u010386612/article/details/51077291\nhttp://gityuan.com/2017/03/19/android-classloader/\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E7%B1%BB%E5%8A%A0%E8%BD%BD/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%B1%82/",
	"title": "类加载虚拟机层",
	"tags": [],
	"description": "",
	"content": "Flow load class trigger flow graph TB EnsureInitialized--\u0026gt;InitializeClass InitializeClass--\u0026gt;MethodVerifier::VerifyClass MethodVerifier::VerifyClass--\u0026gt;MethodVerifier::VerifyMethods MethodVerifier::VerifyMethods--\u0026gt;MethodVerifier::VerifyMethod MethodVerifier::VerifyMethod--\u0026gt;MethodVerifier::CodeFlowVerifyInstruction MethodVerifier::CodeFlowVerifyInstruction--\u0026gt;ResolveType MethodVerifier::VerifyMethod--\u0026gt;ResolveType ResolveType--\u0026gt;FindClass FindClass--\u0026gt;DefineClass ClassLinkerSummary ClassLinker中其他一些常见函数。包括：\n·Resolve相关函数。虽然名称叫Resolve，但在ART代码里，它并非是图8-5类加载、链接和初始化阶段中提到的Resolve。相反，它甚至可能触发一个类的加载和链接流程。\n·FindClass：根据类的字符串名称搜索一个类。如果没有的话，则可能触发类的加载和链接流程。\ngraph LR ResolveMethod--\u0026gt;ResolveType ResolveField--\u0026gt;ResolveType ResolveType--\u0026gt;FindClass FindClass--\u0026gt;FindClassInBaseDexClassLoader--\u0026gt;FindClassInBaseDexClassLoaderClassPath--\u0026gt;DefineClass ResolveMethod template \u0026lt;ClassLinker::ResolveMode kResolveMode\u0026gt; ArtMethod* ClassLinker::ResolveMethod(const DexFile\u0026amp; dex_file, uint32_t method_idx, Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, ArtMethod* referrer, InvokeType type) { //和ResolveType类似，首先判断dex_cache中是否已经解析过这个方法了。  ArtMethod* resolved = dex_cache-\u0026gt;GetResolvedMethod(method_idx, image_pointer_size_); if (resolved != nullptr \u0026amp;\u0026amp; !resolved-\u0026gt;IsRuntimeMethod()) { if (kResolveMode == ClassLinker::kForceICCECheck) { //Java有诸如1.5、1.6这样的版本，在早期Java版本里，有些信息和现在的版本有差异，  //此处将检查是否有信息不兼容的地方（即check incompatible class change），  //如果检查失败，则会设置一个IncompatibleClassChangeError异常，笔者此处不拟讨论。  if (resolved-\u0026gt;CheckIncompatibleClassChange(type)) { ...... //设置异常  return nullptr; } } return resolved; } } // 如果dex_cache里并未缓存，则先解析该方法所在类的类型（由method_id.class_idx_表示）。  const DexFile::MethodId\u0026amp; method_id = dex_file.GetMethodId(method_idx); mirror::Class* klass = ResolveType(dex_file, method_id.class_idx_, dex_cache, class_loader);//main  ...... switch (type) { //type是指该函数的调用类型  case kDirect: case kStatic: /*FindDirectMethod是mirror Class的成员函数，有三个同名函数。在此处调用的函数中， 将沿着klass向上（即搜索klass的父类、祖父类等）搜索类所声明的direct方法，然后比较 这些方法的method_idx是否和输入的method_idx一样。如果一样，则认为找到目标函数。注 意，使用这种方法的时候需要注意比较method_idx是否相等时只有在二者保存在同一个DexCache 对象时才有意义。显然，这种一种优化搜索方法。 */ resolved = klass-\u0026gt;FindDirectMethod(dex_cache.Get(), method_idx, image_pointer_size_); break; case kInterface: if (UNLIKELY(!klass-\u0026gt;IsInterface())) { return nullptr; } else { //如果调用方式是kInterface，则搜索klass及祖父类中的virtual方法以及所  //实现的接口类里的成员方法。  resolved = klass-\u0026gt;FindInterfaceMethod(dex_cache.Get(), method_idx, image_pointer_size_); } break; ...... //其他处理  break; default: UNREACHABLE(); } //如果通过method_idx未找到对应的ArtMethod对象，则尝试通过函数名及签名信息再次搜索。  //通过签名信息来查找匹配函数的话就不会受制于同一个DexCache对象的要求，但比较字符串的  //速度会慢于上面所采用的比较整型变量method_idx的处理方式。  if (resolved == nullptr) { //name是指函数名  const char* name = dex_file.StringDataByIdx(method_id.name_idx_); //signature包含了函数的签名信息，就是函数参数及返回值的类型信息  const Signature signature = dex_file.GetMethodSignature(method_id); switch (type) { case kDirect: case kStatic: //调用另外一个FindDirectMethod，主要参数是signature  resolved = klass-\u0026gt;FindDirectMethod(name, signature, image_pointer_size_); break; ...... } } if (LIKELY(resolved != nullptr \u0026amp;\u0026amp; !resolved-\u0026gt;CheckIncompatibleClassChange(type))) { //如果找到这个方法，则将其存到dex_cache对象中，以method_idx为索引，存储在它的resolved_methods_成员中  dex_cache-\u0026gt;SetResolvedMethod(method_idx, resolved, image_pointer_size_); return resolved; } else { ....../*其他处理 */ } } ResolveField ArtField* ClassLinker::ResolveField(const DexFile\u0026amp; dex_file, uint32_t field_idx,Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader,bool is_static) { //如果已经解析过该成员变量，则返回  ArtField* resolved = dex_cache-\u0026gt;GetResolvedField(field_idx, image_pointer_size_); if (resolved != nullptr) { return resolved; } const DexFile::FieldId\u0026amp; field_id = dex_file.GetFieldId(field_idx); Thread* const self = Thread::Current(); StackHandleScope\u0026lt;1\u0026gt; hs(self); //先找到该成员变量对应的Class对象  Handle\u0026lt;mirror::Class\u0026gt; klass( hs.NewHandle(ResolveType(dex_file, field_id.class_idx_, dex_cache, class_loader))); ..... //下面这段代码用于从Class对象ifields_或sfields_中找到对应成员变量的ArtField对象。注  //意，在搜索过程中，会向上遍历Class派生关系树上的基类。  if (is_static) { resolved = mirror::Class::FindStaticField(self, klass,dex_cache.Get(), field_idx); } else { resolved = klass-\u0026gt;FindInstanceField(dex_cache.Get(), field_idx); } ...... //保存到DexCache resolved_fields_成员变量中  dex_cache-\u0026gt;SetResolvedField(field_idx, resolved, image_pointer_size_); return resolved; } ResolveType mirror::Class* ClassLinker::ResolveType(const DexFile\u0026amp; dex_file, uint16_t type_idx,......) { /*dex_cache的类型为mirror::DexCache，这里直接回顾本章上文对DexCache类的介绍。 它包含如下几个关键成员变量： （1）dex_file_(类型为uint64_t)：实际为DexFile*，指向该对象关联的那个Dex文件。 （2）resolved_fields_(uint64_t)：实际为ArtField*，指向ArtField数组，成员的数据类 型为ArtField。该数组存储了一个Dex文件中定义的所有类的成员变量。另外，只有那些经解 析后得到的ArtField对象才会存到这个数组里。该字段和Dex文件里的field_ids数组有关。 （3）resolved_methods_(uint64_t)：实际为ArtMethod*，指向ArtMethod数组，成员的 数据类型为ArtMethod。该数组存储了一个Dex文件中定义的所有类的成员函数。另外，只有 那些经解析后得到的ArtMethod对象才会存到这个数组里。该字段和Dex文件里的 method_ids数组有关。 （4）resolved_string_(uint64_t)：实际为GCRoot\u0026lt;String\u0026gt;*，指向GcRoot\u0026lt;String\u0026gt;数 组，包括该dex文件里使用的字符串信息数组。String是mirror::String。该字段和Dex 文件的string_ids数组有关 （5）resolved_classes_(uint64_t)：实际为GCRoot\u0026lt;Class\u0026gt;*，指向GcRoot\u0026lt;Class\u0026gt;数组，成 员的数据类型为GcRoot\u0026lt;Class\u0026gt;，存储该dex文件里使用的数据类型信息数组。该字段和Dex 文件里的type_ids数组有关 */ //从dex_cache里找到是否已经缓存过type_idx所代表的那个Class信息  mirror::Class* resolved = dex_cache-\u0026gt;GetResolvedType(type_idx); if (resolved == nullptr) { //如果没有缓存过，则需要找到并存起来  Thread* self = Thread::Current(); //找到这个type的字符串描述  const char* descriptor = dex_file.StringByTypeIdx(type_idx); //搜索这个字符串对应的类是否存在。FindClass在第7章中曾简单介绍过，后文还会详细讨论它  resolved = FindClass(self, descriptor, class_loader);//main  if (resolved != nullptr) { //类信息保存到DexCache对象中  dex_cache-\u0026gt;SetResolvedType(type_idx, resolved); } else { ...... //抛NoClassDefFoundError异常  ThrowNoClassDefFoundError(\u0026#34;Failed resolution of: %s\u0026#34;, descriptor); } return resolved; } FindClass mirror::Class* ClassLinker::FindClass(Thread* self, const char* descriptor, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { //如果字符串只有一个字符，则将搜索基础数据类对应的Class对象  if (descriptor[1] == \u0026#39;\\0\u0026#39;) { // only the descriptors of primitive types should be 1 character long, also avoid class lookup  // for primitive classes that aren\u0026#39;t backed by dex files.  return FindPrimitiveClass(descriptor[0]); } //搜索引用类型对应的类对象，首先根据字符串名计算hash值  const size_t hash = ComputeModifiedUtf8Hash(descriptor); // Find the class in the loaded classes table.  //从ClassLoader对应的ClassTable中根据hash值搜索目标类  ObjPtr\u0026lt;mirror::Class\u0026gt; klass = LookupClass(self, descriptor, hash, class_loader.Get()); //如果目标类已经存在，则确保它的状态大于或等于kStatusResoved。  //EnsureResolved并不会调用上文提到的实际加载或链接类的函数，它只是等待其他线程完成这个工作  if (klass != nullptr) { return EnsureResolved(self, descriptor, klass); } // Class is not yet loaded.  if (descriptor[0] != \u0026#39;[\u0026#39; \u0026amp;\u0026amp; class_loader == nullptr) { // Non-array class and the boot class loader, search the boot class path.  /*对bootstrap类而言，它们是由虚拟机加载的，所以没有对应的ClassLoader。 下面的FindInClassPath函数返回的ClassPathEntry是类型别名，其定义如下： typedef pair\u0026lt;const DexFile*,const DexFile::ClassDef*\u0026gt; ClassPathEntry */ //FindInClassPath将从boot class path里对应的文件中找到目标类所在的Dex文件和对应  //的ClassDef信息，然后调用DefineClass来加载目标类  ClassPathEntry pair = FindInClassPath(descriptor, hash, boot_class_path_); if (pair.second != nullptr) { return DefineClass(self, descriptor, hash, ScopedNullHandle\u0026lt;mirror::ClassLoader\u0026gt;(), *pair.first, *pair.second); } } ObjPtr\u0026lt;mirror::Class\u0026gt; result_ptr; bool descriptor_equals; //如果搜索的是数组类，则创建对应的数组类类对象。  if (descriptor[0] == \u0026#39;[\u0026#39;) { result_ptr = CreateArrayClass(self, descriptor, hash, class_loader); } else { //需要触发ClassLoader进行类加载(会调用defineClass启动类加载)。该函数请读者在学完8.7.9节  ScopedObjectAccessUnchecked soa(self); //7.0上对应的方法是FindClassInPathClassLoader  bool known_hierarchy = FindClassInBaseDexClassLoader(soa, self, descriptor, hash, class_loader, \u0026amp;result_ptr); } if(result_ptr == nullptr) { /*如果通过ClassLoader加载目标类失败，则下面的代码将转入Java层去执行ClassLoader的类 加载。根据代码中的注释所言，类加载失败需要抛出异常，而上面的FindClassInPathClass- Loader并不会添加异常信息，相反，它还会去掉其执行过程中其他函数因处理失败（比如Define- Class）而添加的异常信息。所以，接下来的代码将进入Java层去ClassLoader对象的load- Class函数，虽然目标类最终也会加载失败，但相关异常信息就能添加，同时整个调用的堆栈信息 也能正确反映出来。所以，这种处理方式应是ART虚拟机里为提升运行速度所做的优化处理吧 */ result.reset(soa.Env()-\u0026gt;CallObjectMethod(class_loader_object.get(), WellKnownClasses::java_lang_ClassLoader_loadClass, class_name_object.get())); } ...... // success, return mirror::Class*  return result_ptr.Ptr(); } LookupClass mirror::Class* ClassLinker::LookupClass(Thread* self, const char* descriptor, size_t hash, ObjPtr\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { ReaderMutexLock mu(self, *Locks::classlinker_classes_lock_); ClassTable* const class_table = ClassTableForClassLoader(class_loader); if (class_table != nullptr) { ObjPtr\u0026lt;mirror::Class\u0026gt; result = class_table-\u0026gt;Lookup(descriptor, hash); if (result != nullptr) { return result.Ptr(); } } return nullptr; } ClassTableForClassLoader ClassTable* ClassLinker::ClassTableForClassLoader(ObjPtr\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { return class_loader == nullptr ? boot_class_table_.get() : class_loader-\u0026gt;GetClassTable(); } art/runtime/class_table.cc\nClassTable::Lookup mirror::Class* ClassTable::Lookup(const char* descriptor, size_t hash) { DescriptorHashPair pair(descriptor, hash); ReaderMutexLock mu(Thread::Current(), lock_); for (ClassSet\u0026amp; class_set : classes_) { auto it = class_set.FindWithHash(pair, hash); if (it != class_set.end()) { return it-\u0026gt;Read(); } } return nullptr; } FindClassInBaseDexClassLoader_C层双亲委派 bool ClassLinker::FindClassInBaseDexClassLoader(ScopedObjectAccessAlreadyRunnable\u0026amp; soa, Thread* self, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, ObjPtr\u0026lt;mirror::Class\u0026gt;* result) { // Termination case: boot class loader.  if (IsBootClassLoader(soa, class_loader.Get())) { *result = FindClassInBootClassLoaderClassPath(self, descriptor, hash); return true; } if (IsPathOrDexClassLoader(soa, class_loader)) { // For regular path or dex class loader the search order is:  // - parent  // - class loader dex files  // Handles as RegisterDexFile may allocate dex caches (and cause thread suspension).  StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::ClassLoader\u0026gt; h_parent(hs.NewHandle(class_loader-\u0026gt;GetParent())); if (!FindClassInBaseDexClassLoader(soa, self, descriptor, hash, h_parent, result)) { return false; // One of the parents is not supported.  } if (*result != nullptr) { return true; // Found the class up the chain.  } // Search the current class loader classpath.  *result = FindClassInBaseDexClassLoaderClassPath(soa, descriptor, hash, class_loader); return true; } FindClassInBaseDexClassLoaderClassPath ObjPtr\u0026lt;mirror::Class\u0026gt; ClassLinker::FindClassInBaseDexClassLoaderClassPath( ScopedObjectAccessAlreadyRunnable\u0026amp; soa, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { ObjPtr\u0026lt;mirror::Class\u0026gt; ret; auto define_class = [\u0026amp;](const DexFile* cp_dex_file) REQUIRES_SHARED(Locks::mutator_lock_) { const DexFile::ClassDef* dex_class_def = OatDexFile::FindClassDef(*cp_dex_file, descriptor, hash); if (dex_class_def != nullptr) { //main  ObjPtr\u0026lt;mirror::Class\u0026gt; klass = DefineClass(soa.Self(), descriptor, hash, class_loader, *cp_dex_file, *dex_class_def); if (klass == nullptr) { CHECK(soa.Self()-\u0026gt;IsExceptionPending()) \u0026lt;\u0026lt; descriptor; soa.Self()-\u0026gt;ClearException(); // TODO: Is it really right to break here, and not check the other dex files?  } ret = klass; return false; // Found a Class (or error == nullptr), stop visit.  } return true; // Continue with the next DexFile.  }; VisitClassLoaderDexFiles(soa, class_loader, define_class); return ret; } DefineClassSummary 类的加载、链接和初始化\nClassLinker::DefineClass内部会调用SetupClass和LoadClass\n在ART虚拟机实现中，类的加载、链接及初始化过程可以很容易地从代表类状态Status枚举变量的定义里推导出来的。整个过程可分为\n  Load（对应终态为kStatusLoaded）\n  Resolve（对应终态为kStatusResolved）\n  Verify（对应终态为kStatusVerified）\n  Initialized（对应终态为kStatusInitialized）四个步骤。\n  art/runtime/class_linker.cc\nmirror::Class* ClassLinker::DefineClass(Thread* self, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def) { mirror::DexCache* dex_cache = RegisterDexFile(dex_file, class_loader.Get()); klass-\u0026gt;SetDexCache(dex_cache); SetupClass(dex_file, dex_class_def, klass, class_loader.Get());//main  // Add the newly loaded class to the loaded classes table.  mirror::Class* existing = InsertClass(descriptor, klass.Get(), hash); // Load the fields and other things after we are inserted in the table. This is so that we don\u0026#39;t  // end up allocating unfree-able linear alloc resources and then lose the race condition. The  // other reason is that the field roots are only visited from the class table. So we need to be  // inserted before we allocate / fill in these fields.  LoadClass(self, dex_file, dex_class_def, klass);//load, main  LoadSuperAndInterfaces(klass, dex_file)//main  LinkClass(self, descriptor, klass, interfaces, \u0026amp;h_new_class) //reslove,main ...... return h_new_class.Get(); Load SetupClass void ClassLinker::SetupClass(const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def, Handle\u0026lt;mirror::Class\u0026gt; klass, mirror::ClassLoader* class_loader) { const char* descriptor = dex_file.GetClassDescriptor(dex_class_def); //SetClass是Class的基类mirror Object中的函数。Class也是一种Object，所以此处设置它的  //类类型为”java/lang/Class”对应的那个Class对象  klass-\u0026gt;SetClass(GetClassRoot(kJavaLangClass)); uint32_t access_flags = dex_class_def.GetJavaAccessFlags(); //设置访问标志及该类的加载器对象  klass-\u0026gt;SetAccessFlags(access_flags); klass-\u0026gt;SetClassLoader(class_loader); //设置klass的状态为kStatusIdx。  mirror::Class::SetStatus(klass, mirror::Class::kStatusIdx, nullptr); //设置klass的dex_class_def_idx_和dex_type_idx_成员变量。  klass-\u0026gt;SetDexClassDefIndex(dex_file.GetIndexForClassDef(dex_class_def)); klass-\u0026gt;SetDexTypeIndex(dex_class_def.class_idx_); } LoadClass void ClassLinker::LoadClass(Thread* self, const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def, Handle\u0026lt;mirror::Class\u0026gt; klass) { //class_data的内容就是图8-7中的class_data_item  const uint8_t* class_data = dex_file.GetClassData(dex_class_def); if (class_data == nullptr) { return; } bool has_oat_class = false; if (Runtime::Current()-\u0026gt;IsStarted() \u0026amp;\u0026amp; !Runtime::Current()-\u0026gt;IsAotCompiler()) { //如果不是编译虚拟机的话，则先尝试找到该类经dex2oat编译得到的OatClass信息  OatFile::OatClass oat_class = FindOatClass(dex_file, klass-\u0026gt;GetDexClassDefIndex(), \u0026amp;has_oat_class); if (has_oat_class) { LoadClassMembers(self, dex_file, class_data, klass, \u0026amp;oat_class); } } //不管有没有OatClass信息，最终调用的函数都是LoadClassMembers。  if (!has_oat_class) { LoadClassMembers(self, dex_file, class_data, klass, nullptr); } } void ClassLinker::LoadClassMembers(Thread* self, const DexFile\u0026amp; dex_file,const uint8_t* class_data, Handle\u0026lt;mirror::Class\u0026gt; klass,const OatFile::OatClass* oat_class) { //注意这个函数的参数，class_data为dex文件里的代表该类的class_data_item信息，  //而oat_class描述的是Oat文件里针对这个类提供的一些信息  { LinearAlloc* const allocator = GetAllocatorForClassLoader(klass-\u0026gt;GetClassLoader()); //创建class_data_item迭代器  ClassDataItemIterator it(dex_file, class_data); //分配用于存储目标类静态成员变量的固定长度数组sfields  LengthPrefixedArray\u0026lt;ArtField\u0026gt;* sfields = AllocArtFieldArray( self,allocator,it.NumStaticFields()); size_t num_sfields = 0; uint32_t last_field_idx = 0u; //遍历class_data_item中的静态成员变量数组，然后填充信息到sfields数组里  for (; it.HasNextStaticField(); it.Next()) { uint32_t field_idx = it.GetMemberIndex(); if (num_sfields == 0 || LIKELY(field_idx \u0026gt; last_field_idx)) { //加载这个ArtField的内容。下文将单独介绍此函数  LoadField(it, klass, \u0026amp;sfields-\u0026gt;At(num_sfields)); ++num_sfields; last_field_idx = field_idx; } } // 同理，分配代表该类非静态成员变量的数组  LengthPrefixedArray\u0026lt;ArtField\u0026gt;* ifields = AllocArtFieldArray(self, allocator, it.NumInstanceFields()); size_t num_ifields = 0u; last_field_idx = 0u; for (; it.HasNextInstanceField(); it.Next()) { uint32_t field_idx = it.GetMemberIndex(); if (num_ifields == 0 || LIKELY(field_idx \u0026gt; last_field_idx)) { LoadField(it, klass, \u0026amp;ifields-\u0026gt;At(num_ifields)); //类似的处理  ++num_ifields; last_field_idx = field_idx; } } //设置Class类的sfields_和ifields_成员变量  klass-\u0026gt;SetSFieldsPtr(sfields); klass-\u0026gt;SetIFieldsPtr(ifields); /*设置Class类的methods_成员变量。读者可回顾笔者对该成员变量的解释，它是一个Length- PrefixedArray\u0026lt;ArtMethod\u0026gt;数组，其元素布局为 （1）[0,virtual_methods_offset_)为本类包含的direct成员函数 （2）[virtual_methods_offset_,copied_methods_offset_)为本类包含的virtual 成员函数 （3）[copied_methods_offset_,...)为剩下的诸如miranda函数等内容。下面代码中， 先分配1和2所需要的元素空间，然后设置klass对应的成员变量，其中： klass-\u0026gt;methods_为AllocArtMethodArray的返回值， klass-\u0026gt;copied_methods_offset_为类direct和virtual方法个数之和 klass-\u0026gt;virtual_methods_offset_为类direct方法个数 */ klass-\u0026gt;SetMethodsPtr( AllocArtMethodArray(self, allocator, it.NumDirectMethods() +it.NumVirtualMethods()), it.NumDirectMethods(), it.NumVirtualMethods()); size_t class_def_method_index = 0; uint32_t last_dex_method_index = DexFile::kDexNoIndex; size_t last_class_def_method_index = 0; //遍历direct方法数组，加载它们然后关联字节码  for (size_t i = 0; it.HasNextDirectMethod(); i++, it.Next()) { ArtMethod* method = klass-\u0026gt;GetDirectMethodUnchecked(i, image_pointer_size_); //加载ArtMethod对象，并将其和字节码关联起来。  LoadMethod(self, dex_file, it, klass, method); //注意，oat_class信息只在LinkCode中用到。LinkCode留待10.1节介绍  LinkCode(method, oat_class, class_def_method_index); uint32_t it_method_index = it.GetMemberIndex(); if (last_dex_method_index == it_method_index) { method-\u0026gt;SetMethodIndex(last_class_def_method_index); } else { //设置ArtMethod的method_index_，该值其实就是这个ArtMethod  //位于上面klass methods_数组中的位置  method-\u0026gt;SetMethodIndex(class_def_method_index); last_dex_method_index = it_method_index; last_class_def_method_index = class_def_method_index; } class_def_method_index++; } //处理virtual方法。注意，对表示virtual方法的ArtMethod对象而言，它们的method_index_  //和klass methods_数组没有关系，也不在下面的循环中设置。  for (size_t i = 0; it.HasNextVirtualMethod(); i++, it.Next()) { ...... //和direct方法处理一样，唯一不同的是，此处不调用ArtMethod的SetMethod-Index函数，即不设置它的method_index_成员  } } } LoadField void ClassLinker::LoadField(const ClassDataItemIterator\u0026amp; it, Handle\u0026lt;mirror::Class\u0026gt; klass, ArtField* dst) { const uint32_t field_idx = it.GetMemberIndex(); dst-\u0026gt;SetDexFieldIndex(field_idx); //设置对应于dex文件里的那个field_idx  dst-\u0026gt;SetDeclaringClass(klass.Get()); //设置本成员变量由哪个Class对象定义  dst-\u0026gt;SetAccessFlags(it.GetFieldAccessFlags()); //设置访问标记 } LoadMethod void ClassLinker::LoadMethod(Thread* self, const DexFile\u0026amp; dex_file,const ClassDataItemIterator\u0026amp; it, Handle\u0026lt;mirror::Class\u0026gt; klass, ArtMethod* dst) { uint32_t dex_method_idx = it.GetMemberIndex(); const DexFile::MethodId\u0026amp; method_id = dex_file.GetMethodId(dex_method_idx); const char* method_name = dex_file.StringDataByIdx(method_id.name_idx_); //设置ArtMethod declaring_class_和dex_method_index_和成员变量  dst-\u0026gt;SetDexMethodIndex(dex_method_idx); dst-\u0026gt;SetDeclaringClass(klass.Get()); //设置dex_code_item_offset_成员变量  dst-\u0026gt;SetCodeItemOffset(it.GetMethodCodeItemOffset()); //设置ArtMethod ptr_sized_fields_结构体中的dex_cache_resolved_methods_和dex_cache_  //resolved_types_成员。读者可回顾上文对ArtMethod成员变量的介绍  dst-\u0026gt;SetDexCacheResolvedMethods(klass-\u0026gt;GetDexCache()-\u0026gt;GetResolvedMethods(), image_pointer_size_); dst-\u0026gt;SetDexCacheResolvedTypes(klass-\u0026gt;GetDexCache()-\u0026gt;GetResolvedTypes(), image_pointer_size_); uint32_t access_flags = it.GetMethodAccessFlags(); //处理访问标志。比如，如果函数名为”finalize”的话，设置该类为finalizable  if (UNLIKELY(strcmp(\u0026#34;finalize\u0026#34;, method_name) == 0)) { if (strcmp(\u0026#34;V\u0026#34;, dex_file.GetShorty(method_id.proto_idx_)) == 0) { //该类的class loader如果不为空，则表示不是boot class，也就是系统所必需的那些  //基础类  if (klass-\u0026gt;GetClassLoader() != nullptr){ //设置类的访问标记，增加kAccClassIsFinalizable。表示该类重载了finalize函数  klass-\u0026gt;SetFinalizable(); } else {...... } } } else if (method_name[0] == \u0026#39;\u0026lt;\u0026#39;) { ......//如果函数名为”\u0026lt;init\u0026gt;”或”\u0026lt;clinit\u0026gt;”，则设置访问标志位kAccConstructor  } dst-\u0026gt;SetAccessFlags(access_flags); } LinkCode void ClassLinker::LinkCode(ArtMethod* method, const OatFile::OatClass* oat_class, int32_t class_def_method_index) { Runtime* const runtime = Runtime::Current(); if (runtime-\u0026gt;IsAotCompiler()) { // The following code only applies to a non-compiler runtime.  return; } // Method shouldn\u0026#39;t have already been linked.  DCHECK(method-\u0026gt;GetEntryPointFromQuickCompiledCode() == nullptr); /*在下面的代码中： （1）oat_class的类型为OatFile::OatClass，其内容由oat文件中OatClass区域相应位置处的信息构成。 （2）oat_method的类型为OatFile::OatMethod，其内容由oat文件中OatMethod区域对应的OatQuickMethodHeader信息构成。*/ // Every kind of method should at least get an invoke stub from the oat_method.  // non-abstract methods also get their code pointers.  if (oat_class != nullptr) { /*获取该Java方法对应的OatMethod信息。如果它没有被编译过，则返回的OatMethod对象的code_ offset_取值为0。OatMethod.code_offset_指向对应机器码在oat文件中的位置。其值为0 就表示该方法不存在机器码。 */ const OatFile::OatMethod oat_method = oat_class-\u0026gt;GetOatMethod(class_def_method_index); /*设置ArtMethod ptr_sized_fields_entry_point_from_quick_compiled_code_为 Oat文件区域OatQuickMethodHeader的code_。读者可回顾第9章图9-41“oat和art文件 的关系”。code_处存储的就是该方法编译得到的机器码。注意，为节省篇幅，笔者以后用机器 码入口地址来指代entry_point_from_quick_compiled_code_成员变量。*/ oat_method.LinkMethod(method); } // Install entry point from interpreter.  const void* quick_code = method-\u0026gt;GetEntryPointFromQuickCompiledCode();//获取ArtMethod对象的机器码入口地址  /*在ShouldUseInterpreterEntrypoint函数中，如果机器码入口地址为空（该方法没有经过编译）， 或者虚拟机进入了调试状态，则必须使用解释执行的模式。这种情况下，该函数返回值enter_inter- preter为true。 */ bool enter_interpreter = ShouldUseInterpreterEntrypoint(method, quick_code); if (method-\u0026gt;IsStatic() \u0026amp;\u0026amp; !method-\u0026gt;IsConstructor()) { // For static methods excluding the class initializer, install the trampoline.  // It will be replaced by the proper entry point by ClassLinker::FixupStaticTrampolines  // after initializing class (see ClassLinker::InitializeClass method).  /*如果method为静态且不是类初始化\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;（它是类的静态构造方法）方法，则设置机器码入口 地址为art_quick_resolution_trampoline。根据9.5.4.4.1节的介绍可知。该地址对应的是 一段跳转代码，跳转的目标是artQuickResolutionTrampoline函数。它是一个特殊的函数，和 类的解析有关。注意，虽然在LinkCode中（该函数是在类初始化之前被调用的）设置的跳转目标为 artQuickResolutionTrampoline，但ClassLinker在初始化类的InitializeClass函数的最 后会通过调用FixupStaticTrampolines来尝试更新此处所设置的跳转地址为正确的地址, 更新机器码入口地址entry_point_from_quick_compiled_code_*/ method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickResolutionStub()); } else if (quick_code == nullptr \u0026amp;\u0026amp; method-\u0026gt;IsNative()) { /*如果method为jni方法，并且不存在机器码，则设置机器码入口地址为跳转代码art_quick_ generic_jni_trampoline，它的跳转目标为artQuickGenericJniTrampoline函数。*/ method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickGenericJniStub()); } else if (enter_interpreter) { // Set entry point from compiled code if there\u0026#39;s no code or in interpreter only mode.  /*enter_interpreter的取值来自ShouldUseInterpreterEntrypoint，一般而言，如果该 方法没有对应的机器码，或者在调试运行模式下，则enter_interpreter为true。对应的机 器码入口地址为art_quick_to_interpreter_bridge跳转代码，其跳转的目标 //为artQuickToInterpreterBridge函数。*/ method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickToInterpreterBridge()); } if (method-\u0026gt;IsNative()) { // Unregistering restores the dlsym lookup stub.  /*如果为jni方法，则调用ArtMethod的UnregisterNative函数，其内部主要设置ArtMethod tls_ptr_sized_.entry_point_from_jni_成员变量为跳转代码art_jni_dlsym_look- up_stub，跳转目标为artFindNativeMethod函数。为简单起见，笔者以后用jni机器码入口 地址指代entry_point_from_jni_成员变量。这部分内容和JNI有关，我们以后再讨论它。*/ method-\u0026gt;UnregisterNative(); if (enter_interpreter || quick_code == nullptr) { // We have a native method here without code. Then it should have either the generic JNI  // trampoline as entrypoint (non-static), or the resolution trampoline (static).  // TODO: this doesn\u0026#39;t handle all the cases where trampolines may be installed.  const void* entry_point = method-\u0026gt;GetEntryPointFromQuickCompiledCode(); DCHECK(IsQuickGenericJniStub(entry_point) || IsQuickResolutionStub(entry_point)); } } } art/runtime/oat_file.cc\nOatMethod::LinkMethod void OatFile::OatMethod::LinkMethod(ArtMethod* method) const { CHECK(method != nullptr); method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickCode()); } LoadSuperAndInterfaces bool ClassLinker::LoadSuperAndInterfaces(Handle\u0026lt;mirror::Class\u0026gt; klass, const DexFile\u0026amp; dex_file) { const DexFile::ClassDef\u0026amp; class_def = dex_file.GetClassDef(klass-\u0026gt;GetDexClassDefIndex()); //找到基类的id  uint16_t super_class_idx = class_def.superclass_idx_; //根据基类的id来解析它，返回值是代表基类的Class实例。  //ResolveType函数的内容将在8.7.8节中介绍  mirror::Class* super_class = ResolveType(dex_file, super_class_idx, klass.Get()); if (super_class == nullptr) { return false; } //做一些简单校验。比如，基类如果不允许派生，则返回失败  if (!klass-\u0026gt;CanAccess(super_class)) { return false; } klass-\u0026gt;SetSuperClass(super_class); //设置super_class_成员变量的值  //下面这个检查和编译有关系，笔者不拟讨论它，代码中的注释非常详细  if (!CheckSuperClassChange(klass, dex_file, class_def, super_class)) { return false; } //从dex文件里找到目标类实现了哪些接口类。参考图8-7所示class_def结构体中  //interfaces_off的含义  const DexFile::TypeList* interfaces = dex_file.GetInterfacesList(class_def); if (interfaces != nullptr) { for (size_t i = 0; i \u0026lt; interfaces-\u0026gt;Size(); i++) { uint16_t idx = interfaces-\u0026gt;GetTypeItem(i).type_idx_; //解析这个接口类。下文将介绍ResolveType函数  mirror::Class* interface = ResolveType(dex_file, idx, klass.Get()); ...... //如果接口类找不到或者接口类不允许继承，则返回错误  } } //设置klass的状态为kStatusLoaded  mirror::Class::SetStatus(klass, mirror::Class::kStatusLoaded, nullptr); return true; } Resolve/Link LinkClass相关函数\n进入LinkClass之前，先回顾上文SetupClass和LoadClass的结果。此时：\n·目标类的信息从dex文件里对应的class_def结构体及其他相关结构体已经提取并转换为一个mirror Class对象。\n·同时，该Class对象中代表本类的成员变量和成员函数信息也相应创建为对应的ArtField和ArtMethod的对象，并做好了相关设置。从Class类成员来说，它的methods_、sfields_、ifields_都设置好了。\nLinkClass bool ClassLinker::LinkClass(Thread* self,const char* descriptor, Handle\u0026lt;mirror::Class\u0026gt; klass, //待link的目标class  Handle\u0026lt;mirror::ObjectArray\u0026lt;mirror::Class\u0026gt;\u0026gt; interfaces, MutableHandle\u0026lt;mirror::Class\u0026gt;* h_new_class_out) { /*注意本函数的参数： （1）klass代表输入的目标类，其状态是kStatusLoaded。 （2）h_new_class_out为输出参数，代表LinkClass执行成功后所返回给调用者的、类状态切升级为 kStatusResolved的目标类。所以，这个变量才是LinkClass执行成功后的结果。*/ //Link基类  if (!LinkSuperClass(klass)) { return false; }//main  /*下面将创建一个ArtMethod*数组。数组大小为kImtSize。它是一个编译时常量，由编译参数ART_ IMT_SIZE指定，默认是64。IMT是Interface Method Table的缩写。如其名所示，它和接口所 实现的函数有关。其作用我们后文再介绍 */ ArtMethod* imt[mirror::Class::kImtSize]; std::fill_n(imt, arraysize(imt), //填充这个数组的内容为默认值  Runtime::Current()-\u0026gt;GetImtUnimplementedMethod()); //对该类所包含的方法（包括它实现的接口方法、继承自父类的方法等）进行处理  if (!LinkMethods(self, klass, interfaces, imt)) { return false;}//main  //下面两个函数分别对类的成员进行处理。  if (!LinkInstanceFields(self, klass)) { return false;}//main  size_t class_size; //尤其注意LinkStaticFields函数，它的返回值包括class_size，代表该类所需内存大小。  if (!LinkStaticFields(self, klass, \u0026amp;class_size)) { return false; }//main  //处理Class的reference_instance_offsets_成员变量  CreateReferenceInstanceOffsets(klass);//main  //当目标类是基础数据类、抽象类（不包括数组）、接口类时，下面的if条件满足  if (!klass-\u0026gt;IsTemp() || .....)) { ..... //对于非Temp的类，不需要额外的操作，所以klass的状态被置为kStatusResolved，然后再赋  //值给h_new_class_out。到此，目标类就算解析完了  mirror::Class::SetStatus(klass, mirror::Class::kStatusResolved, self); h_new_class_out-\u0026gt;Assign(klass.Get()); } else {//如果目标类是可实例化的，则需要做额外的处理  StackHandleScope\u0026lt;1\u0026gt; hs(self); //CopyOf很关键，它先创建一个大小为class_size的Class对象，然后，klass的信息将拷贝  //到这个新创建的Class对象中。在这个处理过程汇总，Class对象的类状态将被设置为kStatus-  //Resolving。  auto h_new_class = hs.NewHandle(klass-\u0026gt;CopyOf(self, class_size, imt, image_pointer_size_)); klass-\u0026gt;SetMethodsPtrUnchecked(nullptr, 0, 0); //清理klass的内容  ...... //清理klass的其他内容;  { ...... //更新ClassTable中对应的信息  mirror::Class* existing = table-\u0026gt;UpdateClass(descriptor, h_new_class.Get(), ComputeModifiedUtf8Hash(descriptor)); ...... } //设置klass的状态为kStatusRetired，表示该类已经被废弃  mirror::Class::SetStatus(klass, mirror::Class::kStatusRetired, self); //设置新类的状态为kStatusResolved，表示该类解析完毕。  mirror::Class::SetStatus( h_new_class, mirror::Class::kStatusResolved,self); h_new_class_out-\u0026gt;Assign(h_new_class.Get()); //赋值给输出参数  } return true; } LinkMethods bool ClassLinker::LinkMethods(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, Handle\u0026lt;mirror::ObjectArray\u0026lt;mirror::Class\u0026gt;\u0026gt; interfaces, ArtMethod** out_imt) { ...... std::unordered_map\u0026lt;size_t, ClassLinker::MethodTranslation\u0026gt; default_translations; //下面三个函数很复杂  return SetupInterfaceLookupTable(self, klass, interfaces) \u0026amp;\u0026amp; LinkVirtualMethods(self, klass, \u0026amp;default_translations) \u0026amp;\u0026amp; LinkInterfaceMethods(self, klass, default_translations, out_imt); } LinkInstanceFields bool ClassLinker::LinkInstanceFields(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass) { CHECK(klass.Get() != nullptr); return LinkFields(self, klass, false, nullptr); } LinkStaticFields bool ClassLinker::LinkStaticFields(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, size_t* class_size) { CHECK(klass.Get() != nullptr); return LinkFields(self, klass, true, class_size); } LinkFields bool ClassLinker::LinkFields(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, bool is_static, size_t* class_size) { //确定成员变量的个数  const size_t num_fields = is_static ? klass-\u0026gt;NumStaticFields() : klass-\u0026gt;NumInstanceFields(); //从Class中得到代表静态或非静态成员变量的数组  LengthPrefixedArray\u0026lt;ArtField\u0026gt;* const fields = is_static ? klass-\u0026gt;GetSFieldsPtr() : klass-\u0026gt;GetIFieldsPtr(); MemberOffset field_offset(0); if (is_static) { //如果是静态变量，则得到静态存储空间的起始位置。  field_offset = klass-\u0026gt;GetFirstReferenceStaticFieldOffsetDuringLinking( image_pointer_size_); } else { //获取基类的ObjectSize  mirror::Class* super_class = klass-\u0026gt;GetSuperClass(); if (super_class != nullptr) { field_offset = MemberOffset(super_class-\u0026gt;GetObjectSize()); } } //排序，引用类型放最前面，然后是long/double、int/float等。符合图8-13中的布局要求  std::deque\u0026lt;ArtField*\u0026gt; grouped_and_sorted_fields; for (size_t i = 0; i \u0026lt; num_fields; i++) { grouped_and_sorted_fields.push_back(\u0026amp;fields-\u0026gt;At(i)); } std::sort(grouped_and_sorted_fields.begin(), grouped_and_sorted_fields.end(),LinkFieldsComparator()); size_t current_field = 0; size_t num_reference_fields = 0; FieldGaps gaps; //先处理引用类型的变量  for (; current_field \u0026lt; num_fields; current_field++) { ArtField* field = grouped_and_sorted_fields.front(); Primitive::Type type = field-\u0026gt;GetTypeAsPrimitiveType(); bool isPrimitive = type != Primitive::kPrimNot; if (isPrimitive) { break; } ...... grouped_and_sorted_fields.pop_front(); num_reference_fields++; field-\u0026gt;SetOffset(field_offset); //设置ArtField的offset_变量  field_offset = MemberOffset(field_offset.Uint32Value() + sizeof(mirror::HeapReference\u0026lt;mirror::Object\u0026gt;)); } //我们在ComputeClassSize中曾提到说内存布局可以优化，下面的ShuffleForward就是处理这种优  //化。ShuffleForward是一个模板函数，内部会设置ArtField的offset_。  ShuffleForward\u0026lt;8\u0026gt;(\u0026amp;current_field, \u0026amp;field_offset, \u0026amp;grouped_and_sorted_fields, \u0026amp;gaps); ...... //处理4字节、2字节基础数据类型变量  ShuffleForward\u0026lt;1\u0026gt;(\u0026amp;current_field, \u0026amp;field_offset, \u0026amp;grouped_and_sorted_fields, \u0026amp;gaps); ...... //特殊处理java.lang.ref.Reference类。将它的非静态引用类型变量的个数减去一个。减去的这个  //变量是java Reference类中的referent成员，它和GC有关，需要特殊对待。后续章节会详细介绍GC。  if (!is_static \u0026amp;\u0026amp; klass-\u0026gt;DescriptorEquals(\u0026#34;Ljava/lang/ref/Reference;\u0026#34;)) { --num_reference_fields; } size_t size = field_offset.Uint32Value(); if (is_static) { klass-\u0026gt;SetNumReferenceStaticFields(num_reference_fields); *class_size = size; //设置Class最终所需内存大小  } else { klass-\u0026gt;SetNumReferenceInstanceFields(num_reference_fields); ...... //如果类的对象是固定大小（像数组、String则属于非固定大小），则设置Object所需内存大小  if (!klass-\u0026gt;IsVariableSize()) { ...... klass-\u0026gt;SetObjectSize(size); } } return true; } Verify graph TB dex2oat时verify_预校验--\u0026gt;软错误时kStatusRetryVerificationAtRuntime dex2oat时verify_预校验--\u0026gt;成功kStatusVerified 虚拟机运行时检查--\u0026gt;成功kStatusVerified 成功kStatusVerified--\u0026gt;该类methods_数组所有ArtMethod对象设置kAccSkipAccessChecks标志 成功kStatusVerified--\u0026gt;为类设置kAccVerification-Attempted标记 虚拟机运行时检查--\u0026gt;软错误时kStatusRetryVerificationAtRuntime 软错误时kStatusRetryVerificationAtRuntime--\u0026gt;MethodVerifier对该类进行校验 MethodVerifier对该类进行校验--\u0026gt;依旧软错误 依旧软错误--\u0026gt;为类设置kAccVerification-Attempted标记 VerifyClass void ClassLinker::VerifyClass(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, LogSeverity log_level) { ...... //可能有另外一个线程正在处理类的校验，此处省略的代码将处理这种情况判断该类是否  //已经通过校验（类状态大于或等于kStatusVerified）  if (klass-\u0026gt;IsVerified()) { /* Verify一个类是需要代价的（比如执行上两节代码所示MethodVerifier的相关函数是 需要花费时间），但付出这个代价会带来一定好处。在ART虚拟机中，如果某个类校验通 过的话，后续执行该类的方法时将跳过所谓的访问检查（Access Check）。Access Check 的具体内容将在后续章节介绍。此处举一个简单例子，比如访问检查将判断外部调用者是 否调用了某个类的私有函数。显然，Access Check将影响函数执行的时间。 下面的这个EnsureSkipAccessChecksMethods将做两件事情： （1）为klass methods_数组里的ArtMethod对象设置kAccSkipAccessChecks标志位 （2）为klass设置kAccVerificationAttempted标志位。这个标记位表示该类已经尝试过 校验了，无须再次校验。 这些标志位的作用我们以后碰见具体代码时再讲解。 */ EnsureSkipAccessChecksMethods(klass); return; } //如果类状态大于等于kStatusRetryVerificationAtRuntime并且当前进程是dex2oat(Is-  //AotCompiler用于判断当前进程是否为编译进程)，则直接返回。类的校验将留待真实的虚拟机  //进程来完成。  if (klass-\u0026gt;IsCompileTimeVerified() \u0026amp;\u0026amp; Runtime::Current()-\u0026gt;IsAotCompiler()) { return; } if (klass-\u0026gt;GetStatus() == mirror::Class::kStatusResolved) { //设置类状态为kStatusVerifying，表明klass正处于类校验阶段。  mirror::Class::SetStatus(klass, mirror::Class::kStatusVerifying, self); } else { //如果类的当前状态不是kStatusResolved，则表明该类在dex2oat时已经做过校  //验，但校验结果是kStatusRetryVerificationAtRuntime。所以此处需要在完  //整虚拟机环境下再做校验。  mirror::Class::SetStatus(klass, mirror::Class::SetStatus(klass, mirror::Class::kStatusVerifyingAtRuntime, self); } /*IsVerificationEnabled用于返回虚拟机是否开启了类校验的功能，它和verify_mode.h中定义 的枚举变量VerifyMode有关。该枚举变量有三种取值： （1）kNone：不做校验。 （2）kEnable：标准校验流程。其中，在dex2oat过程中会尝试做预校验（preverifying）。 （3）kSoftFail：强制为软校验失败。这种情况下，指令码在解释执行的时候会进行access check。这部分内容在dex2oat一章中有所体现，以后我们会提到。 从上述内容可知，在ART里，类校验的相关知识绝不仅仅只包含JLS规范中提到的那些诸如检查 字节码是否合法之类的部分，它还和dex2oat编译与Java方法如何执行等内容密切相关。*/ if (!Runtime::Current()-\u0026gt;IsVerificationEnabled()) { mirror::Class::SetStatus(klass, mirror::Class::kStatusVerified, self); EnsureSkipAccessChecksMethods(klass); return; } //先校验父类。AttemptSuperTypeVerification内部也会调用VerifyClass。  ...... //请读者自行阅读它  MutableHandle\u0026lt;mirror::Class\u0026gt; supertype(hs.NewHandle( klass-\u0026gt;GetSuperClass())); if (supertype.Get() != nullptr \u0026amp;\u0026amp; !AttemptSupertypeVerification(self, klass, supertype)) { return; } //如果父类校验通过，并且klass不是接口类的话，我们还要对klass所实现的接口类进行校验。校验  //接口类是从Java 1.8开始，接口类支持定义有默认实现的接口函数，默认函数包含实际的内容，所以  //需要校验。  if ((supertype.Get() == nullptr || supertype-\u0026gt;IsVerified()) \u0026amp;\u0026amp; !klass-\u0026gt;IsInterface()) { int32_t iftable_count = klass-\u0026gt;GetIfTableCount(); MutableHandle\u0026lt;mirror::Class\u0026gt; iface(hs.NewHandle\u0026lt;mirror::Class\u0026gt;(nullptr)); //遍历IfTable，获取其中的接口类。  for (int32_t i = 0; i \u0026lt; iftable_count; i++) { iface.Assign(klass-\u0026gt;GetIfTable()-\u0026gt;GetInterface(i)); //接口类没有默认接口函数，或者已经校验通过，则略过  if (LIKELY(!iface-\u0026gt;HasDefaultMethods() || iface-\u0026gt;IsVerified())) { continue; } else if (UNLIKELY(!AttemptSupertypeVerification(self, klass, iface))) { return; //接口类校验失败。直接返回  } else if (UNLIKELY(!iface-\u0026gt;IsVerified())) { //如果接口类校验后得到的状态为kStatusVerifyingAtRuntime，则跳出循环  supertype.Assign(iface.Get()); break; } } const DexFile\u0026amp; dex_file = *klass-\u0026gt;GetDexCache()-\u0026gt;GetDexFile(); mirror::Class::Status oat_file_class_status( mirror::Class::kStatusNotReady); /*下面这个函数其实只是用来判断klass是否已经在dex2oat阶段做过预校验了。这需要结合该类编译 结果来决定（包含在OatFile中的类状态）。除此之外，如果我们正在编译系统镜像时（即在dex2oat 进程中编译包含在Boot Image的类），则该函数也返回false。preverified如果为false，则将 调用MethodVerifier VerifyClass来做具体的校验工作。VerifyClassUsingOatFile还包含其 他几种返回false的情况，请读者自行阅读。*/ bool preverified = VerifyClassUsingOatFile(dex_file, klass.Get(), oat_file_class_status); verifier::MethodVerifier::FailureKind verifier_failure = verifier::MethodVerifier::kNoFailure; if (!preverified) { //没有预校验的处理  Runtime* runtime = Runtime::Current(); //调用MethodVerifier VerifyClass来完成具体的校验工作,main  verifier_failure = verifier::MethodVerifier::VerifyClass(self, klass.Get(), runtime-\u0026gt;GetCompilerCallbacks(),,...); } ...... if (preverified || verifier_failure != verifier::MethodVerifier::kHardFailure) { ...... if (verifier_failure == verifier::MethodVerifier::kNoFailure) { //自己和基类（或者接口类）的校验结果都正常，则类状态设置为kStatusVerified  if (supertype.Get() == nullptr || supertype-\u0026gt;IsVerified()) { mirror::Class::SetStatus(klass, mirror::Class::kStatusVerified, self); } else {......} } else { //对应校验结果为kSoftFail的情况  if (Runtime::Current()-\u0026gt;IsAotCompiler()) { //如果是dex2oat中出现这种情况，则设置类的状态为kStatusRetryVerificationAtRuntime  mirror::Class::SetStatus(klass, mirror::Class::kStatusRetryVerificationAtRuntime, self); } else { /*设置类状态为kStatusVerified，并且设置类标记位kAccVerificationAttempted。 注意，我们在上面代码中介绍过EnsureSkipAccessChecksMethods函数。这个函数将 （1）为klass methods_数组里的ArtMethod对象设置kAccSkipAccessChecks标志位 （2）为klass设置kAccVerificationAttempted标志位。 而下面的代码只设置了（2），没有设置（1）。所以，虽然类状态为kStatusVerified， 但在执行其方法时可能还要做Access Check */ mirror::Class::SetStatus(klass, mirror::Class::kStatusVerified, self); klass-\u0026gt;SetVerificationAttempted(); } } } else {...... } } else {...... } ....... //其他处理，略过 } MethodVerifier::VerifyClass MethodVerifier::FailureKind MethodVerifier::VerifyClass(Thread* self, mirror::Class* klass,......) { //待校验的类由kclass表示  //如果该类已经被校验过，则直接返回校验成功  if (klass-\u0026gt;IsVerified()) { return kNoFailure; } bool early_failure = false; std::string failure_message; //获取该class所在的Dex文件信息及该类在Dex文件里的class_def信息  const DexFile\u0026amp; dex_file = klass-\u0026gt;GetDexFile(); const DexFile::ClassDef* class_def = klass-\u0026gt;GetClassDef(); //获取该类的基类对象  mirror::Class* super = klass-\u0026gt;GetSuperClass(); std::string temp; //下面这个判断语句表示kclass没有基类，而它又不是Java Object类。显然，这是违背Java语言规范  //的—Java中，只有Object类才没有基类  if (super == nullptr \u0026amp;\u0026amp; strcmp(\u0026#34;Ljava/lang/Object;\u0026#34;, klass-\u0026gt;GetDescriptor(\u0026amp;temp)) != 0) { early_failure = true; failure_message = \u0026#34; that has no super class\u0026#34;; } else if (super != nullptr \u0026amp;\u0026amp; super-\u0026gt;IsFinal()) { //如果基类有派生类的话，基类不能为final  early_failure = true; } else if (class_def == nullptr) { //该类在Dex文件里没有class_def信息  early_failure = true; } if (early_failure) { ...... if (callbacks != nullptr) { //callbacks的类型是CompilerCallbacks，dex字节码转机器码的时候会用上它  ClassReference ref(\u0026amp;dex_file, klass-\u0026gt;GetDexClassDefIndex()); callbacks-\u0026gt;ClassRejected(ref); } return kHardFailure; //返回校验错误  } StackHandleScope\u0026lt;2\u0026gt; hs(self); Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache(hs.NewHandle(klass-\u0026gt;GetDexCache())); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle( klass-\u0026gt;GetClassLoader())); //进一步校验  return VerifyClass(self,\u0026amp;dex_file,dex_cache,......); } MethodVerifier::FailureKind MethodVerifier::VerifyClass(Thread* self, ......) { if ((class_def-\u0026gt;access_flags_ \u0026amp; (kAccAbstract | kAccFinal)) == (kAccAbstract | kAccFinal)) { return kHardFailure; //类不能同时是final又是abstract  } const uint8_t* class_data = dex_file-\u0026gt;GetClassData(*class_def); if (class_data == nullptr) { return kNoFailure; } //创建ClassDataItemIterator迭代器对象，通过它可以获取目标类的class_data_item里的内容  ClassDataItemIterator it(*dex_file, class_data); //不校验类的成员变量  while (it.HasNextStaticField() || it.HasNextInstanceField()) { it.Next(); } ClassLinker* linker = Runtime::Current()-\u0026gt;GetClassLinker(); //对本类所定义的Java方法进行校验。VerifyMethods在上一节已经介绍过了  MethodVerifier::FailureData data1 = VerifyMethods\u0026lt;true\u0026gt;(self, linker, dex_file, ......);//main  //校验本类中的virtual_methods数组  MethodVerifier::FailureData data2 = VerifyMethods\u0026lt;false\u0026gt;(self, linker, dex_file,......); //将校验结果合并到data1的结果中  data1.Merge(data2); //校验结果通过合并后的data1的成员来判断  if (data1.kind == kNoFailure) { return kNoFailure; } else { return data1.kind; } } MethodVerifier::VerifyMethods template \u0026lt;bool kDirect\u0026gt; MethodVerifier::FailureData MethodVerifier::VerifyMethods(Thread* self, ClassLinker* linker,const DexFile* dex_file, const DexFile::ClassDef* class_def,ClassDataItemIterator* it,...) { /* 注意这个函数的参数和返回值： （1）该函数为模板函数。结合图8-7，如果模板参数kDirect为true，则校验的将是目标类中 direct_methods的内容，否则为virtual_methods的内容。 （2）class_def的类型为DexFile::ClassDef。它是Dex文件里的一部分，class_def中最重 要的信息存储在class_data_item中，而class_data_item的内容可借助迭代器it来获取。 （3）self代表当前调用的线程对象。dex_file是目标类所在的Dex文件。 （4）返回值的类型为FailureData。它是MethodVeifier定义的内部类，其内部有一个名为kind 的成员变量，类型为枚举FailureKind，取值有如下三种情况： a) kNoFailure，表示校验无错。 b) kSoftFailure，表示校验软错误，该错误发生在从dex字节码转换为机器码时所做的校验过程 中。编译过程由dex2oat进程完成。dex2oat是一个简单的，仅用于编译的虚拟机进程，它包 含了前文提到的诸如heap、runtime等重要模块，但编译过程不会将所有相关类都加载到虚拟 机里，所以可能会出现编译过程中校验失败的情况。kSoftFailure失败并没有关系，这个类 在后续真正使用之时，虚拟机还会再次进行校验。 c) kHardFailure，表示校验错误，该错误表明校验失败。 */ MethodVerifier::FailureData failure_data; int64_t previous_method_idx = -1; /*同上，如果kDirect为true，则遍历class_data_item信息里的direct_methods数组， 否则遍历其中的virtual_methods数组（代表虚成员函数）。*/ while (HasNextMethod\u0026lt;kDirect\u0026gt;(it)) { self-\u0026gt;AllowThreadSuspension(); uint32_t method_idx = it-\u0026gt;GetMemberIndex(); ...... previous_method_idx = method_idx; /*InvokeType是枚举变量，和dex指令码里函数调用的方式有关：取值包括： （1）kStatic：对应invoke-static相关指令，调用类的静态方法。 （2）kDirect：对应invoke-direct相关指令，指调用那些非静态方法。包括两类，一类是 private修饰的成员函数，另外一类则是指类的构造函数。符合kStatic和kDirect调用类型 函数属于上文所述的direct methods（位于类的direct_methods数组中）。 （3）kVirtual：对应invoke-virtual相关指令，指调用非private、static或final修饰 的成员函数（注意，不包括调用构造函数）。 （4）kSuper：对应invoke-super相关指令，指在子类的函数中通过super来调用直接父类的 函数。注意，dex官方文档只是说invoke-super用于调用直接父类的virtual函数。但笔者测试 发现，必须写成\u0026#34;super.父类函数\u0026#34;的形式才能生成invoke-super指令。 （5）kInterface：对应invoke-interface相关指令，指调用接口中定义的函数。 以上枚举变量的解释可参考第3章最后所列举的谷歌官方文档。 下面代码中的GetMethodInvokeType是迭代器ClassDataItemIterator的成员函数，它将 返回当前所遍历的成员函数的调用方式（InvokeType）。注意，该函数返回kSuper的逻辑和官 方文档对kSuper的描述并不一致。按照该函数的逻辑，它永远也不可能返回kSuper。笔者在模拟 器上验证过这个问题，此处从未有返回过kSuper的情况。感兴趣的读者不妨做一番调研 */ InvokeType type = it-\u0026gt;GetMethodInvokeType(*class_def); //调用ClassLinker的ResolveMethod进行解析，下文将介绍此函数。  ArtMethod* method = linker-\u0026gt;ResolveMethod\u0026lt;ClassLinker::kNoICCECheckForCache\u0026gt;( *dex_file, method_idx, dex_cache, class_loader, nullptr, type); ...... //调用另外一个VerifyMethod函数，其代码见下文  MethodVerifier::FailureData result = VerifyMethod(self,method_idx,...); ...... return failure_data; } MethodVerifier::VerifyMethod MethodVerifier::FailureData MethodVerifier::VerifyMethod(Thread* self, ......) { MethodVerifier::FailureData result; /*创建一个MethodVerifier对象，然后调用它的Verify方法。其内部将校验method（类型为Art- Method*）所代表的Java方法。该方法对应的字节码在code_item（对应dex文件格式里的code_ item）中。 */ MethodVerifier verifier(self,dex_file, dex_cache, class_loader, ......); //Verify返回成功，表示校验通过。即使出现kSoftFailure的情况，该函数也会返回true  if (verifier.Verify()) {//main  ...... //failures_的类型为vector\u0026lt;VerifyError\u0026gt;。VerifyError为枚举变量，定义了校验中可能  //出现的错误情况  if (verifier.failures_.size() != 0) { result.kind = kSoftFailure; } if (method != nullptr) {.....} } else { /*Verify返回失败，但若错误原因是一些试验性指令导致的，则也属于软错误，Dex指令码中有 一些属于试验性质的指令，比如invokelambda。搜索dex_instruction.h文件里带kExperi- mental标记的指令码，即是ART虚拟机所支持的试验性指令 */ if (UNLIKELY(verifier.have_pending_experimental_failure_)) { result.kind = kSoftFailure; } else { result.kind = kHardFailure;} } ...... return result; } MethodVerifier::Verify bool MethodVerifier::Verify() { //从dex文件里取出该方法对应的method_id_item信息  const DexFile::MethodId\u0026amp; method_id = dex_file_-\u0026gt;GetMethodId(dex_method_idx_); //取出该函数的函数名  const char* method_name = dex_file_-\u0026gt;StringDataByIdx(method_id.name_idx_); /*根据函数名判断其是类实例的构造函数还是类的静态构造函数。代码中，\u0026#34;\u0026lt;init\u0026gt;\u0026#34;叫类实例构造函数 （instance constructor），而\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;叫类的静态构造函数（static constructor）。 */ bool instance_constructor_by_name = strcmp(\u0026#34;\u0026lt;init\u0026gt;\u0026#34;, method_name) == 0; bool static_constructor_by_name = strcmp(\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;, method_name) == 0; //上述条件有一个为true，则该函数被认为是构造函数  bool constructor_by_name = instance_constructor_by_name || static_constructor_by_name; /*如果该函数的访问标记（access flags，可参考第3章表3-1自己为构造函数，而函数名又不符合要 求，则设置校验的结果为VERIFY_ERROR_BAD_CLASS_HARD（VerifyError枚举值中的一种）。Fail 函数内部会处理VerifyError里定义的不同错误类型。其中以HARD结尾的枚举变量表示为硬错误 */ if ((method_access_flags_ \u0026amp; kAccConstructor) != 0) { if (!constructor_by_name) { Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; \u0026#34;method is marked as constructor, but not named accordingly\u0026#34;; return false; } is_constructor_ = true; } else if (constructor_by_name) { is_constructor_ = true; } //code_item_代表该函数的内容，如果为nullptr，则表示这个函数为抽象函数或native函数  if (code_item_ == nullptr) { //既不是抽象函数，也不是native函数，但又没有函数内容，校验肯定会失败  if ((method_access_flags_ \u0026amp; (kAccNative | kAccAbstract)) == 0) { Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; ......; //错误原因;  return false; } return true; } /*参考3.2.4节可知，ins_size_表示输入参数所占虚拟寄存器的个数，而registers_size_表示该 函数所需虚拟寄存器的总个数。显然，下面这个if条件为true的话，这个函数肯定会校验失败 */ if (code_item_-\u0026gt;ins_size_ \u0026gt; code_item_-\u0026gt;registers_size_) { Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; ......; Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; ......; return false; } //insn_flags_将保存该方法里的指令码内容  insn_flags_.reset(arena_.AllocArray\u0026lt;InstructionFlags\u0026gt;( code_item_-\u0026gt;insns_size_in_code_units_)); std::uninitialized_fill_n(insn_flags_.get(), code_item_-\u0026gt;insns_size_in_code_units_, InstructionFlags()); //下面四个函数将对指令码的内容进行校验。读者不拟介绍它们，感兴趣的读者不妨自行研究。  bool result = ComputeWidthsAndCountOps(); result = result \u0026amp;\u0026amp; ScanTryCatchBlocks(); result = result \u0026amp;\u0026amp; VerifyInstructions(); result = result \u0026amp;\u0026amp; VerifyCodeFlow(); return result; } Initialize EnsureInitialized bool ClassLinker::EnsureInitialized(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; c, bool can_init_fields, bool can_init_parents) { if (c-\u0026gt;IsInitialized()) { EnsureSkipAccessChecksMethods(c, image_pointer_size_); return true; } // SubtypeCheckInfo::Initialized must happen-before any new-instance for that type.  const bool success = InitializeClass(self, c, can_init_fields, can_init_parents); return success; InitializeClass bool ClassLinker::InitializeClass(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, bool can_init_statics, bool can_init_parents) { ...... //多个线程也可能同时触发目标类的初始化工作，如果这个类已经初始化了，则直接返回  //判断是否能初始化目标类。因为该函数可以在dex2oat编译进程中调用，在编译进程中，某些情况下  //无须初始化类。这部分内容我们不关注，读者以后碰到相关代码时可回顾此处的处理。  if (!CanWeInitializeClass(klass.Get(), can_init_statics, can_init_parents)) { return false; } { //  ..... if (!klass-\u0026gt;IsVerified()) { //如果类还没有校验，则校验它  VerifyClass(self, klass); ...... } ...... /*下面这个函数将对klass做一些检查，大体功能包括： （1）如果klass是接口类，则直接返回，不做任何检查。 （2）如果klass和它的基类superclass是由两个不同的ClassLoader加载的，则需要对比检 查klass VTable和superclass VTable中对应项的两个ArtMethod是否有相同的签名 信息，即两个成员方法的返回值类型、输入参数的个数以及类型是否一致。 （3）如果klass有Iftable，则还需要检查klass IfTable中所实现的接口类的函数与对应 接口类里定义的接口函数是否有一样的签名信息。是否开展检查的前提条件也是klass和接 口类由不同的ClassLoader加载。如果检查失败，则会创建java.lang.LinkageError 错误信息。 */ if (!ValidateSuperClassDescriptors(klass)) {.....} ...... //设置执行类初始化操作的线程ID以及类状态为kStatusInitializing  klass-\u0026gt;SetClinitThreadId(self-\u0026gt;GetTid()); mirror::Class::SetStatus(klass, mirror::Class::kStatusInitializing, self); } //根据JLS规范，klass如果是接口类的话，则不需要初始化接口类的基类（其实就是Object）  if (!klass-\u0026gt;IsInterface() \u0026amp;\u0026amp; klass-\u0026gt;HasSuperClass()) { mirror::Class* super_class = klass-\u0026gt;GetSuperClass(); if (!super_class-\u0026gt;IsInitialized()) { ...... Handle\u0026lt;mirror::Class\u0026gt; handle_scope_super(hs.NewHandle(super_class)); bool super_initialized = InitializeClass(self, handle_scope_super, can_init_statics, true); ...... //基类初始化失败的处理  } } //初始化klass所实现的那些接口类  if (!klass-\u0026gt;IsInterface()) { size_t num_direct_interfaces = klass-\u0026gt;NumDirectInterfaces(); if (UNLIKELY(num_direct_interfaces \u0026gt; 0)) { MutableHandle\u0026lt;mirror::Class\u0026gt; handle_scope_iface(....); for (size_t i = 0; i \u0026lt; num_direct_interfaces; i++) { //handle_scope_iface代表一个接口类对象  handle_scope_iface.Assign(mirror::Class::GetDirectInterface( self, klass, i)); //检查接口类对象是否设置了kAccRecursivelyInitialized标记位。这个标记位表示  //这个接口类已初始化过了。该标志位是ART虚拟机内部处理类初始化时的一种优化手段  if (handle_scope_iface-\u0026gt;HasBeenRecursivelyInitialized()) {continue; } //初始化接口类，并递归初始化接口类的父接口类  bool iface_initialized = InitializeDefaultInterfaceRecursive(self, handle_scope_iface,......); if (!iface_initialized) { return false; } } } } /*到此，klass的父类及接口类都已经初始化了。接下来要初始化klass中的静态成员变量。读者可回 顾图8-7 class_def结构体，其最后一个成员变量为static_values_off，它代表该类静态成员 变量初始值存储的位置。找到这个位置，即可取出对应静态成员变量的初值。 */ const size_t num_static_fields = klass-\u0026gt;NumStaticFields(); if (num_static_fields \u0026gt; 0) { //找到klass对应的ClassDef信息以及对应的DexFile对象  const DexFile::ClassDef* dex_class_def = klass-\u0026gt;GetClassDef(); const DexFile\u0026amp; dex_file = klass-\u0026gt;GetDexFile(); StackHandleScope\u0026lt;3\u0026gt; hs(self); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle( klass-\u0026gt;GetClassLoader())); //找到对应的DexCache对象  Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache(hs.NewHandle(klass-\u0026gt;GetDexCache())); ..... //遍历ClassDef中代表static_values_off的区域  EncodedStaticFieldValueIterator value_it(dex_file, \u0026amp;dex_cache, \u0026amp;class_loader, this, *dex_class_def); const uint8_t* class_data = dex_file.GetClassData(*dex_class_def); ClassDataItemIterator field_it(dex_file, class_data); if (value_it.HasNext()) { for ( ; value_it.HasNext(); value_it.Next(), field_it.Next()) { //找到对应的ArtField成员。下文会介绍ResolveField函数  ArtField* field = ResolveField(dex_file, field_it.GetMemberIndex(), dex_cache, class_loader, true); //设置该ArtField的初值，内部将调用Class的SetFieldXXX相关函数，它会在Class  //对象中存储对应静态成员变量内容的位置（其值为ArtField的offset_）上设置初值。  value_it.ReadValueToField\u0026lt;...\u0026gt;(field); } } } //找到类的\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;函数，并执行它  ArtMethod* clinit = klass-\u0026gt;FindClassInitializer(image_pointer_size_); if (clinit != nullptr) { JValue result; clinit-\u0026gt;Invoke(self, nullptr, 0, \u0026amp;result, \u0026#34;V\u0026#34;); } bool success = true; { if (.....) {......} else { //初始化正常  ..... //设置类状态为kStatusInitialized  mirror::Class::SetStatus(klass, mirror::Class::kStatusInitialized,self); //下面这个函数设置klass静态成员方法ArtMethod的trampoline入口地址。它和  //Java方法的执行有关，这部分内容我们留待后文再来介绍。  //更新机器码入口地址entry_point_from_quick_compiled_code_  FixupStaticTrampolines(klass.Get()); } } return success; } 类加载样例 图8-10　AbsClass0的情况\n图8-11　ConcreteClass的情况\n图8-12　ConcreteChildClass的情况\n·methods_：仅保存在本类中定义的direct、virtual以及拷贝过来的方法。\n·vtable_或embedded_vtable_：如果一个类是可实例化的，则只存在embedded_vtable_变量，否则只存在vtable_。这两个变量保存的信息是一样的，即这个类所有的virtual方法。这个表内容可能会非常多，因为它包含了来自整个继承和实现关系上的所有类的virtual方法。\n·embedded_imtable_：如果一个类是可实例化的，则存在这个变量。它存储了接口类方法。embedded_imtable_本身起到快查表的作用，方便快速找到接口方法。\n·iftable_：存储了该类在接口实现（可能是父类的接口实现关系）实现关系上的信息，包括继承了哪些接口类，实际的接口方法。\n类加载之后Class和Instance的内存占用 图8-14　reference_instance_offsets_说明\n以下为参考代码 ClassLinker EnsureResolved mirror::Class* ClassLinker::EnsureResolved(Thread* self, const char* descriptor, mirror::Class* klass) { // For temporary classes we must wait for them to be retired.  if (init_done_ \u0026amp;\u0026amp; klass-\u0026gt;IsTemp()) { CHECK(!klass-\u0026gt;IsResolved()); if (klass-\u0026gt;IsErroneous()) { ThrowEarlierClassFailure(klass); return nullptr; } ShouldUseInterpreterEntrypoint bool ClassLinker::ShouldUseInterpreterEntrypoint(ArtMethod* method, const void* quick_code) { if (UNLIKELY(method-\u0026gt;IsNative() || method-\u0026gt;IsProxyMethod())) { return false; } if (quick_code == nullptr) { return true; } ...... } GetQuickToInterpreterBridge // Return the address of quick stub code for bridging from quick code to the interpreter. extern \u0026#34;C\u0026#34; void art_quick_to_interpreter_bridge(ArtMethod*); static inline const void* GetQuickToInterpreterBridge() { return reinterpret_cast\u0026lt;const void*\u0026gt;(art_quick_to_interpreter_bridge); } ThrowEarlierClassFailure void ClassLinker::ThrowEarlierClassFailure(ObjPtr\u0026lt;mirror::Class\u0026gt; c, bool wrap_in_no_class_def) { // The class failed to initialize on a previous attempt, so we want to throw  // a NoClassDefFoundError (v2 2.17.5). The exception to this rule is if we  // failed in verification, in which case v2 5.4.1 says we need to re-throw  // the previous error.  Runtime* const runtime = Runtime::Current(); if (!runtime-\u0026gt;IsAotCompiler()) { // Give info if this occurs at runtime.  std::string extra; if (GetVerifyError(c) != nullptr) { ObjPtr\u0026lt;mirror::Object\u0026gt; verify_error = GetVerifyError(c); if (verify_error-\u0026gt;IsClass()) { extra = mirror::Class::PrettyDescriptor(verify_error-\u0026gt;AsClass()); } else { extra = verify_error-\u0026gt;AsThrowable()-\u0026gt;Dump(); } } LOG(INFO) \u0026lt;\u0026lt; \u0026#34;Rejecting re-init on previously-failed class \u0026#34; \u0026lt;\u0026lt; c-\u0026gt;PrettyClass() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; extra;//the stack log of NoClassDefFoundError came from here  } GetVerifyError static mirror::Object* GetVerifyError(ObjPtr\u0026lt;mirror::Class\u0026gt; c) REQUIRES_SHARED(Locks::mutator_lock_) { ObjPtr\u0026lt;mirror::ClassExt\u0026gt; ext(c-\u0026gt;GetExtData()); if (ext == nullptr) { return nullptr; } else { return ext-\u0026gt;GetVerifyError(); } } art/runtime/mirror/class-inl.h\nClass::GetExtData HeapReference\u0026lt;ClassExt\u0026gt; ext_data_; template\u0026lt;VerifyObjectFlags kVerifyFlags, ReadBarrierOption kReadBarrierOption\u0026gt; inline ClassExt* Class::GetExtData() { return GetFieldObject\u0026lt;ClassExt, kVerifyFlags, kReadBarrierOption\u0026gt;( OFFSET_OF_OBJECT_MEMBER(Class, ext_data_)); } art/runtime/mirror/class_ext.h\nclass_ext.h.GetVerifyError // C++ mirror of dalvik.system.ClassExt class MANAGED ClassExt : public Object { // The saved verification error of this class.  HeapReference\u0026lt;Object\u0026gt; verify_error_; Object* GetVerifyError() REQUIRES_SHARED(Locks::mutator_lock_) { return GetFieldObject\u0026lt;ClassExt\u0026gt;(OFFSET_OF_OBJECT_MEMBER(ClassExt, verify_error_)); } } art/runtime/oat_file-inl.h\noat_file-inl.h.GetQuickCode inline const void* OatFile::OatMethod::GetQuickCode() const { return GetOatPointer\u0026lt;const void*\u0026gt;(GetCodeOffset()); } inline uint32_t OatFile::OatMethod::GetCodeOffset() const { return (GetQuickCodeSize() == 0) ? 0 : code_offset_; } art/runtime/runtime.h\nruntime.h.IsAotCompiler // IsAotCompiler for compilers that don\u0026#39;t have a running runtime. Only dex2oat currently.  bool IsAotCompiler() const { return !UseJitCompilation() \u0026amp;\u0026amp; IsCompiler(); } // IsCompiler is any runtime which has a running compiler, either dex2oat or JIT.  bool IsCompiler() const { return compiler_callbacks_ != nullptr; } art/runtime/thread.cc\nThread::ThrowNewWrappedException void Thread::ThrowNewWrappedException(const char* exception_class_descriptor, const char* msg) { DCHECK(!runtime-\u0026gt;IsStarted() || exception_class-\u0026gt;IsThrowableClass()); Handle\u0026lt;mirror::Throwable\u0026gt; exception( hs.NewHandle(ObjPtr\u0026lt;mirror::Throwable\u0026gt;::DownCast(exception_class-\u0026gt;AllocObject(this)))); ArtMethod* exception_init_method = exception_class-\u0026gt;FindConstructor(signature, cl-\u0026gt;GetImagePointerSize()); InvokeWithJValues(soa, ref.get(), exception_init_method, jv_args); if (LIKELY(!IsExceptionPending())) { SetException(exception.Get()); } Thread::SetException void Thread::SetException(ObjPtr\u0026lt;mirror::Throwable\u0026gt; new_exception) { CHECK(new_exception != nullptr); // TODO: DCHECK(!IsExceptionPending());  tlsPtr_.exception = new_exception.Ptr(); } libcore/dalvik/src/main/java/dalvik/system/BaseDexClassLoader.java\nBaseDexClassLoader.findClass @Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { List\u0026lt;Throwable\u0026gt; suppressedExceptions = new ArrayList\u0026lt;Throwable\u0026gt;(); Class c = pathList.findClass(name, suppressedExceptions); if (c == null) { ClassNotFoundException cnfe = new ClassNotFoundException( \u0026#34;Didn\u0026#39;t find class \\\u0026#34;\u0026#34; + name + \u0026#34;\\\u0026#34; on path: \u0026#34; + pathList); for (Throwable t : suppressedExceptions) { cnfe.addSuppressed(t); } throw cnfe; } return c; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E7%B1%BB%E7%BC%96%E8%AF%91/",
	"title": "类编译",
	"tags": [],
	"description": "",
	"content": "类编译 探索总结类编译知识\n dex2oat     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/",
	"title": "系统机制原理",
	"tags": [],
	"description": "",
	"content": "系统机制原理 探索总结系统机制原理知识\n ashmem     bitmap    Bitmap     BitmapSource      handler    Looper     ThreadLocal      input    touchEventNative      kernel    kernel      layoutinflater    LayoutInflater      sharedpreferences    SharedPreferences      thread    StackTraceElement     ThreadState      zygote    SystemServerSource     ZygoteSource     Zygote进程      后台任务    后台任务处理      多进程    binder    BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理      mmkv    MMKV       应用启动退出    应用启动      源码研究方法    Syscall查找方式      系统绘制    Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/",
	"title": "系统绘制",
	"tags": [],
	"description": "",
	"content": "系统绘制 探索总结系统绘制知识\n Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E7%BB%98%E5%88%B6%E5%8E%9F%E7%90%86/",
	"title": "绘制原理",
	"tags": [],
	"description": "",
	"content": "流程原理 ViewRootImpl.setView /** * We have one child */ public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) { // If the application owns the surface, don\u0026#39;t enable hardware acceleration  if (mSurfaceHolder == null) { // While this is supposed to enable only, it can effectively disable  // the acceleration too.  enableHardwareAcceleration(attrs); } // Schedule the first layout -before- adding to the window  // manager, to make sure we do the relayout before receiving  // any other events from the system.  requestLayout(); //mWindowSession是一个aidl，ViewRootImpl利用它来和WindowManagerService交互  //mWindow是一个aidl，WindowManagerService可以利用这个对象与服务端交互  res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); } enableHardwareAcceleration private void enableHardwareAcceleration(WindowManager.LayoutParams attrs) { // Try to enable hardware acceleration if requested  final boolean hardwareAccelerated = (attrs.flags \u0026amp; WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED) != 0; if (hardwareAccelerated) { mAttachInfo.mThreadedRenderer = ThreadedRenderer.create(mContext, translucent, attrs.getTitle().toString()); if (mAttachInfo.mThreadedRenderer != null) { mAttachInfo.mHardwareAccelerated = mAttachInfo.mHardwareAccelerationRequested = true; } } } 创建ThreadedRenderer /** * Creates a threaded renderer using OpenGL. * * @param translucent True if the surface is translucent, false otherwise * * @return A threaded renderer backed by OpenGL. */ public static ThreadedRenderer create(Context context, boolean translucent, String name) { ThreadedRenderer renderer = null; if (isAvailable()) { renderer = new ThreadedRenderer(context, translucent, name); } return renderer; } ThreadedRenderer(Context context, boolean translucent, String name) { long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); mIsOpaque = !translucent; mNativeProxy = nCreateProxy(translucent, rootNodePtr); nSetName(mNativeProxy, name); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nstatic jlong android_view_ThreadedRenderer_createRootRenderNode(JNIEnv* env, jobject clazz) { RootRenderNode* node = new RootRenderNode(env); node-\u0026gt;incStrong(0); node-\u0026gt;setName(\u0026#34;RootRenderNode\u0026#34;); return reinterpret_cast\u0026lt;jlong\u0026gt;(node); } /** * Adopts an existing native render node. */ public static RenderNode adopt(long nativePtr) { return new RenderNode(nativePtr); } 创建RendeProxy static jlong android_view_ThreadedRenderer_createProxy(JNIEnv* env, jobject clazz, jboolean translucent, jlong rootRenderNodePtr) { RootRenderNode* rootRenderNode = reinterpret_cast\u0026lt;RootRenderNode*\u0026gt;(rootRenderNodePtr); ContextFactoryImpl factory(rootRenderNode); return (jlong) new RenderProxy(translucent, rootRenderNode, \u0026amp;factory); } frameworks/base/libs/hwui/renderthread/RenderProxy.cpp\nRenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { } 创建RenderThread RenderThread\u0026amp; RenderThread::getInstance() { // This is a pointer because otherwise __cxa_finalize  // will try to delete it like a Good Citizen but that causes us to crash  // because we don\u0026#39;t want to delete the RenderThread normally.  static RenderThread* sInstance = new RenderThread(); gHasRenderThreadInstance = true; return *sInstance; } RenderThread::RenderThread() : ThreadBase() , mVsyncSource(nullptr) , mVsyncRequested(false) , mFrameCallbackTaskPending(false) , mRenderState(nullptr) , mEglManager(nullptr) , mVkManager(nullptr) { Properties::load(); start(\u0026#34;RenderThread\u0026#34;); } graph TB Thread--\u0026gt;ThreadBase ThreadBase--\u0026gt;ReanderThread 启动RenderThread bool RenderThread::threadLoop() { setpriority(PRIO_PROCESS, 0, PRIORITY_DISPLAY); if (gOnStartHook) { gOnStartHook(); } initThreadLocals(); while (true) { waitForWork(); processQueue(); ...... requestVsync(); } return false; } void RenderThread::initThreadLocals() { mDisplayInfo = DeviceInfo::queryDisplayInfo(); nsecs_t frameIntervalNanos = static_cast\u0026lt;nsecs_t\u0026gt;(1000000000 / mDisplayInfo.fps); mTimeLord.setFrameInterval(frameIntervalNanos); initializeDisplayEventReceiver(); mEglManager = new EglManager(*this); mRenderState = new RenderState(*this); mVkManager = new VulkanManager(*this); mCacheManager = new CacheManager(mDisplayInfo); } 配置DisplayEventReceiver的fd监听 void RenderThread::initializeDisplayEventReceiver() { LOG_ALWAYS_FATAL_IF(mVsyncSource, \u0026#34;Initializing a second DisplayEventReceiver?\u0026#34;); if (!Properties::isolatedProcess) { auto receiver = std::make_unique\u0026lt;DisplayEventReceiver\u0026gt;(); status_t status = receiver-\u0026gt;initCheck(); // Register the FD  mLooper-\u0026gt;addFd(receiver-\u0026gt;getFd(), 0, Looper::EVENT_INPUT, RenderThread::displayEventReceiverCallback, this); mVsyncSource = new DisplayEventReceiverWrapper(std::move(receiver)); } else { mVsyncSource = new DummyVsyncSource(this); } } frameworks/base/libs/hwui/thread/ThreadBase.h\nThreadBase.waitForWork void waitForWork() { nsecs_t nextWakeup; { std::unique_lock lock{mLock}; nextWakeup = mQueue.nextWakeup(lock); } int timeout = -1; if (nextWakeup \u0026lt; std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max()) { timeout = ns2ms(nextWakeup - WorkQueue::clock::now()); if (timeout \u0026lt; 0) timeout = 0; } int result = mLooper-\u0026gt;pollOnce(timeout); LOG_ALWAYS_FATAL_IF(result == Looper::POLL_ERROR, \u0026#34;RenderThread Looper POLL_ERROR!\u0026#34;); } nsecs_t nextWakeup(std::unique_lock\u0026lt;std::mutex\u0026gt;\u0026amp; lock) { if (mWorkQueue.empty()) { return std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max(); } else { return std::begin(mWorkQueue)-\u0026gt;runAt; } } 加入同步任务 RenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { mContext = mRenderThread.queue().runSync([\u0026amp;]() -\u0026gt; CanvasContext* { return CanvasContext::create(mRenderThread, translucent, rootRenderNode, contextFactory); }); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext, rootRenderNode); } ThreadBase.h\nWorkQueue\u0026amp; queue() { return mQueue; } frameworks/base/libs/hwui/thread/WorkQueue.h\ntemplate \u0026lt;class F\u0026gt; auto runSync(F\u0026amp;\u0026amp; func) -\u0026gt; decltype(func()) { std::packaged_task\u0026lt;decltype(func())()\u0026gt; task{std::forward\u0026lt;F\u0026gt;(func)}; post([\u0026amp;task]() { std::invoke(task); }); return task.get_future().get(); }; template \u0026lt;class F\u0026gt; void post(F\u0026amp;\u0026amp; func) { postAt(0, std::forward\u0026lt;F\u0026gt;(func)); } template \u0026lt;class F\u0026gt; void postAt(nsecs_t time, F\u0026amp;\u0026amp; func) { enqueue(WorkItem{time, std::function\u0026lt;void()\u0026gt;(std::forward\u0026lt;F\u0026gt;(func))}); } void enqueue(WorkItem\u0026amp;\u0026amp; item) { bool needsWakeup; { std::unique_lock _lock{mLock}; auto insertAt = std::find_if( std::begin(mWorkQueue), std::end(mWorkQueue), [time = item.runAt](WorkItem \u0026amp; item) { return item.runAt \u0026gt; time; }); needsWakeup = std::begin(mWorkQueue) == insertAt; mWorkQueue.emplace(insertAt, std::move(item)); } if (needsWakeup) { mWakeFunc();//ThreadBase构造时设置的: mLooper-\u0026gt;wake()  } } Looper唤醒后执行processQueue void processQueue() { mQueue.process(); } void process() { auto now = clock::now(); std::vector\u0026lt;WorkItem\u0026gt; toProcess; { std::unique_lock _lock{mLock}; if (mWorkQueue.empty()) return; toProcess = std::move(mWorkQueue); auto moveBack = find_if(std::begin(toProcess), std::end(toProcess), [\u0026amp;now](WorkItem\u0026amp; item) { return item.runAt \u0026gt; now; }); if (moveBack != std::end(toProcess)) { mWorkQueue.reserve(std::distance(moveBack, std::end(toProcess)) + 5); std::move(moveBack, std::end(toProcess), std::back_inserter(mWorkQueue)); toProcess.erase(moveBack, std::end(toProcess)); } } for (auto\u0026amp; item : toProcess) { item.work(); } } WorkQueue和WorkItem结构 WorkQueue std::function\u0026lt;void()\u0026gt; mWakeFunc; std::vector\u0026lt;WorkItem\u0026gt; mWorkQueue; struct WorkItem { nsecs_t runAt; std::function\u0026lt;void()\u0026gt; work; }; 执行任务CanvasContext::create frameworks/base/libs/hwui/renderthread/CanvasContext.cpp\n根据pipelineType创建对应的CanvasContext CanvasContext* CanvasContext::create(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) { auto renderType = Properties::getRenderPipelineType(); switch (renderType) { case RenderPipelineType::OpenGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;OpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaOpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaVulkan: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaVulkanPipeline\u0026gt;(thread)); default: LOG_ALWAYS_FATAL(\u0026#34;canvas context type %d not supported\u0026#34;, (int32_t)renderType); break; } return nullptr; } RenderPipeLine类设计 graph TB IRenderPipeline--\u0026gt;OpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaOpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaVulkanPipeline CanvasContext::CanvasContext(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory, std::unique_ptr\u0026lt;IRenderPipeline\u0026gt; renderPipeline) : mRenderThread(thread) , mGenerationID(0) , mOpaque(!translucent) , mAnimationContext(contextFactory-\u0026gt;createAnimationContext(mRenderThread.timeLord())) , mJankTracker(\u0026amp;thread.globalProfileData(), thread.mainDisplayInfo()) , mProfiler(mJankTracker.frames()) , mContentDrawBounds(0, 0, 0, 0) , mRenderPipeline(std::move(renderPipeline)) { rootRenderNode-\u0026gt;makeRoot(); mRenderNodes.emplace_back(rootRenderNode); mRenderThread.renderState().registerCanvasContext(this); mProfiler.setDensity(mRenderThread.mainDisplayInfo().density); } 执行任务mDrawFrameTask.setContext void DrawFrameTask::setContext(RenderThread* thread, CanvasContext* context, RenderNode* targetNode) { mRenderThread = thread; mContext = context; mTargetNode = targetNode; } requestLayout 策划下一帧 mWindowSession.addToDisplay app进程和wms所在的sytemserver进程通信的binder frameworks/base/core/java/android/view/IWindow.aidl\n/** * API back to a client window that the Window Manager uses to inform it of * interesting things happening. */ oneway interface IWindow {} frameworks/base/core/java/android/view/IWindowSession.aidl\n/** * System private per-application interface to the window manager. */ interface IWindowSession {} frameworks/base/services/core/java/com/android/server/wm/Session.java\nSession.addToDisplay,WMS.addWindow @Override public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId, outFrame, outContentInsets, outStableInsets, outOutsets, outDisplayCutout, outInputChannel); } public int addWindow(Session session, IWindow client, int seq, LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { //WindowState用来描述一个Window  //生成WindowState对象，它是ViewRootImpl 在WindowManager Service端的代表。在它的构造函数里，WindowState 会生成IWindowId.Stub 对象和DeathRecipient对象来分别监听Focus和窗口死亡的信息  final WindowState win = new WindowState(this, session, client, token, parentWindow, appOp[0], seq, attrs, viewVisibility, session.mUid, session.mCanAddInternalSystemWindow); //创建用于通信的SocketPair , 将其传给InputManagerService, 用于接下来的用户输入事件对应的响应窗口（参考Android的用户输入处理）  final boolean openInputChannels = (outInputChannel != null \u0026amp;\u0026amp; (attrs.inputFeatures \u0026amp; INPUT_FEATURE_NO_INPUT_CHANNEL) == 0); if (openInputChannels) { win.openInputChannel(outInputChannel); } //创建了一个Surface Session 并将Surface Session，WindowSession 还有WindowState 三者关联起来.  win.attach(); //mWindowMap是WindowManagerService用来保存当前所有Window新的的集合  mWindowMap.put(client.asBinder(), win); //一个token下会有多个win state。 其实token与PhoneWindow是一一对应的。  win.mToken.addWindow(win); } frameworks/base/services/core/java/com/android/server/wm/WindowState.java\nopenInputChannel void openInputChannel(InputChannel outInputChannel) { if (mInputChannel != null) { throw new IllegalStateException(\u0026#34;Window already has an input channel.\u0026#34;); } String name = getName(); InputChannel[] inputChannels = InputChannel.openInputChannelPair(name);//refer to TouchEventNative.md  mInputChannel = inputChannels[0]; mClientChannel = inputChannels[1]; mInputWindowHandle.inputChannel = inputChannels[0]; if (outInputChannel != null) { mClientChannel.transferTo(outInputChannel); mClientChannel.dispose(); mClientChannel = null; } else { // If the window died visible, we setup a dummy input channel, so that taps  // can still detected by input monitor channel, and we can relaunch the app.  // Create dummy event receiver that simply reports all events as handled.  mDeadWindowEventReceiver = new DeadWindowEventReceiver(mClientChannel); } mService.mInputManager.registerInputChannel(mInputChannel, mInputWindowHandle);//refer to TouchEventNative.md  } attach void attach() { mSession.windowAddedLocked(mAttrs.packageName); } void windowAddedLocked(String packageName) { if (mSurfaceSession == null) { mSurfaceSession = new SurfaceSession(); mService.mSessions.add(this); } } 创建SurfaceSession /** * An instance of this class represents a connection to the surface * flinger, from which you can create one or more Surface instances that will * be composited to the screen. */ public final class SurfaceSession { // Note: This field is accessed by native code.  private long mNativeClient; // SurfaceComposerClient* } /** Create a new connection with the surface flinger. */ public SurfaceSession() { mNativeClient = nativeCreate(); } frameworks/base/core/jni/android_view_SurfaceSession.cpp\nstatic jlong nativeCreate(JNIEnv* env, jclass clazz) { SurfaceComposerClient* client = new SurfaceComposerClient(); client-\u0026gt;incStrong((void*)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(client); } 创建SurfaceComposerClient void SurfaceComposerClient::onFirstRef() { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService());//sf 就是SurfaceFlinger Service  if (sf != 0 \u0026amp;\u0026amp; mStatus == NO_INIT) { auto rootProducer = mParent.promote(); sp\u0026lt;ISurfaceComposerClient\u0026gt; conn; conn = (rootProducer != nullptr) ? sf-\u0026gt;createScopedConnection(rootProducer) : sf-\u0026gt;createConnection(); if (conn != 0) { mClient = conn; mStatus = NO_ERROR; } } } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\n通知SurfaceFlinger.createConnection sp\u0026lt;ISurfaceComposerClient\u0026gt; SurfaceFlinger::createConnection() { return initClient(new Client(this)); } frameworks/native/services/surfaceflinger/Client.h\n创建Client作为BnSurfaceComposerClient class Client : public BnSurfaceComposerClient { public: ... void attachLayer(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle, const sp\u0026lt;Layer\u0026gt;\u0026amp; layer); void detachLayer(const Layer* layer); ... private: // ISurfaceComposerClient interface。 gbp很重要，它维护这一个应用程序的渲染 Buffer队列  virtual status_t createSurface(...sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp); virtual status_t destroySurface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle); //跨进程通信方法  virtual status_t onTransact(uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags); ... // constant  sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; // protected by mLock  DefaultKeyedVector\u0026lt; wp\u0026lt;IBinder\u0026gt;, wp\u0026lt;Layer\u0026gt; \u0026gt; mLayers; // 一个应用程序的所有Layer  ... }; performTraversals private void performTraversals() { // Execute enqueued actions on every traversal in case a detached view enqueued an action  host.dispatchAttachedToWindow(mAttachInfo, 0); relayoutResult = relayoutWindow(params, viewVisibility, insetsPending); if (mSurface.isValid()) { // If we are creating a new surface, then we need to  // completely redraw it. Also, when we get to the  // point of drawing it we will hold off and schedule  // a new traversal instead. This is so we can tell the  // window manager about all of the windows being displayed  // before actually drawing them, so it can display then  // all at once.  newSurface = true; mFullRedrawNeeded = true; mPreviousTransparentRegion.setEmpty(); // Only initialize up-front if transparent regions are not  // requested, otherwise defer to see if the entire window  // will be transparent  if (mAttachInfo.mThreadedRenderer != null) { hwInitialized = mAttachInfo.mThreadedRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { // Don\u0026#39;t pre-allocate if transparent regions  // are requested as they may not be needed  mSurface.allocateBuffers(); } } } // Ask host how big it wants to be  performMeasure(childWidthMeasureSpec, childHeightMeasureSpec); ...... performLayout(lp, mWidth, mHeight); ...... performDraw(); relayoutWindow private int relayoutWindow(WindowManager.LayoutParams params, int viewVisibility, boolean insetsPending) throws RemoteException { int relayoutResult = mWindowSession.relayout(mWindow, mSeq, params, (int) (mView.getMeasuredWidth() * appScale + 0.5f), (int) (mView.getMeasuredHeight() * appScale + 0.5f), viewVisibility, insetsPending ? WindowManagerGlobal.RELAYOUT_INSETS_PENDING : 0, frameNumber, mWinFrame, mPendingOverscanInsets, mPendingContentInsets, mPendingVisibleInsets, mPendingStableInsets, mPendingOutsets, mPendingBackDropFrame, mPendingDisplayCutout, mPendingMergedConfiguration, mSurface); } @Override public int relayout(IWindow window, int seq, WindowManager.LayoutParams attrs, int requestedWidth, int requestedHeight, int viewFlags, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper cutout, MergedConfiguration mergedConfiguration, Surface outSurface) { int res = mService.relayoutWindow(this, window, seq, attrs, requestedWidth, requestedHeight, viewFlags, flags, frameNumber, outFrame, outOverscanInsets, outContentInsets, outVisibleInsets, outStableInsets, outsets, outBackdropFrame, cutout, mergedConfiguration, outSurface); return res; } frameworks/base/services/core/java/com/android/server/wm/WindowManagerService.java\npublic int relayoutWindow(Session session, IWindow client, int seq, LayoutParams attrs, int requestedWidth, int requestedHeight, int viewVisibility, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outOutsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper outCutout, MergedConfiguration mergedConfiguration, Surface outSurface) { result = createSurfaceControl(outSurface, result, win, winAnimator); } private int createSurfaceControl(Surface outSurface, int result, WindowState win,WindowStateAnimator winAnimator) { ... surfaceController = winAnimator.createSurfaceLocked(win.mAttrs.type, win.mOwnerUid); ... surfaceController.getSurface(outSurface); } WindowSurfaceController createSurfaceLocked(int windowType, int ownerUid) { mSurfaceController = new WindowSurfaceController(mSession.mSurfaceSession, attrs.getTitle().toString(), width, height, format, flags, this, windowType, ownerUid); } new WindowSurfaceController() public WindowSurfaceController(SurfaceSession s, String name, int w, int h, int format, int flags, WindowStateAnimator animator, int windowType, int ownerUid) { final SurfaceControl.Builder b = win.makeSurface() .setParent(win.getSurfaceControl()) .setName(name) .setSize(w, h) .setFormat(format) .setFlags(flags) .setMetadata(windowType, ownerUid); mSurfaceControl = b.build(); } /** * Construct a new {@link SurfaceControl} with the set parameters. */ public SurfaceControl build() { return new SurfaceControl(mSession, mName, mWidth, mHeight, mFormat, mFlags, mParent, mWindowType, mOwnerUid); } /** Good practice is to first create the surface with the {@link #HIDDEN} flag * specified, open a transaction, set the surface layer, layer stack, alpha, * and position, call {@link #show} if appropriate, and close the transaction. **/ private SurfaceControl(SurfaceSession session, String name, int w, int h, int format, int flags, SurfaceControl parent, int windowType, int ownerUid) throws OutOfResourcesException, IllegalArgumentException { mNativeObject = nativeCreate(session, name, w, h, format, flags, parent != null ? parent.mNativeObject : 0, windowType, ownerUid); } frameworks/base/core/jni/android_view_SurfaceControl.cpp\nstatic jlong nativeCreate(JNIEnv* env, jclass clazz, jobject sessionObj, jstring nameStr, jint w, jint h, jint format, jint flags, jlong parentObject, jint windowType, jint ownerUid) { ScopedUtfChars name(env, nameStr); //这个client其实就是前面创建的SurfaceComposerClinent  sp\u0026lt;SurfaceComposerClient\u0026gt; client(android_view_SurfaceSession_getClient(env, sessionObj)); SurfaceControl *parent = reinterpret_cast\u0026lt;SurfaceControl*\u0026gt;(parentObject); sp\u0026lt;SurfaceControl\u0026gt; surface; status_t err = client-\u0026gt;createSurfaceChecked( String8(name.c_str()), w, h, format, \u0026amp;surface, flags, parent, windowType, ownerUid); surface-\u0026gt;incStrong((void *)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } status_t SurfaceComposerClient::createSurfaceChecked( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, sp\u0026lt;SurfaceControl\u0026gt;* outSurface, uint32_t flags, SurfaceControl* parent, int32_t windowType, int32_t ownerUid) { sp\u0026lt;SurfaceControl\u0026gt; sur; sp\u0026lt;IBinder\u0026gt; handle; sp\u0026lt;IBinder\u0026gt; parentHandle; sp\u0026lt;IGraphicBufferProducer\u0026gt; gbp; if (parent != nullptr) { parentHandle = parent-\u0026gt;getHandle(); } err = mClient-\u0026gt;createSurface(name, w, h, format, flags, parentHandle, windowType, ownerUid, \u0026amp;handle, \u0026amp;gbp); if (err == NO_ERROR) { *outSurface = new SurfaceControl(this, handle, gbp, true /* owned */); } return err; } status_t Client::createSurface( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, const sp\u0026lt;IBinder\u0026gt;\u0026amp; parentHandle, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp) { //postMessageSync到surfaceFlinger的主线程中处理消息任务，如下:  result = flinger-\u0026gt;createLayer(name, client, w, h, format, flags, windowType, ownerUid, handle, gbp, parent); } createLayer status_t SurfaceFlinger::createLayer( const String8\u0026amp; name, const sp\u0026lt;Client\u0026gt;\u0026amp; client, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* parent) { sp\u0026lt;Layer\u0026gt; layer; String8 uniqueName = getUniqueLayerName(name); switch (flags \u0026amp; ISurfaceComposerClient::eFXSurfaceMask) { case ISurfaceComposerClient::eFXSurfaceNormal: result = createBufferLayer(client, uniqueName, w, h, flags, format, handle, gbp, \u0026amp;layer); break; } result = addClientLayer(client, *handle, *gbp, layer, *parent); return result; } createBufferLayer status_t SurfaceFlinger::createBufferLayer(const sp\u0026lt;Client\u0026gt;\u0026amp; client, const String8\u0026amp; name, uint32_t w, uint32_t h, uint32_t flags, PixelFormat\u0026amp; format, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* outLayer) { // initialize the surfaces  switch (format) { case PIXEL_FORMAT_TRANSPARENT: case PIXEL_FORMAT_TRANSLUCENT: format = PIXEL_FORMAT_RGBA_8888; break; case PIXEL_FORMAT_OPAQUE: format = PIXEL_FORMAT_RGBX_8888; break; } sp\u0026lt;BufferLayer\u0026gt; layer = new BufferLayer(this, client, name, w, h, flags); status_t err = layer-\u0026gt;setBuffers(w, h, format, flags); if (err == NO_ERROR) { *handle = layer-\u0026gt;getHandle(); *gbp = layer-\u0026gt;getProducer(); *outLayer = layer; } return err; } frameworks/native/services/surfaceflinger/BufferLayer.cpp\nBufferLayer::onFirstRef void BufferLayer::onFirstRef() { // Creates a custom BufferQueue for SurfaceFlingerConsumer to use  sp\u0026lt;IGraphicBufferProducer\u0026gt; producer; sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer; BufferQueue::createBufferQueue(\u0026amp;producer, \u0026amp;consumer, true); //MonitoredProducer只是一个装饰类，它实际功能都委托给构造它的参数producer  mProducer = new MonitoredProducer(producer, mFlinger, this); mConsumer = new BufferLayerConsumer(consumer, mFlinger-\u0026gt;getRenderEngine(), mTextureName, this); const sp\u0026lt;const DisplayDevice\u0026gt; hw(mFlinger-\u0026gt;getDefaultDisplayDevice()); updateTransformHint(hw); } frameworks/native/libs/gui/BufferQueue.cpp\nBufferQueue::createBufferQueue void BufferQueue::createBufferQueue(sp\u0026lt;IGraphicBufferProducer\u0026gt;* outProducer, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* outConsumer, bool consumerIsSurfaceFlinger) { sp\u0026lt;BufferQueueCore\u0026gt; core(new BufferQueueCore()); sp\u0026lt;IGraphicBufferProducer\u0026gt; producer(new BufferQueueProducer(core, consumerIsSurfaceFlinger)); sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer(new BufferQueueConsumer(core)); *outProducer = producer; *outConsumer = consumer; } frameworks/native/libs/ui/include/ui/BufferQueueDefs.h\nNUM_BUFFER_SLOTS namespace android { namespace BufferQueueDefs { // BufferQueue will keep track of at most this value of buffers.  // Attempts at runtime to increase the number of buffers past this  // will fail.  static constexpr int NUM_BUFFER_SLOTS = 64; } // namespace BufferQueueDefs } // namespace android  frameworks/native/libs/gui/include/gui/BufferQueueCore.h\nBufferQueueCore // mQueue is a FIFO of queued buffers used in synchronous mode.  Fifo mQueue; // mFreeSlots contains all of the slots which are FREE and do not currently  // have a buffer attached.  std::set\u0026lt;int\u0026gt; mFreeSlots; // mFreeBuffers contains all of the slots which are FREE and currently have  // a buffer attached.  std::list\u0026lt;int\u0026gt; mFreeBuffers; // mConsumerListener is used to notify the connected consumer of  // asynchronous events that it may wish to react to. It is initially  // set to NULL and is written by consumerConnect and consumerDisconnect.  sp\u0026lt;IConsumerListener\u0026gt; mConsumerListener; frameworks/native/libs/gui/BufferQueueProducer.cpp\nBufferQueueProducer class BufferQueueProducer : public BnGraphicBufferProducer, private IBinder::DeathRecipient { frameworks/native/libs/gui/include/gui/BufferQueueConsumer.h\nBufferQueueConsumer class BufferQueueConsumer : public BnGraphicBufferConsumer { // connect connects a consumer to the BufferQueue. Only one  // consumer may be connected, and when that consumer disconnects the  // BufferQueue is placed into the \u0026#34;abandoned\u0026#34; state, causing most  // interactions with the BufferQueue by the producer to fail.  // controlledByApp indicates whether the consumer is controlled by  // the application.  //  // consumerListener may not be NULL.  virtual status_t connect(const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp); } getSurface void getSurface(Surface outSurface) { outSurface.copyFrom(mSurfaceControl); } copyFrom /** * Copy another surface to this one. This surface now holds a reference * to the same data as the original surface, and is -not- the owner. * This is for use by the window manager when returning a window surface * back from a client, converting it from the representation being managed * by the window manager to the representation the client uses to draw * in to it. * * @param other {@link SurfaceControl} to copy from. * */ public void copyFrom(SurfaceControl other) { long surfaceControlPtr = other.mNativeObject; long newNativeObject = nativeGetFromSurfaceControl(surfaceControlPtr); synchronized (mLock) { if (mNativeObject != 0) { nativeRelease(mNativeObject); } setNativeObjectLocked(newNativeObject); } } frameworks/base/core/jni/android_view_Surface.cpp\nstatic jlong nativeGetFromSurfaceControl(JNIEnv* env, jclass clazz, jlong surfaceControlNativeObj) { /* * This is used by the WindowManagerService just after constructing * a Surface and is necessary for returning the Surface reference to * the caller. At this point, we should only have a SurfaceControl. */ sp\u0026lt;SurfaceControl\u0026gt; ctrl(reinterpret_cast\u0026lt;SurfaceControl *\u0026gt;(surfaceControlNativeObj)); sp\u0026lt;Surface\u0026gt; surface(ctrl-\u0026gt;getSurface()); if (surface != NULL) { surface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); } return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } frameworks/native/libs/gui/SurfaceControl.cpp\nsp\u0026lt;Surface\u0026gt; SurfaceControl::getSurface() const { Mutex::Autolock _l(mLock); if (mSurfaceData == 0) { return generateSurfaceLocked(); } return mSurfaceData; } sp\u0026lt;Surface\u0026gt; SurfaceControl::generateSurfaceLocked() const { // This surface is always consumed by SurfaceFlinger, so the  // producerControlledByApp value doesn\u0026#39;t matter; using false.  //这个mGraphicBufferProducer其实就是上面分析的BufferQueueProducer  mSurfaceData = new Surface(mGraphicBufferProducer, false); return mSurfaceData; } Surface::Surface(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp; bufferProducer, bool controlledByApp) : mGraphicBufferProducer(bufferProducer), mAttachInfo.mThreadedRenderer.initialize(mSurface) /** * Initializes the threaded renderer for the specified surface. * @param surface The surface to render * @return True if the initialization was successful, false otherwise. */ boolean initialize(Surface surface) throws OutOfResourcesException { updateEnabledState(surface); nInitialize(mNativeProxy, surface); return status; } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nstatic void android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;Surface\u0026gt; surface = android_view_Surface_getSurface(env, jsurface); proxy-\u0026gt;initialize(surface); } RenderProxy::initialize void RenderProxy::initialize(const sp\u0026lt;Surface\u0026gt;\u0026amp; surface) { mRenderThread.queue().post( [ this, surf = surface ]() mutable { mContext-\u0026gt;setSurface(std::move(surf)); }); } CanvasContext::setSurface void CanvasContext::setSurface(sp\u0026lt;Surface\u0026gt;\u0026amp;\u0026amp; surface) { mNativeSurface = std::move(surface); ColorMode colorMode = mWideColorGamut ? ColorMode::WideColorGamut : ColorMode::Srgb; bool hasSurface = mRenderPipeline-\u0026gt;setSurface(mNativeSurface.get(), mSwapBehavior, colorMode); } frameworks/base/libs/hwui/renderthread/OpenGLPipeline.cpp\nOpenGLPipeline::setSurface bool OpenGLPipeline::setSurface(Surface* surface, SwapBehavior swapBehavior, ColorMode colorMode) { if (surface) { const bool wideColorGamut = colorMode == ColorMode::WideColorGamut; mEglSurface = mEglManager.createSurface(surface, wideColorGamut); } return false; } frameworks/base/libs/hwui/renderthread/EglManager.cpp\nEglManager::createSurface EGLSurface EglManager::createSurface(EGLNativeWindowType window, bool wideColorGamut) { initialize(); EGLSurface surface = eglCreateWindowSurface( mEglDisplay, wideColorGamut ? mEglConfigWideGamut : mEglConfig, window, attribs); return surface; } mSurface.allocateBuffers /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } static void nativeAllocateBuffers(JNIEnv* /* env */ , jclass /* clazz */, jlong nativeObject) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } surface-\u0026gt;allocateBuffers(); } Surface::allocateBuffers void Surface::allocateBuffers() { uint32_t reqWidth = mReqWidth ? mReqWidth : mUserWidth; uint32_t reqHeight = mReqHeight ? mReqHeight : mUserHeight; mGraphicBufferProducer-\u0026gt;allocateBuffers(reqWidth, reqHeight, mReqFormat, mReqUsage); } BufferQueueProducer::allocateBuffers void BufferQueueProducer::allocateBuffers(uint32_t width, uint32_t height, PixelFormat format, uint64_t usage) { Vector\u0026lt;sp\u0026lt;GraphicBuffer\u0026gt;\u0026gt; buffers; for (size_t i = 0; i \u0026lt; newBufferCount; ++i) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( allocWidth, allocHeight, allocFormat, BQ_LAYER_COUNT, allocUsage, allocName); status_t result = graphicBuffer-\u0026gt;initCheck(); buffers.push_back(graphicBuffer); } } frameworks/native/libs/ui/GraphicBuffer.cpp\nnew GraphicBuffer GraphicBuffer::GraphicBuffer(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t usage, std::string requestorName) : GraphicBuffer() { mInitCheck = initWithSize(inWidth, inHeight, inFormat, inLayerCount, usage, std::move(requestorName)); } status_t GraphicBuffer::initWithSize(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t inUsage, std::string requestorName) { GraphicBufferAllocator\u0026amp; allocator = GraphicBufferAllocator::get(); uint32_t outStride = 0; status_t err = allocator.allocate(inWidth, inHeight, inFormat, inLayerCount, inUsage, \u0026amp;handle, \u0026amp;outStride, mId, std::move(requestorName)); return err; } frameworks/native/libs/ui/GraphicBufferAllocator.cpp\nGraphicBufferAllocator GraphicBufferMapper\u0026amp; mMapper; const std::unique_ptr\u0026lt;const Gralloc2::Allocator\u0026gt; mAllocator; GraphicBufferAllocator::allocate status_t GraphicBufferAllocator::allocate(uint32_t width, uint32_t height, PixelFormat format, uint32_t layerCount, uint64_t usage, buffer_handle_t* handle, uint32_t* stride, uint64_t /*graphicBufferId*/, std::string requestorName) { Gralloc2::IMapper::BufferDescriptorInfo info = {}; info.width = width; info.height = height; info.layerCount = layerCount; info.format = static_cast\u0026lt;Gralloc2::PixelFormat\u0026gt;(format); info.usage = usage; Gralloc2::Error error = mAllocator-\u0026gt;allocate(info, stride, handle); } frameworks/native/libs/ui/include/ui/Gralloc2.h\n// A wrapper to IAllocator class Allocator { sp\u0026lt;IAllocator\u0026gt; mAllocator } Allocator::Allocator(const Mapper\u0026amp; mapper) : mMapper(mapper) { mAllocator = IAllocator::getService(); } Allocator::allocate Error Allocator::allocate(BufferDescriptor descriptor, uint32_t count, uint32_t* outStride, buffer_handle_t* outBufferHandles) const { Error error; auto ret = mAllocator-\u0026gt;allocate(descriptor, count, [\u0026amp;](const auto\u0026amp; tmpError, const auto\u0026amp; tmpStride, const auto\u0026amp; tmpBuffers) { error = tmpError; if (tmpError != Error::NONE) { return; } // import buffers  for (uint32_t i = 0; i \u0026lt; count; i++) { error = mMapper.importBuffer(tmpBuffers[i], \u0026amp;outBufferHandles[i]); if (error != Error::NONE) { for (uint32_t j = 0; j \u0026lt; i; j++) { mMapper.freeBuffer(outBufferHandles[j]); outBufferHandles[j] = nullptr; } return; } } *outStride = tmpStride; }); // make sure the kernel driver sees BC_FREE_BUFFER and closes the fds now  hardware::IPCThreadState::self()-\u0026gt;flushCommands(); return (ret.isOk()) ? error : kTransactionError; } hardware/interfaces/graphics/allocator/2.0/IAllocator.hal\ninterface IAllocator { /** * Allocates buffers with the properties specified by the descriptor. * * @param descriptor specifies the properties of the buffers to allocate. * @param count is the number of buffers to allocate. * @return error is NONE upon success. Otherwise, * BAD_DESCRIPTOR when the descriptor is invalid. * NO_RESOURCES when the allocation cannot be fulfilled at this * time. * UNSUPPORTED when any of the property encoded in the descriptor * is not supported. * @return stride is the number of pixels between two consecutive rows of * the buffers, when the concept of consecutive rows is defined. * Otherwise, it has no meaning. * @return buffers is an array of raw handles to the newly allocated * buffers. */ @entry @exit @callflow(next=\u0026#34;*\u0026#34;) allocate(BufferDescriptor descriptor, uint32_t count) generates (Error error, uint32_t stride, vec\u0026lt;handle\u0026gt; buffers); performDraw private boolean draw(boolean fullRedrawNeeded) { Surface surface = mSurface; if (!surface.isValid()) { return false; } if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { if (mAttachInfo.mThreadedRenderer != null \u0026amp;\u0026amp; mAttachInfo.mThreadedRenderer.isEnabled()) { mAttachInfo.mThreadedRenderer.draw(mView, mAttachInfo, this, callback); } else { drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty, surfaceInsets) } } } drawSoftware /** * @return true if drawing was successful, false if an error occurred */ private boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty, Rect surfaceInsets) { // Draw with software renderer.  final Canvas canvas; canvas = mSurface.lockCanvas(dirty); ...... mView.draw(canvas); ...... surface.unlockCanvasAndPost(canvas); } lockCanvas public Canvas lockCanvas(Rect inOutDirty) throws Surface.OutOfResourcesException, IllegalArgumentException { synchronized (mLock) { mLockedObject = nativeLockCanvas(mNativeObject, mCanvas, inOutDirty); return mCanvas; } } static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ANativeWindow_Buffer outBuffer; status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType, GraphicsJNI::defaultColorSpace()); SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits); } Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); if (dirtyRectPtr) { nativeCanvas-\u0026gt;clipRect(dirtyRect.left, dirtyRect.top, dirtyRect.right, dirtyRect.bottom, SkClipOp::kIntersect); } // Create another reference to the surface and return it. This reference  // should be passed to nativeUnlockCanvasAndPost in place of mNativeObject,  // because the latter could be replaced while the surface is locked.  sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } Surface::lock status_t Surface::lock(ANativeWindow_Buffer* outBuffer, ARect* inOutDirtyBounds) { ANativeWindowBuffer* out; int fenceFd = -1; status_t err = dequeueBuffer(\u0026amp;out, \u0026amp;fenceFd); sp\u0026lt;GraphicBuffer\u0026gt; backBuffer(GraphicBuffer::getSelf(out)); status_t res = backBuffer-\u0026gt;lockAsync( GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN, newDirtyRegion.bounds(), \u0026amp;vaddr, fenceFd); mLockedBuffer = backBuffer; outBuffer-\u0026gt;width = backBuffer-\u0026gt;width; outBuffer-\u0026gt;height = backBuffer-\u0026gt;height; outBuffer-\u0026gt;stride = backBuffer-\u0026gt;stride; outBuffer-\u0026gt;format = backBuffer-\u0026gt;format; outBuffer-\u0026gt;bits = vaddr; } Surface::dequeueBuffer int Surface::dequeueBuffer(android_native_buffer_t** buffer, int* fenceFd) { status_t result = mGraphicBufferProducer-\u0026gt;dequeueBuffer(\u0026amp;buf, \u0026amp;fence, reqWidth, reqHeight, reqFormat, reqUsage, \u0026amp;mBufferAge, enableFrameTimestamps ? \u0026amp;frameTimestamps : nullptr); sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; gbuf(mSlots[buf].buffer); if ((result \u0026amp; IGraphicBufferProducer::BUFFER_NEEDS_REALLOCATION) || gbuf == nullptr) { result = mGraphicBufferProducer-\u0026gt;requestBuffer(buf, \u0026amp;gbuf); } *buffer = gbuf.get(); return OK; } dequeuebuffer\nrequestbuffer\ndraw nativeUnlockCanvasAndPost static void nativeUnlockCanvasAndPost(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } // detach the canvas from the surface  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); nativeCanvas-\u0026gt;setBitmap(SkBitmap()); // unlock surface  status_t err = surface-\u0026gt;unlockAndPost(); } mAttachInfo.mThreadedRenderer.draw硬件绘制 硬件加速绘制\nBufferQueueProducer::dequeueBuffer status_t BufferQueueProducer::dequeueBuffer(int* outSlot, sp\u0026lt;android::Fence\u0026gt;* outFence, uint32_t width, uint32_t height, PixelFormat format, uint64_t usage, uint64_t* outBufferAge, FrameEventHistoryDelta* outTimestamps) { int found = BufferItem::INVALID_BUFFER_SLOT; while (found == BufferItem::INVALID_BUFFER_SLOT) { status_t status = waitForFreeSlotThenRelock(FreeSlotCaller::Dequeue, \u0026amp;found); } const sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; buffer(mSlots[found].mGraphicBuffer); *outSlot = found; if ((buffer == NULL) || buffer-\u0026gt;needsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { returnFlags |= BUFFER_NEEDS_REALLOCATION; } if (returnFlags \u0026amp; BUFFER_NEEDS_REALLOCATION) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( width, height, format, BQ_LAYER_COUNT, usage, {mConsumerName.string(), mConsumerName.size()}); status_t error = graphicBuffer-\u0026gt;initCheck(); } } waitForFreeSlotThenRelock status_t BufferQueueProducer::waitForFreeSlotThenRelock(FreeSlotCaller caller, int* found) const { // If we disconnect and reconnect quickly, we can be in a state where  // our slots are empty but we have many buffers in the queue. This can  // cause us to run out of memory if we outrun the consumer. Wait here if  // it looks like we have too many buffers queued up.  const int maxBufferCount = mCore-\u0026gt;getMaxBufferCountLocked(); bool tooManyBuffers = mCore-\u0026gt;mQueue.size() \u0026gt; static_cast\u0026lt;size_t\u0026gt;(maxBufferCount); if (tooManyBuffers) { BQ_LOGV(\u0026#34;%s: queue size is %zu, waiting\u0026#34;, callerString, mCore-\u0026gt;mQueue.size()); } else { // If in shared buffer mode and a shared buffer exists, always  // return it.  if (mCore-\u0026gt;mSharedBufferMode \u0026amp;\u0026amp; mCore-\u0026gt;mSharedBufferSlot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = mCore-\u0026gt;mSharedBufferSlot; } else { if (caller == FreeSlotCaller::Dequeue) { // If we\u0026#39;re calling this from dequeue, prefer free buffers  int slot = getFreeBufferLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else if (mCore-\u0026gt;mAllowAllocation) { *found = getFreeSlotLocked(); } } else { // If we\u0026#39;re calling this from attach, prefer free slots  int slot = getFreeSlotLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else { *found = getFreeBufferLocked(); } } } } } getFreeBufferLocked int BufferQueueProducer::getFreeBufferLocked() const { if (mCore-\u0026gt;mFreeBuffers.empty()) { return BufferQueueCore::INVALID_BUFFER_SLOT; } int slot = mCore-\u0026gt;mFreeBuffers.front(); mCore-\u0026gt;mFreeBuffers.pop_front(); return slot; } BufferQueueProducer::requestBuffer status_t BufferQueueProducer::requestBuffer(int slot, sp\u0026lt;GraphicBuffer\u0026gt;* buf) { mSlots[slot].mRequestBufferCalled = true; *buf = mSlots[slot].mGraphicBuffer; } 其他类结构参考 ViewRootImpl // These can be accessed by any thread, must be protected with a lock.  // Surface can never be reassigned or cleared (use Surface.clear()).  public final Surface mSurface = new Surface(); BufferQueueConsumer status_t BufferQueueConsumer::connect( const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp) { mCore-\u0026gt;mConsumerListener = consumerListener; mCore-\u0026gt;mConsumerControlledByApp = controlledByApp; return NO_ERROR; } Surface.java /** * Handle onto a raw buffer that is being managed by the screen compositor. * * \u0026lt;p\u0026gt;A Surface is generally created by or from a consumer of image buffers (such as a * {@link android.graphics.SurfaceTexture}, {@link android.media.MediaRecorder}, or * {@link android.renderscript.Allocation}), and is handed to some kind of producer (such as * {@link android.opengl.EGL14#eglCreateWindowSurface(android.opengl.EGLDisplay,android.opengl.EGLConfig,java.lang.Object,int[],int) OpenGL}, * {@link android.media.MediaPlayer#setSurface MediaPlayer}, or * {@link android.hardware.camera2.CameraDevice#createCaptureSession CameraDevice}) to draw * into.\u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Note:\u0026lt;/strong\u0026gt; A Surface acts like a * {@link java.lang.ref.WeakReference weak reference} to the consumer it is associated with. By * itself it will not keep its parent consumer from being reclaimed.\u0026lt;/p\u0026gt; */ public class Surface implements Parcelable { } frameworks/native/libs/gui/Surface.cpp\nSurface.cpp struct BufferSlot // mSurfaceTexture is the interface to the surface texture server. All  // operations on the surface texture client ultimately translate into  // interactions with the server using this interface.  sp\u0026lt;IGraphicBufferProducer\u0026gt; mGraphicBufferProducer; struct BufferSlot { sp\u0026lt;GraphicBuffer\u0026gt; buffer; Region dirtyRegion; }; // mSlots stores the buffers that have been allocated for each buffer slot.  // It is initialized to null pointers, and gets filled in with the result of  // IGraphicBufferProducer::requestBuffer when the client dequeues a buffer from a  // slot that has not yet been used. The buffer allocated to a slot will also  // be replaced if the requested buffer usage or geometry differs from that  // of the buffer allocated to a slot.  BufferSlot mSlots[NUM_BUFFER_SLOTS]; AttachInfo /** A set of information given to a view when it is attached to its parent window. */ final static class AttachInfo { } frameworks/base/libs/hwui/FrameInfo.h\nFrameInfo FrameInfoIndex enum class FrameInfoIndex { Flags = 0, IntendedVsync, Vsync, OldestInputEvent, NewestInputEvent, HandleInputStart, AnimationStart, PerformTraversalsStart, DrawStart, // End of UI frame info  SyncQueued, SyncStart, IssueDrawCommandsStart, SwapBuffers, FrameCompleted, DequeueBufferDuration, QueueBufferDuration, // Must be the last value!  // Also must be kept in sync with FrameMetrics.java#FRAME_STATS_COUNT  NumIndexes }; Looper wake void Looper::wake() { uint64_t inc = 1; ssize_t nWrite = TEMP_FAILURE_RETRY(write(mWakeEventFd, \u0026amp;inc, sizeof(uint64_t))); if (nWrite != sizeof(uint64_t)) { if (errno != EAGAIN) { LOG_ALWAYS_FATAL(\u0026#34;Could not write wake signal to fd %d: %s\u0026#34;, mWakeEventFd, strerror(errno)); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/",
	"title": "虚拟机",
	"tags": [],
	"description": "",
	"content": "虚拟机 探索总结虚拟机知识\n alloc_gc    Alloc     AllocRelated     GC     GC_ConcurrentCopying     GC_MarkCompact     GC_MS_CMS     GC_Semi_Space     Runtime_VisitRoots     Space      ART_Lock     jni    C启动Java     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常     解释执行7_0      启动流程    ART启动流程      基础数据结构     混合编译_运行    JVM_JIT     混合编译_运行      类加载    Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层      类编译    dex2oat      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%99%9A%E6%8B%9F%E6%9C%BA/jni/%E8%A7%A3%E9%87%8A%E6%89%A7%E8%A1%8C7_0/",
	"title": "解释执行7_0",
	"tags": [],
	"description": "",
	"content": "quick_entrypoints_x86.S art_quick_invoke_stub /*这段注释来自于源码，它展示了调用art_quick_invoke_stub函数时，相关参数在栈中的布局 * Quick invocation stub (non-static). * On entry: * [sp] = return address 返回值地址，这是由函数调用指令自动压入栈的 * [sp + 4] = method pointer 代表方法C的ArtMethod对象 * [sp + 8] = argument array or null for no argument methods * [sp + 12] = size of argument array in bytes * [sp + 16] = (managed) thread pointer 这是代表调用线程的Thread对象 * [sp + 20] = JValue* result * [sp + 24] = shorty */ DEFINE_FUNCTION art_quick_invoke_stub #定义art_quick_invoke_stub函数  PUSH ebp // save ebp PUSH ebx // save ebx PUSH esi // save esi PUSH edi // save edi ...... //处理浮点寄存器、扩展栈空间等 //下面的循环用于从args中拷贝参数到栈上。此处保留代码中原有的注释 movl 28(%ebp), %ecx // ECX = size of args movl 24(%ebp), %esi // ESI = argument array leal 4(%esp), %edi // EDI = just after Method* in stack arguments rep movsb // while (ecx--) { *edi++ = *esi++ } ...... //略过其他代码 .Lgpr_setup_finished: #至此，参数已经准备好。下面将进入ArtMethod对象的机器码入口  mov 20(%ebp), %eax //EBP+20处保存着ArtMethod* C对象，将其拷贝 到EAX中 #跳转到这个ArtMethod对象机器码入口对应的地方。main  call *ART_METHOD_QUICK_CODE_OFFSET_32(%eax) ..... //恢复栈，设置返回值到result中 ret END_FUNCTION art_quick_invoke_stub art_quick_to_interpreter_bridge #DEFINE_FUNCTION是一个宏，用于定义一个函数。下面将定义 #art_quick_to_interpreter_bridge函数 DEFINE_FUNCTION art_quick_to_interpreter_bridge #下面这个宏在10.1.3.1.3节介绍过了，执行其中的汇编指令后，栈的布局将变成如图10-4所示的样子。  SETUP_REFS_AND_ARGS_CALLEE_SAVE_FRAME ebx, ebx mov %esp, %edx #将ESP保存到EDX中  PUSH eax #EAX入栈，EAX寄存器的值代表被调用方法的ArtMethod对象。  PUSH edx #EDX入栈，  pushl %fs:THREAD_SELF_OFFSET #获取当前线程的Thread对象，并压入栈中  PUSH eax #EAX入栈。  call SYMBOL(artQuickToInterpreterBridge) #main  #调用目标函数  #参数出栈，恢复到SETUP_REFS_AND_ARGS_CALLEE_SAVE_FRAME执行后的栈状态  addl LITERAL(16), %esp ...... #下面三行代码用于处理返回值，xmm为浮点寄存，64位长，而eax，edx为32位长。  #下面这三行代码执行往后，xmm0的低32位的值来自EAX，高32位的值来自EDX。  movd %eax, %xmm0 movd %edx, %xmm1 punpckldq %xmm1, %xmm0 #将xmm1和xmm0低32位的值组合起来存储到xmm0中。  #调整栈顶位置  addl LITERAL(48), %esp POP ebp POP esi POP edi RETURN_OR_DELIVER_PENDING_EXCEPTION #函数返回或抛异常（10.6节将介绍它）,main END_FUNCTION art_quick_to_interpreter_bridge quick_trampoline_entrypoints.cc artQuickToInterpreterBridge extern \u0026#34;C\u0026#34; uint64_t artQuickToInterpreterBridge(ArtMethod* method, Thread* self, ArtMethod** sp) { //参数method代表当前被调用的Java方法，我们用图10-7中的ArtMethod* B表示它  ScopedQuickEntrypointChecks sqec(self); JValue tmp_value; /*PopStackedShadowFrame和Thread对栈的管理有关。此处假设是从机器码跳转到解释执行模式， 并且不是HDeoptimize的情况，那么，该函数返回值deopt_frame为nullptr。 */ ShadowFrame* deopt_frame = self-\u0026gt;PopStackedShadowFrame( StackedShadowFrameType::kSingleFrameDeoptimizationShadowFrame, false); ManagedStack fragment; //重要：构造一个ManagedStack对象。  uint32_t shorty_len = 0; //如果不是代理方法的话，non_proxy_method就是ArtMethod* B本身。  ArtMethod* non_proxy_method = method-\u0026gt;GetInterfaceMethodIfProxy(sizeof(void*)); const DexFile::CodeItem* code_item = non_proxy_method-\u0026gt;GetCodeItem(); const char* shorty = non_proxy_method-\u0026gt;GetShorty(\u0026amp;shorty_len); JValue result; //存储方法调用的返回值  if (deopt_frame != nullptr) { ..... //和HDeoptimize有关，后续章节再介绍它  } else { const char* old_cause = ......; uint16_t num_regs = code_item-\u0026gt;registers_size_; //创建代表ArtMethod B的栈帧对象ShawFrame。注意，它的link_取值为nullptr，  //dex_pc_取值为0  ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, /* link */ nullptr, method, /* dex pc */ 0); ShadowFrame* shadow_frame = shadow_frame_unique_ptr.get(); size_t first_arg_reg = code_item-\u0026gt;registers_size_ - code_item-\u0026gt;ins_size_; //借助BuildQuickShadowFrameVisitor将调用参数放到shadow_frame对象中  BuildQuickShadowFrameVisitor shadow_frame_builder(sp, method-\u0026gt;IsStatic(), shorty, shorty_len, shadow_frame, first_arg_reg); shadow_frame_builder.VisitArguments(); //判断ArtMethod* B所属的类是否已经初始化  const bool needs_initialization = method-\u0026gt;IsStatic() \u0026amp;\u0026amp; !method-\u0026gt;GetDeclaringClass()-\u0026gt;IsInitialized(); //重要：下面两行代码将fragment和shadow_frame放到Thread类对应的成员变量中去处理  //我们后续再讨论这部分内容  self-\u0026gt;PushManagedStackFragment(\u0026amp;fragment); self-\u0026gt;PushShadowFrame(shadow_frame); ...... //如果ArtMethod B所属类没有初始化，则先初始化它。类初始化就是调用ClassLinker的Ensure-  //Initialized函数  if (needs_initialization) { StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Class\u0026gt; h_class(hs.NewHandle( shadow_frame-\u0026gt;GetMethod()-\u0026gt;GetDeclaringClass())); if (!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized( self, h_class, true, true)) {......} } //解释执行的入口函数  result = interpreter::EnterInterpreterFromEntryPoint(self, code_item, shadow_frame);//main  } //和Thread对栈的管理有关  self-\u0026gt;PopManagedStackFragment(fragment); //根据sp的位置找到本方法的调用者，以图10-7为例，即找到ArtMethod* A，是它调用了本方  //法（对应为ArtMethod* B）。  ArtMethod* caller = QuickArgumentVisitor::GetCallingMethod(sp); if (UNLIKELY(Dbg::IsForcedInterpreterNeededForUpcall(self, caller))) { //和HDeoptimize有关  //和HDeoptimize有关  self-\u0026gt;PushDeoptimizationContext(result, shorty[0] == \u0026#39;L\u0026#39;, /* from_code */ false, self-\u0026gt;GetException()); self-\u0026gt;SetException(Thread::GetDeoptimizationException()); } return result.GetJ(); //artQuickToInterpreterBridge返回  } } interpreter.h/cc EnterInterpreterFromEntryPoint extern JValue EnterInterpreterFromEntryPoint( Thread* self, //代表调用线程的Thread对象  const DexFile::CodeItem* code_item, //方法B的dex指令码内容  ShadowFrame* shadow_frame //方法B所需的参数 ); JValue EnterInterpreterFromEntryPoint(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame* shadow_frame) { ...... //下面这段代码和JIT有关，相关知识见本章后续对JIT的介绍  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;NotifyCompiledCodeToInterpreterTransition(self, shadow_frame-\u0026gt;GetMethod()); } //关键函数  return Execute(self, code_item, *shadow_frame, JValue());//main } Execute static inline JValue Execute(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame\u0026amp; shadow_frame,JValue result_register, bool stay_in_interpreter = false) { /*注意stay_in_interpreter参数，它表示是否强制使用解释执行模式。默认为false，它表示如果 方法B存在jit编译得到的机器码，则转到jit去执行。 */ /*下面这个if条件的判断很有深意。我们在本章解释图10-5里ShadowFrame成员变量时曾说过，如果 是HDeoptimize的情况，ShadowFrame的dex_pc_不是0（这表示有一部分指令以机器码方式执 行）。如果dex_pc_为0的话，则表示该方法从一开始就将以解释方式执行。我们称这种情况为纯解 释执行的方法，此时，我们就需要检查它是否存在JIT的情况。 */ if (LIKELY(shadow_frame.GetDexPC() == 0)) { instrumentation::Instrumentation* instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); ArtMethod *method = shadow_frame.GetMethod(); if (UNLIKELY(instrumentation-\u0026gt;HasMethodEntryListeners())) { instrumentation-\u0026gt;MethodEnterEvent(self, shadow_frame.GetThisObject(code_item-\u0026gt;ins_size_), method, 0); } //判断这个需要纯解释执行的方法是否经过JIT编译了  if (!stay_in_interpreter) { jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;MethodEntered(self, shadow_frame.GetMethod()); if (jit-\u0026gt;CanInvokeCompiledCode(method)) { ...... //转入jit编译的机器码去执行并返回结果  } } } } //dex_pc_是否为0判断结束  ...... //下面是解释执行的处理逻辑  ArtMethod* method = shadow_frame.GetMethod(); //transaction_active和dex2oat编译逻辑有关，完整虚拟机运行时候返回false  bool transaction_active = Runtime::Current()-\u0026gt;IsActiveTransaction(); //是否略过Access检查，即判断是否有权限执行本方法。大部分情况下该if条件是满足的  if (LIKELY(method-\u0026gt;SkipAccessChecks())) { /*main,在ART虚拟机中，解释执行的实现方式有三种，由kInterpreterImplKind取值来控制： （1）kMterpImplKind：根据不同CPU平台，采用对应汇编语言编写的，基于goto逻辑的实现。 这也是kInterpreterImplKind的默认取值。 （2）kSwitchImplKind：由C++编写，基于switch/case逻辑实现。 （3）kComputedGotoImplKind：由C++编写，基于goto逻辑实现。根据代码中的注释所述， 这种实现的代码不支持使用clang编译器。 这三种实现的思路大同小异，首选自然是速度更快的汇编处理kMterpImplKind模式。 为了展示一些dex指令的处理逻辑，笔者拟讨论kSwtichImplKind模式的相关代码。 */ if (kInterpreterImplKind == kMterpImplKind) { if (transaction_active) {.....} else if (UNLIKELY(!Runtime::Current()-\u0026gt;IsStarted())) { ...... //针对dex2oat的情况  } else { ...... //ExecuteMterpImpl函数的定义由汇编代码实现,main  bool returned = ExecuteMterpImpl(self, code_item, \u0026amp;shadow_frame, \u0026amp;result_register); } } else if (kInterpreterImplKind == kSwitchImplKind) { if (transaction_active) {...... } else { //kSwitchImplKind的入口函数。注意，最后一个参数的值为false。main  return ExecuteSwitchImpl\u0026lt;false, false\u0026gt;(self, code_item, shadow_frame, result_register, false); } } else {　//kInterpreterImplKind取值为kComputedGotoImplKind的情况,main  if (transaction_active) {......} else { return ExecuteGotoImpl\u0026lt;false, false\u0026gt;(self, code_item, shadow_frame, result_register); } } } ...... } interpreter_switch_impl.cc ExecuteSwitchImpl template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; JValue ExecuteSwitchImpl(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame\u0026amp; shadow_frame, JValue result_register, bool interpret_one_instruction) { //注意上文Execute代码中调用ExeucteSwitchImpl时设置的最后一个参数为false，所以此处inter-  //pret_one_instruction为false。  constexpr bool do_assignability_check = do_access_check; ...... //dex_pc指向要执行的dex指令  uint32_t dex_pc = shadow_frame.GetDexPC(); const auto* const instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); //insns代表方法B的dex指令码数组  const uint16_t* const insns = code_item-\u0026gt;insns_; const Instruction* inst = Instruction::At(insns + dex_pc); uint16_t inst_data; //方法B对应的ArtMethod对象  ArtMethod* method = shadow_frame.GetMethod(); jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); ...... do { //遍历方法B的dex指令码数组，main  dex_pc = inst-\u0026gt;GetDexPc(insns); shadow_frame.SetDexPC(dex_pc); ...... inst_data = inst-\u0026gt;Fetch16(0); /*main,借助switch/case，针对每一种dex指令进行处理。注意，处理每种dex指令前，都有一个PREAMBLE 宏，该宏就是调用instrumentation的DexPcMovedEvent函数。10.5节将单独介绍和instrumentation相关的内容。 */ switch (inst-\u0026gt;Opcode(inst_data)) {//main  case Instruction::NOP: //处理NOP指令  PREAMBLE(); //Next_1xx是Instruction类的成员函数，用于跳过本指令的参数，使之指向下一条  //指令的开头。1xx是dex指令码存储格式的一种。读者可不用管它。  inst = inst-\u0026gt;Next_1xx(); break; ...... //其他dex指令码的处理  case Instruction::INVOKE_DIRECT: { //invoke-direct指令码的处理  PREAMBLE(); //DoInvoke的分析见下文。main  bool success = DoInvoke\u0026lt;kDirect, false, do_access_check\u0026gt;( self, shadow_frame, inst, inst_data, \u0026amp;result_register); /*Next_3xx也是Instruction类的成员函数。下面的POSSIBLY_HANDLE_PENDING_EXCEPTION 是一个宏，如果有异常发生，则进入异常处理，否则将调用Next_3xx函数使得inst指向 下一条指令。整个解释执行的流程就这样循环直到所有指令码处理完毕。main */ POSSIBLY_HANDLE_PENDING_EXCEPTION(!success, Next_3xx); break; } ...... } } while (!interpret_one_instruction); //循环  //记录dex指令执行的位置并更新到shadow_frame中  shadow_frame.SetDexPC(inst-\u0026gt;GetDexPc(insns)); return result_register; } interpreter_common.h/cc DoInvoke template\u0026lt;InvokeType type, bool is_range, bool do_access_check\u0026gt; static inline bool DoInvoke(Thread* self, ShadowFrame\u0026amp; shadow_frame, const Instruction* inst, uint16_t inst_data, JValue* result) { /*先观察DoInvoke的参数： （1）模板参数type：指明调用类型，比如kStatic、kDirect等。 （2）模板参数is_range：如果该方法有多于五个参数的话，则需要使用invoke-xxx-range这样 的指令。 （3）模板参数do_access_check：是否需要访问检查。即检查是否有权限调用invoke指令的目标 方法C。 （4）shadow_frame：方法B对应的ShadowFrame对象。 （5）inst：invoke指令对应的Instruction对象。 （6）inst_data：invoke指令对应的参数。 （7）result：用于存储方法C执行的结果。 */ //method_idx为方法C在dex文件里method_ids数组中的索引  const uint32_t method_idx = (is_range) ? inst-\u0026gt;VRegB_3rc() : inst-\u0026gt;VRegB_35c(); //找到方法C对应的对象。它作为参数存储在方法B的ShawdowFrame对象中。  const uint32_t vregC = (is_range) ? inst-\u0026gt;VRegC_3rc() : inst-\u0026gt;VRegC_35c(); Object* receiver = (type == kStatic) ? nullptr : shadow_frame.GetVRegReference(vregC); //sf_method代表ArtMethod* B。  ArtMethod* sf_method = shadow_frame.GetMethod(); /*FindMethodFromCode用于查找代表目标方法C对应的ArtMethod对象，即ArtMethod* C。其内 部会根据do_access_check的情况检查方法B是否有权限调用方法C。 注意，FindMethodFromCode函数是根据不同调用类型（kStatic、kDirect、kVirtual、kSuper、 kInterface）以找到对应的ArtMethod对象的关键代码。这部分内容请读者自行阅读。*/ ArtMethod* const called_method = FindMethodFromCode\u0026lt;type, do_access_check\u0026gt;( method_idx, \u0026amp;receiver, sf_method, self); //假设方法C对应的ArtMethod对象找到了，所以，called_method不为空。  if (UNLIKELY(called_method == nullptr)) {.......} else if (UNLIKELY(!called_method-\u0026gt;IsInvokable())) {......} else { //下面这段代码和JIT有关，我们留待后续章节再来介绍。  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) {......} ...... //instrumentation的处理  return DoCall\u0026lt;is_range, do_access_check\u0026gt;(called_method, self, shadow_frame, inst, inst_data,result); } } DoCall template\u0026lt;bool is_range, bool do_assignability_check\u0026gt; bool DoCall(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame,const Instruction* inst, uint16_t inst_data, JValue* result) { const uint16_t number_of_inputs = (is_range) ? inst-\u0026gt;VRegA_3rc(inst_data) : inst-\u0026gt;VRegA_35c(inst_data); //kMaxVarArgsRegs为编译常量，值为5  uint32_t arg[Instruction::kMaxVarArgRegs] = {}; uint32_t vregC = 0; if (is_range) {......} else { vregC = inst-\u0026gt;VRegC_35c(); inst-\u0026gt;GetVarArgs(arg, inst_data); //将调用方法C的参数存储到arg数组中,main  } //调用DoCallCommon，我们接着看这个函数  return DoCallCommon\u0026lt;is_range, do_assignability_check\u0026gt;( called_method, self, shadow_frame,result, number_of_inputs, arg, vregC); } DoCallCommon template \u0026lt;bool is_range, bool do_assignability_check, size_t kVarArgMax\u0026gt; static inline bool DoCallCommon(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame, JValue* result, uint16_t number_of_inputs,uint32_t (\u0026amp;arg)[kVarArgMax],uint32_t vregC) { bool string_init = false; //和String类的构造函数有关。此处不拟讨论。  if (UNLIKELY(called_method-\u0026gt;GetDeclaringClass()-\u0026gt;IsStringClass() \u0026amp;\u0026amp; called_method-\u0026gt;IsConstructor())) {.....} const DexFile::CodeItem* code_item = called_method-\u0026gt;GetCodeItem(); uint16_t num_regs; if (LIKELY(code_item != nullptr)) { num_regs = code_item-\u0026gt;registers_size_; } else { num_regs = number_of_inputs; } uint32_t string_init_vreg_this = is_range ? vregC : arg[0]; if (UNLIKELY(string_init)) {......} size_t first_dest_reg = num_regs - number_of_inputs; ...... //创建方法C所需的ShadowFrame对象。  ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, \u0026amp;shadow_frame, called_method, 0); ShadowFrame* new_shadow_frame = shadow_frame_unique_ptr.get(); if (do_assignability_check) { ...... //不考虑这种情况，读者可自行阅读  } else { size_t arg_index = 0; if (is_range) {......} else { //从调用方法B的ShadowFrame对象中拷贝方法C所需的参数到C的ShadowFrame对象里  for (; arg_index \u0026lt; number_of_inputs; ++arg_index) { AssignRegister(new_shadow_frame, shadow_frame, first_dest_reg + arg_index, arg[arg_index]); } } ...... } //准备方法C对应的ShadowFrame对象后，现在将考虑如何跳转到目标方法C。  if (LIKELY(Runtime::Current()-\u0026gt;IsStarted())) { ArtMethod* target = new_shadow_frame-\u0026gt;GetMethod(); //如果处于调试模式，或者方法C不存在机器码，则调用  //ArtInterpreterToInterpreterBridge函数，显然，它是解释执行的继续。  if (ClassLinker::ShouldUseInterpreterEntrypoint( target, target-\u0026gt;GetEntryPointFromQuickCompiledCode())) { ArtInterpreterToInterpreterBridge(self, code_item, new_shadow_frame,result);//main  } else { //如果可以用机器码方式执行方法C，则调用ArtInterpreterToCompiledCodeBridge，  //它将从解释执行模式进入机器码执行模式。  ArtInterpreterToCompiledCodeBridge( self, shadow_frame.GetMethod(), code_item, new_shadow_frame, result); } } else { //dex2oat中的处理。因为dex2oat要执行诸如类的初始化方法\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;，这些方法都  //采用解释执行模式来处理的。  UnstartedRuntime::Invoke(self, code_item, new_shadow_frame, result, first_dest_reg); } } ...... return !self-\u0026gt;IsExceptionPending(); } ArtInterpreterToInterpreterBridge void ArtInterpreterToInterpreterBridge(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame* shadow_frame, JValue* result) { ...... self-\u0026gt;PushShadowFrame(shadow_frame); //方法C对应的ShadowFrame对象入栈  ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); const bool is_static = method-\u0026gt;IsStatic(); if (is_static) { //如果方法C为静态方法，则判断该方法所属的类是否初始化过了，如果没有，则先初始化这个类。  mirror::Class* declaring_class = method-\u0026gt;GetDeclaringClass(); if (UNLIKELY(!declaring_class-\u0026gt;IsInitialized())) { StackHandleScope\u0026lt;1\u0026gt; hs(self); HandleWrapper\u0026lt;Class\u0026gt; h_declaring_class(hs.NewHandleWrapper( \u0026amp;declaring_class)); if (UNLIKELY(!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized( self, h_declaring_class, true, true))) {......} } } //如果不是JNI方法，则调用Execute执行该方法。Execute函数我们在10.2.3节介绍过它了。  if (LIKELY(!shadow_frame-\u0026gt;GetMethod()-\u0026gt;IsNative())) { result-\u0026gt;SetJ(Execute(self, code_item, *shadow_frame,//main  JValue()).GetJ()); } else {...... /*dex2oat中的处理*/ } self-\u0026gt;PopShadowFrame(); //方法C对应的ShadowFrame出栈 } ArtInterpreterToCompiledCodeBridge void ArtInterpreterToCompiledCodeBridge(Thread* self, ArtMethod* caller, const DexFile::CodeItem* code_item, ShadowFrame* shadow_frame, JValue* result) { ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); if (method-\u0026gt;IsStatic()) { //检查方法C所属类是否完成了初始化，如果没有，则先初始化该类。  ...... } uint16_t arg_offset = (code_item == nullptr) ? 0 : code_item-\u0026gt;registers_size_ - code_item-\u0026gt;ins_size_; jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); ...... //JIT相关，此处先略过  //调用ArtMethod* C的Invoke函数。直接来看这个函数的代码。  method-\u0026gt;Invoke(self, shadow_frame-\u0026gt;GetVRegArgs(arg_offset), (shadow_frame-\u0026gt;NumberOfVRegs() - arg_offset) * sizeof(uint32_t), result, method-\u0026gt;GetInterfaceMethodIfProxy(sizeof(void*))-\u0026gt;GetShorty()); } art_method.cc Invoke void ArtMethod::Invoke(Thread* self, uint32_t* args, uint32_t args_size, JValue* result,const char* shorty) { /* 注意参数 （1）args：方法C所需的参数。它是一个数组，元素个数为args_size。 （2）result：存储方法C调用结果的对象。 （3）shorty：方法C的简短描述。 */ //栈操作，详情见下文分析  ManagedStack fragment; self-\u0026gt;PushManagedStackFragment(\u0026amp;fragment);//  Runtime* runtime = Runtime::Current(); if (UNLIKELY(!runtime-\u0026gt;IsStarted() || Dbg::IsForcedInterpreterNeededForCalling(self, this))) {......} else { //再次判断方法C是否存在机器码  bool have_quick_code = GetEntryPointFromQuickCompiledCode() != nullptr; if (LIKELY(have_quick_code)) { //如果是非静态函数，则调用art_quick_invoke_stub函数，否则调用  //art_quick_invoke_static_stub函数。这两个函数也是由汇编代码编写。我们看  //其中的art_quick_invoke_stub函数。  if (!IsStatic()) { (*art_quick_invoke_stub)(this, args, args_size, self, result, shorty); } else { (*art_quick_invoke_static_stub)(this, args, args_size, self, result, shorty); } //和HDeoptimize有关。详情见下文。  if (UNLIKELY(self-\u0026gt;GetException() == Thread::GetDeoptimizationException())) { self-\u0026gt;DeoptimizeWithDeoptimizationException(result); } } ...... self-\u0026gt;PopManagedStackFragment(fragment); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/",
	"title": "跨平台",
	"tags": [],
	"description": "",
	"content": "跨平台 探索总结跨平台知识\n flutter    engine    Engine      startup    startup     startup_dart_framework     startup_embedder_framwwork      touch    Touch      动画    动画      混合开发    FlutterBoost     混合开发      渲染    Widget     渲染      路由    路由      通信    MessageLoop     MethodChannel       "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E8%B7%AF%E7%94%B1/",
	"title": "路由",
	"tags": [],
	"description": "",
	"content": "路由 探索总结路由知识\n 路由     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E8%B7%AF%E7%94%B1/%E8%B7%AF%E7%94%B1/",
	"title": "路由",
	"tags": [],
	"description": "",
	"content": "原理    可能你会比较好奇_Theatre中 offstage 是如何做到不绘制的。\n你应该知道 Element 树的是通过其内部的mout方法将自己挂载到父 Element 上的。_Theatre的 mout方法不太一样， onstage走正常的挂载流程，加入到Element 树中； offstage集合中的 Widget 仅创建了对应的 Element，并没有挂载到 Element 树中。没有进入到Element中，也就不会进入到 RenderObject树中，也就不走到绘制流程了。\n这样你应该能理解Overlay其实是Stack的扩展。Overlay预先进行过滤，从而避免了无用的绘制。\n我们看下当路由中只有一个 Page 时的示意图：\n我们再看下当路由中又被 push 进一个 Page时的情况：\n因为通常 Page 的 opaque=true, maintainState=true,所以 Page2 进入 onstage， Page1 不在需要被绘制，但需要保持状态，进入了offstage。\n因为通常 popupWindow（dialog） 的 opaque=false,我们再向路由中 push 一个 dialog:\n类设计 参考 Flutter 路由原理解析\nFlutter 路由源码解析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E8%BD%AF%E4%BB%B6%E7%BB%98%E5%88%B6/",
	"title": "软件绘制",
	"tags": [],
	"description": "",
	"content": "软件绘制 深入理解Window\nAndroid的UI显示原理之Surface的创建\nAndroid的UI显示原理之Surface的渲染\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/AndroidFramework%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E7%9A%84UI%E6%98%BE%E7%A4%BA%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93.md\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/framework/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/README.md\nAndroid图形系统（九）-View、Canvas与Surface的关系\n 整体流程 把整个流程再简单总结下，View、Canvas与Surface的关系也就一目了然了：\nSurface通过dequeueBuffer流程（具体操作在此不多赘述）获取一块存放绘制数据的buffer。\nView 在onDraw的时候，通过传入的Canvas进行绘制。（这里只是一个绘制的入口而已，本文是针对requestLayout 流程来讲述的，当然你单独用Canvas实现绘制也是一样的）。\n调用java层的CanvasAPI，实际真正负责绘制工作的是底层的Skia引擎，这里核心类包括SKCanvas（画家）以及SKBitmap（画布），绘制好的内容放入Surface 通过dequeueBuffer获取到的GraphicBuffer。\n绘制完毕后，Surface通过queueBuffer将存放好绘制数据的buffer投递到队列中，并通知SurfaceFlinger消费。\n SurfaceFlinger可以说是Android UI渲染体系的核心，在Android系统启动时会启动SurfaceFlinger服务,它的主要作用就是被Android应用程序调用，把绘制(测量，布局，绘制)后的窗口(Surface)渲染到手机屏幕上\nSurfaceControl surface.lockCanvas(): //android_view_Surface.cpp static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ... ANativeWindow_Buffer outBuffer; //调用了Surface的dequeueBuffer，从SurfaceFlinger中申请内存GraphicBuffer,这个buffer是用来传递绘制的元数据的  status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); ... SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType); //新建了一个SkBitmap，并进行了一系列设置  SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits);//bitmap对graphicBuffer进行关联  } else { // be safe with an empty bitmap.  bitmap.setPixels(NULL); } //构造一个native的Canvas对象（SKCanvas)，再返回这个Canvas对象，java层的Canvas对象其实只是对SKCanvas对象的一个简单包装，所有绘制方法都是转交给SKCanvas来做。  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); ... sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } canvas.drawXXX Skia深入分析\n==SkCanvas是按照SkBitmap的方法去关联GraphicBuffer==\n一、渲染层级 从渲染流程上分，Skia可分为如下三个层级：\n 指令层：SkPicture、SkDeferredCanvas-\u0026gt;SkCanvas  这一层决定需要执行哪些绘图操作，绘图操作的预变换矩阵，当前裁剪区域，绘图操作产生在哪些layer上，Layer的生成与合并。\n解析层：SkBitmapDevice-\u0026gt;SkDraw-\u0026gt;SkScan、SkDraw1Glyph::Proc  这一层决定绘制方式，完成坐标变换，解析出需要绘制的形体（点/线/规整矩形）并做好抗锯齿处理，进行相关资源解析并设置好Shader。\n渲染层：SkBlitter-\u0026gt;SkBlitRow::Proc、SkShader::shadeSpan等  这一层进行采样（如果需要），产生实际的绘制效果，完成颜色格式适配，进行透明度混合和抖动处理（如果需要）。\n//Canvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { super.drawLine(startX, startY, stopX, stopY, paint); } //BaseCanvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { throwIfHasHwBitmapInSwMode(paint); nDrawLine(mNativeCanvasWrapper, startX, startY, stopX, stopY, paint.getNativeInstance()); } //frameworks/base/core/jni/android_graphics_Canvas.cpp static void drawLine(JNIEnv* env, jobject, jlong canvasHandle, jfloat startX, jfloat startY, jfloat stopX, jfloat stopY, jlong paintHandle) { Paint* paint = reinterpret_cast\u0026lt;Paint*\u0026gt;(paintHandle); get_canvas(canvasHandle)-\u0026gt;drawLine(startX, startY, stopX, stopY, *paint); } //external/skia/src/core/SkCanvas.cpp void SkCanvas::drawLine(SkScalar x0, SkScalar y0, SkScalar x1, SkScalar y1, const SkPaint\u0026amp; paint) { SkPoint pts[2]; pts[0].set(x0, y0); pts[1].set(x1, y1); this-\u0026gt;drawPoints(kLines_PointMode, 2, pts, paint); } void SkCanvas::drawPoints(PointMode mode, size_t count, const SkPoint pts[], const SkPaint\u0026amp; paint) { TRACE_EVENT0(\u0026#34;skia\u0026#34;, TRACE_FUNC); this-\u0026gt;onDrawPoints(mode, count, pts, paint); } mSurface.unlockCanvasAndPost(canvas): //Surface.cpp status_t Surface::unlockAndPost() { if (mLockedBuffer == 0) { ALOGE(\u0026#34;Surface::unlockAndPost failed, no locked buffer\u0026#34;); return INVALID_OPERATION; } int fd = -1; status_t err = mLockedBuffer-\u0026gt;unlockAsync(\u0026amp;fd);//通过Gralloc模块，最后是操作的ioctl  err = queueBuffer(mLockedBuffer.get(), fd); mPostedBuffer = mLockedBuffer; mLockedBuffer = 0; return err; } int Surface::queueBuffer(android_native_buffer_t* buffer, int fenceFd) { ... int i = getSlotFromBufferLocked(buffer); ... IGraphicBufferProducer::QueueBufferOutput output; IGraphicBufferProducer::QueueBufferInput input(timestamp, isAutoTimestamp, static_cast\u0026lt;android_dataspace\u0026gt;(mDataSpace), crop, mScalingMode, mTransform ^ mStickyTransform, fence, mStickyTransform, mEnableFrameTimestamps); ... status_t err = mGraphicBufferProducer-\u0026gt;queueBuffer(i, input, \u0026amp;output); ... mQueueBufferCondition.broadcast(); return err; } int Surface::getSlotFromBufferLocked(android_native_buffer_t* buffer) const { for (int i = 0; i \u0026lt; NUM_BUFFER_SLOTS; i++) { if (mSlots[i].buffer != NULL \u0026amp;\u0026amp; mSlots[i].buffer-\u0026gt;handle == buffer-\u0026gt;handle) { return i; } } return BAD_VALUE; } 我们看到了queueBuffer函数, 而在Surface的queueBuffer函数中调用了如下函数：\nmGraphicBufferProducer-\u0026gt;queueBuffer status_t BufferQueueProducer::queueBuffer(int slot, const QueueBufferInput \u0026amp;input, QueueBufferOutput *output) { //从input中获取一些列参数  input.deflate(\u0026amp;requestedPresentTimestamp, \u0026amp;isAutoTimestamp, \u0026amp;dataSpace, \u0026amp;crop, \u0026amp;scalingMode, \u0026amp;transform, \u0026amp;acquireFence, \u0026amp;stickyTransform, \u0026amp;getFrameTimestamps); sp\u0026lt;IConsumerListener\u0026gt; frameAvailableListener; sp\u0026lt;IConsumerListener\u0026gt; frameReplacedListener; BufferItem item; //可以理解为一个待渲染的帧  frameAvailableListener = mCore-\u0026gt;mConsumerListener; ...下面就是对item的一系列赋值操作 item.mAcquireCalled = mSlots[slot].mAcquireCalled; item.mGraphicBuffer = mSlots[slot].mGraphicBuffer; //根据slot获取GraphicBuffer。  item.mCrop = crop; item.mTransform = transform \u0026amp; ~static_cast\u0026lt;uint32_t\u0026gt;(NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY); item.mTransformToDisplayInverse = (transform \u0026amp; NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY) != 0; item.mScalingMode = static_cast\u0026lt;uint32_t\u0026gt;(scalingMode); item.mTimestamp = requestedPresentTimestamp; item.mIsAutoTimestamp = isAutoTimestamp; ... if (frameAvailableListener != NULL) { frameAvailableListener-\u0026gt;onFrameAvailable(item); //item是一个frame，准备完毕，要通知外界  } else if (frameReplacedListener != NULL) { frameReplacedListener-\u0026gt;onFrameReplaced(item); } addAndGetFrameTimestamps(\u0026amp;newFrameEventsEntry,etFrameTimestamps ? \u0026amp;output-\u0026gt;frameTimestamps : nullptr); return NO_ERROR; } 这个函数最终会将BufferItem的buffer清除，通知消费者的onFrameAvailable接口。然后消费者可以根据mSlots的序号再来拿buffer。\n// --------------------------------------------------------------------------- // Interface implementation for SurfaceFlingerConsumer::ContentsChangedListener // --------------------------------------------------------------------------- void BufferLayer::onFrameAvailable(const BufferItem\u0026amp; item) { ... mFlinger-\u0026gt;signalLayerUpdate(); } void SurfaceFlinger::signalLayerUpdate() { mEventQueue-\u0026gt;invalidate(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/",
	"title": "通信",
	"tags": [],
	"description": "",
	"content": "通信 探索总结通信知识\n MessageLoop     MethodChannel     "
}]