[
{
	"uri": "https://huanle19891345.github.io/en/android/",
	"title": "android",
	"tags": [],
	"description": "",
	"content": "android 探索总结android知识\n google    supportToAndroidx      系统机制原理    ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Looper     ThreadLocal      input    touchEventNative      kernel    kernel      sharedpreferences    SharedPreferences      zygote    SystemServerSource     ZygoteSource     Zygote进程      多进程    binder    BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理      mmkv    MMKV       应用启动退出    应用启动      系统绘制    Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制       "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/ashmem/",
	"title": "ashmem",
	"tags": [],
	"description": "",
	"content": "ashmem 探索总结ashmem知识\n 匿名共享内存Ashmem     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/",
	"title": "binder",
	"tags": [],
	"description": "",
	"content": "binder 探索总结binder知识\n BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderclient/",
	"title": "BinderClient",
	"tags": [],
	"description": "",
	"content": "Data Flow graph LR parcel_data--\u0026gt;flat_binder_object flat_binder_object--\u0026gt;binder_transaction_data getService SystemServiceRegistry ContextImpl.getSystemService @Override public Object getSystemService(String name) { return SystemServiceRegistry.getSystemService(this, name); } registerServices /** * Manages all of the system services that can be returned by {@link Context#getSystemService}. Used by {@link ContextImpl}. */ static { ...... registerService(Context.ACTIVITY_SERVICE, ActivityManager.class, new CachedServiceFetcher\u0026lt;ActivityManager\u0026gt;() { @Override public ActivityManager createService(ContextImpl ctx) { return new ActivityManager(ctx.getOuterContext(), ctx.mMainThread.getHandler()); }}); ...... registerService(Context.DISPLAY_SERVICE, DisplayManager.class, new CachedServiceFetcher\u0026lt;DisplayManager\u0026gt;() { @Override public DisplayManager createService(ContextImpl ctx) { return new DisplayManager(ctx.getOuterContext()); }}); registerService /** * Statically registers a system service with the context. * This method must be called during static initialization only. */ private static \u0026lt;T\u0026gt; void registerService(String serviceName, Class\u0026lt;T\u0026gt; serviceClass, ServiceFetcher\u0026lt;T\u0026gt; serviceFetcher) { SYSTEM_SERVICE_NAMES.put(serviceClass, serviceName); SYSTEM_SERVICE_FETCHERS.put(serviceName, serviceFetcher); } getSystemService public static Object getSystemService(ContextImpl ctx, String name) { ServiceFetcher\u0026lt;?\u0026gt; fetcher = SYSTEM_SERVICE_FETCHERS.get(name); return fetcher != null ? fetcher.getService(ctx) : null; } CachedServiceFetcher.getService static abstract class CachedServiceFetcher\u0026lt;T\u0026gt; implements ServiceFetcher\u0026lt;T\u0026gt; { @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public final T getService(ContextImpl ctx) { service = createService(ctx); cache[mCacheIndex] = service; return service; } } createService\u0026ndash;\u0026gt;ServiceManager.getService final IBinder b = ServiceManager.getService(Context.CONNECTIVITY_SERVICE);//getService final IConnectivityManager service = IConnectivityManager.Stub.asInterface(b);//asInterface final ProxyInfo proxyInfo = service.getProxyForNetwork(null);//useService ServiceManager getService /** * Returns a reference to a service with the given name. * * @param name the name of the service to get * @return a reference to the service, or \u0026lt;code\u0026gt;null\u0026lt;/code\u0026gt; if the service doesn\u0026#39;t exist */ public static IBinder getService(String name) { try { IBinder service = sCache.get(name); if (service != null) { return service; } else { return Binder.allowBlocking(rawGetService(name)); } } catch (RemoteException e) { Log.e(TAG, \u0026#34;error in getService\u0026#34;, e); } return null; } rawGetService private static IBinder rawGetService(String name) throws RemoteException { final IBinder binder = getIServiceManager().getService(name);//getService then useService  return binder; } getIServiceManager private static IServiceManager getIServiceManager() { if (sServiceManager != null) { return sServiceManager; } // Find the service manager  sServiceManager = ServiceManagerNative .asInterface(Binder.allowBlocking(BinderInternal.getContextObject())); return sServiceManager; } frameworks/base/core/java/com/android/internal/os/BinderInternal.java\nBinderInternal.getContextObject /** * Return the global \u0026#34;context object\u0026#34; of the system. This is usually * an implementation of IServiceManager, which you can use to find * other services. */ public static final native IBinder getContextObject(); frameworks/base/core/jni/android_util_Binder.cpp\nandroid_os_BinderInternal_getContextObject static jobject android_os_BinderInternal_getContextObject(JNIEnv* env, jobject clazz) { sp\u0026lt;IBinder\u0026gt; b = ProcessState::self()-\u0026gt;getContextObject(NULL); return javaObjectForIBinder(env, b); } system/libhwbinder/ProcessState.cpp\nProcessState::getContextObject sp\u0026lt;IBinder\u0026gt; ProcessState::getContextObject(const sp\u0026lt;IBinder\u0026gt;\u0026amp; /*caller*/) { return getStrongProxyForHandle(0); } ProcessState::getStrongProxyForHandle sp\u0026lt;IBinder\u0026gt; ProcessState::getStrongProxyForHandle(int32_t handle) { sp\u0026lt;IBinder\u0026gt; result; handle_entry* e = lookupHandleLocked(handle); if (e != NULL) { // We need to create a new BpHwBinder if there isn\u0026#39;t currently one, OR we  // are unable to acquire a weak reference on this current one. See comment  // in getWeakProxyForHandle() for more info about this.  IBinder* b = e-\u0026gt;binder; if (b == NULL || !e-\u0026gt;refs-\u0026gt;attemptIncWeak(this)) { b = new BpHwBinder(handle); e-\u0026gt;binder = b; if (b) e-\u0026gt;refs = b-\u0026gt;getWeakRefs(); result = b; } else { // This little bit of nastyness is to allow us to add a primary  // reference to the remote proxy when this team doesn\u0026#39;t have one  // but another team is sending the handle to us.  result.force_set(b); e-\u0026gt;refs-\u0026gt;decWeak(this); } } return result; } ProcessState::lookupHandleLocked Vector\u0026lt;handle_entry\u0026gt; mHandleToObject; ProcessState::handle_entry* ProcessState::lookupHandleLocked(int32_t handle) { const size_t N=mHandleToObject.size(); if (N \u0026lt;= (size_t)handle) { handle_entry e; e.binder = NULL; e.refs = NULL; status_t err = mHandleToObject.insertAt(e, N, handle+1-N); if (err \u0026lt; NO_ERROR) return NULL; } return \u0026amp;mHandleToObject.editItemAt(handle); } asInterface(cast IBinder into IxxxInterface) public abstract class ServiceManagerNative extends Binder implements IServiceManager { /** * Cast a Binder object into a service manager interface, generating * a proxy if needed. */ static public IServiceManager asInterface(IBinder obj) { if (obj == null) { return null; } IServiceManager in = (IServiceManager)obj.queryLocalInterface(descriptor); if (in != null) { return in; } return new ServiceManagerProxy(obj); } useService IServiceManager.getService(name) ServiceManagerProxy.getService class ServiceManagerProxy implements IServiceManager { public ServiceManagerProxy(IBinder remote) { mRemote = remote; } public IBinder asBinder() { return mRemote; } public IBinder getService(String name) throws RemoteException { Parcel data = Parcel.obtain(); Parcel reply = Parcel.obtain(); data.writeInterfaceToken(IServiceManager.descriptor); data.writeString(name); mRemote.transact(GET_SERVICE_TRANSACTION, data, reply, 0); IBinder binder = reply.readStrongBinder(); reply.recycle(); data.recycle(); return binder; } asInterface(cast IBinder into IxxxInterface) IConnectivityManager public interface IConnectivityManager extends android.os.IInterface Stub public static abstract class Stub extends android.os.Binder implements android.net.IConnectivityManager asInterface /** * Cast an IBinder object into an android.net.IConnectivityManager interface, * generating a proxy if needed. */ public static android.net.IConnectivityManager asInterface(android.os.IBinder obj) { if ((obj==null)) { return null; } android.os.IInterface iin = obj.queryLocalInterface(DESCRIPTOR); if (((iin!=null)\u0026amp;\u0026amp;(iin instanceof android.net.IConnectivityManager))) { return ((android.net.IConnectivityManager)iin); } return new android.net.IConnectivityManager.Stub.Proxy(obj); } Binder.queryLocalInterface /** * Use information supplied to attachInterface() to return the * associated IInterface if it matches the requested * descriptor. */ public @Nullable IInterface queryLocalInterface(@NonNull String descriptor) { if (mDescriptor != null \u0026amp;\u0026amp; mDescriptor.equals(descriptor)) { return mOwner; } return null; } BinderProxy.queryLocalInterface final class BinderProxy implements IBinder { public IInterface queryLocalInterface(String descriptor) { return null; } Proxy private static class Proxy implements android.net.IConnectivityManager { private android.os.IBinder mRemote; Proxy(android.os.IBinder remote) { mRemote = remote; } useService @Override public android.net.ProxyInfo getProxyForNetwork(android.net.Network nework) throws android.os.RemoteException { android.os.Parcel _data = android.os.Parcel.obtain(); android.os.Parcel _reply = android.os.Parcel.obtain(); android.net.ProxyInfo _result; try { _data.writeInterfaceToken(DESCRIPTOR); if ((nework!=null)) { _data.writeInt(1); nework.writeToParcel(_data, 0); } else { _data.writeInt(0); } mRemote.transact(Stub.TRANSACTION_getProxyForNetwork, _data, _reply, 0); _reply.readException(); if ((0!=_reply.readInt())) { _result = android.net.ProxyInfo.CREATOR.createFromParcel(_reply); } else { _result = null; } } finally { _reply.recycle(); _data.recycle(); } return _result; } Parcel obtain /** * Retrieve a new Parcel object from the pool. */ public static Parcel obtain() { final Parcel[] pool = sOwnedPool; synchronized (pool) { Parcel p; for (int i=0; i\u0026lt;POOL_SIZE; i++) { p = pool[i]; if (p != null) { pool[i] = null; if (DEBUG_RECYCLE) { p.mStack = new RuntimeException(); } p.mReadWriteHelper = ReadWriteHelper.DEFAULT; return p; } } } return new Parcel(0); } recycle /** * Put a Parcel object back into the pool. You must not touch * the object after this call. */ public final void recycle() { if (DEBUG_RECYCLE) mStack = null; freeBuffer(); final Parcel[] pool; if (mOwnsNativeParcelObject) { pool = sOwnedPool; } else { mNativePtr = 0; pool = sHolderPool; } synchronized (pool) { for (int i=0; i\u0026lt;POOL_SIZE; i++) { if (pool[i] == null) { pool[i] = this; return; } } } } transact BinderProxy /** * Java proxy for a native IBinder object. * Allocated and constructed by the native javaObjectforIBinder function. Never allocated * directly from Java code. */ final class BinderProxy implements IBinder { public boolean transact(int code, Parcel data, Parcel reply, int flags) throws RemoteException { Binder.checkParcel(this, code, data, \u0026#34;Unreasonably large binder buffer\u0026#34;); try { return transactNative(code, data, reply, flags); } finally { if (tracingEnabled) { Trace.traceEnd(Trace.TRACE_TAG_ALWAYS); } } } static const JNINativeMethod gBinderProxyMethods[] = { /* name, signature, funcPtr */ {\u0026#34;transactNative\u0026#34;, \u0026#34;(ILandroid/os/Parcel;Landroid/os/Parcel;I)Z\u0026#34;, (void*)android_os_BinderProxy_transact}, android_os_BinderProxy_transact static jboolean android_os_BinderProxy_transact(JNIEnv* env, jobject obj, jint code, jobject dataObj, jobject replyObj, jint flags) // throws RemoteException { Parcel* data = parcelForJavaObject(env, dataObj); Parcel* reply = parcelForJavaObject(env, replyObj); IBinder* target = getBPNativeData(env, obj)-\u0026gt;mObject.get(); //printf(\u0026#34;Transact from Java code to %p sending: \u0026#34;, target); data-\u0026gt;print();  status_t err = target-\u0026gt;transact(code, *data, reply, flags); //if (reply) printf(\u0026#34;Transact from Java code to %p received: \u0026#34;, target); reply-\u0026gt;print();  if (kEnableBinderSample) { if (time_binder_calls) { conditionally_log_binder_call(start_millis, target, code); } } ...... } parcelForJavaObject Parcel* parcelForJavaObject(JNIEnv* env, jobject obj) { if (obj) { Parcel* p = (Parcel*)env-\u0026gt;GetLongField(obj, gParcelOffsets.mNativePtr); return p; } return NULL; } getBPNativeData BinderProxyNativeData* getBPNativeData(JNIEnv* env, jobject obj) { return (BinderProxyNativeData *) env-\u0026gt;GetLongField(obj, gBinderProxyOffsets.mNativeData); } BpBinder status_t BpBinder::transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { // Once a binder has died, it will never come back to life.  if (mAlive) { status_t status = IPCThreadState::self()-\u0026gt;transact( mHandle, code, data, reply, flags);//传递mHandle  if (status == DEAD_OBJECT) mAlive = 0; return status; } return DEAD_OBJECT; } IPCThreadState Parcel mIn; Parcel mOut; self IPCThreadState* IPCThreadState::self() { const pthread_key_t k = gTLS; IPCThreadState* st = (IPCThreadState*)pthread_getspecific(k); if (st) return st; return new IPCThreadState; IPCThreadState() 每个线程都有一个IPCThreadState，每个IPCThreadState中都有一个mIn、一个mOut。成员变量mProcess保存了ProcessState变量(每个进程只有一个)。\n mIn 用来接收来自Binder设备的数据，默认大小为256字节； mOut用来存储发往Binder设备的数据，默认大小为256字节。  IPCThreadState::IPCThreadState() : mProcess(ProcessState::self()), mStrictModePolicy(0), mLastTransactionBinderFlags(0) { pthread_setspecific(gTLS, this); clearCaller(); mIn.setDataCapacity(256); mOut.setDataCapacity(256); } transact status_t IPCThreadState::transact(int32_t handle, uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { flags |= TF_ACCEPT_FDS; err = writeTransactionData(BC_TRANSACTION, flags, handle, code, data, NULL);、//传递handle  if ((flags \u0026amp; TF_ONE_WAY) == 0) { if (reply) {//call waitForResponse with param reply not null  err = waitForResponse(reply); } else { Parcel fakeReply; err = waitForResponse(\u0026amp;fakeReply);//call waitForResponse with param reply null  } } else { //oneway，则不需要等待reply的场景  err = waitForResponse(NULL, NULL); } writeTransactionData status_t IPCThreadState::writeTransactionData(int32_t cmd, uint32_t binderFlags, int32_t handle, uint32_t code, const Parcel\u0026amp; data, status_t* statusBuffer) { binder_transaction_data tr; tr.target.ptr = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ tr.target.handle = handle;//准备写入handle  tr.code = code; //wrapped code  tr.flags = binderFlags; tr.cookie = 0; tr.sender_pid = 0; tr.sender_euid = 0; const status_t err = data.errorCheck(); if (err == NO_ERROR) { tr.data_size = data.ipcDataSize();// mDataSize,binder_transaction的数据大小  tr.data.ptr.buffer = data.ipcData();//mData, binder_transaction的数据的起始地址  tr.offsets_size = data.ipcObjectsCount()*sizeof(binder_size_t);//mObjectsSize,记录着flat_binder_object结构体的个数  tr.data.ptr.offsets = data.ipcObjects();//mObjects, 记录着flat_binder_object结构体在数据偏移量  } mOut.writeInt32(cmd);//cmd = BC_TRANSACTION  mOut.write(\u0026amp;tr, sizeof(tr));//写入binder_transaction_data数据  return NO_ERROR; } Parcel::ipcData uintptr_t Parcel::ipcData() const { return reinterpret_cast\u0026lt;uintptr_t\u0026gt;(mData); } waitForResponse status_t IPCThreadState::waitForResponse(Parcel *reply, status_t *acquireResult) { uint32_t cmd; int32_t err; while (1) { if ((err=talkWithDriver()) \u0026lt; NO_ERROR) break; err = mIn.errorCheck(); if (err \u0026lt; NO_ERROR) break; if (mIn.dataAvail() == 0) continue; cmd = (uint32_t)mIn.readInt32(); switch (cmd) { case BR_TRANSACTION_COMPLETE: if (!reply \u0026amp;\u0026amp; !acquireResult) goto finish; break; case BR_REPLY: { binder_transaction_data tr; err = mIn.read(\u0026amp;tr, sizeof(tr)); if (reply) { if ((tr.flags \u0026amp; TF_STATUS_CODE) == 0) { reply-\u0026gt;ipcSetDataReference( reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), freeBuffer, this); } else { err = *reinterpret_cast\u0026lt;const status_t*\u0026gt;(tr.data.ptr.buffer); freeBuffer(NULL, reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), this); } } else { freeBuffer(NULL, reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), this); continue; } ...... } goto finish; default: err = executeCommand(cmd); if (err != NO_ERROR) goto finish; break; Parcel::dataAvail size_t Parcel::dataAvail() const { size_t result = dataSize() - dataPosition(); if (result \u0026gt; INT32_MAX) { abort(); } return result; } talkWithDriver status_t IPCThreadState::talkWithDriver(bool doReceive) { binder_write_read bwr; // Is the read buffer empty?  const bool needRead = mIn.dataPosition() \u0026gt;= mIn.dataSize(); // We don\u0026#39;t want to write anything if we are still reading  // from data left in the input buffer and the caller  // has requested to read the next data.  const size_t outAvail = (!doReceive || needRead) ? mOut.dataSize() : 0; bwr.write_size = outAvail; bwr.write_buffer = (uintptr_t)mOut.data();//写入write buffer  // This is what we\u0026#39;ll read.  if (doReceive \u0026amp;\u0026amp; needRead) { bwr.read_size = mIn.dataCapacity(); bwr.read_buffer = (uintptr_t)mIn.data(); } else { bwr.read_size = 0; bwr.read_buffer = 0; } // Return immediately if there is nothing to do.  if ((bwr.write_size == 0) \u0026amp;\u0026amp; (bwr.read_size == 0)) return NO_ERROR; bwr.write_consumed = 0; bwr.read_consumed = 0; do { if (ioctl(mProcess-\u0026gt;mDriverFD, BINDER_WRITE_READ, \u0026amp;bwr) \u0026gt;= 0) err = NO_ERROR; else err = -errno; if (mProcess-\u0026gt;mDriverFD \u0026lt;= 0) { err = -EBADF; } } while (err == -EINTR); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderdeath/",
	"title": "BinderDeath",
	"tags": [],
	"description": "",
	"content": "原理总结 Binder死亡通知机制之linkToDeath\nUnlinkToDeath流程类似，参考上文，不做记录\n死亡通知是为了让Bp端(客户端进程)进能知晓Bn端(服务端进程)的生死情况，当Bn端进程死亡后能通知到Bp端。\n 定义：AppDeathRecipient是继承IBinder::DeathRecipient类，主要需要实现其binderDied()来进行死亡通告。 注册：binder-\u0026gt;linkToDeath(AppDeathRecipient)是为了将AppDeathRecipient死亡通知注册到Binder上。  Bp端只需要覆写binderDied()方法，实现一些后尾清除类的工作，则在Bn端死掉后，会回调binderDied()进行相应处理。\nlinkToDeath android_os_BinderProxy_linkToDeath static void android_os_BinderProxy_linkToDeath(JNIEnv* env, jobject obj, jobject recipient, jint flags) { //获取BinderProxy.mObject成员变量值, 即BpBinder对象  IBinder* target = (IBinder*)env-\u0026gt;GetLongField(obj, gBinderProxyOffsets.mObject); sp\u0026lt;JavaDeathRecipient\u0026gt; jdr = new JavaDeathRecipient(env, recipient, list); //建立死亡通知[见小节2.2]  status_t err = target-\u0026gt;linkToDeath(jdr, NULL, flags); }  获取DeathRecipientList: 其成员变量mList记录该BinderProxy的JavaDeathRecipient列表信息；  一个BpBinder可以注册多个死亡回调   创建JavaDeathRecipient: 继承于IBinder::DeathRecipient  linkToDeath status_t BpBinder::linkToDeath( const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie, uint32_t flags) { IPCThreadState* self = IPCThreadState::self(); self-\u0026gt;requestDeathNotification(mHandle, this); self-\u0026gt;flushCommands(); } requestDeathNotification status_t IPCThreadState::requestDeathNotification(int32_t handle, BpBinder* proxy) { mOut.writeInt32(BC_REQUEST_DEATH_NOTIFICATION); mOut.writeInt32((int32_t)handle); mOut.writePointer((uintptr_t)proxy); return NO_ERROR; } flushCommands void IPCThreadState::flushCommands() { if (mProcess-\u0026gt;mDriverFD \u0026lt;= 0) return; talkWithDriver(false); } binder_ioctl_write_read static int binder_ioctl_write_read(struct file *filp, unsigned int cmd, unsigned long arg, struct binder_thread *thread) { int ret = 0; struct binder_proc *proc = filp-\u0026gt;private_data; void __user *ubuf = (void __user *)arg; struct binder_write_read bwr; if (copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr))) { //把用户空间数据ubuf拷贝到bwr  ret = -EFAULT; goto out; } if (bwr.write_size \u0026gt; 0) { //此时写缓存有数据【见小节3.2】  ret = binder_thread_write(proc, thread, bwr.write_buffer, bwr.write_size, \u0026amp;bwr.write_consumed); ... } if (bwr.read_size \u0026gt; 0) { //此时读缓存没有数据  ... } if (copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr))) { //将内核数据bwr拷贝到用户空间ubuf  ret = -EFAULT; goto out; } out: return ret; } binder_thread_write static int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed) { uint32_t cmd; //proc, thread都是指当前发起端进程的信息  while (ptr \u0026lt; end \u0026amp;\u0026amp; thread-\u0026gt;return_error == BR_OK) { get_user(cmd, (uint32_t __user *)ptr); //获取BC_REQUEST_DEATH_NOTIFICATION  ptr += sizeof(uint32_t); switch (cmd) { case BC_REQUEST_DEATH_NOTIFICATION:{ //注册死亡通知  uint32_t target; void __user *cookie; struct binder_ref *ref; struct binder_ref_death *death; get_user(target, (uint32_t __user *)ptr); //获取target  ptr += sizeof(uint32_t); get_user(cookie, (void __user * __user *)ptr); //获取BpBinder  ptr += sizeof(void *); ref = binder_get_ref(proc, target); //拿到目标服务的binder_ref  if (cmd == BC_REQUEST_DEATH_NOTIFICATION) { //native Bp可注册多个，但Kernel只允许注册一个死亡通知  if (ref-\u0026gt;death) { break; } death = kzalloc(sizeof(*death), GFP_KERNEL); INIT_LIST_HEAD(\u0026amp;death-\u0026gt;work.entry); death-\u0026gt;cookie = cookie; //BpBinder指针  ref-\u0026gt;death = death; //当目标binder服务所在进程已死,则直接发送死亡通知。这是非常规情况  if (ref-\u0026gt;node-\u0026gt;proc == NULL) { ref-\u0026gt;death-\u0026gt;work.type = BINDER_WORK_DEAD_BINDER; //当前线程为binder线程,则直接添加到当前线程的todo队列.  if (thread-\u0026gt;looper \u0026amp; (BINDER_LOOPER_STATE_REGISTERED | BINDER_LOOPER_STATE_ENTERED)) { list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;thread-\u0026gt;todo); } else { list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;proc-\u0026gt;todo); wake_up_interruptible(\u0026amp;proc-\u0026gt;wait); } } } else { ... } 在处理BC_REQUEST_DEATH_NOTIFICATION过程，正好遇到对端目标binder服务所在进程已死的情况， 向todo队列增加BINDER_WORK_DEAD_BINDER事务，直接发送死亡通知，但这属于非常规情况。\n更常见的场景是binder服务所在进程死亡后,会调用binder_release方法, 然后调用binder_node_release.这个过程便会发出死亡通知的回调.\n触发死亡通知 当Binder服务所在进程死亡后，会释放进程相关的资源，Binder也是一种资源。 binder_open打开binder驱动/dev/binder，这是字符设备，获取文件描述符。在进程结束的时候会有一个关闭文件系统的过程中会调用驱动close方法，该方法相对应的是release()方法。当binder的fd被释放后，此处调用相应的方法是binder_release().\n但并不是每个close系统调用都会触发调用release()方法. 只有真正释放设备数据结构才调用release(),内核维持一个文件结构被使用多少次的计数，即便是应用程序没有明显地关闭它打开的文件也适用: 内核在进程exit()时会释放所有内存和关闭相应的文件资源, 通过使用close系统调用最终也会release binder.\n[-\u0026gt; binder.c]\nbinder_fops static const struct file_operations binder_fops = { .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .compat_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release, //对应于release的方法 }; binder_release static int binder_release(struct inode *nodp, struct file *filp) { struct binder_proc *proc = filp-\u0026gt;private_data; debugfs_remove(proc-\u0026gt;debugfs_entry); binder_defer_work(proc, BINDER_DEFERRED_RELEASE); return 0; } binder_defer_work static void binder_defer_work(struct binder_proc *proc, enum binder_deferred_state defer) { mutex_lock(\u0026amp;binder_deferred_lock); //获取锁  //添加BINDER_DEFERRED_RELEASE  proc-\u0026gt;deferred_work |= defer; if (hlist_unhashed(\u0026amp;proc-\u0026gt;deferred_work_node)) { hlist_add_head(\u0026amp;proc-\u0026gt;deferred_work_node, \u0026amp;binder_deferred_list); //向工作队列添加binder_deferred_work [见小节4.4]  queue_work(binder_deferred_workqueue, \u0026amp;binder_deferred_work); } mutex_unlock(\u0026amp;binder_deferred_lock); //释放锁 } queue_work //全局工作队列 static struct workqueue_struct *binder_deferred_workqueue; static int __init binder_init(void) { int ret; //创建了名叫“binder”的工作队列  binder_deferred_workqueue = create_singlethread_workqueue(\u0026#34;binder\u0026#34;); if (!binder_deferred_workqueue) return -ENOMEM; ... } device_initcall(binder_init); 关于binder_deferred_work的定义：\nstatic DECLARE_WORK(binder_deferred_work, binder_deferred_func); 在Binder设备驱动初始化的过程执行binder_init()方法中，调用 create_singlethread_workqueue(“binder”)，创建了名叫“binder”的工作队列(workqueue)。 workqueue是kernel提供的一种实现简单而有效的内核线程机制，可延迟执行任务。\n此处binder_deferred_work的func为binder_deferred_func，接下来看该方法。\nbinder_deferred_func static void binder_deferred_func(struct work_struct *work) { struct binder_proc *proc; struct files_struct *files; int defer; do { mutex_lock(\u0026amp;binder_main_lock); //获取binder_main_lock  mutex_lock(\u0026amp;binder_deferred_lock); preempt_disable(); //禁止CPU抢占  if (!hlist_empty(\u0026amp;binder_deferred_list)) { proc = hlist_entry(binder_deferred_list.first, struct binder_proc, deferred_work_node); hlist_del_init(\u0026amp;proc-\u0026gt;deferred_work_node); defer = proc-\u0026gt;deferred_work; proc-\u0026gt;deferred_work = 0; } else { proc = NULL; defer = 0; } mutex_unlock(\u0026amp;binder_deferred_lock); files = NULL; if (defer \u0026amp; BINDER_DEFERRED_PUT_FILES) { files = proc-\u0026gt;files; if (files) proc-\u0026gt;files = NULL; } if (defer \u0026amp; BINDER_DEFERRED_FLUSH) binder_deferred_flush(proc); if (defer \u0026amp; BINDER_DEFERRED_RELEASE) binder_deferred_release(proc); //[见小节4.6]  mutex_unlock(\u0026amp;binder_main_lock); //释放锁  preempt_enable_no_resched(); if (files) put_files_struct(files); } while (proc); } binder_deferred_release 此处proc是来自Bn端的binder_proc\nstatic void binder_deferred_release(struct binder_proc *proc) { struct binder_transaction *t; struct rb_node *n; int threads, nodes, incoming_refs, outgoing_refs, buffers, active_transactions, page_count; hlist_del(\u0026amp;proc-\u0026gt;proc_node); //删除proc_node节点  if (binder_context_mgr_node \u0026amp;\u0026amp; binder_context_mgr_node-\u0026gt;proc == proc) { binder_context_mgr_node = NULL; } //释放binder_thread[见小节4.6.1]  threads = 0; active_transactions = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;threads))) { struct binder_thread *thread; thread = rb_entry(n, struct binder_thread, rb_node); threads++; active_transactions += binder_free_thread(proc, thread); } //释放binder_node [见小节4.6.2]  nodes = 0; incoming_refs = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;nodes))) { struct binder_node *node; node = rb_entry(n, struct binder_node, rb_node); nodes++; rb_erase(\u0026amp;node-\u0026gt;rb_node, \u0026amp;proc-\u0026gt;nodes); incoming_refs = binder_node_release(node, incoming_refs);//key  } //释放binder_ref [见小节4.6.3]  outgoing_refs = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;refs_by_desc))) { struct binder_ref *ref; ref = rb_entry(n, struct binder_ref, rb_node_desc); outgoing_refs++; binder_delete_ref(ref); } //释放binder_work [见小节4.6.4]  binder_release_work(\u0026amp;proc-\u0026gt;todo); binder_release_work(\u0026amp;proc-\u0026gt;delivered_death); buffers = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;allocated_buffers))) { struct binder_buffer *buffer; buffer = rb_entry(n, struct binder_buffer, rb_node); t = buffer-\u0026gt;transaction; if (t) { t-\u0026gt;buffer = NULL; buffer-\u0026gt;transaction = NULL; } //释放binder_buf [见小节4.6.5]  binder_free_buf(proc, buffer); buffers++; } binder_stats_deleted(BINDER_STAT_PROC); page_count = 0; if (proc-\u0026gt;pages) { int i; for (i = 0; i \u0026lt; proc-\u0026gt;buffer_size / PAGE_SIZE; i++) { void *page_addr; if (!proc-\u0026gt;pages[i]) continue; page_addr = proc-\u0026gt;buffer + i * PAGE_SIZE; unmap_kernel_range((unsigned long)page_addr, PAGE_SIZE); __free_page(proc-\u0026gt;pages[i]); page_count++; } kfree(proc-\u0026gt;pages); vfree(proc-\u0026gt;buffer); } put_task_struct(proc-\u0026gt;tsk); kfree(proc); } binder_deferred_release的主要工作有：\n binder_free_thread： proc-\u0026gt;threads所有线程  binder_send_failed_reply(send_reply, BR_DEAD_REPLY)：将发起方线程的return_error值设置为BR_DEAD_REPLY，让其直接返回；   binder_node_release: proc-\u0026gt;nodes所有节点  binder_release_work(\u0026amp;node-\u0026gt;async_todo) node-\u0026gt;refs的所有死亡回调   binder_delete_ref: proc-\u0026gt;refs_by_desc所有引用  清除引用   binder_release_work: proc-\u0026gt;todo, proc-\u0026gt;delivered_death  binder_send_failed_reply(t, BR_DEAD_REPLY)   binder_free_buf: proc-\u0026gt;allocated_buffers所有已分配buffer  释放已分配的buffer   __free_page: proc-\u0026gt;pages所有物理内存页  static int binder_node_release(struct binder_node *node, int refs) { struct binder_ref *ref; int death = 0; list_del_init(\u0026amp;node-\u0026gt;work.entry); //[见小节4.6.4]  binder_release_work(\u0026amp;node-\u0026gt;async_todo); if (hlist_empty(\u0026amp;node-\u0026gt;refs)) { kfree(node); //引用为空，则直接删除节点  binder_stats_deleted(BINDER_STAT_NODE); return refs; } node-\u0026gt;proc = NULL; node-\u0026gt;local_strong_refs = 0; node-\u0026gt;local_weak_refs = 0; hlist_add_head(\u0026amp;node-\u0026gt;dead_node, \u0026amp;binder_dead_nodes); hlist_for_each_entry(ref, \u0026amp;node-\u0026gt;refs, node_entry) { refs++; if (!ref-\u0026gt;death) continue; death++; if (list_empty(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry)) { //添加BINDER_WORK_DEAD_BINDER事务到todo队列 [见小节5.1]  ref-\u0026gt;death-\u0026gt;work.type = BINDER_WORK_DEAD_BINDER; list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;ref-\u0026gt;proc-\u0026gt;todo); wake_up_interruptible(\u0026amp;ref-\u0026gt;proc-\u0026gt;wait); } } return refs; } 该方法会遍历该binder_node所有的binder_ref, 当存在binder死亡通知，则向相应的binder_ref 所在进程的todo队列添加BINDER_WORK_DEAD_BINDER事务并唤醒处于proc-\u0026gt;wait的binder线程,执行binder_thread_read\n处理死亡通知 binder_thread_read static int binder_thread_read(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed, int non_block) ... //唤醒等待中的binder线程  wait_event_freezable_exclusive(proc-\u0026gt;wait, binder_has_proc_work(proc, thread)); binder_lock(__func__); //加锁  if (wait_for_proc_work) proc-\u0026gt;ready_threads--; //空闲的binder线程减1  thread-\u0026gt;looper \u0026amp;= ~BINDER_LOOPER_STATE_WAITING; while (1) { uint32_t cmd; struct binder_transaction_data tr; struct binder_work *w; struct binder_transaction *t = NULL; //从todo队列拿出前面放入的binder_work, 此时type为BINDER_WORK_DEAD_BINDER  if (!list_empty(\u0026amp;thread-\u0026gt;todo)) { w = list_first_entry(\u0026amp;thread-\u0026gt;todo, struct binder_work, entry); } else if (!list_empty(\u0026amp;proc-\u0026gt;todo) \u0026amp;\u0026amp; wait_for_proc_work) { w = list_first_entry(\u0026amp;proc-\u0026gt;todo, struct binder_work, entry); } switch (w-\u0026gt;type) { case BINDER_WORK_DEAD_BINDER: { struct binder_ref_death *death; uint32_t cmd; death = container_of(w, struct binder_ref_death, work); if (w-\u0026gt;type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) ... else cmd = BR_DEAD_BINDER; //进入此分支  put_user(cmd, (uint32_t __user *)ptr);//拷贝到用户空间[见小节5.2]  ptr += sizeof(uint32_t); //此处的cookie是前面传递的BpBinder  put_user(death-\u0026gt;cookie, (binder_uintptr_t __user *)ptr); ptr += sizeof(binder_uintptr_t); if (w-\u0026gt;type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) { ... } else //把该work加入到delivered_death队列  list_move(\u0026amp;w-\u0026gt;entry, \u0026amp;proc-\u0026gt;delivered_death); if (cmd == BR_DEAD_BINDER) goto done; } break; } } ... return 0; } 将命令BR_DEAD_BINDER写到用户空间，此时用户空间执行过程：\ngetAndExecuteCommand status_t IPCThreadState::getAndExecuteCommand() { status_t result; int32_t cmd; result = talkWithDriver(); //该Binder Driver进行交互  if (result \u0026gt;= NO_ERROR) { size_t IN = mIn.dataAvail(); if (IN \u0026lt; sizeof(int32_t)) return result; cmd = mIn.readInt32(); //读取命令  pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount++; pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); result = executeCommand(cmd); //【见小节5.3】  pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount--; pthread_cond_broadcast(\u0026amp;mProcess-\u0026gt;mThreadCountDecrement); pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); set_sched_policy(mMyThreadId, SP_FOREGROUND); } return result; } executeCommand status_t IPCThreadState::executeCommand(int32_t cmd) { BBinder* obj; RefBase::weakref_type* refs; status_t result = NO_ERROR; switch ((uint32_t)cmd) { case BR_DEAD_BINDER: { BpBinder *proxy = (BpBinder*)mIn.readPointer(); proxy-\u0026gt;sendObituary(); //[见小节5.4]  mOut.writeInt32(BC_DEAD_BINDER_DONE); mOut.writePointer((uintptr_t)proxy); } break; ... } ... return result; } 同一个bp端即便注册多次死亡通知，但只会发送一次死亡回调。\nsendObituary void BpBinder::sendObituary() { mAlive = 0; if (mObitsSent) return; mLock.lock(); Vector\u0026lt;Obituary\u0026gt;* obits = mObituaries; if(obits != NULL) { IPCThreadState* self = IPCThreadState::self(); //清空死亡通知[见小节6.2]  self-\u0026gt;clearDeathNotification(mHandle, this); self-\u0026gt;flushCommands(); mObituaries = NULL; } mObitsSent = 1; mLock.unlock(); if (obits != NULL) { const size_t N = obits-\u0026gt;size(); for (size_t i=0; i\u0026lt;N; i++) { //发送死亡通知 [见小节5.5]  reportOneDeath(obits-\u0026gt;itemAt(i)); } delete obits; } } reportOneDeath void BpBinder::reportOneDeath(const Obituary\u0026amp; obit) { //将弱引用提升到sp  sp\u0026lt;DeathRecipient\u0026gt; recipient = obit.recipient.promote(); if (recipient == NULL) return; //回调死亡通知的方法  recipient-\u0026gt;binderDied(this); } 本文开头的实例传递的是AppDeathRecipient，那么回调如下方法。\nprivate final class AppDeathRecipient implements IBinder.DeathRecipient { ... public void binderDied() { synchronized(ActivityManagerService.this) { appDiedLocked(mApp, mPid, mAppThread, true); } } } 结论 对于Binder IPC进程都会打开/dev/binder文件，当进程异常退出时，Binder驱动会保证释放将要退出的进程中没有正常关闭的/dev/binder文件，实现机制是binder驱动通过调用/dev/binder文件所对应的release回调函数，执行清理工作，并且检查BBinder是否有注册死亡通知，当发现存在死亡通知时，那么就向其对应的BpBinder端发送死亡通知消息。\n死亡回调DeathRecipient只有Bp才能正确使用，因为DeathRecipient用于监控Bn端挂掉的情况， 如果Bn建立跟自己的死亡通知，自己进程都挂了，也就无法通知。\n每个BpBinder都有一个记录DeathRecipient列表的对象DeathRecipientList。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderkernel/",
	"title": "BinderKernel",
	"tags": [],
	"description": "",
	"content": "binder_write_read struct binder_write_read { binder_size_t\twrite_size;\t/* bytes to write */ binder_size_t\twrite_consumed;\t/* bytes consumed by driver */ binder_uintptr_t\twrite_buffer; binder_size_t\tread_size;\t/* bytes to read */ binder_size_t\tread_consumed;\t/* bytes consumed by driver */ binder_uintptr_t\tread_buffer; }; binder_transaction_data struct binder_transaction_data { /* The first two are only used for bcTRANSACTION and brTRANSACTION, * identifying the target and contents of the transaction. */ union { /* target descriptor of command transaction */ __u32\thandle; /* target descriptor of return transaction */ binder_uintptr_t ptr; } target; binder_uintptr_t\tcookie;\t/* target object cookie */ __u32\tcode;\t/* transaction command */ /* General information about the transaction. */ __u32\tflags; pid_t\tsender_pid; uid_t\tsender_euid; binder_size_t\tdata_size;\t/* number of bytes of data */ binder_size_t\toffsets_size;\t/* number of bytes of offsets */ /* If this transaction is inline, the data immediately * follows here; otherwise, it ends with a pointer to * the data buffer. */ union { struct { /* transaction data */ binder_uintptr_t\tbuffer; /* offsets from buffer to flat_binder_object structs */ binder_uintptr_t\toffsets; } ptr; __u8\tbuf[8]; } data; }; drivers/android/binder.c\nbinder.c binder_ioctl static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { int ret; struct binder_proc *proc = filp-\u0026gt;private_data; switch (cmd) { case BINDER_WRITE_READ: ret = binder_ioctl_write_read(filp, cmd, arg, thread); } } binder_ioctl_write_read static int binder_ioctl_write_read(struct file *filp, unsigned int cmd, unsigned long arg, struct binder_thread *thread) { int ret = 0; struct binder_proc *proc = filp-\u0026gt;private_data; unsigned int size = _IOC_SIZE(cmd); void __user *ubuf = (void __user *)arg; struct binder_write_read bwr; //将用户空间bwr结构体拷贝到内核空间  copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr)); binder_debug(BINDER_DEBUG_READ_WRITE, \u0026#34;%d:%d write %lld at %016llx, read %lld at %016llx\\n\u0026#34;, proc-\u0026gt;pid, thread-\u0026gt;pid, (u64)bwr.write_size, (u64)bwr.write_buffer, (u64)bwr.read_size, (u64)bwr.read_buffer); if (bwr.write_size \u0026gt; 0) { //将数据放入目标进程 \tret = binder_thread_write(proc, thread, bwr.write_buffer, bwr.write_size, \u0026amp;bwr.write_consumed); } if (bwr.read_size \u0026gt; 0) { //读取自己队列的数据 \tret = binder_thread_read(proc, thread, bwr.read_buffer, bwr.read_size, \u0026amp;bwr.read_consumed, filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK); } //将内核空间bwr结构体拷贝到用户空间  copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr)) return ret; } binder_thread_write static int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed) { uint32_t cmd; struct binder_context *context = proc-\u0026gt;context; void __user *buffer = (void __user *)(uintptr_t)binder_buffer; void __user *ptr = buffer + *consumed; void __user *end = buffer + size; while (ptr \u0026lt; end \u0026amp;\u0026amp; thread-\u0026gt;return_error.cmd == BR_OK) { if (get_user(cmd, (uint32_t __user *)ptr))////拷贝用户空间的cmd命令，此时为BC_TRANSACTION \treturn -EFAULT; ptr += sizeof(uint32_t); switch (cmd) { case BC_TRANSACTION: case BC_REPLY: { struct binder_transaction_data tr; //拷贝用户空间的binder_transaction_data \tif (copy_from_user(\u0026amp;tr, ptr, sizeof(tr))) return -EFAULT; ptr += sizeof(tr); binder_transaction(proc, thread, \u0026amp;tr, cmd == BC_REPLY, 0); break; } } binder_transaction static void binder_transaction(struct binder_proc *proc, struct binder_thread *thread, struct binder_transaction_data *tr, int reply, binder_size_t extra_buffers_size) { struct binder_proc *target_proc = NULL; struct binder_thread *target_thread = NULL; struct binder_node *target_node = NULL; if (reply) { ...... } else { if (tr-\u0026gt;target.handle) { struct binder_ref *ref; binder_proc_lock(proc); ref = binder_get_ref_olocked(proc, tr-\u0026gt;target.handle, true); if (ref) { target_node = binder_get_node_refs_for_txn( ref-\u0026gt;node, \u0026amp;target_proc, \u0026amp;return_error); } else { binder_user_error(\u0026#34;%d:%d got transaction to invalid handle\\n\u0026#34;,proc-\u0026gt;pid, thread-\u0026gt;pid);...... } binder_proc_unlock(proc); } else { // handle=0则找到servicemanager实体 \tmutex_lock(\u0026amp;context-\u0026gt;context_mgr_node_lock); target_node = context-\u0026gt;binder_context_mgr_node; if (target_node) target_node = binder_get_node_refs_for_txn( target_node, \u0026amp;target_proc, \u0026amp;return_error); else return_error = BR_DEAD_REPLY; mutex_unlock(\u0026amp;context-\u0026gt;context_mgr_node_lock); } t-\u0026gt;buffer = binder_alloc_new_buf(\u0026amp;target_proc-\u0026gt;alloc, tr-\u0026gt;data_size, tr-\u0026gt;offsets_size, extra_buffers_size, !reply \u0026amp;\u0026amp; (t-\u0026gt;flags \u0026amp; TF_ONE_WAY)); ...... if (reply) { ...... } else if (!(t-\u0026gt;flags \u0026amp; TF_ONE_WAY)) { BUG_ON(t-\u0026gt;buffer-\u0026gt;async_transaction != 0); /* * Defer the TRANSACTION_COMPLETE, so we don\u0026#39;t return to * userspace immediately; this allows the target process to * immediately start processing this transaction, reducing * latency. We will then return the TRANSACTION_COMPLETE when * the target replies (or there is an error). */ binder_enqueue_deferred_thread_work_ilocked(thread, tcomplete); t-\u0026gt;need_reply = 1; t-\u0026gt;from_parent = thread-\u0026gt;transaction_stack; thread-\u0026gt;transaction_stack = t; if (!binder_proc_transaction(t, target_proc, target_thread)) { ...... goto err_dead_proc_or_thread; } } else { BUG_ON(target_node == NULL); BUG_ON(t-\u0026gt;buffer-\u0026gt;async_transaction != 1); binder_enqueue_thread_work(thread, tcomplete); if (!binder_proc_transaction(t, target_proc, NULL)) goto err_dead_proc_or_thread; } binder_alloc_new_buf /** * binder_alloc_new_buf() - Allocate a new binder buffer * @alloc: binder_alloc for this proc * @data_size: size of user data buffer * @offsets_size: user specified buffer offset * @extra_buffers_size: size of extra space for meta-data (eg, security context) * @is_async: buffer for async transaction * * Allocate a new buffer given the requested sizes. Returns * the kernel version of the buffer pointer. The size allocated * is the sum of the three given sizes (each rounded up to * pointer-sized boundary) * * Return:\tThe allocated buffer or %NULL if error */ struct binder_buffer *binder_alloc_new_buf(struct binder_alloc *alloc, size_t data_size, size_t offsets_size, size_t extra_buffers_size, int is_async) { struct binder_buffer *buffer; mutex_lock(\u0026amp;alloc-\u0026gt;mutex); buffer = binder_alloc_new_buf_locked(alloc, data_size, offsets_size, extra_buffers_size, is_async); mutex_unlock(\u0026amp;alloc-\u0026gt;mutex); return buffer; } binder_get_ref_olocked static struct binder_ref *binder_get_ref_olocked(struct binder_proc *proc, u32 desc, bool need_strong_ref) { struct rb_node *n = proc-\u0026gt;refs_by_desc.rb_node; struct binder_ref *ref; while (n) { ref = rb_entry(n, struct binder_ref, rb_node_desc); if (desc \u0026lt; ref-\u0026gt;data.desc) { n = n-\u0026gt;rb_left; } else if (desc \u0026gt; ref-\u0026gt;data.desc) { n = n-\u0026gt;rb_right; } else if (need_strong_ref \u0026amp;\u0026amp; !ref-\u0026gt;data.strong) { binder_user_error(\u0026#34;tried to use weak ref as strong ref\\n\u0026#34;); return NULL; } else { return ref; } } return NULL; } binder_get_node_refs_for_txn /** Return: The target_node with refs taken or NULL if no @node-\u0026gt;proc is NULL. * Also sets @proc if valid. If the @node-\u0026gt;proc is NULL indicating that the * target proc has died, @error is set to BR_DEAD_REPLY */ static struct binder_node *binder_get_node_refs_for_txn( struct binder_node *node, struct binder_proc **procp, uint32_t *error) { struct binder_node *target_node = NULL; binder_node_inner_lock(node); if (node-\u0026gt;proc) { target_node = node; binder_inc_node_nilocked(node, 1, 0, NULL); binder_inc_node_tmpref_ilocked(node); node-\u0026gt;proc-\u0026gt;tmp_ref++; *procp = node-\u0026gt;proc; } else *error = BR_DEAD_REPLY; binder_node_inner_unlock(node); return target_node; } struct binder_ref struct binder_ref { /* Lookups needed: */ /* node + proc =\u0026gt; ref (transaction) */ /* desc + proc =\u0026gt; ref (transaction, inc/dec ref) */ /* node =\u0026gt; refs + procs (proc exit) */ struct binder_ref_data data; struct rb_node rb_node_desc; struct rb_node rb_node_node; struct hlist_node node_entry; struct binder_proc *proc; struct binder_node *node; struct binder_ref_death *death; }; binder_proc_transaction /** * binder_proc_transaction() - sends a transaction to a process and wakes it up * @t:\ttransaction to send * @proc:\tprocess to send the transaction to * @thread:\tthread in @proc to send the transaction to (may be NULL) * * This function queues a transaction to the specified process. It will try * to find a thread in the target process to handle the transaction and * wake it up. If no thread is found, the work is queued to the proc * waitqueue. * * If the @thread parameter is not NULL, the transaction is always queued * to the waitlist of that specific thread. * * Return:\ttrue if the transactions was successfully queued *\tfalse if the target process or thread is dead */ static bool binder_proc_transaction(struct binder_transaction *t, struct binder_proc *proc, struct binder_thread *thread) { struct binder_node *node = t-\u0026gt;buffer-\u0026gt;target_node; struct binder_priority node_prio; bool oneway = !!(t-\u0026gt;flags \u0026amp; TF_ONE_WAY); bool pending_async = false; if (oneway) { BUG_ON(thread); if (node-\u0026gt;has_async_transaction) { pending_async = true; } else { node-\u0026gt;has_async_transaction = 1; } } if (!thread \u0026amp;\u0026amp; !pending_async) thread = binder_select_thread_ilocked(proc); if (thread) { binder_transaction_priority(thread-\u0026gt;task, t, node_prio, node-\u0026gt;inherit_rt); binder_enqueue_thread_work_ilocked(thread, \u0026amp;t-\u0026gt;work); } else if (!pending_async) { binder_enqueue_work_ilocked(\u0026amp;t-\u0026gt;work, \u0026amp;proc-\u0026gt;todo); } else { binder_enqueue_work_ilocked(\u0026amp;t-\u0026gt;work, \u0026amp;node-\u0026gt;async_todo); } if (!pending_async) binder_wakeup_thread_ilocked(proc, thread, !oneway /* sync */); return true; } binder_wakeup_thread_ilocked /** * binder_wakeup_thread_ilocked() - wakes up a thread for doing proc work. * @proc:\tprocess to wake up a thread in * @thread:\tspecific thread to wake-up (may be NULL) * @sync:\twhether to do a synchronous wake-up * * This function wakes up a thread in the @proc process. * The caller may provide a specific thread to wake-up in * the @thread parameter. If @thread is NULL, this function * will wake up threads that have called poll(). * * Note that for this function to work as expected, callers * should first call binder_select_thread() to find a thread * to handle the work (if they don\u0026#39;t have a thread already), * and pass the result into the @thread parameter. */ static void binder_wakeup_thread_ilocked(struct binder_proc *proc, struct binder_thread *thread, bool sync) { assert_spin_locked(\u0026amp;proc-\u0026gt;inner_lock); if (thread) { if (sync) wake_up_interruptible_sync(\u0026amp;thread-\u0026gt;wait); else wake_up_interruptible(\u0026amp;thread-\u0026gt;wait); return; } /* Didn\u0026#39;t find a thread waiting for proc work; this can happen * in two scenarios: * 1. All threads are busy handling transactions * In that case, one of those threads should call back into * the kernel driver soon and pick up this work. * 2. Threads are using the (e)poll interface, in which case * they may be blocked on the waitqueue without having been * added to waiting_threads. For this case, we just iterate * over all threads not handling transaction work, and * wake them all up. We wake all because we don\u0026#39;t know whether * a thread that called into (e)poll is handling non-binder * work currently. */ binder_wakeup_poll_threads_ilocked(proc, sync); } include/linux/wait.h\nwait.h #define wake_up_interruptible(x)\t__wake_up(x, TASK_INTERRUPTIBLE, 1, NULL) #define wake_up_interruptible_nr(x, nr)\t__wake_up(x, TASK_INTERRUPTIBLE, nr, NULL) #define wake_up_interruptible_all(x)\t__wake_up(x, TASK_INTERRUPTIBLE, 0, NULL) #define wake_up_interruptible_sync(x)\t__wake_up_sync((x), TASK_INTERRUPTIBLE, 1) drivers/android/binder_alloc.h\nbinder_alloc.h struct binder_alloc /** * struct binder_alloc - per-binder proc state for binder allocator * @vma: vm_area_struct passed to mmap_handler * (invarient after mmap) * @tsk: tid for task that called init for this proc * (invariant after init) * @vma_vm_mm: copy of vma-\u0026gt;vm_mm (invarient after mmap) * @buffer: base of per-proc address space mapped via mmap * @user_buffer_offset: offset between user and kernel VAs for buffer * @buffers: list of all buffers for this proc * @free_buffers: rb tree of buffers available for allocation * sorted by size * @allocated_buffers: rb tree of allocated buffers sorted by address * @free_async_space: VA space available for async buffers. This is * initialized at mmap time to 1/2 the full VA space * @pages: array of binder_lru_page * @buffer_size: size of address space specified via mmap * @pid: pid for associated binder_proc (invariant after init) * @pages_high: high watermark of offset in @pages * * Bookkeeping structure for per-proc address space management for binder * buffers. It is normally initialized during binder_init() and binder_mmap() * calls. The address space is used for both user-visible buffers and for * struct binder_buffer objects used to track the user buffers */ //open系统调用时返回的fd信息的private_data里是binder_proc，而mmap过程会修改这个binder_proc的alloc字段信息，从而确保申请的内存位于target process对应的内核空间 struct binder_alloc { } include/linux/rbtree.h\nrbtree.h//红黑树 rb_node struct rb_node { unsigned long __rb_parent_color; struct rb_node *rb_right; struct rb_node *rb_left; } __attribute__((aligned(sizeof(long)))); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderserver/",
	"title": "BinderServer",
	"tags": [],
	"description": "",
	"content": "Binder Native And Java Design classDiagram class IBinder { +queryLocalInterface(descriptor) +linkToDeath(recipient, cookie, flags) status_t +unlinkToDeath(recipient, cookie, flags, outRecipient) status_t +transact(code, data, reply, flags) status_t +localBinder() BBinder +remoteBinder() BpBinder } class BpBinder { } class BBinder { +transact(code, data, reply, flags) #onTransact(code, data, reply, flags) } class BnInterface~INTERFACE~ { +queryLocalInterface(_descriptor) IInterface +getInterfaceDescriptor() descriptor #onAsBinder() IBinder } class BnGraphicBufferProducer { +onTransact() status_t } class IInterface { +asBinder(IInterface*) IBinder } class IGraphicBufferProducer { +ipcMethod() } class BufferQueueProducer { +ipcMethod() } class JavaBBinder { +onTransact() } IBinder \u0026lt;|-- BpBinder IBinder \u0026lt;|-- BBinder BBinder \u0026lt;|-- BnInterface : native type server BBinder \u0026lt;|-- JavaBBinder : java type server BnInterface \u0026lt;|-- BnGraphicBufferProducer : BnInterface\u0026lt;IGraphicBufferProducer\u0026gt; IInterface \u0026lt;|-- IGraphicBufferProducer BnGraphicBufferProducer \u0026lt;|-- BufferQueueProducer IGraphicBufferProducer \u0026lt;|.. BnInterface : INTERFACE classDiagram class IBinder { +queryLocalInterface(descriptor) IInterface +linkToDeath(recipient, flags) +unlinkToDeath(recipient, flags) +transact(code, data, reply, flags) } class BinderProxy { } class Binder { +attachInterface(iinterface, descriptor) +transact(code, data, reply, flags) #onTransact(code, data, reply, flags) } class Stub { +asInterface(iBinder) IConnectivityManager +asBinder() IBinder +onTransact(code, data, reply, flags) } class IInterface { +asBinder() IBinder } class IConnectivityManager { +ipcMethod() } class ConnectivityService { +ipcMethod() } class Proxy { - IBinder mRemote +ipcMethod() } IBinder \u0026lt;|-- BinderProxy IBinder \u0026lt;|-- Binder Binder \u0026lt;|-- Stub IConnectivityManager \u0026lt;|.. Stub IInterface \u0026lt;|-- IConnectivityManager Stub \u0026lt;|-- ConnectivityService IConnectivityManager \u0026lt;|.. Proxy Stub --\u0026gt; Proxy : asInterface返回 NativeBBinder associated with JavaBinder 原理图 addService frameworks/base/core/java/android/os/ServiceManager.java\nServiceManager /** * Place a new @a service called @a name into the service * manager. * * @param name the name of the new service * @param service the service object * @param allowIsolated set to true to allow isolated sandboxed processes * @param dumpPriority supported dump priority levels as a bitmask * to access this service */ public static void addService(String name, IBinder service, boolean allowIsolated, int dumpPriority) { getIServiceManager().addService(name, service, allowIsolated, dumpPriority); } getService \u0026amp;\u0026amp; asInterface 即getiservicemanager()过程参考binderclient\nuseService(addService) class ServiceManagerProxy implements IServiceManager { public ServiceManagerProxy(IBinder remote) { mRemote = remote; } public IBinder asBinder() { return mRemote; } public void addService(String name, IBinder service, boolean allowIsolated, int dumpPriority) throws RemoteException { Parcel data = Parcel.obtain(); Parcel reply = Parcel.obtain(); data.writeInterfaceToken(IServiceManager.descriptor); data.writeString(name); data.writeStrongBinder(service); data.writeInt(allowIsolated ? 1 : 0); data.writeInt(dumpPriority); mRemote.transact(ADD_SERVICE_TRANSACTION, data, reply, 0); reply.recycle(); data.recycle(); } } writeStrongBinder记录BBinder /** * Write an object into the parcel at the current dataPosition(), * growing dataCapacity() if needed. */ public final void writeStrongBinder(IBinder val) { nativeWriteStrongBinder(mNativePtr, val); } frameworks/base/core/jni/android_os_Parcel.cpp\nstatic void android_os_Parcel_writeStrongBinder(JNIEnv* env, jclass clazz, jlong nativePtr, jobject object) { Parcel* parcel = reinterpret_cast\u0026lt;Parcel*\u0026gt;(nativePtr); if (parcel != NULL) { const status_t err = parcel-\u0026gt;writeStrongBinder(ibinderForJavaObject(env, object)); if (err != NO_ERROR) { signalExceptionForError(env, clazz, err); } } } frameworks/base/core/jni/android_util_Binder.cpp\nc和javaBinder对应 gBinderOffsets.mClass = MakeGlobalRefOrDie(env, clazz); gBinderOffsets.mExecTransact = GetMethodIDOrDie(env, clazz, \u0026#34;execTransact\u0026#34;, \u0026#34;(IJJI)Z\u0026#34;); gBinderOffsets.mObject = GetFieldIDOrDie(env, clazz, \u0026#34;mObject\u0026#34;, \u0026#34;J\u0026#34;); sp\u0026lt;IBinder\u0026gt; ibinderForJavaObject(JNIEnv* env, jobject obj) { if (obj == NULL) return NULL; // Instance of Binder?  if (env-\u0026gt;IsInstanceOf(obj, gBinderOffsets.mClass)) { JavaBBinderHolder* jbh = (JavaBBinderHolder*) env-\u0026gt;GetLongField(obj, gBinderOffsets.mObject); return jbh-\u0026gt;get(env, obj); } // Instance of BinderProxy?  if (env-\u0026gt;IsInstanceOf(obj, gBinderProxyOffsets.mClass)) { return getBPNativeData(env, obj)-\u0026gt;mObject; } ALOGW(\u0026#34;ibinderForJavaObject: %p is not a Binder object\u0026#34;, obj); return NULL; } frameworks/base/core/jni/android_util_Binder.cpp\nclass JavaBBinderHolder { public: sp\u0026lt;JavaBBinder\u0026gt; get(JNIEnv* env, jobject obj) { sp\u0026lt;JavaBBinder\u0026gt; b = mBinder.promote(); if (b == NULL) { b = new JavaBBinder(env, obj); mBinder = b; } return b; } wp\u0026lt;JavaBBinder\u0026gt; mBinder; } frameworks/native/libs/binder/Parcel.cpp\nstatus_t Parcel::writeStrongBinder(const sp\u0026lt;IBinder\u0026gt;\u0026amp; val) { return flatten_binder(ProcessState::self(), val, this); } 将BBinder设置为flat_binder_object的cookie status_t flatten_binder(const sp\u0026lt;ProcessState\u0026gt;\u0026amp; /*proc*/, const sp\u0026lt;IBinder\u0026gt;\u0026amp; binder, Parcel* out) { flat_binder_object obj; if (binder != NULL) { IBinder *local = binder-\u0026gt;localBinder();//本地Binder即BBinder,即Server端的Binder  if (!local) {//BBinder为空时  BpBinder *proxy = binder-\u0026gt;remoteBinder(); const int32_t handle = proxy ? proxy-\u0026gt;handle() : 0; obj.hdr.type = BINDER_TYPE_HANDLE; obj.binder = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ obj.handle = handle; obj.cookie = 0; } else { //进入该分支  obj.hdr.type = BINDER_TYPE_BINDER;//后续在binder_transaction时会被调整为BINDER_TYPE_HANDLE类型，进而保存到serviceManager的链表当中  obj.binder = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local-\u0026gt;getWeakRefs()); obj.cookie = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local);//BBinder设置为flat_binder_object的cookie  } } else { obj.hdr.type = BINDER_TYPE_BINDER; obj.binder = 0; obj.cookie = 0; } return finish_flatten_binder(binder, obj, out); } 将flat_binder_object写入Parcel inline static status_t finish_flatten_binder( const sp\u0026lt;IBinder\u0026gt;\u0026amp; , const flat_binder_object\u0026amp; flat, Parcel* out) { return out-\u0026gt;writeObject(flat, false);//将flat_binder_object写入out } transact(ADD_SERVICE_TRANSACTION\u0026hellip;) mRemote.transact(ADD_SERVICE_TRANSACTION, data, reply, 0); serverInit camefromzygote\nframeworks/native/libs/binder/ProcessState.cpp\n#define BINDER_VM_SIZE ((1 * 1024 * 1024) - sysconf(_SC_PAGE_SIZE) * 2) #define DEFAULT_MAX_BINDER_THREADS 15 ProcessState::self sp\u0026lt;ProcessState\u0026gt; ProcessState::self() { gProcess = new ProcessState(\u0026#34;/dev/binder\u0026#34;); return gProcess; } open_driver \u0026amp;\u0026amp; mmap ProcessState::ProcessState(const char *driver) : mDriverName(String8(driver)) , mDriverFD(open_driver(driver))//call open_driver  , mVMStart(MAP_FAILED) , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER) , mThreadCountDecrement(PTHREAD_COND_INITIALIZER) , mExecutingThreadsCount(0) , mMaxThreads(DEFAULT_MAX_BINDER_THREADS) , mStarvationStartTimeMs(0) , mManagesContexts(false) , mBinderContextCheckFunc(NULL) , mBinderContextUserData(NULL) , mThreadPoolStarted(false) , mThreadPoolSeq(1) { if (mDriverFD \u0026gt;= 0) { // mmap the binder, providing a chunk of virtual address space to receive transactions.  mVMStart = mmap(0, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0); } } static int open_driver(const char *driver) { int fd = open(driver, O_RDWR | O_CLOEXEC); if (fd \u0026gt;= 0) { int vers = 0; status_t result = ioctl(fd, BINDER_VERSION, \u0026amp;vers); size_t maxThreads = DEFAULT_MAX_BINDER_THREADS; result = ioctl(fd, BINDER_SET_MAX_THREADS, \u0026amp;maxThreads); } else { ALOGW(\u0026#34;Opening \u0026#39;%s\u0026#39; failed: %s\\n\u0026#34;, driver, strerror(errno)); } return fd; } startThreadPool void ProcessState::startThreadPool() { AutoMutex _l(mLock); if (!mThreadPoolStarted) { mThreadPoolStarted = true; spawnPooledThread(true); } } spawnPooledThread void ProcessState::spawnPooledThread(bool isMain)//创建一个Thread用于提供Binder服务 { if (mThreadPoolStarted) { String8 name = makeBinderThreadName(); ALOGV(\u0026#34;Spawning new pooled thread, name=%s\\n\u0026#34;, name.string()); sp\u0026lt;Thread\u0026gt; t = new PoolThread(isMain); t-\u0026gt;run(name.string()); } } String8 ProcessState::makeBinderThreadName() { int32_t s = android_atomic_add(1, \u0026amp;mThreadPoolSeq); pid_t pid = getpid(); String8 name; name.appendFormat(\u0026#34;Binder:%d_%X\u0026#34;, pid, s); return name; } PoolThread::threadLoop │50 class PoolThread : public Thread │51 { 58 protected: │59 virtual bool threadLoop() │60 { \u0026gt;│61 IPCThreadState::self()-\u0026gt;joinThreadPool(mIsMain); │62 return false; │63 } 66 }; void IPCThreadState::threadDestructor(void *st) { IPCThreadState* const self = static_cast\u0026lt;IPCThreadState*\u0026gt;(st); if (self) { self-\u0026gt;flushCommands(); if (self-\u0026gt;mProcess-\u0026gt;mDriverFD \u0026gt; 0) { ioctl(self-\u0026gt;mProcess-\u0026gt;mDriverFD, BINDER_THREAD_EXIT, 0); } delete self; } } IPCThreadState::joinThreadPool 528 void IPCThreadState::joinThreadPool(bool isMain) │529 { │532 mOut.writeInt32(isMain ? BC_ENTER_LOOPER : BC_REGISTER_LOOPER); │533 │534 status_t result; │535 do { │536 processPendingDerefs(); │537 // now get the next command to be processed, waiting if necessary  \u0026gt;│538 result = getAndExecuteCommand(); │539 │540 if (result \u0026lt; NO_ERROR \u0026amp;\u0026amp; result != TIMED_OUT \u0026amp;\u0026amp; result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF) { │541 ALOGE(\u0026#34;getAndExecuteCommand(fd=%d) returned unexpected error %d, aborting\u0026#34;, │542 mProcess-\u0026gt;mDriverFD, result); │543 abort(); │544 } │545 │546 // Let this thread exit the thread pool if it is no longer  │547 // needed and it is not the main process thread.  │548 if(result == TIMED_OUT \u0026amp;\u0026amp; !isMain) { │549 break; │550 } │551 } while (result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF); │552 │556 mOut.writeInt32(BC_EXIT_LOOPER); │557 talkWithDriver(false); │558 } IPCThreadState::getAndExecuteCommand │435 status_t IPCThreadState::getAndExecuteCommand() │436 { │437 status_t result; │438 int32_t cmd; │439 │440 result = talkWithDriver(); 441 if (result \u0026gt;= NO_ERROR) { │442 size_t IN = mIn.dataAvail(); │443 if (IN \u0026lt; sizeof(int32_t)) return result; │444 cmd = mIn.readInt32(); \u0026gt;│458 result = executeCommand(cmd); │459 │460 pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); │461 mProcess-\u0026gt;mExecutingThreadsCount--; │471 pthread_cond_broadcast(\u0026amp;mProcess-\u0026gt;mThreadCountDecrement); │472 pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); │473 } │474 │475 return result; │476 } │477 IPCThreadState::executeCommand │998 status_t IPCThreadState::executeCommand(int32_t cmd) │999 { │1000 BBinder* obj; │1001 RefBase::weakref_type* refs; │1002 status_t result = NO_ERROR; │1003 │1004 switch ((uint32_t)cmd) { 1077 case BR_TRANSACTION: │1078 { │1079 binder_transaction_data tr; │1080 result = mIn.read(\u0026amp;tr, sizeof(tr)); │1103 Parcel reply; │1104 status_t error; │1116 if (tr.target.ptr) { │1117 // We only have a weak reference on the target object, so we must first try to  │1118 // safely acquire a strong reference before doing anything else with it.  │1119 if (reinterpret_cast\u0026lt;RefBase::weakref_type*\u0026gt;( │1120 tr.target.ptr)-\u0026gt;attemptIncStrong(this)) { \u0026gt;│1121 error = reinterpret_cast\u0026lt;BBinder*\u0026gt;(tr.cookie)-\u0026gt;transact(tr.code, buffer, │1122 \u0026amp;reply, tr.flags); │1123 reinterpret_cast\u0026lt;BBinder*\u0026gt;(tr.cookie)-\u0026gt;decStrong(this); │1124 } else { │1125 error = UNKNOWN_TRANSACTION; │1126 } │1127 │1128 } else { │1129 error = the_context_object-\u0026gt;transact(tr.code, buffer, \u0026amp;reply, tr.flags); │1130 } │1135 if ((tr.flags \u0026amp; TF_ONE_WAY) == 0) { │1136 LOG_ONEWAY(\u0026#34;Sending reply to %d!\u0026#34;, mCallingPid); │1137 if (error \u0026lt; NO_ERROR) reply.setError(error); │1138 sendReply(reply, 0); │1139 } else { │1140 LOG_ONEWAY(\u0026#34;NOT sending reply to %d!\u0026#34;, mCallingPid); │1141 } │1155 break; case BR_SPAWN_LOOPER: mProcess-\u0026gt;spawnPooledThread(false); break; binder_transaction_data.cookie作为BBinder,调用其transact │118 status_t BBinder::transact( │119 uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) │120 { │121 data.setDataPosition(0); │122 │123 status_t err = NO_ERROR; │124 switch (code) { │125 case PING_TRANSACTION: │126 reply-\u0026gt;writeInt32(pingBinder()); │127 break; │128 default: \u0026gt;│129 err = onTransact(code, data, reply, flags); │130 break; │131 } │132 │133 if (reply != NULL) { │134 reply-\u0026gt;setDataPosition(0); │135 } │136 │137 return err; │138 } JavaBBinder::onTransact调用java层Binder对应的execTransact方法 参考c和javabinder对应\nvirtual status_t onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0) { JNIEnv* env = javavm_to_jnienv(mVM); //printf(\u0026#34;Transact from %p to Java code sending: \u0026#34;, this);  //data.print();  //printf(\u0026#34;\\n\u0026#34;);  jboolean res = env-\u0026gt;CallBooleanMethod(mObject, gBinderOffsets.mExecTransact, code, reinterpret_cast\u0026lt;jlong\u0026gt;(\u0026amp;data), reinterpret_cast\u0026lt;jlong\u0026gt;(reply), flags); Binder.java\n// Entry point from android_util_Binder.cpp\u0026#39;s onTransact  private boolean execTransact(int code, long dataObj, long replyObj, int flags) { res = onTransact(code, data, reply, flags); } 其他关联知识点 system/core/libutils/Threads.cpp\nThreads::run status_t Thread::run(const char* name, int32_t priority, size_t stack) { if (mCanCallJava) { res = createThreadEtc(_threadLoop, this, name, priority, stack, \u0026amp;mThread); } else { res = androidCreateRawThreadEtc(_threadLoop, this, name, priority, stack, \u0026amp;mThread); } androidCreateRawThreadEtc int androidCreateRawThreadEtc(android_thread_func_t entryFunction, void *userData, const char* threadName __android_unused, int32_t threadPriority, size_t threadStackSize, android_thread_id_t *threadId) { int result = pthread_create(\u0026amp;thread, \u0026amp;attr, (android_pthread_entry)entryFunction, userData); } _threadLoop │711 int Thread::_threadLoop(void* user) │712 { 726 do { │727 bool result; │728 if (first) { │729 first = false; │730 self-\u0026gt;mStatus = self-\u0026gt;readyToRun(); │731 result = (self-\u0026gt;mStatus == NO_ERROR); │732 │733 if (result \u0026amp;\u0026amp; !self-\u0026gt;exitPending()) { │734 // Binder threads (and maybe others) rely on threadLoop  │735 // running at least once after a successful ::readyToRun()  │736 // (unless, of course, the thread has already been asked to exit  │737 // at that point).  │738 // This is because threads are essentially used like this:  │739 // (new ThreadSubclass())-\u0026gt;run();  │740 // The caller therefore does not retain a strong reference to  │741 // the thread and the thread would simply disappear after the  │742 // successful ::readyToRun() call instead of entering the  │743 // threadLoop at least once.  \u0026gt;│744 result = self-\u0026gt;threadLoop(); │745 } │746 } else { │747 result = self-\u0026gt;threadLoop(); │748 } 766 // Release our strong reference, to let a chance to the thread  │767 // to die a peaceful death.  │768 strong.clear(); │769 // And immediately, re-acquire a strong reference for the next loop  │770 strong = weak.promote(); │771 } while(strong != 0); frameworks/native/libs/binder/include/binder/IBinder.h\nIBinder /** * Base class and low-level protocol for a remotable object. * You can derive from this class to create an object for which other * processes can hold references to it. Communication between processes * (method calls, property get and set) is down through a low-level * protocol implemented on top of the transact() API. */ class IBinder : public virtual RefBase { /** * Check if this IBinder implements the interface named by * @a descriptor. If it does, the base pointer to it is returned, * which you can safely static_cast\u0026lt;\u0026gt; to the concrete C++ interface. */ virtual sp\u0026lt;IInterface\u0026gt; queryLocalInterface(const String16\u0026amp; descriptor); virtual status_t transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0) = 0; /** * Register the @a recipient for a notification if this binder * goes away. If this binder object unexpectedly goes away * (typically because its hosting process has been killed), * then DeathRecipient::binderDied() will be called with a reference * to this. * * The @a cookie is optional -- if non-NULL, it should be a * memory address that you own (that is, you know it is unique). * * @note You will only receive death notifications for remote binders, * as local binders by definition can\u0026#39;t die without you dying as well. * Trying to use this function on a local binder will result in an * INVALID_OPERATION code being returned and nothing happening. * * @note This link always holds a weak reference to its recipient. * * @note You will only receive a weak reference to the dead * binder. You should not try to promote this to a strong reference. * (Nor should you need to, as there is nothing useful you can * directly do with it now that it has passed on.) */ virtual status_t linkToDeath(const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie = NULL, uint32_t flags = 0) = 0; frameworks/native/libs/binder/include/binder/Binder.h\nBBinder class BBinder : public IBinder { public: virtual status_t transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0); virtual status_t linkToDeath(const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie = NULL, uint32_t flags = 0); protected: virtual ~BBinder(); virtual status_t onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0); frameworks/native/libs/binder/include/binder/IInterface.h\nIInterface class IInterface : public virtual RefBase { public: IInterface(); static sp\u0026lt;IBinder\u0026gt; asBinder(const IInterface*); static sp\u0026lt;IBinder\u0026gt; asBinder(const sp\u0026lt;IInterface\u0026gt;\u0026amp;); protected: virtual ~IInterface(); virtual IBinder* onAsBinder() = 0; }; template\u0026lt;typename INTERFACE\u0026gt; class BnInterface : public INTERFACE, public BBinder { public: virtual sp\u0026lt;IInterface\u0026gt; queryLocalInterface(const String16\u0026amp; _descriptor); virtual const String16\u0026amp; getInterfaceDescriptor() const; protected: virtual IBinder* onAsBinder(); }; template\u0026lt;typename INTERFACE\u0026gt; class BpInterface : public INTERFACE, public BpRefBase { public: explicit BpInterface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; remote); protected: virtual IBinder* onAsBinder(); }; BinderInternal_setMaxThreads frameworks/base/core/jni/android_util_Binder.cpp\nstatic void android_os_BinderInternal_setMaxThreads(JNIEnv* env, jobject clazz, jint maxThreads)// called by SystemServer.java BinderInternal.setMaxThreads { ProcessState::self()-\u0026gt;setThreadPoolMaxThreadCount(maxThreads); } frameworks/native/libs/binder/BpBinder.cpp\nBpBinder::create BpBinder* BpBinder::create(int32_t handle) { int32_t trackedUid = -1; if (sCountByUidEnabled) { trackedUid = IPCThreadState::self()-\u0026gt;getCallingUid(); } return new BpBinder(handle, trackedUid); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderservicemanager/",
	"title": "BinderServiceManager",
	"tags": [],
	"description": "",
	"content": "Sequence svclist frameworks/native/cmds/servicemanager/service_manager.c\nservice_manager.c(ServiceManger is single thread) main int main(int argc, char** argv) { struct binder_state *bs; union selinux_callback cb; char *driver; if (argc \u0026gt; 1) { driver = argv[1]; } else { driver = \u0026#34;/dev/binder\u0026#34;; } bs = binder_open(driver, 128*1024);//1  if (binder_become_context_manager(bs)) {//2  ALOGE(\u0026#34;cannot become context manager (%s)\\n\u0026#34;, strerror(errno)); return -1; } binder_loop(bs, svcmgr_handler);//3  return 0; } binder_open\nbinder_become_context_manager\nbinder_loop\nsvcmgr_handler int svcmgr_handler(struct binder_state *bs, struct binder_transaction_data *txn, struct binder_io *msg, struct binder_io *reply) { switch(txn-\u0026gt;code) { case SVC_MGR_GET_SERVICE: case SVC_MGR_CHECK_SERVICE: s = bio_get_string16(msg, \u0026amp;len); handle = do_find_service(s, len, txn-\u0026gt;sender_euid, txn-\u0026gt;sender_pid); if (!handle) break; bio_put_ref(reply, handle); return 0; case SVC_MGR_ADD_SERVICE: s = bio_get_string16(msg, \u0026amp;len); handle = bio_get_ref(msg); allow_isolated = bio_get_uint32(msg) ? 1 : 0; dumpsys_priority = bio_get_uint32(msg); if (do_add_service(bs, s, len, handle, txn-\u0026gt;sender_euid, allow_isolated, dumpsys_priority, txn-\u0026gt;sender_pid)) return -1; break; case SVC_MGR_LIST_SERVICES: { uint32_t n = bio_get_uint32(msg); uint32_t req_dumpsys_priority = bio_get_uint32(msg); if (!svc_can_list(txn-\u0026gt;sender_pid, txn-\u0026gt;sender_euid)) { ALOGE(\u0026#34;list_service() uid=%d - PERMISSION DENIED\\n\u0026#34;, txn-\u0026gt;sender_euid); return -1; } si = svclist; // walk through the list of services n times skipping services that  // do not support the requested priority  while (si) { if (si-\u0026gt;dumpsys_priority \u0026amp; req_dumpsys_priority) { if (n == 0) break; n--; } si = si-\u0026gt;next; } if (si) { bio_put_string16(reply, si-\u0026gt;name); return 0; } return -1; } default: ALOGE(\u0026#34;unknown code %d\\n\u0026#34;, txn-\u0026gt;code); return -1; } bio_put_uint32(reply, 0); return 0; } bio_get_string16\ndo_find_service\ndo_add_service int do_add_service(struct binder_state *bs, const uint16_t *s, size_t len, uint32_t handle, uid_t uid, int allow_isolated, uint32_t dumpsys_priority, pid_t spid) { struct svcinfo *si; if (!handle || (len == 0) || (len \u0026gt; 127)) return -1; if (!svc_can_register(s, len, spid, uid)) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - PERMISSION DENIED\\n\u0026#34;, str8(s, len), handle, uid); return -1; } si = find_svc(s, len); if (si) { if (si-\u0026gt;handle) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - ALREADY REGISTERED, OVERRIDE\\n\u0026#34;, str8(s, len), handle, uid); svcinfo_death(bs, si); } si-\u0026gt;handle = handle; } else { si = malloc(sizeof(*si) + (len + 1) * sizeof(uint16_t)); if (!si) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - OUT OF MEMORY\\n\u0026#34;, str8(s, len), handle, uid); return -1; } si-\u0026gt;handle = handle; si-\u0026gt;len = len; memcpy(si-\u0026gt;name, s, (len + 1) * sizeof(uint16_t)); si-\u0026gt;name[len] = \u0026#39;\\0\u0026#39;; si-\u0026gt;death.func = (void*) svcinfo_death; si-\u0026gt;death.ptr = si; si-\u0026gt;allow_isolated = allow_isolated; si-\u0026gt;dumpsys_priority = dumpsys_priority; si-\u0026gt;next = svclist; svclist = si; } binder_acquire(bs, handle); binder_link_to_death(bs, handle, \u0026amp;si-\u0026gt;death); return 0; } do_find_service uint32_t do_find_service(const uint16_t *s, size_t len, uid_t uid, pid_t spid) { struct svcinfo *si = find_svc(s, len); if (!si || !si-\u0026gt;handle) { return 0; } if (!si-\u0026gt;allow_isolated) { // If this service doesn\u0026#39;t allow access from isolated processes,  // then check the uid to see if it is isolated.  uid_t appid = uid % AID_USER; if (appid \u0026gt;= AID_ISOLATED_START \u0026amp;\u0026amp; appid \u0026lt;= AID_ISOLATED_END) { return 0; } } if (!svc_can_find(s, len, spid, uid)) { return 0; } return si-\u0026gt;handle; } find_svc\nstruct svcinfo struct svcinfo { struct svcinfo *next; uint32_t handle; struct binder_death death; int allow_isolated; uint32_t dumpsys_priority; size_t len; uint16_t name[0]; }; find_svc struct svcinfo *find_svc(const uint16_t *s16, size_t len) { struct svcinfo *si; for (si = svclist; si; si = si-\u0026gt;next) { if ((len == si-\u0026gt;len) \u0026amp;\u0026amp; !memcmp(s16, si-\u0026gt;name, len * sizeof(uint16_t))) { return si; } } return NULL; } frameworks/native/cmds/servicemanager/binder.c\nbinder.c binder_open struct binder_state *binder_open(const char* driver, size_t mapsize) { struct binder_state *bs; struct binder_version vers; bs-\u0026gt;fd = open(driver, O_RDWR | O_CLOEXEC); ioctl(bs-\u0026gt;fd, BINDER_VERSION, \u0026amp;vers) bs-\u0026gt;mapped = mmap(NULL, mapsize, PROT_READ, MAP_PRIVATE, bs-\u0026gt;fd, 0); } binder_become_context_manager int binder_become_context_manager(struct binder_state *bs) { return ioctl(bs-\u0026gt;fd, BINDER_SET_CONTEXT_MGR, 0); } binder_loop void binder_loop(struct binder_state *bs, binder_handler func) { int res; struct binder_write_read bwr; uint32_t readbuf[32]; bwr.write_size = 0; bwr.write_consumed = 0; bwr.write_buffer = 0; readbuf[0] = BC_ENTER_LOOPER; binder_write(bs, readbuf, sizeof(uint32_t)); for (;;) { bwr.read_size = sizeof(readbuf); bwr.read_consumed = 0; bwr.read_buffer = (uintptr_t) readbuf; res = ioctl(bs-\u0026gt;fd, BINDER_WRITE_READ, \u0026amp;bwr); res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func); } } binder_parse\nbinder_write int binder_write(struct binder_state *bs, void *data, size_t len) { struct binder_write_read bwr; int res; bwr.write_size = len; bwr.write_consumed = 0; bwr.write_buffer = (uintptr_t) data; bwr.read_size = 0; bwr.read_consumed = 0; bwr.read_buffer = 0; res = ioctl(bs-\u0026gt;fd, BINDER_WRITE_READ, \u0026amp;bwr); return res; } binder_parse int binder_parse(struct binder_state *bs, struct binder_io *bio, uintptr_t ptr, size_t size, binder_handler func) { while (ptr \u0026lt; end) { uint32_t cmd = *(uint32_t *) ptr; ptr += sizeof(uint32_t); switch(cmd) { case BR_TRANSACTION: { struct binder_transaction_data *txn = (struct binder_transaction_data *) ptr; if ((end - ptr) \u0026lt; sizeof(*txn)) { ALOGE(\u0026#34;parse: txn too small!\\n\u0026#34;); return -1; } binder_dump_txn(txn); if (func) { unsigned rdata[256/4]; struct binder_io msg; struct binder_io reply; int res; bio_init(\u0026amp;reply, rdata, sizeof(rdata), 4); bio_init_from_txn(\u0026amp;msg, txn); res = func(bs, txn, \u0026amp;msg, \u0026amp;reply);//callback method svcmgr_handler  if (txn-\u0026gt;flags \u0026amp; TF_ONE_WAY) { binder_free_buffer(bs, txn-\u0026gt;data.ptr.buffer); } else { binder_send_reply(bs, \u0026amp;reply, txn-\u0026gt;data.ptr.buffer, res); } } ptr += sizeof(*txn); break; } } bio_init_from_txn\nsvcmgr_handler\nstruct binder_io struct binder_io { char *data; /* pointer to read/write from */ binder_size_t *offs; /* array of offsets */ size_t data_avail; /* bytes available in data buffer */ size_t offs_avail; /* entries available in offsets array */ char *data0; /* start of data buffer */ binder_size_t *offs0; /* start of offsets buffer */ uint32_t flags; uint32_t unused; }; bio_init_from_txn void bio_init_from_txn(struct binder_io *bio, struct binder_transaction_data *txn) { bio-\u0026gt;data = bio-\u0026gt;data0 = (char *)(intptr_t)txn-\u0026gt;data.ptr.buffer; bio-\u0026gt;offs = bio-\u0026gt;offs0 = (binder_size_t *)(intptr_t)txn-\u0026gt;data.ptr.offsets; bio-\u0026gt;data_avail = txn-\u0026gt;data_size; bio-\u0026gt;offs_avail = txn-\u0026gt;offsets_size / sizeof(size_t); bio-\u0026gt;flags = BIO_F_SHARED; } bio_get_string16 uint16_t *bio_get_string16(struct binder_io *bio, size_t *sz) { size_t len; /* Note: The payload will carry 32bit size instead of size_t */ len = (size_t) bio_get_uint32(bio); if (sz) *sz = len; return bio_get(bio, (len + 1) * sizeof(uint16_t)); } uint32_t bio_get_uint32(struct binder_io *bio) { uint32_t *ptr = bio_get(bio, sizeof(*ptr)); return ptr ? *ptr : 0; } bio_get static void *bio_get(struct binder_io *bio, size_t size) { size = (size + 3) \u0026amp; (~3); if (bio-\u0026gt;data_avail \u0026lt; size){ bio-\u0026gt;data_avail = 0; bio-\u0026gt;flags |= BIO_F_OVERFLOW; return NULL; } else { void *ptr = bio-\u0026gt;data; bio-\u0026gt;data += size; bio-\u0026gt;data_avail -= size; return ptr; } } bio_get_ref uint32_t bio_get_ref(struct binder_io *bio) { struct flat_binder_object *obj; obj = _bio_get_obj(bio); if (!obj) return 0; if (obj-\u0026gt;hdr.type == BINDER_TYPE_HANDLE) return obj-\u0026gt;handle; return 0; } bio_put_ref void bio_put_ref(struct binder_io *bio, uint32_t handle) { struct flat_binder_object *obj; if (handle) obj = bio_alloc_obj(bio); else obj = bio_alloc(bio, sizeof(*obj)); if (!obj) return; obj-\u0026gt;flags = 0x7f | FLAT_BINDER_FLAG_ACCEPTS_FDS; obj-\u0026gt;hdr.type = BINDER_TYPE_HANDLE; obj-\u0026gt;handle = handle; obj-\u0026gt;cookie = 0; } _bio_get_obj static struct flat_binder_object *_bio_get_obj(struct binder_io *bio) { size_t n; size_t off = bio-\u0026gt;data - bio-\u0026gt;data0; for (n = 0; n \u0026lt; bio-\u0026gt;offs_avail; n++) { if (bio-\u0026gt;offs[n] == off) return bio_get(bio, sizeof(struct flat_binder_object)); } bio-\u0026gt;data_avail = 0; bio-\u0026gt;flags |= BIO_F_OVERFLOW; return NULL; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binder%E5%8E%9F%E7%90%86/",
	"title": "Binder原理",
	"tags": [],
	"description": "",
	"content": "写给 android 应用工程师的 binder 原理剖析\n架构设计分析（三）Android 9.0 Binder机制\n彻底理解Android Binder通信架构 Android 6.0\nBinder系列5—注册服务(addService)\nAndroid IPC: Part 2 - Binder and Service Manager Perspective\n深入理解Binder通信原理及面试问题\nBinder | 内存拷贝的本质和变迁\nLinux 背景知识 传统 IPC 通信原理 Binder IPC 原理 BinderProcedure flow struct binder_write_read transact total "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/bitmap/bitmap/",
	"title": "Bitmap",
	"tags": [],
	"description": "",
	"content": "Bitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/bitmap/",
	"title": "bitmap",
	"tags": [],
	"description": "",
	"content": "bitmap 探索总结bitmap知识\n Bitmap     BitmapSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/bitmap/bitmapsource/",
	"title": "BitmapSource",
	"tags": [],
	"description": "",
	"content": "类设计 NativeAllocationRegistry procedure ART reclaim NativeAllocationRegistry procedure(only object which will be reclaim(GC not reachable) would be enqueued)\ngraph TB ReferenceQueueDaemon.runInernal--\u0026gt;ReferenceQueue.enqueuePending ReferenceQueue.enqueuePending--\u0026gt;ReferenceQueue.enqueueLocked ReferenceQueue.enqueueLocked--\u0026gt;Cleaner.clean Cleaner.clean--\u0026gt;CleanerChunk.run CleanerChunk.run--\u0026gt;NativeAllocationRegistry.applyFreeFunction ImageDecoder decodeDrawable public static Drawable decodeDrawable(@NonNull Source src, @NonNull OnHeaderDecodedListener listener) throws IOException { return decodeDrawableImpl(src, listener); } decodeDrawableImpl private static Drawable decodeDrawableImpl(@NonNull Source src, @Nullable OnHeaderDecodedListener listener) throws IOException { ImageDecoder decoder = src.createImageDecoder() decoder.mSource = src; decoder.callHeaderDecoded(listener, src); Bitmap bm = decoder.decodeBitmapInternal(); return new BitmapDrawable(res, bm); } decodeBitmapInternal private Bitmap decodeBitmapInternal() throws IOException { checkState(); return nDecodeBitmap(mNativePtr, this, mPostProcessor != null, mDesiredWidth, mDesiredHeight, mCropRect, mMutable, mAllocator, mUnpremultipliedRequired, mConserveMemory, mDecodeAsAlphaMask, mDesiredColorSpace); } Source frameworks/base/core/jni/android/graphics/ImageDecoder.cpp\nImageDecoder.cpp ImageDecoder_nDecodeBitmap static jobject ImageDecoder_nDecodeBitmap(JNIEnv* env, jobject /*clazz*/, jlong nativePtr, jobject jdecoder, jboolean jpostProcess, jint desiredWidth, jint desiredHeight, jobject jsubset, jboolean requireMutable, jint allocator, jboolean requireUnpremul, jboolean preferRamOverQuality, jboolean asAlphaMask, jobject jcolorSpace) {\t...... SkBitmap bm; auto bitmapInfo = decodeInfo; if (asAlphaMask \u0026amp;\u0026amp; colorType == kGray_8_SkColorType) { bitmapInfo = bitmapInfo.makeColorType(kAlpha_8_SkColorType); } if (!bm.setInfo(bitmapInfo)) { doThrowIOE(env, \u0026#34;Failed to setInfo properly\u0026#34;); return nullptr; } sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap; // If we are going to scale or subset, we will create a new bitmap later on,  // so use the heap for the temporary.  // FIXME: Use scanline decoding on only a couple lines to save memory. b/70709380.  if (allocator == ImageDecoder::kSharedMemory_Allocator \u0026amp;\u0026amp; !scale \u0026amp;\u0026amp; !jsubset) { nativeBitmap = Bitmap::allocateAshmemBitmap(\u0026amp;bm); } else { nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;bm);//nativeBitmap和bm都被赋值完毕  } ...... return bitmap::createBitmap(env, nativeBitmap.release(), bitmapCreateFlags, ninePatchChunk, ninePatchInsets); } allocateheapbitmap\ncreateBitmap\nBitmap.java android/graphics/Bitmap.java\ncreateBitmap public static Bitmap createBitmap(@Nullable DisplayMetrics display, int width, int height, @NonNull Config config, boolean hasAlpha, @NonNull ColorSpace colorSpace) { bm = nativeCreate(null, 0, width, width, height, config.nativeInt, true, null, null); return bm; nativeCreate\nBitmapCons() /** * Private constructor that must received an already allocated native bitmap * int (pointer). */ // called from JNI Bitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { mWidth = width; mHeight = height; mIsMutable = isMutable; mRequestPremultiplied = requestPremultiplied; mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); } frameworks/base/core/jni/android/graphics/\nBitmap.cpp(graphics) gBitmapMethods nativeCreate \u0026ndash;\u0026gt; Bitmap_creator\nstatic const JNINativeMethod gBitmapMethods[] = { { \u0026#34;nativeCreate\u0026#34;, \u0026#34;([IIIIIIZ[FLandroid/graphics/ColorSpace$Rgb$TransferParameters;)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_creator }, { \u0026#34;nativeCopy\u0026#34;, \u0026#34;(JIZ)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copy }, { \u0026#34;nativeCopyAshmem\u0026#34;, \u0026#34;(J)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copyAshmem }, { \u0026#34;nativeCopyAshmemConfig\u0026#34;, \u0026#34;(JI)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copyAshmemConfig }, { \u0026#34;nativeGetNativeFinalizer\u0026#34;, \u0026#34;()J\u0026#34;, (void*)Bitmap_getNativeFinalizer }, { \u0026#34;nativeRecycle\u0026#34;, \u0026#34;(J)Z\u0026#34;, (void*)Bitmap_recycle }, { \u0026#34;nativeReconfigure\u0026#34;, \u0026#34;(JIIIZ)V\u0026#34;, (void*)Bitmap_reconfigure }, { \u0026#34;nativeCompress\u0026#34;, \u0026#34;(JIILjava/io/OutputStream;[B)Z\u0026#34;, (void*)Bitmap_compress }, { \u0026#34;nativeErase\u0026#34;, \u0026#34;(JI)V\u0026#34;, (void*)Bitmap_erase }, { \u0026#34;nativeRowBytes\u0026#34;, \u0026#34;(J)I\u0026#34;, (void*)Bitmap_rowBytes }, { \u0026#34;nativeGetPixel\u0026#34;, \u0026#34;(JII)I\u0026#34;, (void*)Bitmap_getPixel }, { \u0026#34;nativeGetPixels\u0026#34;, \u0026#34;(J[IIIIIII)V\u0026#34;, (void*)Bitmap_getPixels }, { \u0026#34;nativeSetPixel\u0026#34;, \u0026#34;(JIII)V\u0026#34;, (void*)Bitmap_setPixel }, { \u0026#34;nativeSetPixels\u0026#34;, \u0026#34;(J[IIIIIII)V\u0026#34;, (void*)Bitmap_setPixels }, { \u0026#34;nativeCopyPixelsToBuffer\u0026#34;, \u0026#34;(JLjava/nio/Buffer;)V\u0026#34;, (void*)Bitmap_copyPixelsToBuffer }, { \u0026#34;nativeCopyPixelsFromBuffer\u0026#34;, \u0026#34;(JLjava/nio/Buffer;)V\u0026#34;, (void*)Bitmap_copyPixelsFromBuffer }, }; Bitmap_creator static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkBitmap bitmap; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;bitmap); if (!nativeBitmap) { ALOGE(\u0026#34;OOM allocating Bitmap with dimensions %i x %i\u0026#34;, width, height); doThrowOOME(env); return NULL; } if (jColors != NULL) { GraphicsJNI::SetPixels(env, jColors, offset, stride, 0, 0, width, height, bitmap); } return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); allocateheapbitmap\ncreateBitmap\nbitmap::createBitmap jobject createBitmap(JNIEnv* env, Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { bool isMutable = bitmapCreateFlags \u0026amp; kBitmapCreateFlag_Mutable; bool isPremultiplied = bitmapCreateFlags \u0026amp; kBitmapCreateFlag_Premultiplied; // The caller needs to have already set the alpha type properly, so the  // native SkBitmap stays in sync with the Java Bitmap.  BitmapWrapper* bitmapWrapper = new BitmapWrapper(bitmap); jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmapWrapper), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); return obj; } bitmapcons\nBitmap_getNativeFinalizer static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } Bitmap_destruct static void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } libcore/luni/src/main/java/libcore/util\nNativeAllocationRegistry.java /** * A NativeAllocationRegistry is used to associate native allocations with * Java objects and register them with the runtime. * There are two primary benefits of registering native allocations associated * with Java objects: * \u0026lt;ol\u0026gt; * \u0026lt;li\u0026gt;The runtime will account for the native allocations when scheduling * garbage collection to run.\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;The runtime will arrange for the native allocation to be automatically * freed by a user-supplied function when the associated Java object becomes * unreachable.\u0026lt;/li\u0026gt; * \u0026lt;/ol\u0026gt; * A separate NativeAllocationRegistry should be instantiated for each kind * of native allocation, where the kind of a native allocation consists of the * native function used to free the allocation and the estimated size of the * allocation. Once a NativeAllocationRegistry is instantiated, it can be * used to register any number of native allocations of that kind. * @hide */ public class NativeAllocationRegistry { public NativeAllocationRegistry(ClassLoader classLoader, long freeFunction, long size) { this.classLoader = classLoader; this.freeFunction = freeFunction; this.size = size; } } registerNativeAllocation /** * Registers a new native allocation and associated Java object with the * runtime. * This NativeAllocationRegistry\u0026#39;s \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; will * automatically be called with \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; as its sole * argument when \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable. If you * maintain copies of \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; outside * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt;, you must not access these after * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable, because they may be dangling * pointers. * \u0026lt;p\u0026gt; * The returned Runnable can be used to free the native allocation before * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable. The runnable will have no * effect if the native allocation has already been freed by the runtime * or by using the runnable. * \u0026lt;p\u0026gt; * WARNING: This unconditionally takes ownership, i.e. deallocation * responsibility of nativePtr. nativePtr will be DEALLOCATED IMMEDIATELY * if the registration attempt throws an exception (other than one reporting * a programming error). * * @param referent Non-null java object to associate the native allocation with * @param nativePtr Non-zero address of the native allocation * @return runnable to explicitly free native allocation * @throws IllegalArgumentException if either referent or nativePtr is null. * @throws OutOfMemoryError if there is not enough space on the Java heap * in which to register the allocation. In this * case, \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; will be * called with \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; as its * argument before the OutOfMemoryError is * thrown. */ public Runnable registerNativeAllocation(Object referent, long nativePtr) { if (referent == null) { throw new IllegalArgumentException(\u0026#34;referent is null\u0026#34;); } if (nativePtr == 0) { throw new IllegalArgumentException(\u0026#34;nativePtr is null\u0026#34;); } CleanerThunk thunk; CleanerRunner result; try { thunk = new CleanerThunk(); Cleaner cleaner = Cleaner.create(referent, thunk); result = new CleanerRunner(cleaner); registerNativeAllocation(this.size); } catch (VirtualMachineError vme /* probably OutOfMemoryError */) { applyFreeFunction(freeFunction, nativePtr); throw vme; } // Other exceptions are impossible.  // Enable the cleaner only after we can no longer throw anything, including OOME.  thunk.setNativePtr(nativePtr); return result; } CleanerThunk private class CleanerThunk implements Runnable { private long nativePtr; public CleanerThunk() { this.nativePtr = 0; } public void run() { if (nativePtr != 0) { applyFreeFunction(freeFunction, nativePtr); registerNativeFree(size); } } public void setNativePtr(long nativePtr) { this.nativePtr = nativePtr; } } applyFreeFunction /** * Calls \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt;(\u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt;). * Provided as a convenience in the case where you wish to manually free a * native allocation using a \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; without using a * NativeAllocationRegistry. */ public static native void applyFreeFunction(long freeFunction, long nativePtr); registerNativeFree private static void registerNativeFree(long size) { VMRuntime.getRuntime().registerNativeFree((int)Math.min(size, Integer.MAX_VALUE)); } registerNativeAllocation private static void registerNativeAllocation(long size) { VMRuntime.getRuntime().registerNativeAllocation((int)Math.min(size,Integer.MAX_VALUE)); } CleanerRunner private static class CleanerRunner implements Runnable { private final Cleaner cleaner; public CleanerRunner(Cleaner cleaner) { this.cleaner = cleaner; } public void run() { cleaner.clean(); } } libcore/ojluni/src/main/java/sun/misc/Cleaner.java\nCleaner create public class Cleaner extends PhantomReference\u0026lt;Object\u0026gt; { /** * Creates a new cleaner. * * @param ob the referent object to be cleaned * @param thunk * The cleanup code to be run when the cleaner is invoked. The * cleanup code is run directly from the reference-handler thread, * so it should be as simple and straightforward as possible. * * @return The new cleaner */ public static Cleaner create(Object ob, Runnable thunk) { if (thunk == null) return null; return add(new Cleaner(ob, thunk)); } add private static synchronized Cleaner add(Cleaner cl) { if (first != null) { cl.next = first; first.prev = cl;//双向链表，插入表头  } first = cl; return cl; }\tclean /** * Runs this cleaner, if it has not been run before. */ public void clean() { if (!remove(this)) return; try { thunk.run(); } } libcore/libart/src/main/java/dalvik/system/\nVMRuntime.java registerNativeAllocation /** * Registers a native allocation so that the heap knows about it and performs GC as required. * If the number of native allocated bytes exceeds the native allocation watermark, the * function requests a concurrent GC. If the native bytes allocated exceeds a second higher * watermark, it is determined that the application is registering native allocations at an * unusually high rate and a GC is performed inside of the function to prevent memory usage * from excessively increasing. Memory allocated via system malloc() should not be included * in this count. The argument must be the same as that later passed to registerNativeFree(), * but may otherwise be approximate. */ @UnsupportedAppUsage @libcore.api.CorePlatformApi public native void registerNativeAllocation(long bytes); frameworks/base/libs/hwui/hwui/Bitmap.cpp\nBitmap.cpp(hwui) class ANDROID_API Bitmap : public SkPixelRef {} AllocPixelRef function typedef sk_sp\u0026lt;Bitmap\u0026gt; (*AllocPixelRef)(size_t allocSize, const SkImageInfo\u0026amp; info, size_t rowBytes); allocateHeapBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateHeapBitmap(SkBitmap* bitmap) { return allocateBitmap(bitmap, \u0026amp;android::allocateHeapBitmap); } allocateBitmap static sk_sp\u0026lt;Bitmap\u0026gt; allocateBitmap(SkBitmap* bitmap, AllocPixelRef alloc) { const SkImageInfo\u0026amp; info = bitmap-\u0026gt;info(); // we must respect the rowBytes value already set on the bitmap instead of  // attempting to compute our own.  const size_t rowBytes = bitmap-\u0026gt;rowBytes(); if (!computeAllocationSize(rowBytes, bitmap-\u0026gt;height(), \u0026amp;size)) { return nullptr; } auto wrapper = alloc(size, info, rowBytes); if (wrapper) { wrapper-\u0026gt;getSkBitmap(bitmap); } return wrapper; alloc\nandroid::allocateHeapBitmap static sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { void* addr = calloc(size, 1);//申请bitmap内存空间,单位bytes，默认初始化为0  if (!addr) { return nullptr; } return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } getSkBitmap void Bitmap::getSkBitmap(SkBitmap* outBitmap) { outBitmap-\u0026gt;setHasHardwareMipMap(mHasHardwareMipMap); if (isHardware()) { if (uirenderer::Properties::isSkiaEnabled()) { outBitmap-\u0026gt;allocPixels(SkImageInfo::Make(info().width(), info().height(), info().colorType(), info().alphaType(), nullptr)); } else { outBitmap-\u0026gt;allocPixels(info()); } uirenderer::renderthread::RenderProxy::copyGraphicBufferInto(graphicBuffer(), outBitmap); if (mInfo.colorSpace()) { sk_sp\u0026lt;SkPixelRef\u0026gt; pixelRef = sk_ref_sp(outBitmap-\u0026gt;pixelRef()); outBitmap-\u0026gt;setInfo(mInfo); outBitmap-\u0026gt;setPixelRef(std::move(pixelRef), 0, 0); } return; } outBitmap-\u0026gt;setInfo(mInfo, rowBytes()); outBitmap-\u0026gt;setPixelRef(sk_ref_sp(this), 0, 0); } setinfo\nsetpixelref\nallocateAshmemBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateAshmemBitmap(SkBitmap* bitmap) { return allocateBitmap(bitmap, \u0026amp;Bitmap::allocateAshmemBitmap); } allocatebitmap\nallocateAshmemBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateAshmemBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { // Create new ashmem region with read/write priv  int fd = ashmem_create_region(\u0026#34;bitmap\u0026#34;, size); if (fd \u0026lt; 0) { return nullptr; } void* addr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if (addr == MAP_FAILED) { close(fd); return nullptr; } if (ashmem_set_prot_region(fd, PROT_READ) \u0026lt; 0) { munmap(addr, size); close(fd); return nullptr; } return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, fd, size, info, rowBytes)); } external/skia/src/core/\nSkBitmap.cpp setInfo bool SkBitmap::setInfo(const SkImageInfo\u0026amp; info, size_t rowBytes) { fPixelRef = nullptr; // Free pixels.  fPixmap.reset(info.makeAlphaType(newAT), nullptr, SkToU32(rowBytes)); return true; makealphatype\nsetPixelRef void SkBitmap::setPixelRef(sk_sp\u0026lt;SkPixelRef\u0026gt; pr, int dx, int dy) { fPixelRef = kUnknown_SkColorType != this-\u0026gt;colorType() ? std::move(pr) : nullptr; void* p = nullptr; size_t rowBytes = this-\u0026gt;rowBytes(); // ignore dx,dy if there is no pixelref  if (fPixelRef) { rowBytes = fPixelRef-\u0026gt;rowBytes(); // TODO(reed): Enforce that PixelRefs must have non-null pixels.  p = fPixelRef-\u0026gt;pixels(); if (p) { p = (char*)p + dy * rowBytes + dx * this-\u0026gt;bytesPerPixel(); } } SkPixmapPriv::ResetPixmapKeepInfo(\u0026amp;fPixmap, p, rowBytes); pixels\nexternal/skia/include/core/SkPixelRef.h\nSkPixelRef pixels void* pixels() const { return fPixels; } size_t rowBytes() const { return fRowBytes; } external/skia/include/core/\nSkImageInfo.h makeAlphaType SkImageInfo makeAlphaType(SkAlphaType newAlphaType) const { return Make(fWidth, fHeight, fColorType, newAlphaType, fColorSpace); } external/skia/src/core/\nSkPixmap reset void SkPixmap::reset(const SkImageInfo\u0026amp; info, const void* addr, size_t rowBytes) { fPixels = addr; fRowBytes = rowBytes; fInfo = info; } "
},
{
	"uri": "https://huanle19891345.github.io/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/",
	"title": "flutter",
	"tags": [],
	"description": "",
	"content": "flutter 探索总结flutter知识\n 通信    Flutter消息机制      "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/flutter%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6/",
	"title": "Flutter消息机制",
	"tags": [],
	"description": "",
	"content": "消息机制 深入理解Flutter消息机制\nThreadHost初始化\n[-\u0026gt; flutter/shell/common/thread_host.cc] ThreadHost::ThreadHost(std::string name_prefix, uint64_t mask) { if (mask \u0026amp; ThreadHost::Type::Platform) { platform_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.platform\u0026quot;); } if (mask \u0026amp; ThreadHost::Type::UI) { //创建线程 [见小节2.2] ui_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.ui\u0026quot;); } if (mask \u0026amp; ThreadHost::Type::GPU) { gpu_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.gpu\u0026quot;); } if (mask \u0026amp; ThreadHost::Type::IO) { io_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.io\u0026quot;); } } TaskRunner初始化\n[-\u0026gt; flutter/fml/task_runner.cc] TaskRunner::TaskRunner(fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop) : loop_(std::move(loop)) {} Flutter引擎启动过程，会创建UI/GPU/IO这3个线程，并且会为每个线程依次创建MessageLoop对象，启动后处于epoll_wait等待状态。对于Flutter的消息机制跟Android原生的消息机制有很多相似之处，都有消息(或者任务)、消息队列以及Looper，有一点不同的是Android有一个Handler类，用于发送消息以及执行回调方法，相对应Flutter中有着相近功能的便是TaskRunner。\n上图是从源码中提炼而来的任务处理流程，比官方流程图更容易理解一些复杂流程的时序问题，后续会专门讲解个中原由。Flutter的任务队列处理机制跟Android的消息队列处理相通，只不过Flutter分为Task和MicroTask两种类型，引擎和Dart虚拟机的事件以及Future都属于Task，Dart层执行scheduleMicrotask()所产生的属于Microtask。\n每次Flutter引擎在消费任务时调用FlushTasks()方法，遍历整个延迟任务队列delayed_tasks_，将已到期的任务加入task队列，然后开始处理任务。\n Step 1: 检查task，当task队列不为空，先执行一个task； Step 2: 检查microTask，当microTask不为空，则执行microTask；不断循环Step 2 直到microTask队列为空，再回到执行Step 1；  可简单理解为先处理完所有的Microtask，然后再处理Task。因为scheduleMicrotask()方法的调用自身就处于一个Task，执行完当前的task，也就意味着马上执行该Microtask。\n了解了其工作机制，再来看看这4个Task Runner的具体工作内容。\n Platform Task Runner：运行在Android或者iOS的主线程，尽管阻塞该线程并不会影响Flutter渲染管道，平台线程建议不要执行耗时操作；否则可能触发watchdog来结束该应用。比如Android、iOS都是使用平台线程来传递用户输入事件，一旦平台线程被阻塞则会引起手势事件丢失。 UI Task Runner: 运行在ui线程，比如1.ui，用于引擎执行root isolate中的所有Dart代码，执行渲染与处理Vsync信号，将widget转换生成Layer Tree。除了渲染之外，还有处理Native Plugins消息、Timers、Microtasks等工作； GPU Task Runner：运行在gpu线程，比如1.gpu，用于将Layer Tree转换为具体GPU指令，执行设备GPU相关的skia调用，转换相应平台的绘制方式，比如OpenGL, vulkan, metal等。每一帧的绘制需要UI Runner和GPU Runner配合完成，任何一个环节延迟都可能导致掉帧； IO Task Runner：运行在io线程，比如1.io，前3个Task Runner都不允许执行耗时操作，该Runner用于将图片从磁盘读取出来，解压转换为GPU可识别的格式后，再上传给GPU线程。为了能访问GPU，IO Runner跟GPU Runner的Context在同一个ShareGroup。比如ui.image通过异步调用让IO Runner来异步加载图片，该线程不能执行其他耗时操作，否则可能会影响图片加载的性能。  深入理解Flutter异步Future机制\n深入理解Flutter的Isolate创建过程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/google/",
	"title": "google",
	"tags": [],
	"description": "",
	"content": "google 探索总结google知识\n supportToAndroidx     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/graphics/",
	"title": "Graphics",
	"tags": [],
	"description": "",
	"content": "https://source.android.com/devices/graphics/index.html\nAndroid graphics components No matter what rendering API developers use, everything is rendered onto a \u0026ldquo;surface.\u0026rdquo; The surface represents the producer side of a buffer queue that is often consumed by SurfaceFlinger. Every window that is created on the Android platform is backed by a surface. A==ll of the visible surfaces rendered are composited onto the display by SurfaceFlinger.==\nThe following diagram shows how the key components work together:\nFigure 1. How surfaces are rendered\nThe main components are described below:\nImage Stream Producers An image stream producer can be anything that ==produces graphic buffers for consumption==. Examples include ==OpenGL ES, Canvas 2D==, and mediaserver video decoders.\nFigure 2. Graphic data flow through Android\n OpenGL ES OpenGL for Embedded Systems (OpenGL ES or GLES) is a subset[2] of the OpenGL computer graphics rendering application programming interface (API) for rendering 2D and 3D computer graphics such as those used by video games, ==typically hardware-accelerated using a graphics processing unit (GPU)==. It is designed for embedded systems like smartphones, tablet computers, video game consoles and PDAs. OpenGL ES is the \u0026ldquo;most widely deployed 3D graphics API in history\u0026rdquo;.[3]\nThe API is cross-language and multi-platform. The libraries GLUT and GLU are not available for OpenGL ES. OpenGL ES is managed by the non-profit technology consortium Khronos Group. Vulkan, a next-generation API from Khronos, is made for simpler high performance drivers for mobile and desktop devices.[4]\nVulkan Application developers use Vulkan to create apps that ==execute commands on the GPU== with significantly reduced overhead. Vulkan also provides a more direct mapping to the capabilities found in current graphics hardware ==compared to EGL and GLES==, minimizing opportunities for driver bugs and reducing developer testing time.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/handler/",
	"title": "handler",
	"tags": [],
	"description": "",
	"content": "handler 探索总结handler知识\n Looper     ThreadLocal     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/input/",
	"title": "input",
	"tags": [],
	"description": "",
	"content": "input 探索总结input知识\n touchEventNative     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/kernel/",
	"title": "kernel",
	"tags": [],
	"description": "",
	"content": "kernel 探索总结kernel知识\n kernel     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/kernel/kernel/",
	"title": "kernel",
	"tags": [],
	"description": "",
	"content": "下载和编译内核步骤 Android 9.0内核编译\n下载内核 cd kernel git clone https://android.googlesource.com/kernel/goldfish 执行完这两条命令后就可以看到kernel目录下有一个goldfish目录了,goldfish内核专门是提供给emulator用的.\ncd goldfish git branch -r git checkout origin/android-goldfish-4.4-dev -b android-goldfish-4.4-dev 这里涉及到要下载哪个版本的内核,emulator命令默认用的是qemu内核, 一般跟这个版本的内核一样就可以了,可以直接启用emulator然后进入到Settings-\u0026gt;System-\u0026gt;About phone-\u0026gt;点击Android version,里面就有内核版本号.\n编译内核 一定要和Android编译时lunch选的一样, 可以进入到out/target/product目录下查看自己编的是什么版本, 如果是generic_x86_64,那lunch的就是aosp_x86_64_eng的,其他版本依此类推. 接下来就可以编译了,下面我提供了几个编译的脚本大家可以进行对比和参照,lunch不同的版本对应的脚本是不一样的,即使编译通过了,也不能运行,我因为这个浪费了很长的时间 使用方法:\n 在goldfish目录下创建一个build.sh文件 将脚本里面的内容复制到build.sh中,或者根据脚本自己写, 注意lunch的版本 执行chmod a+rx build.sh并且执行./build.sh.  aosp_x86-eng #指定编译的内核类型 export ARCH=x86 #指定的gcc编译器的前缀, 就是下面PATH中的x86_64-linux-android-4.9的前缀 export CROSS_COMPILE=x86_64-linux-android- export REAL_CROSS_COMPILE=x86_64-linux-android- #这里android_root要写是android根目录的绝对地址例如: ~/google/android-9.0 PATH=$PATH:/home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gcc/linux-x86/x86/x86_64-linux-android-4.9/bin #编译的配置,在arch/x86/configs目录下, make x86_64_ranchu_defconfig #编译内核命令 make -j16 编译内核大概10来分钟就可以完成了,之后会生成一个arch/x86_64/boot/bzImage的东西,不同kernel生成的是不一样的,要看清楚. 最后回到android根目录执行emulator -kernel kernel/goldfish/arch/x86/boot/bzImage启动虚拟机\n启动虚拟机 ~/Android/Source/android-9.0.0_r3$ emulator -show-kernel -kernel /home/zhenghuan/Android/Source/kernel/goldfish/arch/x86/boot/bzImage -qemu -s  -kernel use specific emulated kernel 指定模拟器的内核，这里指定我们自己编译的内核arch/x86/boot/bzImage -qemu args... pass arguments to qemu 传递qemu参数，emulator就是基于qemu开发的 -s 是qemu参数，等同于-gdb tcp::1234，意思就是通过tcp的1234端口，gdb可以连接到内核中的kgdb。一般连接kgdb都要通过串口来连接，但是qemu通过指定-gdb tcp::1234就可以了，不知到原理是什么。  调试android内核 使用Android模拟器调试linux内核\n如何在Android上调试内核 在Android上调试内核，一般都要借助于内核中的kgdb。kgdb是内核对gdb的支持，通过编译配置kgdb和其他相关配置，可以通过gdb远程连接到内核中的kgdb。kgdb只能远程调试，也就是说，要有一台被调试的机器(target machine)和一台开发机器(develop machine)。如果真机调试，target就是手机，develop就是ubuntu主机。如果是模拟器调试，target就是模拟器，develop是ubuntu主机。\n步骤 goldfish/.config编译选项 CONFIG_DEBUG_KERNEL=y 打开这个选项后，vmlinux 才有符号 CONFIG_DEBUG_INFO=y CONFIG_FRAME_POINTER=y //开启kgdb CONFIG_KGDB=y CONFIG_DEBUG_RODATA=n CONFIG_RANDOMIZE_BASE=n CONFIG_DEBUG_RODATA这个选项我们虽然手动设置为n，但是执行make后会被覆盖，所以我们要改以下两个文件，确保CONFIG_DEBUG_RODATA不开启:\nzhangjg@zjg:~/deve/open_source/android-kernel/goldfish$ git diff diff --git a/arch/arm/mm/Kconfig b/arch/arm/mm/Kconfig index 41218867a9a6..e67810313d97 100644 --- a/arch/arm/mm/Kconfig +++ b/arch/arm/mm/Kconfig @@ -1052,7 +1052,7 @@ config ARM_KERNMEM_PERMS config DEBUG_RODATA bool \u0026#34;Make kernel text and rodata read-only\u0026#34; depends on ARM_KERNMEM_PERMS - default y + default n help If this is set, kernel text and rodata will be made read-only. This is to help catch accidental or malicious attempts to change the diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig index ad1f3bfafe75..50fa4dc68eff 100644 --- a/arch/x86/Kconfig +++ b/arch/x86/Kconfig @@ -307,7 +307,7 @@ config FIX_EARLYCON_MEM def_bool y config DEBUG_RODATA - def_bool y + def_bool n config PGTABLE_LEVELS int 注意，一定确保CONFIG_DEBUG_RODATA和CONFIG_RANDOMIZE_BASE不开启，如果开启这两个选项，通过gdb不能设置断点，报如下错误:\n(gdb) b vfs_write Breakpoint 1 at 0xffffffff803474d8: file fs/read_write.c, line 524. (gdb) c Continuing. Warning: Cannot insert breakpoint 1. Cannot access memory at address 0xffffffff803474d8 make -j16 Serial console over KGDB NMI debugger port (SERIAL_KGDB_NMI) [N/y/?] (NEW) N KGDB: kernel debugger (KGDB) [Y/n/?] y KGDB: use kgdb over the serial console (KGDB_SERIAL_CONSOLE) [Y/n/m/?] (NEW) n KGDB: internal test suite (KGDB_TESTS) [N/y/?] (NEW) N KGDB: Allow debugging with traps in notifiers (KGDB_LOW_LEVEL_TRAP) [N/y/?] (NEW) N KGDB_KDB: include kdb frontend for kgdb (KGDB_KDB) [N/y/?] (NEW) y KDB: Select kdb command functions to be enabled by default (KDB_DEFAULT_ENABLE) [0x1] (NEW) 0x1 KGDB_KDB: keyboard as input device (KDB_KEYBOARD) [N/y/?] (NEW) y KDB: continue after catastrophic errors (KDB_CONTINUE_CATASTROPHIC) [0] (NEW) 0 Kernel: arch/x86/boot/bzImage is ready (#2) ton在内核源码根目录生成vmlinux文件 启动虚拟机(见上部) gdb /path/to/vmlinux 最好使用aosp/prebuilts/gdb/linux-x86里的gdb，这个版本的gdb是兼容所有体系结构的。 gdb命令在aosp/prebuilts/gdb/linux-x86/bin目录中\n~/Android/Source/kernel/goldfish$ export PATH=/home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gdb/linux-x86/bin:$PATH ~/Android/Source/kernel/goldfish$ which gdb /home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gdb/linux-x86/bin/gdb ~/Android/Source/kernel/goldfish$ gdb ./vmlinux GNU gdb (GDB) 7.11 Copyright (C) 2016 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-linux-gnu\u0026#34;. Type \u0026#34;show configuration\u0026#34; for configuration details. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;. Find the GDB manual and other documentation resources online at: \u0026lt;http://www.gnu.org/software/gdb/documentation/\u0026gt;. For help, type \u0026#34;help\u0026#34;. Type \u0026#34;apropos word\u0026#34; to search for commands related to \u0026#34;word\u0026#34;... Reading symbols from ./vmlinux...done. (gdb) target remote :1234 Remote debugging using :1234 0xffffffff834345e8 in ?? () (gdb) bt #0 0xffffffff834345e8 in ?? () #1 0xffffffff84003ec8 in ?? () #2 0xffffffff8340c0d9 in ?? () #3 0x0000000000000000 in ?? () 调试效果 可以设置断点并进入断点停下，但无法next和step(step有概率能成功)单步跳转,总是跳转到apic模块，考虑使用走读+断点调试的方式研究\n其他 全局修改编译优化，位于goldfish/Makefile:\n#ifdef CONFIG_CC_OPTIMIZE_FOR_SIZE #KBUILD_CFLAGS\t+= $(call cc-option,-Oz,-Os) #else #ifdef CONFIG_PROFILE_ALL_BRANCHES #KBUILD_CFLAGS\t+= -O2 #else #KBUILD_CFLAGS += -O2 #endif #endif KBUILD_CFLAGS += -Og  https://github.com/torvalds/linux\nhttps://source.android.com/setup/build/building-kernels\nhttps://source.android.com/devices/architecture/kernel\nhttps://android.googlesource.com/kernel/common/\n下载时Repo Branches选择common-android-4.14\nBuilding Kernels This page details the process of building custom kernels for Android devices. The following instructions guide you through the process of selecting the right sources, building the kernel, and embedding the results into a system image built from the Android Open Source Project (AOSP).\n android版本与linux内核版本对应关系\nhttps://blog.csdn.net/ly890700/article/details/75040704/\n6.0 Marshmallow |23 |3.18.10\nAndroid安卓版本 | API级别 | Linux内核版本 ——————————————————————- 1.5 Cupcake | 3 | 2.6.27 1.6 Donut | 4 | 2.6.29 2.0/1 Eclair | 5-7 | 2.6.29 2.2.x Froyo | 8 | 2.6.32 2.3.x Gingerbread | 9, 10 | 2.6.35 3.x.x Honeycomb | 11-13 | 2.6.36 4.0.x Ice Cream San | 14, 15 | 3.0.1 4.1.x Jelly Bean | 16 | 3.0.31 4.2.x Jelly Bean | 17 | 3.4.0 4.3 Jelly Bean | 18 | 3.4.39 4.4 Kit Kat | 19, 20 | 3.10 5.x Lollipop | 21, 22 | 3.16.1 6.0 Marshmallow | 23 | 3.18.10 7.0 Nougat | 24 | 4.4.1 7.1 Nougat | 25 | 4.4.1 8.0 Oreo | 26 | 4.10 8.1 Oreo | 27 | 4.10 9.0 Pie | 28 | 4.4, 4.9 and 4.14\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/handler/looper/",
	"title": "Looper",
	"tags": [],
	"description": "",
	"content": "原理总结 Looper就是对epoll系统调用的封装层，屏蔽外部对epoll的直接使用\nLooper addFd int Looper::addFd(int fd, int ident, int events, Looper_callbackFunc callback, void* data) { // use SimpleLooperCallback as adapter from handleEvent to callback function  return addFd(fd, ident, events, callback ? new SimpleLooperCallback(callback) : NULL, data); } int Looper::addFd(int fd, int ident, int events, const sp\u0026lt;LooperCallback\u0026gt;\u0026amp; callback, void* data) { if (!callback.get()) { if (! mAllowNonCallbacks) { ALOGE(\u0026#34;Invalid attempt to set NULL callback but not allowed for this looper.\u0026#34;); return -1; } if (ident \u0026lt; 0) { ALOGE(\u0026#34;Invalid attempt to set NULL callback with ident \u0026lt; 0.\u0026#34;); return -1; } } else { ident = POLL_CALLBACK; } Request request; request.fd = fd; request.ident = ident; request.events = events; request.seq = mNextRequestSeq++; request.callback = callback; request.data = data; struct epoll_event eventItem; request.initEventItem(\u0026amp;eventItem); ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex \u0026lt; 0) { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, fd, \u0026amp; eventItem); mRequests.add(fd, request); } else { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_MOD, fd, \u0026amp; eventItem); } } Request::initEventItem void Looper::Request::initEventItem(struct epoll_event* eventItem) const { int epollEvents = 0; if (events \u0026amp; EVENT_INPUT) epollEvents |= EPOLLIN; if (events \u0026amp; EVENT_OUTPUT) epollEvents |= EPOLLOUT; memset(eventItem, 0, sizeof(epoll_event)); // zero out unused members of data field union  eventItem-\u0026gt;events = epollEvents; eventItem-\u0026gt;data.fd = fd; } pollOnce int Looper::pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) { int result = 0; for (;;) { while (mResponseIndex \u0026lt; mResponses.size()) { const Response\u0026amp; response = mResponses.itemAt(mResponseIndex++); int ident = response.request.ident; if (ident \u0026gt;= 0) { int fd = response.request.fd; int events = response.events; void* data = response.request.data; if (outFd != NULL) *outFd = fd; if (outEvents != NULL) *outEvents = events; if (outData != NULL) *outData = data; return ident; } } if (result != 0) { if (outFd != NULL) *outFd = 0; if (outEvents != NULL) *outEvents = 0; if (outData != NULL) *outData = NULL; return result; } result = pollInner(timeoutMillis); } } pollInner int Looper::pollInner(int timeoutMillis) { // Poll.  int result = POLL_WAKE; mResponses.clear(); mResponseIndex = 0; struct epoll_event eventItems[EPOLL_MAX_EVENTS]; int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_EVENTS, timeoutMillis); for (int i = 0; i \u0026lt; eventCount; i++) { int fd = eventItems[i].data.fd; uint32_t epollEvents = eventItems[i].events; if (fd == mWakeEventFd) { if (epollEvents \u0026amp; EPOLLIN) { awoken(); } } else { ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex \u0026gt;= 0) { int events = 0; if (epollEvents \u0026amp; EPOLLIN) events |= EVENT_INPUT; if (epollEvents \u0026amp; EPOLLOUT) events |= EVENT_OUTPUT; if (epollEvents \u0026amp; EPOLLERR) events |= EVENT_ERROR; if (epollEvents \u0026amp; EPOLLHUP) events |= EVENT_HANGUP; pushResponse(events, mRequests.valueAt(requestIndex)); } } } //1：处理C层发送的消息  // Invoke pending message callbacks.  mNextMessageUptime = LLONG_MAX; while (mMessageEnvelopes.size() != 0) { nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); const MessageEnvelope\u0026amp; messageEnvelope = mMessageEnvelopes.itemAt(0); if (messageEnvelope.uptime \u0026lt;= now) { // Remove the envelope from the list.  // We keep a strong reference to the handler until the call to handleMessage  // finishes. Then we drop it so that the handler can be deleted *before*  // we reacquire our lock.  { // obtain handler  sp\u0026lt;MessageHandler\u0026gt; handler = messageEnvelope.handler; Message message = messageEnvelope.message; mMessageEnvelopes.removeAt(0); mSendingMessage = true; mLock.unlock(); handler-\u0026gt;handleMessage(message); } // release handler  mLock.lock(); mSendingMessage = false; result = POLL_CALLBACK; } else { // The last message left at the head of the queue determines the next wakeup time.  mNextMessageUptime = messageEnvelope.uptime; break; } } //2：回调通过addFd添加进来的监听  // Invoke all response callbacks.  for (size_t i = 0; i \u0026lt; mResponses.size(); i++) { Response\u0026amp; response = mResponses.editItemAt(i); if (response.request.ident == POLL_CALLBACK) { int fd = response.request.fd; int events = response.events; void* data = response.request.data; // Invoke the callback. Note that the file descriptor may be closed by  // the callback (and potentially even reused) before the function returns so  // we need to be a little careful when removing the file descriptor afterwards.  int callbackResult = response.request.callback-\u0026gt;handleEvent(fd, events, data);//回调flutter在MessageLoopAndroid构造方法中设置的callback监听  if (callbackResult == 0) {//callback方法返回0时表示需要移除该fd监听  removeFd(fd, response.request.seq); } // Clear the callback reference in the response structure promptly because we  // will not clear the response vector itself until the next poll.  response.request.callback.clear(); result = POLL_CALLBACK; } } return result;//3：:返回之后回到java层的死循环处处理java层消息 } pushResponse void Looper::pushResponse(int events, const Request\u0026amp; request) { Response response; response.events = events; response.request = request; mResponses.push(response); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/mmkv/mmkv/",
	"title": "MMKV",
	"tags": [],
	"description": "",
	"content": "参考 https://github.com/Tencent/MMKV/wiki/android_ipc\nhttps://github.com/Tencent/MMKV/wiki/design\n原理总结 MMKV 本质上是将文件 mmap 到内存块中，将新增的 key-value 统统 append 到内存中；到达边界后，进行重整回写以腾出空间，空间还是不够的话，就 double 内存空间；对于内存文件中可能存在的重复键值，MMKV 只选用最后写入的作为有效键值。\n状态同步 写指针的同步 我们可以在每个进程内部缓存自己的写指针，然后在写入键值的同时，还要把最新的写指针位置也写到 mmap 内存中；这样每个进程只需要对比一下缓存的指针与 mmap 内存的写指针，如果不一样，就说明其他进程进行了写操作。事实上 MMKV 原本就在文件头部保存了有效内存的大小，这个数值刚好就是写指针的内存偏移量，我们可以重用这个数值来校对写指针。\n内存重整的感知 考虑使用一个单调递增的序列号，每次发生内存重整，就将序列号递增。将这个序列号也放到 mmap 内存中，每个进程内部也缓存一份，只需要对比序列号是否一致，就能够知道其他进程是否触发了内存重整。\n内存增长的感知 事实上 MMKV 在内存增长之前，会先尝试通过内存重整来腾出空间，重整后还不够空间才申请新的内存。所以内存增长可以跟内存重整一样处理。至于新的内存大小，可以通过查询文件大小来获得，无需在 mmap 内存另外存放。\n挑选进程锁  文件锁，优点是天然 robust，缺点是不支持递归加锁，也不支持读写锁升级/降级，需要自行实现。 pthread_mutex，优点是 pthread 库支持递归加锁，也支持读写锁升级/降级，缺点是不 robust，需要自行清理。  文件锁 到这里我们已经完成了数据的多进程同步工作，是时候回头处理锁事了，亦即前面提到的递归锁和锁升级/降级。\n递归锁 意思是如果一个进程/线程已经拥有了锁，那么后续的加锁操作不会导致卡死，并且解锁也不会导致外层的锁被解掉。对于文件锁来说，前者是满足的，后者则不然。因为文件锁是状态锁，没有计数器，无论加了多少次锁，一个解锁操作就全解掉。只要用到子函数，就非常需要递归锁。\n锁升级/降级 锁升级是指将已经持有的共享锁，升级为互斥锁，亦即将读锁升级为写锁；锁降级则是反过来。文件锁支持锁升级，但是容易死锁：假如 A、B 进程都持有了读锁，现在都想升级到写锁，就会陷入相互等待的困境，发生死锁。另外，由于文件锁不支持递归锁，也导致了锁降级无法进行，一降就降到没有锁。\n为了解决递归锁和锁升级/降级这两个难题，需要对文件锁(系统调用flock)进行封装，增加读锁、写锁计数器。处理逻辑如下表：\n   读锁计数器 写锁计数器 加读锁 加写锁 解读锁 解写锁     0 0 加读锁 加写锁 - -   0 1 +1 +1 - 解写锁   0 N +1 +1 - -1   1 0 +1 解读锁再加写锁 解读锁 -   1 1 +1 +1 -1 加读锁   1 N +1 +1 -1 -1   N 0 +1 解读锁再加写锁 -1 -   N 1 +1 +1 -1 加读锁   N N +1 +1 -1 -1    需要注意的地方有两点：\n 加写锁时，如果当前已经持有读锁，那么先尝试加写锁，try_lock 失败说明其他进程持有了读锁，我们需要先将自己的读锁释放掉，再进行加写锁操作，以避免死锁的发生。(这里的死锁指的是：本进程先加了读锁，之后又尝试加写锁，而这个写锁要等到前面那个读锁释放之后才能加上，而这是不可能的，因此造成死锁)。 解写锁时，假如之前曾经持有读锁，那么我们不能直接释放掉写锁，这样会导致读锁也解了。我们应该加一个读锁，将锁降级。  graph LR 加读锁--\u0026gt;直接加 加写锁--\u0026gt;非首次加写锁,直接+1 加写锁--\u0026gt;首次加写锁,如果有读锁,需要先unlock,防止死锁 解读锁--\u0026gt;直接解 解写锁--\u0026gt;写锁数量大于1直接-1 解写锁--\u0026gt;写锁数量为1,如果有读锁,加读锁锁降级,避免解写锁时读锁也解了,锁失效 MMKV initialize public static String initialize(String rootDir, LibLoader loader, MMKVLogLevel logLevel) { if (loader != null) { if (BuildConfig.FLAVOR.equals(\u0026#34;SharedCpp\u0026#34;)) { loader.loadLibrary(\u0026#34;c++_shared\u0026#34;); } loader.loadLibrary(\u0026#34;mmkv\u0026#34;); } else { if (BuildConfig.FLAVOR.equals(\u0026#34;SharedCpp\u0026#34;)) { System.loadLibrary(\u0026#34;c++_shared\u0026#34;); } System.loadLibrary(\u0026#34;mmkv\u0026#34;); } jniInitialize(rootDir, logLevel2Int(logLevel)); MMKV.rootDir = rootDir; return MMKV.rootDir; } loadLibrary\njniinitialize\nregisterContentChangeNotify // content change notification of other process // trigger by getXXX() or setXXX() or checkContentChangedByOuterProcess() private static MMKVContentChangeNotification gContentChangeNotify; public static void registerContentChangeNotify(MMKVContentChangeNotification notify) { gContentChangeNotify = notify; setWantsContentChangeNotify(gContentChangeNotify != null); } setwantscontentchangenotify\nonContentChangedByOuterProcess private static void onContentChangedByOuterProcess(String mmapID) { if (gContentChangeNotify != null) { gContentChangeNotify.onContentChangedByOuterProcess(mmapID); } } defaultMMKV public static MMKV defaultMMKV() { long handle = getDefaultMMKV(SINGLE_PROCESS_MODE, null); return checkProcessMode(handle, \u0026#34;DefaultMMKV\u0026#34;, SINGLE_PROCESS_MODE); } native-bridge.cpp JNI_OnLoad extern \u0026#34;C\u0026#34; JNIEXPORT JNICALL jint JNI_OnLoad(JavaVM *vm, void *reserved) { g_currentJVM = vm; JNIEnv *env; if (vm-\u0026gt;GetEnv(reinterpret_cast\u0026lt;void **\u0026gt;(\u0026amp;env), JNI_VERSION_1_6) != JNI_OK) { return -1; } static const char *clsName = \u0026#34;com/tencent/mmkv/MMKV\u0026#34;; jclass instance = env-\u0026gt;FindClass(clsName); g_cls = reinterpret_cast\u0026lt;jclass\u0026gt;(env-\u0026gt;NewGlobalRef(instance)); int ret = registerNativeMethods(env, g_cls); return JNI_VERSION_1_6; } registerNativeMethods static int registerNativeMethods(JNIEnv *env, jclass cls) { return env-\u0026gt;RegisterNatives(cls, g_methods, sizeof(g_methods) / sizeof(g_methods[0])); } jniInitialize MMKV_JNI void jniInitialize(JNIEnv *env, jobject obj, jstring rootDir, jint logLevel) { const char *kstr = env-\u0026gt;GetStringUTFChars(rootDir, nullptr); if (kstr) { MMKV::initializeMMKV(kstr, (MMKVLogLevel) logLevel); env-\u0026gt;ReleaseStringUTFChars(rootDir, kstr); } } setWantsContentChangeNotify MMKV_JNI void setWantsContentChangeNotify(JNIEnv *env, jclass type, jboolean notify) { if (notify == JNI_TRUE) { MMKV::registerContentChangeHandler(onContentChangedByOuterProcess); } else { MMKV::unRegisterContentChangeHandler(); } } registercontentchangehandler\nonContentChangedByOuterProcess_n static void onContentChangedByOuterProcess(const std::string \u0026amp;mmapID) { auto currentEnv = getCurrentEnv(); if (currentEnv \u0026amp;\u0026amp; g_callbackOnContentChange) { jstring str = string2jstring(currentEnv, mmapID); currentEnv-\u0026gt;CallStaticVoidMethod(g_cls, g_callbackOnContentChange, str); } } g_callbackOnContentChange\ngetDefaultMMKV MMKV_JNI jlong getDefaultMMKV(JNIEnv *env, jobject obj, jint mode, jstring cryptKey) { MMKV *kv = nullptr; if (cryptKey) { string crypt = jstring2string(env, cryptKey); if (crypt.length() \u0026gt; 0) { kv = MMKV::defaultMMKV((MMKVMode) mode, \u0026amp;crypt); } } if (!kv) { kv = MMKV::defaultMMKV((MMKVMode) mode, nullptr); } return (jlong) kv; } getMMKVWithID MMKV_JNI jlong getMMKVWithID(JNIEnv *env, jobject, jstring mmapID, jint mode, jstring cryptKey, jstring rootPath) { string str = jstring2string(env, mmapID); kv = MMKV::mmkvWithID(str, DEFAULT_MMAP_SIZE, (MMKVMode) mode, \u0026amp;crypt, \u0026amp;path); return (jlong) kv; } mmkvwithid\nMMKV.cpp initializeMMKV void MMKV::initializeMMKV(const MMKVPath_t \u0026amp;rootDir, MMKVLogLevel logLevel) { g_currentLogLevel = logLevel; ThreadLock::ThreadOnce(\u0026amp;once_control, initialize); g_rootDir = rootDir; mkPath(g_rootDir); } initialize void initialize() { g_instanceDic = new unordered_map\u0026lt;string, MMKV *\u0026gt;; g_instanceLock = new ThreadLock(); g_instanceLock-\u0026gt;initialize(); mmkv::DEFAULT_MMAP_SIZE = mmkv::getPageSize(); } registerContentChangeHandler void MMKV::registerContentChangeHandler(mmkv::ContentChangeHandler handler) { g_contentChangeHandler = handler; } defaultMMKV MMKV *MMKV::defaultMMKV(MMKVMode mode, string *cryptKey) { #ifndef MMKV_ANDROID  return mmkvWithID(DEFAULT_MMAP_ID, mode, cryptKey); #else  return mmkvWithID(DEFAULT_MMAP_ID, DEFAULT_MMAP_SIZE, mode, cryptKey); #endif } mmkvWithID MMKV *MMKV::mmkvWithID(const string \u0026amp;mmapID, int size, MMKVMode mode, string *cryptKey, string *rootPath) { SCOPED_LOCK(g_instanceLock); auto mmapKey = mmapedKVKey(mmapID, rootPath); auto itr = g_instanceDic-\u0026gt;find(mmapKey); if (itr != g_instanceDic-\u0026gt;end()) { MMKV *kv = itr-\u0026gt;second; return kv; } auto kv = new MMKV(mmapID, size, mode, cryptKey, rootPath); (*g_instanceDic)[mmapKey] = kv; return kv; } MMKV() MMKV::MMKV(const string \u0026amp;mmapID, int size, MMKVMode mode, string *cryptKey, string *rootPath) : m_mmapID(mmapedKVKey(mmapID, rootPath)) // historically Android mistakenly use mmapKey as mmapID  , m_path(mappedKVPathWithID(m_mmapID, mode, rootPath)) , m_crcPath(crcPathWithID(m_mmapID, mode, rootPath)) , m_dic(nullptr) , m_dicCrypt(nullptr) , m_file(new MemoryFile(m_path, size, (mode \u0026amp; MMKV_ASHMEM) ? MMFILE_TYPE_ASHMEM : MMFILE_TYPE_FILE)) , m_metaFile(new MemoryFile(m_crcPath, DEFAULT_MMAP_SIZE, m_file-\u0026gt;m_fileType)) , m_metaInfo(new MMKVMetaInfo()) , m_crypter(nullptr) , m_lock(new ThreadLock()) , m_fileLock(new FileLock(m_metaFile-\u0026gt;getFd(), (mode \u0026amp; MMKV_ASHMEM))) , m_sharedProcessLock(new InterProcessLock(m_fileLock, SharedLockType)) , m_exclusiveProcessLock(new InterProcessLock(m_fileLock, ExclusiveLockType)) , m_isInterProcess((mode \u0026amp; MMKV_MULTI_PROCESS) != 0 || (mode \u0026amp; CONTEXT_MODE_MULTI_PROCESS) != 0) { m_actualSize = 0; m_output = nullptr; // force use fcntl(), otherwise will conflict with MemoryFile::reloadFromFile()  m_fileModeLock = new FileLock(m_file-\u0026gt;getFd(), true); m_sharedProcessModeLock = new InterProcessLock(m_fileModeLock, SharedLockType); m_exclusiveProcessModeLock = nullptr; # ifndef MMKV_DISABLE_CRYPT  if (cryptKey \u0026amp;\u0026amp; cryptKey-\u0026gt;length() \u0026gt; 0) { m_dicCrypt = new MMKVMapCrypt(); m_crypter = new AESCrypt(cryptKey-\u0026gt;data(), cryptKey-\u0026gt;length()); } else # endif  { m_dic = new MMKVMap(); } m_needLoadFromFile = true; m_hasFullWriteback = false; m_crcDigest = 0; m_sharedProcessLock-\u0026gt;m_enable = m_isInterProcess; m_exclusiveProcessLock-\u0026gt;m_enable = m_isInterProcess; // sensitive zone  { SCOPED_LOCK(m_sharedProcessLock); loadFromFile(); } } loadFromFile void MMKV::loadFromFile() { if (!m_file-\u0026gt;isFileValid()) { m_file-\u0026gt;reloadFromFile(); } auto ptr = (uint8_t *) m_file-\u0026gt;getMemory(); if (loadFromFile \u0026amp;\u0026amp; m_actualSize \u0026gt; 0) { MMBuffer inputBuffer(ptr + Fixed32Size, m_actualSize, MMBufferNoCopy); } MemoryFile reloadFromFile void MemoryFile::reloadFromFile() { m_fd = open(m_name.c_str(), O_RDWR | O_CREAT | O_CLOEXEC, S_IRWXU); FileLock fileLock(m_fd); InterProcessLock lock(\u0026amp;fileLock, ExclusiveLockType); SCOPED_LOCK(\u0026amp;lock); mmkv::getFileSize(m_fd, m_size); // round up to (n * pagesize)  if (m_size \u0026lt; DEFAULT_MMAP_SIZE || (m_size % DEFAULT_MMAP_SIZE != 0)) { size_t roundSize = ((m_size / DEFAULT_MMAP_SIZE) + 1) * DEFAULT_MMAP_SIZE; truncate(roundSize); } else { auto ret = mmap(); if (!ret) { doCleanMemoryCache(true); } } } mmap bool MemoryFile::mmap() { m_ptr = (char *) ::mmap(m_ptr, m_size, PROT_READ | PROT_WRITE, MAP_SHARED, m_fd, 0); if (m_ptr == MAP_FAILED) { MMKVError(\u0026#34;fail to mmap [%s], %s\u0026#34;, m_name.c_str(), strerror(errno)); m_ptr = nullptr; return false; } return true; } getMemory void *getMemory() { return m_ptr; } FileLock FileLock::FileLock(MMKVFileHandle_t fd, bool isAshmem) : m_fd(fd), m_sharedLockCount(0), m_exclusiveLockCount(0), m_isAshmem(isAshmem) { m_lockInfo.l_type = F_WRLCK; m_lockInfo.l_start = 0; m_lockInfo.l_whence = SEEK_SET; m_lockInfo.l_len = 0; m_lockInfo.l_pid = 0; } lock bool FileLock::lock(LockType lockType) { return doLock(lockType, true); } doLock bool FileLock::doLock(LockType lockType, bool wait, bool *tryAgain) { if (lockType == SharedLockType) { // don\u0026#39;t want shared-lock to break any existing locks  if (m_sharedLockCount \u0026gt; 0 || m_exclusiveLockCount \u0026gt; 0) { m_sharedLockCount++; return true; } } else { // don\u0026#39;t want exclusive-lock to break existing exclusive-locks  if (m_exclusiveLockCount \u0026gt; 0) { m_exclusiveLockCount++; return true; } // prevent deadlock  if (m_sharedLockCount \u0026gt; 0) { unLockFirstIfNeeded = true; } } auto ret = platformLock(lockType, wait, unLockFirstIfNeeded, tryAgain); if (ret) { if (lockType == SharedLockType) { m_sharedLockCount++; } else { m_exclusiveLockCount++; } } return ret; } unlock bool FileLock::unlock(LockType lockType) { if (lockType == SharedLockType) { if (m_sharedLockCount == 0) { return false; } // don\u0026#39;t want shared-lock to break any existing locks  if (m_sharedLockCount \u0026gt; 1 || m_exclusiveLockCount \u0026gt; 0) { m_sharedLockCount--; return true; } } else { if (m_exclusiveLockCount == 0) { return false; } if (m_exclusiveLockCount \u0026gt; 1) { m_exclusiveLockCount--; return true; } // restore shared-lock when all exclusive-locks are done  if (m_sharedLockCount \u0026gt; 0) { unlockToSharedLock = true; } } auto ret = platformUnLock(unlockToSharedLock); if (ret) { if (lockType == SharedLockType) { m_sharedLockCount--; } else { m_exclusiveLockCount--; } } return ret; } platformLock bool FileLock::platformLock(LockType lockType, bool wait, bool unLockFirstIfNeeded, bool *tryAgain) { if (m_isAshmem) { return ashmemLock(lockType, wait, unLockFirstIfNeeded, tryAgain); } auto realLockType = LockType2FlockType(lockType); auto cmd = wait ? realLockType : (realLockType | LOCK_NB); if (unLockFirstIfNeeded) { // try lock  auto ret = flock(m_fd, realLockType | LOCK_NB); if (ret == 0) { return true; } // let\u0026#39;s be gentleman: unlock my shared-lock to prevent deadlock  ret = flock(m_fd, LOCK_UN); if (ret != 0) { MMKVError(\u0026#34;fail to try unlock first fd=%d, ret=%d, error:%s\u0026#34;, m_fd, ret, strerror(errno)); } } auto ret = flock(m_fd, cmd); ...... } platformUnLock bool FileLock::platformUnLock(bool unlockToSharedLock) { if (m_isAshmem) { return ashmemUnLock(unlockToSharedLock); } int cmd = unlockToSharedLock ? LOCK_SH : LOCK_UN; auto ret = flock(m_fd, cmd); } InterProcessLock InterProcessLock(FileLock *fileLock, LockType lockType) : m_fileLock(fileLock), m_lockType(lockType), m_enable(true) { MMKV_ASSERT(m_fileLock); } lock void lock() { if (m_enable) { m_fileLock-\u0026gt;lock(m_lockType); } } unlock void unlock() { if (m_enable) { m_fileLock-\u0026gt;unlock(m_lockType); } } ScopedLock explicit ScopedLock(T *oLock) : m_lock(oLock) { MMKV_ASSERT(m_lock); lock(); } ~ScopedLock() { unlock(); m_lock = nullptr; } lock unLock template \u0026lt;typename T\u0026gt; class ScopedLock { T *m_lock; void lock() { if (m_lock) { m_lock-\u0026gt;lock(); } } void unlock() { if (m_lock) { m_lock-\u0026gt;unlock(); } } } ThreadLock.cpp ThreadOnce pthread_once用来确保在C++下多线程并发时，callback只调用一次，可用于C++中的单例模式\npthread_once实现简析\nvoid ThreadLock::ThreadOnce(ThreadOnceToken_t *onceToken, void (*callback)()) { pthread_once(onceToken, callback); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/mmkv/",
	"title": "mmkv",
	"tags": [],
	"description": "",
	"content": "mmkv 探索总结mmkv知识\n MMKV     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/sharedpreferences/sharedpreferences/",
	"title": "SharedPreferences",
	"tags": [],
	"description": "",
	"content": "1、加载/初始化 维护spName\u0026ndash;\u0026gt;file,file\u0026ndash;\u0026gt;sharedPreferencesImpl两个ArrayMap内存缓存 ContextImpl.java\n@Override public SharedPreferences getSharedPreferences(String name, int mode) { File file; synchronized (ContextImpl.class) { if (mSharedPrefsPaths == null) { mSharedPrefsPaths = new ArrayMap\u0026lt;\u0026gt;(); } file = mSharedPrefsPaths.get(name); if (file == null) { file = getSharedPreferencesPath(name); mSharedPrefsPaths.put(name, file); } } return getSharedPreferences(file, mode); } @Override public SharedPreferences getSharedPreferences(File file, int mode) { SharedPreferencesImpl sp; synchronized (ContextImpl.class) { final ArrayMap\u0026lt;File, SharedPreferencesImpl\u0026gt; cache = getSharedPreferencesCacheLocked(); sp = cache.get(file); if (sp == null) { checkMode(mode); sp = new SharedPreferencesImpl(file, mode); cache.put(file, sp); return sp; } } return sp; } SharedPreferencesImpl构造方法切子线程loadFromDisk,得到Map\u0026lt;String, Object\u0026gt; mMap SharedPreferencesImpl.java\nSharedPreferencesImpl(File file, int mode) { mFile = file; mBackupFile = makeBackupFile(file); mMode = mode; mLoaded = false; mMap = null; mThrowable = null; startLoadFromDisk(); } private void startLoadFromDisk() { new Thread(\u0026#34;SharedPreferencesImpl-load\u0026#34;) { public void run() { loadFromDisk(); } }.start(); } private void loadFromDisk() { synchronized (mLock) { if (mLoaded) { return; } if (mBackupFile.exists()) { mFile.delete(); mBackupFile.renameTo(mFile); } } str = new BufferedInputStream(new FileInputStream(mFile), 16 * 1024); map = (Map\u0026lt;String, Object\u0026gt;) XmlUtils.readMapXml(str); synchronized (mLock) { mLoaded = true; mThrowable = thrown; // It\u0026#39;s important that we always signal waiters, even if we\u0026#39;ll make  // them fail with an exception. The try-finally is pretty wide, but  // better safe than sorry.  try { mMap = map; } catch (Throwable t) { mThrowable = t; } finally { mLock.notifyAll(); } } edit: wait util loaded @Override public Editor edit() { // TODO: remove the need to call awaitLoadedLocked() when  // requesting an editor. will require some work on the  // Editor, but then we should be able to do:  //  // context.getSharedPreferences(..).edit().putString(..).apply()  //  // ... all without blocking.  synchronized (mLock) { awaitLoadedLocked(); } return new EditorImpl(); } @GuardedBy(\u0026#34;mLock\u0026#34;) private void awaitLoadedLocked() { while (!mLoaded) { try { mLock.wait(); } catch (InterruptedException unused) { } } } putXxx: mModified.put(key, value) @Override public Editor putString(String key, @Nullable String value) { synchronized (mEditorLock) { mModified.put(key, value); return this; } } 2、编辑提交 2.1、 commit()流程 @Override public boolean commit() { MemoryCommitResult mcr = commitToMemory(); SharedPreferencesImpl.this.enqueueDiskWrite(mcr, null /* sync write on this thread okay */); try { mcr.writtenToDiskLatch.await(); } catch (InterruptedException e) { return false; } notifyListeners(mcr); return mcr.writeToDiskResult; } 2.1.1 commitToMemory // Returns true if any changes were made  private MemoryCommitResult commitToMemory() { long memoryStateGeneration; List\u0026lt;String\u0026gt; keysModified = null; Set\u0026lt;OnSharedPreferenceChangeListener\u0026gt; listeners = null; Map\u0026lt;String, Object\u0026gt; mapToWriteToDisk; synchronized (SharedPreferencesImpl.this.mLock) { mapToWriteToDisk = mMap; synchronized (mEditorLock) { for (Map.Entry\u0026lt;String, Object\u0026gt; e : mModified.entrySet()) { String k = e.getKey(); Object v = e.getValue(); // \u0026#34;this\u0026#34; is the magic value for a removal mutation. In addition,  // setting a value to \u0026#34;null\u0026#34; for a given key is specified to be  // equivalent to calling remove on that key.  if (v == this || v == null) { if (!mapToWriteToDisk.containsKey(k)) { continue; } mapToWriteToDisk.remove(k); } else { if (mapToWriteToDisk.containsKey(k)) { Object existingValue = mapToWriteToDisk.get(k); if (existingValue != null \u0026amp;\u0026amp; existingValue.equals(v)) { continue; } } mapToWriteToDisk.put(k, v); } changesMade = true; } return new MemoryCommitResult(memoryStateGeneration, keysModified, listeners, mapToWriteToDisk); } } 2.2.2 enqueueDiskWrite private void enqueueDiskWrite(final MemoryCommitResult mcr, final Runnable postWriteRunnable) { final boolean isFromSyncCommit = (postWriteRunnable == null); final Runnable writeToDiskRunnable = new Runnable() { @Override public void run() { synchronized (mWritingToDiskLock) { writeToFile(mcr, isFromSyncCommit); } synchronized (mLock) { mDiskWritesInFlight--; } if (postWriteRunnable != null) { postWriteRunnable.run(); } } }; // Typical #commit() path with fewer allocations, doing a write on  // the current thread.  if (isFromSyncCommit) { boolean wasEmpty = false; synchronized (mLock) { wasEmpty = mDiskWritesInFlight == 1; } if (wasEmpty) { writeToDiskRunnable.run(); return; } } QueuedWork.queue(writeToDiskRunnable, !isFromSyncCommit); } QueuedWork.queue  当apply()方式提交的时候，默认消息会延迟发送100毫秒，避免频繁的磁盘写入操作。 当commit()方式，调用QueuedWork的queue()时，会立即向handler()发送Message。  /** Delay for delayed runnables, as big as possible but low enough to be barely perceivable */ private static final long DELAY = 100; public static void queue(Runnable work, boolean shouldDelay) { Handler handler = getHandler(); synchronized (sLock) { sWork.add(work); if (shouldDelay \u0026amp;\u0026amp; sCanDelay) { handler.sendEmptyMessageDelayed(QueuedWorkHandler.MSG_RUN, DELAY); } else { handler.sendEmptyMessage(QueuedWorkHandler.MSG_RUN); } } } /** * Lazily create a handler on a separate thread. */ private static Handler getHandler() { synchronized (sLock) { if (sHandler == null) { HandlerThread handlerThread = new HandlerThread(\u0026#34;queued-work-looper\u0026#34;, Process.THREAD_PRIORITY_FOREGROUND); handlerThread.start(); sHandler = new QueuedWorkHandler(handlerThread.getLooper()); } return sHandler; } } private static class QueuedWorkHandler extends Handler { static final int MSG_RUN = 1; QueuedWorkHandler(Looper looper) { super(looper); } public void handleMessage(Message msg) { if (msg.what == MSG_RUN) { processPendingWork(); } } } private static void processPendingWork() { long startTime = 0; synchronized (sProcessingWork) { LinkedList\u0026lt;Runnable\u0026gt; work; synchronized (sLock) { work = (LinkedList\u0026lt;Runnable\u0026gt;) sWork.clone(); sWork.clear(); // Remove all msg-s as all work will be processed now  getHandler().removeMessages(QueuedWorkHandler.MSG_RUN); } if (work.size() \u0026gt; 0) { for (Runnable w : work) { w.run(); } } } } writeToFile private void writeToFile(MemoryCommitResult mcr, boolean isFromSyncCommit) { boolean fileExists = mFile.exists(); // Rename the current file so it may be used as a backup during the next read  if (fileExists) { boolean backupFileExists = mBackupFile.exists(); if (!backupFileExists) { if (!mFile.renameTo(mBackupFile)) { Log.e(TAG, \u0026#34;Couldn\u0026#39;t rename file \u0026#34; + mFile + \u0026#34; to backup file \u0026#34; + mBackupFile); mcr.setDiskWriteResult(false, false); return; } } else { mFile.delete(); } } // Attempt to write the file, delete the backup and return true as atomically as  // possible. If any exception occurs, delete the new file; next time we will restore  // from the backup.  try { FileOutputStream str = createFileOutputStream(mFile); XmlUtils.writeMapXml(mcr.mapToWriteToDisk, str); FileUtils.sync(str); str.close(); // Writing was successful, delete the backup file if there is one.  mBackupFile.delete(); mcr.setDiskWriteResult(true, true); void setDiskWriteResult(boolean wasWritten, boolean result) { this.wasWritten = wasWritten; writeToDiskResult = result; writtenToDiskLatch.countDown(); } 2.2、 apply()流程 public void apply() { final MemoryCommitResult mcr = commitToMemory(); final Runnable awaitCommit = new Runnable() { @Override public void run() { try { mcr.writtenToDiskLatch.await(); } catch (InterruptedException ignored) { } } }; QueuedWork.addFinisher(awaitCommit); Runnable postWriteRunnable = new Runnable() { @Override public void run() { awaitCommit.run(); QueuedWork.removeFinisher(awaitCommit); } }; SharedPreferencesImpl.this.enqueueDiskWrite(mcr, postWriteRunnable); notifyListeners(mcr); } 2.2.1 commitToMemory 2.2.2 enqueueDiskWrite 2.3 主线程堵塞ANR waitToFinish，processPendingWork  You don\u0026rsquo;t need to worry about Android component lifecycles and their interaction with apply() writing to disk. The framework makes sure in-flight disk writes from apply() complete before switching states.\n //QueuedWork.java  public static void waitToFinish() { ... processPendingWork();//执行文件写入磁盘操作  .... } private static void processPendingWork() { long startTime = 0; .... if (work.size() \u0026gt; 0) { for (Runnable w : work) { w.run(); } ... } waitToFinish()会将，储存在QueuedWork的操作一并处理掉。什么时候呢？在Activiy的 onPause()、BroadcastReceiver的onReceive()以及Service的onStartCommand()方法之前都会调用waitToFinish()。大家知道这些方法都是执行在主线程中，一旦waitToFinish()执行超时，就会跑出ANR。\n至于waitToFinish调用具体时机，查看ActivityThread.java类文件。这里只是说本质原理\n线程安全 多操作线程安全 为了保证SharedPreferences是线程安全的，Google的设计者一共使用了3把锁：\n对于简单的 读操作 而言，我们知道其原理是读取内存中mMap的值并返回，那么为了保证线程安全，只需要加一把锁保证mMap的线程安全即可：\nmMap相关的mLock锁 public String getString(String key, @Nullable String defValue) { synchronized (mLock) { String v = (String)mMap.get(key); return v != null ? v : defValue; } } 写操作线程安全 对于写操作而言，每次putXXX()并不能立即更新在mMap中，这是理所当然的，如果开发者没有调用apply()方法，那么这些数据的更新理所当然应该被抛弃掉，但是如果直接更新在mMap中，那么数据就难以恢复。\n因此，Editor本身也应该持有一个mEditorMap对象，用于存储数据的更新；只有当调用apply()时，才尝试将mEditorMap与mMap进行合并，以达到数据更新的目的。\n因此，这里我们还需要另外一把锁保证mEditorMap的线程安全，笔者认为，不和mMap公用同一把锁的原因是，在apply()被调用之前，getXXX和putXXX理应是没有冲突的。\n代码实现参考如下：\nEditorImpl相关的mEditorLock锁 public final class EditorImpl implements Editor { @Override public Editor putString(String key, String value) { synchronized (mEditorLock) { mEditorMap.put(key, value); return this; } } } 而当真正需要执行apply()进行写操作时，mEditorMap与mMap进行合并，这时必须通过2把锁保证mEditorMap与mMap的线程安全，保证mMap最终能够更新成功，最终向对应的xml文件中进行更新。\n文件的更新理所当然也需要加一把锁：\n写文件时的锁mWritingToDiskLock // SharedPreferencesImpl.EditorImpl.enqueueDiskWrite() synchronized (mWritingToDiskLock) { writeToFile(mcr, isFromSyncCommit); } 最终，我们一共通过使用了3把锁，对整个写操作的线程安全进行了保证。\n 篇幅限制，本文不对源码进行详细引申，有兴趣的读者可参考 SharedPreferencesImpl.EditorImpl 类的apply()源码。\n 3、跨进程操作的解决方案 //ContextImpl private void checkMode(int mode) { if (getApplicationInfo().targetSdkVersion \u0026gt;= Build.VERSION_CODES.N) { if ((mode \u0026amp; MODE_WORLD_READABLE) != 0) { throw new SecurityException(\u0026#34;MODE_WORLD_READABLE no longer supported\u0026#34;); } if ((mode \u0026amp; MODE_WORLD_WRITEABLE) != 0) { throw new SecurityException(\u0026#34;MODE_WORLD_WRITEABLE no longer supported\u0026#34;); } } } Andorid 7.0及以上会抛出异常，Sharepreferences不再支持多进程模式。多进程共享文件会出现问题的本质在于，因为不同进程，所以线程同步会失效。要解决这个问题，可尝试跨进程解决方案，如ContentProvider、AIDL、AIDL、Service。\n4、替代方案 MMKV Jetpack DataStore 5、 小结 通过本文我们了解了SharedPreferences的基本原理。再回头看看文章开头的那几个问题，是不是有答案了。\n commit()方法和apply()方法的区别：commit()方法是同步的有返回结果，同步保证使用Countdownlatch，即使同步但不保证往磁盘的写入是发生在当前线程的。apply()方法是异步的具体发生在QueuedWork中，里面维护了一个单线程去执行磁盘写入操作。 commit()和apply()方法其实都是Block主线程。commit()只要在主线程调用就会堵塞主线程;apply（）方法磁盘写入操作虽然是异步的，但是当组件(Activity Service BroadCastReceiver)这些系统组件特定状态转换的时候，会把QueuedWork中未完成的那些磁盘写入操作放在主线程执行，且如果比较耗时会产生ANR。 跨进程操作，需要借助Android平台常规的IPC手段（如，AIDL ContentProvider等来封装一层sp数据处理流程）来完成。 替代解决方案:看4。  6. 参考 SharedPreferences灵魂拷问之原理\n官方也无力回天？“SharedPreferences 存在什么问题？”\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/sharedpreferences/",
	"title": "sharedpreferences",
	"tags": [],
	"description": "",
	"content": "sharedpreferences 探索总结sharedpreferences知识\n SharedPreferences     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/google/supporttoandroidx/",
	"title": "supportToAndroidx",
	"tags": [],
	"description": "",
	"content": "升级背景 为了升级公司客户端架构，促进更高效的开发效率，减少模板代码并提升稳定性，需要基础仓库从support迁移到androidx，并提供相应的升级方案以及基于androidx的基础组件。\n模块拆分方式命名   不依赖support/androidx的模块称为pure模块\n  依赖support的称为support模块\n  依赖androidx的称为androidx模块\n  升级方案  module内部，将原本的基础仓库old base module拆分为base_support + base_pure两个模块，剥离support依赖。其中base_pure模块拆分到一个单独的project中，而base_support项目需要新增base_androidx branch，分开两个branch迭代，并通过cherrypick进行修改同步，同时分别发布独立的maven。 old base module所依赖的模块，也需要按照1的方式进行拆分。同时pure模块只能依赖pure模块,非pure模块可以依赖对应的非pure模块和pure模块 pure模块的单测test模块是support或者androidx都没关系，不影响发版仓库中的内容 androidx利用灰度版本去进行测试  包依赖关系 graph TB app_support--\u0026gt;base_support app_support--\u0026gt;base_pure app_androidx--\u0026gt;base_androidx app_androidx--\u0026gt;base_pure base_pure--\u0026gt;xxx_pure base_support--\u0026gt;xxx_support base_support--\u0026gt;xxx_pure base_androidx--\u0026gt;xxx_androidx base_androidx--\u0026gt;xxx_pure 升级步骤 https://developer.android.google.cn/jetpack/androidx/migrate?hl=zh-cn\nhttps://medium.com/androiddevelopers/migrating-to-androidx-tip-tricks-and-guidance-88d5de238876\n是时候迁移至 AndroidX 了！\ngraph LR olderSupport--\u0026gt;|APIchanges|28.0.0Support--\u0026gt;|namespaceChanges|androidx1.0  创建新分支准备迁移，停止同步进行的新功能开发和重构，防止冲突 在old base module中搜索support进行处理,去除不必要的support库依赖 support升级到28，这是因为，1.0.0 版本的 AndroidX 工件是与支持库 28.0.0 工件等效的二进制文件。 编译和测试用例通过 配置android.useAndroidX=true android.enableJetifier=true 更新依赖的仓库到支持androidx的版本 迁移到androidx: AS操作 Refactor \u0026gt; Migrate to AndroidX  基于androidx的后续基础架构封装 新架构单独封装一个独立的module(使用androidx)，提供基础能力\n 基础View组件(Activity,Fragment,View等)，支持DataBinding的能力选择 基础ViewModel组件 基础Repository组件 新架构组件的使用规范和样例 startup启动组件 后台任务调度执行组件 datastore组件替代现有的sharedPreference 其他jetpack组件，按需封装提供  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/systemserversource/",
	"title": "SystemServerSource",
	"tags": [],
	"description": "",
	"content": "main /** * The main entry point from zygote. */ public static void main(String[] args) { new SystemServer().run(); } run private void run() { // The system server should never make non-oneway calls  Binder.setWarnOnBlocking(true); // Ensure binder calls into the system always run at foreground priority.  BinderInternal.disableBackgroundScheduling(true); // Increase the number of binder threads in system_server  BinderInternal.setMaxThreads(sMaxBinderThreads); // Prepare the main looper thread (this thread).  android.os.Process.setThreadPriority( android.os.Process.THREAD_PRIORITY_FOREGROUND); android.os.Process.setCanSelfBackground(false); Looper.prepareMainLooper(); startBootstrapServices(); startCoreServices(); startOtherServices(); // Loop forever.  Looper.loop(); throw new RuntimeException(\u0026#34;Main thread loop unexpectedly exited\u0026#34;); } startOtherServices private void startOtherServices() { traceBeginAndSlog(\u0026#34;StartInputManagerService\u0026#34;); inputManager = new InputManagerService(context); traceEnd(); traceBeginAndSlog(\u0026#34;StartWindowManagerService\u0026#34;); // WMS needs sensor service ready  ConcurrentUtils.waitForFutureNoInterrupt(mSensorServiceStart, START_SENSOR_SERVICE); mSensorServiceStart = null; wm = WindowManagerService.main(context, inputManager, mFactoryTestMode != FactoryTest.FACTORY_TEST_LOW_LEVEL, !mFirstBoot, mOnlyCore, new PhoneWindowManager()); ServiceManager.addService(Context.WINDOW_SERVICE, wm, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL | DUMP_FLAG_PROTO); ServiceManager.addService(Context.INPUT_SERVICE, inputManager, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL); } "
},
{
	"uri": "https://huanle19891345.github.io/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/handler/threadlocal/",
	"title": "ThreadLocal",
	"tags": [],
	"description": "",
	"content": "ThreadLocal模型 graph LR thread--\u0026gt;threadLocalMap threadLocalMap--\u0026gt;entry1 threadLocalMap--\u0026gt;entry2 threadLocalMap--\u0026gt;entryLooper threadLocalMap--\u0026gt;entryxxx entry1--\u0026gt;key=threadlocal1,value=T1 entry2--\u0026gt;key=threadlocal2,value=T2 entryLooper--\u0026gt;LooperEntry(key=threadlocal_Looper,value=Looper) LooperEntry--\u0026gt;MessageQueue  线性探测解决hash冲突 超过默认长度(16)的2/3时rehash减少hash冲突，扩容一倍 threadlocal作为key保存在entry中时是WeakReference，在被回收时清除记录，因此需要外部定义TheadLocal实例的地方配置为static，否则在外部回收threadlocal时，threadlocalmap中的entry也会被清理掉 lazy模式，只有添加第一个 元素时才通过createMap创建ThreadLocalMap  Thread /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; /* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ThreadLocal threadLocalHashCode public class ThreadLocal\u0026lt;T\u0026gt; { /** * ThreadLocals rely on per-thread linear-probe hash maps attached * to each thread (Thread.threadLocals and * inheritableThreadLocals). The ThreadLocal objects act as keys, * searched via threadLocalHashCode. This is a custom hash code * (useful only within ThreadLocalMaps) that eliminates collisions * in the common case where consecutively constructed ThreadLocals * are used by the same threads, while remaining well-behaved in * less common cases. */ private final int threadLocalHashCode = nextHashCode(); private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() { return nextHashCode.getAndAdd(HASH_INCREMENT); } set /** * Sets the current thread\u0026#39;s copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the {@link #initialValue} * method to set the values of thread-locals. * * @param value the value to be stored in the current thread\u0026#39;s copy of * this thread-local. */ public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } get /** * Returns the value in the current thread\u0026#39;s copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the {@link #initialValue} method. * * @return the current thread\u0026#39;s value of this thread-local */ public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; return result; } } return setInitialValue(); } setInitialValue private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } initialValue /** * Returns the current thread\u0026#39;s \u0026#34;initial value\u0026#34; for this * thread-local variable. This method will be invoked the first * time a thread accesses the variable with the {@link #get} * method, unless the thread previously invoked the {@link #set} * method, in which case the {@code initialValue} method will not * be invoked for the thread. Normally, this method is invoked at * most once per thread, but it may be invoked again in case of * subsequent invocations of {@link #remove} followed by {@link #get}. * * \u0026lt;p\u0026gt;This implementation simply returns {@code null}; if the * programmer desires thread-local variables to have an initial * value other than {@code null}, {@code ThreadLocal} must be * subclassed, and this method overridden. Typically, an * anonymous inner class will be used. * * @return the initial value for this thread-local */ protected T initialValue() { return null; } createMap void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } ThreadLocalMap static class ThreadLocalMap { /** Construct a new map initially containing (firstKey, firstValue). * ThreadLocalMaps are constructed lazily, so we only create * one when we have at least one entry to put in it. */ ThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode \u0026amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); } } Entry /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as \u0026#34;stale entries\u0026#34; in the code that follows. */ static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } table /** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * Set the resize threshold to maintain at worst a 2/3 load factor. */ private void setThreshold(int len) { threshold = len * 2 / 3; } getEntry /** * Get the entry associated with key. This method * itself handles only the fast path: a direct hit of existing * key. It otherwise relays to getEntryAfterMiss. This is * designed to maximize performance for direct hits, in part * by making this method readily inlinable. * * @param key the thread local object * @return the entry associated with key, or null if no such */ private Entry getEntry(ThreadLocal\u0026lt;?\u0026gt; key) { int i = key.threadLocalHashCode \u0026amp; (table.length - 1); Entry e = table[i]; if (e != null \u0026amp;\u0026amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); } getEntryAfterMiss /** * Version of getEntry method for use when key is not found in * its direct hash slot. * * @param key the thread local object * @param i the table index for key\u0026#39;s hash code * @param e the entry at table[i] * @return the entry associated with key, or null if no such */ private Entry getEntryAfterMiss(ThreadLocal\u0026lt;?\u0026gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null; } nextIndex /** * Increment i modulo len. */ private static int nextIndex(int i, int len) { return ((i + 1 \u0026lt; len) ? i + 1 : 0); } set /** * Set the value associated with key. * * @param key the thread local object * @param value the value to be set */ private void set(ThreadLocal\u0026lt;?\u0026gt; key, Object value) { // We don\u0026#39;t use a fast path as with get() because it is at  // least as common to use set() to create new entries as  // it is to replace existing ones, in which case, a fast  // path would fail more often than not.  Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode \u0026amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) \u0026amp;\u0026amp; sz \u0026gt;= threshold) rehash(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/input/toucheventnative/",
	"title": "touchEventNative",
	"tags": [],
	"description": "",
	"content": "原理图 SystemServer startOtherServices private void startOtherServices() { inputManager = new InputManagerService(context); wm = WindowManagerService.main(context, inputManager, mFactoryTestMode != FactoryTest.FACTORY_TEST_LOW_LEVEL, !mFirstBoot, mOnlyCore, new PhoneWindowManager()); ServiceManager.addService(Context.WINDOW_SERVICE, wm, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL | DUMP_FLAG_PROTO); ServiceManager.addService(Context.INPUT_SERVICE, inputManager, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL); ...... inputManager.setWindowManagerCallbacks(wm.getInputMonitor()); inputManager.start(); } InputManagerService public class InputManagerService extends IInputManager.Stub { public InputManagerService(Context context) { this.mContext = context; this.mHandler = new InputManagerHandler(DisplayThread.get().getLooper()); mPtr = nativeInit(this, mContext, mHandler.getLooper().getQueue()); } } start public void start() { Slog.i(TAG, \u0026#34;Starting input manager\u0026#34;); nativeStart(mPtr); } registerInputChannel public void registerInputChannel(InputChannel inputChannel, InputWindowHandle inputWindowHandle) { nativeRegisterInputChannel(mPtr, inputChannel, inputWindowHandle, false); } frameworks/base/services/core/jni/com_android_server_input_InputManagerService.cpp\ncom_android_server_input_InputManagerService nativeInit static jlong nativeInit(JNIEnv* env, jclass /* clazz */, jobject serviceObj, jobject contextObj, jobject messageQueueObj) { sp\u0026lt;MessageQueue\u0026gt; messageQueue = android_os_MessageQueue_getMessageQueue(env, messageQueueObj); NativeInputManager* im = new NativeInputManager(contextObj, serviceObj, messageQueue-\u0026gt;getLooper()); im-\u0026gt;incStrong(0); return reinterpret_cast\u0026lt;jlong\u0026gt;(im); } nativeStart static void nativeStart(JNIEnv* env, jclass /* clazz */, jlong ptr) { NativeInputManager* im = reinterpret_cast\u0026lt;NativeInputManager*\u0026gt;(ptr); status_t result = im-\u0026gt;getInputManager()-\u0026gt;start(); } nativeRegisterInputChannel static void nativeRegisterInputChannel(JNIEnv* env, jclass /* clazz */, jlong ptr, jobject inputChannelObj, jobject inputWindowHandleObj, jboolean monitor) { NativeInputManager* im = reinterpret_cast\u0026lt;NativeInputManager*\u0026gt;(ptr); status_t status = im-\u0026gt;registerInputChannel( env, inputChannel, inputWindowHandle, monitor); } frameworks/base/services/core/jni/com_android_server_input_InputManagerService.cpp\nNativeInputManager NativeInputManager::NativeInputManager(jobject contextObj, jobject serviceObj, const sp\u0026lt;Looper\u0026gt;\u0026amp; looper) : mLooper(looper), mInteractive(true) { sp\u0026lt;EventHub\u0026gt; eventHub = new EventHub(); mInputManager = new InputManager(eventHub, this, this); } registerInputChannel status_t NativeInputManager::registerInputChannel(JNIEnv* /* env */, const sp\u0026lt;InputChannel\u0026gt;\u0026amp; inputChannel, const sp\u0026lt;InputWindowHandle\u0026gt;\u0026amp; inputWindowHandle, bool monitor) { ATRACE_CALL(); return mInputManager-\u0026gt;getDispatcher()-\u0026gt;registerInputChannel( inputChannel, inputWindowHandle, monitor); } frameworks/native/services/inputflinger/InputManager.cpp\nInputManager InputManager::InputManager( const sp\u0026lt;EventHubInterface\u0026gt;\u0026amp; eventHub, const sp\u0026lt;InputReaderPolicyInterface\u0026gt;\u0026amp; readerPolicy, const sp\u0026lt;InputDispatcherPolicyInterface\u0026gt;\u0026amp; dispatcherPolicy) { mDispatcher = new InputDispatcher(dispatcherPolicy); mReader = new InputReader(eventHub, readerPolicy, mDispatcher); initialize(); } initialize void InputManager::initialize() { mReaderThread = new InputReaderThread(mReader); mDispatcherThread = new InputDispatcherThread(mDispatcher); } start status_t InputManager::start() { status_t result = mDispatcherThread-\u0026gt;run(\u0026#34;InputDispatcher\u0026#34;, PRIORITY_URGENT_DISPLAY); result = mReaderThread-\u0026gt;run(\u0026#34;InputReader\u0026#34;, PRIORITY_URGENT_DISPLAY); return OK; } frameworks/native/services/inputflinger/EventHub.cpp\nEventHub EventHub EventHub::EventHub(void) : { mEpollFd = epoll_create(EPOLL_SIZE_HINT); mINotifyFd = inotify_init(); int result = inotify_add_watch(mINotifyFd, DEVICE_PATH, IN_DELETE | IN_CREATE); struct epoll_event eventItem; memset(\u0026amp;eventItem, 0, sizeof(eventItem)); eventItem.events = EPOLLIN; eventItem.data.u32 = EPOLL_ID_INOTIFY; result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mINotifyFd, \u0026amp;eventItem); int wakeFds[2]; result = pipe(wakeFds); mWakeReadPipeFd = wakeFds[0]; mWakeWritePipeFd = wakeFds[1]; result = fcntl(mWakeReadPipeFd, F_SETFL, O_NONBLOCK); result = fcntl(mWakeWritePipeFd, F_SETFL, O_NONBLOCK); eventItem.data.u32 = EPOLL_ID_WAKE; result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeReadPipeFd, \u0026amp;eventItem); } getEvents size_t EventHub::getEvents(int timeoutMillis, RawEvent* buffer, size_t bufferSize) { for (;;) { // Grab the next input event.  bool deviceChanged = false; while (mPendingEventIndex \u0026lt; mPendingEventCount) { const struct epoll_event\u0026amp; eventItem = mPendingEventItems[mPendingEventIndex++]; if (eventItem.data.u32 == EPOLL_ID_INOTIFY) { if (eventItem.events \u0026amp; EPOLLIN) { mPendingINotify = true; } continue; } ...... if (mPendingINotify \u0026amp;\u0026amp; mPendingEventIndex \u0026gt;= mPendingEventCount) { mPendingINotify = false; readNotifyLocked(); } } int pollResult = epoll_wait(mEpollFd, mPendingEventItems, EPOLL_MAX_EVENTS, timeoutMillis); } readNotifyLocked status_t EventHub::readNotifyLocked() { res = read(mINotifyFd, event_buf, sizeof(event_buf)); } frameworks/native/services/inputflinger/InputReader.cpp\nInputReaderThread threadLoop bool InputReaderThread::threadLoop() { mReader-\u0026gt;loopOnce(); return true; } frameworks/native/services/inputflinger/InputReader.cpp\nInputReader InputReader::InputReader(const sp\u0026lt;EventHubInterface\u0026gt;\u0026amp; eventHub, const sp\u0026lt;InputReaderPolicyInterface\u0026gt;\u0026amp; policy, const sp\u0026lt;InputListenerInterface\u0026gt;\u0026amp; listener) : mContext(this), mEventHub(eventHub), mPolicy(policy), { mQueuedListener = new QueuedInputListener(listener); } threadLoop bool InputReaderThread::threadLoop() { mReader-\u0026gt;loopOnce(); return true; } loopOnce void InputReader::loopOnce() { size_t count = mEventHub-\u0026gt;getEvents(timeoutMillis, mEventBuffer, EVENT_BUFFER_SIZE); if (count) { processEventsLocked(mEventBuffer, count); } // Flush queued events out to the listener.  // This must happen outside of the lock because the listener could potentially call  // back into the InputReader\u0026#39;s methods, such as getScanCodeState, or become blocked  // on another thread similarly waiting to acquire the InputReader lock thereby  // resulting in a deadlock. This situation is actually quite plausible because the  // listener is actually the input dispatcher, which calls into the window manager,  // which occasionally calls into the input reader.  mQueuedListener-\u0026gt;flush(); } getevents\nflush\nframeworks/native/services/inputflinger/InputListener.cpp\nQueuedInputListener flush void QueuedInputListener::flush() { size_t count = mArgsQueue.size(); for (size_t i = 0; i \u0026lt; count; i++) { NotifyArgs* args = mArgsQueue[i]; args-\u0026gt;notify(mInnerListener); delete args; } mArgsQueue.clear(); } NotifyMotionArgs notify void NotifyMotionArgs::notify(const sp\u0026lt;InputListenerInterface\u0026gt;\u0026amp; listener) const { listener-\u0026gt;notifyMotion(this); } notifymotion\nframeworks/native/services/inputflinger/InputDispatcher.cpp\nInputDispatcher threadLoop bool InputDispatcherThread::threadLoop() { mDispatcher-\u0026gt;dispatchOnce(); return true; } dispatchOnce void InputDispatcher::dispatchOnce() { // Run a dispatch loop if there are no pending commands.  // The dispatch loop might enqueue commands to run afterwards.  if (!haveCommandsLocked()) { dispatchOnceInnerLocked(\u0026amp;nextWakeupTime); } // Wait for callback or timeout or wake. (make sure we round up, not down)  nsecs_t currentTime = now(); int timeoutMillis = toMillisecondTimeoutDelay(currentTime, nextWakeupTime); mLooper-\u0026gt;pollOnce(timeoutMillis);//registerInputChannel时通过Looper.wake()唤醒线程 } notifyMotion void InputDispatcher::notifyMotion(const NotifyMotionArgs* args) { if (needWake) { mLooper-\u0026gt;wake(); } } dispatchOnceInnerLocked void InputDispatcher::dispatchOnceInnerLocked(nsecs_t* nextWakeupTime) { case EventEntry::TYPE_MOTION: { MotionEntry* typedEntry = static_cast\u0026lt;MotionEntry*\u0026gt;(mPendingEvent); if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; isAppSwitchDue) { dropReason = DROP_REASON_APP_SWITCH; } if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; isStaleEventLocked(currentTime, typedEntry)) { dropReason = DROP_REASON_STALE; } if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; mNextUnblockedEvent) { dropReason = DROP_REASON_BLOCKED; } done = dispatchMotionLocked(currentTime, typedEntry, \u0026amp;dropReason, nextWakeupTime); break; } dispatchMotionLocked bool InputDispatcher::dispatchMotionLocked( nsecs_t currentTime, MotionEntry* entry, DropReason* dropReason, nsecs_t* nextWakeupTime) { dispatchEventLocked(currentTime, entry, inputTargets); return true; } dispatchEventLocked void InputDispatcher::dispatchEventLocked(nsecs_t currentTime, EventEntry* eventEntry, const Vector\u0026lt;InputTarget\u0026gt;\u0026amp; inputTargets) { for (size_t i = 0; i \u0026lt; inputTargets.size(); i++) { const InputTarget\u0026amp; inputTarget = inputTargets.itemAt(i); ssize_t connectionIndex = getConnectionIndexLocked(inputTarget.inputChannel); if (connectionIndex \u0026gt;= 0) { sp\u0026lt;Connection\u0026gt; connection = mConnectionsByFd.valueAt(connectionIndex); prepareDispatchCycleLocked(currentTime, connection, eventEntry, \u0026amp;inputTarget); } } prepareDispatchCycleLocked void InputDispatcher::prepareDispatchCycleLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection, EventEntry* eventEntry, const InputTarget* inputTarget) { enqueueDispatchEntriesLocked(currentTime, connection, splitMotionEntry, inputTarget); } enqueueDispatchEntriesLocked void InputDispatcher::enqueueDispatchEntriesLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection, EventEntry* eventEntry, const InputTarget* inputTarget) { bool wasEmpty = connection-\u0026gt;outboundQueue.isEmpty(); ...... // If the outbound queue was previously empty, start the dispatch cycle going.  if (wasEmpty \u0026amp;\u0026amp; !connection-\u0026gt;outboundQueue.isEmpty()) { startDispatchCycleLocked(currentTime, connection); } } startDispatchCycleLocked void InputDispatcher::startDispatchCycleLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection) { EventEntry* eventEntry = dispatchEntry-\u0026gt;eventEntry; switch (eventEntry-\u0026gt;type) { case EventEntry::TYPE_KEY: { KeyEntry* keyEntry = static_cast\u0026lt;KeyEntry*\u0026gt;(eventEntry); // Publish the key event.  status = connection-\u0026gt;inputPublisher.publishKeyEvent(dispatchEntry-\u0026gt;seq, keyEntry-\u0026gt;deviceId, keyEntry-\u0026gt;source, dispatchEntry-\u0026gt;resolvedAction, dispatchEntry-\u0026gt;resolvedFlags, keyEntry-\u0026gt;keyCode, keyEntry-\u0026gt;scanCode, keyEntry-\u0026gt;metaState, keyEntry-\u0026gt;repeatCount, keyEntry-\u0026gt;downTime, keyEntry-\u0026gt;eventTime); break; } case EventEntry::TYPE_MOTION: { // Publish the motion event.  status = connection-\u0026gt;inputPublisher.publishMotionEvent(dispatchEntry-\u0026gt;seq, motionEntry-\u0026gt;deviceId, motionEntry-\u0026gt;source, motionEntry-\u0026gt;displayId, dispatchEntry-\u0026gt;resolvedAction, motionEntry-\u0026gt;actionButton, dispatchEntry-\u0026gt;resolvedFlags, motionEntry-\u0026gt;edgeFlags, motionEntry-\u0026gt;metaState, motionEntry-\u0026gt;buttonState, xOffset, yOffset, motionEntry-\u0026gt;xPrecision, motionEntry-\u0026gt;yPrecision, motionEntry-\u0026gt;downTime, motionEntry-\u0026gt;eventTime, motionEntry-\u0026gt;pointerCount, motionEntry-\u0026gt;pointerProperties, usingCoords); break; } publishmotionevent\nhandleReceiveCallback int InputDispatcher::handleReceiveCallback(int fd, int events, void* data) { InputDispatcher* d = static_cast\u0026lt;InputDispatcher*\u0026gt;(data); ssize_t connectionIndex = d-\u0026gt;mConnectionsByFd.indexOfKey(fd); sp\u0026lt;Connection\u0026gt; connection = d-\u0026gt;mConnectionsByFd.valueAt(connectionIndex); if (!(events \u0026amp; (ALOOPER_EVENT_ERROR | ALOOPER_EVENT_HANGUP))) { if (!(events \u0026amp; ALOOPER_EVENT_INPUT)) {//仅仅对ALOOPER_EVENT_INPUT事件类型进行处理  ALOGW(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received spurious callback for unhandled poll event. \u0026#34; \u0026#34;events=0x%x\u0026#34;, connection-\u0026gt;getInputChannelName().c_str(), events); return 1; } nsecs_t currentTime = now(); bool gotOne = false; status_t status; for (;;) { uint32_t seq; bool handled; status = connection-\u0026gt;inputPublisher.receiveFinishedSignal(\u0026amp;seq, \u0026amp;handled); if (status) { break; } d-\u0026gt;finishDispatchCycleLocked(currentTime, connection, seq, handled); gotOne = true; } if (gotOne) { d-\u0026gt;runCommandsLockedInterruptible(); if (status == WOULD_BLOCK) { return 1; } } }   Input系统—InputReader线程：通过EventHub从/dev/input节点获取事件，转换成EventEntry事件加入到InputDispatcher的mInboundQueue。\n  Input系统—InputDispatcher线程：从mInboundQueue队列取出事件，转换成DispatchEntry事件加入到connection的outboundQueue队列。再然后开始处理分发事件，取出outbound队列，放入waitQueue.\n  Input系统—UI线程\n：创建socket pair，分别位于”InputDispatcher”线程和focused窗口所在进程的UI主线程，可相互通信。\n UI主线程：通过setFdEvents()， 监听socket客户端，收到消息后回调NativeInputEventReceiver();【见小节2.1】 “InputDispatcher”线程： 通过IMS.registerInputChannel()，监听socket服务端，收到消息后回调handleReceiveCallback；【见小节3.1】    前面文章都是介绍了两个线程InputReader和InputDispatcher的工作过程。在InputDispatcher的过程讲到 调用InputChanel通过socket与远程进程通信，本文便展开讲解这个socket是如何建立的。\n对于InputReader和InputDispatcher都是运行在system_server进程； 用户点击的界面往往可能是某一个app，而每个app一般地都运行在自己的进程，这里就涉及到跨进程通信，app进程是如何与system进程建立通信。\nframeworks/native/libs/input/InputTransport.cpp\nInputPublisher publishMotionEvent status_t InputPublisher::publishMotionEvent( uint32_t seq,...... { return mChannel-\u0026gt;sendMessage(\u0026amp;msg); } InputConsumer sendFinishedSignal status_t InputConsumer::sendFinishedSignal(uint32_t seq, bool handled) { return sendUnchainedFinishedSignal(seq, handled); } sendUnchainedFinishedSignal status_t InputConsumer::sendUnchainedFinishedSignal(uint32_t seq, bool handled) { InputMessage msg; msg.header.type = InputMessage::TYPE_FINISHED; msg.body.finished.seq = seq; msg.body.finished.handled = handled; return mChannel-\u0026gt;sendMessage(\u0026amp;msg); } InputChannel(两个Socket实现双向监听) sendMessage status_t InputChannel::sendMessage(const InputMessage* msg) { size_t msgLength = msg-\u0026gt;size(); ssize_t nWrite; do { nWrite = ::send(mFd, msg, msgLength, MSG_DONTWAIT | MSG_NOSIGNAL); } while (nWrite == -1 \u0026amp;\u0026amp; errno == EINTR); Socket/Channel SystemServer进程 [-\u0026gt; WindowManagerService.java]\npublic int addWindow(Session session, IWindow client, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, InputChannel outInputChannel) { inputChannels数组：\n inputChannels[0]所对应的InputChannel名称的后缀为(server); inputChannels[1]所对应的InputChannel名称的后缀为(client)；  其中：\n 服务端inputChannels[0]保存到WindowState的mInputChannel； 客户端inputChannels[1]传递给outInputChannel，最终传递给ViewRootImpl的mInputChannel；  [-\u0026gt; InputTransport.cpp]\nstatus_t InputChannel::openInputChannelPair(const String8\u0026amp; name, sp\u0026lt;InputChannel\u0026gt;\u0026amp; outServerChannel, sp\u0026lt;InputChannel\u0026gt;\u0026amp; outClientChannel) { int sockets[2]; //真正创建socket对的地方【核心】  if (socketpair(AF_UNIX, SOCK_SEQPACKET, 0, sockets)) { ... return result; } int bufferSize = SOCKET_BUFFER_SIZE; //32k  setsockopt(sockets[0], SOL_SOCKET, SO_SNDBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[0], SOL_SOCKET, SO_RCVBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[1], SOL_SOCKET, SO_SNDBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[1], SOL_SOCKET, SO_RCVBUF, \u0026amp;bufferSize, sizeof(bufferSize)); String8 serverChannelName = name; serverChannelName.append(\u0026#34; (server)\u0026#34;); //创建InputChannel对象  outServerChannel = new InputChannel(serverChannelName, sockets[0]); String8 clientChannelName = name; clientChannelName.append(\u0026#34; (client)\u0026#34;); //创建InputChannel对象  outClientChannel = new InputChannel(clientChannelName, sockets[1]); return OK; } 该方法主要功能:\n 创建socket pair; (非阻塞式的socket) 设置两个socket的接收和发送的buffer上限为32KB; 创建client和server的Native层InputChannel对象;  sockets[0]所对应的InputChannel名称的后缀为(server); sockets[1]所对应的InputChannel名称的后缀为(client)    创建InputChannel对象位于文件InputTransport.cpp，如下：\nInputChannel::InputChannel(const String8\u0026amp; name, int fd) : mName(name), mFd(fd) { //将socket设置成非阻塞方式  int result = fcntl(mFd, F_SETFL, O_NONBLOCK); } frameworks/native/services/inputflinger/InputDispatcher.cpp\nregisterInputChannel status_t InputDispatcher::registerInputChannel(const sp\u0026lt;InputChannel\u0026gt;\u0026amp; inputChannel, const sp\u0026lt;InputWindowHandle\u0026gt;\u0026amp; inputWindowHandle, bool monitor) { { AutoMutex _l(mLock); ... //创建Connection[见小节2.8.4]  sp\u0026lt;Connection\u0026gt; connection = new Connection(inputChannel, inputWindowHandle, monitor); int fd = inputChannel-\u0026gt;getFd();//fd为socket fd  mConnectionsByFd.add(fd, connection); ... //将该fd添加到Looper监听[见小节2.8.5]  mLooper-\u0026gt;addFd(fd, 0, ALOOPER_EVENT_INPUT, handleReceiveCallback, this); } mLooper-\u0026gt;wake(); //connection改变, 则唤醒looper  return OK; } 将新创建的connection保存到mConnectionsByFd成员变量，“InputDispatcher”线程的Looper添加对socket服务端的监听功能； 当该socket有消息时便会唤醒该线程工作。\nViewRootImpl的setView()过程:\n 创建socket pair，作为InputChannel:  socket服务端保存到system_server中的WindowState的mInputChannel； socket客户端通过binder传回到远程进程的UI主线程ViewRootImpl的mInputChannel；   IMS.registerInputChannel()注册InputChannel，监听socket服务端：  Loop便是“InputDispatcher”线程的Looper; 回调方法handleReceiveCallback。    Socket/Channel app进程 [-\u0026gt; android_view_InputEventReceiver.cpp]\nvoid NativeInputEventReceiver::setFdEvents(int events) { if (mFdEvents != events) { mFdEvents = events; int fd = mInputConsumer.getChannel()-\u0026gt;getFd();//channel提供fd  if (events) { //将socket客户端的fd添加到主线程的消息池【见小节3.6.1】  mMessageQueue-\u0026gt;getLooper()-\u0026gt;addFd(fd, 0, events, this, NULL);//fd可读时触发本类的handleEvent回调  } else { mMessageQueue-\u0026gt;getLooper()-\u0026gt;removeFd(fd); } } } 此处的Looper便是UI主线程的Looper，将socket客户端的fd添加到UI线程的Looper来监听，回调方法为NativeInputEventReceiver。\n首先，通过openInputChannelPair来创建socket pair，作为InputChannel:\n socket服务端保存到system_server中的WindowState的mInputChannel； socket客户端通过binder传回到远程进程的UI主线程ViewRootImpl的mInputChannel(inputChannel是binder调用的out参数)；  紧接着，完成了两个线程的epoll监听工作：\n [小节2.8]IMS.registerInputChannel(): “InputDispatcher”线程监听socket服务端，收到消息后回调InputDispatcher.handleReceiveCallback()； [小节3.6]setFdEvents(): UI主线程监听socket客户端，收到消息后回调NativeInputEventReceiver.handleEvent().  system/core/libutils/Looper.cpp\nLooper.cpp pollInner int Looper::pollInner(int timeoutMillis) { // Invoke all response callbacks.  for (size_t i = 0; i \u0026lt; mResponses.size(); i++) { // Invoke the callback. Note that the file descriptor may be closed by  // the callback (and potentially even reused) before the function returns so  // we need to be a little careful when removing the file descriptor afterwards.  int callbackResult = response.request.callback-\u0026gt;handleEvent(fd, events, data); } } frameworks/base/core/jni/android_view_InputEventReceiver.cpp\nNativeInputEventReceiver handleEvent int NativeInputEventReceiver::handleEvent(int receiveFd, int events, void* data) { if (events \u0026amp; ALOOPER_EVENT_INPUT) { JNIEnv* env = AndroidRuntime::getJNIEnv(); status_t status = consumeEvents(env, false /*consumeBatches*/, -1, NULL); mMessageQueue-\u0026gt;raiseAndClearException(env, \u0026#34;handleReceiveCallback\u0026#34;); return status == OK || status == NO_MEMORY ? 1 : 0; } } consumeEvents status_t NativeInputEventReceiver::consumeEvents(JNIEnv* env, bool consumeBatches, nsecs_t frameTime, bool* outConsumedBatch) { for (;;) { uint32_t seq; InputEvent* inputEvent; int32_t displayId; status_t status = mInputConsumer.consume(\u0026amp;mInputEventFactory, consumeBatches, frameTime, \u0026amp;seq, \u0026amp;inputEvent, \u0026amp;displayId); jobject inputEventObj; switch (inputEvent-\u0026gt;getType()) { case AINPUT_EVENT_TYPE_KEY: if (kDebugDispatchCycle) { ALOGD(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received key event.\u0026#34;, getInputChannelName().c_str()); } inputEventObj = android_view_KeyEvent_fromNative(env, static_cast\u0026lt;KeyEvent*\u0026gt;(inputEvent)); break; case AINPUT_EVENT_TYPE_MOTION: { if (kDebugDispatchCycle) { ALOGD(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received motion event.\u0026#34;, getInputChannelName().c_str()); } MotionEvent* motionEvent = static_cast\u0026lt;MotionEvent*\u0026gt;(inputEvent); if ((motionEvent-\u0026gt;getAction() \u0026amp; AMOTION_EVENT_ACTION_MOVE) \u0026amp;\u0026amp; outConsumedBatch) { *outConsumedBatch = true; } inputEventObj = android_view_MotionEvent_obtainAsCopy(env, motionEvent); break; } default: assert(false); // InputConsumer should prevent this from ever happening  inputEventObj = NULL; } if (inputEventObj) { env-\u0026gt;CallVoidMethod(receiverObj.get(), gInputEventReceiverClassInfo.dispatchInputEvent, seq, inputEventObj, displayId); } InputEventReceiver dispatchInputEvent // Called from native code.  @SuppressWarnings(\u0026#34;unused\u0026#34;) private void dispatchInputEvent(int seq, InputEvent event, int displayId) { mSeqMap.put(event.getSequenceNumber(), seq); onInputEvent(event, displayId); } finishInputEvent public final void finishInputEvent(InputEvent event, boolean handled) { nativeFinishInputEvent(mReceiverPtr, seq, handled); } frameworks/base/core/jni/android_view_InputEventReceiver.cpp\nandroid_view_InputEventReceiver nativeFinishInputEvent static void nativeFinishInputEvent(JNIEnv* env, jclass clazz, jlong receiverPtr, jint seq, jboolean handled) { sp\u0026lt;NativeInputEventReceiver\u0026gt; receiver = reinterpret_cast\u0026lt;NativeInputEventReceiver*\u0026gt;(receiverPtr); status_t status = receiver-\u0026gt;finishInputEvent(seq, handled); } finishInputEvent status_t NativeInputEventReceiver::finishInputEvent(uint32_t seq, bool handled) { status_t status = mInputConsumer.sendFinishedSignal(seq, handled); } sendfinishedsignal\n参考 \u0026laquo;深入理解Android : 卷3 第五章 输入系统\u0026raquo;\nInput系统—事件处理全过程\nInput系统—ANR原理分析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/vsync/",
	"title": "Vsync",
	"tags": [],
	"description": "",
	"content": "原理图 Vsync App进程 graph TB DisplayEventDispatcher::scheduleVsync--\u0026gt;eventConnection.requestNextVsync sequenceDiagram participant JavaDispalyEventReveiver participant NativeDisplayEventReceiver participant Looper participant BitTube NativeDisplayEventReceiver-\u0026gt;\u0026gt;+Looper: looper.addFd Looper--\u0026gt;\u0026gt;-NativeDisplayEventReceiver: fd可读 NativeDisplayEventReceiver-\u0026gt;\u0026gt;+NativeDisplayEventReceiver: handleEvent NativeDisplayEventReceiver-\u0026gt;\u0026gt;-BitTube: recvObjects BitTube--\u0026gt;\u0026gt;NativeDisplayEventReceiver: return NativeDisplayEventReceiver-\u0026gt;\u0026gt;JavaDispalyEventReveiver:dispatchVsnc frameworks/base/libs/androidfw/DisplayEventDispatcher.cpp\nDisplayEventDispatcher.cpp initialize status_t DisplayEventDispatcher::initialize() { status_t result = mReceiver.initCheck(); int rc = mLooper-\u0026gt;addFd(mReceiver.getFd(), 0, Looper::EVENT_INPUT, this, NULL); return OK; } handleEvent int DisplayEventDispatcher::handleEvent(int, int events, void*) { // Drain all pending events, keep the last vsync.  nsecs_t vsyncTimestamp; int32_t vsyncDisplayId; uint32_t vsyncCount; if (processPendingEvents(\u0026amp;vsyncTimestamp, \u0026amp;vsyncDisplayId, \u0026amp;vsyncCount)) { dispatchVsync(vsyncTimestamp, vsyncDisplayId, vsyncCount); } return 1; // keep the callback } scheduleVsync status_t DisplayEventDispatcher::scheduleVsync() { if (!mWaitingForVsync) { // Drain all pending events.  if (processPendingEvents(\u0026amp;vsyncTimestamp, \u0026amp;vsyncDisplayId, \u0026amp;vsyncCount)) { this, ns2ms(static_cast\u0026lt;nsecs_t\u0026gt;(vsyncTimestamp))); } status_t status = mReceiver.requestNextVsync(); mWaitingForVsync = true; } return OK; } frameworks/native/libs/gui/DisplayEventReceiver.cpp\nDisplayEventReceiver.cpp sp\u0026lt;IDisplayEventConnection\u0026gt; mEventConnection; std::unique_ptr\u0026lt;gui::BitTube\u0026gt; mDataChannel; DisplayEventReceiver() /* * DisplayEventReceiver creates and registers an event connection with * SurfaceFlinger. VSync events are disabled by default. Call setVSyncRate * or requestNextVsync to receive them. * Other events start being delivered immediately. */ DisplayEventReceiver::DisplayEventReceiver(ISurfaceComposer::VsyncSource vsyncSource) { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService()); if (sf != NULL) { mEventConnection = sf-\u0026gt;createDisplayEventConnection(vsyncSource); if (mEventConnection != NULL) { mDataChannel = std::make_unique\u0026lt;gui::BitTube\u0026gt;(); mEventConnection-\u0026gt;stealReceiveChannel(mDataChannel.get()); } } } getFd int DisplayEventReceiver::getFd() const { if (mDataChannel == NULL) return NO_INIT; return mDataChannel-\u0026gt;getFd(); } getEvents ssize_t DisplayEventReceiver::getEvents(DisplayEventReceiver::Event* events, size_t count) { return DisplayEventReceiver::getEvents(mDataChannel.get(), events, count); } ssize_t DisplayEventReceiver::getEvents(gui::BitTube* dataChannel, Event* events, size_t count) { return gui::BitTube::recvObjects(dataChannel, events, count); } requestNextVsync status_t DisplayEventReceiver::requestNextVsync() { if (mEventConnection != NULL) { mEventConnection-\u0026gt;requestNextVsync(); return NO_ERROR; } return NO_INIT; } frameworks/native/libs/gui/BitTube.cpp\nBitTube getFd int BitTube::getFd() const { return mReceiveFd; } frameworks/native/libs/gui/SurfaceComposerClient.cpp\nframeworks/native/libs/gui/include/private/gui/ComposerService.h\nComposerService // This holds our connection to the composer service (i.e. SurfaceFlinger). // If the remote side goes away, we will re-establish the connection. // Users of this class should not retain the value from // getComposerService() for an extended period. class ComposerService : public Singleton\u0026lt;ComposerService\u0026gt; { sp\u0026lt;ISurfaceComposer\u0026gt; mComposerService; sp\u0026lt;IBinder::DeathRecipient\u0026gt; mDeathObserver; } getComposerService // Get a connection to the Composer Service. This will block until  // a connection is established. /*static*/ sp\u0026lt;ISurfaceComposer\u0026gt; ComposerService::getComposerService() { ComposerService\u0026amp; instance = ComposerService::getInstance(); Mutex::Autolock _l(instance.mLock); if (instance.mComposerService == NULL) { ComposerService::getInstance().connectLocked(); assert(instance.mComposerService != NULL); } return instance.mComposerService; } connectLocked void ComposerService::connectLocked() { const String16 name(\u0026#34;SurfaceFlinger\u0026#34;); while (getService(name, \u0026amp;mComposerService) != NO_ERROR) {//get SurfaceFlinger Service  usleep(250000); } assert(mComposerService != NULL); // Create the death listener.  class DeathObserver : public IBinder::DeathRecipient { ComposerService\u0026amp; mComposerService; virtual void binderDied(const wp\u0026lt;IBinder\u0026gt;\u0026amp; who) { ALOGW(\u0026#34;ComposerService remote (surfaceflinger) died [%p]\u0026#34;, who.unsafe_get()); mComposerService.composerServiceDied(); } public: explicit DeathObserver(ComposerService\u0026amp; mgr) : mComposerService(mgr) { } }; mDeathObserver = new DeathObserver(*const_cast\u0026lt;ComposerService*\u0026gt;(this)); IInterface::asBinder(mComposerService)-\u0026gt;linkToDeath(mDeathObserver); } composerServiceDied void ComposerService::composerServiceDied() { Mutex::Autolock _l(mLock); mComposerService = NULL; mDeathObserver = NULL; } frameworks/native/libs/binder/include/binder/IServiceManager.h\nIServiceManager getService template\u0026lt;typename INTERFACE\u0026gt; status_t getService(const String16\u0026amp; name, sp\u0026lt;INTERFACE\u0026gt;* outService) { const sp\u0026lt;IServiceManager\u0026gt; sm = defaultServiceManager(); if (sm != NULL) { *outService = interface_cast\u0026lt;INTERFACE\u0026gt;(sm-\u0026gt;getService(name)); if ((*outService) != NULL) return NO_ERROR; } return NAME_NOT_FOUND; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/vsync_surfaceflinger/",
	"title": "Vsync_SurfaceFlinger",
	"tags": [],
	"description": "",
	"content": "Android-SurfaceFlinger启动与绘图原理\n创建 HWComposer 对象(通过 HAL 层的 HWComposer 硬件模块 或 软件模拟产生 Vsync 信号)，现在的 Android 系统基本上都可以看成是通过硬件 HWComposer 产生 Vsync 信号，而不使用软件模拟，所以下面解析都只谈及硬件 HWComposer 的 Vsync 信号；\nChoreographer 会通过上面创建的 APP 延时源 mEventThreadSource 对象及其对应的 EventThread 线程来监听同步模拟发出的 Vsync 信号，然后进行绘制(measure/layout/draw)操作。具体逻辑见 Android-Choreographer原理。\nSurfaceFlinger类设计 graph TB SurfaceFlinger--\u0026gt;BnSurfaceComposer--\u0026gt;BnInterface BnSurfaceComposer--\u0026gt;ISurfaceComposer ISurfaceComposer--\u0026gt;IInterface BnInterface--\u0026gt;BBinder--\u0026gt;IBinder system/core/rootdir/init.rc\ninit.rc on property:vold.decrypt=trigger_restart_framework stop surfaceflinger start surfaceflinger # A/B update verifier that marks a successful boot. exec_start update_verifier class_start main class_start late_start frameworks/native/services/surfaceflinger/surfaceflinger.rc\nsurfaceflinger.rc service surfaceflinger /system/bin/surfaceflinger class core animation user system group graphics drmrpc readproc onrestart restart zygote writepid /dev/stune/foreground/tasks socket pdx/system/vr/display/client stream 0666 system graphics u:object_r:pdx_display_client_endpoint_socket:s0 socket pdx/system/vr/display/manager stream 0666 system graphics u:object_r:pdx_display_manager_endpoint_socket:s0 socket pdx/system/vr/display/vsync stream 0666 system graphics u:object_r:pdx_display_vsync_endpoint_socket:s0 frameworks/native/services/surfaceflinger/main_surfaceflinger.cpp\nmain_surfaceflinger.cpp main int main(int, char**) { // When SF is launched in its own process, limit the number of  // binder threads to 4.  ProcessState::self()-\u0026gt;setThreadPoolMaxThreadCount(4); // start the thread pool  sp\u0026lt;ProcessState\u0026gt; ps(ProcessState::self()); ps-\u0026gt;startThreadPool(); // instantiate surfaceflinger  sp\u0026lt;SurfaceFlinger\u0026gt; flinger = new SurfaceFlinger(); setpriority(PRIO_PROCESS, 0, PRIORITY_URGENT_DISPLAY); set_sched_policy(0, SP_FOREGROUND); // initialize before clients can connect  flinger-\u0026gt;init(); // publish surface flinger  sp\u0026lt;IServiceManager\u0026gt; sm(defaultServiceManager()); sm-\u0026gt;addService(String16(SurfaceFlinger::getServiceName()), flinger, false, IServiceManager::DUMP_FLAG_PRIORITY_CRITICAL); // run surface flinger in this thread  flinger-\u0026gt;run(); return 0; } frameworks/native/services/surfaceflinger/SurfaceFlinger.h\nSurfaceFlinger SurfaceFlinger class SurfaceFlinger : public BnSurfaceComposer, public PriorityDumper, private IBinder::DeathRecipient, private HWC2::ComposerCallback { // these are thread safe  mutable std::unique_ptr\u0026lt;MessageQueue\u0026gt; mEventQueue{std::make_unique\u0026lt;impl::MessageQueue\u0026gt;()}; VSyncModulator mVsyncModulator; DispSync mPrimaryDispSync; using CreateBufferQueueFunction = std::function\u0026lt;void(sp\u0026lt;IGraphicBufferProducer\u0026gt;* /* outProducer */, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* /* outConsumer */, bool /* consumerIsSurfaceFlinger */)\u0026gt;; CreateBufferQueueFunction mCreateBufferQueue; using CreateNativeWindowSurfaceFunction = std::function\u0026lt;std::unique_ptr\u0026lt;NativeWindowSurface\u0026gt;(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp;)\u0026gt;; CreateNativeWindowSurfaceFunction mCreateNativeWindowSurface; } SurfaceFlinger::SurfaceFlinger(SurfaceFlinger::SkipInitializationTag) : BnSurfaceComposer(), Display(false), ...... mMainThreadId(std::this_thread::get_id()), mCreateBufferQueue(\u0026amp;BufferQueue::createBufferQueue), mCreateNativeWindowSurface(\u0026amp;impl::NativeWindowSurface::create) {} onFirstRef void SurfaceFlinger::onFirstRef() { mEventQueue-\u0026gt;init(this); } init void SurfaceFlinger::init() { // start the EventThread  mEventThreadSource = std::make_unique\u0026lt;DispSyncSource\u0026gt;(\u0026amp;mPrimaryDispSync, SurfaceFlinger::vsyncPhaseOffsetNs, true, \u0026#34;app\u0026#34;); mEventThread = std::make_unique\u0026lt;impl::EventThread\u0026gt;(mEventThreadSource.get(), [this]() { resyncWithRateLimit(); }, impl::EventThread::InterceptVSyncsCallback(), \u0026#34;appEventThread\u0026#34;); mSfEventThreadSource = std::make_unique\u0026lt;DispSyncSource\u0026gt;(\u0026amp;mPrimaryDispSync, SurfaceFlinger::sfVsyncPhaseOffsetNs, true, \u0026#34;sf\u0026#34;); mSFEventThread = std::make_unique\u0026lt;impl::EventThread\u0026gt;(mSfEventThreadSource.get(), [this]() { resyncWithRateLimit(); }, [this](nsecs_t timestamp) { mInterceptor-\u0026gt;saveVSyncEvent(timestamp); mEventQueue-\u0026gt;setEventThread(mSFEventThread.get()); mVsyncModulator.setEventThread(mSFEventThread.get()); // Get a RenderEngine for the given display / config (can\u0026#39;t fail)  getBE().mRenderEngine = RE::impl::RenderEngine::create(HAL_PIXEL_FORMAT_RGBA_8888, hasWideColorDisplay ? RE::RenderEngine::WIDE_COLOR_SUPPORT : 0); getBE().mHwc.reset( new HWComposer(std::make_unique\u0026lt;Hwc2::impl::Composer\u0026gt;(getBE().mHwcServiceName))); getBE().mHwc-\u0026gt;registerCallback(this, getBE().mComposerSequenceId); mEventControlThread = std::make_unique\u0026lt;impl::EventControlThread\u0026gt;( [this](bool enabled) { setVsyncEnabled(HWC_DISPLAY_PRIMARY, enabled); }); // set initial conditions (e.g. unblank default device)  initializeDisplays(); } onVsyncReceived void SurfaceFlinger::onVsyncReceived(int32_t sequenceId, hwc2_display_t displayId, int64_t timestamp) { Mutex::Autolock lock(mStateLock); // Ignore any vsyncs from a previous hardware composer.  if (sequenceId != getBE().mComposerSequenceId) { return; } int32_t type; if (!getBE().mHwc-\u0026gt;onVsync(displayId, timestamp, \u0026amp;type)) { return; } bool needsHwVsync = false; { // Scope for the lock  Mutex::Autolock _l(mHWVsyncLock); if (type == DisplayDevice::DISPLAY_PRIMARY \u0026amp;\u0026amp; mPrimaryHWVsyncEnabled) { needsHwVsync = mPrimaryDispSync.addResyncSample(timestamp); } } if (needsHwVsync) { enableHardwareVsync(); } else { disableHardwareVsync(false); } } disableHardwareVsync void SurfaceFlinger::disableHardwareVsync(bool makeUnavailable) { Mutex::Autolock _l(mHWVsyncLock); if (mPrimaryHWVsyncEnabled) { //eventControl(HWC_DISPLAY_PRIMARY, SurfaceFlinger::EVENT_VSYNC, false);  mEventControlThread-\u0026gt;setVsyncEnabled(false); mPrimaryDispSync.endResync(); mPrimaryHWVsyncEnabled = false; } if (makeUnavailable) { mHWVsyncAvailable = false; } } run void SurfaceFlinger::run() { do { waitForEvent(); } while (true); } waitForEvent void SurfaceFlinger::waitForEvent() { mEventQueue-\u0026gt;waitMessage(); } onMessageReceived void SurfaceFlinger::onMessageReceived(int32_t what) { switch (what) { case MessageQueue::INVALIDATE: { bool refreshNeeded = handleMessageTransaction(); refreshNeeded |= handleMessageInvalidate(); refreshNeeded |= mRepaintEverything; if (refreshNeeded) { // Signal a refresh if a transaction modified the window state,  // a new buffer was latched, or if HWC has requested a full  // repaint  signalRefresh();//call handleMessageRefresh()  } break; } case MessageQueue::REFRESH: { handleMessageRefresh(); break; } } } handleMessageRefresh void SurfaceFlinger::handleMessageRefresh() { ATRACE_CALL(); mRefreshPending = false; nsecs_t refreshStartTime = systemTime(SYSTEM_TIME_MONOTONIC); preComposition(refreshStartTime); rebuildLayerStacks(); setUpHWComposer(); doDebugFlashRegions(); doTracing(\u0026#34;handleRefresh\u0026#34;); logLayerStats(); doComposition(); postComposition(refreshStartTime); mPreviousPresentFence = getBE().mHwc-\u0026gt;getPresentFence(HWC_DISPLAY_PRIMARY); mHadClientComposition = false; for (size_t displayId = 0; displayId \u0026lt; mDisplays.size(); ++displayId) { const sp\u0026lt;DisplayDevice\u0026gt;\u0026amp; displayDevice = mDisplays[displayId]; mHadClientComposition = mHadClientComposition || getBE().mHwc-\u0026gt;hasClientComposition(displayDevice-\u0026gt;getHwcDisplayId()); } mVsyncModulator.onRefreshed(mHadClientComposition); mLayersWithQueuedFrames.clear(); } createDisplayEventConnection sp\u0026lt;IDisplayEventConnection\u0026gt; SurfaceFlinger::createDisplayEventConnection( ISurfaceComposer::VsyncSource vsyncSource) { if (vsyncSource == eVsyncSourceSurfaceFlinger) { return mSFEventThread-\u0026gt;createEventConnection(); } else { return mEventThread-\u0026gt;createEventConnection(); } } resyncWithRateLimit void SurfaceFlinger::resyncWithRateLimit() { static constexpr nsecs_t kIgnoreDelay = ms2ns(500); // No explicit locking is needed here since EventThread holds a lock while calling this method  static nsecs_t sLastResyncAttempted = 0; const nsecs_t now = systemTime(); if (now - sLastResyncAttempted \u0026gt; kIgnoreDelay) { resyncToHardwareVsync(false); } sLastResyncAttempted = now; } resyncToHardwareVsync void SurfaceFlinger::resyncToHardwareVsync(bool makeAvailable) { Mutex::Autolock _l(mHWVsyncLock); if (makeAvailable) { mHWVsyncAvailable = true; } else if (!mHWVsyncAvailable) { // Hardware vsync is not currently available, so abort the resync  // attempt for now  return; } const auto\u0026amp; activeConfig = getBE().mHwc-\u0026gt;getActiveConfig(HWC_DISPLAY_PRIMARY); const nsecs_t period = activeConfig-\u0026gt;getVsyncPeriod(); mPrimaryDispSync.reset(); mPrimaryDispSync.setPeriod(period); if (!mPrimaryHWVsyncEnabled) { mPrimaryDispSync.beginResync(); //eventControl(HWC_DISPLAY_PRIMARY, SurfaceFlinger::EVENT_VSYNC, true);  mEventControlThread-\u0026gt;setVsyncEnabled(true); mPrimaryHWVsyncEnabled = true; } } setVsyncEnabled void SurfaceFlinger::setVsyncEnabled(int disp, int enabled) { getHwComposer().setVsyncEnabled(disp, enabled ? HWC2::Vsync::Enable : HWC2::Vsync::Disable); } frameworks/native/libs/gui/include/gui/ISurfaceComposer.h\nVsyncSource enum VsyncSource { eVsyncSourceApp = 0, eVsyncSourceSurfaceFlinger = 1 }; ComposerCallbackBridge :IComposerCallback ComposerCallback* mCallback; onVsync Return\u0026lt;void\u0026gt; onVsync(Hwc2::Display display, int64_t timestamp) override { mCallback-\u0026gt;onVsyncReceived(mSequenceId, display, timestamp); return Void(); } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\nDispSyncSource DispSync* mDispSync; Mutex mCallbackMutex; // Protects the following  VSyncSource::Callback* mCallback = nullptr; onDispSyncEvent virtual void onDispSyncEvent(nsecs_t when) { VSyncSource::Callback* callback; { Mutex::Autolock lock(mCallbackMutex); callback = mCallback; if (mTraceVsync) { mValue = (mValue + 1) % 2; ATRACE_INT(mVsyncEventLabel.string(), mValue); } } if (callback != nullptr) { callback-\u0026gt;onVSyncEvent(when); } } frameworks/native/services/surfaceflinger/EventThread.cpp\nEventThread class EventThread : public android::EventThread, private VSyncSource::Callback { class Connection : public BnDisplayEventConnection { public: explicit Connection(EventThread* eventThread); virtual ~Connection(); virtual status_t postEvent(const DisplayEventReceiver::Event\u0026amp; event); // count \u0026gt;= 1 : continuous event. count is the vsync rate  // count == 0 : one-shot event that has not fired  // count ==-1 : one-shot event that fired this round / disabled  int32_t count; private: virtual void onFirstRef(); status_t stealReceiveChannel(gui::BitTube* outChannel) override; status_t setVsyncRate(uint32_t count) override; void requestNextVsync() override; // asynchronous  EventThread* const mEventThread; gui::BitTube mChannel; }; EventThread() EventThread::EventThread(VSyncSource* src, ResyncWithRateLimitCallback resyncWithRateLimitCallback, InterceptVSyncsCallback interceptVSyncsCallback, const char* threadName) : mVSyncSource(src), mResyncWithRateLimitCallback(resyncWithRateLimitCallback), mInterceptVSyncsCallback(interceptVSyncsCallback) { for (auto\u0026amp; event : mVSyncEvent) { event.header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; event.header.id = 0; event.header.timestamp = 0; event.vsync.count = 0; } mThread = std::thread(\u0026amp;EventThread::threadMain, this); pthread_setname_np(mThread.native_handle(), threadName); pid_t tid = pthread_gettid_np(mThread.native_handle()); // Use SCHED_FIFO to minimize jitter  constexpr int EVENT_THREAD_PRIORITY = 2; struct sched_param param = {0}; param.sched_priority = EVENT_THREAD_PRIORITY; if (pthread_setschedparam(mThread.native_handle(), SCHED_FIFO, \u0026amp;param) != 0) { ALOGE(\u0026#34;Couldn\u0026#39;t set SCHED_FIFO for EventThread\u0026#34;); } set_sched_policy(tid, SP_FOREGROUND); } threadMain void EventThread::threadMain() NO_THREAD_SAFETY_ANALYSIS { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mMutex); while (mKeepRunning) { DisplayEventReceiver::Event event; Vector\u0026lt;sp\u0026lt;EventThread::Connection\u0026gt; \u0026gt; signalConnections; signalConnections = waitForEventLocked(\u0026amp;lock, \u0026amp;event); // dispatch events to listeners...  const size_t count = signalConnections.size(); for (size_t i = 0; i \u0026lt; count; i++) { const sp\u0026lt;Connection\u0026gt;\u0026amp; conn(signalConnections[i]); // now see if we still need to report this event  status_t err = conn-\u0026gt;postEvent(event); } } } waitForEventLocked // This will return when (1) a vsync event has been received, and (2) there was // at least one connection interested in receiving it when we started waiting. Vector\u0026lt;sp\u0026lt;EventThread::Connection\u0026gt; \u0026gt; EventThread::waitForEventLocked( std::unique_lock\u0026lt;std::mutex\u0026gt;* lock, DisplayEventReceiver::Event* event) { ...... if (!timestamp \u0026amp;\u0026amp; !eventPending) { // wait for something to happen  if (waitForVSync) { // This is where we spend most of our time, waiting  // for vsync events and new client registrations.  //  // If the screen is off, we can\u0026#39;t use h/w vsync, so we  // use a 16ms timeout instead. It doesn\u0026#39;t need to be  // precise, we just need to keep feeding our clients.  //  // We don\u0026#39;t want to stall if there\u0026#39;s a driver bug, so we  // use a (long) timeout when waiting for h/w vsync, and  // generate fake events when necessary.  bool softwareSync = mUseSoftwareVSync; auto timeout = softwareSync ? 16ms : 1000ms; if (mCondition.wait_for(*lock, timeout) == std::cv_status::timeout) { if (!softwareSync) { ALOGW(\u0026#34;Timed out waiting for hw vsync; faking it\u0026#34;); } // FIXME: how do we decide which display id the fake  // vsync came from ?  mVSyncEvent[0].header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; mVSyncEvent[0].header.id = DisplayDevice::DISPLAY_PRIMARY; mVSyncEvent[0].header.timestamp = systemTime(SYSTEM_TIME_MONOTONIC); mVSyncEvent[0].vsync.count++; } } else { // Nobody is interested in vsync, so we just want to sleep.  // h/w vsync should be disabled, so this will wait until we  // get a new connection, or an existing connection becomes  // interested in receiving vsync again.  mCondition.wait(*lock); } // here we\u0026#39;re guaranteed to have a timestamp and some connections to signal  // (The connections might have dropped out of mDisplayEventConnections  // while we were asleep, but we\u0026#39;ll still have strong references to them.)  return signalConnections; } onVSyncEvent void EventThread::onVSyncEvent(nsecs_t timestamp) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); mVSyncEvent[0].header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; mVSyncEvent[0].header.id = 0; mVSyncEvent[0].header.timestamp = timestamp; mVSyncEvent[0].vsync.count++; mCondition.notify_all();//唤醒EventThread线程 } Connection::postEvent status_t EventThread::Connection::postEvent(const DisplayEventReceiver::Event\u0026amp; event) { ssize_t size = DisplayEventReceiver::sendEvents(\u0026amp;mChannel, \u0026amp;event, 1); return size \u0026lt; 0 ? status_t(size) : status_t(NO_ERROR); } createEventConnection sp\u0026lt;BnDisplayEventConnection\u0026gt; EventThread::createEventConnection() const { return new Connection(const_cast\u0026lt;EventThread*\u0026gt;(this)); } Connection::stealReceiveChannel /* * stealReceiveChannel() returns a BitTube to receive events from. Only the receive file * descriptor of outChannel will be initialized, and this effectively \u0026#34;steals\u0026#34; the receive * channel from the remote end (such that the remote end can only use its send channel). */ status_t EventThread::Connection::stealReceiveChannel(gui::BitTube* outChannel) { outChannel-\u0026gt;setReceiveFd(mChannel.moveReceiveFd()); return NO_ERROR; } Connection::requestNextVsync void EventThread::Connection::requestNextVsync() { mEventThread-\u0026gt;requestNextVsync(this); } requestNextVsync void EventThread::requestNextVsync(const sp\u0026lt;EventThread::Connection\u0026gt;\u0026amp; connection) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); if (mResyncWithRateLimitCallback) { mResyncWithRateLimitCallback();//callback resyncWithRateLimit in SurfaceFlinger  } if (connection-\u0026gt;count \u0026lt; 0) { connection-\u0026gt;count = 0; mCondition.notify_all(); } } frameworks/native/services/surfaceflinger/EventControlThread.cpp\nEventControlThread setVsyncEnabled void EventControlThread::setVsyncEnabled(bool enabled) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); mVsyncEnabled = enabled; mCondition.notify_all(); } threadMain // Unfortunately std::unique_lock gives warnings with -Wthread-safety void EventControlThread::threadMain() NO_THREAD_SAFETY_ANALYSIS { auto keepRunning = true; auto currentVsyncEnabled = false; while (keepRunning) { mSetVSyncEnabled(currentVsyncEnabled); std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mMutex); mCondition.wait(lock, [this, currentVsyncEnabled, keepRunning]() NO_THREAD_SAFETY_ANALYSIS { return currentVsyncEnabled != mVsyncEnabled || keepRunning != mKeepRunning; }); currentVsyncEnabled = mVsyncEnabled; keepRunning = mKeepRunning; } } frameworks/native/libs/gui/DisplayEventReceiver.cpp\nDisplayEventReceiver sendEvents ssize_t DisplayEventReceiver::sendEvents(gui::BitTube* dataChannel, Event const* events, size_t count) { return gui::BitTube::sendObjects(dataChannel, events, count); } frameworks/native/libs/gui/BitTube.cpp\nBitTube // Socket buffer size. The default is typically about 128KB, which is much larger than we really // need. So we make it smaller. static const size_t DEFAULT_SOCKET_BUFFER_SIZE = 4 * 1024; BitTube() BitTube::BitTube(size_t bufsize) { init(bufsize, bufsize); } init void BitTube::init(size_t rcvbuf, size_t sndbuf) { int sockets[2]; if (socketpair(AF_UNIX, SOCK_SEQPACKET, 0, sockets) == 0) { size_t size = DEFAULT_SOCKET_BUFFER_SIZE; setsockopt(sockets[0], SOL_SOCKET, SO_RCVBUF, \u0026amp;rcvbuf, sizeof(rcvbuf)); setsockopt(sockets[1], SOL_SOCKET, SO_SNDBUF, \u0026amp;sndbuf, sizeof(sndbuf)); // since we don\u0026#39;t use the \u0026#34;return channel\u0026#34;, we keep it small...  setsockopt(sockets[0], SOL_SOCKET, SO_SNDBUF, \u0026amp;size, sizeof(size)); setsockopt(sockets[1], SOL_SOCKET, SO_RCVBUF, \u0026amp;size, sizeof(size)); fcntl(sockets[0], F_SETFL, O_NONBLOCK); fcntl(sockets[1], F_SETFL, O_NONBLOCK); mReceiveFd.reset(sockets[0]); mSendFd.reset(sockets[1]); } else { mReceiveFd.reset(); ALOGE(\u0026#34;BitTube: pipe creation failed (%s)\u0026#34;, strerror(errno)); } } sendObjects ssize_t BitTube::sendObjects(BitTube* tube, void const* events, size_t count, size_t objSize) { const char* vaddr = reinterpret_cast\u0026lt;const char*\u0026gt;(events); ssize_t size = tube-\u0026gt;write(vaddr, count * objSize); // ALOGE_IF(size\u0026lt;0, \u0026#34;error %d sending %d events\u0026#34;, size, count);  return size \u0026lt; 0 ? size : size / static_cast\u0026lt;ssize_t\u0026gt;(objSize); } write ssize_t BitTube::write(void const* vaddr, size_t size) { ssize_t err, len; do { len = ::send(mSendFd, vaddr, size, MSG_DONTWAIT | MSG_NOSIGNAL); // cannot return less than size, since we\u0026#39;re using SOCK_SEQPACKET  err = len \u0026lt; 0 ? errno : 0; } while (err == EINTR); return err == 0 ? len : -err; } recvObjects ssize_t BitTube::recvObjects(BitTube* tube, void* events, size_t count, size_t objSize) { char* vaddr = reinterpret_cast\u0026lt;char*\u0026gt;(events); ssize_t size = tube-\u0026gt;read(vaddr, count * objSize); // ALOGE_IF(size\u0026lt;0, \u0026#34;error %d receiving %d events\u0026#34;, size, count);  return size \u0026lt; 0 ? size : size / static_cast\u0026lt;ssize_t\u0026gt;(objSize); } rameworks/native/services/surfaceflinger/DispSync.cpp\nDispSync // mThread is the thread from which all the callbacks are called.  sp\u0026lt;DispSyncThread\u0026gt; mThread; init void DispSync::init(bool hasSyncFramework, int64_t dispSyncPresentTimeOffset) { mThread-\u0026gt;run(\u0026#34;DispSync\u0026#34;, PRIORITY_URGENT_DISPLAY + PRIORITY_MORE_FAVORABLE); reset(); beginResync(); } addResyncSample bool DispSync::addResyncSample(nsecs_t timestamp) { updateModelLocked(); } updateModelLocked void DispSync::updateModelLocked() { mThread-\u0026gt;updateModel(mPeriod, mPhase, mReferenceTime); } frameworks/native/services/surfaceflinger/DispSync.cpp\nDispSyncThread class DispSyncThread : public Thread { Vector\u0026lt;EventListener\u0026gt; mEventListeners; } threadLoop virtual bool threadLoop() { status_t err; nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); while (true) { targetTime = computeNextEventTimeLocked(now); bool isWakeup = false; if (now \u0026lt; targetTime) { if (kTraceDetailedInfo) ATRACE_NAME(\u0026#34;DispSync waiting\u0026#34;); if (targetTime == INT64_MAX) { ALOGV(\u0026#34;[%s] Waiting forever\u0026#34;, mName); err = mCond.wait(mMutex); } else { ALOGV(\u0026#34;[%s] Waiting until %\u0026#34; PRId64, mName, ns2us(targetTime)); err = mCond.waitRelative(mMutex, targetTime - now); } } callbackInvocations = gatherCallbackInvocationsLocked(now); if (callbackInvocations.size() \u0026gt; 0) { fireCallbackInvocations(callbackInvocations); } } } gatherCallbackInvocationsLocked Vector\u0026lt;CallbackInvocation\u0026gt; gatherCallbackInvocationsLocked(nsecs_t now) { Vector\u0026lt;CallbackInvocation\u0026gt; callbackInvocations; nsecs_t onePeriodAgo = now - mPeriod; for (size_t i = 0; i \u0026lt; mEventListeners.size(); i++) { nsecs_t t = computeListenerNextEventTimeLocked(mEventListeners[i], onePeriodAgo); if (t \u0026lt; now) { CallbackInvocation ci; ci.mCallback = mEventListeners[i].mCallback; ci.mEventTime = t; callbackInvocations.push(ci); mEventListeners.editItemAt(i).mLastEventTime = t; } } return callbackInvocations; } fireCallbackInvocations void fireCallbackInvocations(const Vector\u0026lt;CallbackInvocation\u0026gt;\u0026amp; callbacks) { for (size_t i = 0; i \u0026lt; callbacks.size(); i++) { callbacks[i].mCallback-\u0026gt;onDispSyncEvent(callbacks[i].mEventTime); } } updateModel void updateModel(nsecs_t period, nsecs_t phase, nsecs_t referenceTime) { Mutex::Autolock lock(mMutex); mPeriod = period; mPhase = phase; mReferenceTime = referenceTime; mCond.signal(); } frameworks/native/services/surfaceflinger/MessageQueue.h\nMessageQueue namespace impl { class MessageQueue final : public android::MessageQueue { class Handler : public MessageHandler { enum { eventMaskInvalidate = 0x1, eventMaskRefresh = 0x2, eventMaskTransaction = 0x4 }; MessageQueue\u0026amp; mQueue; int32_t mEventMask; public: explicit Handler(MessageQueue\u0026amp; queue) : mQueue(queue), mEventMask(0) {} virtual void handleMessage(const Message\u0026amp; message); void dispatchRefresh(); void dispatchInvalidate(); }; friend class Handler; sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; sp\u0026lt;Looper\u0026gt; mLooper; android::EventThread* mEventThread; sp\u0026lt;IDisplayEventConnection\u0026gt; mEvents; gui::BitTube mEventTube; sp\u0026lt;Handler\u0026gt; mHandler; } init void MessageQueue::init(const sp\u0026lt;SurfaceFlinger\u0026gt;\u0026amp; flinger) { mFlinger = flinger; mLooper = new Looper(true);//system/core/include/utils/Looper.h  mHandler = new Handler(*this); } setEventThread void MessageQueue::setEventThread(android::EventThread* eventThread) { if (mEventThread == eventThread) { return; } if (mEventTube.getFd() \u0026gt;= 0) { mLooper-\u0026gt;removeFd(mEventTube.getFd()); } mEventThread = eventThread; mEvents = eventThread-\u0026gt;createEventConnection(); mEvents-\u0026gt;stealReceiveChannel(\u0026amp;mEventTube); mLooper-\u0026gt;addFd(mEventTube.getFd(), 0, Looper::EVENT_INPUT, MessageQueue::cb_eventReceiver, this); } waitMessage void MessageQueue::waitMessage() { do { IPCThreadState::self()-\u0026gt;flushCommands(); int32_t ret = mLooper-\u0026gt;pollOnce(-1); switch (ret) { case Looper::POLL_WAKE: case Looper::POLL_CALLBACK: continue; case Looper::POLL_ERROR: ALOGE(\u0026#34;Looper::POLL_ERROR\u0026#34;); continue; case Looper::POLL_TIMEOUT: // timeout (should not happen)  continue; default: // should not happen  ALOGE(\u0026#34;Looper::pollOnce() returned unknown status %d\u0026#34;, ret); continue; } } while (true); } cb_eventReceiver int MessageQueue::cb_eventReceiver(int fd, int events, void* data) { MessageQueue* queue = reinterpret_cast\u0026lt;MessageQueue*\u0026gt;(data); return queue-\u0026gt;eventReceiver(fd, events); } eventReceiver int MessageQueue::eventReceiver(int /*fd*/, int /*events*/) { ssize_t n; DisplayEventReceiver::Event buffer[8]; while ((n = DisplayEventReceiver::getEvents(\u0026amp;mEventTube, buffer, 8)) \u0026gt; 0) { for (int i = 0; i \u0026lt; n; i++) { if (buffer[i].header.type == DisplayEventReceiver::DISPLAY_EVENT_VSYNC) { mHandler-\u0026gt;dispatchInvalidate(); break; } } } return 1; } Handler::dispatchInvalidate void MessageQueue::Handler::dispatchInvalidate() { if ((android_atomic_or(eventMaskInvalidate, \u0026amp;mEventMask) \u0026amp; eventMaskInvalidate) == 0) { mQueue.mLooper-\u0026gt;sendMessage(this, Message(MessageQueue::INVALIDATE)); } } Handler::handleMessage void MessageQueue::Handler::handleMessage(const Message\u0026amp; message) { switch (message.what) { case INVALIDATE: android_atomic_and(~eventMaskInvalidate, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; case REFRESH: android_atomic_and(~eventMaskRefresh, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; } } frameworks/native/services/surfaceflinger/DisplayHardware/HWC2.h\nComposerCallback // Implement this interface to receive hardware composer events. // // These callback functions will generally be called on a hwbinder thread, but // when first registering the callback the onHotplugReceived() function will // immediately be called on the thread calling registerCallback(). // // All calls receive a sequenceId, which will be the value that was supplied to // HWC2::Device::registerCallback(). It\u0026#39;s used to help differentiate callbacks // from different hardware composer instances. class ComposerCallback { public: virtual void onHotplugReceived(int32_t sequenceId, hwc2_display_t display, Connection connection) = 0; virtual void onRefreshReceived(int32_t sequenceId, hwc2_display_t display) = 0; virtual void onVsyncReceived(int32_t sequenceId, hwc2_display_t display, int64_t timestamp) = 0; virtual ~ComposerCallback() = default; };  frameworks/native/libs/gui/IGraphicBufferProducer.cpp\nIGraphicBufferProducer.cpp queueBuffer virtual status_t queueBuffer(int buf, const QueueBufferInput\u0026amp; input, QueueBufferOutput* output) { Parcel data, reply; data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor()); data.writeInt32(buf); data.write(input); status_t result = remote()-\u0026gt;transact(QUEUE_BUFFER, data, \u0026amp;reply); return result; } onTransact status_t BnGraphicBufferProducer::onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { switch(code) { case QUEUE_BUFFER: { CHECK_INTERFACE(IGraphicBufferProducer, data, reply); int buf = data.readInt32(); QueueBufferInput input(data); QueueBufferOutput output; status_t result = queueBuffer(buf, input, \u0026amp;output); reply-\u0026gt;write(output); reply-\u0026gt;writeInt32(result); return NO_ERROR; } │79 status_t MonitoredProducer::queueBuffer(int slot, const QueueBufferInput\u0026amp; input, │80 QueueBufferOutput* output) { \u0026gt;│81 return mProducer-\u0026gt;queueBuffer(slot, input, output); │82 } │83 │750 status_t BufferQueueProducer::queueBuffer(int slot, │751 const QueueBufferInput \u0026amp;input, QueueBufferOutput *output) { \u0026gt;│977 frameAvailableListener-\u0026gt;onFrameAvailable(item); │46 void BufferQueue::ProxyConsumerListener::onFrameAvailable( │47 const BufferItem\u0026amp; item) { │48 sp\u0026lt;ConsumerListener\u0026gt; listener(mConsumerListener.promote()); │49 if (listener != NULL) { \u0026gt;│50 listener-\u0026gt;onFrameAvailable(item); │51 } │52 } │104 void ConsumerBase::onFrameAvailable(const BufferItem\u0026amp; item) { │105 CB_LOGV(\u0026#34;onFrameAvailable\u0026#34;); │106 │107 sp\u0026lt;FrameAvailableListener\u0026gt; listener; │108 { // scope for the lock  │109 Mutex::Autolock lock(mFrameAvailableMutex); │110 listener = mFrameAvailableListener.promote(); │111 } │112 │113 if (listener != NULL) { │114 CB_LOGV(\u0026#34;actually calling onFrameAvailable\u0026#34;); \u0026gt;│115 listener-\u0026gt;onFrameAvailable(item); │116 } │117 } │723 // ---------------------------------------------------------------------------  │724 // Interface implementation for SurfaceFlingerConsumer::ContentsChangedListener  │725 // ---------------------------------------------------------------------------  │726 │727 void BufferLayer::onFrameAvailable(const BufferItem\u0026amp; item) { │728 // Add this buffer from our internal queue tracker  │729 { // Autolock scope B+\u0026gt;│730 Mutex::Autolock lock(mQueueItemLock); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/",
	"title": "zygote",
	"tags": [],
	"description": "",
	"content": "zygote 探索总结zygote知识\n SystemServerSource     ZygoteSource     Zygote进程     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/zygotesource/",
	"title": "ZygoteSource",
	"tags": [],
	"description": "",
	"content": "原理图 ZygoteInit.main public static void main(String argv[]) { ZygoteServer zygoteServer = new ZygoteServer(); for (int i = 1; i \u0026lt; argv.length; i++) { if (\u0026#34;start-system-server\u0026#34;.equals(argv[i])) { startSystemServer = true; } else if (\u0026#34;--enable-lazy-preload\u0026#34;.equals(argv[i])) { enableLazyPreload = true; } else if (argv[i].startsWith(ABI_LIST_ARG)) { abiList = argv[i].substring(ABI_LIST_ARG.length()); } else if (argv[i].startsWith(SOCKET_NAME_ARG)) { socketName = argv[i].substring(SOCKET_NAME_ARG.length()); } else { throw new RuntimeException(\u0026#34;Unknown command line argument: \u0026#34; + argv[i]); } } zygoteServer.registerServerSocketFromEnv(socketName); if (startSystemServer) { Runnable r = forkSystemServer(abiList, socketName, zygoteServer); // {@code r == null} in the parent (zygote) process, and {@code r != null} in the  // child (system_server) process.  if (r != null) { r.run(); return; } } Log.i(TAG, \u0026#34;Accepting command socket connections\u0026#34;); // The select loop returns early in the child process after a fork and  // loops forever in the zygote.  caller = zygoteServer.runSelectLoop(abiList); // We\u0026#39;re in the child process and have exited the select loop. Proceed to execute the  // command.  if (caller != null) { caller.run(); } } forkSystemServer private static Runnable forkSystemServer(String abiList, String socketName, ZygoteServer zygoteServer) { /* Request to fork the system server process */ pid = Zygote.forkSystemServer( parsedArgs.uid, parsedArgs.gid, parsedArgs.gids, parsedArgs.runtimeFlags, null, parsedArgs.permittedCapabilities, parsedArgs.effectiveCapabilities); /* For child process */ if (pid == 0) { if (hasSecondZygote(abiList)) { waitForSecondaryZygote(socketName); } zygoteServer.closeServerSocket(); return handleSystemServerProcess(parsedArgs); } /** @return 0 if this is the child, pid of the child * if this is the parent, or -1 on error. */ public static int forkSystemServer(int uid, int gid, int[] gids, int runtimeFlags, int[][] rlimits, long permittedCapabilities, long effectiveCapabilities) { int pid = nativeForkSystemServer( uid, gid, gids, runtimeFlags, rlimits, permittedCapabilities, effectiveCapabilities); // Enable tracing as soon as we enter the system_server.  if (pid == 0) { Trace.setTracingEnabled(true, runtimeFlags); } return pid; } SystemServer handleSystemServerProcess /** * Finish remaining work for the newly forked system server process. */ private static Runnable handleSystemServerProcess(ZygoteConnection.Arguments parsedArgs) { ClassLoader cl = null; if (systemServerClasspath != null) { cl = createPathClassLoader(systemServerClasspath, parsedArgs.targetSdkVersion); Thread.currentThread().setContextClassLoader(cl); } /* * Pass the remaining arguments to SystemServer. */ return ZygoteInit.zygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, cl); } zygoteInit public static final Runnable zygoteInit(int targetSdkVersion, String[] argv, ClassLoader classLoader) { Slog.d(RuntimeInit.TAG, \u0026#34;RuntimeInit: Starting application from zygote\u0026#34;); RuntimeInit.commonInit(); ZygoteInit.nativeZygoteInit(); return RuntimeInit.applicationInit(targetSdkVersion, argv, classLoader); } RuntimeInit.commonInit @UnsupportedAppUsage protected static final void commonInit() { /* * set handlers; these apply to all threads in the VM. Apps can replace * the default handler, but not the pre handler. */ LoggingHandler loggingHandler = new LoggingHandler(); RuntimeHooks.setUncaughtExceptionPreHandler(loggingHandler); Thread.setDefaultUncaughtExceptionHandler(new KillApplicationHandler(loggingHandler)); } frameworks/base/core/jni/AndroidRuntime.cpp\nnativeZygoteInit static void com_android_internal_os_ZygoteInit_nativeZygoteInit(JNIEnv* env, jobject clazz) { gCurRuntime-\u0026gt;onZygoteInit(); } frameworks/base/cmds/app_process/app_main.cpp\nvirtual void onZygoteInit() { sp\u0026lt;ProcessState\u0026gt; proc = ProcessState::self(); ALOGV(\u0026#34;App process: starting thread pool.\\n\u0026#34;); proc-\u0026gt;startThreadPool(); } RuntimeInit.applicationInit protected static Runnable applicationInit(int targetSdkVersion, String[] argv, ClassLoader classLoader) { // If the application calls System.exit(), terminate the process  // immediately without running any shutdown hooks. It is not possible to  // shutdown an Android application gracefully. Among other things, the  // Android runtime shutdown hooks close the Binder driver, which can cause  // leftover running threads to crash before the process actually exits.  nativeSetExitWithoutCleanup(true); // We want to be fairly aggressive about heap utilization, to avoid  // holding on to a lot of memory that isn\u0026#39;t needed.  VMRuntime.getRuntime().setTargetHeapUtilization(0.75f); VMRuntime.getRuntime().setTargetSdkVersion(targetSdkVersion); final Arguments args = new Arguments(argv); // The end of of the RuntimeInit event (see #zygoteInit).  Trace.traceEnd(Trace.TRACE_TAG_ACTIVITY_MANAGER); // Remaining arguments are passed to the start class\u0026#39;s static main  return findStaticMain(args.startClass, args.startArgs, classLoader); } //ActivityThread的全类名由AMS startProcess时写入到socket，zygoteServer再读取，传递过来 protected static Runnable findStaticMain(String className, String[] argv, ClassLoader classLoader) { cl = Class.forName(className, true, classLoader); Method m; m = cl.getMethod(\u0026#34;main\u0026#34;, new Class[] { String[].class }); return new MethodAndArgsCaller(m, argv); ZygoteServer runSelectLoop /** * Runs the zygote process\u0026#39;s select loop. Accepts new connections as * they happen, and reads commands from connections one spawn-request\u0026#39;s * worth at a time. */ Runnable runSelectLoop(String abiList) { ArrayList\u0026lt;FileDescriptor\u0026gt; fds = new ArrayList\u0026lt;FileDescriptor\u0026gt;(); ArrayList\u0026lt;ZygoteConnection\u0026gt; peers = new ArrayList\u0026lt;ZygoteConnection\u0026gt;(); fds.add(mServerSocket.getFileDescriptor()); peers.add(null); while (true) { StructPollfd[] pollFds = new StructPollfd[fds.size()]; for (int i = 0; i \u0026lt; pollFds.length; ++i) { pollFds[i] = new StructPollfd(); pollFds[i].fd = fds.get(i); pollFds[i].events = (short) POLLIN; } try { Os.poll(pollFds, -1); } catch (ErrnoException ex) { throw new RuntimeException(\u0026#34;poll failed\u0026#34;, ex); } for (int i = pollFds.length - 1; i \u0026gt;= 0; --i) { if ((pollFds[i].revents \u0026amp; POLLIN) == 0) { continue; } if (i == 0) { ZygoteConnection newPeer = acceptCommandPeer(abiList); peers.add(newPeer); fds.add(newPeer.getFileDesciptor()); } else { try { ZygoteConnection connection = peers.get(i); final Runnable command = connection.processOneCommand(this); } } } } ZygoteConnection.processOneCommand /** * Reads one start command from the command socket. If successful, a child is forked and a * {@code Runnable} that calls the childs main method (or equivalent) is returned in the child * process. {@code null} is always returned in the parent process (the zygote). */ Runnable processOneCommand(ZygoteServer zygoteServer) { pid = Zygote.forkAndSpecialize(parsedArgs.uid, parsedArgs.gid, parsedArgs.gids, parsedArgs.runtimeFlags, rlimits, parsedArgs.mountExternal, parsedArgs.seInfo, parsedArgs.niceName, fdsToClose, fdsToIgnore, parsedArgs.startChildZygote, parsedArgs.instructionSet, parsedArgs.appDataDir); if (pid == 0) { // in child  zygoteServer.setForkChild(); zygoteServer.closeServerSocket(); IoUtils.closeQuietly(serverPipeFd); serverPipeFd = null; return handleChildProc(parsedArgs, descriptors, childPipeFd, parsedArgs.startChildZygote); } else { // In the parent. A pid \u0026lt; 0 indicates a failure and will be handled in  // handleParentProc.  IoUtils.closeQuietly(childPipeFd); childPipeFd = null; handleParentProc(pid, descriptors, serverPipeFd); return null; } ChildProcess handleChildProc private Runnable handleChildProc(Arguments parsedArgs, FileDescriptor[] descriptors, FileDescriptor pipeFd, boolean isZygote) { if (!isZygote) { return ZygoteInit.zygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, null /* classLoader */); } else { return ZygoteInit.childZygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, null /* classLoader */); } zygoteInit zygoteinit\n参考 \u0026laquo;深入理解Android 卷1 4.4.1ActivityManagerService发送请求\u0026gt;\nZygote为什么使用Socket不用Binder fork()不支持多线程，如果使用Binder则fork()时可能会丢弃binder线程池中的任务或造成死锁，而通过socket进行单线程可以解决这个问题\n安全性?\nRuntimeInit.main //没啥机会调用到\n@UnsupportedAppUsage public static final void main(String[] argv) { enableDdms(); commonInit(); /* * Now that we\u0026#39;re running in interpreted code, call back into native code * to run the system. */ nativeFinishInit(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/zygote/zygote%E8%BF%9B%E7%A8%8B/",
	"title": "Zygote进程",
	"tags": [],
	"description": "",
	"content": "What is the Zygote copy-on-write heap?\nAll \u0026ldquo;Zygote-based\u0026rdquo; processes have memory pages that are identical among them.\nThose pages are not copied, instead everything is linked to the same memory page. This reduces the amount on RAM used by all the \u0026ldquo;Zygote-based\u0026rdquo; processes.\nIf one of those process writes new data into such a page the page is automatically copied before the write actually takes place (because otherwise the memory of all forks would be changed).\nThis mechanism is called copy-on-write.\nhttps://en.wikipedia.org/wiki/Copy-on-write\nCopy-on-write From Wikipedia, the free encyclopedia\nCopy-on-write (CoW or COW), sometimes referred to as implicit sharing[1] or shadowing,[2] is a resource-management technique used in computer programming to efficiently implement a \u0026ldquo;duplicate\u0026rdquo; or \u0026ldquo;copy\u0026rdquo; operation on modifiable resources.[3] If a resource is duplicated but not modified, it is not necessary to create a new resource; the resource can be shared between the copy and the original. Modifications must still create a copy, hence the technique: the copy operation is deferred to the first write. By sharing resources in this way, it is possible to significantly reduce the resource consumption of unmodified copies, while adding a small overhead to resource-modifying operations.\nIn virtual memory management Copy-on-write finds its main use in sharing the virtual memory of operating system processes, in the implementation of the fork system call. Typically, the process does not modify any memory and immediately executes a new process, replacing the address space entirely. Thus, it would be wasteful to copy all of the process\u0026rsquo;s memory during a fork, and instead the copy-on-write technique is used.\nCopy-on-write can be implemented efficiently using the page table by marking certain pages of memory as read-only and keeping a count of the number of references to the page. When data is written to these pages, the kernel intercepts the write attempt and allocates a new physical page, initialized with the copy-on-write data, although the allocation can be skipped if there is only one reference. The kernel then updates the page table with the new (writable) page, decrements the number of references, and performs the write. The new allocation ensures that a change in the memory of one process is not visible in another\u0026rsquo;s.\nIn multithreaded systems, COW can be implemented without the use of traditional locking and instead use compare-and-swap to increment or decrement the internal reference counter. Since the original resource will never be altered, it can safely be copied by multiple threads (after the reference count was increased) without the need of performance-expensive locking such as mutexes.\nAndroid性能优化之系统资源预加载的思考\nZygote fork内存分配\nEach app process is forked from an existing process called Zygote. The Zygote process starts when the system boots and loads common framework code and resources (such as activity themes). To start a new app process, the system forks the Zygote process then loads and runs the app\u0026rsquo;s code in the new process. This approach allows most of the RAM pages allocated for framework code and resources to be shared across all app processes.\nMost static data is mmapped into a process. This technique allows data to be shared between processes, and also allows it to be paged out when needed. Example static data include: Dalvik code (by placing it in a pre-linked .odex file for direct mmapping), app resources (by designing the resource table to be a structure that can be mmapped and by aligning the zip entries of the APK), and traditional project elements like native code in .so files.\nn many places, Android shares the same dynamic RAM across processes using explicitly allocated shared memory regions (either with ashmem or gralloc). For example, window surfaces use shared memory between the app and screen compositor, and cursor buffers use shared memory between the content provider and client.\n初识Zygote进程\n第4章 深入理解 Zygote\n4.4 Zygote的分裂 前文已经讲道，Zygote分裂出嫡长子system_server后，就通过runSelectLoopMode等待并处理来自客户的消息，那么，谁会向Zygote发送消息呢？这里，以一个Activity的启动为例，具体分析Zygote是如何分裂和繁殖的。\n4.4.1 ActivityManagerService发送请求 ActivityManagerService也是由SystemServer创建的。假设通过startActivit来启动一个新的Activity，而这个Activity附属于一个还未启动的进程，那么这个进程该如何启动呢？先来看看ActivityManagerService中的startProcessLocked函数，代码如下所示：\n4.4.2 有求必应之响应请求 前面有一节，题目叫“有求必应之等待请求”，那么这一节“有求必应之响应请求”会回到ZygoteInit。下面就看看它是如何处理请求的。\nZygote分裂子进程后，自己将在handleParentProc中做一些扫尾工作，然后继续等待请求进行下一次分裂。\n这个android.app.ActivityThread类，实际上是Android中apk程序所对应的进程，它的main函数就是apk程序的main函数。从这个类的命名（android.app）中也可以看出些端倪。\n通过这一节的分析，读者可以想到，Android系统运行的那些apk程序，其父都是zygote。这一点，可以通过adb shell登录后，用ps命令查看进程和父进程号来确认。\n4.4.3 关于 Zygote分裂的总结\n源码分析 — ActivityThread(一)之main()的调用 (Android应用进程的孵化)\n小结： Zygote响应请求的流程\n Zygote 进程调用 ZygoteInit.runSelectLoop() 开启一个轮训器； SystemServer 进程发送消息到 Zygote ，在 ZygoteConnection.readArgumentList() 中接收消息； Zygote 通过 fork 创建子进程； 子进程调用android.app.ActivityThread.main() 方法；  其实，这个原理跟 Handler 的 Looper 原理很像，Looper开启一个轮训器，不断的从 MessageQueue 中获取最新的 Message，进而处理这个消息； 而在 ZygoteInit.runSelectLoop() 也是启动一个轮训器，从指定的 Socket 中读取数据，然后进行处理；\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/ashmem/%E5%8C%BF%E5%90%8D%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98ashmem/",
	"title": "匿名共享内存Ashmem",
	"tags": [],
	"description": "",
	"content": "原理图 sequenceDiagram sharedMemory-\u0026gt;\u0026gt;+ashmem_dev: 1: ashmem_create_region ashmem_dev-\u0026gt;\u0026gt;ashmem_dev : fd = __ashmem_open() 创建ashmem_area放入file-\u0026gt;private_data ashmem_dev-\u0026gt;\u0026gt;ashmem_dev: ioctl(fd, ASHMEM_SET_NAME, buf) ashmem_dev-\u0026gt;\u0026gt;ashmem_dev: ioctl(fd, ASHMEM_SET_SIZE, size) ashmem_dev-\u0026gt;\u0026gt;-sharedMemory: fd sharedMemory-\u0026gt;\u0026gt;+Os : 2: mmap Os-\u0026gt;\u0026gt;-ashmem : ashmem_mmap ashmem-\u0026gt;\u0026gt;+shmem: vmfile = shmem_file_setup shmem-\u0026gt;\u0026gt;shmem: shmem_get_inode shmem-\u0026gt;\u0026gt;-shmem: alloc_file ashmem-\u0026gt;\u0026gt;shmem: shmem_set_file sharedMemory-\u0026gt;\u0026gt;ashmem_dev: 3: native_write ashmem_dev-\u0026gt;\u0026gt;ashmem: unpinned \u0026amp;\u0026amp; ashmem_pin_region ashmem_dev-\u0026gt;\u0026gt;shmem: env-\u0026gt;GetByteArrayRegion shmem-\u0026gt;\u0026gt;+shmem: shmem_fault shmem-\u0026gt;\u0026gt;-shmem: shmem_getpage分配真实物理页 ashmem_dev-\u0026gt;\u0026gt;ashmem: ashmem_unpin_region MemoryFile public MemoryFile(String name, int length) throws IOException { try { mSharedMemory = SharedMemory.create(name, length); mMapping = mSharedMemory.mapReadWrite(); } catch (ErrnoException ex) { ex.rethrowAsIOException(); } } SharedMemory create public static @NonNull SharedMemory create(@Nullable String name, int size) throws ErrnoException { return new SharedMemory(nCreate(name, size)); } nCreate\nSharedMemory::cons private SharedMemory(FileDescriptor fd) { mFileDescriptor = fd; mSize = nGetSize(mFileDescriptor); mMemoryRegistration = new MemoryRegistration(mSize); mCleaner = Cleaner.create(mFileDescriptor, new Closer(mFileDescriptor, mMemoryRegistration)); } mapReadWrite public @NonNull ByteBuffer mapReadWrite() throws ErrnoException { return map(OsConstants.PROT_READ | OsConstants.PROT_WRITE, 0, mSize); } map public @NonNull ByteBuffer map(int prot, int offset, int length) throws ErrnoException { checkOpen(); validateProt(prot); //mmap  long address = Os.mmap(0, length, prot, OsConstants.MAP_SHARED, mFileDescriptor, offset); boolean readOnly = (prot \u0026amp; OsConstants.PROT_WRITE) == 0; Runnable unmapper = new Unmapper(address, length, mMemoryRegistration.acquire()); return new DirectByteBuffer(length, address, mFileDescriptor, unmapper, readOnly); } Os public static long mmap(long address, long byteCount, int prot, int flags, FileDescriptor fd, long offset) throws ErrnoException { // BlockGuardOs extends ForwardingOs中被代理的Os的mmap,也就是Linux的mmap  return Libcore.os.mmap(address, byteCount, prot, flags, fd, offset); } Libcore public final class Libcore { private Libcore() { } /** * Direct access to syscalls. Code should strongly prefer using {@link #os} * unless it has a strong reason to bypass the helpful checks/guards that it * provides. */ public static Os rawOs = new Linux(); /** * Access to syscalls with helpful checks/guards. */ public static Os os = new BlockGuardOs(rawOs); } Linux mmap public native long mmap(long address, long byteCount, int prot, int flags, FileDescriptor fd, long offset) throws ErrnoException; frameworks/base/core/jni/android_os_SharedMemory.cpp\nandroid_os_SharedMemory SharedMemory_create static jobject SharedMemory_create(JNIEnv* env, jobject, jstring jname, jint size) { // Name is optional so we can\u0026#39;t use ScopedUtfChars for this as it throws NPE on null  const char* name = jname ? env-\u0026gt;GetStringUTFChars(jname, nullptr) : nullptr; int fd = ashmem_create_region(name, size); // Capture the error, if there is one, before calling ReleaseStringUTFChars  int err = fd \u0026lt; 0 ? errno : 0; if (name) { env-\u0026gt;ReleaseStringUTFChars(jname, name); } return jniCreateFileDescriptor(env, fd); } libnativehelper/JNIHelp.cpp\nJNIHelp jniCreateFileDescriptor jobject jniCreateFileDescriptor(C_JNIEnv* env, int fd) { JNIEnv* e = reinterpret_cast\u0026lt;JNIEnv*\u0026gt;(env); if (fileDescriptorInitMethod == nullptr) { InitFieldsAndMethods(e); } jobject fileDescriptor = (*env)-\u0026gt;NewObject(e, JniConstants::fileDescriptorClass, fileDescriptorInitMethod); // NOTE: NewObject ensures that an OutOfMemoryError will be seen by the Java  // caller if the alloc fails, so we just return NULL when that happens.  if (fileDescriptor != NULL) { jniSetFileDescriptorOfFD(env, fileDescriptor, fd); } return fileDescriptor; } system/core/libcutils/ashmem-dev.cpp\nashmem-dev #define ASHMEM_DEVICE \u0026#34;/dev/ashmem\u0026#34; ashmem_create_region /* * ashmem_create_region - creates a new ashmem region and returns the file * descriptor, or \u0026lt;0 on error * * `name\u0026#39; is an optional label to give the region (visible in /proc/pid/maps) * `size\u0026#39; is the size of the region, in page-aligned bytes */ int ashmem_create_region(const char *name, size_t size) { int ret, save_errno; int fd = __ashmem_open(); if (fd \u0026lt; 0) { return fd; } if (name) { char buf[ASHMEM_NAME_LEN] = {0}; strlcpy(buf, name, sizeof(buf)); ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_NAME, buf)); } ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_SIZE, size)); return fd; } __ashmem_open static int __ashmem_open() { int fd; pthread_mutex_lock(\u0026amp;__ashmem_lock); fd = __ashmem_open_locked(); pthread_mutex_unlock(\u0026amp;__ashmem_lock); return fd; } __ashmem_open_locked /* logistics of getting file descriptor for ashmem */ static int __ashmem_open_locked() { int ret; struct stat st; int fd = TEMP_FAILURE_RETRY(open(ASHMEM_DEVICE, O_RDWR | O_CLOEXEC)); if (fd \u0026lt; 0) { return fd; } ret = TEMP_FAILURE_RETRY(fstat(fd, \u0026amp;st)); __ashmem_rdev = st.st_rdev; return fd; } drivers/staging/android/ashmem.c\nashmem.c #define ASHMEM_NAME_DEF\t\u0026#34;dev/ashmem\u0026#34; ashmem_open static int ashmem_open(struct inode *inode, struct file *file) { struct ashmem_area *asma; int ret; ret = generic_file_open(inode, file); if (unlikely(ret)) return ret; asma = kmem_cache_zalloc(ashmem_area_cachep, GFP_KERNEL); if (unlikely(!asma)) return -ENOMEM; INIT_LIST_HEAD(\u0026amp;asma-\u0026gt;unpinned_list); memcpy(asma-\u0026gt;name, ASHMEM_NAME_PREFIX, ASHMEM_NAME_PREFIX_LEN); asma-\u0026gt;prot_mask = PROT_MASK; file-\u0026gt;private_data = asma; return 0; } ashmem_mmap static int ashmem_mmap(struct file *file, struct vm_area_struct *vma) { struct ashmem_area *asma = file-\u0026gt;private_data; int ret = 0; if (!asma-\u0026gt;file) { char *name = ASHMEM_NAME_DEF; struct file *vmfile; if (asma-\u0026gt;name[ASHMEM_NAME_PREFIX_LEN] != \u0026#39;\\0\u0026#39;) name = asma-\u0026gt;name; /* ... and allocate the backing shmem file */ //shmem_file_setup是原生linux的共享内存机制,匿名共享内存其实就是在Linux共享内存的基础上做了改进 \tvmfile = shmem_file_setup(name, asma-\u0026gt;size, vma-\u0026gt;vm_flags); if (IS_ERR(vmfile)) { ret = PTR_ERR(vmfile); goto out; } vmfile-\u0026gt;f_mode |= FMODE_LSEEK; asma-\u0026gt;file = vmfile; } get_file(asma-\u0026gt;file); if (vma-\u0026gt;vm_flags \u0026amp; VM_SHARED) shmem_set_file(vma, asma-\u0026gt;file); else { if (vma-\u0026gt;vm_file) fput(vma-\u0026gt;vm_file); vma-\u0026gt;vm_file = asma-\u0026gt;file; } return ret; } mm/shmem.c\nshmem.c shmem_file_setup /** * shmem_file_setup - get an unlinked file living in tmpfs * @name: name for dentry (to be seen in /proc/\u0026lt;pid\u0026gt;/maps * @size: size to be set for the file * @flags: VM_NORESERVE suppresses pre-accounting of the entire object size */ struct file *shmem_file_setup(const char *name, loff_t size, unsigned long flags) { return __shmem_file_setup(name, size, flags, 0); } __shmem_file_setup static struct file *__shmem_file_setup(const char *name, loff_t size, unsigned long flags, unsigned int i_flags) { inode = shmem_get_inode(sb, NULL, S_IFREG | S_IRWXUGO, 0, flags);//分配inode，分配成功就好比建立了文件，也许并未存在真实文件映射  res = alloc_file(\u0026amp;path, FMODE_WRITE | FMODE_READ, \u0026amp;shmem_file_operations); return res; } shmem_set_file void shmem_set_file(struct vm_area_struct *vma, struct file *file) { if (vma-\u0026gt;vm_file) fput(vma-\u0026gt;vm_file); vma-\u0026gt;vm_file = file; vma-\u0026gt;vm_ops = \u0026amp;shmem_vm_ops; } //TODO shmem_vm_ops结构体的定义是下面两者中的哪一种，通过debug确定\nstatic const struct vm_operations_struct shmem_vm_ops = { .fault\t= shmem_fault, .map_pages\t= filemap_map_pages, #ifdef CONFIG_NUMA \t.set_policy = shmem_set_policy, .get_policy = shmem_get_policy, #endif }; #define shmem_vm_ops\tgeneric_file_vm_ops  const struct vm_operations_struct generic_file_vm_ops = { .fault\t= filemap_fault, .map_pages\t= filemap_map_pages, .page_mkwrite\t= filemap_page_mkwrite, }; 参考 Android匿名共享内存（Ashmem）原理\nAndroid系统匿名共享内存（Anonymous Shared Memory）C++调用接口分析（1）\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%A4%9A%E8%BF%9B%E7%A8%8B/",
	"title": "多进程",
	"tags": [],
	"description": "",
	"content": "多进程 探索总结多进程知识\n binder    BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理      mmkv    MMKV      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%80%E5%87%BA/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8/",
	"title": "应用启动",
	"tags": [],
	"description": "",
	"content": "原理图 上述流程4——5之间还有一个过程，即当ActivityManagerService调用attachApplicationLocked时会跨进程调用thread.bindApplication通知应用进程发消息并调用handleBindApplication，内部会第一次初始化应用进程的mResources和mClassLoader给LoadedApk\nActivity.startActivity public void startActivityForResult(@RequiresPermission Intent intent, int requestCode, @Nullable Bundle options) { if (mParent == null) { options = transferSpringboardActivityOptions(options); Instrumentation.ActivityResult ar = mInstrumentation.execStartActivity( this, mMainThread.getApplicationThread(), mToken, this, intent, requestCode, options); } } Instrumentation.execStartActivity public ActivityResult execStartActivity( Context who, IBinder contextThread, IBinder token, Activity target, Intent intent, int requestCode, Bundle options) { IApplicationThread whoThread = (IApplicationThread) contextThread; int result = ActivityManager.getService() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target != null ? target.mEmbeddedID : null, requestCode, 0, null, options); ActivityManager.getService().startActivity public static IActivityManager getService() { return IActivityManagerSingleton.get(); } private static final Singleton\u0026lt;IActivityManager\u0026gt; IActivityManagerSingleton = new Singleton\u0026lt;IActivityManager\u0026gt;() { @Override protected IActivityManager create() { final IBinder b = ServiceManager.getService(Context.ACTIVITY_SERVICE); final IActivityManager am = IActivityManager.Stub.asInterface(b); return am; } }; public abstract class Singleton\u0026lt;T\u0026gt; { private T mInstance; protected abstract T create(); public final T get() { synchronized (this) { if (mInstance == null) { mInstance = create(); } return mInstance; } } } ActivityManagerService.startActivity @Override public final int startActivity(IApplicationThread caller, String callingPackage, Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, Bundle bOptions) { return startActivityAsUser(caller, callingPackage, intent, resolvedType, resultTo, resultWho, requestCode, startFlags, profilerInfo, bOptions, UserHandle.getCallingUserId()); } public final int startActivityAsUser(IApplicationThread caller, String callingPackage, Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, Bundle bOptions, int userId, boolean validateIncomingUser) { enforceNotIsolatedCaller(\u0026#34;startActivity\u0026#34;); userId = mActivityStartController.checkTargetUser(userId, validateIncomingUser, Binder.getCallingPid(), Binder.getCallingUid(), \u0026#34;startActivityAsUser\u0026#34;); // TODO: Switch to user app stacks here.  return mActivityStartController.obtainStarter(intent, \u0026#34;startActivityAsUser\u0026#34;) .setCaller(caller) .setCallingPackage(callingPackage) .setResolvedType(resolvedType) .setResultTo(resultTo) .setResultWho(resultWho) .setRequestCode(requestCode) .setStartFlags(startFlags) .setProfilerInfo(profilerInfo) .setActivityOptions(bOptions) .setMayWait(userId) .execute(); } /** * Starts an activity based on the request parameters provided earlier. * @return The starter result. */ int execute() { return startActivity(mRequest.caller, mRequest.intent, mRequest.ephemeralIntent, mRequest.resolvedType, mRequest.activityInfo,......; } private int startActivity(IApplicationThread caller, Intent intent, Intent ephemeralIntent,......) { ActivityRecord r = new ActivityRecord(mService, callerApp, callingPid, callingUid, callingPackage, intent, resolvedType, aInfo, mService.getGlobalConfiguration(), resultRecord, resultWho, requestCode, componentSpecified, voiceSession != null, mSupervisor, checkedOptions, sourceRecord); return startActivity(r, sourceRecord, voiceSession, voiceInteractor, startFlags, true /* doResume */, checkedOptions, inTask, outActivity); } private int startActivity(final ActivityRecord r, ActivityRecord sourceRecord, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, int startFlags, boolean doResume, ActivityOptions options, TaskRecord inTask, ActivityRecord[] outActivity) { int result = START_CANCELED; try { result = startActivityUnchecked(r, sourceRecord, voiceSession, voiceInteractor, startFlags, doResume, options, inTask, outActivity); private int startActivityUnchecked(final ActivityRecord r, ActivityRecord sourceRecord, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, int startFlags, boolean doResume, ActivityOptions options, TaskRecord inTask, ActivityRecord[] outActivity) { final TaskRecord taskToAffiliate = (mLaunchTaskBehind \u0026amp;\u0026amp; mSourceRecord != null) ? mSourceRecord.getTask() : null; // Should this be considered a new task?  int result = START_SUCCESS; if (mStartActivity.resultTo == null \u0026amp;\u0026amp; mInTask == null \u0026amp;\u0026amp; !mAddingToTask \u0026amp;\u0026amp; (mLaunchFlags \u0026amp; FLAG_ACTIVITY_NEW_TASK) != 0) { newTask = true; result = setTaskFromReuseOrCreateNewTask(taskToAffiliate, topStack); } else if (mSourceRecord != null) { result = setTaskFromSourceRecord(); } else if (mInTask != null) { result = setTaskFromInTask(); } else { // This not being started from an existing activity, and not part of a new task...  // just put it in the top task, though these days this case should never happen.  setTaskToCurrentTopOrCreateNewTask(); } mSupervisor.resumeFocusedStackTopActivityLocked(mTargetStack, mStartActivity,mOptions); boolean resumeFocusedStackTopActivityLocked( ActivityStack targetStack, ActivityRecord target, ActivityOptions targetOptions) { final ActivityRecord r = mFocusedStack.topRunningActivityLocked(); if (r == null || !r.isState(RESUMED)) { mFocusedStack.resumeTopActivityUncheckedLocked(null, null); } return false; } boolean resumeTopActivityUncheckedLocked(ActivityRecord prev, ActivityOptions options) { boolean result = false; try { // Protect against recursion.  mStackSupervisor.inResumeTopActivity = true; result = resumeTopActivityInnerLocked(prev, options); } finally { mStackSupervisor.inResumeTopActivity = false; } return result; } @GuardedBy(\u0026#34;mService\u0026#34;) private boolean resumeTopActivityInnerLocked(ActivityRecord prev, ActivityOptions options) { mStackSupervisor.startSpecificActivityLocked(next, true, false); } void startSpecificActivityLocked(ActivityRecord r, boolean andResume, boolean checkConfig) { // Is this activity\u0026#39;s application already running?  ProcessRecord app = mService.getProcessRecordLocked(r.processName, r.info.applicationInfo.uid, true); if (app != null \u0026amp;\u0026amp; app.thread != null) { //进程已经启动  try { if ((r.info.flags\u0026amp;ActivityInfo.FLAG_MULTIPROCESS) == 0 || !\u0026#34;android\u0026#34;.equals(r.info.packageName)) { // Don\u0026#39;t add this if it is a platform component that is marked  // to run in multiple processes, because this is actually  // part of the framework so doesn\u0026#39;t make sense to track as a  // separate apk in the process.  app.addPackage(r.info.packageName, r.info.applicationInfo.longVersionCode, mService.mProcessStats); } realStartActivityLocked(r, app, andResume, checkConfig); return; } } //启动应用进程  mService.startProcessLocked(r.processName, r.info.applicationInfo, true, 0, \u0026#34;activity\u0026#34;, r.intent.getComponent(), false, false, true); } startProcessLocked @GuardedBy(\u0026#34;this\u0026#34;) final ProcessRecord startProcessLocked(String processName, ApplicationInfo info, boolean knownToBeDead, int intentFlags, String hostingType, ComponentName hostingName, boolean allowWhileBooting, boolean isolated, boolean keepIfLarge) { return startProcessLocked(processName, info, knownToBeDead, intentFlags, hostingType, hostingName, allowWhileBooting, isolated, 0 /* isolatedUid */, keepIfLarge, null /* ABI override */, null /* entryPoint */, null /* entryPointArgs */, null /* crashHandler */); } @GuardedBy(\u0026#34;this\u0026#34;) final ProcessRecord startProcessLocked(String processName, ApplicationInfo info, boolean knownToBeDead, int intentFlags, String hostingType, ComponentName hostingName, boolean allowWhileBooting, boolean isolated, int isolatedUid, boolean keepIfLarge, String abiOverride, String entryPoint, String[] entryPointArgs, Runnable crashHandler) { ProcessRecord app; if (app == null) { app = newProcessRecordLocked(info, processName, isolated, isolatedUid); } final boolean success = startProcessLocked(app, hostingType, hostingNameStr, abiOverride); return success ? app : null; } @GuardedBy(\u0026#34;this\u0026#34;) private final boolean startProcessLocked(ProcessRecord app, String hostingType, String hostingNameStr, String abiOverride) { return startProcessLocked(app, hostingType, hostingNameStr, false /* disableHiddenApiChecks */, abiOverride); } /** * @return {@code true} if process start is successful, false otherwise. */ @GuardedBy(\u0026#34;this\u0026#34;) private final boolean startProcessLocked(ProcessRecord app, String hostingType, String hostingNameStr, boolean disableHiddenApiChecks, String abiOverride) { ...... return startProcessLocked(hostingType, hostingNameStr, entryPoint, app, uid, gids, runtimeFlags, mountExternal, seInfo, requiredAbi, instructionSet, invokeWith, startTime); } @GuardedBy(\u0026#34;this\u0026#34;) private boolean startProcessLocked(String hostingType, String hostingNameStr, String entryPoint, ProcessRecord app, int uid, int[] gids, int runtimeFlags, int mountExternal, String seInfo, String requiredAbi, String instructionSet, String invokeWith, long startTime) { final ProcessStartResult startResult = startProcess(hostingType, entryPoint, app, uid, gids, runtimeFlags, mountExternal, seInfo, requiredAbi, instructionSet, invokeWith, startTime); } private ProcessStartResult startProcess(String hostingType, String entryPoint, ProcessRecord app, int uid, int[] gids, int runtimeFlags, int mountExternal, String seInfo, String requiredAbi, String instructionSet, String invokeWith, long startTime) { startResult = Process.start(entryPoint, app.processName, uid, uid, gids, runtimeFlags, mountExternal, app.info.targetSdkVersion, seInfo, requiredAbi, instructionSet, app.info.dataDir, invokeWith, new String[] {PROC_START_SEQ_IDENT + app.startSeq}); } public static final ZygoteProcess zygoteProcess = new ZygoteProcess(ZYGOTE_SOCKET, SECONDARY_ZYGOTE_SOCKET); public static final ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { return zygoteProcess.start(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, zygoteArgs); } frameworks/base/core/java/android/os/ZygoteProcess.java\nZygoteProcess.start /** * The name of the socket used to communicate with the primary zygote. */ private final LocalSocketAddress mSocket; /** * The name of the secondary (alternate ABI) zygote socket. */ private final LocalSocketAddress mSecondarySocket; public final Process.ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { return startViaZygote(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, false /* startChildZygote */, zygoteArgs); private Process.ProcessStartResult startViaZygote(final String processClass, final String niceName, final int uid, final int gid, final int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, boolean startChildZygote, String[] extraArgs) throws ZygoteStartFailedEx { synchronized(mLock) { return zygoteSendArgsAndGetResult(openZygoteSocketIfNeeded(abi), argsForZygote); } } openZygoteSocketIfNeeded /** * Tries to open socket to Zygote process if not already open. If * already open, does nothing. May block and retry. Requires that mLock be held. */ @GuardedBy(\u0026#34;mLock\u0026#34;) private ZygoteState openZygoteSocketIfNeeded(String abi) throws ZygoteStartFailedEx { if (primaryZygoteState == null || primaryZygoteState.isClosed()) { primaryZygoteState = ZygoteState.connect(mSocket); } if (primaryZygoteState.matches(abi)) { return primaryZygoteState; } // The primary zygote didn\u0026#39;t match. Try the secondary.  if (secondaryZygoteState == null || secondaryZygoteState.isClosed()) { secondaryZygoteState = ZygoteState.connect(mSecondarySocket); } if (secondaryZygoteState.matches(abi)) { return secondaryZygoteState; } public static ZygoteState connect(LocalSocketAddress address) throws IOException { DataInputStream zygoteInputStream = null; BufferedWriter zygoteWriter = null; final LocalSocket zygoteSocket = new LocalSocket(); zygoteSocket.connect(address); //inputStream，读取Zygote发来的数据  zygoteInputStream = new DataInputStream(zygoteSocket.getInputStream()); //outputStream,写入socket数据  zygoteWriter = new BufferedWriter(new OutputStreamWriter(zygoteSocket.getOutputStream()), 256); String abiListString = getAbiList(zygoteWriter, zygoteInputStream); return new ZygoteState(zygoteSocket, zygoteInputStream, zygoteWriter, Arrays.asList(abiListString.split(\u0026#34;,\u0026#34;))); } /** * Queries the zygote for the list of ABIS it supports. */ @GuardedBy(\u0026#34;mLock\u0026#34;) private static String getAbiList(BufferedWriter writer, DataInputStream inputStream) throws IOException { // Each query starts with the argument count (1 in this case)  writer.write(\u0026#34;1\u0026#34;); // ... followed by a new-line.  writer.newLine(); // ... followed by our only argument.  writer.write(\u0026#34;--query-abi-list\u0026#34;); writer.newLine(); writer.flush(); // The response is a length prefixed stream of ASCII bytes.  int numBytes = inputStream.readInt(); byte[] bytes = new byte[numBytes]; inputStream.readFully(bytes); return new String(bytes, StandardCharsets.US_ASCII); } zygoteSendArgsAndGetResult /** * Sends an argument list to the zygote process, which starts a new child * and returns the child\u0026#39;s pid. Please note: the present implementation * replaces newlines in the argument list with spaces. * * @throws ZygoteStartFailedEx if process start failed for any reason */ @GuardedBy(\u0026#34;mLock\u0026#34;) private static Process.ProcessStartResult zygoteSendArgsAndGetResult( ZygoteState zygoteState, ArrayList\u0026lt;String\u0026gt; args) throws ZygoteStartFailedEx { /** * See com.android.internal.os.SystemZygoteInit.readArgumentList() * Presently the wire format to the zygote process is: * a) a count of arguments (argc, in essence) * b) a number of newline-separated argument strings equal to count * * After the zygote process reads these it will write the pid of * the child or -1 on failure, followed by boolean to * indicate whether a wrapper process was used. */ final BufferedWriter writer = zygoteState.writer; final DataInputStream inputStream = zygoteState.inputStream; writer.write(Integer.toString(args.size())); writer.newLine(); for (int i = 0; i \u0026lt; sz; i++) { String arg = args.get(i); writer.write(arg); writer.newLine(); } writer.flush(); // Should there be a timeout on this?  Process.ProcessStartResult result = new Process.ProcessStartResult(); // Always read the entire result from the input stream to avoid leaving  // bytes in the stream for future process starts to accidentally stumble  // upon.  result.pid = inputStream.readInt(); result.usingWrapper = inputStream.readBoolean(); return result; Zygote启动AppProcess 参考\nActivityThread.main final ApplicationThread mAppThread = new ApplicationThread(); Looper.prepareMainLooper(); public static void main(String[] args) { Looper.prepareMainLooper(); } IActivityManager.attachApplication ActivityThread thread = new ActivityThread(); thread.attach(false, startSeq); private void attach(boolean system, long startSeq) { RuntimeInit.setApplicationObject(mAppThread.asBinder()); final IActivityManager mgr = ActivityManager.getService(); try { mgr.attachApplication(mAppThread, startSeq); } catch (RemoteException ex) { throw ex.rethrowFromSystemServer(); } } Looper.loop() Looper.loop(); ActivityManagerService.attachApplication @Override public final void attachApplication(IApplicationThread thread, long startSeq) { synchronized (this) { int callingPid = Binder.getCallingPid(); final int callingUid = Binder.getCallingUid(); final long origId = Binder.clearCallingIdentity(); attachApplicationLocked(thread, callingPid, callingUid, startSeq); Binder.restoreCallingIdentity(origId); } } @GuardedBy(\u0026#34;this\u0026#34;) private final boolean attachApplicationLocked(IApplicationThread thread, int pid, int callingUid, long startSeq) { AppDeathRecipient adr = new AppDeathRecipient(app, pid, thread); thread.asBinder().linkToDeath(adr, 0); app.deathRecipient = adr; thread.bindApplication(....) StackSupervisor.attachApplicationLocked(app)//realStartActivityLocked  } linkToDeath配置AppDeathRecipient监听appDeath private final class AppDeathRecipient implements IBinder.DeathRecipient { final ProcessRecord mApp; final int mPid; final IApplicationThread mAppThread; @Override public void binderDied() { synchronized(ActivityManagerService.this) { appDiedLocked(mApp, mPid, mAppThread, true); } } } thread.bindApplication class ApplicationThread { public final void bindApplication(String processName, ApplicationInfo appInfo, List\u0026lt;ProviderInfo\u0026gt; providers, ComponentName instrumentationName, ProfilerInfo profilerInfo, Bundle instrumentationArgs, IInstrumentationWatcher instrumentationWatcher, IUiAutomationConnection instrumentationUiConnection, int debugMode, boolean enableBinderTracking, boolean trackAllocation, boolean isRestrictedBackupMode, boolean persistent, Configuration config, CompatibilityInfo compatInfo, Map services, Bundle coreSettings, String buildSerial, boolean autofillCompatibilityEnabled) { sendMessage(H.BIND_APPLICATION, data); } public void handleMessage(Message msg) { switch (msg.what) { case BIND_APPLICATION: AppBindData data = (AppBindData)msg.obj; handleBindApplication(data); break; private void handleBindApplication(AppBindData data) { data.info = getPackageInfoNoCheck(data.appInfo, data.compatInfo); app = data.info.makeApplication(data.restrictedBackupMode, null); installContentProviders(app, data.providers); mInstrumentation.callApplicationOnCreate(app); } getPackageInfo初始化LoadedApk @Override public final LoadedApk getPackageInfoNoCheck(ApplicationInfo ai, CompatibilityInfo compatInfo) { return getPackageInfo(ai, compatInfo, null, false, true, false); } private LoadedApk getPackageInfo(ApplicationInfo aInfo, CompatibilityInfo compatInfo, ClassLoader baseLoader, boolean securityViolation, boolean includeCode, boolean registerPackage) { packageInfo = new LoadedApk(this, aInfo, compatInfo, baseLoader, securityViolation, includeCode \u0026amp;\u0026amp; (aInfo.flags\u0026amp;ApplicationInfo.FLAG_HAS_CODE) != 0, registerPackage); } LoadedApk.makeApplication public Application makeApplication(boolean forceDefaultAppClass, Instrumentation instrumentation) { java.lang.ClassLoader cl = getClassLoader(); ContextImpl appContext = ContextImpl.createAppContext(mActivityThread, this); app = mActivityThread.mInstrumentation.newApplication(cl, appClass, appContext); appContext.setOuterContext(app); } public ClassLoader getClassLoader() { synchronized (this) { if (mClassLoader == null) { createOrUpdateClassLoaderLocked(null /*addedPaths*/); } return mClassLoader; } } public Application newApplication(ClassLoader cl, String className, Context context) throws InstantiationException, IllegalAccessException, ClassNotFoundException { Application app = getFactory(context.getPackageName()) .instantiateApplication(cl, className); app.attach(context); return app; } private AppComponentFactory getFactory(String pkg) { if (pkg == null) { Log.e(TAG, \u0026#34;No pkg specified, disabling AppComponentFactory\u0026#34;); return AppComponentFactory.DEFAULT; } if (mThread == null) { Log.e(TAG, \u0026#34;Uninitialized ActivityThread, likely app-created Instrumentation,\u0026#34; + \u0026#34; disabling AppComponentFactory\u0026#34;, new Throwable()); return AppComponentFactory.DEFAULT; } LoadedApk apk = mThread.peekPackageInfo(pkg, true); // This is in the case of starting up \u0026#34;android\u0026#34;.  if (apk == null) apk = mThread.getSystemContext().mPackageInfo; return apk.getAppFactory(); } AppComponentFactory.instantiateApplication public @NonNull Application instantiateApplication(@NonNull ClassLoader cl, @NonNull String className) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (Application) cl.loadClass(className).newInstance(); } Application.attach /* package */ final void attach(Context context) { attachBaseContext(context); mLoadedApk = ContextImpl.getImpl(context).mPackageInfo; } installContentProviders mInstrumentation.callApplicationOnCreate public void callApplicationOnCreate(Application app) { app.onCreate(); } realStartActivityLocked boolean attachApplicationLocked(ProcessRecord app) throws RemoteException { realStartActivityLocked(activity, app, top == activity /* andResume */, true /* checkConfig */)) } Create activity launch transaction final boolean realStartActivityLocked(ActivityRecord r, ProcessRecord app, boolean andResume, boolean checkConfig) throws RemoteException { // Create activity launch transaction.  final ClientTransaction clientTransaction = ClientTransaction.obtain(app.thread, r.appToken); clientTransaction.addCallback(LaunchActivityItem.obtain(new Intent(r.intent), System.identityHashCode(r), r.info, // TODO: Have this take the merged configuration instead of separate global  // and override configs.  mergedConfiguration.getGlobalConfiguration(), mergedConfiguration.getOverrideConfiguration(), r.compat, r.launchedFromPackage, task.voiceInteractor, app.repProcState, r.icicle, r.persistentState, results, newIntents, mService.isNextTransitionForward(), profilerInfo)); // Set desired final state.  final ActivityLifecycleItem lifecycleItem; if (andResume) { lifecycleItem = ResumeActivityItem.obtain(mService.isNextTransitionForward()); } else { lifecycleItem = PauseActivityItem.obtain(); } clientTransaction.setLifecycleStateRequest(lifecycleItem); // Schedule transaction.  mService.getLifecycleManager().scheduleTransaction(clientTransaction); } /** * Schedule a transaction, which may consist of multiple callbacks and a lifecycle request. * @param transaction A sequence of client transaction items. * @throws RemoteException * * @see ClientTransaction */ void scheduleTransaction(ClientTransaction transaction) throws RemoteException { final IApplicationThread client = transaction.getClient(); transaction.schedule(); if (!(client instanceof Binder)) { // If client is not an instance of Binder - it\u0026#39;s a remote call and at this point it is  // safe to recycle the object. All objects used for local calls will be recycled after  // the transaction is executed on client in ActivityThread.  transaction.recycle(); } } ClientTransaction.java\n/** Get the target client of the transaction. */ public IApplicationThread getClient() { return mClient; } /** * Schedule the transaction after it was initialized. It will be send to client and all its * individual parts will be applied in the following sequence: * 1. The client calls {@link #preExecute(ClientTransactionHandler)}, which triggers all work * that needs to be done before actually scheduling the transaction for callbacks and * lifecycle state request. * 2. The transaction message is scheduled. * 3. The client calls {@link TransactionExecutor#execute(ClientTransaction)}, which executes * all callbacks and necessary lifecycle transitions. */ public void schedule() throws RemoteException { mClient.scheduleTransaction(this); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%80%E5%87%BA/",
	"title": "应用启动退出",
	"tags": [],
	"description": "",
	"content": "应用启动退出 探索总结应用启动退出知识\n 应用启动     "
},
{
	"uri": "https://huanle19891345.github.io/en/",
	"title": "技术探索总结",
	"tags": [],
	"description": "",
	"content": "技术探索总结 探索客户端技术背后的原理细节\nAOSP研究方式  android    google    supportToAndroidx      系统机制原理    ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Looper     ThreadLocal      input    touchEventNative      kernel    kernel      sharedpreferences    SharedPreferences      zygote    SystemServerSource     ZygoteSource     Zygote进程      多进程    binder    BinderClient   BinderDeath   BinderKernel   BinderServer   BinderServiceManager   Binder原理    mmkv    MMKV     应用启动退出    应用启动      系统绘制    Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制        跨平台    flutter    通信    Flutter消息机制        "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E7%BB%98%E5%88%B6/",
	"title": "硬件加速绘制",
	"tags": [],
	"description": "",
	"content": "硬件加速绘制 Android硬件加速过程分析\n理解Android硬件加速原理的小白文\nAndroid硬件加速原理与实现\n总结：\n CPU更擅长复杂逻辑控制，而GPU得益于大量ALU和并行结构设计，更擅长数学运算。 页面由各种基础元素（DisplayList）构成，渲染时需要进行大量浮点运算。 硬件加速条件下，CPU用于控制复杂绘制逻辑，构建或更新DisplayList；GPU用于完成图形计算，渲染DisplayList。 硬件加速条件下，刷新界面尤其是播放动画时，CPU只重建或更新必要的DisplayList，进一步提高渲染效率。   软硬件加速的区别 软硬件加速的区别主要是==图形的绘制究竟是GPU来处理还是CPU，如果是GPU==，就认为是硬件加速绘制，反之，软件绘制。\n不仅仅限定在绘制方面，绘制之前，在如何构建绘制区域上，硬件加速也做出了很大优化，因此硬件加速特性可以从下面两部分来分析：\n ==前期策略：如何构建需要绘制的区域== ==后期绘制：单独渲染线程，依赖GPU进行绘制==  无论是软件绘制还是硬件加速，==绘制内存的分配都是类似的，都是需要请求SurfaceFlinger服务分配一块内存==，只不过硬件加速有可能从FrameBuffer硬件缓冲区直接分配内存（SurfaceFlinger一直这么干的），==两者的绘制都是在APP端，绘制完成之后同样需要通知SurfaceFlinger进行合成，在这个流程上没有任何区别==，真正的区别在于在APP端如何完成UI数据绘制\n软件绘制同硬件加速的区别主要是在绘制上，内存分配、图层合成等整体流程是一样的，只不过硬件加速相比软件绘制算法更加合理，同时采用单独的渲染线程，减轻了主线程的负担。\n软件绘制跟硬件加速的分歧点 ViewRootImpl.java\nprivate void draw(boolean fullRedrawNeeded) { ... if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { //关键点1 是否开启硬件加速  if (mAttachInfo.mHardwareRenderer != null \u0026amp;\u0026amp; mAttachInfo.mHardwareRenderer.isEnabled()) { ... dirty.setEmpty(); mBlockResizeBuffer = false; //关键点2 硬件加速绘制  mAttachInfo.mHardwareRenderer.draw(mView, mAttachInfo, this); } else { ... //关键点3 软件绘制  if (!drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty)) { return; } ... 其实到这里软件绘制跟硬件加速的分歧点已经找到了，就是ViewRootImpl在draw的时候，如果需要硬件加速就利用 HardwareRenderer进行draw，否则走软件绘制流程，drawSoftware其实很简单，利用Surface.lockCanvas，向SurfaceFlinger申请一块匿名共享内存内存分配，同时获取一个普通的SkiaCanvas，用于调用Skia库，进行图形绘制，\nprivate boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty) { final Canvas canvas; try { //关键点1  canvas = mSurface.lockCanvas(dirty); .. //关键点2 绘制  mView.draw(canvas); .. //关键点3 通知SurfaceFlinger进行图层合成  surface.unlockCanvasAndPost(canvas); } ... return true; } 默认情况下Skia的绘制没有采用GPU渲染的方式（虽然Skia也能用GPU渲染），也就说默认drawSoftware工作完全由CPU来完成，不会牵扯到GPU的操作，但是8.0之后，Google逐渐加重了Skia，开始让Skia接手OpenGL，间接统一调用，将来还可能是Skia同Vulkan的结合，不过这里不是重点。重点看下HardwareRenderer所进行的硬件加速绘制。\nHardwareRenderer硬件加速绘制模型 开头说过，硬件加速绘制包括两个阶段：==构建阶段+绘制阶段==，所谓构建就是递归遍历所有视图，将需要的操作缓存下来，之后再交给单独的Render线程利用OpenGL渲染。在Android硬件加速框架中，==View视图被抽象成RenderNode节点==，==View中的绘制都会被抽象成一个个DrawOp（DisplayListOp）==，比如View中drawLine，构建中就会被抽象成一个DrawLintOp，drawBitmap操作会被抽象成DrawBitmapOp，==每个子View的绘制被抽象成DrawRenderNodeOp，每个DrawOp有对应的OpenGL绘制命令，同时内部也握着绘图所需要的数据==。如下所示：\n如此以来，==每个View不仅仅握有自己DrawOp List，同时还拿着子View的绘制入口，如此递归==，便能够统计到所有的绘制Op，很多分析都称==为Display List==，源码中也是这么来命名类的，不过这里其实更像是一个树，而不仅仅是List，示意如下：\n构建完成后，就可以==将这个绘图Op树交给Render线程进行绘制==，这里是同软件绘制很不同的地方，软件绘制时，View一般都在主线程中完成绘制，而硬件加速，除非特殊要求，一般都是在单独线程中完成绘制，如此以来就分担了主线程很多压力，提高了UI线程的响应速度。\nAndroid硬件加速（二）-RenderThread与OpenGL GPU渲染\n利用HardwareRenderer构建DrawOp集 HardwareRenderer是整个硬件加速绘制的入口，实现是一个ThreadedRenderer对象，从名字能看出，ThreadedRenderer应该跟一个Render线程息息相关，不过ThreadedRenderer是在UI线程中创建的，那么与UI线程也必定相关，其主要作用：\n ==在UI线程中完成DrawOp集构建== ==负责跟渲染线程通信==  可见ThreadedRenderer的作用是很重要的，简单看一下实现：\nThreadedRenderer(Context context, boolean translucent) { ... //新建native node  long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); //新建NativeProxy  mNativeProxy = nCreateProxy(translucent, rootNodePtr); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } 从上面代码看出，ThreadedRenderer中有一个==RootNode==用来标识整个DrawOp树的根节点，有个这个根节点就可以访问所有的绘制Op，同时还有个==RenderProxy对象，这个对象就是用来跟渲染线程进行通信的句柄==，看一下其构造函数：\nRenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()) , mContext(nullptr) { SETUP_TASK(createContext); args-\u0026gt;translucent = translucent; args-\u0026gt;rootRenderNode = rootRenderNode; args-\u0026gt;thread = \u0026amp;mRenderThread; args-\u0026gt;contextFactory = contextFactory; mContext = (CanvasContext*) postAndWait(task); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext); } 从RenderThread::getInstance()可以看出，==RenderThread是一个单例线程==，也就是说，每个进程最多只有一个硬件渲染线程，这样就不会存在多线程并发访问冲突问题。下面就接着看ThreadedRenderer的draw函数，如何构建渲染Op树：\nThreadedRenderer::draw @Override void draw(View view, AttachInfo attachInfo, HardwareDrawCallbacks callbacks) { attachInfo.mIgnoreDirtyState = true; final Choreographer choreographer = attachInfo.mViewRootImpl.mChoreographer; choreographer.mFrameInfo.markDrawStart(); //关键点1：构建View的DrawOp树  updateRootDisplayList(view, callbacks); //关键点2：通知RenderThread线程绘制  int syncResult = nSyncAndDrawFrame(mNativeProxy, frameInfo, frameInfo.length); ... } 关键点1 updateRootDisplayList，构建RootDisplayList，其实就是构建View的DrawOp树，==updateRootDisplayList会进而调用根View的updateDisplayListIfDirty，让其递归子View的updateDisplayListIfDirty，从而完成DrawOp树的创==建，简述一下流程：\nupdateRootDisplayList private void updateRootDisplayList(View view, HardwareDrawCallbacks callbacks) { updateViewTreeDisplayList(view); if (mRootNodeNeedsUpdate || !mRootNode.isValid()) { //获取DisplayListCanvas, 利用View的RenderNode获取一个DisplayListCanvas  DisplayListCanvas canvas = mRootNode.start(mSurfaceWidth, mSurfaceHeight); try { //利用canvas缓存Op, 利用DisplayListCanvas构建并缓存所有的DrawOp  final int saveCount = canvas.save(); canvas.translate(mInsetLeft, mInsetTop); callbacks.onHardwarePreDraw(canvas); canvas.insertReorderBarrier(); canvas.drawRenderNode(view.updateDisplayListIfDirty()); canvas.insertInorderBarrier(); callbacks.onHardwarePostDraw(canvas); canvas.restoreToCount(saveCount); mRootNodeNeedsUpdate = false; } finally { //将所有Op填充到RootRenderNode, 将DisplayListCanvas缓存的DrawOp填充到RenderNode  mRootNode.end(canvas); } } } View.java递归构建DrawOp @NonNull public RenderNode updateDisplayListIfDirty() { final RenderNode renderNode = mRenderNode; ... // start 获取一个 DisplayListCanvas 用于绘制 硬件加速  final DisplayListCanvas canvas = renderNode.start(width, height); try { // 是否是textureView  final HardwareLayer layer = getHardwareLayer(); if (layer != null \u0026amp;\u0026amp; layer.isValid()) { canvas.drawHardwareLayer(layer, 0, 0, mLayerPaint); } else if (layerType == LAYER_TYPE_SOFTWARE) { // 是否强制软件绘制  buildDrawingCache(true); Bitmap cache = getDrawingCache(true); if (cache != null) { canvas.drawBitmap(cache, 0, 0, mLayerPaint); } } else { // 如果仅仅是ViewGroup，并且自身不用绘制，直接递归子View  if ((mPrivateFlags \u0026amp; PFLAG_SKIP_DRAW) == PFLAG_SKIP_DRAW) { dispatchDraw(canvas); } else { //调用自己draw，如果是ViewGroup会递归子View  draw(canvas); } } } finally { //缓存构建Op  renderNode.end(canvas); setDisplayListProperties(renderNode); } } return renderNode; } ViewGroup::dispatchDraw @Override protected void dispatchDraw(Canvas canvas) { boolean usingRenderNodeProperties = canvas.isRecordingFor(mRenderNode); final int childrenCount = mChildrenCount; final View[] children = mChildren; int flags = mGroupFlags; for (int i = 0; i \u0026lt; childrenCount; i++) { final int childIndex = getAndVerifyPreorderedIndex(childrenCount, i, customOrder); final View child = getAndVerifyPreorderedView(preorderedList, children, childIndex); if ((child.mViewFlags \u0026amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) { more |= drawChild(canvas, child, drawingTime); } } } protected boolean drawChild(Canvas canvas, View child, long drawingTime) { return child.draw(canvas, this, drawingTime); } View::draw boolean draw(Canvas canvas, ViewGroup parent, long drawingTime) { boolean drawingWithRenderNode = mAttachInfo != null \u0026amp;\u0026amp; mAttachInfo.mHardwareAccelerated \u0026amp;\u0026amp; hardwareAcceleratedCanvas; if (drawingWithRenderNode) { renderNode = updateDisplayListIfDirty(); } } drawLine 假如在View onDraw中，有个drawLine，这里就会调用DisplayListCanvas的drawLine函数，DisplayListCanvas及RenderNode类图大概如下 DisplayListCanvas的drawLine函数最终会进入DisplayListCanvas.cpp的drawLine，\nvoid DisplayListCanvas::drawLines(const float* points, int count, const SkPaint\u0026amp; paint) { points = refBuffer\u0026lt;float\u0026gt;(points, count); addDrawOp(new (alloc()) DrawLinesOp(points, count, refPaint(\u0026amp;paint))); } 可以看到，这里构建了一个DrawLinesOp，并添加到DisplayListCanvas的缓存列表中去，如此递归便可以完成DrawOp树的构建，在构建后利用RenderNode的end函数，将DisplayListCanvas中的数据缓存到RenderNode中去：\npublic void end(DisplayListCanvas canvas) { canvas.onPostDraw(); long renderNodeData = canvas.finishRecording(); //将DrawOp缓存到RenderNode中去  nSetDisplayListData(mNativeRenderNode, renderNodeData); // canvas 回收掉]  canvas.recycle(); mValid = true; } RenderThread渲染UI到Graphic Buffer DrawOp树构建完毕后，UI线程利用RenderProxy向RenderThread线程发送一个DrawFrameTask任务请求，RenderThread被唤醒，开始渲染，大致流程如下：\n 首先进行DrawOp的==合并== 接着绘制特殊的Layer 最后==绘制其余所有的DrawOpList== 调用swapBuffers将前面已经绘制好的图形缓冲区提交给Surface Flinger合成和显示。  syncAndDrawFrame static int android_view_ThreadedRenderer_syncAndDrawFrame(JNIEnv* env, jobject clazz, jlong proxyPtr, jlongArray frameInfo, jint frameInfoSize) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); env-\u0026gt;GetLongArrayRegion(frameInfo, 0, frameInfoSize, proxy-\u0026gt;frameInfo()); return proxy-\u0026gt;syncAndDrawFrame(); } RenderProxy::syncAndDrawFrame int RenderProxy::syncAndDrawFrame() { return mDrawFrameTask.drawFrame(); } DrawFrameTask::drawFrame int DrawFrameTask::drawFrame() { postAndWait(); return mSyncResult; } DrawFrameTask::postAndWait void DrawFrameTask::postAndWait() { AutoMutex _lock(mLock); mRenderThread-\u0026gt;queue().post([this]() { run(); }); mSignal.wait(mLock); } DrawFrameTask::run void DrawFrameTask::run() { canUnblockUiThread = syncFrameState(info); // Grab a copy of everything we need  CanvasContext* context = mContext; // From this point on anything in \u0026#34;this\u0026#34; is *UNSAFE TO ACCESS*  if (canUnblockUiThread) { unblockUiThread(); } if (CC_LIKELY(canDrawThisFrame)) { context-\u0026gt;draw(); } else { // wait on fences so tasks don\u0026#39;t overlap next frame  context-\u0026gt;waitOnFences(); } if (!canUnblockUiThread) { unblockUiThread(); } } CanvasContext::draw void CanvasContext::draw() { mCurrentFrameInfo-\u0026gt;markIssueDrawCommandsStart(); Frame frame = mRenderPipeline-\u0026gt;getFrame(); SkRect windowDirty = computeDirtyRect(frame, \u0026amp;dirty); bool drew = mRenderPipeline-\u0026gt;draw(frame, windowDirty, dirty, mLightGeometry, \u0026amp;mLayerUpdateQueue, mContentDrawBounds, mOpaque, mWideColorGamut, mLightInfo, mRenderNodes, \u0026amp;(profiler())); bool didSwap = mRenderPipeline-\u0026gt;swapBuffers(frame, drew, windowDirty, mCurrentFrameInfo, \u0026amp;requireSwap); } 绘制内存的由来 DrawOp树的构建只是在普通的==用户内存==中，而部分数据对于SurfaceFlinger都是不可见的，之后又绘制到==共享内存==中的数据才会被SurfaceFlinger合成，之前分析过软件绘制的共享内存是来自匿名共享内存，那么硬件加速的共享内存来自何处呢？到这里可能要倒回去看看ViewRootImpl\nprivate void performTraversals() { ... if (mAttachInfo.mHardwareRenderer != null) { try { hwInitialized = mAttachInfo.mHardwareRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { mSurface.allocateBuffers(); } } catch (OutOfResourcesException e) { handleOutOfResourcesException(e); return; } } .... /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } 对于硬件加速的场景，请求SurfaceFlinger内存分配的时机会稍微提前，而不是像软件绘制，由Surface的lockCanvas发起，主要目的是：预先分配slot位置，避免在渲染的时候再申请，一是避免分配失败，浪费了CPU之前的准备工作，二是也可以将渲染线程个工作简化，减少延时。不过，还是会存在另一个问题，一个APP进程，==同一时刻会有多个Surface绘图界面，但是渲染线程只有一个，那么究竟渲染那个呢==？这个时候就需要将Surface与渲染线程（上下文）绑定。\nSurface与渲染线程（上下文）绑定 static jboolean android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;ANativeWindow\u0026gt; window = android_view_Surface_getNativeWindow(env, jsurface); return proxy-\u0026gt;initialize(window); } 首先通过android_view_Surface_getNativeWindowSurface获取Surface，在Native层,Surface对应一个ANativeWindow,接着，通过RenderProxy类的成员函数initialize将前面获得的ANativeWindow绑定到RenderThread\nbool RenderProxy::initialize(const sp\u0026lt;ANativeWindow\u0026gt;\u0026amp; window) { SETUP_TASK(initialize); args-\u0026gt;context = mContext; args-\u0026gt;window = window.get(); return (bool) postAndWait(task); } 仍旧是向渲染线程发送消息，让其绑定当前Window，其实就是调用CanvasContext的initialize函数，让绘图上下文绑定绘图内存：\nbool CanvasContext::initialize(ANativeWindow* window) { setSurface(window); if (mCanvas) return false; mCanvas = new OpenGLRenderer(mRenderThread.renderState()); mCanvas-\u0026gt;initProperties(); return true; } CanvasContext通过setSurface将当前要渲染的Surface绑定到到RenderThread中，大概流程是通过eglApi获得一个EGLSurface，EGLSurface封装了一个绘图表面，进而，==通过eglApi将EGLSurface设定为当前渲染窗口==，并将绘图内存等信息进行同步，==之后通过RenderThread绘制的时候才能知道是在哪个窗口上进行绘制==。之后，再创建一个OpenGLRenderer对象，后面执行OpenGL相关操作的时候，其实就是通过OpenGLRenderer来进行的。\n合并操作和绘制 真正调用OpenGL绘制之前还有一些合并操作，这是Android硬件加速做的优化，回过头继续走draw流程，其实就是走OpenGLRenderer的drawRenderNode进行递归处理：\nvoid OpenGLRenderer::drawRenderNode(RenderNode* renderNode, Rect\u0026amp; dirty, int32_t replayFlags) { ... \u0026lt;!--构建deferredList--\u0026gt; DeferredDisplayList deferredList(mState.currentClipRect(), avoidOverdraw); DeferStateStruct deferStruct(deferredList, *this, replayFlags); \u0026lt;!--合并及分组--\u0026gt; renderNode-\u0026gt;defer(deferStruct, 0); \u0026lt;!--绘制layer--\u0026gt; flushLayers(); startFrame(); \u0026lt;!--绘制 DrawOp树--\u0026gt; deferredList.flush(*this, dirty); ... } 先看下renderNode-\u0026gt;defer(deferStruct, 0)，合并操作，DrawOp树并不是直接被绘制的，而是首先通过DeferredDisplayList进行一个合并优化，这个是Android硬件加速中采用的一种优化手段，不仅可以减少不必要的绘制，还可以将相似的绘制集中处理，提高绘制速度。\nvoid RenderNode::defer(DeferStateStruct\u0026amp; deferStruct, const int level) { DeferOperationHandler handler(deferStruct, level); issueOperations\u0026lt;DeferOperationHandler\u0026gt;(deferStruct.mRenderer, handler); } RenderNode::defer其实内含递归操作，比如，如果当前RenderNode代表DecorView，它就会递归所有的子View进行合并优化处理\n合并及优化的流程及算法，其实主要就是根据DrawOp树构建DeferedDisplayList。在合并过程中，DrawOp被分为两种：需要合的与不需要合并的，并分别缓存在不同的列表中，\n 无法合并的按照类型分别存放在Batch*mBatchLookup[kOpBatch_Count]中 可以合并的按照类型及MergeID存储到TinyHashMap\u0026lt;mergeid_t, DrawBatch*\u0026gt;mMergingBatches[kOpBatch_Count]中  合并之后，DeferredDisplayList Vector\u0026lt;Batch * \u0026gt; mBatches 包含全部整合后的绘制命令，之后渲染即可，需要注意的是这里的合并并不是多个变一个，只是做了一个集合，主要是方便使用各资源纹理等，比如绘制文字的时候，需要根据文字的纹理进行渲染，而这个时候就需要查询文字的纹理坐标系，合并到一起方便统一处理，一次渲染，减少资源加载的浪费。\n它的主要特点是==在另一个Render线程使用OpenGL进行绘制==，这个是它最重要的特点。而mBatches中所有的DrawOp都会通过OpenGL被绘制到GraphicBuffer中，最后通过swapBuffers通知SurfaceFlinger合成。\n "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/",
	"title": "系统机制原理",
	"tags": [],
	"description": "",
	"content": "系统机制原理 探索总结系统机制原理知识\n ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Looper     ThreadLocal      input    touchEventNative      kernel    kernel      sharedpreferences    SharedPreferences      zygote    SystemServerSource     ZygoteSource     Zygote进程      多进程    binder    BinderClient     BinderDeath     BinderKernel     BinderServer     BinderServiceManager     Binder原理      mmkv    MMKV       应用启动退出    应用启动      系统绘制    Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/",
	"title": "系统绘制",
	"tags": [],
	"description": "",
	"content": "系统绘制 探索总结系统绘制知识\n Graphics     Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E7%BB%98%E5%88%B6%E5%8E%9F%E7%90%86/",
	"title": "绘制原理",
	"tags": [],
	"description": "",
	"content": "流程原理 ViewRootImpl.setView /** * We have one child */ public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) { // If the application owns the surface, don\u0026#39;t enable hardware acceleration  if (mSurfaceHolder == null) { // While this is supposed to enable only, it can effectively disable  // the acceleration too.  enableHardwareAcceleration(attrs); } // Schedule the first layout -before- adding to the window  // manager, to make sure we do the relayout before receiving  // any other events from the system.  requestLayout(); //mWindowSession是一个aidl，ViewRootImpl利用它来和WindowManagerService交互  //mWindow是一个aidl，WindowManagerService可以利用这个对象与服务端交互  res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); } enableHardwareAcceleration private void enableHardwareAcceleration(WindowManager.LayoutParams attrs) { // Try to enable hardware acceleration if requested  final boolean hardwareAccelerated = (attrs.flags \u0026amp; WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED) != 0; if (hardwareAccelerated) { mAttachInfo.mThreadedRenderer = ThreadedRenderer.create(mContext, translucent, attrs.getTitle().toString()); if (mAttachInfo.mThreadedRenderer != null) { mAttachInfo.mHardwareAccelerated = mAttachInfo.mHardwareAccelerationRequested = true; } } } 创建ThreadedRenderer /** * Creates a threaded renderer using OpenGL. * * @param translucent True if the surface is translucent, false otherwise * * @return A threaded renderer backed by OpenGL. */ public static ThreadedRenderer create(Context context, boolean translucent, String name) { ThreadedRenderer renderer = null; if (isAvailable()) { renderer = new ThreadedRenderer(context, translucent, name); } return renderer; } ThreadedRenderer(Context context, boolean translucent, String name) { long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); mIsOpaque = !translucent; mNativeProxy = nCreateProxy(translucent, rootNodePtr); nSetName(mNativeProxy, name); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nstatic jlong android_view_ThreadedRenderer_createRootRenderNode(JNIEnv* env, jobject clazz) { RootRenderNode* node = new RootRenderNode(env); node-\u0026gt;incStrong(0); node-\u0026gt;setName(\u0026#34;RootRenderNode\u0026#34;); return reinterpret_cast\u0026lt;jlong\u0026gt;(node); } /** * Adopts an existing native render node. */ public static RenderNode adopt(long nativePtr) { return new RenderNode(nativePtr); } 创建RendeProxy static jlong android_view_ThreadedRenderer_createProxy(JNIEnv* env, jobject clazz, jboolean translucent, jlong rootRenderNodePtr) { RootRenderNode* rootRenderNode = reinterpret_cast\u0026lt;RootRenderNode*\u0026gt;(rootRenderNodePtr); ContextFactoryImpl factory(rootRenderNode); return (jlong) new RenderProxy(translucent, rootRenderNode, \u0026amp;factory); } frameworks/base/libs/hwui/renderthread/RenderProxy.cpp\nRenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { } 创建RenderThread RenderThread\u0026amp; RenderThread::getInstance() { // This is a pointer because otherwise __cxa_finalize  // will try to delete it like a Good Citizen but that causes us to crash  // because we don\u0026#39;t want to delete the RenderThread normally.  static RenderThread* sInstance = new RenderThread(); gHasRenderThreadInstance = true; return *sInstance; } RenderThread::RenderThread() : ThreadBase() , mVsyncSource(nullptr) , mVsyncRequested(false) , mFrameCallbackTaskPending(false) , mRenderState(nullptr) , mEglManager(nullptr) , mVkManager(nullptr) { Properties::load(); start(\u0026#34;RenderThread\u0026#34;); } graph TB Thread--\u0026gt;ThreadBase ThreadBase--\u0026gt;ReanderThread 启动RenderThread bool RenderThread::threadLoop() { setpriority(PRIO_PROCESS, 0, PRIORITY_DISPLAY); if (gOnStartHook) { gOnStartHook(); } initThreadLocals(); while (true) { waitForWork(); processQueue(); ...... requestVsync(); } return false; } void RenderThread::initThreadLocals() { mDisplayInfo = DeviceInfo::queryDisplayInfo(); nsecs_t frameIntervalNanos = static_cast\u0026lt;nsecs_t\u0026gt;(1000000000 / mDisplayInfo.fps); mTimeLord.setFrameInterval(frameIntervalNanos); initializeDisplayEventReceiver(); mEglManager = new EglManager(*this); mRenderState = new RenderState(*this); mVkManager = new VulkanManager(*this); mCacheManager = new CacheManager(mDisplayInfo); } 配置DisplayEventReceiver的fd监听 void RenderThread::initializeDisplayEventReceiver() { LOG_ALWAYS_FATAL_IF(mVsyncSource, \u0026#34;Initializing a second DisplayEventReceiver?\u0026#34;); if (!Properties::isolatedProcess) { auto receiver = std::make_unique\u0026lt;DisplayEventReceiver\u0026gt;(); status_t status = receiver-\u0026gt;initCheck(); // Register the FD  mLooper-\u0026gt;addFd(receiver-\u0026gt;getFd(), 0, Looper::EVENT_INPUT, RenderThread::displayEventReceiverCallback, this); mVsyncSource = new DisplayEventReceiverWrapper(std::move(receiver)); } else { mVsyncSource = new DummyVsyncSource(this); } } frameworks/base/libs/hwui/thread/ThreadBase.h\nThreadBase.waitForWork void waitForWork() { nsecs_t nextWakeup; { std::unique_lock lock{mLock}; nextWakeup = mQueue.nextWakeup(lock); } int timeout = -1; if (nextWakeup \u0026lt; std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max()) { timeout = ns2ms(nextWakeup - WorkQueue::clock::now()); if (timeout \u0026lt; 0) timeout = 0; } int result = mLooper-\u0026gt;pollOnce(timeout); LOG_ALWAYS_FATAL_IF(result == Looper::POLL_ERROR, \u0026#34;RenderThread Looper POLL_ERROR!\u0026#34;); } nsecs_t nextWakeup(std::unique_lock\u0026lt;std::mutex\u0026gt;\u0026amp; lock) { if (mWorkQueue.empty()) { return std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max(); } else { return std::begin(mWorkQueue)-\u0026gt;runAt; } } 加入同步任务 RenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { mContext = mRenderThread.queue().runSync([\u0026amp;]() -\u0026gt; CanvasContext* { return CanvasContext::create(mRenderThread, translucent, rootRenderNode, contextFactory); }); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext, rootRenderNode); } ThreadBase.h\nWorkQueue\u0026amp; queue() { return mQueue; } frameworks/base/libs/hwui/thread/WorkQueue.h\ntemplate \u0026lt;class F\u0026gt; auto runSync(F\u0026amp;\u0026amp; func) -\u0026gt; decltype(func()) { std::packaged_task\u0026lt;decltype(func())()\u0026gt; task{std::forward\u0026lt;F\u0026gt;(func)}; post([\u0026amp;task]() { std::invoke(task); }); return task.get_future().get(); }; template \u0026lt;class F\u0026gt; void post(F\u0026amp;\u0026amp; func) { postAt(0, std::forward\u0026lt;F\u0026gt;(func)); } template \u0026lt;class F\u0026gt; void postAt(nsecs_t time, F\u0026amp;\u0026amp; func) { enqueue(WorkItem{time, std::function\u0026lt;void()\u0026gt;(std::forward\u0026lt;F\u0026gt;(func))}); } void enqueue(WorkItem\u0026amp;\u0026amp; item) { bool needsWakeup; { std::unique_lock _lock{mLock}; auto insertAt = std::find_if( std::begin(mWorkQueue), std::end(mWorkQueue), [time = item.runAt](WorkItem \u0026amp; item) { return item.runAt \u0026gt; time; }); needsWakeup = std::begin(mWorkQueue) == insertAt; mWorkQueue.emplace(insertAt, std::move(item)); } if (needsWakeup) { mWakeFunc();//ThreadBase构造时设置的: mLooper-\u0026gt;wake()  } } Looper唤醒后执行processQueue void processQueue() { mQueue.process(); } void process() { auto now = clock::now(); std::vector\u0026lt;WorkItem\u0026gt; toProcess; { std::unique_lock _lock{mLock}; if (mWorkQueue.empty()) return; toProcess = std::move(mWorkQueue); auto moveBack = find_if(std::begin(toProcess), std::end(toProcess), [\u0026amp;now](WorkItem\u0026amp; item) { return item.runAt \u0026gt; now; }); if (moveBack != std::end(toProcess)) { mWorkQueue.reserve(std::distance(moveBack, std::end(toProcess)) + 5); std::move(moveBack, std::end(toProcess), std::back_inserter(mWorkQueue)); toProcess.erase(moveBack, std::end(toProcess)); } } for (auto\u0026amp; item : toProcess) { item.work(); } } WorkQueue和WorkItem结构 WorkQueue std::function\u0026lt;void()\u0026gt; mWakeFunc; std::vector\u0026lt;WorkItem\u0026gt; mWorkQueue; struct WorkItem { nsecs_t runAt; std::function\u0026lt;void()\u0026gt; work; }; 执行任务CanvasContext::create frameworks/base/libs/hwui/renderthread/CanvasContext.cpp\n根据pipelineType创建对应的CanvasContext CanvasContext* CanvasContext::create(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) { auto renderType = Properties::getRenderPipelineType(); switch (renderType) { case RenderPipelineType::OpenGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;OpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaOpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaVulkan: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaVulkanPipeline\u0026gt;(thread)); default: LOG_ALWAYS_FATAL(\u0026#34;canvas context type %d not supported\u0026#34;, (int32_t)renderType); break; } return nullptr; } RenderPipeLine类设计 graph TB IRenderPipeline--\u0026gt;OpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaOpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaVulkanPipeline CanvasContext::CanvasContext(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory, std::unique_ptr\u0026lt;IRenderPipeline\u0026gt; renderPipeline) : mRenderThread(thread) , mGenerationID(0) , mOpaque(!translucent) , mAnimationContext(contextFactory-\u0026gt;createAnimationContext(mRenderThread.timeLord())) , mJankTracker(\u0026amp;thread.globalProfileData(), thread.mainDisplayInfo()) , mProfiler(mJankTracker.frames()) , mContentDrawBounds(0, 0, 0, 0) , mRenderPipeline(std::move(renderPipeline)) { rootRenderNode-\u0026gt;makeRoot(); mRenderNodes.emplace_back(rootRenderNode); mRenderThread.renderState().registerCanvasContext(this); mProfiler.setDensity(mRenderThread.mainDisplayInfo().density); } 执行任务mDrawFrameTask.setContext void DrawFrameTask::setContext(RenderThread* thread, CanvasContext* context, RenderNode* targetNode) { mRenderThread = thread; mContext = context; mTargetNode = targetNode; } requestLayout 策划下一帧 mWindowSession.addToDisplay app进程和wms所在的sytemserver进程通信的binder frameworks/base/core/java/android/view/IWindow.aidl\n/** * API back to a client window that the Window Manager uses to inform it of * interesting things happening. */ oneway interface IWindow {} frameworks/base/core/java/android/view/IWindowSession.aidl\n/** * System private per-application interface to the window manager. */ interface IWindowSession {} frameworks/base/services/core/java/com/android/server/wm/Session.java\nSession.addToDisplay,WMS.addWindow @Override public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId, outFrame, outContentInsets, outStableInsets, outOutsets, outDisplayCutout, outInputChannel); } public int addWindow(Session session, IWindow client, int seq, LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { //WindowState用来描述一个Window  //生成WindowState对象，它是ViewRootImpl 在WindowManager Service端的代表。在它的构造函数里，WindowState 会生成IWindowId.Stub 对象和DeathRecipient对象来分别监听Focus和窗口死亡的信息  final WindowState win = new WindowState(this, session, client, token, parentWindow, appOp[0], seq, attrs, viewVisibility, session.mUid, session.mCanAddInternalSystemWindow); //创建用于通信的SocketPair , 将其传给InputManagerService, 用于接下来的用户输入事件对应的响应窗口（参考Android的用户输入处理）  final boolean openInputChannels = (outInputChannel != null \u0026amp;\u0026amp; (attrs.inputFeatures \u0026amp; INPUT_FEATURE_NO_INPUT_CHANNEL) == 0); if (openInputChannels) { win.openInputChannel(outInputChannel); } //创建了一个Surface Session 并将Surface Session，WindowSession 还有WindowState 三者关联起来.  win.attach(); //mWindowMap是WindowManagerService用来保存当前所有Window新的的集合  mWindowMap.put(client.asBinder(), win); //一个token下会有多个win state。 其实token与PhoneWindow是一一对应的。  win.mToken.addWindow(win); } frameworks/base/services/core/java/com/android/server/wm/WindowState.java\nopenInputChannel void openInputChannel(InputChannel outInputChannel) { if (mInputChannel != null) { throw new IllegalStateException(\u0026#34;Window already has an input channel.\u0026#34;); } String name = getName(); InputChannel[] inputChannels = InputChannel.openInputChannelPair(name);//refer to TouchEventNative.md  mInputChannel = inputChannels[0]; mClientChannel = inputChannels[1]; mInputWindowHandle.inputChannel = inputChannels[0]; if (outInputChannel != null) { mClientChannel.transferTo(outInputChannel); mClientChannel.dispose(); mClientChannel = null; } else { // If the window died visible, we setup a dummy input channel, so that taps  // can still detected by input monitor channel, and we can relaunch the app.  // Create dummy event receiver that simply reports all events as handled.  mDeadWindowEventReceiver = new DeadWindowEventReceiver(mClientChannel); } mService.mInputManager.registerInputChannel(mInputChannel, mInputWindowHandle);//refer to TouchEventNative.md  } attach void attach() { mSession.windowAddedLocked(mAttrs.packageName); } void windowAddedLocked(String packageName) { if (mSurfaceSession == null) { mSurfaceSession = new SurfaceSession(); mService.mSessions.add(this); } } 创建SurfaceSession /** * An instance of this class represents a connection to the surface * flinger, from which you can create one or more Surface instances that will * be composited to the screen. */ public final class SurfaceSession { // Note: This field is accessed by native code.  private long mNativeClient; // SurfaceComposerClient* } /** Create a new connection with the surface flinger. */ public SurfaceSession() { mNativeClient = nativeCreate(); } frameworks/base/core/jni/android_view_SurfaceSession.cpp\nstatic jlong nativeCreate(JNIEnv* env, jclass clazz) { SurfaceComposerClient* client = new SurfaceComposerClient(); client-\u0026gt;incStrong((void*)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(client); } 创建SurfaceComposerClient void SurfaceComposerClient::onFirstRef() { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService());//sf 就是SurfaceFlinger Service  if (sf != 0 \u0026amp;\u0026amp; mStatus == NO_INIT) { auto rootProducer = mParent.promote(); sp\u0026lt;ISurfaceComposerClient\u0026gt; conn; conn = (rootProducer != nullptr) ? sf-\u0026gt;createScopedConnection(rootProducer) : sf-\u0026gt;createConnection(); if (conn != 0) { mClient = conn; mStatus = NO_ERROR; } } } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\n通知SurfaceFlinger.createConnection sp\u0026lt;ISurfaceComposerClient\u0026gt; SurfaceFlinger::createConnection() { return initClient(new Client(this)); } frameworks/native/services/surfaceflinger/Client.h\n创建Client作为BnSurfaceComposerClient class Client : public BnSurfaceComposerClient { public: ... void attachLayer(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle, const sp\u0026lt;Layer\u0026gt;\u0026amp; layer); void detachLayer(const Layer* layer); ... private: // ISurfaceComposerClient interface。 gbp很重要，它维护这一个应用程序的渲染 Buffer队列  virtual status_t createSurface(...sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp); virtual status_t destroySurface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle); //跨进程通信方法  virtual status_t onTransact(uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags); ... // constant  sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; // protected by mLock  DefaultKeyedVector\u0026lt; wp\u0026lt;IBinder\u0026gt;, wp\u0026lt;Layer\u0026gt; \u0026gt; mLayers; // 一个应用程序的所有Layer  ... }; performTraversals private void performTraversals() { // Execute enqueued actions on every traversal in case a detached view enqueued an action  host.dispatchAttachedToWindow(mAttachInfo, 0); relayoutResult = relayoutWindow(params, viewVisibility, insetsPending); if (mSurface.isValid()) { // If we are creating a new surface, then we need to  // completely redraw it. Also, when we get to the  // point of drawing it we will hold off and schedule  // a new traversal instead. This is so we can tell the  // window manager about all of the windows being displayed  // before actually drawing them, so it can display then  // all at once.  newSurface = true; mFullRedrawNeeded = true; mPreviousTransparentRegion.setEmpty(); // Only initialize up-front if transparent regions are not  // requested, otherwise defer to see if the entire window  // will be transparent  if (mAttachInfo.mThreadedRenderer != null) { hwInitialized = mAttachInfo.mThreadedRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { // Don\u0026#39;t pre-allocate if transparent regions  // are requested as they may not be needed  mSurface.allocateBuffers(); } } } // Ask host how big it wants to be  performMeasure(childWidthMeasureSpec, childHeightMeasureSpec); ...... performLayout(lp, mWidth, mHeight); ...... performDraw(); relayoutWindow private int relayoutWindow(WindowManager.LayoutParams params, int viewVisibility, boolean insetsPending) throws RemoteException { int relayoutResult = mWindowSession.relayout(mWindow, mSeq, params, (int) (mView.getMeasuredWidth() * appScale + 0.5f), (int) (mView.getMeasuredHeight() * appScale + 0.5f), viewVisibility, insetsPending ? WindowManagerGlobal.RELAYOUT_INSETS_PENDING : 0, frameNumber, mWinFrame, mPendingOverscanInsets, mPendingContentInsets, mPendingVisibleInsets, mPendingStableInsets, mPendingOutsets, mPendingBackDropFrame, mPendingDisplayCutout, mPendingMergedConfiguration, mSurface); } @Override public int relayout(IWindow window, int seq, WindowManager.LayoutParams attrs, int requestedWidth, int requestedHeight, int viewFlags, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper cutout, MergedConfiguration mergedConfiguration, Surface outSurface) { int res = mService.relayoutWindow(this, window, seq, attrs, requestedWidth, requestedHeight, viewFlags, flags, frameNumber, outFrame, outOverscanInsets, outContentInsets, outVisibleInsets, outStableInsets, outsets, outBackdropFrame, cutout, mergedConfiguration, outSurface); return res; } frameworks/base/services/core/java/com/android/server/wm/WindowManagerService.java\npublic int relayoutWindow(Session session, IWindow client, int seq, LayoutParams attrs, int requestedWidth, int requestedHeight, int viewVisibility, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outOutsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper outCutout, MergedConfiguration mergedConfiguration, Surface outSurface) { result = createSurfaceControl(outSurface, result, win, winAnimator); } private int createSurfaceControl(Surface outSurface, int result, WindowState win,WindowStateAnimator winAnimator) { ... surfaceController = winAnimator.createSurfaceLocked(win.mAttrs.type, win.mOwnerUid); ... surfaceController.getSurface(outSurface); } WindowSurfaceController createSurfaceLocked(int windowType, int ownerUid) { mSurfaceController = new WindowSurfaceController(mSession.mSurfaceSession, attrs.getTitle().toString(), width, height, format, flags, this, windowType, ownerUid); } new WindowSurfaceController() public WindowSurfaceController(SurfaceSession s, String name, int w, int h, int format, int flags, WindowStateAnimator animator, int windowType, int ownerUid) { final SurfaceControl.Builder b = win.makeSurface() .setParent(win.getSurfaceControl()) .setName(name) .setSize(w, h) .setFormat(format) .setFlags(flags) .setMetadata(windowType, ownerUid); mSurfaceControl = b.build(); } /** * Construct a new {@link SurfaceControl} with the set parameters. */ public SurfaceControl build() { return new SurfaceControl(mSession, mName, mWidth, mHeight, mFormat, mFlags, mParent, mWindowType, mOwnerUid); } /** Good practice is to first create the surface with the {@link #HIDDEN} flag * specified, open a transaction, set the surface layer, layer stack, alpha, * and position, call {@link #show} if appropriate, and close the transaction. **/ private SurfaceControl(SurfaceSession session, String name, int w, int h, int format, int flags, SurfaceControl parent, int windowType, int ownerUid) throws OutOfResourcesException, IllegalArgumentException { mNativeObject = nativeCreate(session, name, w, h, format, flags, parent != null ? parent.mNativeObject : 0, windowType, ownerUid); } frameworks/base/core/jni/android_view_SurfaceControl.cpp\nstatic jlong nativeCreate(JNIEnv* env, jclass clazz, jobject sessionObj, jstring nameStr, jint w, jint h, jint format, jint flags, jlong parentObject, jint windowType, jint ownerUid) { ScopedUtfChars name(env, nameStr); //这个client其实就是前面创建的SurfaceComposerClinent  sp\u0026lt;SurfaceComposerClient\u0026gt; client(android_view_SurfaceSession_getClient(env, sessionObj)); SurfaceControl *parent = reinterpret_cast\u0026lt;SurfaceControl*\u0026gt;(parentObject); sp\u0026lt;SurfaceControl\u0026gt; surface; status_t err = client-\u0026gt;createSurfaceChecked( String8(name.c_str()), w, h, format, \u0026amp;surface, flags, parent, windowType, ownerUid); surface-\u0026gt;incStrong((void *)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } status_t SurfaceComposerClient::createSurfaceChecked( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, sp\u0026lt;SurfaceControl\u0026gt;* outSurface, uint32_t flags, SurfaceControl* parent, int32_t windowType, int32_t ownerUid) { sp\u0026lt;SurfaceControl\u0026gt; sur; sp\u0026lt;IBinder\u0026gt; handle; sp\u0026lt;IBinder\u0026gt; parentHandle; sp\u0026lt;IGraphicBufferProducer\u0026gt; gbp; if (parent != nullptr) { parentHandle = parent-\u0026gt;getHandle(); } err = mClient-\u0026gt;createSurface(name, w, h, format, flags, parentHandle, windowType, ownerUid, \u0026amp;handle, \u0026amp;gbp); if (err == NO_ERROR) { *outSurface = new SurfaceControl(this, handle, gbp, true /* owned */); } return err; } status_t Client::createSurface( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, const sp\u0026lt;IBinder\u0026gt;\u0026amp; parentHandle, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp) { //postMessageSync到surfaceFlinger的主线程中处理消息任务，如下:  result = flinger-\u0026gt;createLayer(name, client, w, h, format, flags, windowType, ownerUid, handle, gbp, parent); } createLayer status_t SurfaceFlinger::createLayer( const String8\u0026amp; name, const sp\u0026lt;Client\u0026gt;\u0026amp; client, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* parent) { sp\u0026lt;Layer\u0026gt; layer; String8 uniqueName = getUniqueLayerName(name); switch (flags \u0026amp; ISurfaceComposerClient::eFXSurfaceMask) { case ISurfaceComposerClient::eFXSurfaceNormal: result = createBufferLayer(client, uniqueName, w, h, flags, format, handle, gbp, \u0026amp;layer); break; } result = addClientLayer(client, *handle, *gbp, layer, *parent); return result; } createBufferLayer status_t SurfaceFlinger::createBufferLayer(const sp\u0026lt;Client\u0026gt;\u0026amp; client, const String8\u0026amp; name, uint32_t w, uint32_t h, uint32_t flags, PixelFormat\u0026amp; format, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* outLayer) { // initialize the surfaces  switch (format) { case PIXEL_FORMAT_TRANSPARENT: case PIXEL_FORMAT_TRANSLUCENT: format = PIXEL_FORMAT_RGBA_8888; break; case PIXEL_FORMAT_OPAQUE: format = PIXEL_FORMAT_RGBX_8888; break; } sp\u0026lt;BufferLayer\u0026gt; layer = new BufferLayer(this, client, name, w, h, flags); status_t err = layer-\u0026gt;setBuffers(w, h, format, flags); if (err == NO_ERROR) { *handle = layer-\u0026gt;getHandle(); *gbp = layer-\u0026gt;getProducer(); *outLayer = layer; } return err; } frameworks/native/services/surfaceflinger/BufferLayer.cpp\nBufferLayer::onFirstRef void BufferLayer::onFirstRef() { // Creates a custom BufferQueue for SurfaceFlingerConsumer to use  sp\u0026lt;IGraphicBufferProducer\u0026gt; producer; sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer; BufferQueue::createBufferQueue(\u0026amp;producer, \u0026amp;consumer, true); //MonitoredProducer只是一个装饰类，它实际功能都委托给构造它的参数producer  mProducer = new MonitoredProducer(producer, mFlinger, this); mConsumer = new BufferLayerConsumer(consumer, mFlinger-\u0026gt;getRenderEngine(), mTextureName, this); const sp\u0026lt;const DisplayDevice\u0026gt; hw(mFlinger-\u0026gt;getDefaultDisplayDevice()); updateTransformHint(hw); } frameworks/native/libs/gui/BufferQueue.cpp\nBufferQueue::createBufferQueue void BufferQueue::createBufferQueue(sp\u0026lt;IGraphicBufferProducer\u0026gt;* outProducer, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* outConsumer, bool consumerIsSurfaceFlinger) { sp\u0026lt;BufferQueueCore\u0026gt; core(new BufferQueueCore()); sp\u0026lt;IGraphicBufferProducer\u0026gt; producer(new BufferQueueProducer(core, consumerIsSurfaceFlinger)); sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer(new BufferQueueConsumer(core)); *outProducer = producer; *outConsumer = consumer; } frameworks/native/libs/ui/include/ui/BufferQueueDefs.h\nNUM_BUFFER_SLOTS namespace android { namespace BufferQueueDefs { // BufferQueue will keep track of at most this value of buffers.  // Attempts at runtime to increase the number of buffers past this  // will fail.  static constexpr int NUM_BUFFER_SLOTS = 64; } // namespace BufferQueueDefs } // namespace android  frameworks/native/libs/gui/include/gui/BufferQueueCore.h\nBufferQueueCore // mQueue is a FIFO of queued buffers used in synchronous mode.  Fifo mQueue; // mFreeSlots contains all of the slots which are FREE and do not currently  // have a buffer attached.  std::set\u0026lt;int\u0026gt; mFreeSlots; // mFreeBuffers contains all of the slots which are FREE and currently have  // a buffer attached.  std::list\u0026lt;int\u0026gt; mFreeBuffers; // mConsumerListener is used to notify the connected consumer of  // asynchronous events that it may wish to react to. It is initially  // set to NULL and is written by consumerConnect and consumerDisconnect.  sp\u0026lt;IConsumerListener\u0026gt; mConsumerListener; frameworks/native/libs/gui/BufferQueueProducer.cpp\nBufferQueueProducer class BufferQueueProducer : public BnGraphicBufferProducer, private IBinder::DeathRecipient { frameworks/native/libs/gui/include/gui/BufferQueueConsumer.h\nBufferQueueConsumer class BufferQueueConsumer : public BnGraphicBufferConsumer { // connect connects a consumer to the BufferQueue. Only one  // consumer may be connected, and when that consumer disconnects the  // BufferQueue is placed into the \u0026#34;abandoned\u0026#34; state, causing most  // interactions with the BufferQueue by the producer to fail.  // controlledByApp indicates whether the consumer is controlled by  // the application.  //  // consumerListener may not be NULL.  virtual status_t connect(const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp); } getSurface void getSurface(Surface outSurface) { outSurface.copyFrom(mSurfaceControl); } copyFrom /** * Copy another surface to this one. This surface now holds a reference * to the same data as the original surface, and is -not- the owner. * This is for use by the window manager when returning a window surface * back from a client, converting it from the representation being managed * by the window manager to the representation the client uses to draw * in to it. * * @param other {@link SurfaceControl} to copy from. * */ public void copyFrom(SurfaceControl other) { long surfaceControlPtr = other.mNativeObject; long newNativeObject = nativeGetFromSurfaceControl(surfaceControlPtr); synchronized (mLock) { if (mNativeObject != 0) { nativeRelease(mNativeObject); } setNativeObjectLocked(newNativeObject); } } frameworks/base/core/jni/android_view_Surface.cpp\nstatic jlong nativeGetFromSurfaceControl(JNIEnv* env, jclass clazz, jlong surfaceControlNativeObj) { /* * This is used by the WindowManagerService just after constructing * a Surface and is necessary for returning the Surface reference to * the caller. At this point, we should only have a SurfaceControl. */ sp\u0026lt;SurfaceControl\u0026gt; ctrl(reinterpret_cast\u0026lt;SurfaceControl *\u0026gt;(surfaceControlNativeObj)); sp\u0026lt;Surface\u0026gt; surface(ctrl-\u0026gt;getSurface()); if (surface != NULL) { surface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); } return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } frameworks/native/libs/gui/SurfaceControl.cpp\nsp\u0026lt;Surface\u0026gt; SurfaceControl::getSurface() const { Mutex::Autolock _l(mLock); if (mSurfaceData == 0) { return generateSurfaceLocked(); } return mSurfaceData; } sp\u0026lt;Surface\u0026gt; SurfaceControl::generateSurfaceLocked() const { // This surface is always consumed by SurfaceFlinger, so the  // producerControlledByApp value doesn\u0026#39;t matter; using false.  //这个mGraphicBufferProducer其实就是上面分析的BufferQueueProducer  mSurfaceData = new Surface(mGraphicBufferProducer, false); return mSurfaceData; } Surface::Surface(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp; bufferProducer, bool controlledByApp) : mGraphicBufferProducer(bufferProducer), mAttachInfo.mThreadedRenderer.initialize(mSurface) /** * Initializes the threaded renderer for the specified surface. * @param surface The surface to render * @return True if the initialization was successful, false otherwise. */ boolean initialize(Surface surface) throws OutOfResourcesException { updateEnabledState(surface); nInitialize(mNativeProxy, surface); return status; } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nstatic void android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;Surface\u0026gt; surface = android_view_Surface_getSurface(env, jsurface); proxy-\u0026gt;initialize(surface); } RenderProxy::initialize void RenderProxy::initialize(const sp\u0026lt;Surface\u0026gt;\u0026amp; surface) { mRenderThread.queue().post( [ this, surf = surface ]() mutable { mContext-\u0026gt;setSurface(std::move(surf)); }); } CanvasContext::setSurface void CanvasContext::setSurface(sp\u0026lt;Surface\u0026gt;\u0026amp;\u0026amp; surface) { mNativeSurface = std::move(surface); ColorMode colorMode = mWideColorGamut ? ColorMode::WideColorGamut : ColorMode::Srgb; bool hasSurface = mRenderPipeline-\u0026gt;setSurface(mNativeSurface.get(), mSwapBehavior, colorMode); } frameworks/base/libs/hwui/renderthread/OpenGLPipeline.cpp\nOpenGLPipeline::setSurface bool OpenGLPipeline::setSurface(Surface* surface, SwapBehavior swapBehavior, ColorMode colorMode) { if (surface) { const bool wideColorGamut = colorMode == ColorMode::WideColorGamut; mEglSurface = mEglManager.createSurface(surface, wideColorGamut); } return false; } frameworks/base/libs/hwui/renderthread/EglManager.cpp\nEglManager::createSurface EGLSurface EglManager::createSurface(EGLNativeWindowType window, bool wideColorGamut) { initialize(); EGLSurface surface = eglCreateWindowSurface( mEglDisplay, wideColorGamut ? mEglConfigWideGamut : mEglConfig, window, attribs); return surface; } mSurface.allocateBuffers /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } static void nativeAllocateBuffers(JNIEnv* /* env */ , jclass /* clazz */, jlong nativeObject) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } surface-\u0026gt;allocateBuffers(); } Surface::allocateBuffers void Surface::allocateBuffers() { uint32_t reqWidth = mReqWidth ? mReqWidth : mUserWidth; uint32_t reqHeight = mReqHeight ? mReqHeight : mUserHeight; mGraphicBufferProducer-\u0026gt;allocateBuffers(reqWidth, reqHeight, mReqFormat, mReqUsage); } BufferQueueProducer::allocateBuffers void BufferQueueProducer::allocateBuffers(uint32_t width, uint32_t height, PixelFormat format, uint64_t usage) { Vector\u0026lt;sp\u0026lt;GraphicBuffer\u0026gt;\u0026gt; buffers; for (size_t i = 0; i \u0026lt; newBufferCount; ++i) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( allocWidth, allocHeight, allocFormat, BQ_LAYER_COUNT, allocUsage, allocName); status_t result = graphicBuffer-\u0026gt;initCheck(); buffers.push_back(graphicBuffer); } } frameworks/native/libs/ui/GraphicBuffer.cpp\nnew GraphicBuffer GraphicBuffer::GraphicBuffer(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t usage, std::string requestorName) : GraphicBuffer() { mInitCheck = initWithSize(inWidth, inHeight, inFormat, inLayerCount, usage, std::move(requestorName)); } status_t GraphicBuffer::initWithSize(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t inUsage, std::string requestorName) { GraphicBufferAllocator\u0026amp; allocator = GraphicBufferAllocator::get(); uint32_t outStride = 0; status_t err = allocator.allocate(inWidth, inHeight, inFormat, inLayerCount, inUsage, \u0026amp;handle, \u0026amp;outStride, mId, std::move(requestorName)); return err; } frameworks/native/libs/ui/GraphicBufferAllocator.cpp\nGraphicBufferAllocator GraphicBufferMapper\u0026amp; mMapper; const std::unique_ptr\u0026lt;const Gralloc2::Allocator\u0026gt; mAllocator; GraphicBufferAllocator::allocate status_t GraphicBufferAllocator::allocate(uint32_t width, uint32_t height, PixelFormat format, uint32_t layerCount, uint64_t usage, buffer_handle_t* handle, uint32_t* stride, uint64_t /*graphicBufferId*/, std::string requestorName) { Gralloc2::IMapper::BufferDescriptorInfo info = {}; info.width = width; info.height = height; info.layerCount = layerCount; info.format = static_cast\u0026lt;Gralloc2::PixelFormat\u0026gt;(format); info.usage = usage; Gralloc2::Error error = mAllocator-\u0026gt;allocate(info, stride, handle); } frameworks/native/libs/ui/include/ui/Gralloc2.h\n// A wrapper to IAllocator class Allocator { sp\u0026lt;IAllocator\u0026gt; mAllocator } Allocator::Allocator(const Mapper\u0026amp; mapper) : mMapper(mapper) { mAllocator = IAllocator::getService(); } Allocator::allocate Error Allocator::allocate(BufferDescriptor descriptor, uint32_t count, uint32_t* outStride, buffer_handle_t* outBufferHandles) const { Error error; auto ret = mAllocator-\u0026gt;allocate(descriptor, count, [\u0026amp;](const auto\u0026amp; tmpError, const auto\u0026amp; tmpStride, const auto\u0026amp; tmpBuffers) { error = tmpError; if (tmpError != Error::NONE) { return; } // import buffers  for (uint32_t i = 0; i \u0026lt; count; i++) { error = mMapper.importBuffer(tmpBuffers[i], \u0026amp;outBufferHandles[i]); if (error != Error::NONE) { for (uint32_t j = 0; j \u0026lt; i; j++) { mMapper.freeBuffer(outBufferHandles[j]); outBufferHandles[j] = nullptr; } return; } } *outStride = tmpStride; }); // make sure the kernel driver sees BC_FREE_BUFFER and closes the fds now  hardware::IPCThreadState::self()-\u0026gt;flushCommands(); return (ret.isOk()) ? error : kTransactionError; } hardware/interfaces/graphics/allocator/2.0/IAllocator.hal\ninterface IAllocator { /** * Allocates buffers with the properties specified by the descriptor. * * @param descriptor specifies the properties of the buffers to allocate. * @param count is the number of buffers to allocate. * @return error is NONE upon success. Otherwise, * BAD_DESCRIPTOR when the descriptor is invalid. * NO_RESOURCES when the allocation cannot be fulfilled at this * time. * UNSUPPORTED when any of the property encoded in the descriptor * is not supported. * @return stride is the number of pixels between two consecutive rows of * the buffers, when the concept of consecutive rows is defined. * Otherwise, it has no meaning. * @return buffers is an array of raw handles to the newly allocated * buffers. */ @entry @exit @callflow(next=\u0026#34;*\u0026#34;) allocate(BufferDescriptor descriptor, uint32_t count) generates (Error error, uint32_t stride, vec\u0026lt;handle\u0026gt; buffers); performDraw private boolean draw(boolean fullRedrawNeeded) { Surface surface = mSurface; if (!surface.isValid()) { return false; } if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { if (mAttachInfo.mThreadedRenderer != null \u0026amp;\u0026amp; mAttachInfo.mThreadedRenderer.isEnabled()) { mAttachInfo.mThreadedRenderer.draw(mView, mAttachInfo, this, callback); } else { drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty, surfaceInsets) } } } drawSoftware /** * @return true if drawing was successful, false if an error occurred */ private boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty, Rect surfaceInsets) { // Draw with software renderer.  final Canvas canvas; canvas = mSurface.lockCanvas(dirty); ...... mView.draw(canvas); ...... surface.unlockCanvasAndPost(canvas); } lockCanvas public Canvas lockCanvas(Rect inOutDirty) throws Surface.OutOfResourcesException, IllegalArgumentException { synchronized (mLock) { mLockedObject = nativeLockCanvas(mNativeObject, mCanvas, inOutDirty); return mCanvas; } } static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ANativeWindow_Buffer outBuffer; status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType, GraphicsJNI::defaultColorSpace()); SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits); } Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); if (dirtyRectPtr) { nativeCanvas-\u0026gt;clipRect(dirtyRect.left, dirtyRect.top, dirtyRect.right, dirtyRect.bottom, SkClipOp::kIntersect); } // Create another reference to the surface and return it. This reference  // should be passed to nativeUnlockCanvasAndPost in place of mNativeObject,  // because the latter could be replaced while the surface is locked.  sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } Surface::lock status_t Surface::lock(ANativeWindow_Buffer* outBuffer, ARect* inOutDirtyBounds) { ANativeWindowBuffer* out; int fenceFd = -1; status_t err = dequeueBuffer(\u0026amp;out, \u0026amp;fenceFd); sp\u0026lt;GraphicBuffer\u0026gt; backBuffer(GraphicBuffer::getSelf(out)); status_t res = backBuffer-\u0026gt;lockAsync( GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN, newDirtyRegion.bounds(), \u0026amp;vaddr, fenceFd); mLockedBuffer = backBuffer; outBuffer-\u0026gt;width = backBuffer-\u0026gt;width; outBuffer-\u0026gt;height = backBuffer-\u0026gt;height; outBuffer-\u0026gt;stride = backBuffer-\u0026gt;stride; outBuffer-\u0026gt;format = backBuffer-\u0026gt;format; outBuffer-\u0026gt;bits = vaddr; } Surface::dequeueBuffer int Surface::dequeueBuffer(android_native_buffer_t** buffer, int* fenceFd) { status_t result = mGraphicBufferProducer-\u0026gt;dequeueBuffer(\u0026amp;buf, \u0026amp;fence, reqWidth, reqHeight, reqFormat, reqUsage, \u0026amp;mBufferAge, enableFrameTimestamps ? \u0026amp;frameTimestamps : nullptr); sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; gbuf(mSlots[buf].buffer); if ((result \u0026amp; IGraphicBufferProducer::BUFFER_NEEDS_REALLOCATION) || gbuf == nullptr) { result = mGraphicBufferProducer-\u0026gt;requestBuffer(buf, \u0026amp;gbuf); } *buffer = gbuf.get(); return OK; } dequeuebuffer\nrequestbuffer\ndraw nativeUnlockCanvasAndPost static void nativeUnlockCanvasAndPost(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } // detach the canvas from the surface  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); nativeCanvas-\u0026gt;setBitmap(SkBitmap()); // unlock surface  status_t err = surface-\u0026gt;unlockAndPost(); } mAttachInfo.mThreadedRenderer.draw硬件绘制 硬件加速绘制\nBufferQueueProducer::dequeueBuffer status_t BufferQueueProducer::dequeueBuffer(int* outSlot, sp\u0026lt;android::Fence\u0026gt;* outFence, uint32_t width, uint32_t height, PixelFormat format, uint64_t usage, uint64_t* outBufferAge, FrameEventHistoryDelta* outTimestamps) { int found = BufferItem::INVALID_BUFFER_SLOT; while (found == BufferItem::INVALID_BUFFER_SLOT) { status_t status = waitForFreeSlotThenRelock(FreeSlotCaller::Dequeue, \u0026amp;found); } const sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; buffer(mSlots[found].mGraphicBuffer); *outSlot = found; if ((buffer == NULL) || buffer-\u0026gt;needsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { returnFlags |= BUFFER_NEEDS_REALLOCATION; } if (returnFlags \u0026amp; BUFFER_NEEDS_REALLOCATION) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( width, height, format, BQ_LAYER_COUNT, usage, {mConsumerName.string(), mConsumerName.size()}); status_t error = graphicBuffer-\u0026gt;initCheck(); } } waitForFreeSlotThenRelock status_t BufferQueueProducer::waitForFreeSlotThenRelock(FreeSlotCaller caller, int* found) const { // If we disconnect and reconnect quickly, we can be in a state where  // our slots are empty but we have many buffers in the queue. This can  // cause us to run out of memory if we outrun the consumer. Wait here if  // it looks like we have too many buffers queued up.  const int maxBufferCount = mCore-\u0026gt;getMaxBufferCountLocked(); bool tooManyBuffers = mCore-\u0026gt;mQueue.size() \u0026gt; static_cast\u0026lt;size_t\u0026gt;(maxBufferCount); if (tooManyBuffers) { BQ_LOGV(\u0026#34;%s: queue size is %zu, waiting\u0026#34;, callerString, mCore-\u0026gt;mQueue.size()); } else { // If in shared buffer mode and a shared buffer exists, always  // return it.  if (mCore-\u0026gt;mSharedBufferMode \u0026amp;\u0026amp; mCore-\u0026gt;mSharedBufferSlot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = mCore-\u0026gt;mSharedBufferSlot; } else { if (caller == FreeSlotCaller::Dequeue) { // If we\u0026#39;re calling this from dequeue, prefer free buffers  int slot = getFreeBufferLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else if (mCore-\u0026gt;mAllowAllocation) { *found = getFreeSlotLocked(); } } else { // If we\u0026#39;re calling this from attach, prefer free slots  int slot = getFreeSlotLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else { *found = getFreeBufferLocked(); } } } } } getFreeBufferLocked int BufferQueueProducer::getFreeBufferLocked() const { if (mCore-\u0026gt;mFreeBuffers.empty()) { return BufferQueueCore::INVALID_BUFFER_SLOT; } int slot = mCore-\u0026gt;mFreeBuffers.front(); mCore-\u0026gt;mFreeBuffers.pop_front(); return slot; } BufferQueueProducer::requestBuffer status_t BufferQueueProducer::requestBuffer(int slot, sp\u0026lt;GraphicBuffer\u0026gt;* buf) { mSlots[slot].mRequestBufferCalled = true; *buf = mSlots[slot].mGraphicBuffer; } 其他类结构参考 ViewRootImpl // These can be accessed by any thread, must be protected with a lock.  // Surface can never be reassigned or cleared (use Surface.clear()).  public final Surface mSurface = new Surface(); BufferQueueConsumer status_t BufferQueueConsumer::connect( const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp) { mCore-\u0026gt;mConsumerListener = consumerListener; mCore-\u0026gt;mConsumerControlledByApp = controlledByApp; return NO_ERROR; } Surface.java /** * Handle onto a raw buffer that is being managed by the screen compositor. * * \u0026lt;p\u0026gt;A Surface is generally created by or from a consumer of image buffers (such as a * {@link android.graphics.SurfaceTexture}, {@link android.media.MediaRecorder}, or * {@link android.renderscript.Allocation}), and is handed to some kind of producer (such as * {@link android.opengl.EGL14#eglCreateWindowSurface(android.opengl.EGLDisplay,android.opengl.EGLConfig,java.lang.Object,int[],int) OpenGL}, * {@link android.media.MediaPlayer#setSurface MediaPlayer}, or * {@link android.hardware.camera2.CameraDevice#createCaptureSession CameraDevice}) to draw * into.\u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Note:\u0026lt;/strong\u0026gt; A Surface acts like a * {@link java.lang.ref.WeakReference weak reference} to the consumer it is associated with. By * itself it will not keep its parent consumer from being reclaimed.\u0026lt;/p\u0026gt; */ public class Surface implements Parcelable { } frameworks/native/libs/gui/Surface.cpp\nSurface.cpp struct BufferSlot // mSurfaceTexture is the interface to the surface texture server. All  // operations on the surface texture client ultimately translate into  // interactions with the server using this interface.  sp\u0026lt;IGraphicBufferProducer\u0026gt; mGraphicBufferProducer; struct BufferSlot { sp\u0026lt;GraphicBuffer\u0026gt; buffer; Region dirtyRegion; }; // mSlots stores the buffers that have been allocated for each buffer slot.  // It is initialized to null pointers, and gets filled in with the result of  // IGraphicBufferProducer::requestBuffer when the client dequeues a buffer from a  // slot that has not yet been used. The buffer allocated to a slot will also  // be replaced if the requested buffer usage or geometry differs from that  // of the buffer allocated to a slot.  BufferSlot mSlots[NUM_BUFFER_SLOTS]; AttachInfo /** A set of information given to a view when it is attached to its parent window. */ final static class AttachInfo { } frameworks/base/libs/hwui/FrameInfo.h\nFrameInfo FrameInfoIndex enum class FrameInfoIndex { Flags = 0, IntendedVsync, Vsync, OldestInputEvent, NewestInputEvent, HandleInputStart, AnimationStart, PerformTraversalsStart, DrawStart, // End of UI frame info  SyncQueued, SyncStart, IssueDrawCommandsStart, SwapBuffers, FrameCompleted, DequeueBufferDuration, QueueBufferDuration, // Must be the last value!  // Also must be kept in sync with FrameMetrics.java#FRAME_STATS_COUNT  NumIndexes }; Looper wake void Looper::wake() { uint64_t inc = 1; ssize_t nWrite = TEMP_FAILURE_RETRY(write(mWakeEventFd, \u0026amp;inc, sizeof(uint64_t))); if (nWrite != sizeof(uint64_t)) { if (errno != EAGAIN) { LOG_ALWAYS_FATAL(\u0026#34;Could not write wake signal to fd %d: %s\u0026#34;, mWakeEventFd, strerror(errno)); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/",
	"title": "跨平台",
	"tags": [],
	"description": "",
	"content": "跨平台 探索总结跨平台知识\n flutter    通信    Flutter消息机制       "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E8%BD%AF%E4%BB%B6%E7%BB%98%E5%88%B6/",
	"title": "软件绘制",
	"tags": [],
	"description": "",
	"content": "软件绘制 深入理解Window\nAndroid的UI显示原理之Surface的创建\nAndroid的UI显示原理之Surface的渲染\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/AndroidFramework%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E7%9A%84UI%E6%98%BE%E7%A4%BA%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93.md\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/framework/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/README.md\nAndroid图形系统（九）-View、Canvas与Surface的关系\n 整体流程 把整个流程再简单总结下，View、Canvas与Surface的关系也就一目了然了：\nSurface通过dequeueBuffer流程（具体操作在此不多赘述）获取一块存放绘制数据的buffer。\nView 在onDraw的时候，通过传入的Canvas进行绘制。（这里只是一个绘制的入口而已，本文是针对requestLayout 流程来讲述的，当然你单独用Canvas实现绘制也是一样的）。\n调用java层的CanvasAPI，实际真正负责绘制工作的是底层的Skia引擎，这里核心类包括SKCanvas（画家）以及SKBitmap（画布），绘制好的内容放入Surface 通过dequeueBuffer获取到的GraphicBuffer。\n绘制完毕后，Surface通过queueBuffer将存放好绘制数据的buffer投递到队列中，并通知SurfaceFlinger消费。\n SurfaceFlinger可以说是Android UI渲染体系的核心，在Android系统启动时会启动SurfaceFlinger服务,它的主要作用就是被Android应用程序调用，把绘制(测量，布局，绘制)后的窗口(Surface)渲染到手机屏幕上\nSurfaceControl surface.lockCanvas(): //android_view_Surface.cpp static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ... ANativeWindow_Buffer outBuffer; //调用了Surface的dequeueBuffer，从SurfaceFlinger中申请内存GraphicBuffer,这个buffer是用来传递绘制的元数据的  status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); ... SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType); //新建了一个SkBitmap，并进行了一系列设置  SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits);//bitmap对graphicBuffer进行关联  } else { // be safe with an empty bitmap.  bitmap.setPixels(NULL); } //构造一个native的Canvas对象（SKCanvas)，再返回这个Canvas对象，java层的Canvas对象其实只是对SKCanvas对象的一个简单包装，所有绘制方法都是转交给SKCanvas来做。  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); ... sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } canvas.drawXXX Skia深入分析\n==SkCanvas是按照SkBitmap的方法去关联GraphicBuffer==\n一、渲染层级 从渲染流程上分，Skia可分为如下三个层级：\n 指令层：SkPicture、SkDeferredCanvas-\u0026gt;SkCanvas  这一层决定需要执行哪些绘图操作，绘图操作的预变换矩阵，当前裁剪区域，绘图操作产生在哪些layer上，Layer的生成与合并。\n解析层：SkBitmapDevice-\u0026gt;SkDraw-\u0026gt;SkScan、SkDraw1Glyph::Proc  这一层决定绘制方式，完成坐标变换，解析出需要绘制的形体（点/线/规整矩形）并做好抗锯齿处理，进行相关资源解析并设置好Shader。\n渲染层：SkBlitter-\u0026gt;SkBlitRow::Proc、SkShader::shadeSpan等  这一层进行采样（如果需要），产生实际的绘制效果，完成颜色格式适配，进行透明度混合和抖动处理（如果需要）。\n//Canvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { super.drawLine(startX, startY, stopX, stopY, paint); } //BaseCanvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { throwIfHasHwBitmapInSwMode(paint); nDrawLine(mNativeCanvasWrapper, startX, startY, stopX, stopY, paint.getNativeInstance()); } //frameworks/base/core/jni/android_graphics_Canvas.cpp static void drawLine(JNIEnv* env, jobject, jlong canvasHandle, jfloat startX, jfloat startY, jfloat stopX, jfloat stopY, jlong paintHandle) { Paint* paint = reinterpret_cast\u0026lt;Paint*\u0026gt;(paintHandle); get_canvas(canvasHandle)-\u0026gt;drawLine(startX, startY, stopX, stopY, *paint); } //external/skia/src/core/SkCanvas.cpp void SkCanvas::drawLine(SkScalar x0, SkScalar y0, SkScalar x1, SkScalar y1, const SkPaint\u0026amp; paint) { SkPoint pts[2]; pts[0].set(x0, y0); pts[1].set(x1, y1); this-\u0026gt;drawPoints(kLines_PointMode, 2, pts, paint); } void SkCanvas::drawPoints(PointMode mode, size_t count, const SkPoint pts[], const SkPaint\u0026amp; paint) { TRACE_EVENT0(\u0026#34;skia\u0026#34;, TRACE_FUNC); this-\u0026gt;onDrawPoints(mode, count, pts, paint); } mSurface.unlockCanvasAndPost(canvas): //Surface.cpp status_t Surface::unlockAndPost() { if (mLockedBuffer == 0) { ALOGE(\u0026#34;Surface::unlockAndPost failed, no locked buffer\u0026#34;); return INVALID_OPERATION; } int fd = -1; status_t err = mLockedBuffer-\u0026gt;unlockAsync(\u0026amp;fd);//通过Gralloc模块，最后是操作的ioctl  err = queueBuffer(mLockedBuffer.get(), fd); mPostedBuffer = mLockedBuffer; mLockedBuffer = 0; return err; } int Surface::queueBuffer(android_native_buffer_t* buffer, int fenceFd) { ... int i = getSlotFromBufferLocked(buffer); ... IGraphicBufferProducer::QueueBufferOutput output; IGraphicBufferProducer::QueueBufferInput input(timestamp, isAutoTimestamp, static_cast\u0026lt;android_dataspace\u0026gt;(mDataSpace), crop, mScalingMode, mTransform ^ mStickyTransform, fence, mStickyTransform, mEnableFrameTimestamps); ... status_t err = mGraphicBufferProducer-\u0026gt;queueBuffer(i, input, \u0026amp;output); ... mQueueBufferCondition.broadcast(); return err; } int Surface::getSlotFromBufferLocked(android_native_buffer_t* buffer) const { for (int i = 0; i \u0026lt; NUM_BUFFER_SLOTS; i++) { if (mSlots[i].buffer != NULL \u0026amp;\u0026amp; mSlots[i].buffer-\u0026gt;handle == buffer-\u0026gt;handle) { return i; } } return BAD_VALUE; } 我们看到了queueBuffer函数, 而在Surface的queueBuffer函数中调用了如下函数：\nmGraphicBufferProducer-\u0026gt;queueBuffer status_t BufferQueueProducer::queueBuffer(int slot, const QueueBufferInput \u0026amp;input, QueueBufferOutput *output) { //从input中获取一些列参数  input.deflate(\u0026amp;requestedPresentTimestamp, \u0026amp;isAutoTimestamp, \u0026amp;dataSpace, \u0026amp;crop, \u0026amp;scalingMode, \u0026amp;transform, \u0026amp;acquireFence, \u0026amp;stickyTransform, \u0026amp;getFrameTimestamps); sp\u0026lt;IConsumerListener\u0026gt; frameAvailableListener; sp\u0026lt;IConsumerListener\u0026gt; frameReplacedListener; BufferItem item; //可以理解为一个待渲染的帧  frameAvailableListener = mCore-\u0026gt;mConsumerListener; ...下面就是对item的一系列赋值操作 item.mAcquireCalled = mSlots[slot].mAcquireCalled; item.mGraphicBuffer = mSlots[slot].mGraphicBuffer; //根据slot获取GraphicBuffer。  item.mCrop = crop; item.mTransform = transform \u0026amp; ~static_cast\u0026lt;uint32_t\u0026gt;(NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY); item.mTransformToDisplayInverse = (transform \u0026amp; NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY) != 0; item.mScalingMode = static_cast\u0026lt;uint32_t\u0026gt;(scalingMode); item.mTimestamp = requestedPresentTimestamp; item.mIsAutoTimestamp = isAutoTimestamp; ... if (frameAvailableListener != NULL) { frameAvailableListener-\u0026gt;onFrameAvailable(item); //item是一个frame，准备完毕，要通知外界  } else if (frameReplacedListener != NULL) { frameReplacedListener-\u0026gt;onFrameReplaced(item); } addAndGetFrameTimestamps(\u0026amp;newFrameEventsEntry,etFrameTimestamps ? \u0026amp;output-\u0026gt;frameTimestamps : nullptr); return NO_ERROR; } 这个函数最终会将BufferItem的buffer清除，通知消费者的onFrameAvailable接口。然后消费者可以根据mSlots的序号再来拿buffer。\n// --------------------------------------------------------------------------- // Interface implementation for SurfaceFlingerConsumer::ContentsChangedListener // --------------------------------------------------------------------------- void BufferLayer::onFrameAvailable(const BufferItem\u0026amp; item) { ... mFlinger-\u0026gt;signalLayerUpdate(); } void SurfaceFlinger::signalLayerUpdate() { mEventQueue-\u0026gt;invalidate(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/",
	"title": "通信",
	"tags": [],
	"description": "",
	"content": "通信 探索总结通信知识\n Flutter消息机制     "
}]