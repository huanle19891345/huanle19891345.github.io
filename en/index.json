[
{
	"uri": "https://huanle19891345.github.io/en/android/",
	"title": "android",
	"tags": [],
	"description": "",
	"content": "android 探索总结android知识\n google    supportToAndroidx      系统机制原理    系统绘制    硬件加速绘制Source     软件绘制       "
},
{
	"uri": "https://huanle19891345.github.io/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/",
	"title": "flutter",
	"tags": [],
	"description": "",
	"content": "flutter 探索总结flutter知识\n 通信    Flutter消息机制      "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/flutter%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6/",
	"title": "Flutter消息机制",
	"tags": [],
	"description": "",
	"content": "消息机制 深入理解Flutter消息机制\nThreadHost初始化\n[-\u0026gt; flutter/shell/common/thread_host.cc] ThreadHost::ThreadHost(std::string name_prefix, uint64_t mask) { if (mask \u0026amp; ThreadHost::Type::Platform) { platform_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.platform\u0026quot;); } if (mask \u0026amp; ThreadHost::Type::UI) { //创建线程 [见小节2.2] ui_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.ui\u0026quot;); } if (mask \u0026amp; ThreadHost::Type::GPU) { gpu_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.gpu\u0026quot;); } if (mask \u0026amp; ThreadHost::Type::IO) { io_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026quot;.io\u0026quot;); } } TaskRunner初始化\n[-\u0026gt; flutter/fml/task_runner.cc] TaskRunner::TaskRunner(fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop) : loop_(std::move(loop)) {} Flutter引擎启动过程，会创建UI/GPU/IO这3个线程，并且会为每个线程依次创建MessageLoop对象，启动后处于epoll_wait等待状态。对于Flutter的消息机制跟Android原生的消息机制有很多相似之处，都有消息(或者任务)、消息队列以及Looper，有一点不同的是Android有一个Handler类，用于发送消息以及执行回调方法，相对应Flutter中有着相近功能的便是TaskRunner。\n上图是从源码中提炼而来的任务处理流程，比官方流程图更容易理解一些复杂流程的时序问题，后续会专门讲解个中原由。Flutter的任务队列处理机制跟Android的消息队列处理相通，只不过Flutter分为Task和MicroTask两种类型，引擎和Dart虚拟机的事件以及Future都属于Task，Dart层执行scheduleMicrotask()所产生的属于Microtask。\n每次Flutter引擎在消费任务时调用FlushTasks()方法，遍历整个延迟任务队列delayed_tasks_，将已到期的任务加入task队列，然后开始处理任务。\n Step 1: 检查task，当task队列不为空，先执行一个task； Step 2: 检查microTask，当microTask不为空，则执行microTask；不断循环Step 2 直到microTask队列为空，再回到执行Step 1；  可简单理解为先处理完所有的Microtask，然后再处理Task。因为scheduleMicrotask()方法的调用自身就处于一个Task，执行完当前的task，也就意味着马上执行该Microtask。\n了解了其工作机制，再来看看这4个Task Runner的具体工作内容。\n Platform Task Runner：运行在Android或者iOS的主线程，尽管阻塞该线程并不会影响Flutter渲染管道，平台线程建议不要执行耗时操作；否则可能触发watchdog来结束该应用。比如Android、iOS都是使用平台线程来传递用户输入事件，一旦平台线程被阻塞则会引起手势事件丢失。 UI Task Runner: 运行在ui线程，比如1.ui，用于引擎执行root isolate中的所有Dart代码，执行渲染与处理Vsync信号，将widget转换生成Layer Tree。除了渲染之外，还有处理Native Plugins消息、Timers、Microtasks等工作； GPU Task Runner：运行在gpu线程，比如1.gpu，用于将Layer Tree转换为具体GPU指令，执行设备GPU相关的skia调用，转换相应平台的绘制方式，比如OpenGL, vulkan, metal等。每一帧的绘制需要UI Runner和GPU Runner配合完成，任何一个环节延迟都可能导致掉帧； IO Task Runner：运行在io线程，比如1.io，前3个Task Runner都不允许执行耗时操作，该Runner用于将图片从磁盘读取出来，解压转换为GPU可识别的格式后，再上传给GPU线程。为了能访问GPU，IO Runner跟GPU Runner的Context在同一个ShareGroup。比如ui.image通过异步调用让IO Runner来异步加载图片，该线程不能执行其他耗时操作，否则可能会影响图片加载的性能。  深入理解Flutter异步Future机制\n深入理解Flutter的Isolate创建过程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/google/",
	"title": "google",
	"tags": [],
	"description": "",
	"content": "google 探索总结google知识\n supportToAndroidx     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/google/supporttoandroidx/",
	"title": "supportToAndroidx",
	"tags": [],
	"description": "",
	"content": "升级背景 为了升级公司客户端架构，促进更高效的开发效率，减少模板代码并提升稳定性，需要基础仓库从support迁移到androidx，并提供相应的升级方案以及基于androidx的基础组件。\n模块拆分方式命名   不依赖support/androidx的模块称为pure模块\n  依赖support的称为support模块\n  依赖androidx的称为androidx模块\n  升级方案  module内部，将原本的基础仓库old base module拆分为base_support + base_pure两个模块，剥离support依赖。其中base_pure模块拆分到一个单独的project中，而base_support项目需要新增base_androidx branch，分开两个branch迭代，并通过cherrypick进行修改同步，同时分别发布独立的maven。 old base module所依赖的模块，也需要按照1的方式进行拆分。同时pure模块只能依赖pure模块,非pure模块可以依赖对应的非pure模块和pure模块 pure模块的单测test模块是support或者androidx都没关系，不影响发版仓库中的内容 androidx利用灰度版本去进行测试  包依赖关系 graph TB app_support--\u0026gt;base_support app_support--\u0026gt;base_pure app_androidx--\u0026gt;base_androidx app_androidx--\u0026gt;base_pure base_pure--\u0026gt;xxx_pure base_support--\u0026gt;xxx_support base_support--\u0026gt;xxx_pure base_androidx--\u0026gt;xxx_androidx base_androidx--\u0026gt;xxx_pure 升级步骤 https://developer.android.google.cn/jetpack/androidx/migrate?hl=zh-cn\nhttps://medium.com/androiddevelopers/migrating-to-androidx-tip-tricks-and-guidance-88d5de238876\n是时候迁移至 AndroidX 了！\ngraph LR olderSupport--\u0026gt;|APIchanges|28.0.0Support--\u0026gt;|namespaceChanges|androidx1.0  创建新分支准备迁移，停止同步进行的新功能开发和重构，防止冲突 在old base module中搜索support进行处理,去除不必要的support库依赖 support升级到28，这是因为，1.0.0 版本的 AndroidX 工件是与支持库 28.0.0 工件等效的二进制文件。 编译和测试用例通过 配置android.useAndroidX=true android.enableJetifier=true 更新依赖的仓库到支持androidx的版本 迁移到androidx: AS操作 Refactor \u0026gt; Migrate to AndroidX  基于androidx的后续基础架构封装 新架构单独封装一个独立的module(使用androidx)，提供基础能力\n"
},
{
	"uri": "https://huanle19891345.github.io/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/",
	"title": "技术探索总结",
	"tags": [],
	"description": "",
	"content": "技术探索总结 探索客户端技术背后的原理细节\n android    google    supportToAndroidx      系统机制原理    系统绘制    硬件加速绘制Source     软件绘制        跨平台    flutter      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E7%BB%98%E5%88%B6source/",
	"title": "硬件加速绘制Source",
	"tags": [],
	"description": "",
	"content": "RenderPipeLine类设计 graph TB IRenderPipeline--\u0026gt;OpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaOpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaVulkanPipeline RenderThread继承结构 graph TB Thread--\u0026gt;ThreadBase ThreadBase--\u0026gt;ReanderThread 流程研究 frameworks/base/core/java/android/view/IWindow.aidl\nIWindow /** * API back to a client window that the Window Manager uses to inform it of * interesting things happening. * * {@hide} */ oneway interface IWindow {} frameworks/base/core/java/android/view/IWindowSession.aidl\nIWindowSession /** * System private per-application interface to the window manager. * * {@hide} */ interface IWindowSession {} ViewRootImpl // These can be accessed by any thread, must be protected with a lock.  // Surface can never be reassigned or cleared (use Surface.clear()).  public final Surface mSurface = new Surface(); setView /** * We have one child */ public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) { // If the application owns the surface, don\u0026#39;t enable hardware acceleration  if (mSurfaceHolder == null) { // While this is supposed to enable only, it can effectively disable  // the acceleration too.  enableHardwareAcceleration(attrs); } // Schedule the first layout -before- adding to the window  // manager, to make sure we do the relayout before receiving  // any other events from the system.  requestLayout(); //mWindowSession是一个aidl，ViewRootImpl利用它来和WindowManagerService交互  //mWindow是一个aidl，WindowManagerService可以利用这个对象与服务端交互  res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); } enableHardwareAcceleration private void enableHardwareAcceleration(WindowManager.LayoutParams attrs) { // Try to enable hardware acceleration if requested  final boolean hardwareAccelerated = (attrs.flags \u0026amp; WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED) != 0; if (hardwareAccelerated) { mAttachInfo.mThreadedRenderer = ThreadedRenderer.create(mContext, translucent, attrs.getTitle().toString()); if (mAttachInfo.mThreadedRenderer != null) { mAttachInfo.mHardwareAccelerated = mAttachInfo.mHardwareAccelerationRequested = true; } } } draw private boolean draw(boolean fullRedrawNeeded) { Surface surface = mSurface; if (!surface.isValid()) { return false; } if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { if (mAttachInfo.mThreadedRenderer != null \u0026amp;\u0026amp; mAttachInfo.mThreadedRenderer.isEnabled()) { mAttachInfo.mThreadedRenderer.draw(mView, mAttachInfo, this, callback); } else { drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty, surfaceInsets) } } } threadedrenderer\ndrawSoftware /** * @return true if drawing was successful, false if an error occurred */ private boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty, Rect surfaceInsets) { // Draw with software renderer.  final Canvas canvas; canvas = mSurface.lockCanvas(dirty); ...... mView.draw(canvas); ...... surface.unlockCanvasAndPost(canvas); } lockcanvas\nnativeunlockcanvasandpost\nperformTraversals private void performTraversals() { // Execute enqueued actions on every traversal in case a detached view enqueued an action  host.dispatchAttachedToWindow(mAttachInfo, 0); relayoutResult = relayoutWindow(params, viewVisibility, insetsPending); if (mSurface.isValid()) { // If we are creating a new surface, then we need to  // completely redraw it. Also, when we get to the  // point of drawing it we will hold off and schedule  // a new traversal instead. This is so we can tell the  // window manager about all of the windows being displayed  // before actually drawing them, so it can display then  // all at once.  newSurface = true; mFullRedrawNeeded = true; mPreviousTransparentRegion.setEmpty(); // Only initialize up-front if transparent regions are not  // requested, otherwise defer to see if the entire window  // will be transparent  if (mAttachInfo.mThreadedRenderer != null) { hwInitialized = mAttachInfo.mThreadedRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { // Don\u0026#39;t pre-allocate if transparent regions  // are requested as they may not be needed  mSurface.allocateBuffers(); } } } // Ask host how big it wants to be  performMeasure(childWidthMeasureSpec, childHeightMeasureSpec); ...... performLayout(lp, mWidth, mHeight); ...... performDraw(); ThreadedRenderer surface\nrelayoutWindow private int relayoutWindow(WindowManager.LayoutParams params, int viewVisibility, boolean insetsPending) throws RemoteException { int relayoutResult = mWindowSession.relayout(mWindow, mSeq, params, (int) (mView.getMeasuredWidth() * appScale + 0.5f), (int) (mView.getMeasuredHeight() * appScale + 0.5f), viewVisibility, insetsPending ? WindowManagerGlobal.RELAYOUT_INSETS_PENDING : 0, frameNumber, mWinFrame, mPendingOverscanInsets, mPendingContentInsets, mPendingVisibleInsets, mPendingStableInsets, mPendingOutsets, mPendingBackDropFrame, mPendingDisplayCutout, mPendingMergedConfiguration, mSurface); } frameworks/base/services/core/java/com/android/server/wm/Session.java\nSession addToDisplay @Override public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId, outFrame, outContentInsets, outStableInsets, outOutsets, outDisplayCutout, outInputChannel); } windowAddedLocked void windowAddedLocked(String packageName) { if (mSurfaceSession == null) { mSurfaceSession = new SurfaceSession(); mService.mSessions.add(this); } } relayout @Override public int relayout(IWindow window, int seq, WindowManager.LayoutParams attrs, int requestedWidth, int requestedHeight, int viewFlags, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper cutout, MergedConfiguration mergedConfiguration, Surface outSurface) { int res = mService.relayoutWindow(this, window, seq, attrs, requestedWidth, requestedHeight, viewFlags, flags, frameNumber, outFrame, outOverscanInsets, outContentInsets, outVisibleInsets, outStableInsets, outsets, outBackdropFrame, cutout, mergedConfiguration, outSurface); return res; } frameworks/base/services/core/java/com/android/server/wm/WindowManagerService.java\nWindowManagerService addWindow public int addWindow(Session session, IWindow client, int seq, LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { //WindowState用来描述一个Window  //生成WindowState对象，它是ViewRootImpl 在WindowManager Service端的代表。在它的构造函数里，WindowState 会生成IWindowId.Stub 对象和DeathRecipient对象来分别监听Focus和窗口死亡的信息  final WindowState win = new WindowState(this, session, client, token, parentWindow, appOp[0], seq, attrs, viewVisibility, session.mUid, session.mCanAddInternalSystemWindow); //创建用于通信的SocketPair , 将其传给InputManagerService, 用于接下来的用户输入事件对应的响应窗口（参考Android的用户输入处理）  final boolean openInputChannels = (outInputChannel != null \u0026amp;\u0026amp; (attrs.inputFeatures \u0026amp; INPUT_FEATURE_NO_INPUT_CHANNEL) == 0); if (openInputChannels) { win.openInputChannel(outInputChannel); } //创建了一个Surface Session 并将Surface Session，WindowSession 还有WindowState 三者关联起来.  win.attach(); //mWindowMap是WindowManagerService用来保存当前所有Window新的的集合  mWindowMap.put(client.asBinder(), win); //一个token下会有多个win state。 其实token与PhoneWindow是一一对应的。  win.mToken.addWindow(win); } relayoutWindow public int relayoutWindow(Session session, IWindow client, int seq, LayoutParams attrs, int requestedWidth, int requestedHeight, int viewVisibility, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outOutsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper outCutout, MergedConfiguration mergedConfiguration, Surface outSurface) { result = createSurfaceControl(outSurface, result, win, winAnimator); } createSurfaceControl private int createSurfaceControl(Surface outSurface, int result, WindowState win,WindowStateAnimator winAnimator) { ... surfaceController = winAnimator.createSurfaceLocked(win.mAttrs.type, win.mOwnerUid); ... surfaceController.getSurface(outSurface); } WindowStateAnimator createSurfaceLocked WindowSurfaceController createSurfaceLocked(int windowType, int ownerUid) { mSurfaceController = new WindowSurfaceController(mSession.mSurfaceSession, attrs.getTitle().toString(), width, height, format, flags, this, windowType, ownerUid); } WindowSurfaceController SurfaceControl mSurfaceControl; public WindowSurfaceController(SurfaceSession s, String name, int w, int h, int format, int flags, WindowStateAnimator animator, int windowType, int ownerUid) { final SurfaceControl.Builder b = win.makeSurface() .setParent(win.getSurfaceControl()) .setName(name) .setSize(w, h) .setFormat(format) .setFlags(flags) .setMetadata(windowType, ownerUid); mSurfaceControl = b.build(); } getSurface void getSurface(Surface outSurface) { outSurface.copyFrom(mSurfaceControl); } copyfrom\nSurfaceControl.java Builder.build /** * Construct a new {@link SurfaceControl} with the set parameters. */ public SurfaceControl build() { return new SurfaceControl(mSession, mName, mWidth, mHeight, mFormat, mFlags, mParent, mWindowType, mOwnerUid); } /** Good practice is to first create the surface with the {@link #HIDDEN} flag * specified, open a transaction, set the surface layer, layer stack, alpha, * and position, call {@link #show} if appropriate, and close the transaction. **/ private SurfaceControl(SurfaceSession session, String name, int w, int h, int format, int flags, SurfaceControl parent, int windowType, int ownerUid) throws OutOfResourcesException, IllegalArgumentException { mNativeObject = nativeCreate(session, name, w, h, format, flags, parent != null ? parent.mNativeObject : 0, windowType, ownerUid); } frameworks/base/core/jni/android_view_SurfaceControl.cpp\nandroid_view_SurfaceControl nativeCreate static jlong nativeCreate(JNIEnv* env, jclass clazz, jobject sessionObj, jstring nameStr, jint w, jint h, jint format, jint flags, jlong parentObject, jint windowType, jint ownerUid) { ScopedUtfChars name(env, nameStr); //这个client其实就是前面创建的SurfaceComposerClinent  sp\u0026lt;SurfaceComposerClient\u0026gt; client(android_view_SurfaceSession_getClient(env, sessionObj)); SurfaceControl *parent = reinterpret_cast\u0026lt;SurfaceControl*\u0026gt;(parentObject); sp\u0026lt;SurfaceControl\u0026gt; surface; status_t err = client-\u0026gt;createSurfaceChecked( String8(name.c_str()), w, h, format, \u0026amp;surface, flags, parent, windowType, ownerUid); surface-\u0026gt;incStrong((void *)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } frameworks/base/services/core/java/com/android/server/wm/WindowState.java\nWindowState openInputChannel void openInputChannel(InputChannel outInputChannel) { if (mInputChannel != null) { throw new IllegalStateException(\u0026#34;Window already has an input channel.\u0026#34;); } String name = getName(); InputChannel[] inputChannels = InputChannel.openInputChannelPair(name);//refer to TouchEventNative.md  mInputChannel = inputChannels[0]; mClientChannel = inputChannels[1]; mInputWindowHandle.inputChannel = inputChannels[0]; if (outInputChannel != null) { mClientChannel.transferTo(outInputChannel); mClientChannel.dispose(); mClientChannel = null; } else { // If the window died visible, we setup a dummy input channel, so that taps  // can still detected by input monitor channel, and we can relaunch the app.  // Create dummy event receiver that simply reports all events as handled.  mDeadWindowEventReceiver = new DeadWindowEventReceiver(mClientChannel); } mService.mInputManager.registerInputChannel(mInputChannel, mInputWindowHandle);//refer to TouchEventNative.md  } attach void attach() { mSession.windowAddedLocked(mAttrs.packageName); } SurfaceSession /** * An instance of this class represents a connection to the surface * flinger, from which you can create one or more Surface instances that will * be composited to the screen. */ public final class SurfaceSession { // Note: This field is accessed by native code.  private long mNativeClient; // SurfaceComposerClient* } SurfaceSession() /** Create a new connection with the surface flinger. */ public SurfaceSession() { mNativeClient = nativeCreate(); } frameworks/base/core/jni/android_view_SurfaceSession.cpp\nandroid_view_SurfaceSession.cpp nativeCreate static jlong nativeCreate(JNIEnv* env, jclass clazz) { SurfaceComposerClient* client = new SurfaceComposerClient(); client-\u0026gt;incStrong((void*)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(client); } SurfaceComposerClient onFirstRef void SurfaceComposerClient::onFirstRef() { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService());//sf 就是SurfaceFlinger Service  if (sf != 0 \u0026amp;\u0026amp; mStatus == NO_INIT) { auto rootProducer = mParent.promote(); sp\u0026lt;ISurfaceComposerClient\u0026gt; conn; conn = (rootProducer != nullptr) ? sf-\u0026gt;createScopedConnection(rootProducer) : sf-\u0026gt;createConnection(); if (conn != 0) { mClient = conn; mStatus = NO_ERROR; } } } createSurfaceChecked status_t SurfaceComposerClient::createSurfaceChecked( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, sp\u0026lt;SurfaceControl\u0026gt;* outSurface, uint32_t flags, SurfaceControl* parent, int32_t windowType, int32_t ownerUid) { sp\u0026lt;SurfaceControl\u0026gt; sur; sp\u0026lt;IBinder\u0026gt; handle; sp\u0026lt;IBinder\u0026gt; parentHandle; sp\u0026lt;IGraphicBufferProducer\u0026gt; gbp; if (parent != nullptr) { parentHandle = parent-\u0026gt;getHandle(); } err = mClient-\u0026gt;createSurface(name, w, h, format, flags, parentHandle, windowType, ownerUid, \u0026amp;handle, \u0026amp;gbp); if (err == NO_ERROR) { *outSurface = new SurfaceControl(this, handle, gbp, true /* owned */); } return err; } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\nSurfaceFlinger createConnection sp\u0026lt;ISurfaceComposerClient\u0026gt; SurfaceFlinger::createConnection() { return initClient(new Client(this)); } createLayer status_t SurfaceFlinger::createLayer( const String8\u0026amp; name, const sp\u0026lt;Client\u0026gt;\u0026amp; client, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* parent) { sp\u0026lt;Layer\u0026gt; layer; String8 uniqueName = getUniqueLayerName(name); switch (flags \u0026amp; ISurfaceComposerClient::eFXSurfaceMask) { case ISurfaceComposerClient::eFXSurfaceNormal: result = createBufferLayer(client, uniqueName, w, h, flags, format, handle, gbp, \u0026amp;layer); break; } result = addClientLayer(client, *handle, *gbp, layer, *parent); return result; } createBufferLayer status_t SurfaceFlinger::createBufferLayer(const sp\u0026lt;Client\u0026gt;\u0026amp; client, const String8\u0026amp; name, uint32_t w, uint32_t h, uint32_t flags, PixelFormat\u0026amp; format, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* outLayer) { // initialize the surfaces  switch (format) { case PIXEL_FORMAT_TRANSPARENT: case PIXEL_FORMAT_TRANSLUCENT: format = PIXEL_FORMAT_RGBA_8888; break; case PIXEL_FORMAT_OPAQUE: format = PIXEL_FORMAT_RGBX_8888; break; } sp\u0026lt;BufferLayer\u0026gt; layer = new BufferLayer(this, client, name, w, h, flags); status_t err = layer-\u0026gt;setBuffers(w, h, format, flags); if (err == NO_ERROR) { *handle = layer-\u0026gt;getHandle(); *gbp = layer-\u0026gt;getProducer(); *outLayer = layer; } return err; } frameworks/native/services/surfaceflinger/BufferLayer.cpp\nBufferLayer getProducer sp\u0026lt;IGraphicBufferProducer\u0026gt; BufferLayer::getProducer() const { return mProducer; } onFirstRef void BufferLayer::onFirstRef() { // Creates a custom BufferQueue for SurfaceFlingerConsumer to use  sp\u0026lt;IGraphicBufferProducer\u0026gt; producer; sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer; BufferQueue::createBufferQueue(\u0026amp;producer, \u0026amp;consumer, true); //MonitoredProducer只是一个装饰类，它实际功能都委托给构造它的参数producer  mProducer = new MonitoredProducer(producer, mFlinger, this); mConsumer = new BufferLayerConsumer(consumer, mFlinger-\u0026gt;getRenderEngine(), mTextureName, this); const sp\u0026lt;const DisplayDevice\u0026gt; hw(mFlinger-\u0026gt;getDefaultDisplayDevice()); updateTransformHint(hw); } frameworks/native/libs/gui/BufferQueue.cpp\nBufferQueue createBufferQueue void BufferQueue::createBufferQueue(sp\u0026lt;IGraphicBufferProducer\u0026gt;* outProducer, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* outConsumer, bool consumerIsSurfaceFlinger) { sp\u0026lt;BufferQueueCore\u0026gt; core(new BufferQueueCore()); sp\u0026lt;IGraphicBufferProducer\u0026gt; producer(new BufferQueueProducer(core, consumerIsSurfaceFlinger)); sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer(new BufferQueueConsumer(core)); *outProducer = producer; *outConsumer = consumer; } frameworks/native/libs/gui/include/gui/BufferQueueCore.h\nBufferQueueCore // mQueue is a FIFO of queued buffers used in synchronous mode.  Fifo mQueue; // mFreeSlots contains all of the slots which are FREE and do not currently  // have a buffer attached.  std::set\u0026lt;int\u0026gt; mFreeSlots; // mFreeBuffers contains all of the slots which are FREE and currently have  // a buffer attached.  std::list\u0026lt;int\u0026gt; mFreeBuffers; // mConsumerListener is used to notify the connected consumer of  // asynchronous events that it may wish to react to. It is initially  // set to NULL and is written by consumerConnect and consumerDisconnect.  sp\u0026lt;IConsumerListener\u0026gt; mConsumerListener; frameworks/native/libs/gui/BufferQueueProducer.cpp\nBufferQueueProducer class BufferQueueProducer : public BnGraphicBufferProducer, private IBinder::DeathRecipient { dequeueBuffer status_t BufferQueueProducer::dequeueBuffer(int* outSlot, sp\u0026lt;android::Fence\u0026gt;* outFence, uint32_t width, uint32_t height, PixelFormat format, uint64_t usage, uint64_t* outBufferAge, FrameEventHistoryDelta* outTimestamps) { int found = BufferItem::INVALID_BUFFER_SLOT; while (found == BufferItem::INVALID_BUFFER_SLOT) { status_t status = waitForFreeSlotThenRelock(FreeSlotCaller::Dequeue, \u0026amp;found); } const sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; buffer(mSlots[found].mGraphicBuffer); *outSlot = found; if ((buffer == NULL) || buffer-\u0026gt;needsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { returnFlags |= BUFFER_NEEDS_REALLOCATION; } if (returnFlags \u0026amp; BUFFER_NEEDS_REALLOCATION) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( width, height, format, BQ_LAYER_COUNT, usage, {mConsumerName.string(), mConsumerName.size()}); status_t error = graphicBuffer-\u0026gt;initCheck(); } } graphicbuffer\nwaitForFreeSlotThenRelock status_t BufferQueueProducer::waitForFreeSlotThenRelock(FreeSlotCaller caller, int* found) const { // If we disconnect and reconnect quickly, we can be in a state where  // our slots are empty but we have many buffers in the queue. This can  // cause us to run out of memory if we outrun the consumer. Wait here if  // it looks like we have too many buffers queued up.  const int maxBufferCount = mCore-\u0026gt;getMaxBufferCountLocked(); bool tooManyBuffers = mCore-\u0026gt;mQueue.size() \u0026gt; static_cast\u0026lt;size_t\u0026gt;(maxBufferCount); if (tooManyBuffers) { BQ_LOGV(\u0026#34;%s: queue size is %zu, waiting\u0026#34;, callerString, mCore-\u0026gt;mQueue.size()); } else { // If in shared buffer mode and a shared buffer exists, always  // return it.  if (mCore-\u0026gt;mSharedBufferMode \u0026amp;\u0026amp; mCore-\u0026gt;mSharedBufferSlot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = mCore-\u0026gt;mSharedBufferSlot; } else { if (caller == FreeSlotCaller::Dequeue) { // If we\u0026#39;re calling this from dequeue, prefer free buffers  int slot = getFreeBufferLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else if (mCore-\u0026gt;mAllowAllocation) { *found = getFreeSlotLocked(); } } else { // If we\u0026#39;re calling this from attach, prefer free slots  int slot = getFreeSlotLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else { *found = getFreeBufferLocked(); } } } } } getFreeBufferLocked int BufferQueueProducer::getFreeBufferLocked() const { if (mCore-\u0026gt;mFreeBuffers.empty()) { return BufferQueueCore::INVALID_BUFFER_SLOT; } int slot = mCore-\u0026gt;mFreeBuffers.front(); mCore-\u0026gt;mFreeBuffers.pop_front(); return slot; } requestBuffer status_t BufferQueueProducer::requestBuffer(int slot, sp\u0026lt;GraphicBuffer\u0026gt;* buf) { mSlots[slot].mRequestBufferCalled = true; *buf = mSlots[slot].mGraphicBuffer; } allocateBuffers void BufferQueueProducer::allocateBuffers(uint32_t width, uint32_t height, PixelFormat format, uint64_t usage) { Vector\u0026lt;sp\u0026lt;GraphicBuffer\u0026gt;\u0026gt; buffers; for (size_t i = 0; i \u0026lt; newBufferCount; ++i) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( allocWidth, allocHeight, allocFormat, BQ_LAYER_COUNT, allocUsage, allocName); status_t result = graphicBuffer-\u0026gt;initCheck(); buffers.push_back(graphicBuffer); } } graphicbuffer\nframeworks/native/libs/gui/include/gui/BufferQueueConsumer.h\nBufferQueueConsumer class BufferQueueConsumer : public BnGraphicBufferConsumer { // connect connects a consumer to the BufferQueue. Only one  // consumer may be connected, and when that consumer disconnects the  // BufferQueue is placed into the \u0026#34;abandoned\u0026#34; state, causing most  // interactions with the BufferQueue by the producer to fail.  // controlledByApp indicates whether the consumer is controlled by  // the application.  //  // consumerListener may not be NULL.  virtual status_t connect(const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp); } status_t BufferQueueConsumer::connect( const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp) { mCore-\u0026gt;mConsumerListener = consumerListener; mCore-\u0026gt;mConsumerControlledByApp = controlledByApp; return NO_ERROR; } frameworks/native/services/surfaceflinger/Client.h\nClient class Client : public BnSurfaceComposerClient { public: ... void attachLayer(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle, const sp\u0026lt;Layer\u0026gt;\u0026amp; layer); void detachLayer(const Layer* layer); ... private: // ISurfaceComposerClient interface。 gbp很重要，它维护这一个应用程序的渲染 Buffer队列  virtual status_t createSurface(...sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp); virtual status_t destroySurface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle); //跨进程通信方法  virtual status_t onTransact(uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags); ... // constant  sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; // protected by mLock  DefaultKeyedVector\u0026lt; wp\u0026lt;IBinder\u0026gt;, wp\u0026lt;Layer\u0026gt; \u0026gt; mLayers; // 一个应用程序的所有Layer  ... }; createSurface status_t Client::createSurface( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, const sp\u0026lt;IBinder\u0026gt;\u0026amp; parentHandle, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp) { //postMessageSync到surfaceFlinger的主线程中处理消息任务，如下:  result = flinger-\u0026gt;createLayer(name, client, w, h, format, flags, windowType, ownerUid, handle, gbp, parent); } Surface /** * Handle onto a raw buffer that is being managed by the screen compositor. * * \u0026lt;p\u0026gt;A Surface is generally created by or from a consumer of image buffers (such as a * {@link android.graphics.SurfaceTexture}, {@link android.media.MediaRecorder}, or * {@link android.renderscript.Allocation}), and is handed to some kind of producer (such as * {@link android.opengl.EGL14#eglCreateWindowSurface(android.opengl.EGLDisplay,android.opengl.EGLConfig,java.lang.Object,int[],int) OpenGL}, * {@link android.media.MediaPlayer#setSurface MediaPlayer}, or * {@link android.hardware.camera2.CameraDevice#createCaptureSession CameraDevice}) to draw * into.\u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Note:\u0026lt;/strong\u0026gt; A Surface acts like a * {@link java.lang.ref.WeakReference weak reference} to the consumer it is associated with. By * itself it will not keep its parent consumer from being reclaimed.\u0026lt;/p\u0026gt; */ public class Surface implements Parcelable { } copyFrom /** * Copy another surface to this one. This surface now holds a reference * to the same data as the original surface, and is -not- the owner. * This is for use by the window manager when returning a window surface * back from a client, converting it from the representation being managed * by the window manager to the representation the client uses to draw * in to it. * * @param other {@link SurfaceControl} to copy from. * */ public void copyFrom(SurfaceControl other) { long surfaceControlPtr = other.mNativeObject; long newNativeObject = nativeGetFromSurfaceControl(surfaceControlPtr); synchronized (mLock) { if (mNativeObject != 0) { nativeRelease(mNativeObject); } setNativeObjectLocked(newNativeObject); } } nativegetfromsurfacecontrol\nallocateBuffers /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } nativeallocatebuffers\ncome from performtraversals\nlockCanvas public Canvas lockCanvas(Rect inOutDirty) throws Surface.OutOfResourcesException, IllegalArgumentException { synchronized (mLock) { mLockedObject = nativeLockCanvas(mNativeObject, mCanvas, inOutDirty); return mCanvas; } } nativelockcanvas\nframeworks/base/core/jni/android_view_Surface.cpp\nandroid_view_Surface nativeGetFromSurfaceControl static jlong nativeGetFromSurfaceControl(JNIEnv* env, jclass clazz, jlong surfaceControlNativeObj) { /* * This is used by the WindowManagerService just after constructing * a Surface and is necessary for returning the Surface reference to * the caller. At this point, we should only have a SurfaceControl. */ sp\u0026lt;SurfaceControl\u0026gt; ctrl(reinterpret_cast\u0026lt;SurfaceControl *\u0026gt;(surfaceControlNativeObj)); sp\u0026lt;Surface\u0026gt; surface(ctrl-\u0026gt;getSurface()); if (surface != NULL) { surface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); } return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } surfacecontrol\nnativeAllocateBuffers static void nativeAllocateBuffers(JNIEnv* /* env */ , jclass /* clazz */, jlong nativeObject) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } surface-\u0026gt;allocateBuffers(); } surface.cpp\nnativeLockCanvas static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ANativeWindow_Buffer outBuffer; status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType, GraphicsJNI::defaultColorSpace()); SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits); } Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); if (dirtyRectPtr) { nativeCanvas-\u0026gt;clipRect(dirtyRect.left, dirtyRect.top, dirtyRect.right, dirtyRect.bottom, SkClipOp::kIntersect); } // Create another reference to the surface and return it. This reference  // should be passed to nativeUnlockCanvasAndPost in place of mNativeObject,  // because the latter could be replaced while the surface is locked.  sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } lock\nnativeUnlockCanvasAndPost static void nativeUnlockCanvasAndPost(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } // detach the canvas from the surface  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); nativeCanvas-\u0026gt;setBitmap(SkBitmap()); // unlock surface  status_t err = surface-\u0026gt;unlockAndPost(); } frameworks/native/libs/gui/SurfaceControl.cpp\nSurfaceControl getSurface sp\u0026lt;Surface\u0026gt; SurfaceControl::getSurface() const { Mutex::Autolock _l(mLock); if (mSurfaceData == 0) { return generateSurfaceLocked(); } return mSurfaceData; } generateSurfaceLocked sp\u0026lt;Surface\u0026gt; SurfaceControl::generateSurfaceLocked() const { // This surface is always consumed by SurfaceFlinger, so the  // producerControlledByApp value doesn\u0026#39;t matter; using false.  //这个mGraphicBufferProducer其实就是上面分析的BufferQueueProducer  mSurfaceData = new Surface(mGraphicBufferProducer, false); return mSurfaceData; } frameworks/native/libs/gui/Surface.cpp\nSurface.cpp struct BufferSlot // mSurfaceTexture is the interface to the surface texture server. All  // operations on the surface texture client ultimately translate into  // interactions with the server using this interface.  sp\u0026lt;IGraphicBufferProducer\u0026gt; mGraphicBufferProducer; struct BufferSlot { sp\u0026lt;GraphicBuffer\u0026gt; buffer; Region dirtyRegion; }; // mSlots stores the buffers that have been allocated for each buffer slot.  // It is initialized to null pointers, and gets filled in with the result of  // IGraphicBufferProducer::requestBuffer when the client dequeues a buffer from a  // slot that has not yet been used. The buffer allocated to a slot will also  // be replaced if the requested buffer usage or geometry differs from that  // of the buffer allocated to a slot.  BufferSlot mSlots[NUM_BUFFER_SLOTS]; Surface() Surface::Surface(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp; bufferProducer, bool controlledByApp) : mGraphicBufferProducer(bufferProducer), allocateBuffers void Surface::allocateBuffers() { uint32_t reqWidth = mReqWidth ? mReqWidth : mUserWidth; uint32_t reqHeight = mReqHeight ? mReqHeight : mUserHeight; mGraphicBufferProducer-\u0026gt;allocateBuffers(reqWidth, reqHeight, mReqFormat, mReqUsage); } bufferqueueproducer\nlock status_t Surface::lock(ANativeWindow_Buffer* outBuffer, ARect* inOutDirtyBounds) { ANativeWindowBuffer* out; int fenceFd = -1; status_t err = dequeueBuffer(\u0026amp;out, \u0026amp;fenceFd); sp\u0026lt;GraphicBuffer\u0026gt; backBuffer(GraphicBuffer::getSelf(out)); status_t res = backBuffer-\u0026gt;lockAsync( GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN, newDirtyRegion.bounds(), \u0026amp;vaddr, fenceFd); mLockedBuffer = backBuffer; outBuffer-\u0026gt;width = backBuffer-\u0026gt;width; outBuffer-\u0026gt;height = backBuffer-\u0026gt;height; outBuffer-\u0026gt;stride = backBuffer-\u0026gt;stride; outBuffer-\u0026gt;format = backBuffer-\u0026gt;format; outBuffer-\u0026gt;bits = vaddr; } dequeueBuffer int Surface::dequeueBuffer(android_native_buffer_t** buffer, int* fenceFd) { status_t result = mGraphicBufferProducer-\u0026gt;dequeueBuffer(\u0026amp;buf, \u0026amp;fence, reqWidth, reqHeight, reqFormat, reqUsage, \u0026amp;mBufferAge, enableFrameTimestamps ? \u0026amp;frameTimestamps : nullptr); sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; gbuf(mSlots[buf].buffer); if ((result \u0026amp; IGraphicBufferProducer::BUFFER_NEEDS_REALLOCATION) || gbuf == nullptr) { result = mGraphicBufferProducer-\u0026gt;requestBuffer(buf, \u0026amp;gbuf); } *buffer = gbuf.get(); return OK; } requestbuffer\nframeworks/native/libs/ui/GraphicBuffer.cpp\nGraphicBuffer GraphicBuffer::GraphicBuffer(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t usage, std::string requestorName) : GraphicBuffer() { mInitCheck = initWithSize(inWidth, inHeight, inFormat, inLayerCount, usage, std::move(requestorName)); } com from dequeuebuffer\ninitWithSize status_t GraphicBuffer::initWithSize(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t inUsage, std::string requestorName) { GraphicBufferAllocator\u0026amp; allocator = GraphicBufferAllocator::get(); uint32_t outStride = 0; status_t err = allocator.allocate(inWidth, inHeight, inFormat, inLayerCount, inUsage, \u0026amp;handle, \u0026amp;outStride, mId, std::move(requestorName)); return err; } frameworks/native/libs/ui/GraphicBufferAllocator.cpp\nGraphicBufferAllocator GraphicBufferMapper\u0026amp; mMapper; const std::unique_ptr\u0026lt;const Gralloc2::Allocator\u0026gt; mAllocator; allocate status_t GraphicBufferAllocator::allocate(uint32_t width, uint32_t height, PixelFormat format, uint32_t layerCount, uint64_t usage, buffer_handle_t* handle, uint32_t* stride, uint64_t /*graphicBufferId*/, std::string requestorName) { Gralloc2::IMapper::BufferDescriptorInfo info = {}; info.width = width; info.height = height; info.layerCount = layerCount; info.format = static_cast\u0026lt;Gralloc2::PixelFormat\u0026gt;(format); info.usage = usage; Gralloc2::Error error = mAllocator-\u0026gt;allocate(info, stride, handle); } frameworks/native/libs/ui/include/ui/Gralloc2.h\nAllocator // A wrapper to IAllocator class Allocator { sp\u0026lt;IAllocator\u0026gt; mAllocator } Allocator::Allocator(const Mapper\u0026amp; mapper) : mMapper(mapper) { mAllocator = IAllocator::getService(); } allocate Error Allocator::allocate(BufferDescriptor descriptor, uint32_t count, uint32_t* outStride, buffer_handle_t* outBufferHandles) const { Error error; auto ret = mAllocator-\u0026gt;allocate(descriptor, count, [\u0026amp;](const auto\u0026amp; tmpError, const auto\u0026amp; tmpStride, const auto\u0026amp; tmpBuffers) { error = tmpError; if (tmpError != Error::NONE) { return; } // import buffers  for (uint32_t i = 0; i \u0026lt; count; i++) { error = mMapper.importBuffer(tmpBuffers[i], \u0026amp;outBufferHandles[i]); if (error != Error::NONE) { for (uint32_t j = 0; j \u0026lt; i; j++) { mMapper.freeBuffer(outBufferHandles[j]); outBufferHandles[j] = nullptr; } return; } } *outStride = tmpStride; }); // make sure the kernel driver sees BC_FREE_BUFFER and closes the fds now  hardware::IPCThreadState::self()-\u0026gt;flushCommands(); return (ret.isOk()) ? error : kTransactionError; } hardware/interfaces/graphics/allocator/2.0/IAllocator.hal\ninterface IAllocator /** * Allocates buffers with the properties specified by the descriptor. * * @param descriptor specifies the properties of the buffers to allocate. * @param count is the number of buffers to allocate. * @return error is NONE upon success. Otherwise, * BAD_DESCRIPTOR when the descriptor is invalid. * NO_RESOURCES when the allocation cannot be fulfilled at this * time. * UNSUPPORTED when any of the property encoded in the descriptor * is not supported. * @return stride is the number of pixels between two consecutive rows of * the buffers, when the concept of consecutive rows is defined. * Otherwise, it has no meaning. * @return buffers is an array of raw handles to the newly allocated * buffers. */ @entry @exit @callflow(next=\u0026#34;*\u0026#34;) allocate(BufferDescriptor descriptor, uint32_t count) generates (Error error, uint32_t stride, vec\u0026lt;handle\u0026gt; buffers); frameworks/native/libs/ui/include/ui/BufferQueueDefs.h\nBufferQueueDefs.h NUM_BUFFER_SLOTS namespace android { namespace BufferQueueDefs { // BufferQueue will keep track of at most this value of buffers.  // Attempts at runtime to increase the number of buffers past this  // will fail.  static constexpr int NUM_BUFFER_SLOTS = 64; } // namespace BufferQueueDefs } // namespace android  ThreadedRenderer create /** * Creates a threaded renderer using OpenGL. * * @param translucent True if the surface is translucent, false otherwise * * @return A threaded renderer backed by OpenGL. */ public static ThreadedRenderer create(Context context, boolean translucent, String name) { ThreadedRenderer renderer = null; if (isAvailable()) { renderer = new ThreadedRenderer(context, translucent, name); } return renderer; } ThreadedRenderer() ThreadedRenderer(Context context, boolean translucent, String name) { long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); mIsOpaque = !translucent; mNativeProxy = nCreateProxy(translucent, rootNodePtr); nSetName(mNativeProxy, name); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } initialize /** * Initializes the threaded renderer for the specified surface. * @param surface The surface to render * @return True if the initialization was successful, false otherwise. */ boolean initialize(Surface surface) throws OutOfResourcesException { updateEnabledState(surface); nInitialize(mNativeProxy, surface); return status; } android_view_threadedrenderer_initialize\nframeworks/base/core/jni/android_view_ThreadedRenderer.cpp\nandroid_view_ThreadedRenderer android_view_ThreadedRenderer_initialize static void android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;Surface\u0026gt; surface = android_view_Surface_getSurface(env, jsurface); proxy-\u0026gt;initialize(surface); } renderproxy\nAttachInfo /** * A set of information given to a view when it is attached to its parent * window. */ final static class AttachInfo { } RenderNode adopt /** * Adopts an existing native render node. */ public static RenderNode adopt(long nativePtr) { return new RenderNode(nativePtr); } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nandroid_view_ThreadedRenderer android_view_ThreadedRenderer_createRootRenderNode static jlong android_view_ThreadedRenderer_createRootRenderNode(JNIEnv* env, jobject clazz) { RootRenderNode* node = new RootRenderNode(env); node-\u0026gt;incStrong(0); node-\u0026gt;setName(\u0026#34;RootRenderNode\u0026#34;); return reinterpret_cast\u0026lt;jlong\u0026gt;(node); } android_view_ThreadedRenderer_createProxy static jlong android_view_ThreadedRenderer_createProxy(JNIEnv* env, jobject clazz, jboolean translucent, jlong rootRenderNodePtr) { RootRenderNode* rootRenderNode = reinterpret_cast\u0026lt;RootRenderNode*\u0026gt;(rootRenderNodePtr); ContextFactoryImpl factory(rootRenderNode); return (jlong) new RenderProxy(translucent, rootRenderNode, \u0026amp;factory); } android_view_ThreadedRenderer_syncAndDrawFrame static int android_view_ThreadedRenderer_syncAndDrawFrame(JNIEnv* env, jobject clazz, jlong proxyPtr, jlongArray frameInfo, jint frameInfoSize) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); env-\u0026gt;GetLongArrayRegion(frameInfo, 0, frameInfoSize, proxy-\u0026gt;frameInfo()); return proxy-\u0026gt;syncAndDrawFrame(); } frameworks/base/libs/hwui/renderthread/RenderProxy.cpp\nRenderProxy.cpp RenderProxy() RenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { mContext = mRenderThread.queue().runSync([\u0026amp;]() -\u0026gt; CanvasContext* { return CanvasContext::create(mRenderThread, translucent, rootRenderNode, contextFactory); }); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext, rootRenderNode); } canvascontext\ninitialize void RenderProxy::initialize(const sp\u0026lt;Surface\u0026gt;\u0026amp; surface) { mRenderThread.queue().post( [ this, surf = surface ]() mutable { mContext-\u0026gt;setSurface(std::move(surf)); }); } canvascontext\nsyncAndDrawFrame int RenderProxy::syncAndDrawFrame() { return mDrawFrameTask.drawFrame(); } drawframetask\nRenderThread getInstance RenderThread\u0026amp; RenderThread::getInstance() { // This is a pointer because otherwise __cxa_finalize  // will try to delete it like a Good Citizen but that causes us to crash  // because we don\u0026#39;t want to delete the RenderThread normally.  static RenderThread* sInstance = new RenderThread(); gHasRenderThreadInstance = true; return *sInstance; } RenderThread() RenderThread::RenderThread() : ThreadBase() , mVsyncSource(nullptr) , mVsyncRequested(false) , mFrameCallbackTaskPending(false) , mRenderState(nullptr) , mEglManager(nullptr) , mVkManager(nullptr) { Properties::load(); start(\u0026#34;RenderThread\u0026#34;); } threadLoop bool RenderThread::threadLoop() { setpriority(PRIO_PROCESS, 0, PRIORITY_DISPLAY); if (gOnStartHook) { gOnStartHook(); } initThreadLocals(); while (true) { waitForWork(); processQueue(); ...... requestVsync(); } return false; } initThreadLocals void RenderThread::initThreadLocals() { mDisplayInfo = DeviceInfo::queryDisplayInfo(); nsecs_t frameIntervalNanos = static_cast\u0026lt;nsecs_t\u0026gt;(1000000000 / mDisplayInfo.fps); mTimeLord.setFrameInterval(frameIntervalNanos); initializeDisplayEventReceiver(); mEglManager = new EglManager(*this); mRenderState = new RenderState(*this); mVkManager = new VulkanManager(*this); mCacheManager = new CacheManager(mDisplayInfo); } initializeDisplayEventReceiver void RenderThread::initializeDisplayEventReceiver() { LOG_ALWAYS_FATAL_IF(mVsyncSource, \u0026#34;Initializing a second DisplayEventReceiver?\u0026#34;); if (!Properties::isolatedProcess) { auto receiver = std::make_unique\u0026lt;DisplayEventReceiver\u0026gt;(); status_t status = receiver-\u0026gt;initCheck(); // Register the FD  mLooper-\u0026gt;addFd(receiver-\u0026gt;getFd(), 0, Looper::EVENT_INPUT, RenderThread::displayEventReceiverCallback, this); mVsyncSource = new DisplayEventReceiverWrapper(std::move(receiver)); } else { mVsyncSource = new DummyVsyncSource(this); } } frameworks/base/libs/hwui/thread/ThreadBase.h\nThreadBase waitForWork void waitForWork() { nsecs_t nextWakeup; { std::unique_lock lock{mLock}; nextWakeup = mQueue.nextWakeup(lock); } int timeout = -1; if (nextWakeup \u0026lt; std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max()) { timeout = ns2ms(nextWakeup - WorkQueue::clock::now()); if (timeout \u0026lt; 0) timeout = 0; } int result = mLooper-\u0026gt;pollOnce(timeout); LOG_ALWAYS_FATAL_IF(result == Looper::POLL_ERROR, \u0026#34;RenderThread Looper POLL_ERROR!\u0026#34;); } ThreadBase() ThreadBase() : Thread(false) , mLooper(new Looper(false)) , mQueue([this]() { mLooper-\u0026gt;wake(); }, mLock) {} processQueue void processQueue() { mQueue.process(); } frameworks/base/libs/hwui/thread/WorkQueue.h\nWorkQueue std::function\u0026lt;void()\u0026gt; mWakeFunc; std::vector\u0026lt;WorkItem\u0026gt; mWorkQueue; struct WorkItem struct WorkItem { nsecs_t runAt; std::function\u0026lt;void()\u0026gt; work; }; nextWakeup nsecs_t nextWakeup(std::unique_lock\u0026lt;std::mutex\u0026gt;\u0026amp; lock) { if (mWorkQueue.empty()) { return std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max(); } else { return std::begin(mWorkQueue)-\u0026gt;runAt; } } enqueue void enqueue(WorkItem\u0026amp;\u0026amp; item) { bool needsWakeup; { std::unique_lock _lock{mLock}; auto insertAt = std::find_if( std::begin(mWorkQueue), std::end(mWorkQueue), [time = item.runAt](WorkItem \u0026amp; item) { return item.runAt \u0026gt; time; }); needsWakeup = std::begin(mWorkQueue) == insertAt; mWorkQueue.emplace(insertAt, std::move(item)); } if (needsWakeup) { mWakeFunc(); } } process void process() { auto now = clock::now(); std::vector\u0026lt;WorkItem\u0026gt; toProcess; { std::unique_lock _lock{mLock}; if (mWorkQueue.empty()) return; toProcess = std::move(mWorkQueue); auto moveBack = find_if(std::begin(toProcess), std::end(toProcess), [\u0026amp;now](WorkItem\u0026amp; item) { return item.runAt \u0026gt; now; }); if (moveBack != std::end(toProcess)) { mWorkQueue.reserve(std::distance(moveBack, std::end(toProcess)) + 5); std::move(moveBack, std::end(toProcess), std::back_inserter(mWorkQueue)); toProcess.erase(moveBack, std::end(toProcess)); } } for (auto\u0026amp; item : toProcess) { item.work(); } } frameworks/base/libs/hwui/renderthread/CanvasContext.cpp\nCanvasContext create CanvasContext* CanvasContext::create(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) { auto renderType = Properties::getRenderPipelineType(); switch (renderType) { case RenderPipelineType::OpenGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;OpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaOpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaVulkan: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaVulkanPipeline\u0026gt;(thread)); default: LOG_ALWAYS_FATAL(\u0026#34;canvas context type %d not supported\u0026#34;, (int32_t)renderType); break; } return nullptr; } come from renderproxy\nCanvasContext() CanvasContext::CanvasContext(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory, std::unique_ptr\u0026lt;IRenderPipeline\u0026gt; renderPipeline) : mRenderThread(thread) , mGenerationID(0) , mOpaque(!translucent) , mAnimationContext(contextFactory-\u0026gt;createAnimationContext(mRenderThread.timeLord())) , mJankTracker(\u0026amp;thread.globalProfileData(), thread.mainDisplayInfo()) , mProfiler(mJankTracker.frames()) , mContentDrawBounds(0, 0, 0, 0) , mRenderPipeline(std::move(renderPipeline)) { rootRenderNode-\u0026gt;makeRoot(); mRenderNodes.emplace_back(rootRenderNode); mRenderThread.renderState().registerCanvasContext(this); mProfiler.setDensity(mRenderThread.mainDisplayInfo().density); } setSurface void CanvasContext::setSurface(sp\u0026lt;Surface\u0026gt;\u0026amp;\u0026amp; surface) { mNativeSurface = std::move(surface); ColorMode colorMode = mWideColorGamut ? ColorMode::WideColorGamut : ColorMode::Srgb; bool hasSurface = mRenderPipeline-\u0026gt;setSurface(mNativeSurface.get(), mSwapBehavior, colorMode); } called by renderproxy\ndraw void CanvasContext::draw() { mCurrentFrameInfo-\u0026gt;markIssueDrawCommandsStart(); Frame frame = mRenderPipeline-\u0026gt;getFrame(); SkRect windowDirty = computeDirtyRect(frame, \u0026amp;dirty); bool drew = mRenderPipeline-\u0026gt;draw(frame, windowDirty, dirty, mLightGeometry, \u0026amp;mLayerUpdateQueue, mContentDrawBounds, mOpaque, mWideColorGamut, mLightInfo, mRenderNodes, \u0026amp;(profiler())); bool didSwap = mRenderPipeline-\u0026gt;swapBuffers(frame, drew, windowDirty, mCurrentFrameInfo, \u0026amp;requireSwap); } frameworks/base/libs/hwui/FrameInfo.h\nFrameInfo FrameInfoIndex enum class FrameInfoIndex { Flags = 0, IntendedVsync, Vsync, OldestInputEvent, NewestInputEvent, HandleInputStart, AnimationStart, PerformTraversalsStart, DrawStart, // End of UI frame info  SyncQueued, SyncStart, IssueDrawCommandsStart, SwapBuffers, FrameCompleted, DequeueBufferDuration, QueueBufferDuration, // Must be the last value!  // Also must be kept in sync with FrameMetrics.java#FRAME_STATS_COUNT  NumIndexes }; frameworks/base/libs/hwui/renderthread/OpenGLPipeline.cpp\nOpenGLPipeline setSurface bool OpenGLPipeline::setSurface(Surface* surface, SwapBehavior swapBehavior, ColorMode colorMode) { if (surface) { const bool wideColorGamut = colorMode == ColorMode::WideColorGamut; mEglSurface = mEglManager.createSurface(surface, wideColorGamut); } return false; } frameworks/base/libs/hwui/renderthread/EglManager.cpp\nEglManager createSurface EGLSurface EglManager::createSurface(EGLNativeWindowType window, bool wideColorGamut) { initialize(); EGLSurface surface = eglCreateWindowSurface( mEglDisplay, wideColorGamut ? mEglConfigWideGamut : mEglConfig, window, attribs); return surface; } DrawFrameTask setContext void DrawFrameTask::setContext(RenderThread* thread, CanvasContext* context, RenderNode* targetNode) { mRenderThread = thread; mContext = context; mTargetNode = targetNode; } drawFrame int DrawFrameTask::drawFrame() { postAndWait(); return mSyncResult; } postAndWait void DrawFrameTask::postAndWait() { AutoMutex _lock(mLock); mRenderThread-\u0026gt;queue().post([this]() { run(); }); mSignal.wait(mLock); } called by renderproxy\nrun void DrawFrameTask::run() { canUnblockUiThread = syncFrameState(info); // Grab a copy of everything we need  CanvasContext* context = mContext; // From this point on anything in \u0026#34;this\u0026#34; is *UNSAFE TO ACCESS*  if (canUnblockUiThread) { unblockUiThread(); } if (CC_LIKELY(canDrawThisFrame)) { context-\u0026gt;draw(); } else { // wait on fences so tasks don\u0026#39;t overlap next frame  context-\u0026gt;waitOnFences(); } if (!canUnblockUiThread) { unblockUiThread(); } } canvascontext\nLooper wake void Looper::wake() { uint64_t inc = 1; ssize_t nWrite = TEMP_FAILURE_RETRY(write(mWakeEventFd, \u0026amp;inc, sizeof(uint64_t))); if (nWrite != sizeof(uint64_t)) { if (errno != EAGAIN) { LOG_ALWAYS_FATAL(\u0026#34;Could not write wake signal to fd %d: %s\u0026#34;, mWakeEventFd, strerror(errno)); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/",
	"title": "系统机制原理",
	"tags": [],
	"description": "",
	"content": "系统机制原理 探索总结系统机制原理知识\n 系统绘制    硬件加速绘制Source     软件绘制      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/",
	"title": "系统绘制",
	"tags": [],
	"description": "",
	"content": "系统绘制 探索总结系统绘制知识\n 硬件加速绘制Source     软件绘制     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/",
	"title": "跨平台",
	"tags": [],
	"description": "",
	"content": "跨平台 探索总结跨平台知识\n flutter    android    google    supportToAndroidx      系统机制原理    硬件加速绘制Source     软件绘制       跨平台    flutter    通信    Flutter消息机制       "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%B3%BB%E7%BB%9F%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E8%BD%AF%E4%BB%B6%E7%BB%98%E5%88%B6/",
	"title": "软件绘制",
	"tags": [],
	"description": "",
	"content": "软件绘制 深入理解Window\nAndroid的UI显示原理之Surface的创建\nAndroid的UI显示原理之Surface的渲染\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/AndroidFramework%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E7%9A%84UI%E6%98%BE%E7%A4%BA%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93.md\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/framework/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/README.md\nAndroid图形系统（九）-View、Canvas与Surface的关系\n 整体流程 把整个流程再简单总结下，View、Canvas与Surface的关系也就一目了然了：\nSurface通过dequeueBuffer流程（具体操作在此不多赘述）获取一块存放绘制数据的buffer。\nView 在onDraw的时候，通过传入的Canvas进行绘制。（这里只是一个绘制的入口而已，本文是针对requestLayout 流程来讲述的，当然你单独用Canvas实现绘制也是一样的）。\n调用java层的CanvasAPI，实际真正负责绘制工作的是底层的Skia引擎，这里核心类包括SKCanvas（画家）以及SKBitmap（画布），绘制好的内容放入Surface 通过dequeueBuffer获取到的GraphicBuffer。\n绘制完毕后，Surface通过queueBuffer将存放好绘制数据的buffer投递到队列中，并通知SurfaceFlinger消费。\n SurfaceFlinger可以说是Android UI渲染体系的核心，在Android系统启动时会启动SurfaceFlinger服务,它的主要作用就是被Android应用程序调用，把绘制(测量，布局，绘制)后的窗口(Surface)渲染到手机屏幕上\nSurfaceControl surface.lockCanvas(): //android_view_Surface.cpp static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ... ANativeWindow_Buffer outBuffer; //调用了Surface的dequeueBuffer，从SurfaceFlinger中申请内存GraphicBuffer,这个buffer是用来传递绘制的元数据的  status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); ... SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType); //新建了一个SkBitmap，并进行了一系列设置  SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits);//bitmap对graphicBuffer进行关联  } else { // be safe with an empty bitmap.  bitmap.setPixels(NULL); } //构造一个native的Canvas对象（SKCanvas)，再返回这个Canvas对象，java层的Canvas对象其实只是对SKCanvas对象的一个简单包装，所有绘制方法都是转交给SKCanvas来做。  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); ... sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } canvas.drawXXX Skia深入分析\n==SkCanvas是按照SkBitmap的方法去关联GraphicBuffer==\n一、渲染层级 从渲染流程上分，Skia可分为如下三个层级：\n 指令层：SkPicture、SkDeferredCanvas-\u0026gt;SkCanvas  这一层决定需要执行哪些绘图操作，绘图操作的预变换矩阵，当前裁剪区域，绘图操作产生在哪些layer上，Layer的生成与合并。\n解析层：SkBitmapDevice-\u0026gt;SkDraw-\u0026gt;SkScan、SkDraw1Glyph::Proc  这一层决定绘制方式，完成坐标变换，解析出需要绘制的形体（点/线/规整矩形）并做好抗锯齿处理，进行相关资源解析并设置好Shader。\n渲染层：SkBlitter-\u0026gt;SkBlitRow::Proc、SkShader::shadeSpan等  这一层进行采样（如果需要），产生实际的绘制效果，完成颜色格式适配，进行透明度混合和抖动处理（如果需要）。\n//Canvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { super.drawLine(startX, startY, stopX, stopY, paint); } //BaseCanvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { throwIfHasHwBitmapInSwMode(paint); nDrawLine(mNativeCanvasWrapper, startX, startY, stopX, stopY, paint.getNativeInstance()); } //frameworks/base/core/jni/android_graphics_Canvas.cpp static void drawLine(JNIEnv* env, jobject, jlong canvasHandle, jfloat startX, jfloat startY, jfloat stopX, jfloat stopY, jlong paintHandle) { Paint* paint = reinterpret_cast\u0026lt;Paint*\u0026gt;(paintHandle); get_canvas(canvasHandle)-\u0026gt;drawLine(startX, startY, stopX, stopY, *paint); } //external/skia/src/core/SkCanvas.cpp void SkCanvas::drawLine(SkScalar x0, SkScalar y0, SkScalar x1, SkScalar y1, const SkPaint\u0026amp; paint) { SkPoint pts[2]; pts[0].set(x0, y0); pts[1].set(x1, y1); this-\u0026gt;drawPoints(kLines_PointMode, 2, pts, paint); } void SkCanvas::drawPoints(PointMode mode, size_t count, const SkPoint pts[], const SkPaint\u0026amp; paint) { TRACE_EVENT0(\u0026#34;skia\u0026#34;, TRACE_FUNC); this-\u0026gt;onDrawPoints(mode, count, pts, paint); } mSurface.unlockCanvasAndPost(canvas): //Surface.cpp status_t Surface::unlockAndPost() { if (mLockedBuffer == 0) { ALOGE(\u0026#34;Surface::unlockAndPost failed, no locked buffer\u0026#34;); return INVALID_OPERATION; } int fd = -1; status_t err = mLockedBuffer-\u0026gt;unlockAsync(\u0026amp;fd);//通过Gralloc模块，最后是操作的ioctl  err = queueBuffer(mLockedBuffer.get(), fd); mPostedBuffer = mLockedBuffer; mLockedBuffer = 0; return err; } int Surface::queueBuffer(android_native_buffer_t* buffer, int fenceFd) { ... int i = getSlotFromBufferLocked(buffer); ... IGraphicBufferProducer::QueueBufferOutput output; IGraphicBufferProducer::QueueBufferInput input(timestamp, isAutoTimestamp, static_cast\u0026lt;android_dataspace\u0026gt;(mDataSpace), crop, mScalingMode, mTransform ^ mStickyTransform, fence, mStickyTransform, mEnableFrameTimestamps); ... status_t err = mGraphicBufferProducer-\u0026gt;queueBuffer(i, input, \u0026amp;output); ... mQueueBufferCondition.broadcast(); return err; } int Surface::getSlotFromBufferLocked(android_native_buffer_t* buffer) const { for (int i = 0; i \u0026lt; NUM_BUFFER_SLOTS; i++) { if (mSlots[i].buffer != NULL \u0026amp;\u0026amp; mSlots[i].buffer-\u0026gt;handle == buffer-\u0026gt;handle) { return i; } } return BAD_VALUE; } 我们看到了queueBuffer函数, 而在Surface的queueBuffer函数中调用了如下函数：\nmGraphicBufferProducer-\u0026gt;queueBuffer status_t BufferQueueProducer::queueBuffer(int slot, const QueueBufferInput \u0026amp;input, QueueBufferOutput *output) { //从input中获取一些列参数  input.deflate(\u0026amp;requestedPresentTimestamp, \u0026amp;isAutoTimestamp, \u0026amp;dataSpace, \u0026amp;crop, \u0026amp;scalingMode, \u0026amp;transform, \u0026amp;acquireFence, \u0026amp;stickyTransform, \u0026amp;getFrameTimestamps); sp\u0026lt;IConsumerListener\u0026gt; frameAvailableListener; sp\u0026lt;IConsumerListener\u0026gt; frameReplacedListener; BufferItem item; //可以理解为一个待渲染的帧  frameAvailableListener = mCore-\u0026gt;mConsumerListener; ...下面就是对item的一系列赋值操作 item.mAcquireCalled = mSlots[slot].mAcquireCalled; item.mGraphicBuffer = mSlots[slot].mGraphicBuffer; //根据slot获取GraphicBuffer。  item.mCrop = crop; item.mTransform = transform \u0026amp; ~static_cast\u0026lt;uint32_t\u0026gt;(NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY); item.mTransformToDisplayInverse = (transform \u0026amp; NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY) != 0; item.mScalingMode = static_cast\u0026lt;uint32_t\u0026gt;(scalingMode); item.mTimestamp = requestedPresentTimestamp; item.mIsAutoTimestamp = isAutoTimestamp; ... if (frameAvailableListener != NULL) { frameAvailableListener-\u0026gt;onFrameAvailable(item); //item是一个frame，准备完毕，要通知外界  } else if (frameReplacedListener != NULL) { frameReplacedListener-\u0026gt;onFrameReplaced(item); } addAndGetFrameTimestamps(\u0026amp;newFrameEventsEntry,etFrameTimestamps ? \u0026amp;output-\u0026gt;frameTimestamps : nullptr); return NO_ERROR; } 这个函数最终会将BufferItem的buffer清除，通知消费者的onFrameAvailable接口。然后消费者可以根据mSlots的序号再来拿buffer。\n// --------------------------------------------------------------------------- // Interface implementation for SurfaceFlingerConsumer::ContentsChangedListener // --------------------------------------------------------------------------- void BufferLayer::onFrameAvailable(const BufferItem\u0026amp; item) { ... mFlinger-\u0026gt;signalLayerUpdate(); } void SurfaceFlinger::signalLayerUpdate() { mEventQueue-\u0026gt;invalidate(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/",
	"title": "通信",
	"tags": [],
	"description": "",
	"content": "通信 探索总结通信知识\n Flutter消息机制     "
}]