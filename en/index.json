[
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/anr/1anrsystmhandle/",
	"title": "1ANRSystmHandle",
	"tags": [],
	"description": "",
	"content": "ANR 设计原理 组件超时分类 Broadcast 超时原理举例 ANR Trace Dump流程 图解 sequenceDiagram SystemServer-\u0026gt;\u0026gt;SystemServer: AppNotResponding.run activate SystemServer Note right of SystemServer: 1.非异常场景下,统计进程信息,包括: Note right of SystemServer: 发生ANR的进程,SystemServer进程,SurfaceFligner进程,CPU占用高的5个进程 Note right of SystemServer: 2.打印ANR顶部信息 被统计的进程-\u0026gt;\u0026gt;被统计的进程: 虚拟机启动过程在SignalCatcher进行信号注册和监听(SIGQUIT) SystemServer-\u0026gt;\u0026gt;被统计的进程: 3.逐个向统计的进程发送SIGQUIT信号,通知dump进程信息 被统计的进程-\u0026gt;\u0026gt;被统计的进程: TheadList::DumpForSigQuit activate 被统计的进程 Note right of 被统计的进程: 遍历所有的Java线程和虚拟机线程,设置checkpoint,请求挂起suspend deactivate 被统计的进程 被统计的进程-\u0026gt;\u0026gt;被统计的进程: 所有线程挂起后，SignalCatcher线程开始遍历Dump各线程的堆栈和线程数据，结束之后再唤醒线程 SystemServer-\u0026gt;\u0026gt;SystemServer: 监听管道并读取管道内容,写入Trace文件 deactivate SystemServer 参考signalcatcher获取各线程信息的工作过程\nCapture ANR ANR 信息写入 继续以广播接收为例，在上面介绍到当判定超时后，会调用系统服务 AMS 接口，搜集本次 ANR 相关信息并存档(data/anr/trace，data/system/dropbox)，入口如下。\n进入系统服务 AMS 之后，AppError 先进行场景判断，以过滤当前进程是不是已经发生并正在执行 Dump 流程，或者已经发生 Crash，或者已经被系统 Kill 之类的情况。并且还考虑了系统是否正在关机等场景，如果都不符合上述条件，则认为当前进程真的发生 ANR。\n顶部信息 接下来系统再判断当前 ANR 进程对用户是否可感知，如后台低优先级进程(没有重要服务或者 Activity 界面)。\n然后开始统计与该进程有关联的进程，或系统核心服务进程的信息；例如与应用进程经常交互的 SurfaceFligner，SystemServer 等系统进程，如果这些系统服务进程在响应时被阻塞，那么将导致应用进程 IPC 通信过程被卡死。\n首先把自身进程(系统服务 SystemServer)加进来，逻辑如下：\n接着获取其它系统核心进程，因为这些服务进程是 Init 进程直接创建的，并不在 SystemServer 或 Zygote 进程管理范围。\n在搜集完第一步信息之后，接下来便开始统计各进程本地的更多信息，如虚拟机相关信息、Java 线程状态及堆栈。以便于知道此刻这些进程乃至系统都发生了什么情况\nDump Trace 流程 系统为何要收集其它进程信息呢？因为从性能角度来说，任何进程出现高 CPU 或高 IO 情况，都会抢占系统资源，进而影响其它进程调度不及时的现象。下面从代码角度看看系统 dump 流程：\nprivate static void dumpStackTraces(String tracesFile, ArrayList\u0026lt;Integer\u0026gt; firstPids, ArrayList\u0026lt;Integer\u0026gt; nativePids, ArrayList\u0026lt;Integer\u0026gt; extraPids, boolean useTombstonedForJavaTraces) { ...... ...... //考虑到性能影响，一次dump最多持续20S，否则放弃后续进程直接结束  remainingTime = 20 * 1000; try { ...... //按照优先级依次获取各个进程trace日志  int num = firstPids.size(); for (int i = 0; i \u0026lt; num; i++) { final long timeTaken; if (useTombstonedForJavaTraces) { timeTaken = dumpJavaTracesTombstoned(firstPids.get(i), tracesFile, remainingTime); } else { timeTaken = observer.dumpWithTimeout(firstPids.get(i), remainingTime); } remainingTime -= timeTaken; if (remainingTime \u0026lt;= 0) { //已经超时，则不再进行后续进程的dump操作  return; } } } } //按照优先级依次获取各个进程trace日志  for (int pid : nativePids) { final long nativeDumpTimeoutMs = Math.min(NATIVE_DUMP_TIMEOUT_MS, remainingTime); final long start = SystemClock.elapsedRealtime(); Debug.dumpNativeBacktraceToFileTimeout( pid, tracesFile, (int) (nativeDumpTimeoutMs / 1000)); final long timeTaken = SystemClock.elapsedRealtime() - start; remainingTime -= timeTaken; if (remainingTime \u0026lt;= 0) { //已经超时，则不再进行后续进程的dump操作  return; } } } //按照优先级依次获取各个进程trace日志  for (int pid : extraPids) { final long timeTaken; if (useTombstonedForJavaTraces) { timeTaken = dumpJavaTracesTombstoned(pid, tracesFile, remainingTime); } else { timeTaken = observer.dumpWithTimeout(pid, remainingTime); } remainingTime -= timeTaken; if (remainingTime \u0026lt;= 0) { //已经超时，则不再进行后续进程的dump操作  return; } } } } ...... } 出于安全考虑，进程之间是相互隔离的，即使是系统进程也无法直接获取其它进程相关信息。因此需要借助 IPC 通信的方式，将指令发送到目标进程，目标进程接收到信号后，协助完成自身进程 Dump 信息并发送给系统进程。以 AndroidP 系统为例，大致流程图如下：\n关于应用进程接收信号和响应能力，是在虚拟机内部实现的，在虚拟机启动过程中进行信号注册和监听(SIGQUIT)，初始化逻辑如下：\nSignalCatcher 线程接收到信号后，首先 Dump 当前虚拟机有关信息，如内存状态，对象，加载 Class，GC 等等，接下来设置各线程标记位(check_point)，以请求线程起态(suspend)。其它线程运行过程进行上下文切换时，会检查该标记，如果发现有挂起请求，会主动将自己挂起。等到所有线程挂起后，SignalCatcher 线程开始遍历 Dump 各线程的堆栈和线程数据，结束之后再唤醒线程。期间如果某些线程一直无法挂起直到超时，那么本次 Dump 流程则失败，并主动抛出超时异常。\nSignalCatcher获取各线程信息的工作过程 根据上面梳理的流程，SignalCatcher 获取各线程信息的工作过程，示意图如下：\n到这里，基本介绍完了系统设计原理，并以广播发送为例说明系统是如何判定 ANR 的，以及发生 ANR 后，系统是如何获取系统信息和进程信息，以及其他进程是如何协助系统进程完成日志收集的。\n整体来看链路比较长，而且涉及到与很多进程交互，同时为了进一步降低对应用乃至系统的影响，系统在很多环节都设置大量超时检测。而且从上面流程可以看到发生 ANR 时，系统进程除了发送信号给其它进程之外，自身也 Dump Trace，并获取系统整体及各进程 CPU 使用情况，且将其它进程 Dump 发送的数据写到文件中。因此这些开销将会导致系统进程在 ANR 过程承担很大的负载，这是为什么我们经常在 ANR Trace 中看到 SystemServer 进程 CPU 占比普遍较高的主要原因。\n参考 Android ANR Trace 详解\nHow to read Dalvik SIGQUIT output\nhttps://codezjx.com/2017/08/06/anr-trace-analytics/\nActivityManagerService\n 在产生ANR的时候，会回调到AMS的appNotResponding()方法，以下为关键代码，中文注释为相关代码的解读： 我们来详细看下dumpStackTraces()这个方法，此处将dump出firstPids与lastPids进程的相关线程堆栈信息至traces.txt，中文注释为相关代码的解读。  http://zhijianz.me/2017/07/11/ANR%E5%88%86%E6%9E%90-trace%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/\nAndroid ANR Trace 详解\nhttps://github.com/iqiyi/xCrash\n今日头条 anr 优化实践系列 - 设计原理及影响因素\n今日头条 anr 优化实践系列 - 监控工具与分析思路\n今日头条 ANR 优化实践系列分享 - 实例剖析集锦\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/1binderservicemanager/",
	"title": "1BinderServiceManager",
	"tags": [],
	"description": "",
	"content": "Sequence svclist frameworks/native/cmds/servicemanager/service_manager.c\nservice_manager.c(ServiceManger is single thread) main int main(int argc, char** argv) { struct binder_state *bs; union selinux_callback cb; char *driver; if (argc \u0026gt; 1) { driver = argv[1]; } else { driver = \u0026#34;/dev/binder\u0026#34;; } bs = binder_open(driver, 128*1024);//1  if (binder_become_context_manager(bs)) {//2  ALOGE(\u0026#34;cannot become context manager (%s)\\n\u0026#34;, strerror(errno)); return -1; } binder_loop(bs, svcmgr_handler);//3  return 0; } binder_open\nbinder_become_context_manager\nbinder_loop\nsvcmgr_handler int svcmgr_handler(struct binder_state *bs, struct binder_transaction_data *txn, struct binder_io *msg, struct binder_io *reply) { switch(txn-\u0026gt;code) { case SVC_MGR_GET_SERVICE: case SVC_MGR_CHECK_SERVICE: s = bio_get_string16(msg, \u0026amp;len); handle = do_find_service(s, len, txn-\u0026gt;sender_euid, txn-\u0026gt;sender_pid); if (!handle) break; bio_put_ref(reply, handle); return 0; case SVC_MGR_ADD_SERVICE: s = bio_get_string16(msg, \u0026amp;len); handle = bio_get_ref(msg); allow_isolated = bio_get_uint32(msg) ? 1 : 0; dumpsys_priority = bio_get_uint32(msg); if (do_add_service(bs, s, len, handle, txn-\u0026gt;sender_euid, allow_isolated, dumpsys_priority, txn-\u0026gt;sender_pid)) return -1; break; case SVC_MGR_LIST_SERVICES: { uint32_t n = bio_get_uint32(msg); uint32_t req_dumpsys_priority = bio_get_uint32(msg); if (!svc_can_list(txn-\u0026gt;sender_pid, txn-\u0026gt;sender_euid)) { ALOGE(\u0026#34;list_service() uid=%d - PERMISSION DENIED\\n\u0026#34;, txn-\u0026gt;sender_euid); return -1; } si = svclist; // walk through the list of services n times skipping services that  // do not support the requested priority  while (si) { if (si-\u0026gt;dumpsys_priority \u0026amp; req_dumpsys_priority) { if (n == 0) break; n--; } si = si-\u0026gt;next; } if (si) { bio_put_string16(reply, si-\u0026gt;name); return 0; } return -1; } default: ALOGE(\u0026#34;unknown code %d\\n\u0026#34;, txn-\u0026gt;code); return -1; } bio_put_uint32(reply, 0); return 0; } bio_get_string16\ndo_find_service\ndo_add_service int do_add_service(struct binder_state *bs, const uint16_t *s, size_t len, uint32_t handle, uid_t uid, int allow_isolated, uint32_t dumpsys_priority, pid_t spid) { struct svcinfo *si; if (!handle || (len == 0) || (len \u0026gt; 127)) return -1; if (!svc_can_register(s, len, spid, uid)) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - PERMISSION DENIED\\n\u0026#34;, str8(s, len), handle, uid); return -1; } si = find_svc(s, len); if (si) { if (si-\u0026gt;handle) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - ALREADY REGISTERED, OVERRIDE\\n\u0026#34;, str8(s, len), handle, uid); svcinfo_death(bs, si); } si-\u0026gt;handle = handle; } else { si = malloc(sizeof(*si) + (len + 1) * sizeof(uint16_t)); if (!si) { ALOGE(\u0026#34;add_service(\u0026#39;%s\u0026#39;,%x) uid=%d - OUT OF MEMORY\\n\u0026#34;, str8(s, len), handle, uid); return -1; } si-\u0026gt;handle = handle; si-\u0026gt;len = len; memcpy(si-\u0026gt;name, s, (len + 1) * sizeof(uint16_t)); si-\u0026gt;name[len] = \u0026#39;\\0\u0026#39;; si-\u0026gt;death.func = (void*) svcinfo_death; si-\u0026gt;death.ptr = si; si-\u0026gt;allow_isolated = allow_isolated; si-\u0026gt;dumpsys_priority = dumpsys_priority; si-\u0026gt;next = svclist; svclist = si; } binder_acquire(bs, handle); binder_link_to_death(bs, handle, \u0026amp;si-\u0026gt;death); return 0; } do_find_service uint32_t do_find_service(const uint16_t *s, size_t len, uid_t uid, pid_t spid) { struct svcinfo *si = find_svc(s, len); if (!si || !si-\u0026gt;handle) { return 0; } if (!si-\u0026gt;allow_isolated) { // If this service doesn\u0026#39;t allow access from isolated processes,  // then check the uid to see if it is isolated.  uid_t appid = uid % AID_USER; if (appid \u0026gt;= AID_ISOLATED_START \u0026amp;\u0026amp; appid \u0026lt;= AID_ISOLATED_END) { return 0; } } if (!svc_can_find(s, len, spid, uid)) { return 0; } return si-\u0026gt;handle; } find_svc\nstruct svcinfo struct svcinfo { struct svcinfo *next; uint32_t handle; struct binder_death death; int allow_isolated; uint32_t dumpsys_priority; size_t len; uint16_t name[0]; }; find_svc struct svcinfo *find_svc(const uint16_t *s16, size_t len) { struct svcinfo *si; for (si = svclist; si; si = si-\u0026gt;next) { if ((len == si-\u0026gt;len) \u0026amp;\u0026amp; !memcmp(s16, si-\u0026gt;name, len * sizeof(uint16_t))) { return si; } } return NULL; } frameworks/native/cmds/servicemanager/binder.c\nbinder.c binder_open struct binder_state *binder_open(const char* driver, size_t mapsize) { struct binder_state *bs; struct binder_version vers; bs-\u0026gt;fd = open(driver, O_RDWR | O_CLOEXEC); ioctl(bs-\u0026gt;fd, BINDER_VERSION, \u0026amp;vers) bs-\u0026gt;mapped = mmap(NULL, mapsize, PROT_READ, MAP_PRIVATE, bs-\u0026gt;fd, 0); } binder_become_context_manager int binder_become_context_manager(struct binder_state *bs) { return ioctl(bs-\u0026gt;fd, BINDER_SET_CONTEXT_MGR, 0); } binder_loop void binder_loop(struct binder_state *bs, binder_handler func) { int res; struct binder_write_read bwr; uint32_t readbuf[32]; bwr.write_size = 0; bwr.write_consumed = 0; bwr.write_buffer = 0; readbuf[0] = BC_ENTER_LOOPER; binder_write(bs, readbuf, sizeof(uint32_t)); for (;;) { bwr.read_size = sizeof(readbuf); bwr.read_consumed = 0; bwr.read_buffer = (uintptr_t) readbuf; res = ioctl(bs-\u0026gt;fd, BINDER_WRITE_READ, \u0026amp;bwr); res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func); } } binder_parse\nbinder_write int binder_write(struct binder_state *bs, void *data, size_t len) { struct binder_write_read bwr; int res; bwr.write_size = len; bwr.write_consumed = 0; bwr.write_buffer = (uintptr_t) data; bwr.read_size = 0; bwr.read_consumed = 0; bwr.read_buffer = 0; res = ioctl(bs-\u0026gt;fd, BINDER_WRITE_READ, \u0026amp;bwr); return res; } binder_parse int binder_parse(struct binder_state *bs, struct binder_io *bio, uintptr_t ptr, size_t size, binder_handler func) { while (ptr \u0026lt; end) { uint32_t cmd = *(uint32_t *) ptr; ptr += sizeof(uint32_t); switch(cmd) { case BR_TRANSACTION: { struct binder_transaction_data *txn = (struct binder_transaction_data *) ptr; if ((end - ptr) \u0026lt; sizeof(*txn)) { ALOGE(\u0026#34;parse: txn too small!\\n\u0026#34;); return -1; } binder_dump_txn(txn); if (func) { unsigned rdata[256/4]; struct binder_io msg; struct binder_io reply; int res; bio_init(\u0026amp;reply, rdata, sizeof(rdata), 4); bio_init_from_txn(\u0026amp;msg, txn); res = func(bs, txn, \u0026amp;msg, \u0026amp;reply);//callback method svcmgr_handler  if (txn-\u0026gt;flags \u0026amp; TF_ONE_WAY) { binder_free_buffer(bs, txn-\u0026gt;data.ptr.buffer); } else { binder_send_reply(bs, \u0026amp;reply, txn-\u0026gt;data.ptr.buffer, res); } } ptr += sizeof(*txn); break; } } bio_init_from_txn\nsvcmgr_handler\nstruct binder_io struct binder_io { char *data; /* pointer to read/write from */ binder_size_t *offs; /* array of offsets */ size_t data_avail; /* bytes available in data buffer */ size_t offs_avail; /* entries available in offsets array */ char *data0; /* start of data buffer */ binder_size_t *offs0; /* start of offsets buffer */ uint32_t flags; uint32_t unused; }; bio_init_from_txn void bio_init_from_txn(struct binder_io *bio, struct binder_transaction_data *txn) { bio-\u0026gt;data = bio-\u0026gt;data0 = (char *)(intptr_t)txn-\u0026gt;data.ptr.buffer; bio-\u0026gt;offs = bio-\u0026gt;offs0 = (binder_size_t *)(intptr_t)txn-\u0026gt;data.ptr.offsets; bio-\u0026gt;data_avail = txn-\u0026gt;data_size; bio-\u0026gt;offs_avail = txn-\u0026gt;offsets_size / sizeof(size_t); bio-\u0026gt;flags = BIO_F_SHARED; } bio_get_string16 uint16_t *bio_get_string16(struct binder_io *bio, size_t *sz) { size_t len; /* Note: The payload will carry 32bit size instead of size_t */ len = (size_t) bio_get_uint32(bio); if (sz) *sz = len; return bio_get(bio, (len + 1) * sizeof(uint16_t)); } uint32_t bio_get_uint32(struct binder_io *bio) { uint32_t *ptr = bio_get(bio, sizeof(*ptr)); return ptr ? *ptr : 0; } bio_get static void *bio_get(struct binder_io *bio, size_t size) { size = (size + 3) \u0026amp; (~3); if (bio-\u0026gt;data_avail \u0026lt; size){ bio-\u0026gt;data_avail = 0; bio-\u0026gt;flags |= BIO_F_OVERFLOW; return NULL; } else { void *ptr = bio-\u0026gt;data; bio-\u0026gt;data += size; bio-\u0026gt;data_avail -= size; return ptr; } } bio_get_ref uint32_t bio_get_ref(struct binder_io *bio) { struct flat_binder_object *obj; obj = _bio_get_obj(bio); if (!obj) return 0; if (obj-\u0026gt;hdr.type == BINDER_TYPE_HANDLE) return obj-\u0026gt;handle; return 0; } bio_put_ref void bio_put_ref(struct binder_io *bio, uint32_t handle) { struct flat_binder_object *obj; if (handle) obj = bio_alloc_obj(bio); else obj = bio_alloc(bio, sizeof(*obj)); if (!obj) return; obj-\u0026gt;flags = 0x7f | FLAT_BINDER_FLAG_ACCEPTS_FDS; obj-\u0026gt;hdr.type = BINDER_TYPE_HANDLE; obj-\u0026gt;handle = handle; obj-\u0026gt;cookie = 0; } _bio_get_obj static struct flat_binder_object *_bio_get_obj(struct binder_io *bio) { size_t n; size_t off = bio-\u0026gt;data - bio-\u0026gt;data0; for (n = 0; n \u0026lt; bio-\u0026gt;offs_avail; n++) { if (bio-\u0026gt;offs[n] == off) return bio_get(bio, sizeof(struct flat_binder_object)); } bio-\u0026gt;data_avail = 0; bio-\u0026gt;flags |= BIO_F_OVERFLOW; return NULL; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/1hotfixresearch/",
	"title": "1hotfixResearch",
	"tags": [],
	"description": "",
	"content": "价值 热修复的作用   可快速修复，避免线上Bug带来的业务损失，把损失降到最低。\n  保证客户端的更新率，无须用户进行版本升级安装\n  良好的用户体验，无感知修复异常。节省用户下载安装成本。\n  分类 图解 graph LR subgraph dex插入到数组的最前 DexElements end subgraph env-\u0026gt;FromReflectedMethod得到方法对应的ArtMethod,对其所有成员进行修改 NativeHook end subgraph 避免类被加上ISPREVERIFIED 补丁dex end 代码修复--\u0026gt;NativeHook 代码修复--\u0026gt;DexElements DexElements--\u0026gt;补丁dex DexElements--\u0026gt;全量dex 代码修复--\u0026gt;混合优化 代码修复--\u0026gt;代码插桩和替换 各技术能力范围 https://github.com/Tencent/tinker/wiki\n    Tinker QZone AndFix Robust     类替换 yes yes no no   So替换 yes no no no   资源替换 yes yes no no   全平台支持 yes yes yes yes   即时生效 no no yes yes   性能损耗 较小 较大 较小 较小   补丁包大小 较小 较大 一般 一般   开发透明 yes yes no no   复杂度 较低 较低 复杂 复杂   gradle支持 yes no no no   Rom体积 较大 较小 较小 较小   成功率 较高 较高 一般 最高    代码修复 代码插桩和替换/Java Hook Instant Run 原理 在第一次完整编译的时候给所有的类插桩（字节码操作），使它们的方法能被代理\n代码改动后的增量编译中，通过gradle插件生成包含了改动代码的代理类\n通过app中的instant-run服务给代码被改动的类的$change字段复制，这样所有方法都转发到了代理类，而代理类里就是改动后的逻辑\nRobust 美团， 开源，实时修复\n原理 1、打基础包时插桩，在每个方法前插入一段类型为 ChangeQuickRedirect 静态变量的逻辑，插入过程对业务开发是完全透明\n2、加载补丁时，从补丁包中读取要替换的类及具体替换的方法实现，新建ClassLoader加载补丁dex。当changeQuickRedirect不为null时，可能会执行到accessDispatch从而替换掉之前老的逻辑，达到fix的目的\n优缺点 优点\n· 高兼容性（Robust只是在正常的使用DexClassLoader）、高稳定性，修复成功率高达99.9%\n· 补丁实时生效，不需要重新启动\n· 支持方法级别的修复，包括静态方法\n· 支持增加方法和类\n· 支持ProGuard的混淆、内联、优化等操作\n缺点\n· 代码是侵入式的，会在原有的类中加入相关代码\n· so和资源的替换暂时不支持\n· 会增大apk的体积，平均一个函数会比原来增加17.47个字节，10万个函数会增加1.67M\nNativeHook AndFix 开源，实时生效\nHotFix 阿里百川，未开源，免费、实时生效\nHotFix是AndFix的优化版本，Sophix是HotFix的优化版本。目前阿里系主推是Sophix。\n原理 每一个Java方法在art中都对应一个ArtMethod,ArtMethod记录了这个Java方法的所有信息，包括访问权限及代码执行地址等。通过env-\u0026gt;FromReflectedMethod得到方法对应的ArtMethod的真正开始地址，然后强转为ArtMethod指针，从而对其所有成员进行修改。\n这样以后调用这个方法时就会直接走到新方法的实现中，达到热修复的效果。\n优缺点 优点\n· 即时生效\n· 没有性能开销，不需要任何编辑器的插桩或代码改写\n缺点\n· 存在稳定及兼容性问题。ArtMethod的结构基本参考Google开源的代码，各大厂商的ROM都可能有所改动，可能导致结构不一致，修复失败。\n· 无法增加变量及类，只能修复方法级别的Bug，无法做到新功能的发布\nJava multiDex Qzone 超级补丁 QQ空间，未开源，冷启动修复\nQFix 手Q团队，开源，冷启动修复\nNuwa 大众点评，开源，冷启动修复\n原理 Android内部使用的是BaseDexClassLoader、PathClassLoader、DexClassLoader三个类加载器实现从DEX文件中读取类数据，其中PathClassLoader和DexClassLoader都是继承自BaseDexClassLoader实现。dex文件转换成dexFile对象，存入Element[]数组，findclass顺序遍历Element数组获取DexFile，然后执行DexFile的findclass。\n所以此方案的原理是Hook了ClassLoader.pathList.dexElements[]，将补丁的dex插入到数组的最前端。因为ClassLoader的findClass是通过遍历dexElements[]中的dex来寻找类的。所以会优先查找到修复的类。从而达到修复的效果\n优缺点 优点\n· 不需要考虑对dalvik虚拟机和art虚拟机做适配\n· 代码是非侵入式的，对apk体积影响不大\n缺点\n· 需要下次启动才修复\n· 性能损耗大，为了避免类被加上CLASS_ISPREVERIFIED，使用插桩，单独放一个帮助类在独立的dex中让其他类调用。\nJava Dex 替换 Tinker 微信团队，开源，冷启动修复。提供分发管理，基础版免费\nAmigo 饿了么，开源，冷启动修复\nAmigo 原理与 QQZone 的方案有些类似，QQZone,Tinker,Nuwa这类方案是通过修改PathClassLoader中的dex实现的，Amigo则是釜底抽薪直接替换ClassLoader。同时进一步实现了 so 文件、资源文件、四大组件的修复，可以对APP全面进行修复，不愧 Amigo（朋友）这个称号，能在危急时刻送来全面的帮助。同时Amigo也致力解决使用过程中的带来的束缚，比如对代码进行插桩、打包时保存和指定映射文件等(如果mapping文件丢了后果不堪设想)，所以开发和打包完全无侵入。\n原理 为了避免dex插桩带来的性能损耗，dex替换采取另外的方式。原理是提供dex差量包，整体替换dex的方案。差量的方式给出patch.dex，然后将patch.dex与应用的classes.dex合并成一个完整的dex，完整dex加载得到dexFile对象作为参数构建一个Element对象然后整体替换掉旧的dex-Elements数组。\nTinker自研了DexDiff/DexMerge算法。Tinker还支持资源和So包的更新，So补丁包使用BsDiff来生成，资源补丁包直接使用文件md5对比来生成，针对资源比较大的（默认大于100KB属于大文件）会使用BsDiff来对文件生成差量补丁。\n优缺点 优点\n· 兼容性高\n· 补丁小\n· 开发透明，代码非侵入式\n缺点\n· 冷启动修复，下次启动修复\n· Dex合并内存消耗在vm head上，容易OOM，最后导致合并失败\n混合优化 Sophix 未开源，商业收费，实时生效/冷启动修复\n资源修复 全量包 Amigo 饿了么\nInstant Run 原理 资源修复原理 Instant Run(替换AssertManager)\n1、构建一个新的AssetManager，并通过反射调用addAssertPath，把这个完整的新资源包加入到AssetManager中。这样就得到一个含有所有新资源的AssetManager\n2、找到所有之前引用到原有AssetManager的地方，通过反射，把引用处替换为AssetManager\n具体实现查看insatnt-run.jar中的MonkeyPatcher#monkeyPatchExistingResources()\n差量包 Tinker Sophix 原理 Sophix\n我们发现，其实大量代码都是在处理兼容性问题和找到所有AssetManager的引用处，真正的替换的逻辑其实很简单。\n我们的方案没有直接使用Instant Run的技术，而是另辟蹊径，构造了一个package id为0x66的资源包，这个包里只包含改变了的资源项，然后直接在原有AssetManager中addAssetPath这个包就可以了。\n由于补丁包的package id为0x66，不与目前已经加载的0x7f冲突，因此直接加入到已有的AssetManager中就可以直接使用了。补丁包里面的资源，只包含原有包里面没有而新的包里面有的新增资源，以及原有内容发生了改变的资源。并且，我们采用了更加优雅的替换方式，直接在原有的AssetManager对象上进行析构和重构(直接在原有AssetManager中addAssetPath这个包,加到已有的AssetManager中)，这样所有原先对AssetManager对象的引用是没有发生改变的，所以就不需要像Instant Run那样进行繁琐的修改了。\n可以说，我们的资源修复方案，优越性超过了Google官方的Instant Run方案。整个资源替换的方案优势在于：\n  不修改AssetManager的引用处，替换更快更完全。（对比Instanat Run以及所有copycat的实现）\n  不必下发完整包，补丁包中只包含有变动的资源。（对比Instanat Run、Amigo等方式的实现）\n  不需要在运行时合成完整包。不占用运行时计算和内存资源。（对比Tinker的实现）\n  SO修复 接口调用转换 Tinker 原理 sdk提供接口替换System默认加载so库的接口\nSOPatchManger.loadLibrary( StringlibName)\n替换\nSystem.loadLibrary( StringlibName)\nSOPatchManger.loadLibrary接口加载so库的时候优先尝试去加载sdk指定目录下补丁的so。若不存在，则再去加载安装apk目录下的so库\n优缺点 优点：不需要对不同sdk版本进行兼容，所以sdk版本都是System.loadLibrary这个接口\n缺点：需要侵入业务代码，替换掉System默认加载so库的接口\n插桩实现 Amigo 饿了么 Sophix 原理 so库的修复本质上是对native方法的修复和替换。\n采用类似类修复的反射注入方式。把补丁so库的路径加到nativeLibraryDirectories数组的最前面，就能够达到加载so库的时候是补丁so库，而不是原来的so库，从而达到修复的目的。\n优缺点 优点：不需侵入用户接口调用\n缺点：需要做版本兼容控制，兼容性较差\n发布流程变化 使用热修复技术后由于发布流程的变化，肯定也需求采用相应的分支管理进行控制。\n通常移动开发的分支管理采用特性分支，如下：\n   分支 描述     master 主分支（只能merge，不能commit，设置权限），用于管理线上版本，及时设置对应Tag   dev 开发分支，每个新版本的研发根据版本号基于主分支创建，测试通过验证后，上线合入master分支   function X 功能分支，按需求设定。基于开发分支创建，完成功能开发后合入dev开发分支    接入热修复后，推荐可参考如下分支策略：\n   分支 描述     master 主分支（只能merge，不能commit，设置权限），用于管理线上版本，及时设置对应Tag（一般3位版本号）   hot_fix 热修复分支。基于master分支创建，修复紧急问题后，测试推送后，将hot_fix再合并到master分支。再次为master分支打tag。（一般4位版本号）   dev 开发分支，每个新版本的研发根据版本号基于主分支创建，测试通过验证后，上线合入master分支   function X 功能分支，按需求设定。基于开发分支创建，完成功能开发后合入dev开发分支    注意热修复分支的测试及发布流程应用正常版本流程一致，保证质量。\n分发监控 目前主流的热修复方案，像Tinker及Sophix都会提供补丁的分发及监控。这也是我们选择热修复技术方案需要考虑的关键因素之一。毕竟为了保证线上版本的质量，分发控制及实时监测必不可少。\n参考 Android热修复技术原理详解\nAndroid热修复技术原理(最新最全)\nAndroid热修复技术，你会怎么选？\n《深入探索Android热修复技术原理7.3Q.pdf》\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/1javacrash/",
	"title": "1javacrash",
	"tags": [],
	"description": "",
	"content": "1javacrash 探索总结1javacrash知识\n JavaCrashSystemHandle     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/1lifecycle/",
	"title": "1lifecycle",
	"tags": [],
	"description": "",
	"content": "1lifecycle 探索总结1lifecycle知识\n Lifecycle     LifecycleCoroutine     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/1managememory/",
	"title": "1manageMemory",
	"tags": [],
	"description": "",
	"content": "Overview of memory management Share memory 图解 graph LR shareMemory--\u0026gt;forksZygoteProcess--\u0026gt;frameworkCode forksZygoteProcess--\u0026gt;resources shareMemory--\u0026gt;mmapStaticData--\u0026gt;odex mmapStaticData--\u0026gt;appResourceTable mmapStaticData--\u0026gt;so shareMemory--\u0026gt;sharedMemoryRegions--\u0026gt;ashmem--\u0026gt;|betweenAppAndScreenCompositor|windowSurfaces ashmem--\u0026gt;|betweenContentProviderAndClient|cursorBuffers sharedMemoryRegions--\u0026gt;gralloc In order to fit everything it needs in RAM, Android tries to share RAM pages across processes. It can do so in the following ways:\n Each app process is forked from an existing process called Zygote. The Zygote process starts when the system boots and loads common framework code and resources (such as activity themes). To start a new app process, the system forks the Zygote process then loads and runs the app\u0026rsquo;s code in the new process. This approach allows most of the RAM pages allocated for framework code and resources to be shared across all app processes. Most static data is mmapped into a process. This technique allows data to be shared between processes, and also allows it to be paged out when needed. Example static data include: Dalvik code (by placing it in a pre-linked .odex file for direct mmapping), app resources (by designing the resource table to be a structure that can be mmapped and by aligning the zip entries of the APK), and traditional project elements like native code in .so files. In many places, Android shares the same dynamic RAM across processes using explicitly allocated shared memory regions (either with ashmem or gralloc). For example, window surfaces use shared memory between the app and screen compositor, and cursor buffers use shared memory between the content provider and client.  Due to the extensive use of shared memory, determining how much memory your app is using requires care. Techniques to properly determine your app\u0026rsquo;s memory use are discussed in Investigating Your RAM Usage.\nAllocate and reclaim app memory The Dalvik heap is constrained to a single virtual memory range for each app process. This defines the logical heap size, which can grow as it needs to but only up to a limit that the system defines for each app.\nThe logical size of the heap is not the same as the amount of physical memory used by the heap. When inspecting your app\u0026rsquo;s heap, Android computes a value called the Proportional Set Size (PSS), which accounts for both dirty and clean pages that are shared with other processes—but only in an amount that\u0026rsquo;s proportional to how many apps share that RAM. This (PSS) total is what the system considers to be your physical memory footprint. For more information about PSS, see the Investigating Your RAM Usage guide.\nThe Dalvik heap does not compact the logical size of the heap, meaning that Android does not defragment the heap to close up space. Android can only shrink the logical heap size when there is unused space at the end of the heap. However, the system can still reduce physical memory used by the heap. After garbage collection, Dalvik walks the heap and finds unused pages, then returns those pages to the kernel using madvise. So, paired allocations and deallocations of large chunks should result in reclaiming all (or nearly all) the physical memory used. However, reclaiming memory from small allocations can be much less efficient because the page used for a small allocation may still be shared with something else that has not yet been freed.\nRestrict app memory To maintain a functional multi-tasking environment, Android sets a hard limit on the heap size for each app. The exact heap size limit varies between devices based on how much RAM the device has available overall. If your app has reached the heap capacity and tries to allocate more memory, it can receive an OutOfMemoryError.\nIn some cases, you might want to query the system to determine exactly how much heap space you have available on the current device—for example, to determine how much data is safe to keep in a cache. You can query the system for this figure by calling getMemoryClass(). This method returns an integer indicating the number of megabytes available for your app\u0026rsquo;s heap.\nMemory allocation among processes Types of memory Android devices contain three different types of memory: RAM, zRAM, and storage. Note that both the CPU and GPU access the same RAM.\nFigure 1. Types of memory - RAM, zRAM, and storage\n RAM is the fastest type of memory, but is usually limited in size. High-end devices typically have the largest amounts of RAM. zRAM is a partition of RAM used for swap space. Everything is compressed when placed into zRAM, and then decompressed when copied out of zRAM. This portion of RAM grows or shrinks in size as pages are moved into or taken out of zRAM. Device manufacturers can set the maximum size. Storage contains all of the persistent data such as the file system and the included object code for all apps, libraries, and the platform. Storage has much more capacity than the other two types of memory. On Android, storage isn’t used for swap space like it is on other Linux implementations since frequent writing can cause wear on this memory, and shorten the life of the storage medium.  Memory pages 图解 graph LR subgraph Can be moved/compressed in zRAM by kswapd zRAMDirty end subgraph written back to the file in storage SharedDirty end subgraph can be deleted by kswapd CachedClean end Pages--\u0026gt;Free Pages--\u0026gt;Used Used--\u0026gt;|backed by a file on storage|Cached Cached--\u0026gt;Private--\u0026gt;CachedClean(\u0026quot;Clean\u0026quot;) Cached--\u0026gt;Shared--\u0026gt;CachedClean Private--\u0026gt;zRAMDirty(\u0026quot;Dirty\u0026quot;) Used--\u0026gt;|not backed by a file on storage|Anonymous--\u0026gt;zRAMDirty(\u0026quot;Dirty\u0026quot;) Shared--\u0026gt;SharedDirty RAM is broken up into pages. Typically each page is 4KB of memory.\nPages are considered either free or used. Free pages are unused RAM. Used pages are RAM that the system is actively using, and are grouped into the following categories:\n Cached: Memory backed by a file on storage (for example, code or memory-mapped files). There are two types of cached memory:  Private: Owned by one process and not shared  Clean: Unmodified copy of a file on storage, can be deleted by kswapd to increase free memory Dirty: Modified copy of the file on storage; can be moved to, or compressed in, zRAM by kswapd to increase free memory   Shared: Used by multiple processes  Clean: Unmodified copy of the file on storage, can be deleted by kswapd to increase free memory Dirty: Modified copy of the file on storage; allows changes to be written back to the file in storage to increase free memory by kswapd, or explicitly using msync() or munmap()     Anonymous: Memory not backed by a file on storage (for example, allocated mmap() with the MAP_ANONYMOUS flag set)  Dirty: Can be moved/compressed in zRAM by kswapd to increase free memory    Note: Clean pages contain an exact copy of a file (or portion of a file) that exists in storage. A clean page becomes a dirty page when it no longer contains an exact copy of the file (for example, from the result of an application operation). Clean pages can be deleted because they can always be regenerated using the data from storage; dirty pages cannot be deleted or else data would be lost.\nLow memory management Android has two main mechanisms to deal with low memory situations: the kernel swap daemon and low-memory killer.\nkernel swap daemon The kernel swap daemon (kswapd) is part of the Linux kernel, and converts used memory into free memory. The daemon becomes active when free memory on the device runs low. The Linux kernel maintains low and high free memory thresholds. When free memory falls below the low threshold, kswapd starts to reclaim memory. Once the free memory reaches the high threshold, kswapd stops reclaiming memory.\nkswapd can reclaim clean pages by deleting them because they\u0026rsquo;re backed by storage and have not been modified. If a process tries to address a clean page that has been deleted, the system copies the page from storage to RAM. This operation is known as demand paging.\nFigure 2. Clean page, backed by storage, deleted\nkswapd can move cached private dirty pages and anonymous dirty pages to zRAM, where they are compressed. Doing so frees up available memory in RAM (free pages). If a process tries to touch a dirty page in zRAM, the page is uncompressed and moved back into RAM. If the process associated with a compressed page is killed, then the page is deleted from zRAM.\nIf the amount of free memory falls below a certain threshold, the system starts killing processes.\nFigure 3. Dirty page moved to zRAM and compressed\nLow-memory killer Many times, kswapd cannot free enough memory for the system. In this case, the system uses onTrimMemory() to notify an app that memory is running low and that it should reduce its allocations. If this is not sufficient, the kernel starts killing processes to free up memory. It uses the low-memory killer (LMK) to do this.\nTo decide which process to kill, LMK uses an \u0026ldquo;out of memory\u0026rdquo; score called oom_adj_score to prioritize the running processes. Processes with a high score are killed first. Background apps are first to be killed, and system processes are last to be killed. The following table lists the LMK scoring categories from high-to-low. Items in the highest-scoring category, in row one, will be killed first:\nFigure 4. Android processes, with high scores at the top and low scores at the bottom\nCalculating memory footprint The kernel tracks all memory pages in the system.\nFigure 5. Pages used by different processes\nWhen determining how much memory is being used by an app, the system must account for shared pages. Apps that access the same service or library will be sharing memory pages. For example, Google Play Services and a game app may be sharing a location service. This makes it difficult to determine how much memory belongs to the service at large versus each application.\nFigure 6. Pages shared by two apps (middle)\nTo determine the memory footprint for an application, any of the following metrics may be used:\n Resident Set Size (RSS): The number of shared and non-shared pages used by the app Proportional Set Size (PSS): The number of non-shared pages used by the app and an even distribution of the shared pages (for example, if three processes are sharing 3MB, each process gets 1MB in PSS) Unique Set Size (USS): The number of non-shared pages used by the app (shared pages are not included)  PSS is useful for the operating system when it wants to know how much memory is used by all processes since pages don’t get counted multiple times. PSS takes a long time to calculate because the system needs to determine which pages are shared and by how many processes. RSS doesn\u0026rsquo;t distinguish between shared and non-shared pages (making it faster to calculate) and is better for tracking changes in memory allocation.\n参考 https://developer.android.com/topic/performance/memory-management\nhttps://developer.android.com/topic/performance/memory\nAPI maxMemory = ((ActivityManager) context.getSystemService(Context.ACTIVITY_SERVICE)).getMemoryClass(); val am: ActivityManager = context.getSystemService(Context.ACTIVITY_SERVICE) as ActivityManager //系统内存信息 val memInfo = ActivityManager.MemoryInfo() am.getMemoryInfo(memInfo); Runtime.getRuntime().maxMemory() Debug.getPss() reader = new RandomAccessFile(\u0026#34;/proc/self/status\u0026#34;, \u0026#34;r\u0026#34;); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/2livedata/1mediatorlivedata/",
	"title": "1MediatorLiveData",
	"tags": [],
	"description": "",
	"content": "原理图 graph LR MediatorLiveData--\u0026gt;|addSource|sourceLiveDataN subgraph SourceN,observeForever when mediatorLiveData acitve sourceLiveDataN--\u0026gt;|onChange|observerN end MediatorLiveData--\u0026gt;|addSource|sourceLiveData2 subgraph Source2,observeForever when mediatorLiveData acitve sourceLiveData2--\u0026gt;|onChange|observer2 end MediatorLiveData--\u0026gt;|addSource|sourceLiveData1 subgraph Source1,observeForever when mediatorLiveData acitve sourceLiveData1--\u0026gt;|onChange|observer1 end MutableLiveData public class MutableLiveData\u0026lt;T\u0026gt; extends LiveData\u0026lt;T\u0026gt; { /** * Creates a MutableLiveData initialized with the given {@code value}. * * @param value initial value */ public MutableLiveData(T value) { super(value); } /** * Creates a MutableLiveData with no value assigned to it. */ public MutableLiveData() { super(); } @Override public void postValue(T value) { super.postValue(value); } @Override public void setValue(T value) { super.setValue(value); } } MediatorLiveData public class MediatorLiveData\u0026lt;T\u0026gt; extends MutableLiveData\u0026lt;T\u0026gt; { private SafeIterableMap\u0026lt;LiveData\u0026lt;?\u0026gt;, Source\u0026lt;?\u0026gt;\u0026gt; mSources = new SafeIterableMap\u0026lt;\u0026gt;(); addSource //监听source的onChanged事件，并将其转发到第二个参数onChanged @MainThread public \u0026lt;S\u0026gt; void addSource(@NonNull LiveData\u0026lt;S\u0026gt; source, @NonNull Observer\u0026lt;? super S\u0026gt; onChanged) { Source\u0026lt;S\u0026gt; e = new Source\u0026lt;\u0026gt;(source, onChanged); Source\u0026lt;?\u0026gt; existing = mSources.putIfAbsent(source, e); if (existing != null \u0026amp;\u0026amp; existing.mObserver != onChanged) { throw new IllegalArgumentException( \u0026#34;This source was already added with the different observer\u0026#34;); } if (existing != null) { return; } if (hasActiveObservers()) { e.plug(); } } removeSource @MainThread public \u0026lt;S\u0026gt; void removeSource(@NonNull LiveData\u0026lt;S\u0026gt; toRemote) { Source\u0026lt;?\u0026gt; source = mSources.remove(toRemote); if (source != null) { source.unplug(); } } onActive @CallSuper @Override protected void onActive() { for (Map.Entry\u0026lt;LiveData\u0026lt;?\u0026gt;, Source\u0026lt;?\u0026gt;\u0026gt; source : mSources) { source.getValue().plug(); } } onInactive @CallSuper @Override protected void onInactive() { for (Map.Entry\u0026lt;LiveData\u0026lt;?\u0026gt;, Source\u0026lt;?\u0026gt;\u0026gt; source : mSources) { source.getValue().unplug(); } } Source private static class Source\u0026lt;V\u0026gt; implements Observer\u0026lt;V\u0026gt; { final LiveData\u0026lt;V\u0026gt; mLiveData; final Observer\u0026lt;? super V\u0026gt; mObserver; int mVersion = START_VERSION; Source(LiveData\u0026lt;V\u0026gt; liveData, final Observer\u0026lt;? super V\u0026gt; observer) { mLiveData = liveData; mObserver = observer; } void plug() { mLiveData.observeForever(this); } void unplug() { mLiveData.removeObserver(this); } @Override public void onChanged(@Nullable V v) { if (mVersion != mLiveData.getVersion()) { mVersion = mLiveData.getVersion(); mObserver.onChanged(v); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/nativecrash/1nativecrash%E9%80%89%E5%9E%8B%E5%92%8C%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B/",
	"title": "1nativeCrash选型和整体流程",
	"tags": [],
	"description": "",
	"content": "原理流程四个阶段 graph LR nativeCrashHappening--\u0026gt;systemHandle(1:SystemHandle)--\u0026gt;|debug|tombstoneFile(TombstoneFile) tombstoneFile--\u0026gt;symbolrecovery(3:SymbolRecovery)--\u0026gt;analysisRootCause(4:AnalysisRootCause) systemHandle--\u0026gt;|release|collectStack(2:CollectStack)--\u0026gt;|upload|tombstoneFile 处理流程 一个完整的 Native 崩溃从捕获到解析要经历哪些流程。\n  编译端。编译 C/C++ 代码时，需要将带符号信息的文件保留下来。\n  客户端。捕获到崩溃时候，将收集到尽可能多的有用信息写入日志文件，然后选择合适的时机上传到服务器。\n  服务端。读取客户端上报的日志文件，寻找适合的符号文件，生成可读的 C/C++ 调用栈。\n  现有的方案 对于很多中小型公司来说，我并不建议自己去实现一套如此复杂的系统，可以选择一些第三方的服务。目前各种平台也是百花齐放，包括腾讯的Bugly、阿里的啄木鸟平台、网易云捕、Google 的 Firebase 等等。\n当然，在平台的选择方面，我认为，从产品化跟社区维护来说，Bugly 在国内做的最好；从技术深度跟捕获能力来说，阿里 UC 浏览器内核团队打造的啄木鸟平台最佳。\nxCrash BreakPad https://chromium.googlesource.com/breakpad/breakpad/+/master\nhttps://chromium.googlesource.com/breakpad/breakpad/+/master/docs/\nhttps://chromium.googlesource.com/breakpad/breakpad/+/master/docs/getting_started_with_breakpad.md\nhttps://github.com/google/breakpad\nhttps://github.com/AndroidAdvanceWithGeektime/Chapter01\nGoogle breakpad是一个跨平台的崩溃转储和分析框架和工具集合。\nBreakpad由三个主要组件：\n client，以library的形式内置在你的应用中，当崩溃发生时写 minidump文件 symbol dumper, 读取由编译器生成的调试信息（debugging information），并生成 symbol file processor， 读取 minidump文件 和 symbol file ，生成可读的c/c++ Stack trace.  简单来说就是一个生成 minidump，一个生成symbol file，然后将其合并处理成可读的Stack trace。\nbugly nativecrash模块+ setCrashHandleCallback监听上报到公司服务器\n选型结论:==xCrash==\n   判断标准 xCrash bugly/网易云捕/阿里的啄木鸟平台     是否开源 是 否   自动上传到三方后台 否 是   是否需要公司后台符号解析 是 是    参考 google breakpad native　crash分析工具\n01 | 崩溃优化（上）：关于“崩溃”那些事儿\nBugly Android 符号表配置\nhttps://chromium.googlesource.com/breakpad/breakpad/+/master\nhttps://bugly.qq.com/docs/user-guide/advance-features-android/?v=20200312155538#crash\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/1space/",
	"title": "1Space",
	"tags": [],
	"description": "",
	"content": "类设计 ART虚拟机提供了多种内存分配手段，它们分别由LargeObjectSpace、BumpPointerSpace、ZygoteSpace、RegionSpace、DlMallocSpace和RosAllocSpace六个类(叶子节点)来实现。ImageSpace用于.art文件的加载\nclassDiagram class Space { +GetNames() +Contains() +IsImageSpace() +IsMallocSpace() +isZygoteSpace() +isBumpPointerSpace() +IsRegionSpace() } class AllocSpace { +GetByteAllocated() +GetObjectsAllocated() +Alloc() +AllocThreadSafe() +Free() +FreeList() } Space \u0026lt;|-- ContinuousSpace ContinuousSpace \u0026lt;|-- MemMapSpace MemMapSpace \u0026lt;|-- ImageSpace MemMapSpace \u0026lt;|-- ContinuousMemMapAllocSpace AllocSpace \u0026lt;|-- ContinuousMemMapAllocSpace AllocSpace \u0026lt;|-- LargeObjectSpace Space \u0026lt;|-- DiscontinuousSpace DiscontinuousSpace \u0026lt;|-- LargeObjectSpace ContinuousMemMapAllocSpace \u0026lt;|-- BumpPointerSpace ContinuousMemMapAllocSpace \u0026lt;|-- RegionSpace ContinuousMemMapAllocSpace \u0026lt;|-- ZygoteSpace ContinuousMemMapAllocSpace \u0026lt;|-- MallocSpace MallocSpace \u0026lt;|-- DlMallocSpace MallocSpace \u0026lt;|-- RosAllocSpace LargeObjectSpace \u0026lt;|-- LargeObjectMapSpace LargeObjectSpace \u0026lt;|-- FreeListSpace SpaceBitmap space_bitmap(-inl).h\nstatic constexpr int kBitsPerIntPtrT = sizeof(intptr_t) * kBitsPerByte; // System page size. We check this against sysconf(_SC_PAGE_SIZE) at runtime, but use a simple // compile-time constant so the compiler can generate better code. static constexpr int kPageSize = 4096; // Required object alignment static constexpr size_t kObjectAlignment = 8; static constexpr size_t kLargeObjectAlignment = kPageSize; typedef SpaceBitmap\u0026lt;kObjectAlignment\u0026gt; ContinuousSpaceBitmap; typedef SpaceBitmap\u0026lt;kLargeObjectAlignment\u0026gt; LargeObjectBitmap; template\u0026lt;size_t kAlignment\u0026gt; class SpaceBitmap { // Backing storage for bitmap.  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map_; // This bitmap itself, word sized for efficiency in scanning.  uintptr_t* const bitmap_begin_; Set(const mirror::Object* obj) bool Set(const mirror::Object* obj) ALWAYS_INLINE { return Modify\u0026lt;true\u0026gt;(obj);//obj是一个内存地址。Modify本身是又是一个模板函数 } Modify(const mirror::Object* obj) inline bool SpaceBitmap\u0026lt;kAlignment\u0026gt;::Modify(const mirror::Object* obj) { uintptr_t addr = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(obj); //offset是obj和heap_begin_（内存基地址）的偏移量  const uintptr_t offset = addr - heap_begin_; //先计算这个偏移量落在哪个字节中  const size_t index = OffsetToIndex(offset); //再计算这个偏移量落在字节的哪个比特位上  const uintptr_t mask = OffsetToMask(offset); //用index取出位图对应的字节（注意，位图存储空间是以字节为单位的，而不是以比特位为单位）  uintptr_t* address = \u0026amp;bitmap_begin_[index];//main  uintptr_t old_word = *address; if (kSetBit) {//kSetBit为true的话，表示往位图中存储某个地址  if ((old_word \u0026amp; mask) == 0) {//如果该比特位还未设置，才设置  *address = old_word | mask;//设置mask比特位  } } else { //取消mask比特位，这相当于从位图中去除对应位置所保存的地址  *address = old_word \u0026amp; ~mask; } return (old_word \u0026amp; mask) != 0; } // \u0026lt;offset\u0026gt; is the difference from .base to a pointer address.  // \u0026lt;index\u0026gt; is the index of .bits that contains the bit representing  // \u0026lt;offset\u0026gt;.  static constexpr size_t OffsetToIndex(size_t offset) { return (offset / kAlignment) / kBitsPerIntPtrT;//先对齐  } template\u0026lt;typename T\u0026gt; static constexpr T IndexToOffset(T index) { return static_cast\u0026lt;T\u0026gt;(index * kAlignment * kBitsPerIntPtrT); } // Bits are packed in the obvious way.  static constexpr uintptr_t OffsetToMask(uintptr_t offset) { return (static_cast\u0026lt;size_t\u0026gt;(1)) \u0026lt;\u0026lt; ((offset / kAlignment) % kBitsPerIntPtrT); } Walk(ObjectCallback* callback, void* arg) template\u0026lt;size_t kAlignment\u0026gt; void SpaceBitmap\u0026lt;kAlignment\u0026gt;::Walk(ObjectCallback* callback, void* arg) { //注意这个函数的参数，callback是回调函数，每次从位图中确定一个对象的地址后将回调它,main  uintptr_t end = OffsetToIndex(HeapLimit() - heap_begin_ - 1); uintptr_t* bitmap_begin = bitmap_begin_; for (uintptr_t i = 0; i \u0026lt;= end; ++i) { uintptr_t w = bitmap_begin[i]; if (w != 0) { uintptr_t ptr_base = IndexToOffset(i) + heap_begin_; do { const size_t shift = CTZ(w);//w中末尾为0的个数，也就是第一个值为1的索引位  //计算该索引位所存储的对象地址值，注意下面代码行中计算对象地址的公式  mirror::Object* obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(ptr_base + shift * kAlignment); (*callback)(obj, arg);//回调callback，arg是传入的参数  w ^= (static_cast\u0026lt;uintptr_t\u0026gt;(1)) \u0026lt;\u0026lt; shift;//清除该索引位的1，继续循环  } while (w != 0); } } } space.h\nSpace class Space { protected: std::string name_; //表示一个Space对象的名称  /*GcRetentionPolicy是一个枚举变量，其定义如下： enum GcRetentionPolicy { //下面这个枚举值表示本空间无需GC kGcRetentionPolicyNeverCollect, //每次GC都需要回收本空间的垃圾对象 kGcRetentionPolicyAlwaysCollect, //只在full GC的时候回收本空间的垃圾对象 kGcRetentionPolicyFullCollect, } */ GcRetentionPolicy gc_retention_policy_; ...... }; ContinuousSpace Continuous spaces have bitmaps, and an address range. Although not required, objects within continuous spaces can be marked in the card table.\n// Address at which the space begins. //ContinuousSpace代表一块内存地址连续的空间，begin_为该内存空间的起始地址  uint8_t* Begin() const { return begin_; } // Current address at which the space ends, which may vary as the space is filled.  //可以将end_看作水位线。如果一个ContinuousSpace对象可分配内存的话，那么end_表示  //当前内存分配到哪了。end_最大不能超过下面的limit_成员变量  uint8_t* End() const { return end_.LoadRelaxed(); } // The end of the address range covered by the space. //limit_是这块内存空间的末尾地址。end_不能超过limit_  uint8_t* Limit() const { return limit_; } public: //Capacity函数返回该空间的容量，值为limit_- begin_  virtual size_t Capacity() const { return Limit() - Begin(); } //Size函数返回该空间当前使用了多少，值为end_- begin_。  size_t Size() const { return End() - Begin(); } } MemMapSpace class MemMapSpace : public ContinuousSpace { protected: std::unique_ptr\u0026lt;MemMap\u0026gt;mem_map_;//该成员变量指向所管理的MemMap对象 } ContinuousMemMapAllocSpace Used by the heap compaction interface to enable copying from one type of alloc space to another.\nclass ContinuousMemMapAllocSpace : public MemMapSpace, public AllocSpace { protected: /*ContinuousSpaceBitmap为数据类型别名，其定义如下： typedef SpaceBitmap\u0026lt;kObjectAlignment\u0026gt; ContinuousSpaceBitmap; kObjectAlignment取值为8。下文将解释这三个成员变量的取值情况。*/ std::unique_ptr\u0026lt;accounting::ContinuousSpaceBitmap\u0026gt;live_bitmap_; std::unique_ptr\u0026lt;accounting::ContinuousSpaceBitmap\u0026gt;mark_bitmap_; std::unique_ptr\u0026lt;accounting::ContinuousSpaceBitmap\u0026gt;temp_bitmap_; } BumpPointerSpace   Sequential Allocation或Linear Allocation, 正因为BumpPointerSpace采用了如此简单的内存分配算法，所以它压根就不能释放某一次所分配的内存（和ZygoteSpace一样，Free等函数没有真正的实现），而只支持一次性释放所有已分配的内存（实现了AllocSpace的Clear函数）。\n  BumpPointer-Space非常适合做线程本地内存分配——Thread Local Allocation Blocks，简写为TLAB，它代表一块专属某个线程的内存资源\n  Create // A bump pointer space allocates by incrementing a pointer, it doesn\u0026#39;t provide a free // implementation as its intended to be evacuated. BumpPointerSpace* BumpPointerSpace::Create(const std::string\u0026amp; name, size_t capacity, uint8_t* requested_begin) { capacity = RoundUp(capacity, kPageSize); std::string error_msg; //创建MemMap对象  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map(MemMap::MapAnonymous(name.c_str(), requested_begin, capacity,...)); ..... return new BumpPointerSpace(name, mem_map.release()); } BumpPointerSpace::BumpPointerSpace(const std::string\u0026amp; name, MemMap* mem_map) : ContinuousMemMapAllocSpace(name, mem_map, mem_map-\u0026gt;Begin(), mem_map-\u0026gt;Begin(), mem_map-\u0026gt;End(),GcRetentionPolicyAlwaysCollect), growth_end_(mem_map-\u0026gt;End()),//内存资源的尾部。分配的内存不允许超过该位置  objects_allocated_(0),//创建了多少个mirror Object对象  bytes_allocated_(0), //分配了多少字节的内存  block_lock_(\u0026#34;Block lock\u0026#34;, kBumpPointerSpaceBlockLock), main_block_size_(0),//main_block_size_和num_blocks_的作用见下文代码分析  num_blocks_(0) { } Alloc Alloc用于为某个mirror Object对象分配所需的内存。 inline mirror::Object* BumpPointerSpace::Alloc(Thread*, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { /* Alloc函数的原型由AllocSpace类定义，其参数的含义为： self：第一个参数。代表调用线程的线程对象，由于BumpPointerSpace没有使用这个参数， 所以上面的参数列表中并没有它（注意，第一个参数有参数类型，但没有参数名）。 num_bytes:第二个参数。此次内存分配所需的内存大小 bytes_allocated：实际分配了多少内存。它是一个输出参数。如果内存分配成功的话，该参数 大于或等于num_bytes。有一些内存分配算法会在实际所需内存大小上额外多分配一些内存用以 存储该算法所需的特殊信息。 usable_size：输出参数。如上文所说，实际分配的内存可能比所需内存要多。该变量表示所分配 的内存资源中可被外界使用的大小。显然，如果内存分配成功的话，该变量大于或等于num_bytes。 bytes_tl_bulk_allocated：它和thread local内存分配有关，其作用见下文代码分析。 另外，Alloc函数返回值的类型为mirror Object*。所以，Alloc就是用于为一个 Java Object对象（虚拟机中对应一个mirror Object对象）分配所需内存的函数。 */ //num_bytes按8字节向上对齐（kAlignment为8）  num_bytes = RoundUp(num_bytes, kAlignment); mirror::Object* ret = AllocNonvirtual(num_bytes);//main  //设置返回值参数  if (LIKELY(ret != nullptr)) { //BumpPointerSpace内存分配算法无需额外信息。所以实际分配内存大小就是num_bytes  //当然，num_bytes已经按8字节向上对齐  *bytes_allocated = num_bytes; if (usable_size != nullptr) { *usable_size = num_bytes; } *bytes_tl_bulk_allocated = num_bytes; } return ret; } AllocNonvirtual inline mirror::Object* BumpPointerSpace::AllocNonvirtual(size_t num_bytes) { //具体的内存分配由下面这个函数完成  mirror::Object* ret = AllocNonvirtualWithoutAccounting(num_bytes); if (ret != nullptr) { /*objects_allocated_和bytes_allocated_的类型为AtomicInteger，可在多个线程中实现原子操作。其中； objects_allocated_：表示当前所分配的Object对象的个数。 bytes_allocated_：当前所分配的总内存大小。 下面的FetchAndAddSequentiallyConsistent函数为原子操作，相当于做加法。 */ objects_allocated_.FetchAndAddSequentiallyConsistent(1); bytes_allocated_.FetchAndAddSequentiallyConsistent(num_bytes); } return ret; } AllocNonvirtualWithoutAccounting inline mirror::Object* BumpPointerSpace::AllocNonvirtualWithoutAccounting( size_t num_bytes) { uint8_t* old_end; uint8_t* new_end; /*end_类型为Atomic\u0026lt;uint8_t*\u0026gt;，它是ContinuousSpace类的成员变量，它表示上一次内 存分配的末尾位置。也就是Bump Pointer的位置。BumpPointerSpace构造函数中，该成员变 量取值等于内存的起始位置。由于BumpPointerSpace的分配算法很简单，所以只需使用原子变量 即可实现多线程并发操作。 */ do { old_end = end_.LoadRelaxed();//获取当前末尾位置  new_end = old_end + num_bytes;//计算新的末尾位置  if (UNLIKELY(new_end \u0026gt;growth_end_)) {//如果超过内存资源的大小，则返回空指针  return nullptr; } } while (!end_.CompareExchangeWeakSequentiallyConsistent( old_end, new_end)); //while循环退出后，end_将指向最新的末尾位置new_end。此次内存分配得到的内存起始地址为old_end,main  return reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(old_end); } AllocNewTlab //AllocNewTlab：当ART虚拟机决定从调用线程的本地存储空间中分配内存时将调用此函数。 bool BumpPointerSpace::AllocNewTlab(Thread* self, size_t bytes) { //注意参数，self代表调用线程，bytes代表此次内存分配的大小  MutexLock mu(Thread::Current(), block_lock_); //先释放self线程原来的TLAB（Thread Local Allocation Buffer），TLAB其实就代表一块内存  RevokeThreadLocalBuffersLocked(self); uint8_t* start = AllocBlock(bytes);//main  if (start == nullptr) { return false; } //设置self线程的TLAB，起始位置为start，结束位置为start+bytes。TLAB的详情见下文介绍。  self-\u0026gt;SetTlab(start, start + bytes); return true; } AllocBlock // Returns the start of the storage. uint8_t* BumpPointerSpace::AllocBlock(size_t bytes) { bytes = RoundUp(bytes, kAlignment); /*num_blocks_表示当前分配了多少内存块。每次调用AllocBlock都对应一个内存块。 BumpPointerSpace中，这样的内存块由BlockHeader数据结构来描述，其内容为： struct BlockHeader { size_t size_; //内存块总大小 size_t unused_; //还剩多少空余内存 }; */ //如果是第一次分配内存块，则需要设置main_block_size_的值。UpdateMainBlock  //的实现很简单，就是将当前已经分配的内存大小（由end_减去begin_）赋值给main_block_size_  if (!num_blocks_) { UpdateMainBlock();//内部的代码为：main_block_size_ = Size();  } //分配内存，在原来所需内存大小的基础上加上BlockHeader结构体所需内存  uint8_t* storage = reinterpret_cast\u0026lt;uint8_t*\u0026gt;( AllocNonvirtualWithoutAccounting(bytes + sizeof(BlockHeader)));//main  if (LIKELY(storage != nullptr)) { BlockHeader* header = reinterpret_cast\u0026lt;BlockHeader*\u0026gt;(storage); header-\u0026gt;size_ = bytes;//设置BlockHeader的信息。  storage += sizeof(BlockHeader);//返回给外部使用者的内存不包括BlockHeader部分  ++num_blocks_;//num_blocks_递增1  } return storage; } Free(Thread*, mirror::Object*) size_t Free(Thread*, mirror::Object*) OVERRIDE { return 0;//直接返回0，说明BumpPointerSpace不能释放某一个Object所占据的内存 } Clear void BumpPointerSpace::Clear() { if (!kMadviseZeroes) {//Linux平台上该值为true。  memset(Begin(), 0, Limit() - Begin());//将对应内存资源的内容清零  } //下面这个函数的作用和上面代码中调用memset清零内存空间的效果类似，我们在11.4.7节中介绍过它  madvise(Begin(), Limit() - Begin(), MADV_DONTNEED), -1); SetEnd(Begin());//设置end_等于begin_。  //所有相关成员变量恢复为初值  objects_allocated_.StoreRelaxed(0); bytes_allocated_.StoreRelaxed(0); growth_end_ = Limit(); { MutexLock mu(Thread::Current(), block_lock_); num_blocks_ = 0; main_block_size_ = 0; } Walk(ObjectCallback* callback, void* arg) void BumpPointerSpace::Walk(ObjectCallback* callback, void* arg) { uint8_t* pos = Begin(); uint8_t* end = End(); uint8_t* main_end = pos; { { MutexLock mu(Thread::Current(), block_lock_); if (num_blocks_ == 0) { UpdateMainBlock();//计算main block的大小。  } main_end = Begin() + main_block_size_; if (num_blocks_ == 0) { end = main_end; } } //先遍历main block  while (pos \u0026lt; main_end) { mirror::Object* obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(pos); /*判断这个obj是不是真实存在。从内存角度来说obj本身是存在的，因为上面代码中obj直 接由内存地址转换而来。所以obj肯定不为空指针。但obj可能并不是真正的对象。下面的 GetClass函数将获取该obj对应的klass_（该对象所属的类）。如果为空，说明obj并 不存在。对BumpPointerSpace使用的内存分配算法而言，也就没必要继续遍历了。 所以下面的if条件满足后，函数就直接返回了。*/ if (obj-\u0026gt;GetClass\u0026lt;kDefaultVerifyFlags, kWithoutReadBarrier\u0026gt;() == nullptr) { return;} else { callback(obj, arg);//调用callback,main  //获取下一个对象的位置，  pos = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(GetNextObject(obj));//main  } } //如果还有其他线程的TLAB的话，则继续遍历。此时就需要考虑BlockHeader的存在了  while (pos \u0026lt; end) { BlockHeader* header = reinterpret_cast\u0026lt;BlockHeader*\u0026gt;(pos); size_t block_size = header-\u0026gt;size_; pos += sizeof(BlockHeader); mirror::Object* obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(pos); const mirror::Object* end_obj = reinterpret_cast\u0026lt;const mirror::Object*\u0026gt;(pos + block_size); while (obj \u0026lt; end_obj \u0026amp;\u0026amp; obj-\u0026gt;GetClass\u0026lt;kDefaultVerifyFlags, kWithoutReadBarrier\u0026gt;() != nullptr) { callback(obj, arg); obj = GetNextObject(obj); } pos += block_size; } } GetNextObject(mirror::Object* obj) mirror::Object* BumpPointerSpace::GetNextObject(mirror::Object* obj) { //obj表示当前所遍历的object对象的地址。那么，下一个对象的地址就是obj+obj的大小。  const uintptr_t position = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(obj) + obj-\u0026gt;SizeOf(); //按8字节对齐  return reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(RoundUp(position, kAlignment)); } GetBytesAllocated uint64_t BumpPointerSpace::GetBytesAllocated() { //由图13-2可知，bytes_allocated_表示main block部分所分配的内存大小  uint64_t total = static_cast\u0026lt;uint64_t\u0026gt;(bytes_allocated_.LoadRelaxed()); Thread* self = Thread::Current(); ...... /*如果有多个线程使用TLAB，则需要计算它们的TLAB大小。 */ std::list\u0026lt;Thread*\u0026gt;thread_list = Runtime::Current()-\u0026gt;GetThreadList()-\u0026gt;GetList(); ...... if (num_blocks_ \u0026gt; 0) { for (Thread* thread : thread_list) { total += thread-\u0026gt;GetThreadLocalBytesAllocated();//Thread GetThreadLocalBytesAllocated返回值就是tlsPtr_.thread_local_end减去 tlsPtr_.thread_local_start的差。  } } return total; } RegionSpace  RegionSpace的内存分配算法比BumpPointerSpace稍微高级一点。它先将内存资源划分成一个个固定大小（由kRegionSize指定，默认为1MB）的内存块。每一个内存块由一个Region对象表示。进行内存分配时，先找到满足要求的Region，然后从这个Region中分配资源。  class RegionSpace FINAL : public ContinuousMemMapAllocSpace { ...... //枚举变量RegionType用于描述内存块的类型。有些内容需要结合内存回收的相关知识才能理解，  //此处暂且不表  enum class RegionType : uint8_t { kRegionTypeAll, kRegionTypeFromSpace, kRegionTypeUnevacFromSpace, kRegionTypeToSpace, kRegionTypeNone, }; //枚举变量RegionState用于描述内存块的内存分配状态。  enum class RegionState : uint8_t { kRegionStateFree, //内存块还未分配过内存  kRegionStateAllocated, //内存块分配过一些内存  /*如果需要分配比如3.5MB空间的话，则需要动用四个内存块。第一个内存块的状态将设置为 kRegionStateLarge，表示该Region为一个超过kRegionSize大小的内存的起始部分。 后面三个内存块的状态均为kRegionStateLargeTail。注意，第四个内存块将只用到0.5MB 的空间，剩下的0.5MB空间不能再用于内存分配。 */ kRegionStateLarge, kRegionStateLargeTail, }; } Create RegionSpace* RegionSpace::Create(const std::string\u0026amp; name, size_t capacity, uint8_t* requested_begin) { capacity = RoundUp(capacity, kRegionSize);//按1MB大小向上对齐  std::string error_msg; //创建一个MemMap对象  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map(MemMap::MapAnonymous(name.c_str(), requested_begin, capacity, ...)); ...... //创建RegionSpace对象  return new RegionSpace(name, mem_map.release()); } RegionSpace::RegionSpace(const std::string\u0026amp; name, MemMap* mem_map) : ContinuousMemMapAllocSpace(name, mem_map, mem_map-\u0026gt;Begin(), mem_map-\u0026gt;End(), mem_map-\u0026gt;End(),kGcRetentionPolicyAlwaysCollect), region_lock_(\u0026#34;Region lock\u0026#34;, kRegionSpaceRegionLock), time_(1U) { size_t mem_map_size = mem_map-\u0026gt;Size(); //计算有多少个Region,main  num_regions_ = mem_map_size / kRegionSize;//1MB  num_non_free_regions_ = 0U;//该成员变量表示已经占有的内存块个数  //创建Region数组  regions_.reset(new Region[num_regions_]); uint8_t* region_addr = mem_map-\u0026gt;Begin(); //初始化regions_数组的成员  for (size_t i = 0; i \u0026lt; num_regions_; ++i, region_addr += kRegionSize) { //构造Region对象。region_addr表示该区域的起始地址，region_addr+kRegionSize  //为该内存区域的尾部地址  regions_[i] = Region(i, region_addr, region_addr + kRegionSize); } //full_region_表示一个内存资源不足的内存块，其用法见下文代码分析  full_region_ = Region(); //current_region_指向当前正在用的内存块,main  current_region_ = \u0026amp;full_region_; //evac_region_成员变量的含义需要配合内存回收相关知识才能理解，我们后文碰到时再介绍  evac_region_ = nullptr; } Alloc inline mirror::Object* RegionSpace::Alloc(Thread*, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //按8字节向上对齐  num_bytes = RoundUp(num_bytes, kAlignment); return AllocNonvirtual\u0026lt;false\u0026gt;(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } template\u0026lt;bool kForEvac\u0026gt; inline mirror::Object* RegionSpace::AllocNonvirtual(size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //AllocNonvirtual函数有一个模板参数kForEvac。该参数和内存回收有关。我们先不讨论它。  //Alloc调用AllocNonvirtual时，kForEvac取值为false  mirror::Object* obj; //如果所需内存小于kRegionSize，则从当前的region对象中分配  if (LIKELY(num_bytes \u0026lt;= kRegionSize)) { if (!kForEvac) { //调用Region的Alloc函数。由RegionSpace的Create函数可知，current_region_  //最初是指向full_region_的。所以，下面的Alloc肯定返回nullptr  obj = current_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  } else {//如果kForEvac为true，则从evac_region_指向的Region中分配  obj = evac_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } //如果obj创建成功，则返回它  if (LIKELY(obj != nullptr)) { return obj; } //如果执行到这，表明上面的内存分配失败。注意，上面的代码中并未使用锁同步。现在，  //我们需要重新尝试分配（因为有可能别的线程设置了current_region_，使得它指向  //一个新的内存块，而这个内存块里说不定就有空闲的内存资源）  MutexLock mu(Thread::Current(), region_lock_); //具体的内存分配代码和上面完全一样  if (!kForEvac) { obj = current_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  } else { obj = evac_region_-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } if (LIKELY(obj != nullptr)) { return obj; } //如果此时内存还分配失败（说明其他线程没有更新current_region_），则我们需要自己  //来遍历regions_数组以找到一个空闲的内存块,main  if (!kForEvac) { /*RegionSpace的用法和Copying垃圾回收方法有关，该方法要求预留一半的内存作为 fromspace。所以，在下面的if条件中，如果已经被占用的内存块个数超过总内存块个数的 一半，则不再允许内存分配。*/ if ((num_non_free_regions_ + 1) * 2 \u0026gt;num_regions_) { return nullptr;} //遍历内存块，找到一个空闲的内存块  for (size_t i = 0; i \u0026lt;num_regions_; ++i) { Region* r = \u0026amp;regions_[i];//main  //Region IsFree返回region state_成员变量的值。regions_数组中各个Region  //对象的state_初值为kRegionStateFree，表示内存块还未分配过内存  if (r-\u0026gt;IsFree()) { //Region Unfree设置state_的值为kRegionStateAllocated，同时设置  //type_为kRegionTypeToSpace  r-\u0026gt;Unfree(time_); r-\u0026gt;SetNewlyAllocated(); ++num_non_free_regions_; obj = r-\u0026gt;Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  current_region_ = r;//更新current_region_  return obj; } } } else { //kForEvac为true的处理 ...... } AllocNewTlab bool RegionSpace::AllocNewTlab(Thread* self) { MutexLock mu(self, region_lock_); RevokeThreadLocalBuffersLocked(self); //同Alloc函数里的注释一样，我们要预留一半的空间  if ((num_non_free_regions_ + 1) * 2 \u0026gt; num_regions_) { return false; } //找到一个空闲的Region对象  for (size_t i = 0; i \u0026lt; num_regions_; ++i) { Region* r = \u0026amp;regions_[i]; if (r-\u0026gt;IsFree()) { r-\u0026gt;Unfree(time_); ++num_non_free_regions_; r-\u0026gt;SetTop(r-\u0026gt;End()); //将这个Region和对应的线程关联起来,main  r-\u0026gt;is_a_tlab_ = true; r-\u0026gt;thread_ = self; //对线程而言，它只需要关注TLAB是否存在。如果存在的话，这块内存有多大。线程并不关心  //内存是由哪个Space以何种方式提供。  self-\u0026gt;SetTlab(r-\u0026gt;Begin(), r-\u0026gt;End()); return true; } } return false; } Free(Thread*, mirror::Object*) size_t Free(Thread*, mirror::Object*) OVERRIDE { UNIMPLEMENTED(FATAL);//不能释放单个对象所分配的内存  return 0; } Clear void RegionSpace::Clear() { MutexLock mu(Thread::Current(), region_lock_); //遍历regions_数组  for (size_t i = 0; i \u0026lt; num_regions_; ++i) { Region* r = \u0026amp;regions_[i]; if (!r-\u0026gt;IsFree()) { --num_non_free_regions_; } r-\u0026gt;Clear();//调用Region Clear  } current_region_ = \u0026amp;full_region_; evac_region_ = \u0026amp;full_region_; } Walk(ObjectCallback* callback, void* arg) void Walk(ObjectCallback* callback, void* arg) { WalkInternal\u0026lt;false\u0026gt;(callback, arg); } RegionSpace::Region class Region { public: Region() //idx_为内存块在RegionSpace regions_数组中的索引  : idx_(static_cast\u0026lt;size_t\u0026gt;(-1)), //begin_和end_代表内存资源的起始位置，top_为内存分配的水位线  begin_(nullptr), top_(nullptr), end_(nullptr), state_(RegionState::kRegionStateAllocated), type_(RegionType::kRegionTypeToSpace), //objects_allocated_表示创建了多少个Object对象，  objects_allocated_(0), ...... //is_a_tlab_表示该内存块是否被用作TLAB，thread_表示用它作TLAB的线程  is_a_tlab_(false), thread_(nullptr) { //RegionSpace构造函数中，full_region_成员变量通过这个构造函数来创建  } //RegionSpace构造函数中，regions_数组中的Region元素通过下面这个构造函数来创建  Region(size_t idx, uint8_t* begin, uint8_t* end) : idx_(idx), begin_(begin), top_(begin), end_(end), state_(RegionState::kRegionStateFree), type_(RegionType::kRegionTypeNone), ...... {} } Alloc inline mirror::Object* RegionSpace::Region::Alloc(size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //atomic_top指向当前内存分配的位置  Atomic\u0026lt;uint8_t*\u0026gt;* atomic_top = reinterpret_cast\u0026lt;Atomic\u0026lt;uint8_t*\u0026gt;*\u0026gt;(\u0026amp;top_); uint8_t* old_top; uint8_t* new_top; //更新分配后的内存位置  do { old_top = atomic_top-\u0026gt;LoadRelaxed(); new_top = old_top + num_bytes; if (UNLIKELY(new_top \u0026gt; end_)) { return nullptr; } } while (!atomic_top-\u0026gt;CompareExchangeWeakSequentiallyConsistent( old_top, new_top)); reinterpret_cast\u0026lt;Atomic\u0026lt;uint64_t\u0026gt;*\u0026gt;(\u0026amp;objects_allocated_)-\u0026gt; FetchAndAddSequentiallyConsistent(1); *bytes_allocated = num_bytes; if (usable_size != nullptr) { *usable_size = num_bytes; } *bytes_tl_bulk_allocated = num_bytes; return reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(old_top); } Clear void Clear() { top_ = begin_; state_ = RegionState::kRegionStateFree; type_ = RegionType::kRegionTypeNone; objects_allocated_ = 0; alloc_time_ = 0; live_bytes_ = static_cast\u0026lt;size_t\u0026gt;(-1); if (!kMadviseZeroes) {memset(begin_, 0, end_ - begin_);} madvise(begin_, end_ - begin_, MADV_DONTNEED); is_newly_allocated_ = false; is_a_tlab_ = false; thread_ = nullptr; } MallocSpace MallocSpace::MallocSpace(const std::string\u0026amp; name, MemMap* mem_map, ....., bool create_bitmaps,.....) : ContinuousMemMapAllocSpace(name, mem_map,.... kGcRetentionPolicyAlwaysCollect), ...... { //DlMallocSpace和RosAllocSpace创建时均设置create_bitmaps为true  if (create_bitmaps) { //bitmap_index_是一个全局静态变量，用于给位图对象命名  size_t bitmap_index = bitmap_index_++; ...... /*创建live_bitmap_和mark_bitmap_。我们不关心它们的命名。这两个位图对象覆盖的内存 范围从MemMap Begin开始，大小是MemMap Size（NonGrowthLimitCapacity函数内部 调用MemMap Size）。简单点说，live_bitmap_和mark_bitmap_位图对象所包含的位图数 组恰好覆盖了这个MallocSpace所关联的MemMap内存空间。*/ live_bitmap_.reset(accounting::ContinuousSpaceBitmap::Create(...,Begin(),NonGrowthLimitCapacity())); mark_bitmap_.reset(accounting::ContinuousSpaceBitmap::Create(..., Begin(), NonGrowthLimitCapacity())); heap.cc\nHeap::CreateMallocSpaceFromMemMap space::MallocSpace* Heap::CreateMallocSpaceFromMemMap(MemMap* mem_map, size_t initial_size, size_t growth_limit, size_t capacity, const char* name, bool can_move_objects) { /*注意参数，mem_map代表一块内存空间，内存的分配和释放均是在它上面发生的。 initial_size为内存空间初始分配大小。 growth_limit为最大的内存可分配位置，而capacity则为实际内存空间的容量。 growth_limit可以动态调整，但是不能超过capacity。 can_move_objects参数的含义和一种垃圾回收的算法有关。我们以后碰到相关代码时再 来介绍它。 */ space::MallocSpace* malloc_space = nullptr; if (kUseRosAlloc) {//编译常量，默认为true，即ART优先使用rosalloc  //kDefaultStartingSize为编译常量，大小为4K。下面将创建RosAllocSpace对象  //low_memory_mode_表示是否为低内存模式。只有RosAllocSpace支持该模式  malloc_space = space::RosAllocSpace::CreateFromMemMap( mem_map, name, kDefaultStartingSize, initial_size, growth_limit,apacity,low_memory_mode_,can_move_objects); } else { //使用DlMallocSpace。它不支持low memory模式  malloc_space = space::DlMallocSpace::CreateFromMemMap(mem_map, name, kDefaultStartingSize,initial_size, growth_limit, capacity, can_move_objects); } //kUseRememberedSet值为true，下面这段if代码的相关知识留待13.8节介绍  if (collector::SemiSpace::kUseRememberedSet\u0026amp;\u0026amp; non_moving_space_ != main_space_) { //创建一个RememberedSet对象。详情见13.8节的内容  accounting::RememberedSet* rem_set = new accounting::RememberedSet(std::string(name) + \u0026#34; remembered set\u0026#34;, this, malloc_space); AddRememberedSet(rem_set); } malloc_space-\u0026gt;SetFootprintLimit(malloc_space-\u0026gt;Capacity()); return malloc_space; } dlmalloc_space.cc\nDlMallocSpace Create DlMallocSpace* DlMallocSpace::Create(const std::string\u0026amp; name, size_t initial_size, size_t growth_limit, size_t capacity, uint8_t* requested_begin, bool can_move_objects) { uint64_t start_time = 0; size_t starting_size = kPageSize; //先创建内存资源  MemMap* mem_map = CreateMemMap(name, starting_size, \u0026amp;initial_size, \u0026amp;growth_limit, \u0026amp;capacity, requested_begin); //再创建DlMallocSpace对象。CreateFromMemMap的代码见下文  DlMallocSpace* space = CreateFromMemMap(......); return space; } CreateFromMemMap DlMallocSpace* DlMallocSpace::CreateFromMemMap(MemMap* mem_map, const std::string\u0026amp; name, size_t starting_size, size_t initial_size, size_t growth_limit, size_t capacity, bool can_move_objects) { //内部调用dlmalloc的接口，starting_size为初始大小，initial_size为dlmalloc的  //limit水位线。CreateMspace返回的mspace为dlmalloc内部使用的结构，外界用void*  //作为它的数据类型,main  void* mspace = CreateMspace(mem_map-\u0026gt;Begin(), starting_size, initial_size); .... uint8_t* end = mem_map-\u0026gt;Begin() + starting_size; //调用mprotect保护从starting_size水位线到capacity这段内存，后续将根据需要进行调整  if (capacity - starting_size \u0026gt; 0) { CHECK_MEMORY_CALL(mprotect, (end, capacity - starting_size, PROT_NONE),name); } uint8_t* begin = mem_map-\u0026gt;Begin(); if (Runtime::Current()-\u0026gt;IsRunningOnMemoryTool()) { ...... } else {//构造DlMallocSpace对象，它的参数比较多。将mspace传给DlMallocSPace,main  return new DlMallocSpace(mem_map, initial_size, name, mspace, begin, end, begin + capacity,growth_limit, can_move_objects, starting_size); } } void* DlMallocSpace::CreateMspace(void* begin, size_t morecore_start, size_t initial_size) { errno = 0; //create_mspace_with_base和mspace_set_footprint_limit均是dlmalloc的API  void* msp = create_mspace_with_base(begin, morecore_start, false); if (msp != nullptr) { mspace_set_footprint_limit(msp, initial_size); } ...... return msp; } rosalloc_space.cc\nRosAllocSpace Create RosAllocSpace* RosAllocSpace::Create(const std::string\u0026amp; name, size_t initial_size, size_t growth_limit, size_t capacity, uint8_t* requested_begin, bool low_memory_mode, bool can_move_objects) { uint64_t start_time = 0; //kDefaultStartingSize取值为一个内存页的大小，对x86 32位平台而言，其值为4KB  size_t starting_size = Heap::kDefaultStartingSize; //先创建一个MemMap对象  MemMap* mem_map = CreateMemMap(name, starting_size, \u0026amp;initial_size, \u0026amp;growth_limit, \u0026amp;capacity, requested_begin); //再创建RosAllocSpace对象  RosAllocSpace* space = CreateFromMemMap(......); return space; } CreateFromMemMap RosAllocSpace* RosAllocSpace::CreateFromMemMap(MemMap* mem_map, const std::string\u0026amp; name, size_t starting_size, size_t initial_size,size_t growth_limit, size_t capacity, bool low_memory_mode, bool can_move_objects) { bool running_on_memory_tool = Runtime::Current()-\u0026gt;IsRunningOnMemoryTool(); //CreateRosAlloc将创建rosallc对象,main  allocator::RosAlloc* rosalloc = CreateRosAlloc( mem_map-\u0026gt;Begin(), starting_size, initial_size, capacity, low_memory_mode, running_on_memory_tool); uint8_t* end = mem_map-\u0026gt;Begin() + starting_size; uint8_t* begin = mem_map-\u0026gt;Begin(); if (running_on_memory_tool) { ...... } else {//构造一个RosAllocSpace对象。RosAllocSpace构造函数和  //DlMallocSpace构造函数类似，都很简单，笔者不拟介绍它。  return new RosAllocSpace(mem_map, initial_size, name, rosalloc,...); } } allocator::RosAlloc* RosAllocSpace::CreateRosAlloc(void* begin, size_t morecore_start,size_t initial_size, size_t maximum_size, bool low_memory_mode,....) { errno = 0; //new一个RosAlloc对象，它就是rosalloc模块。低内存模式将影响rosalloc内存释放的算法  allocator::RosAlloc* rosalloc = new art::gc::allocator::RosAlloc( begin, morecore_start, maximum_size, low_memory_mode ? art::gc::allocator::RosAlloc::kPageReleaseModeAll : art::gc::allocator::RosAlloc::kPageReleaseModeSizeAndEnd, running_on_memory_tool); if (rosalloc != nullptr) { rosalloc-\u0026gt;SetFootprintLimit(initial_size); } ...... return rosalloc; } RosAlloc::RosAlloc(void* base, size_t capacity, size_t max_capacity, PageReleaseMode page_release_mode, bool running_on_memory_tool, size_t page_release_size_threshold) : base_(reinterpret_cast\u0026lt;uint8_t*\u0026gt;(base)), footprint_(capacity), capacity_(capacity), max_capacity_(max_capacity), ...... { .... /*图13-4、图13-5中的bracketSizes、headSizes和numOfPages等数组均为RosAlloc态 的静成员变量。下面的Initialize函数将初始化它们。初始化的结果已经绘制在图13-4、 图13-5中了。感兴趣的读者可自行研究该函数的代码。*/ if (!initialized_) { Initialize(); } //创建同步锁，一共42个。当从不同粒度的内存资源池中分配内存时将使用不同的同步锁  //对象进行保护。这样处理的好处是可提高内存分配的并发效率  for (size_t i = 0; i \u0026lt;kNumOfSizeBrackets; i++) { size_bracket_lock_names_[i] = StringPrintf(\u0026#34;an rosalloc size bracket %d lock\u0026#34;, static_cast\u0026lt;int\u0026gt;(i)); size_bracket_locks_[i] = new Mutex( size_bracket_lock_names_[i].c_str(), kRosAllocBracketLock); /*current_runs_为Run*定长数组，元素个数为42。下面的代码将设置数组的内容都指向 dedicated_full_run_。dedicated_full_run_是RosAlloc的静态成员变量，类型为 Run*。它代表一块没有内存可供分配的资源池。一般而言，可以将current_runs_各个元素 设置为nullptr。但使用current_runs_的地方就需要判断其元素是否为nullptr。所以， 此处的做法是将current_runs_各成员指向这个无法分配资源的Run对象。这样就可以消除 空指针的判断。而代码处理dedicated_full_run_时就和处理其他那些正常的资源分配殆尽的 Run对象一样即可，后续我们将看到相关的代码。*/ current_runs_[i] = dedicated_full_run_; } size_t num_of_pages = footprint_ / kPageSize; size_t max_num_of_pages = max_capacity_ / kPageSize; std::string error_msg; //创建page_map_mem_map_ MemMap对象，参考图13-6  page_map_mem_map_.reset(MemMap::MapAnonymous(\u0026#34;rosalloc page map\u0026#34;, nullptr, RoundUp(max_num_of_pages, kPageSize),.....)); //page_map_mem_map_基地址是page_map_  page_map_ = page_map_mem_map_-\u0026gt;Begin(); page_map_size_ = num_of_pages;//该RosAlloc所管理的内存页有多大，参考图13-6  max_page_map_size_ = max_num_of_pages;//内存最大有多少个内存页  //free_page_run_size_map_为vector数组，类型为size_t。其作用我们下文再介绍  free_page_run_size_map_.resize(num_of_pages); //将base_强转成一个FreePageRun对象，可参考图13-6  FreePageRun* free_pages = reinterpret_cast\u0026lt;FreePageRun*\u0026gt;(base_); //设置本free_pages对象的大小并释放相关内存页。最开始时base_所对应的内存块全部  //都是空闲的，所以第一个free_pages的大小为capacity_  free_pages-\u0026gt;SetByteSize(this, capacity_);//main  free_pages-\u0026gt;ReleasePages(this);//释放本free_pages所包含的内存,main  //free_page_runs_为set\u0026lt;FreePageRun*\u0026gt;容器  free_page_runs_.insert(free_pages); } RosAlloc::FreePageRun::SetByteSize\nvoid SetByteSize(RosAlloc* rosalloc, size_t byte_size) { /*下面两行代码的含义如下： 先得到本FreePageRun的基地址fpr_base。根据上面RosAlloc的构造函数可知，FreePageRun 对象是将base_内存块上的地址强制转换数据类型得到的。 ToPageMapIndex函数用于返回fpr_base在page_map_中的索引号。参考图13-6可知，page_map_ 一个元素代表base_中一个内存页。所以，ToPageMapIndex的实现就很容易想到了，即用fpr_base- base_，然后除以内存页大小即可算出该FreePageRun对象对应哪个内存页 */ uint8_t* fpr_base = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(this); size_t pm_idx = rosalloc-\u0026gt;ToPageMapIndex(fpr_base); //free_page_run_size_map_是一个数组，下面将设置对应索引的元素的值，  //用于表示对应FreePageRun对象所管理的内存空间大小  rosalloc-\u0026gt;free_page_run_size_map_[pm_idx] = byte_size; } RosAlloc::FreePageRun::ReleasePages\nvoid ReleasePages(RosAlloc* rosalloc) { uint8_t* start = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(this); //ByteSize函数是上文SetByteSize函数的对应，用于返回free_page_run_size_map_  //对应元素的值。在RosAlloc构造函数调用流程中，byte_size返回为capacity_  size_t byte_size = ByteSize(rosalloc); //ShouldReleasePages判断是否需要释放内存页。我们下文再介绍它  if (ShouldReleasePages(rosalloc)) { //直接看下面这个函数。start表示本FreePageRun对象在base_内存块中的起始位置  rosalloc-\u0026gt;ReleasePageRange(start, start + byte_size);//main  } } RosAlloc::ReleasePageRange\nsize_t RosAlloc::ReleasePageRange(uint8_t* start, uint8_t* end) { //start和end参数用于指明要释放的内存的起始和终点位置  //清零这段内存  if (!kMadviseZeroes) { memset(start, 0, end - start);} CHECK_EQ(madvise(start, end - start, MADV_DONTNEED), 0); //调用者只是指明了内存段的起始和终点位置，我们需要将这个位置转换为RosAlloc内部的  //内存页位置  size_t pm_idx = ToPageMapIndex(start);//返回start位置对应的内存页索引号  size_t reclaimed_bytes = 0; //返回end位置对应的内存页索引号  const size_t max_idx = pm_idx + (end - start) / kPageSize; for (; pm_idx \u0026lt; max_idx; ++pm_idx) { /*图13-6中曾说过，page_map_保存base_中各内存页的状态，kPageMapEmpty即为其中的 一种状态。内存页的初始状态为kPageMapReleased，表示内存在系统中还未分配。 kPageMapEmpty表示内存可以被回收。 */ if (page_map_[pm_idx] == kPageMapEmpty) { reclaimed_bytes += kPageSize;//reclaimed_bytes表示此次回收的内存大小  page_map_[pm_idx] = kPageMapReleased;//设置对应内存页的状态  } } return reclaimed_bytes; } AllocCommon inline mirror::Object* RosAllocSpace::AllocCommon(Thread* self, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { size_t rosalloc_bytes_allocated = 0; size_t rosalloc_usable_size = 0; size_t rosalloc_bytes_tl_bulk_allocated = 0; ...... //调用RosAlloc的Alloc函数分配内存。我们下文会详细介绍rosalloc内存分配算法  mirror::Object* result = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;( rosalloc_-\u0026gt;Alloc\u0026lt;kThreadSafe\u0026gt;(self, num_bytes, \u0026amp;rosalloc_bytes_allocated, \u0026amp;rosalloc_usable_size, \u0026amp;rosalloc_bytes_tl_bulk_allocated)); ...... return result; } rosalloc.h\nRosAlloc::Alloc template\u0026lt;bool kThreadSafe\u0026gt; inline ALWAYS_INLINE void* RosAlloc::Alloc(Thread* self, size_t size, size_t* bytes_allocated,size_t* usable_size, size_t* bytes_tl_bulk_allocated) { //Alloc是一个模板函数，包含模板参数kThreadSafe，默认值为true。ART虚拟机中  //绝大部分情况下该模板参数都使用这个默认的true。我们重点介绍它的处理情况  //kLargeSizeThreshold为2KB。如果所需的内存超过2KB，则使用AllocLargeObject  //来处理。AllocLargeObject将留给读者自行阅读  if (UNLIKELY(size \u0026gt;kLargeSizeThreshold)) { return AllocLargeObject(self, size, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } void* m; //我们将着重介绍kThreadSafe为true的情况  if (kThreadSafe) { m = AllocFromRun(self, size, bytes_allocated, usable_size, bytes_tl_bulk_allocated);//main  } else { .....//kThreadSafe为false的情况，读者在学完本节的基础上可自行研究它  } return m; } RosAlloc::AllocFromRun RosAlloc原理图 //RosAllocSpace //kNumOfSizeBrackets值为42,描述每种slot所支持的内存分配粒度  static size_t bracketSizes[kNumOfSizeBrackets]; //numOfPages则记录了每种slot对应的内存资源有多少（以4KB字节为单位）  static size_t numOfPages[kNumOfSizeBrackets]; 一个Run对应一种粒度(一行)\nRosAllc::AllocFromRun流程图 graph TB SizeToIndex(\u0026quot;size_t idx = SizeToIndexAndBracketSize(size, \u0026amp;bracket_size)\u0026quot;)--\u0026gt;indexBelow16{\u0026quot;idx \u0026lt; 16?\u0026quot;} indexBelow16--\u0026gt;|yes|getRosAllocRun(\u0026quot;Run* thread_local_run = self-\u0026gt;GetRosAllocRun(idx)\u0026quot;) getRosAllocRun--\u0026gt;AllocSlot(\u0026quot;slot_addr = thread_local_run-\u0026gt;AllocSlot();\u0026quot;) AllocSlot--\u0026gt;slotAddrIsNull{\u0026quot;slot_addr == nullptr?\u0026quot;} slotAddrIsNull--\u0026gt;|yes|RefillRun(\u0026quot;thread_local_run = RefillRun(self, idx);\u0026quot;) RefillRun--\u0026gt;AllocSlot2(\u0026quot;slot_addr = thread_local_run-\u0026gt;AllocSlot();\u0026quot;) indexBelow16--\u0026gt;|no|AllocFromCurrentRunUnlocked(\u0026quot;slot_addr = AllocFromCurrentRunUnlocked(self, idx);\u0026quot;) void* RosAlloc::AllocFromRun(Thread* self, size_t size, size_t* bytes_allocated,size_t* usable_size, size_t* bytes_tl_bulk_allocated) { size_t bracket_size; /*SizeToIndexAndBracketSize将根据调用者所期望分配的内存大小来决定使用哪种粒度的资源池 （idx表示索引号）以及这种资源池中slot的大小（由bracket_size决定）。*/ size_t idx = SizeToIndexAndBracketSize(size, \u0026amp;bracket_size);//main  void* slot_addr; //kNumThreadLocalSizeBrackets取值为16。由图13-4可知，idx小于16的话，对应的内  //存分配粒度最大不超过128字节。所以，下面if条件满足的话，说明所要分配的内存大小小于  //128字节  if (LIKELY(idx\u0026lt;kNumThreadLocalSizeBrackets)) { /*如果所需内存不超过128字节，我们会尝试从线程本地内存资源池中分配内存。注意，线程本地存储 内存池并不是前文提到的TLAB。但它和TLAB含义类似。只不过Thread类对rosalloc有单独的支持。下面的Thread GetRosAllocRun函数将返回tlsPtr_.rosalloc_runs数组对应索引的元 素。读者回顾7.5.2.1节可知，tlsPtr_有一个rosalloc_runs数组，包含16个元素，它们初始 化都指向RosAlloc的dedicated_full_run_对象。 这段if代码块表示当我们所需要的内存小于128字节时，RosAlloc将尝试从调用线程所拥有的本地 资源池中分配内存，这样就不需要同步锁的保护了，如此可提高内存分配的速度。 注意，由于初始值都指向dedicated_full_run_，下面的代码执行时将无须判断thread_local_ run是否为nullptr。*/ Run* thread_local_run = reinterpret_cast\u0026lt;Run*\u0026gt;(self-\u0026gt;GetRosAllocRun(idx)); //tlsPtr_ rosallc_runs默认取值也是dedicated_full_run_，在这个Run对象中没有可分配内  //的内存资源。所以，首次调用下面的AllocSlot必然返回nullptr，表明当前这个Run中没有空闲存了  slot_addr = thread_local_run-\u0026gt;AllocSlot(); if (UNLIKELY(slot_addr == nullptr)) { /*如果slot_addr为空指针，说明thread_local_run这个Run中没有空余内存。 下面我们就需要解决这个问题。此时就需要同步锁的保护了。但我们只需要使用目标索引的同步 锁就行了。比如，分配8字节内存不够用时，我们就用保护8字节资源的同步锁。如此，它就不会 和保护其他内存资源的同步锁竞争，从而可提高内存分配速度。*/ MutexLock mu(self, *size_bracket_locks_[idx]); bool is_all_free_after_merge; /*参考图13-5，Run中有thread_local_free_list_和free_list_两个用于管理空闲slot 的SlotFreeList对象。MergeThreadLocalFreeListToFreeList函数将thread_local_ free_list_里的空闲资源合并到free_list_。 对于dedicate_full_run_来说，合并它们后，空闲资源并不会增加，所以该函数返回false。 请读者阅读掌握本章内容后再自行研究下面这个函数。*/ if (thread_local_run-\u0026gt;MergeThreadLocalFreeListToFreeList( \u0026amp;is_all_free_after_merge)) {...... } else {//MergeThreadLocalFreeListToFreeList返回false的情况  ...... //RefillRun是重点，它将给idx所对应的Run对象添加内存资源，所以叫Refill  thread_local_run = RefillRun(self, idx);//main  ..... //将thread_local_run设置为调用线程的线程本地内存资源池  thread_local_run-\u0026gt;SetIsThreadLocal(true); self-\u0026gt;SetRosAllocRun(idx, thread_local_run); } //bytes_tl_bulk_allocated表示本资源池中剩余的内存  *bytes_tl_bulk_allocated = thread_local_run-\u0026gt;NumberOfFreeSlots() * bracket_size; //重新分配资源。AllocSlot非常简单，就是从free_list_中返回一个Slot对象。  slot_addr = thread_local_run-\u0026gt;AllocSlot();//main  } else {//slot_addr不为nullptr的处理  *bytes_tl_bulk_allocated = 0; } *bytes_allocated = bracket_size; *usable_size = bracket_size; } else { /*当所需内存超过128字节时，将从RosAlloc内部的资源池中分配。这个时候也需要 同步锁来保护了。当然，如上面代码一样，不同大小的资源池会使用不同的同步锁来保护。 AllocFromCurrentRunUnlocked将从RosAlloc的current_runs_[idx]中进行分配。 如果current_runs_[idx]对应的资源池内存资源不足，将会调用RefillRun给对应的资源池重新加满内存资源。*/ MutexLock mu(self, *size_bracket_locks_[idx]); slot_addr = AllocFromCurrentRunUnlocked(self, idx);//main  if (LIKELY(slot_addr != nullptr)) { *bytes_allocated = bracket_size; *usable_size = bracket_size; *bytes_tl_bulk_allocated = bracket_size; } } return slot_addr; } RosAlloc::RefillRun RosAlloc::Run* RosAlloc::RefillRun(Thread* self, size_t idx) { ......//这里还有一段处理，读者以后可自行研究这段代码  return AllocRun(self, idx);//我们看这个函数 } RosAlloc::Run* RosAlloc::AllocRun(Thread* self, size_t idx) { RosAlloc::Run* new_run = nullptr; { MutexLock mu(self, lock_); /*AllocPages函数将从base_所在的内存中分配一段内存空间。这内存空间对外由一个Run 对象来管理。该空间的大小（以4KB为单位）由numOfPages[idx]决定。kPageMapRun 是内存页状态中的一种。 */ new_run = reinterpret_cast\u0026lt;Run*\u0026gt;(AllocPages(self, numOfPages[idx], kPageMapRun));//main  } if (LIKELY(new_run != nullptr)) { new_run-\u0026gt;size_bracket_idx_ = idx; .....//清理这块内存资源池  //初始化Run对象中的free_list_成员。  new_run-\u0026gt;InitFreeList(); } return new_run; } RosAlloc::AllocPages void* RosAlloc::AllocPages(Thread* self, size_t num_pages, uint8_t page_map_type) { //AllocPages是以内存页为单位进行分配的  lock_.AssertHeld(self); FreePageRun* res = nullptr;//RosAlloc借助FreePageRun来管理内存分配  //req_bytes_size是以字节为单位的内存大小  const size_t req_byte_size = num_pages * kPageSize; //free_pages_runs_为Set\u0026lt;FreePageRun*\u0026gt;，第一个元素在RosAlloc构造函数中添加，  //这个元素位于base_，所包含的空闲内存大小为capacity_。  for (auto it = free_page_runs_.begin(); it != free_page_runs_.end(); ) { FreePageRun* fpr = *it; size_t fpr_byte_size = fpr-\u0026gt;ByteSize(this); //如果当前的FreePageRun对象所管理的空闲内存资源比所需内存要多，则对当前fpr对象进行拆分  if (req_byte_size \u0026lt;= fpr_byte_size) { free_page_runs_.erase(it++);//当前fpr对象从容器中移除  if (req_byte_size \u0026lt; fpr_byte_size) { //新的fpr对象为当前fpr对象的起始位置+待分配内存大小  FreePageRun* remainder = reinterpret_cast\u0026lt;FreePageRun*\u0026gt;(reinterpret_cast\u0026lt;uint8_t*\u0026gt;(fpr) + req_byte_size); //新fpr对象所管理的空闲内存资源大小等于原fpr的大小减去此次分配的内存大小  remainder-\u0026gt;SetByteSize(this, fpr_byte_size - req_byte_size); free_page_runs_.insert(remainder);//把新的fpr对象加入容器  //更新原fpr对象所管理的内存资源大小，它将作为返回值返回给调用者  fpr-\u0026gt;SetByteSize(this, req_byte_size); } res = fpr; break; } else { ++it; } } /*如果free_page_runs_中没有合适的FreePageRun对象，则考虑是否需要进行扩容。 base_所在的内存块初始设置的大小是capacity_，当前可用的大小由footprint_ base_所在的内存块初始设置的大小是capacity_，当前可用的大小由footprint_控制。如果footprint_小于capacity_，则还能继续扩容。这部分代码比较复杂，建议读者 学完本节后再自行阅读它*/ ...... if (LIKELY(res != nullptr)) { //更新内存页的状态信息。page_map_idx表示res这块新分配内存所对应的状态信息所在数组的索引  size_t page_map_idx = ToPageMapIndex(res); switch (page_map_type) { case kPageMapRun: //如上文所述，page_map_保存了base_内存页的状态信息。如果一次分配了多个内存页的话，  //第一个内存页的状态将设置为kPageMapRun，其余内存页的状态为kPageMapRunPart  page_map_[page_map_idx] = kPageMapRun; for (size_t i = 1; i \u0026lt; num_pages; i++) { page_map_[page_map_idx + i] = kPageMapRunPart; } break; ...... } return res; } InitFreeList void InitFreeList() { const uint8_t idx = size_bracket_idx_; const size_t bracket_size = bracketSizes[idx]; const size_t bracket_size = bracketSizes[idx]; /*结合图13-5可知，FirstSlot函数这个Run中第一个slot的位置。代码中，一个slot由Slot类 表示。Slot内部有一个next_成员变量，指向下一个Slot对象。所以，一个Run中的Slot对象可 构成一个链表来管理。*/ Slot* first_slot = FirstSlot(); /*LastSlot返回Run中最后一个Slot的位置。free_list_是Run的成员变量，其数据类型 为SlotFreeList\u0026lt;false\u0026gt;，它是RosAlloc实现的一个用于管理Slot的容器。下面的for 循环将把图13-5 Run中的Slot对象通过free_list_管理起来。虽然下面的代码是从末尾 Slot向前遍历，但最终结果就是free_list_ head_指向第一个Slot对象。而Run中的所有 Slot对象又通过上面提到的Slot next_成员变量构成一个链表。 */ for (Slot* slot = LastSlot(); slot \u0026gt;= first_slot; slot = slot-\u0026gt;Left(bracket_size)) { free_list_.Add(slot); } } RosAlloc::Run::AllocSlot inline void* RosAlloc::Run::AllocSlot() { /*Remove将free_list_中移除head_所指向的那个Slot单元。从这一点可以看出，Run对Slot的管 理是比较简单的。就是通过一个链表把Slot单元管理起来，每次要分配的时候取链表的头部返回给 外界。*/ Slot* slot = free_list_.Remove(); ..... return slot; } // Compute numOfSlots and slotOffsets.  for (size_t i = 0; i \u0026lt; kNumOfSizeBrackets; i++) { size_t bracket_size = bracketSizes[i]; size_t run_size = kPageSize * numOfPages[i]; size_t max_num_of_slots = run_size / bracket_size; // Search for the maximum number of slots that allows enough space  // for the header.  for (int s = max_num_of_slots; s \u0026gt;= 0; s--) { size_t tmp_slots_size = bracket_size * s; if (tmp_slots_size + tmp_header_size \u0026lt;= run_size) { // Found the right number of slots, that is, there was enough  // space for the header (including the bit maps.)  num_of_slots = s; header_size = tmp_header_size; break; } Free size_t RosAllocSpace::Free(Thread* self, mirror::Object* ptr) { .... return rosalloc_-\u0026gt;Free(self, ptr);//调用RosAlloc的Free函数释放内存 } DiscontinuousSpace class DiscontinuousSpace : public Space { protected: /*LargeObjectBitmap为类型别名，其定义如下： typedef SpaceBitmap\u0026lt;kLargeObjectAlignment\u0026gt;LargeObjectBitmap; kLargeObjectAlignment为常量，值为内存页的大小（4KB）。SpaceBitmap的详情可回顾 7.6.1.1.1节的内容。简单来说，SpaceBitmap是一个位图数组，该数组以比特位为元素： (1) 数组的每一位对应一段内存空间中一个内存单元的位置。内存单元的大小等于模板参数的值。 比如上面的kLargeObjectAlignment表示以一个内存单元大小为4KB (2) 如果位图数组某个元素取值为1，则表明对应的内存单元中有内容。如果为0，则表示对应的内存单元没有内容。比如，我们在内存单元中创建了一个对象时，就需要修改位图数组中对应比特位元素的值为1。*/ std::unique_ptr\u0026lt;accounting::LargeObjectBitmap\u0026gt;live_bitmap_; std::unique_ptr\u0026lt;accounting::LargeObjectBitmap\u0026gt;mark_bitmap_; } DiscontinuousSpace::DiscontinuousSpace(const std::string\u0026amp; name, GcRetentionPolicy gc_retention_policy) : Space(name, gc_retention_policy) { const size_t capacity = static_cast\u0026lt;size_t\u0026gt;(std::numeric_limits\u0026lt;uint32_t\u0026gt;::max()); live_bitmap_.reset(accounting::LargeObjectBitmap::Create(\u0026#34;large live objects\u0026#34;, nullptr, capacity)); mark_bitmap_.reset(accounting::LargeObjectBitmap::Create(\u0026#34;large marked objects\u0026#34;, nullptr, capacity)); } LargeObjectMapSpace LargeObjectMapSpace* LargeObjectMapSpace::Create(const std::string\u0026amp; name) { if (Runtime::Current()-\u0026gt;IsRunningOnMemoryTool()) {......} else {//构造一个LargeObjectMapSpace对象。其构造函数非常简单  return new LargeObjectMapSpace(name); } } Alloc mirror::Object* LargeObjectMapSpace::Alloc(Thread* self, size_t num_bytes, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { std::string error_msg; //这就是LargeObjectMapSpace的内存分配算法，直接创建一个MemMap对象  MemMap* mem_map = MemMap::MapAnonymous(\u0026#34;large object space allocation\u0026#34;, nullptr, num_bytes, PROT_READ | PROT_WRITE, true, false, \u0026amp;error_msg); //将这块内存映射空间的基地址转换为返回值的类型  mirror::Object* const obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;( mem_map-\u0026gt;Begin()); MutexLock mu(self, lock_); /*large_objects_是LargeObjectMapSpace的成员变量，类型为 AllocationTrackingSafeMap\u0026lt;mirror::Object*, LargeObject, kAllocatorTagLOSMaps\u0026gt;。读者不要被这个看起来很复杂的数据结构吓到， AllocationTrakingSafeMap其实就是一个map，key的类型是Object*，value的类型是 LargeObject。LargeObject是LargeObjectMapSpace中的内部类，用于保存该内存映射 空间所对应的MemMap对象。 */ large_objects_.Put(obj, LargeObject {mem_map, false}); ......//其他一些处理，略过  return obj; } thread.h\nThread //虽然tlsPtr_是我们的老熟人了，但它还有一些成员变量的含义在前面的章节中没有介绍 struct PACKED(sizeof(void*)) tls_ptr_sized_values { ...... //下面这个变量表示TLAB上分配了多个对象  size_t thread_local_objects; //指明TLAB的起始位置  uint8_t* thread_local_start; /*指明TLAB当前所分配的内存位置，它位于thread_local_start和thread_local_end 之间。[thread_local_start,thead_local_pos)这部分空间属于已经分配的内存， [thead_local_pos,thread_local_end)这部分为空闲待分配的内存。*/ uint8_t* thread_local_pos; uint8_t* thread_local_end;//指明TLAB的末尾位置  ...... } tlsPtr_; SetTlab void Thread::SetTlab(uint8_t* start, uint8_t* end) { tlsPtr_.thread_local_start = start; tlsPtr_.thread_local_pos = tlsPtr_.thread_local_start; tlsPtr_.thread_local_end = end; tlsPtr_.thread_local_objects = 0; } AllocTlab inline mirror::Object* Thread::AllocTlab(size_t bytes) { ++tlsPtr_.thread_local_objects; mirror::Object* ret = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(tlsPtr_.thread_local_pos); tlsPtr_.thread_local_pos += bytes;//更新内存水位线即可  return ret; } TLAB设计思路 "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/1startup/1startup/",
	"title": "1startup",
	"tags": [],
	"description": "",
	"content": "Flutter 安卓平台源码剖析\nFlutter启动流程源码分析\n深入理解Flutter引擎启动\u0026ndash;详细\nFlutter作为一款跨平台的框架，可以运行在Android、iOS等平台，Android为例讲解如何从Android应用启动流程中衔接到Flutter框架，如何启动Flutter引擎的启动流程。 熟悉Android的开发者，应该都了解APP启动过程，会执行Application和Activity的初始化，并调用它们的onCreate()方法。那么FlutterApplication和FlutterActivity的onCreate()方法是连接Native和Flutter的枢纽。\n FlutterApplication.java的onCreate过程：初始化配置文件/加载libflutter.so/注册JNI方法； FlutterActivity.java的onCreate过程：创建FlutterView、Engine, Dart虚拟机、Isolate、taskRunner等对象，最终执行执行到Dart的main()方法，执行runApp(Widget app)来处理整个Dart业务代码。  深入理解Flutter应用启动\u0026ndash;runApp(Widget app)方法开始\nrunApp(MyApp)是flutter应用开始真正执行业务逻辑代码的起点，整个过程主要工作：\n WidgetsFlutterBinding初始化：这是一个单例模式，负责创建WidgetsFlutterBinding对象，WidgetsFlutterBinding继承抽象类BindingBase，并且附带7个mixin，初始化渲染、语义化、绘制、平台消息以及手势等一系列操作； attachRootWidget：遍历挂载整个视图树，并建立Widget、Element、RenderObject之间的连接与关系，此处Element的具体类型为RenderObjectToWidgetElement； scheduleWarmUpFrame：调度预热帧，执行帧绘制方法handleBeginFrame和handleDrawFrame。  从WidgetsFlutterBinding是单例模式，从小节[2.4]得WidgetsBinding的renderViewElement记录着唯一的RenderObjectToWidgetElement对象，从小节[2.3.2]可知RendererBinding的renderView记录着唯一的RenderView对象；也就是说每个flutter应用创建的Root Widget跟Element、RenderObject一一对应，且单例唯一。\nMyApp是用户定义的根Widget，为了建立三棵树的关系，RenderObjectToWidgetAdapter起到重要的桥接功能，该类的createElement方法创建RenderObjectToWidgetElement对象，createRenderObject()方法获取的是RenderView。\n "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/1startup/",
	"title": "1startup",
	"tags": [],
	"description": "",
	"content": "1startup 探索总结1startup知识\n 1startup     2startup_embedder_framwwork     3flutter_surface     4startup_dart_framework     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/xcrash/1xcrash%E5%8E%9F%E7%90%86/",
	"title": "1xCrash原理",
	"tags": [],
	"description": "",
	"content": "xCrash 架构与实现 整体架构 xCrash 整体分为两部分：运行于崩溃的 APP 进程内的部分，和独立进程的部分（我们称为 dumper）。\n1、APP 进程内 这部分可以再分为 Java 和 native 两个部分。\n（1）Java 部分： ①Java 崩溃捕获。直接使用 JVM 提供的机制来完成，最后生成兼容 tombstone 格式的 dump 文件。\n②Native 崩溃捕获机制的注册器。通过 JNI 激活 native 层的对应机制。\n③Tombstone 文件解析器。可以将 tombstone 文件解析成 json 格式。\n④Tombstone 文件管理器。可以检索设备上已经生成的 tombstone 文件。\n（2）Native 部分： ①JNI Bridge。负责与 Java 层的交互。（传参与回调）\n②Signal handlers。负责信号捕获，以及启动独立进程 dumper。\n③Fallback mode。负责当 dumper 捕获崩溃信息失败时，尝试在崩溃进行的 signal handler 中收集崩溃信息。\n2、Dumper 独立进程 这部分是纯 native 的实现： ①Process。负责崩溃进程中各个线程的控制（attach 和 detach），以及进程层面的信息收集，比如 FD 列表、logcat 等等。\n②Threads。负责崩溃进程中的线程相关数据的收集，比如 registers、backtrace、stack 等等。\n③Memory Layout。负责 maps 和 smaps 的解析。\n④Memory。负责各种内存数据的读写。比如来自本地 buffer、来自mmap() 的 ELF 文件、或者通过 ptrace() 远程访问的崩溃进程的内存。\n⑤Registers。负责各种处理机架构相关的数据处理。\n⑥ELF。负责 ELF 信息的解析。需要解析各种 unwind table 和 symbols 信息，有时需要使用 LZMA 解压 .gnu_debugdata 中的 mini debug info 信息做进一步的处理。\nxCrash 的其他功能 除了获取常见的设备信息、registers、backtrace、stack、memory near、maps、logcat 等基本信息，xCrash 还提供以下的功能：\n1、完整的 FD 列表\n让你知道崩溃时进程中的每一个 FD 具体都用在了哪里。\n2、详细的内存使用统计\n获取了操作系统全局的物理内存使用统计、崩溃进程的虚拟内存使用统计、崩溃进程的内存详细使用信息（类似 dumpsys meminfo）。让你对进程崩溃时的内存状态有全面的了解。\n3、用正则白名单设置需要获取哪些线程的信息\nAPP 的线程数超过 100 个是很常见的，如果像系统 tombstone 那样总是获取全部线程的 registers、backtrace 等信息，在大多数情况下是没有必要的；这也容易导致 unwind 时间过长，崩溃捕获逻辑还没有走完，APP 就被系统强杀了。xCrash 让你能通过一组正则表达式白名单来设置需要获取哪些线程的信息。\n4、零权限需求\nxCrash 不需要 root 权限，也不需要任何的 APP 系统权限，这让使用 xCrash 的 APP 没有任何权限方面的负担。\n5、监测设备是否已被 root\n监测的过程是完全透明和无感知的。在后期分析数据时，如果发现某个崩溃只发生在已被 root 的设备上，就有理由怀疑是否是一些特别的原因造成的。\n6、极高的崩溃信息捕获成功率\nxCrash 通过 FD 预留；Flash “占坑”文件；写文件失败时通过预分配内存保存 backtrace 等重要信息做紧急回调、clone() + execl() 失败后进入 fallback 模式执行本地 unwind 等一系列保护措施，最大程度的保证了崩溃信息捕获的成功率。\n7、扩展性支持\nxCrash 支持崩溃后附加用户自定义信息。目前在爱奇艺 APP 中，已经通过 xCrash 的扩展能力，在崩溃时投递了大播放日志、弹幕日志、NLE视频编辑日志、APP Life Cycle Trace等信息。为排查特定业务的崩溃问题提供支持。\n参考 干货|安卓app崩溃捕获方案——xcrash\nhttps://github.com/iqiyi/xCrash\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/1%E6%8F%92%E4%BB%B6%E5%8C%96%E9%9D%A2%E4%B8%B4%E7%9A%84%E9%97%AE%E9%A2%98/",
	"title": "1插件化面临的问题",
	"tags": [],
	"description": "",
	"content": "图解 graph LR subgraph 解决插件组件生命周期调用问题 插件生命周期 end subgraph 反射AssetManager.assetPath,再通过AssetManager来创建一个新的Resources对象 加载插件资源 end subgraph newDexClassLoader加载插件apk,从插件ClassLoader中load指定的插件Activity名字,newInstance之后强转为Activity类型使用 加载插件类 end subgraph 上下文如BaseContext,mResources,activityInfo在attach时反射替换为插件的 直接提供插件Activity给系统 end 插件生命周期--\u0026gt;启动插件Activity 启动插件Activity--\u0026gt;HookInstrumentation的execStartActivity 启动插件Activity--\u0026gt;|Shadow|更改启动Activity方式,调用自定义方法到插件进程,转成插代理Activity 插件生命周期--\u0026gt;AMS回到App端 AMS回到App端--\u0026gt;直接提供插件Activity给系统--\u0026gt;Hack修改宿主PathClassLoader 直接提供插件Activity给系统--\u0026gt;HackActivityThread主线程Handler AMS回到App端--\u0026gt;提供代理Activity给系统--\u0026gt;生命周期转发给插件Activity 提供代理Activity给系统--\u0026gt;|Shadow|生命周期转发给插件Activity,再转调回代理Activity 加载插件类 Shadow的全动态设计原理解析\nJava还有两个和动态化相关的特性，一个是接口，另一个是向上转型。\nClass\u0026lt;?\u0026gt; implClass = classLoader.loadClass(\u0026#34;com.xxx.AImpl\u0026#34;); Object implObject = implClass.newInstance(); A a = (A) implObject; 这里假设classLoader动态加载了一些Java类，其中就有一个类叫做com.xxx.AImpl，AImpl继承自A，或者AImpl实现了A接口。注意这里用了强制类型转换，是因为代码层面是将Object类型向下转型成了A。但实际上我们知道implObject的类型是AImpl，AImpl转换成A是一个向上转型。向上转型总是安全的。所以用这种方法总是可以先定义出接口，精心设计接口，让接口足够通用和稳定。只要接口不变，它的实现总是可以修改的。我们将接口打包在宿主中，接口就轻易不能更新了。但是它的实现总是可以更新的。\n加载插件资源 传统方式 https://github.com/singwhatiwanna/dynamic-load-apk/\n我们知道，activity的工作主要是由ContextImpl来完成的， 它在activity中是一个叫做mBase的成员变量。注意到Context中有如下两个抽象方法，看起来是和资源有关的，实际上context就是通过它们来获取资源的，这两个抽象方法的真正实现在ContextImpl中。也即是说，只要我们自己实现这两个方法，就可以解决资源问题了。\n/** Return an AssetManager instance for your application\u0026#39;s package. */ public abstract AssetManager getAssets(); /** Return a Resources instance for your application\u0026#39;s package. */ public abstract Resources getResources(); 下面看一下如何实现这两个方法 首先要加载apk中的资源：\nprotected void loadResources() { try { AssetManager assetManager = AssetManager.class.newInstance(); Method addAssetPath = assetManager.getClass().getMethod(\u0026#34;addAssetPath\u0026#34;, String.class); addAssetPath.invoke(assetManager, mDexPath); mAssetManager = assetManager; } catch (Exception e) { e.printStackTrace(); } Resources superRes = super.getResources(); mResources = new Resources(mAssetManager, superRes.getDisplayMetrics(), superRes.getConfiguration()); mTheme = mResources.newTheme(); mTheme.setTo(super.getTheme()); } 说明：加载的方法是通过反射，通过调用AssetManager中的addAssetPath方法，我们可以将一个apk中的资源加载到Resources中，由于addAssetPath是隐藏api我们无法直接调用，所以只能通过反射，下面是它的声明，通过注释我们可以看出，传递的路径可以是zip文件也可以是一个资源目录，而apk就是一个zip，所以直接将apk的路径传给它，资源就加载到AssetManager中了，然后再通过AssetManager来创建一个新的Resources对象，这个对象就是我们可以使用的apk中的资源了，这样我们的问题就解决了。\nShadow使用的方式 val packageManager = hostAppContext.packageManager val packageArchiveInfo = packageManager.getPackageArchiveInfo( archiveFilePath, PackageManager.GET_ACTIVITIES or PackageManager.GET_META_DATA or PackageManager.GET_SERVICES or PackageManager.GET_PROVIDERS or PackageManager.GET_SIGNATURES ) packageArchiveInfo.applicationInfo.nativeLibraryDir = installedApk.libraryPath packageArchiveInfo.applicationInfo.dataDir = dataDir.absolutePath packageArchiveInfo.applicationInfo.publicSourceDir = archiveFilePath packageArchiveInfo.applicationInfo.sourceDir = archiveFilePath packageManager.getResourcesForApplication(packageArchiveInfo.applicationInfo) getResourcesForApplication控制AssetManager加载插件路径里的资源： createAssetManager(ResourcesKey):358, ResourcesManager (android.app), ResourcesManager.java createResourcesImpl(ResourcesKey):490, ResourcesManager (android.app), ResourcesManager.java getOrCreateResources(IBinder, ResourcesKey, ClassLoader):787, ResourcesManager (android.app), ResourcesManager.java getResources(IBinder, String, String[], String[], String[], int, Configuration, CompatibilityInfo, ClassLoader):853, ResourcesManager (android.app), ResourcesManager.java getTopLevelResources(String, String[], String[], String[], int, LoadedApk):1940, ActivityThread (android.app), ActivityThread.java getResourcesForApplication(ApplicationInfo):1420, ApplicationPackageManager (android.app), ApplicationPackageManager.java create(PackageInfo, String, Context):32, CreateResourceBloc (com.tencent.shadow.core.loader.blocs), CreateResourceBloc.kt call():109, LoadPluginBloc$loadPlugin$buildResources$1 (com.tencent.shadow.core.loader.blocs), LoadPluginBloc.kt 上述创建的插件Resource存放在ShadowPluginLoader中PluginPartsMap对应的entry value也就是pluginParts中，pluginParts保存了插件application，classLoader，resources等信息\n上述resource被用来构造mixResource并在ShadowActivityDelegate的getResource方法中返回mixResource，默认使用插件resource\n 不同插件之间，宿主和插件之间的资源管理方面：\n 公用一套资源，需要采用固定资源id及ID分段机制避免冲突 独立资源方案，不同插件管理自己的资源  解决插件组件生命周期调用问题 插件Activity生命周期\n动态代理和Binder hook(AMS和PMS)方式，如360的DroidPlugin方案等  以下是静态代理，占坑方式偷梁换柱\n启动插件Activity替换成代理Activity  1.1 通过Hook Instrumentation的execStartActivity()把intent中的插件Activity替换成代理Activity，让系统去启动代理Activity 1.2 宿主启动插件，更改启动Activity的方式，通过调用FastPluginManager的startPluginActivity方法到插件进程将插件Activity转成成代理ContainerActivity(Shadow中宿主启动插件的方式)正常启动 1.3 插件Activity跳转内部Activity，在super类内部控制转调代理Activity  再次回到App端初始化Activity时，需要将代理Activity替换成(或转调到)插件Activity 有几种Hook方式可以实现\n 2.1：直接提供插件Activity给系统，让系统回调插件Activity的生命周期(VirtualAPk, Replugin，Neptune新版)  面临插件上下文信息使用的是宿主信息的问题:\n需要在Activity attach方法调用后(Instrumentation#callActivityOnCreate)反射替换刚刚attach到Activity里的BaseContext，mResources，activityInfo等属性，这里可以优化的是可以在对应属性的getter方法中拦截处理，而不是反射替换到属性值，因此需要字节码插桩让插件的Activity继承自PluginActivity(插件Activity基类)，在这个基类中实现各种对插件包依赖的转调(Neptune新的方式)，通过装饰者模式实现\n 2.2：提供给系统的是代理Activity   2.2.1 需要将所有生命周期方法(还有attach方法)全部转调给插件Activity,目的是让插件Activity自身有活力     2.2.2 (Shadow)生命周期方法由代理Activity转调到插件Activity，并在插件Activity调用super方法时转调到代理Activity，插件Activity可以不继承Activity仅仅是一个Object，插件Activity完全不需要有活力，只要代理Activity有活力就行    面临插件上下文信息使用的是宿主信息的问题: Shadow的处理方式和上面装饰者的方式类似，区别在于动态插桩的插件基类不是真的Activity，是一个ContextWrapper，也就是说，本身就是一个装饰功能类，并非真的Activity，中间的双向转调层可以获取插件信息并通过HostActivityDelegator转调给宿主Activity\nTencent Shadow—零反射全动态Android插件框架正式开源 那么一个重要的原则就是，如果一个组件需要安装才能使用，那么就别在没安装的情况下把它交给系统。我们已知的插件框架中，做的最好的也不符合这个原则，所以尽管它的Hook点少，但就是由于它将没有安装的Activity交给系统了，所以后面就不得不做一些Hack的事修补\nShadow解决Activity等组件生命周期的方法解析\n实际上通过前面的分析，我们发现其实根本不需要插件Activity执行super.onCreate()方法。明确了这个方案原本的目的，就是在宿主中注册并启动一个壳子Activity，这个壳子Activity什么都不自己做，想办法让插件Activity的各个生命周期方法实现代码成为壳子Activity的各个生命周期实现方法的代码。因此我们根本不需要插件Activity是一个系统Activity的子类。我们只是因为需要插件Activity还能正常安装运行，才导致它是一个真正的系统Activity子类的。\nclass ShadowActivity { ContainerActivity containerActivity; public void onCreate(Bundle savedInstanceState) { containerActivity.superOnCreate(savedInstanceState); } } class XXXPluginActivity extends ShadowActivity { @Override public void onCreate(Bundle savedInstanceState) { savedInstanceState.clear(); super.onCreate(savedInstanceState); } } class ContainerActivity extends Activity { ShadowActivity pluginActivity; @Override protected void onCreate(Bundle savedInstanceState) { pluginActivity.onCreate(savedInstanceState); } public void superOnCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); } } 仔细思考下现在的调用结果，是不是PluginActivity在正常安装运行和插件环境下运行时行为就一致了？ "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/1%E7%B1%BB%E7%BC%96%E8%AF%91/",
	"title": "1类编译",
	"tags": [],
	"description": "",
	"content": "1类编译 探索总结1类编译知识\n dex2oat     dex2oat介绍     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%93%8D%E5%BA%94%E5%BC%8F%E6%9E%B6%E6%9E%84/1%E8%B7%A8%E7%BB%84%E4%BB%B6%E4%BC%A0%E9%80%92%E6%95%B0%E6%8D%AE/",
	"title": "1跨组件传递数据",
	"tags": [],
	"description": "",
	"content": "总览 InheritedWidget图解 graph TB parent(\u0026quot;parentInheritedWidget\u0026quot;)--\u0026gt;|_dependents:依赖我,的组件,也就是我的改变需要通知到的组件|child(\u0026quot;child.inheritFromWidgetOfExactType\u0026quot;) child--\u0026gt;|getParentInheritedWidget|parent child--\u0026gt;|useParentInheritedWidget|child 类设计 Element.mount @mustCallSuper void mount(Element parent, dynamic newSlot) { _updateInheritance();//main  } InheritedElement._updateInheritance @override void _updateInheritance() { assert(_active); final Map\u0026lt;Type, InheritedElement\u0026gt; incomingWidgets = _parent?._inheritedWidgets; if (incomingWidgets != null) _inheritedWidgets = HashMap\u0026lt;Type, InheritedElement\u0026gt;.from(incomingWidgets); else _inheritedWidgets = HashMap\u0026lt;Type, InheritedElement\u0026gt;(); _inheritedWidgets[widget.runtimeType] = this; } Element.inheritFromWidgetOfExactType /// Obtains the nearest widget of the given type, which must be the type of a  /// concrete [InheritedWidget] subclass, and registers this build context with  /// that widget such that when that widget changes (or a new widget of that  /// type is introduced, or the widget goes away), this build context is  /// rebuilt so that it can obtain new values from that widget.  ///  /// This method is deprecated. Please use [dependOnInheritedWidgetOfExactType] instead.  // TODO(a14n): Remove this when it goes to stable, https://github.com/flutter/flutter/pull/44189 @override InheritedWidget inheritFromWidgetOfExactType(Type targetType, { Object aspect }) {//继承自BuildContext  assert(_debugCheckStateIsActiveForAncestorLookup()); final InheritedElement ancestor = _inheritedWidgets == null ? null : _inheritedWidgets[targetType]; if (ancestor != null) { assert(ancestor is InheritedElement); return inheritFromElement(ancestor, aspect: aspect); } _hadUnsatisfiedDependencies = true; return null; } @override InheritedWidget inheritFromElement(InheritedElement ancestor, { Object aspect }) { return dependOnInheritedElement(ancestor, aspect: aspect); } @override InheritedWidget dependOnInheritedElement(InheritedElement ancestor, { Object aspect }) { assert(ancestor != null); _dependencies ??= HashSet\u0026lt;InheritedElement\u0026gt;(); _dependencies.add(ancestor); ancestor.updateDependencies(this, aspect); return ancestor.widget; } ancestor.updateDependencies /// Subclasses can manage their own dependencies values so that they /// can selectively rebuild dependents in [notifyDependent]. @protected void updateDependencies(Element dependent, Object aspect) { setDependencies(dependent, null); } /// Sets the value returned by [getDependencies] value for [dependent].  ///  /// Each dependent element is mapped to a single object value  /// which represents how the element depends on this  /// [InheritedElement]. The [updateDependencies] method sets this value to  /// null by default so that dependent elements are rebuilt unconditionally.  ///  /// Subclasses can manage these values with [updateDependencies]  /// so that they can selectively rebuild dependents in [notifyDependent]. @protected void setDependencies(Element dependent, Object value) { _dependents[dependent] = value; } InheritedElement.notifyClients /// Notifies all dependent elements that this inherited widget has changed, by  /// calling [Element.didChangeDependencies]. @override void notifyClients(InheritedWidget oldWidget) { for (Element dependent in _dependents.keys) { assert(() { // check that it really is our descendant  Element ancestor = dependent._parent; while (ancestor != this \u0026amp;\u0026amp; ancestor != null) ancestor = ancestor._parent; return ancestor == this; }()); // check that it really depends on us  assert(dependent._dependencies.contains(this)); notifyDependent(oldWidget, dependent);//main  } //通知依赖我，的组件(childWidgets)，我的变换需要通知到它们 @protected void notifyDependent(covariant InheritedWidget oldWidget, Element dependent) { dependent.didChangeDependencies();//默认调用Element的markNeedsBuild(),rebuild时如果_dirty为false则直接return不会performRebuild() } notifyClients调用时机 //InheritedElement extends ProxyElement //performBuild--\u0026gt;updateChild--\u0026gt;update ProxyElement { @override void update(ProxyWidget newWidget) { final ProxyWidget oldWidget = widget; assert(widget != null); assert(widget != newWidget); super.update(newWidget); assert(widget == newWidget); updated(oldWidget);//main  _dirty = true; rebuild(); } } @protected void updated(covariant ProxyWidget oldWidget) { notifyClients(oldWidget); } Notification图解 graph TB parent(\u0026quot;parentNotificationListener\u0026quot;)--\u0026gt;|ignoreThisArrow|child child--\u0026gt;|dispatch|parent--\u0026gt;|_dispatchWithParaNotification|parent dispatch /// A notification that can bubble up the widget tree.  ///  /// You can determine the type of a notification using the `is` operator to  /// check the [runtimeType] of the notification.  ///  /// To listen for notifications in a subtree, use a [NotificationListener].  ///  /// To send a notification, call [dispatch] on the notification you wish to  /// send. The notification will be delivered to any [NotificationListener]  /// widgets with the appropriate type parameters that are ancestors of the given  /// [BuildContext]. Notification { void dispatch(BuildContext target) { target?.visitAncestorElements(visitAncestor); } bool visitAncestor(Element element) { if (element is StatelessElement) { final StatelessWidget widget = element.widget; if (widget is NotificationListener\u0026lt;Notification\u0026gt;) { if (widget._dispatch(this, element)) // that function checks the type dynamically  return false; } } return true; } } Element.visitAncestorElements @override void visitAncestorElements(bool visitor(Element element)) {//继承自BuildContext  assert(_debugCheckStateIsActiveForAncestorLookup()); Element ancestor = _parent; while (ancestor != null \u0026amp;\u0026amp; visitor(ancestor)) ancestor = ancestor._parent; } NotificationListener._dispatch class NotificationListener\u0026lt;T extends Notification\u0026gt; extends StatelessWidget { /// Return true to cancel the notification bubbling. Return false (or null) to  /// allow the notification to continue to be dispatched to further ancestors.  final NotificationListenerCallback\u0026lt;T\u0026gt; onNotification; bool _dispatch(Notification notification, Element element) { if (onNotification != null \u0026amp;\u0026amp; notification is T) { final bool result = onNotification(notification); return result == true; // so that null and false have the same effect  } return false; } } 参考 InheritedNotifier, InheritedModel flutter_15_跨组件传递数据\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/2alloc/",
	"title": "2Alloc",
	"tags": [],
	"description": "",
	"content": "graph LR subgraph CollectorType kCollectorTypeCC kCollectorTypeMC kCollectorTypeSS kCollectorTypeGSS kCollectorTypeMS kCollectorTypeCMS end subgraph AllocatorType kCollectorTypeMS--\u0026gt;MallocSpace kCollectorTypeCMS--\u0026gt;MallocSpace kCollectorTypeCC--\u0026gt;RegionSpace kCollectorTypeMC--\u0026gt;BumpPointerSpace kCollectorTypeSS--\u0026gt;BumpPointerSpace kCollectorTypeGSS--\u0026gt;BumpPointerSpace MallocSpace--\u0026gt;|kUseRosAlloc|kAllocatorTypeRosAlloc MallocSpace--\u0026gt;kAllocatorTypeDlMalloc RegionSpace--\u0026gt;|use_tlab_|kAllocatorTypeRegionTLAB RegionSpace--\u0026gt;kAllocatorTypeRegion BumpPointerSpace--\u0026gt;|use_tlab_|kAllocatorTypeTLAB BumpPointerSpace--\u0026gt;kAllocatorTypeBumpPointer end heap.cc\nHeap::ChangeCollector(CollectorType) void Heap::ChangeCollector(CollectorType collector_type) { /*CollectorType是一个枚举变量，用于定义不同的回收器类型。collector_type_是 Heap类的成员变量，描述当前设定的回收器类型。对笔者所搭建的模拟器而言，虚拟机使用的 回收器类型为kCollectorTypeCMS。CMS是ConcurrentMarkSweep的缩写。它是标记 清除垃圾回收算法的一种。本书后续章节会详细介绍它们。此处，读者仅作简单了解即可。 */ if (collector_type != collector_type_) { collector_type_ = collector_type;//设置垃圾回收器类型  ...... switch (collector_type_) { case kCollectorTypeCC: {//CC是Concurrent Copying的缩写  ..... if (use_tlab_) {//是否使用TLAB。本例中不使用它，所以use_tlab_为false  //ChangeAllocator函数将设置内存分配器的类型  ChangeAllocator(kAllocatorTypeRegionTLAB); } else { ChangeAllocator(kAllocatorTypeRegion); } break; } case kCollectorTypeMC://MC:Mark Compact  case kCollectorTypeSS://SS:Semi-space  //GSS:改进版的SS  case kCollectorTypeGSS:{ ..... if (use_tlab_) { ChangeAllocator(kAllocatorTypeTLAB); } else { ChangeAllocator(kAllocatorTypeBumpPointer); } break; } case kCollectorTypeMS: {//MS：mark-sweep  ...... ChangeAllocator(kUseRosAlloc ? kAllocatorTypeRosAlloc : kAllocatorTypeDlMalloc); break; } case kCollectorTypeCMS: {//本例对应这种情况  ..... //kUseRosAlloc默认为true  ChangeAllocator(kUseRosAlloc ? kAllocatorTypeRosAlloc : kAllocatorTypeDlMalloc); break; } ..... } ...... } } ChangeAllocator(AllocatorType) void Heap::ChangeAllocator(AllocatorType allocator) { //current_allocator_为Heap成员变量，表示当前所设定的内存分配器类型  if (current_allocator_ != allocator) { current_allocator_ = allocator; MutexLock mu(nullptr, *Locks::runtime_shutdown_lock_); //下面这两个函数比较关键，我们来看它们  SetQuickAllocEntryPointsAllocator(current_allocator_); Runtime::Current()-\u0026gt;GetInstrumentation()-\u0026gt;ResetQuickAllocEntryPoints(); } } quick_alloc_entrypoints.cc::SetQuickAllocEntryPointsAllocator /*SetQuickAllocEntryPointsAllocator函数定义在quick_alloc_entrypoints.cc文件中。 请读者注意这个文件的文件名，它是quickallocentrypoints。ART虚拟机以机器码运行Java程序的 时候，如果涉及内存分配有关的指令（下文将介绍new instance/array机器码的处理），则需要跳 转到和内存分配有关的入口地址去执行。这些内存分配的入口地址都定义在这个quick_alloc_entrypoints.cc 文件中。 entry_points_allocator是一个静态变量，默认取值为DlMalloc，表示默认使用dlmalloc作为内存 分配器。而SetQuickAllocEntryPointsAllocator可以修改它的值。下文将见到这个静态变量的作用。 */ static gc::AllocatorType entry_points_allocator = gc::kAllocatorTypeDlMalloc; //修改entry_poionts_allocator静态变量的取值 void SetQuickAllocEntryPointsAllocator(gc::AllocatorType allocator) { entry_points_allocator = allocator; } instrumentation.cc\nInstrumentation::ResetQuickAllocEntryPoints void Instrumentation::ResetQuickAllocEntryPoints() { Runtime* runtime = Runtime::Current(); if (runtime-\u0026gt;IsStarted()) { MutexLock mu(Thread::Current(), *Locks::thread_list_lock_); //针对每一个线程对象调用ResetQuickAllocEntryPointsForThread函数。其内部将  //调用Thread的ResetQuickAllocEntryPointsForThread  runtime-\u0026gt;GetThreadList()-\u0026gt;ForEach(ResetQuickAllocEntryPointsForThread, nullptr); } } Thread::ResetQuickAllocEntryPointsForThread thread.h\nclass Thread{ ... /*每一个线程对象都包含tlsPtr_成员，而这个成员中有一个quick_entrypoints，它包含了很多入口 地址，它们在Java指令经编译得到的机器码中大量被调用。其实，它们就是机器码（也就是由Java 开发人员编写的程序逻辑）和虚拟机交互的入口。相关知识请读者回顾本书前面介绍的与虚拟机执行 有关的内容。*/ struct PACKED(sizeof(void*)) tls_ptr_sized_values { QuickEntryPoints quick_entrypoints; }tlsPtr_; void Thread::ResetQuickAllocEntryPointsForThread() { //修改tlsPtr_ quick_entrypoins结构体  ResetQuickAllocEntryPoints(\u0026amp;tlsPtr_.quick_entrypoints); } quick_alloc_entrypoints.cc::ResetQuickAllocEntryPoints void ResetQuickAllocEntryPoints(QuickEntryPoints* qpoints) { #if !defined(__APPLE__) || !defined(__LP64__)  //这个变量我们在上文中介绍过了。以笔者所搭建的模拟器为例，它的取值是kAllocatorTypeRosAlloc  switch (entry_points_allocator) { case gc::kAllocatorTypeDlMalloc: { SetQuickAllocEntryPoints_dlmalloc(qpoints, entry_points_instrumented); return; } case gc::kAllocatorTypeRosAlloc: { //entry_points_instrumented也是一个静态变量，表示是否使用辅助工具  //（instrumentation的含义），默认为false。我们不讨论它  SetQuickAllocEntryPoints_rosalloc(qpoints, entry_points_instrumented); return; } ...... } ..... UNREACHABLE(); } quick_alloc_entrypoints.cc::SetQuickAllocEntryPoints##suffix //在SetQuickAllocEntryPoints_rosalloc函数中，rosalloc是下面的suffix //所以，下面代码中pAllocObject的取值就是art_quick_alloc_object_rosalloc void SetQuickAllocEntryPoints##suffix(QuickEntryPoints* qpoints,\\ bool instrumented) { \\ if (instrumented) { ......\\ } else { \\ qpoints-\u0026gt;pAllocObject = art_quick_alloc_object##suffix; \\ ...... } \\ } //借助suffix，我们可以定义不同内存分配器所对应的artAllocObjectFromCodeXXX函数 extern \u0026#34;C\u0026#34; mirror::Object* artAllocObjectFromCode ##suffix##suffix2( \\ uint32_t type_idx, ArtMethod* method, Thread* self) { \\ ScopedQuickEntrypointChecks sqec(self); \\ .....\\略过一些其他情况的处理，感兴趣的读者可自行阅读 //AllocObjectFromCode我们在解释执行模式中见过了  return AllocObjectFromCode\u0026lt;false, instrumented_bool\u0026gt;(type_idx, method, self, allocator_type); \\ } \\ extern \u0026#34;C\u0026#34; mirror::Array* artAllocArrayFromCode##suffix##suffix2( \\ uint32_t type_idx, int32_t component_count, ArtMethod* method, \\ Thread* self) { \\ ScopedQuickEntrypointChecks sqec(self); \\ //AllocArrayFromCode我们也在上文中介绍过了  return AllocArrayFromCode\u0026lt;false, instrumented_bool\u0026gt;(type_idx,\\ component_count, method, self, allocator_type); \\ } \\ 解释执行 interpreter_switch_impl.cc\nExecuteSwitchImpl template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; JValue ExecuteSwitchImpl(.....) { ...... case Instruction::NEW_INSTANCE: { Object* obj = nullptr; Class* c = ResolveVerifyAndClinit(inst-\u0026gt;VRegB_21c(), shadow_frame.GetMethod(),self, false, do_access_check); if (LIKELY(c != nullptr)) { if (UNLIKELY(c-\u0026gt;IsStringClass())) { gc::AllocatorType allocator_type = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator(); //下面这个函数对象类的代码，请读者自行研究  mirror::SetStringCountVisitor visitor(0); //如果new一个String对象，则调用String Alloc函数  obj = String::Alloc\u0026lt;true\u0026gt;(self, 0, allocator_type, visitor);//main  } else { //如果new非String对象，则调用AllocObjectFromCode函数  obj = AllocObjectFromCode\u0026lt;do_access_check, true\u0026gt;(//main  inst-\u0026gt;VRegB_21c(), shadow_frame.GetMethod(), self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()); } } ...... break; } case Instruction::NEW_ARRAY: { int32_t length = shadow_frame.GetVReg(inst-\u0026gt;VRegB_22c(inst_data)); //如果new一个数组，则调用AllocArrayFromCode函数  Object* obj = AllocArrayFromCode\u0026lt;do_access_check, true\u0026gt;(//main  inst-\u0026gt;VRegC_22c(), length, shadow_frame.GetMethod(), self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()); ...... break; } ..... } array.h\nclass MANAGED Array : public Object { ...... private: int32_t length_;//元素的个数  /*用于存储数组元素的内容。注意，虽然first_element_元素长度是32位，但它其实只是一 块存储空间。该数组元素的个数需要根据Java层中对应数组元素所占位长来计算。比如，假设 Java层中要创建包含4个short元素的数组。那么，first_element_数组的长度就是2。 因为uint32_t为32位，而Java层short类型的位长是16,。*/ uint32_t first_element_[0]; }; string.h\nString::Alloc class MANAGED String FINAL : public Object { ..... int32_t count_; uint32_t hash_code_; uint16_t value_[0]; //value_数组才是真正存储字符串内容的地方。  ..... }; template \u0026lt;bool kIsInstrumented, typename PreFenceVisitor\u0026gt; inline String* String::Alloc(Thread* self, int32_t utf16_length, gc::AllocatorType allocator_type, const PreFenceVisitor\u0026amp; pre_fence_visitor) { //注意参数，utf16_length代表以UTF-16编码的字符个数。也就是说，一个字符占2个字节  //sizeof(String)将返回String类的大小（不包括value_数组的内容）  constexpr size_t header_size = sizeof(String); size_t length = static_cast\u0026lt;size_t\u0026gt;(utf16_length); size_t data_size = sizeof(uint16_t) * length;//计算字符串内容所需的内存大小  //计算最终所需分配的内存大小  size_t size = header_size + data_size; //size按8字节向上对齐  size_t alloc_size = RoundUp(size, kObjectAlignment); Class* string_class = GetJavaLangString(); ..... gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); //调用Heap AllocObjectWithAllocator函数分配内存,main  return down_cast\u0026lt;String*\u0026gt;( heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, true\u0026gt;(self, string_class, alloc_size,allocator_type, pre_fence_visitor)); } entrypoint_utils-inl.h\nAllocObjectFromCode inline mirror::Object* AllocObjectFromCode(uint32_t type_idx, ArtMethod* method, Thread* self, gc::AllocatorType allocator_type) { ......//我们仅考察内存分配的调用逻辑  //klass代表所要创建的对象的类。调用它的Alloc函数  return klass-\u0026gt;Alloc\u0026lt;kInstrumented\u0026gt;(self, allocator_type); } Class::Alloc //class-inl.h template\u0026lt;bool kIsInstrumented, bool kCheckAddFinalizer\u0026gt; inline Object* Class::Alloc(Thread* self,gc::AllocatorType allocator_type){ .....//我们仅考察内存分配的调用逻辑  mirror::Object* obj = heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, false\u0026gt;(self, this, this-\u0026gt;object_size_,allocator_type, VoidFunctor()); ...... return obj; } AllocArrayFromCode template \u0026lt;bool kAccessCheck, bool kInstrumented\u0026gt; inline mirror::Array* AllocArrayFromCode(uint32_t type_idx, int32_t component_count, ArtMethod* method, Thread* self, gc::AllocatorType allocator_type) { ...... return mirror::Array::Alloc\u0026lt;kInstrumented\u0026gt;(self, klass, component_count, klass-\u0026gt;GetComponentSizeShift(), allocator_type); } Array::Alloc array-inl.h template \u0026lt;bool kIsInstrumented, bool kFillUsable\u0026gt; inline Array* Array::Alloc(Thread* self, Class* array_class, int32_t component_count, size_t component_size_shift, gc::AllocatorType allocator_type) { /*下面的ComputeArraySize将根据要创建数组的元素个数（component_count决定）和元素的数据 类型（由component_size_shift间接决定可参考primitive.hComponentSizeShift函数） 来计算该数组对象最终所需要的内存大小。 */ size_t size = ComputeArraySize(component_count, component_size_shift); ...... gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); Array* result; if (!kFillUsable) {//kFillUsable默认为false  SetLengthVisitor visitor(component_count); result = down_cast\u0026lt;Array*\u0026gt;( heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, true\u0026gt;(self, array_class, size,allocator_type, visitor)); } else { ......} ...... return result; } heap(-inl).h\nAllocObjectWithAllocator /*AllocObjectWithAllocator为模板函数，包含三个模板参数： kInstrumented：和工具使用有关。我们不讨论它的情况 kCheckLargeObject：判断要分配的内存大小是否属于大对象的范围 PreFenceVisitor：一个函数对象，AllocObjectWithAllocator完成工作后会调用它。*/ template \u0026lt;bool kInstrumented, bool kCheckLargeObject, typename PreFenceVisitor\u0026gt; ALWAYS_INLINE mirror::Object* AllocObjectWithAllocator(Thread* self, mirror::Class* klass, size_t byte_count, AllocatorType allocator, const PreFenceVisitor\u0026amp; pre_fence_visitor) { //AllocObjectWithAllocator函数参数的含义都很简单，笔者不拟赘述。另外，请读者注意 //解释执行和机器码模式下调用这个函数时传入的内存器分配类型都是kAllocatorTypeRosAlloc  mirror::Object* obj; /*kCheckLargeObject为true并且ShouldAllocLargeObject返回true时，将转入 AllocLargeObject函数。ShouldAllocLargeObject判断条件我们在上文介绍 LargeObjectSpace时已经讲过，如果要分配的内存大于12KB（由Heap成员变量 large_object_threshhold_控制，默认为12KB），并且所创建对象的类型为基础数据类 型的数组或String，则属于大对象内存分配的范畴。*/ if (kCheckLargeObject \u0026amp;\u0026amp; UNLIKELY(ShouldAllocLargeObject(klass , byte_count))) { //AllocLargeObject函数将以kAllocatorTypeLOS为内存分配器的类型再次调用AllocObjectWithAllocator函数  obj = AllocLargeObject\u0026lt;kInstrumented, PreFenceVisitor\u0026gt;(self, \u0026amp;klass, byte_count, pre_fence_visitor); /*如果obj不为空，表明内存分配成功，返回obj。如果obj为空指针，则清除可能产生的异常 但还需要继续尝试分配内存。因为kAllocatorTypeLOS内存分配器没有内存可分配，但其他 类型的内存分配器（本例是kAllocatorTypeRosAlloc）可能还有内存供分配）。 */ if (obj != nullptr) { return obj; } else { self-\u0026gt;ClearException(); } } size_t bytes_allocated; size_t usable_size; size_t new_num_bytes_allocated = 0; if (allocator == kAllocatorTypeTLAB || allocator == kAllocatorTypeRegionTLAB) { //所需内存大小按8字节向上对齐  byte_count = RoundUp(byte_count, space::BumpPointerSpace::kAlignment); } /*如果使用线程本地内存资源（TLAB），则先判断线程对象（self指定）TLAB是否还有足够 内存。如果有，则直接从线程的TLAB中分配内存。注意，只有BumpPointerSpace和 RegionSpace支持TLAB。rosalloc也有线程本地内存资源，只不过名字不叫TLAB。 */ if ((allocator == kAllocatorTypeTLAB || allocator == kAllocatorTypeRegionTLAB) \u0026amp;\u0026amp; byte_count \u0026lt;= self-\u0026gt;TlabSize()) { obj = self-\u0026gt;AllocTlab(byte_count); obj-\u0026gt;SetClass(klass); ...... bytes_allocated = byte_count; usable_size = bytes_allocated; pre_fence_visitor(obj, usable_size);//调用回调对象  QuasiAtomic::ThreadFenceForConstructor(); } else if (!kInstrumented \u0026amp;\u0026amp; allocator == kAllocatorTypeRosAlloc\u0026amp;\u0026amp; (obj = rosalloc_space_-\u0026gt;AllocThreadLocal(self, byte_count , \u0026amp;bytes_allocated)) \u0026amp;\u0026amp; LIKELY(obj != nullptr)) { //如果使用rosalloc，则调用RosAllocSpace的AllocThreadLocal在self所属线程  //对应的内存空间中分配资源。上文已经对rosalloc做了详尽介绍，感兴趣的读者可自行研究这部分代码  obj-\u0026gt;SetClass(klass); .....//  usable_size = bytes_allocated; pre_fence_visitor(obj, usable_size); QuasiAtomic::ThreadFenceForConstructor(); } else { /*如果前面的if条件均不满足（并不一定说明内存分配失败，有可能是内存分配器不满足if 的条件），则调用TryToAlloce函数进行内存分配。下文将单独介绍它。 */ size_t bytes_tl_bulk_allocated = 0; obj = TryToAllocate\u0026lt;kInstrumented, false\u0026gt;(self, allocator, byte_count, \u0026amp;bytes_allocated, \u0026amp;usable_size, \u0026amp;bytes_tl_bulk_allocated); if (UNLIKELY(obj == nullptr)) { //TryToAllocate如果返回空指针，说明内存资源有点紧张，下面将调用  //AllocateInternalWithGc再次进行内存分配尝试，但该函数内部会开展垃圾回收。  //下文将单独介绍AllocateInternalWithGc函数  obj = AllocateInternalWithGc(self, allocator,.....); if (obj == nullptr) { //如果obj依然为空指针，还需要判断是否有异常发生。根据注释所言，如果上面代码执行  //过程中切换了内存分配器的类型，则obj为空并且没有待投递的异常。  if (!self-\u0026gt;IsExceptionPending()) { /*调用AllocObject。注意，这里并没有传入内存分配器类型。如上面所说，此时 内存分配器类型已经发生了变化（否则不会满足if的条件）。AllocObject将使用 新的内存分配器类型重新调用一次AllocObjectWithAllocator。 */ return AllocObject\u0026lt;true\u0026gt;(self,klass, byte_count, pre_fence_visitor); } //返回空指针，说明确实没有内存。此时一定会有一个OutOfMemory的异常等待我们  return nullptr; } } //如果代码执行到此处，说明内存分配成功  obj-\u0026gt;SetClass(klass); ...... //下面这个if代码块也和垃圾回收有关。我们后续章节再讨论它们  if (collector::SemiSpace::kUseRememberedSet\u0026amp;\u0026amp; UNLIKELY( allocator == kAllocatorTypeNonMoving)) { .... WriteBarrierField(obj, mirror::Object::ClassOffset(), klass); } pre_fence_visitor(obj, usable_size); QuasiAtomic::ThreadFenceForConstructor(); //Heap的num_bytes_allocated_成员变量保存了当前所分配的内存大小  new_num_bytes_allocated = static_cast\u0026lt;size_t\u0026gt;( num_bytes_allocated_.FetchAndAddRelaxed(bytes_tl_bulk_allocated)) + bytes_tl_bulk_allocated; } ..... /*下面的AllocatorHasAllocationStack函数将检查分配器的类型，如果分配器类型不为 kAllocatorTypeBumpPointer、kAllocatorTypeTLAB、 kAllocatorTypeRegion、kAllocatorTypeRegionTLAB中时将返回true。 PushOnAllocationStack的代码将把obj保存到self线程的对应数据结构中。详情见下文13.6.4.3节的介绍。*/ if (AllocatorHasAllocationStack(allocator)) { PushOnAllocationStack(self, \u0026amp;obj);//main  } //下面的if语句和GC有关，我们统一留待后续章节再介绍  if (AllocatorMayHaveConcurrentGC(allocator) \u0026amp;\u0026amp;IsGcConcurrent()) { CheckConcurrentGC(self, new_num_bytes_allocated, \u0026amp;obj); } ....... return obj; } Heap::TryToAllocate template \u0026lt;const bool kInstrumented, const bool kGrow\u0026gt; inline mirror::Object* Heap::TryToAllocate(Thread* self, AllocatorType allocator_type,.....) { /*TryToAllocate有一个模板参数kGrow。它的含义和Heap对内存水位线的控制有关。 后续章节我们再来介绍与之有关的内容。注意，上文AllocObjectWithAllocator调用TryToAllocate时，kGrow设置为false */ ...... mirror::Object* ret; //根据内存分配器的类型选择不同的内存分配器  switch (allocator_type) { case kAllocatorTypeBumpPointer: {//使用BumpPointerSpace  alloc_size = RoundUp(alloc_size, space::BumpPointerSpace::kAlignment); ret = bump_pointer_space_-\u0026gt;AllocNonvirtual(alloc_size); ..... break; } case kAllocatorTypeRosAlloc: {//使用RosAllocSpace  if (kInstrumented \u0026amp;\u0026amp; UNLIKELY(is_running_on_memory_tool_)) { ...... } else { /*结合上文对rosalloc分配器的介绍可知，rosalloc分配内存时会先确定一个Run，然后 从这个Run中找到空闲的slot作为最终的内存资源。如果这个Run没有空闲资源，则会先创建 这个Run（其所包含的slot都需要分配好）。虽然我们此次要分配的内存只有alloc_size 大小，但它可能会导致一个Run的内存被分配。所以，下面的MaxBytesBulkAllocated- ForNonvirtual函数返回能匹配alloc_size的slot所属的Run需要多大内存（一个Run 包含多个slot。一个slot大于或等于alloc_size）。 IsOutOfMemoryOnAllocation为Heap的成员函数，它将判断可能需要分配的内存 大小是否超过水位线。如果超过水位线，则内存分配失败。*/ size_t max_bytes_tl_bulk_allocated = rosalloc_space_-\u0026gt;MaxBytesBulkAllocatedForNonvirtual(alloc_size); if (UNLIKELY(IsOutOfMemoryOnAllocation\u0026lt;kGrow\u0026gt;(allocator_type, max_bytes_tl_bulk_allocated))) { return nullptr; } //调用RosAllocSpace AllocNonVirtual分配内存  ret = rosalloc_space_-\u0026gt;AllocNonvirtual(self, alloc_size,...); } break; } case kAllocatorTypeDlMalloc: {//dlmalloc的处理  ...... break; } case kAllocatorTypeNonMoving: { /*non_moving_space_的类型为MallocSpace*。这说明kAllocatorTypeNonMoving 并不是一种独立的内存分配算法，它只是MallocSpace的一种使用场景。从内存分配角度来 说，下面的Alloc要么由RosAllocSpace实现，要么由DlMallocSpace实现。 kAllocatorTypeNonMoving的真正作用和下一章要介绍的GC有关，我们后续碰到时再介绍 它们。 */ ret = non_moving_space_-\u0026gt;Alloc(self, alloc_size, bytes_allocated, usable_size, bytes_tl_bulk_allocated); break; } case kAllocatorTypeLOS:....//其他内存分配器类型的处理，笔者不拟赘述  case kAllocatorTypeTLAB:.... case kAllocatorTypeRegion:.... case kAllocatorTypeRegionTLAB:... ...... } return ret; } Heap::AllocateInternalWithGc 原理图 graph LR WaitForGcToComplete--\u0026gt;TryToAllocate1--\u0026gt;|failed|CollectGarbageInternal--\u0026gt;TryToAllocate2(\u0026quot;TryToAllocate2\u0026quot;) --\u0026gt;|failed|CollectGarbageInternal2(\u0026quot;GcTypeIteratorCollectGarbageInternal\u0026quot;)--\u0026gt;TryToAllocateN(\u0026quot;TryToAllocateN\u0026quot;) --\u0026gt;|failed|ThrowOutOfMemoryError mirror::Object* Heap::AllocateInternalWithGc(Thread* self, AllocatorType allocator, bool instrumented,....,mirror::Class** klass) { .... /*WaitForGcToComplete：等待GC完成（如果当前正有GC任务的话）。返回值的类型GcType 我们在7.6.2节中曾介绍过它。此处回顾如下： GcType为枚举变量，它有四种取值，对应垃圾回收力度由轻到重： (1) kGcTypeNone：没有做GC。 (2) kGcTypeSticky：表示仅扫描和回收上次GC到本次GC这个时间段内所创建的对象 (3) kGcTypePartial：仅扫描和回收应用进程自己的堆，不处理zygote的堆。这种方式和 Android中Java应用程序的创建方式有关。在Android中，应用进程是zygote进程fork 出来的。 (4) kGcTypeFull：它将扫描APP自己以及它从父进程zygote继承得到的堆。 垃圾回收时会由轻到重开展回收，以本例所设置的垃圾回收器类型kCollectorTypeCMS而言， 它会由轻到重，分别尝试kGcTypeSticky、kGcTypePartial、kGcTypeFull。 请读者注意，笔者在第14章中将介绍这几种回收策略的代码实现逻辑。*/ collector::GcType last_gc = WaitForGcToComplete(kGcCauseForAlloc, self); ..... //last_gc不为kGcTypeNone，表示系统完成了一次GC，再次尝试分配内存。注意，这次GC  //并不是由AllocateInternalWithGc发起的  if (last_gc != collector::kGcTypeNone) { mirror::Object* ptr = TryToAllocate\u0026lt;true, false\u0026gt;(self,....); if (ptr != nullptr) { return ptr; } } /*next_gc_type_表示我们要发起的GC粒度。它的取值和垃圾回收器类型有关。next_gc_type_ 的类型也是GcType。我们上文介绍过它的取值情况。 */ collector::GcType tried_type = next_gc_type_; //CollectGarbageInternal将发起GC，注意它的最后一个参数表示是否回收  //Soft Reference对象（详情见GC相关的知识）  const bool gc_ran = CollectGarbageInternal(tried_type, kGcCauseForAlloc, false) != collector::kGcTypeNone; ...... if (gc_ran) {//gc_ran为true，表示执行了一次GC。现在，再次尝试分配内存  mirror::Object* ptr = TryToAllocate\u0026lt;true, false\u0026gt;(self, ......); if (ptr != nullptr) { return ptr; } } //还是没有内存，此时，我们需要根据gc_plan_（数组），以上面代码中注释提到的CMS而言，  //该数组的内容分别是kGcTypeSticky、kGcTypePartial、kGcTypeFull。下面的for循环将  //由轻到重开展垃圾回收  for (collector::GcType gc_type : gc_plan_) { if (gc_type == tried_type) { continue; } const bool plan_gc_ran = CollectGarbageInternal(gc_type, kGcCauseForAlloc, false) != collector::kGcTypeNone; ...... if (plan_gc_ran) {//每执行一次回收就尝试分配一次内存  mirror::Object* ptr = TryToAllocate\u0026lt;true, false\u0026gt;(self,.....); if (ptr != nullptr) { return ptr; } } } //再次尝试分配内存，但需要设置TryToAllocate的kGrow模板参数为true。读者可以看看  //TryToAllocate函数的代码，对rosalloc而言，kGrow为true并没有多大用处  mirror::Object* ptr = TryToAllocate\u0026lt;true, true\u0026gt;(self, allocator,....); if (ptr != nullptr) { return ptr; } //还是没有空余内存的话，则以最强力度（gc_plan_数组的末尾元素代表最强力度的GcType），  //并且不放过soft reference对象（第三个参数为true）再做一次GC  CollectGarbageInternal(gc_plan_.back(), kGcCauseForAlloc, true); ..... ptr = TryToAllocate\u0026lt;true, true\u0026gt;(self, allocator,.....); if (ptr == nullptr) { //根据内存分配器的类型尝试做内存压缩（Compact）等操作。操作成功的话还会尝试  //内存分配。这部分内容也和GC有关，我们后续章节再介绍  .... } if (ptr == nullptr) {//设置OOM异常  ThrowOutOfMemoryError(self, alloc_size, allocator); } return ptr; } Heap::PushOnAllocationStack inline void Heap::PushOnAllocationStack(Thread* self, mirror::Object** obj) { //编译常量kUseThreadLocalAllocationStack表示是否使用线程的Allocation Stack，  //默认取值为true。  if (kUseThreadLocalAllocationStack) { /*调用Thread PushOnThreadLocalAllocationStack函数保存这个obj对象。该obj 保存在线程的Allocation Stack中。注意，该函数如果返回false，说明Allocation Stack内存不足。此时需要调用Heap PushOnThreadLocalAllocationStackWithInternalGC函数为线程分配Allocation Stack的空间。 */ if (UNLIKELY(!self-\u0026gt;PushOnThreadLocalAllocationStack(*obj))) { PushOnThreadLocalAllocationStackWithInternalGC(self, obj); } } else if ...... } inline bool Thread::PushOnThreadLocalAllocationStack(mirror::Object* obj) { if (tlsPtr_.thread_local_alloc_stack_top\u0026lt; tlsPtr_.thread_local_alloc_stack_end) { //obj存储到stack_top所指向的位置，此后递增stack_top的值  tlsPtr_.thread_local_alloc_stack_top-\u0026gt;Assign(obj); ++tlsPtr_.thread_local_alloc_stack_top; return true; } return false; //返回false，说明Allocation Stack空间不够 } void Heap::PushOnThreadLocalAllocationStackWithInternalGC(Thread* self, mirror::Object** obj) { StackReference\u0026lt;mirror::Object\u0026gt;* start_address; StackReference\u0026lt;mirror::Object\u0026gt;* end_address; /*kThreadLocalAllocationStackSize取值为128，即每个线程有能存128个Object对象 指针的空间。AtomicBumpBack的功能见上文对AtomicStack的讲解。 */ while (!allocation_stack_-\u0026gt;AtomicBumpBack(kThreadLocalAllocationStackSize, \u0026amp;start_address, \u0026amp;end_address)) { ....... CollectGarbageInternal(collector::kGcTypeSticky, kGcCauseForAlloc,false); } //设置self线程的Allocation Stack  self-\u0026gt;SetThreadLocalAllocationStack(start_address, end_address); } thread.h\nstruct PACKED(sizeof(void*)) tls_ptr_sized_values { ...... /*下面这两个成员变量的初始值为nullptr，它们标示了一段内存的起始和结束位置。代码中称 这段内存为Allocation Stack。Allocation Stack就是一个栈容器，它存储的是一组 StackReference\u0026lt;Object\u0026gt;元素。读者可以将一个StackReference\u0026lt;Object\u0026gt;实例看成一 个指向Object的指针。 */ StackReference\u0026lt;mirror::Object\u0026gt;* thread_local_alloc_stack_top; StackReference\u0026lt;mirror::Object\u0026gt;* thread_local_alloc_stack_end; ...... 机器码执行 code_generator_x86.cc\nInstructionCodeGeneratorX86::VisitNewInstance void InstructionCodeGeneratorX86::VisitNewInstance(HNewInstance* instruction) { if (instruction-\u0026gt;IsStringAlloc()) {//如果是创建String类型的对象  Register temp = instruction-\u0026gt;GetLocations()-\u0026gt;GetTemp(0).AsRegister\u0026lt;Register\u0026gt;(); MemberOffset code_offset = ArtMethod::EntryPointFromQuickCompiledCodeOffset(kX86WordSize); /*根据thread.cc InitStringEntryPoints函数的设置可知，QuickEntryPoints pNewEmptyString指向java lang StringFactory newEmptyString函数的机器码 入口地址。也就是说，如果创建String类型的对象，则会调用StringFactory类的 newEmptyString函数。 */ __ fs()-\u0026gt;movl(temp, Address::Absolute(QUICK_ENTRY_POINT(pNewEmptyString))); __ call(Address(temp, code_offset.Int32Value())); ...... } else { /*参考instruction_builder.ccBuildNewInstance函数可知，下面的GetEntryPoint返回 kQuickAllocObject或kQuickAllocObjectInitialized，它们分别对应QuickEntryPoints 结构体里的pQuickAllocObject和pQuickAllocObjectInitialized成员变量。*/ codegen_-\u0026gt;InvokeRuntime(instruction-\u0026gt;GetEntrypoint(),....); ...... } } String::Alloc //StringFactory.java public static String newEmptyString() { //newStringFromChars最终将调用下面代码所示的native函数  return newStringFromChars(EmptyArray.CHAR, 0, 0); } //最终会调用下面这个native函数 static native String newStringFromChars(int offset, int charCount, char[] data); //java_lang_StringFactory.cc static jstring StringFactory_newStringFromChars(JNIEnv* env, jclass, jint offset,jint char_count, jcharArray java_data) { ..... gc::AllocatorType allocator_type = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator(); //内部调用String Alloc函数。其内容我们在解释执行模式一节中已经介绍过了  mirror::String* result = mirror::String::AllocFromCharArray\u0026lt;true\u0026gt;( soa.Self(), char_count,char_array, offset, allocator_type); return soa.AddLocalReference\u0026lt;jstring\u0026gt;(result); } InstructionCodeGeneratorX86::VisitNewArray void InstructionCodeGeneratorX86::VisitNewArray(HNewArray* instruction) { InvokeRuntimeCallingConvention calling_convention; __ movl(calling_convention.GetRegisterAt(0), Immediate(instruction-\u0026gt;GetTypeIndex())); /*参考instruction_builder.ccProcessDexInstruction函数对NEW_ARRAY的处理， GetEntryPoint返回值为kQuickAllocArrayWithAccessCheck或kQuickAllocArray， 它们分别对应QuickEntryPoints结构体里的pQuickAllocArrayWithAccessCheck和 pQuickAllocArray成员变量。 */ codegen_-\u0026gt;InvokeRuntime(instruction-\u0026gt;GetEntrypoint(), instruction, instruction-\u0026gt;GetDexPc(), nullptr); ...... } Heap构造函数中所创建的Space 图13-9　Heap构造函数中所创建的Space (heapSize=384MB)\nHeap::Heap Heap::Heap(size_t initial_size, size_t growth_limit,... size_t capacity,size_t non_moving_space_capacity, const std::string\u0026amp; image_file_name,..... CollectorType foreground_collector_type, CollectorType background_collector_type, space::LargeObjectSpaceType large_object_space_type, size_t large_object_threshold,....){ ...... /*foreground_collector_type：当应用程序处于前台（即用户能感知的情况）时GC的类型。 此处为kCollectorTypeCMS（以后简称CMS） background_collector_type：当应用程序位于后台时GC的类型。此处为 kCollectorTypeHomogeneousSpaceCompact（以后简称HSC）。注意，这是 一种空间压缩的方法，可减少内存碎片。但需要较长时间暂停程序的运行，所以只能 在程序位于后台（用户不可见）的时候来执行。 large_object_threshold：被认定为大对象的标准。来自runtime_options.def的 LargeObjectThreshold参数，默认取值为Heap.h kDefaultLargeObjectThreshold（大小为3个内存页，此处为12KB）。*/ //desired_collector_type_取值同foreground_collector_type，本例为kCollectorTypeCMS  ChangeCollector(desired_collector_type_); //初始化live_bitmap_和mark_bitmap_成员变量，类型为HeapBitmap，读者可参考  //7.6.1.1节  live_bitmap_.reset(new accounting::HeapBitmap(this)); mark_bitmap_.reset(new accounting::HeapBitmap(this)); ...... Heap::AddSpace void Heap::AddSpace(space::Space* space) { WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); if (space-\u0026gt;IsContinuousSpace()) { //根据图13-1，除了LargeObjectSpace外，其他的Space都属于ContinuousSpace  space::ContinuousSpace* continuous_space = space-\u0026gt;AsContinuousSpace(); /*ContinuousSpace GetLiveBitmap和GetMarkBitmap是虚函数。其实现者为 ContinuousMemMapAllocSpace。而ContinuousMemMapAllocSpace定义了 live_bitmap_和mark_bitmap_两个成员变量。根据13.7.3节可知，只有DlMallocSpace 和RosAllocSpace初始化了这两个成员变量。 */ accounting::ContinuousSpaceBitmap* live_bitmap = continuous_space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = continuous_space-\u0026gt;GetMarkBitmap(); if (live_bitmap != nullptr) { /*下面的live_bitmap_和mark_bitmap_为Heap的成员变量，类型为HeapBitmap。 其详细信息可参考7.6.1.1节的内容。简单来说，下面的AddContinuousSpaceBitmap 函数将把一个位图对象加到HeapBitmap continuous_space_bitmaps_ （ContinuousSpaceBitmap数组）中去。*/ live_bitmap_-\u0026gt;AddContinuousSpaceBitmap(live_bitmap); mark_bitmap_-\u0026gt;AddContinuousSpaceBitmap(mark_bitmap); } //continuous_spaces_为Heap的成员变量，类型为vector\u0026lt;ContinuousSpace*\u0026gt;，即  //一个存储ContinuousSpace对象的数组。下面将continuous_space加到这个数组中  continuous_spaces_.push_back(continuous_space); //对continuous_spaces_数组中的元素进行排序，内存空间起始位置小的排在前面。  //图13-9中Space对象就是按这个顺序排列的（从左到右，内存起始地址由低到高）  std::sort(continuous_spaces_.begin(), continuous_spaces_.end(), [](const space::ContinuousSpace* a, const space::ContinuousSpace* b) { return a-\u0026gt;Begin() \u0026lt; b-\u0026gt;Begin(); }); } else { //处理DiscontinuousSpace，也就是唯一的LargeObjectMapSpace  space::DiscontinuousSpace* discontinuous_space = space-\u0026gt;AsDiscontinuousSpace(); //AddLargeObjectBitmap用于将位图对象加入HeapBitmap large_object_bitmaps_数组中  live_bitmap_-\u0026gt;AddLargeObjectBitmap(discontinuous_space-\u0026gt;GetLiveBitmap()); mark_bitmap_-\u0026gt;AddLargeObjectBitmap(discontinuous_space-\u0026gt;GetMarkBitmap()); //discontinuous_spaces_为Heap成员变量，类型为vector\u0026lt;DiscontinuousSpace*\u0026gt;  discontinuous_spaces_.push_back(discontinuous_space); } //如果Space可分配内存，则还需要将这个AllocSpace对象加到  //Heap alloc_spaces_数组中保存，其类型为vector\u0026lt;AllocSpace*\u0026gt;  if (space-\u0026gt;IsAllocSpace()) { alloc_spaces_.push_back(space-\u0026gt;AsAllocSpace()); } } Heap::RemoveSpace void Heap::RemoveSpace(space::Space* space) { WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); if (space-\u0026gt;IsContinuousSpace()) { space::ContinuousSpace* continuous_space = space-\u0026gt;AsContinuousSpace(); accounting::ContinuousSpaceBitmap* live_bitmap =continuous_space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = continuous_space-\u0026gt;GetMarkBitmap(); if (live_bitmap != nullptr) { live_bitmap_-\u0026gt;RemoveContinuousSpaceBitmap(live_bitmap); mark_bitmap_-\u0026gt;RemoveContinuousSpaceBitmap(mark_bitmap); } auto it = std::find(continuous_spaces_.begin(), continuous_spaces_.end(), continuous_space); continuous_spaces_.erase(it); } else { ....//类似处理，操作discontinuous_spaces_数组  } if (space-\u0026gt;IsAllocSpace()) { auto it = std::find(alloc_spaces_.begin(), alloc_spaces_.end(),space-\u0026gt;AsAllocSpace()); alloc_spaces_.erase(it); } } CardTable,Space,RememberedSet,ModUionTable的关系 图13-10　分代GC示意\nheap.cc\nHeap::Heap //构造方法 ...... static constexpr size_t kMinHeapAddress = 4 * KB; //CardTable的覆盖范围从4KB开始，到4GB结束。读者可参考图13-11 card_table_.reset(accounting::CardTable::Create(//main  reinterpret_cast\u0026lt;uint8_t*\u0026gt;(kMinHeapAddress), 4 * GB - kMinHeapAddress)); ...... if (collector::SemiSpace::kUseRememberedSet \u0026amp;\u0026amp; non_moving_space_ != main_space_) { accounting::RememberedSet* non_moving_space_rem_set = new accounting::RememberedSet(\u0026#34;Non-moving space remembered set\u0026#34;, this, non_moving_space_); /*Heap中有一个名为remembered_sets_的成员变量，其数据类型为 AllocationTrackingSafeMap\u0026lt;space::Space*,accounting::RememberedSet*,...\u0026gt;。 读者可将AllocationTrackingSafeMap看作std map。下面的AddRememberedSet函数 将把一个RememberedSet对象和它所关联的space_加入到remembered_sets_容器中。 AddRememberedSet非常简单，请读者自行阅读。*/ AddRememberedSet(non_moving_space_rem_set); } card_table(-inl).h/cc\nCardTable::Create CardTable* CardTable::Create(const uint8_t* heap_begin, size_t heap_capacity) { /*CardTable类定义了几个编译常量，如下所示： static constexpr size_t kCardShift = 7; static constexpr size_t kCardSize = 1 \u0026lt;\u0026lt;kCardShift;//kCardSize值为128 static constexpr uint8_t kCardClean = 0x0; static constexpr uint8_t kCardDirty = 0x70;*/ //计算需要多少个Card  size_t capacity = heap_capacity / kCardSize; std::string error_msg; //创建一个MemMap映射对象，其大小为capacity+256。  std::unique_ptr\u0026lt;MemMap\u0026gt; mem_map( MemMap::MapAnonymous(\u0026#34;card table\u0026#34;, nullptr, capacity + 256, PROT_READ | PROT_WRITE,...)); //下面省略了一段代码，用于计算图13-11中提到的对齐区域，见下文介绍  ...... //创建CardTable对象。biased_begin是第一个card的位置，offset是用于计算偏移量的值  return new CardTable(mem_map.release(), biased_begin, offset); } thread.cc\nvoid Thread::InitCardTable() { //Heap GetCardTable返回Heap card_table_成员变量。这说明所有线程对象共用一个  //CardTable。CardTable GetBiasedBegin函数返回这个CardTable用于存储记录的内存  //空间的起始地址。  tlsPtr_.card_table = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCardTable()-\u0026gt;GetBiasedBegin(); } CardTable::CardTable(MemMap* mem_map, uint8_t* biased_begin, size_t offset) : mem_map_(mem_map), biased_begin_(biased_begin), offset_(offset) { } remembered_set.cc\nRememberedSet class RememberedSet {//为方便讲解，代码行位置有所调整  public: //CardSet是类型别名，它是一个std set容器，key的类型为uint8_t*。一个元素代表  //CardTable中的一个Card，也就是该Card的地址保存在CardSet中  typedef std::set\u0026lt;uint8_t*, std::less\u0026lt;uint8_t*\u0026gt;,....\u0026gt;CardSet; private: //RememberedSet只有如下四个成员变量  const std::string name_;//RememberedSet的名称  Heap* const heap_; space::ContinuousSpace* const space_;//关联一个Space，读者可回顾图13-11  CardSet dirty_cards_; public: /*RemeberedSet的构造函数。代码中有几处地方会创建RememberedSet对象 (1) Heap构造函数中为non_moving_space_对象创建一个RememberedSet对象 (2) CreateMallocSpaceFromMemMap函数，为每一个通过该函数创建的MallocSpace对象创建一个RememberedSet对象。 注意，non_moving_space_虽然是MallocSpace对象，但它是由DlMallocSpace CreateFromMemMap函数创建而来，所以并不受上面第2条的影响。*/ explicit RememberedSet(const std::string\u0026amp; name, Heap* heap, space::ContinuousSpace* space) : name_(name), heap_(heap), space_(space) {} .... //RememberedSet成员函数较少，下面两个是其中最重要的成员函数，详情见下文代码分析  void ClearCards(); void UpdateAndMarkReferences(space::ContinuousSpace* target_space, collector::GarbageCollector* collector); ...... }; ClearCards void RememberedSet::ClearCards() { CardTable* card_table = GetHeap()-\u0026gt;GetCardTable(); RememberedSetCardVisitor card_visitor(\u0026amp;dirty_cards_); /*上文介绍了CardTable ModifyCardsAtomic函数的作用。此处的ClearCards函数将用到 它。其功能为扫描space_对应的card，调用AgeCardVisitor函数获取card的新值，然后 调用card_visitor函数对象。 */ card_table-\u0026gt;ModifyCardsAtomic(space_-\u0026gt;Begin(), space_-\u0026gt;End(), AgeCardVisitor(), card_visitor); } /*ModifyCardsAtomic用于修改从scan_begin到scan_end内存范围对应CardTable card的值。修改前调用模板参数visitor函数对象，visitor需要返回该Card的新值。 如果新值和旧值不同，则调用模板参数modified函数对象以通知外界。函数名中的Atomic意 为原子操作。该函数的代码不短，但难度不大。*/ template \u0026lt;typename Visitor, typename ModifiedVisitor\u0026gt; void ModifyCardsAtomic(uint8_t* scan_begin, uint8_t* scan_end, const Visitor\u0026amp; visitor, const ModifiedVisitor\u0026amp; modified); class AgeCardVisitor { public: uint8_t operator()(uint8_t card) const { //参数card就是指CardTable中的一个Card。如果它的值为kCardDirty，则返回  //0x6E（kCardDirty - 1），否则返回0。总之，card的新值不会是kCardDirty  return (card == accounting::CardTable::kCardDirty) ? card - 1 : 0; } }; class RememberedSetCardVisitor { public: explicit RememberedSetCardVisitor( RememberedSet::CardSet* const dirty_cards) : dirty_cards_(dirty_cards) {} //expected_value为card的旧值（调用AgeCardVisitor之前的值），而  //new_value为AgeCardVisitor返回的新值。此处没有用到new_value  void operator()(uint8_t* card, uint8_t expected_value, uint8_t new_value ATTRIBUTE_UNUSED) const { //如果card的值为kCardDirty，将其加入RememberedSet dirty_cards_ set容器中  if (expected_value == CardTable::kCardDirty) { dirty_cards_-\u0026gt;insert(card); } } private: RememberedSet::CardSet* const dirty_cards_; }; UpdateAndMarkReferences //遍历space_里所有存在跨Space引用的Object，然后对它们进行标记 void RememberedSet::UpdateAndMarkReferences( space::ContinuousSpace* target_space, collector::GarbageCollector* collector) { /*注意target_space的含义：UpdateAndMarkReferences将检查space_中的Object是否 引用了位于target_space空间中的Object。*/ CardTable* card_table = heap_-\u0026gt;GetCardTable(); //如果space_中的对象引用了target_space中的对象，则下面这个变量会被设置为true，  //此时它的值为false  bool contains_reference_to_target_space = false; //创建RememberedSetObjectVisitor函数对象  RememberedSetObjectVisitor obj_visitor(target_space,\u0026amp;contains_reference_to_target_space, collector); //要遍历一个ContinuousSpaceBitmap中所包含的Object，需要借助与之关联的位图对象  ContinuousSpaceBitmap* bitmap = space_-\u0026gt;GetLiveBitmap(); CardSet remove_card_set; //dirty_cards容器已经包含了space_中那些标志为kDirtyCard的card信息。  //下面的循环将遍历dirty_cards中的card  for (uint8_t* const card_addr : dirty_cards_) { contains_reference_to_target_space = false; //将card地址转换为Space中对应的那个128字节单元的基地址。读者可回顾图13-11  uintptr_t start = reinterpret_cast\u0026lt;uintptr_t\u0026gt;( card_table-\u0026gt;AddrFromCard(card_addr)); /*访问这个128字节单元中的Object，调用obj_visitor函数对象。7.6.1.1.3节SpaceBitmap的 Walk函数。VisitMarkedRange与之类似，它将访问[start，start+128)这部分位图所对应内 存空间中的Object们，每得到一个Object，就调用一次obj_visitor函数对象。VisitMarkRange 函数中有一段参考性的实现代码，读者不妨一看（笔者在13.2节中曾展示过这段代码）。 */ bitmap-\u0026gt;VisitMarkedRange(start, start + CardTable::kCardSize, obj_visitor); //如果这个128字节单元中的Object没有引用target_space中的Object，则对应的  //card区域需要从dirty_cards容器中移除。先将这个card存到临时容器  //remove_card_set中，后续将一次性移除它们  if (!contains_reference_to_target_space) { remove_card_set.insert(card_addr); } } //从dirty_cards_中移除那些不存在跨Space引用的card  for (uint8_t* const card_addr : remove_card_set) { dirty_cards_.erase(card_addr); } } class RememberedSetObjectVisitor { public: ...... //SpaceBitmap VisitMarkedRange每找到一个Object都会调用下面这个函数  void operator()(mirror::Object* obj) const { /*调用Object VisitReferences函数，传入另外一个函数对象。Object VisitReferences用于访问一个Object的引用型成员变量。想必读者已经猜到了，GC中 常说的标记（Mark）操作肯定会用到这个函数来寻找对象之间的引用关系。13.8.3节将详细 介绍此函数。 */ RememberedSetReferenceVisitor visitor(target_space_, contains_reference_to_target_space_,collector_); obj-\u0026gt;VisitReferences(visitor, visitor); } ...... }; class RememberedSetReferenceVisitor { public: ...... /*RememberedSetReferenceVisitor有多个调用函数以及回调函数。它们和Object VisitReferences的实现有关。本节仅看下面一个函数，其他几个函数的作用大同小异。 */ void operator()(mirror::Object* obj, MemberOffset offset, bool is_static ATTRIBUTE_UNUSED) const { //offset是成员变量位于obj所在内存中的位置。将其转换成对应的Object。即ref_ptr  //就是这个引用型成员变量所指向的那个Object  mirror::HeapReference\u0026lt;mirror::Object\u0026gt;* ref_ptr = obj-\u0026gt;GetFieldObjectReferenceAddr(offset); //判断target_space_中是否包含ref_ptr。如果包含，则存在跨Space的引用关系  if (target_space_-\u0026gt;HasAddress(ref_ptr-\u0026gt;AsMirrorPtr())) { *contains_reference_to_target_space_ = true; //我们后续章节再介绍MarkHeapReference函数  collector_-\u0026gt;MarkHeapReference(ref_ptr); } } //其他几个回调函数，和Object VisitReferences有关  ...... }; Object-inl.h\ntemplate \u0026lt;VerifyObjectFlags kVerifyFlags\u0026gt; inline HeapReference\u0026lt;Object\u0026gt;* Object::GetFieldObjectReferenceAddr(MemberOffset field_offset) { if (kVerifyFlags \u0026amp; kVerifyThis) { VerifyObject(this); } return reinterpret_cast\u0026lt;HeapReference\u0026lt;Object\u0026gt;*\u0026gt;(reinterpret_cast\u0026lt;uint8_t*\u0026gt;(this) + field_offset.Int32Value()); } MarkCard 发生下述依赖时，将a对应的card设置为kCardDirty\ngraph TB a(\u0026quot;a.b\u0026quot;)--\u0026gt;|引用|b 解释执行模式下，iput-object指令将触发DoFieldPut函数被调用\ninterpreter_common.cc\nDoFieldPut bool DoFieldPut(Thread* self,... uint16_t inst_data){ ...... //f是代表目标成员变量的ArtField对象  ArtField* f = FindFieldFromCode\u0026lt;find_type, do_access_check\u0026gt;(field_idx, .... Primitive::ComponentSize(field_type)); ...... switch (field_type) { case Primitive::kPrimNot: { Object* reg = shadow_frame.GetVRegReference(vregA); ...... f-\u0026gt;SetObj\u0026lt;transaction_active\u0026gt;(obj, reg); break; } ..... } //art_field-inl.h template\u0026lt;bool kTransactionActive\u0026gt; inline void ArtField::SetObj(mirror::Object* object, mirror::Object* new_value) { if (UNLIKELY(IsVolatile())) {.....} else { //调用Object SetFieldObject函数  object-\u0026gt;SetFieldObject\u0026lt;kTransactionActive\u0026gt;(GetOffset(), new_value); } } //object-inl.h inline void Object::SetFieldObject(MemberOffset field_offset, Object* new_value) { /*设置对应成员变量的值其不使用Write Barrier。其内部就是更新本Object对象 field_offset内存处的值为new_value。不熟悉Object对象内存布局的读者请阅读8.7.4.2 节的内容。 */ SetFieldObjectWithoutWriteBarrier\u0026lt;...\u0026gt;(field_offset, new_value); //只要新值不为空，都需要调用Heap WriteBarrierField函数  if (new_value != nullptr) { Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;WriteBarrierField(this, field_offset, new_value); ...... } } //heap.h ALWAYS_INLINE void WriteBarrierField(const mirror::Object* dst, MemberOffset offset ATTRIBUTE_UNUSED, const mirror::Object* new_value ATTRIBUTE_UNUSED) { /*注意，WriteBarrierField只用到第一个参数dst，它就是成员变量被赋值的那个对象，而成员变 量的新值（new_value表示）并未使用。在下面的代码中，上文Heap构造函数中已经见过card_table_ 了。而MarkCard将标记dst对应的Card标志为kCardDirty。其详情见下文的介绍。 */ card_table_-\u0026gt;MarkCard(dst); } MarkCard ALWAYS_INLINE void MarkCard(const void *addr) { /*CardFromAddr返回addr对应的Card，然后设置其值为kCardDirty。从这里也可以看出， ART虚拟机中，一个Card为一个字节（CardFromAddr返回值类型为uint8_t*）。*/ *CardFromAddr(addr) = kCardDirty; } inline uint8_t* CardTable::CardFromAddr(const void *addr) const { //由基地址加上addr右移7位（相当于除以128）以得到对应card的位置。而CardTable的基  //准位置从biased_begin_算起  uint8_t *card_addr = biased_begin_ + (reinterpret_cast\u0026lt;uintptr_t\u0026gt;(addr) \u0026gt;\u0026gt;kCardShift); return card_addr; } bool IsDirty(const mirror::Object* obj) const { return GetCard(obj) == kCardDirty; } uint8_t GetCard(const mirror::Object* obj) const { return *CardFromAddr(obj); } Object-inl.h::VisitReferences template \u0026lt;bool kVisitNativeRoots = true, VerifyObjectFlags kVerifyFlags = kDefaultVerifyFlags, ReadBarrierOption kReadBarrierOption = kWithReadBarrier, typename Visitor, typename JavaLangRefVisitor = VoidFunctor\u0026gt; void VisitReferences(const Visitor\u0026amp; visitor, const JavaLangRefVisitor\u0026amp; ref_visitor) { //klass为Object所属的类（即mirrorObject的成员变量klass）  mirror::Class* klass = GetClass\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;(); //klass是Object第一个引用型成员变量，调用visitor来访问它  visitor(this, ClassOffset(), false); //获取类的类型  const uint32_t class_flags = klass-\u0026gt;GetClassFlags\u0026lt;kVerifyNone\u0026gt;(); if (LIKELY(class_flags == kClassFlagNormal)) { /*调用VisitInstanceFieldsReferences函数访问其引用型成员变量。这个函数的实现与 我们在8.7.4.3节介绍的引用型成员变量在Object内存中的布局密切相关。我们在该节中还 展示了下面这个函数内部将要调用的VisitFieldsReferences的代码。另外，VisitInstances- FieldsReferences用于访问对象的非静态引用型成员变量。*/ VisitInstanceFieldsReferences\u0026lt;.....\u0026gt;(klass, visitor); } else {//其他类标志位的处理。  if ((class_flags \u0026amp;kClassFlagNoReferenceFields) == 0) { if (class_flags == kClassFlagClass) { //如果目标对象本身就是一个Java Class对象，则将其转换为Class对象，然后调用  //mirror Class VisitReferences函数  mirror::Class* as_klass = AsClass\u0026lt;...\u0026gt;(); as_klass-\u0026gt;VisitReferences\u0026lt;....\u0026gt;(klass, visitor); } else if (class_flags == kClassFlagObjectArray) { //如果是一个Object数组，则转换成mirror ObjectArray，调用它的  //VisitReferences函数  AsObjectArray\u0026lt;mirror::Object,.....\u0026gt;()-\u0026gt;VisitReferences(visitor); } else if ((class_flags \u0026amp;kClassFlagReference) != 0) { //如果类的类型为Java Reference的一种，则先调用VisitInstanceFieldsReferences  VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); //然后调用JavaLangRefVisitor。注意，第二个参数将目标对象转换成一个mirror  //Reference对象  ref_visitor(klass, AsReference\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;()); } else if (class_flags == kClassFlagDexCache) { //将自己转换为DexCache  mirror::DexCache* const dex_cache = AsDexCache\u0026lt;....\u0026gt;(); //调用DexCache VisitReference函数  dex_cache-\u0026gt;VisitReferences\u0026lt;...\u0026gt;(klass, visitor); } else { mirror::ClassLoader* const class_loader = AsClassLoader\u0026lt;...\u0026gt;(); //将自己转换成ClassLoader，然后调用它的VisitReferences  class_loader-\u0026gt;VisitReferences\u0026lt;...\u0026gt;(klass, visitor); } } } } Visitor和JavaLangRefVisitor示例 class VisitorAndJavaLangRefVisitor {//同时支持Visitor和JavaLangRefVisitor  /*Visitior需要重载如下所示的函数调用操作符。obj代表目标对象，offset代表目标对象中的 某个引用型成员变量在内存中的位置（读者可回顾8.7.4.2节的内容以了解Object的内存布 局），is_static表示该成员变量是否为static类型 void operator()(mirror::Object* obj, MemberOffset offset,bool is_static) const{} /*JavaLangRefVisitor需要重载如下所示的函数调用操作符。klass代表目标对象所属的类，ref 则是目标对象本身。注意，只有类的数据类型属于Java Reference的其中一种时（说明目标对象 为mirror Reference对象），下面这个函数才会被调用。注意，它并不是用来访问成员变量，而是 访问目标对象本身（将其从mirror Object转换成mirror Reference后）*/ void operator()(mirror::Class* klass, mirror::Reference* ref) const{} //下面这两个函数是Visitor必须实现的成员函数，其使用场景见下文的介绍  void VisitRootIfNonNull(mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* root) const {} void VisitRoot(mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* root) const { } ...... }; class-inl.h\nClass::VisitReferences template \u0026lt;bool kVisitNativeRoots,...,typename Visitor\u0026gt; inline void Class::VisitReferences(mirror::Class* klass, const Visitor\u0026amp; visitor) { //调用mirror Object的VisitInstanceFieldsReferences函数以访问非静态的引用型成员变量  VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); if (IsResolved\u0026lt;kVerifyFlags\u0026gt;()) { //访问静态引用型成员变量  VisitStaticFieldsReferences\u0026lt;....\u0026gt;(this, visitor); } if (kVisitNativeRoots) { //类的成员函数（对应为ArtMethod）、成员变量（对应为ArtField）均定义在mirror  //Class中。下面的VisitNativeRoots用于访问它们，来看代码  VisitNativeRoots(visitor, Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;GetImagePointerSize()); } } template\u0026lt;class Visitor\u0026gt; void Class::VisitNativeRoots(Visitor\u0026amp; visitor, size_t pointer_size) { //访问静态成员变量  for (ArtField\u0026amp; field : GetSFieldsUnchecked()) { field.VisitRoots(visitor); } //访问非静态成员变量  for (ArtField\u0026amp; field : GetIFieldsUnchecked()) { field.VisitRoots(visitor); } //GetMethods返回一个Class所定义的所有成员方法（不包括其继承得来的方法）。读者可回顾  //8.7.4.1节的内容  for (ArtMethod\u0026amp; method : GetMethods(pointer_size)) { method.VisitRoots(visitor, pointer_size); } } art_field-inl.h\nArtField::VisitRoots template\u0026lt;typename RootVisitorType\u0026gt; inline void ArtField::VisitRoots(RootVisitorType\u0026amp; visitor) { //调用函数对象的VisitRoot函数。declaring_class_是该成员变量所属的类  visitor.VisitRoot(declaring_class_.AddressWithoutBarrier()); } object_array-inl.h\nObjectArray::VisitReferences template\u0026lt;class T\u0026gt; template\u0026lt;typename Visitor\u0026gt; inline void ObjectArray\u0026lt;T\u0026gt;::VisitReferences(const Visitor\u0026amp; visitor) { const size_t length = static_cast\u0026lt;size_t\u0026gt;(GetLength()); for (size_t i = 0; i \u0026lt; length; ++i) { visitor(this, OffsetOfElement(i), false); } } dex_cache-inl.h\nDexCache::VisitReferences template \u0026lt;bool kVisitNativeRoots,..., typename Visitor\u0026gt; inline void DexCache::VisitReferences(mirror::Class* klass, const Visitor\u0026amp; visitor) { VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); if (kVisitNativeRoots) { //访问DexCache里的字符串信息。读者可回顾8.7.1.2节的内容  //GetString返回DexCache strings_成员变量  GcRoot\u0026lt;mirror::String\u0026gt;* strings = GetStrings(); for (size_t i = 0, num_strings = NumStrings(); i != num_strings; ++i) { //调用Visitor VisitRootIfNonNull函数  visitor.VisitRootIfNonNull(strings[i].AddressWithoutBarrier()); } //访问DexCache里的类型信息（DexCache resolved_types_成员变量）  GcRoot\u0026lt;mirror::Class\u0026gt;* resolved_types = GetResolvedTypes(); for (size_t i = 0, num_types = NumResolvedTypes(); i != num_types; ++i) { visitor.VisitRootIfNonNull(resolved_types[i].AddressWithoutBarrier()); } }//if判断结束 } class_loader-inl.h\nClassLoader::VisitReferences template \u0026lt;bool kVisitClasses,... typename Visitor\u0026gt; inline void ClassLoader::VisitReferences(mirror::Class* klass, const Visitor\u0026amp; visitor) { VisitInstanceFieldsReferences\u0026lt;...\u0026gt;(klass, visitor); if (kVisitClasses) { ClassTable* const class_table = GetClassTable(); if (class_table != nullptr) { //调用ClassTable的VisitRoots函数，内部将调用visitor的VisitRoots函数  //请读者自行阅读ClassTable VisitRoots函数的实现，非常简单  class_table-\u0026gt;VisitRoots(visitor); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/anr/2anrmonitor_collectinfo/",
	"title": "2ANRMonitor_CollectInfo",
	"tags": [],
	"description": "",
	"content": "应用层如何判定 ANR Android M(6.0) 版本之后，应用侧无法直接通过监听 data/anr/trace 文件，监控是否发生 ANR，那么大家又有什么其它手段去判定 ANR 呢？下面我们简单介绍一下\n站在应用侧角度来看，因为系统没有提供太友好的机制，去主动通知应用是否发生 ANR，而且很多信息更是对应用屏蔽了访问权限，但是对于三方 App 来说，也需要关注基本的用户体验，因此很多公司也进行了大量的探索，并给出了不同的解决思路，目前了解到的方案(思路)主要有下面 2 种：\n 主线程 watchdog 机制  核心思想是在应用层定期向主线程设置探测消息，并在异步设置超时监测，如在规定的时间内没有收到发送的探测消息状态更新，则判定可能发生 ANR，为什么是可能发生 ANR？因为还需要进一步从系统服务获取相关数据(下面会讲到如何获取)，进一步判定是否真的发生 ANR。\n 监听 SIGNALQUIT 信号  该方案在很多公司有应用，网上也有相关介绍，这里主要介绍一下思路。我们在上面提到了虚拟机是通过注册和监听 SIGNALQUIT 信号的方式执行请求的，而对于信号机制有了解的同学马上就可以猜到，我们也可以在应用层参考此方式注册相同信号去监听。不过要注意的是注册之后虚拟机之前注册的就会被覆盖，需要在适当的时候进行恢复，否则小心系统(厂商)找上门。\n当接收到该信号时，过滤场景，确定是发生用户可感知的 ANR 之后，从 Java 层获取各线程堆栈，或通过反射方式获取到虚拟机内部 Dump 线程堆栈的接口，在内存映射的函数地址，强制调用该接口，并将数据重定向输出到本地。\n该方案从思路上来说优于第一种方案，并且遵循系统信息获取方式，获取的线程信息及虚拟机信息更加全面，但缺点是对性能影响比较大，对于复杂的 App 来说，统计其耗时，部分场景一次 Dump 耗时可能要超过 10S。\n应用层如何获取 ANR Info 上面提到无论是 Watchdog 还是监听信号的方式，都需要结论进一步过滤，以确保收集我们想要的 ANR 场景，因此需要利用系统提供的接口，进一步判定当前应用是否发生问题(ANR，Crash)；\n与此同时，除了需要获取进程中各线程状态之外，我们也需要知道系统乃至其他进程的一些状态，如系统 CPU，Mem，IO 负载，关键进程的 CPU 使用率等等，便于推测发生问题时系统环境是否正常；\n获取信息相关接口类如下：\n通过该接口获取的相关信息，示意如下，其中下图红框选中的关键字，我们在后续 ANR 分析思路一章，会对其进行详细释义：\nxcrashanr\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/2binderserver/",
	"title": "2BinderServer",
	"tags": [],
	"description": "",
	"content": "Binder Native And Java Design classDiagram class IBinder { +queryLocalInterface(descriptor) +linkToDeath(recipient, cookie, flags) status_t +unlinkToDeath(recipient, cookie, flags, outRecipient) status_t +transact(code, data, reply, flags) status_t +localBinder() BBinder +remoteBinder() BpBinder } class BpBinder { } class BBinder { +transact(code, data, reply, flags) #onTransact(code, data, reply, flags) } class BnInterface~INTERFACE~ { +queryLocalInterface(_descriptor) IInterface +getInterfaceDescriptor() descriptor #onAsBinder() IBinder } class BnGraphicBufferProducer { +onTransact() status_t } class IInterface { +asBinder(IInterface*) IBinder } class IGraphicBufferProducer { +ipcMethod() } class BufferQueueProducer { +ipcMethod() } class JavaBBinder { +onTransact() } IBinder \u0026lt;|-- BpBinder IBinder \u0026lt;|-- BBinder BBinder \u0026lt;|-- BnInterface : native type server BBinder \u0026lt;|-- JavaBBinder : java type server BnInterface \u0026lt;|-- BnGraphicBufferProducer : BnInterface\u0026lt;IGraphicBufferProducer\u0026gt; IInterface \u0026lt;|-- IGraphicBufferProducer BnGraphicBufferProducer \u0026lt;|-- BufferQueueProducer IGraphicBufferProducer \u0026lt;|.. BnInterface : INTERFACE classDiagram class IBinder { +queryLocalInterface(descriptor) IInterface +linkToDeath(recipient, flags) +unlinkToDeath(recipient, flags) +transact(code, data, reply, flags) } class BinderProxy { } class Binder { +attachInterface(iinterface, descriptor) +transact(code, data, reply, flags) #onTransact(code, data, reply, flags) } class Stub { +asInterface(iBinder) IConnectivityManager +asBinder() IBinder +onTransact(code, data, reply, flags) } class IInterface { +asBinder() IBinder } class IConnectivityManager { +ipcMethod() } class ConnectivityService { +ipcMethod() } class Proxy { - IBinder mRemote +ipcMethod() } IBinder \u0026lt;|-- BinderProxy IBinder \u0026lt;|-- Binder Binder \u0026lt;|-- Stub IConnectivityManager \u0026lt;|.. Stub IInterface \u0026lt;|-- IConnectivityManager Stub \u0026lt;|-- ConnectivityService IConnectivityManager \u0026lt;|.. Proxy Stub --\u0026gt; Proxy : asInterface返回 NativeBBinder associated with JavaBinder 原理图 addService frameworks/base/core/java/android/os/ServiceManager.java\nServiceManager /** * Place a new @a service called @a name into the service * manager. * * @param name the name of the new service * @param service the service object * @param allowIsolated set to true to allow isolated sandboxed processes * @param dumpPriority supported dump priority levels as a bitmask * to access this service */ public static void addService(String name, IBinder service, boolean allowIsolated, int dumpPriority) { getIServiceManager().addService(name, service, allowIsolated, dumpPriority); } getService \u0026amp;\u0026amp; asInterface 即getiservicemanager()过程参考binderclient\nuseService(addService) class ServiceManagerProxy implements IServiceManager { public ServiceManagerProxy(IBinder remote) { mRemote = remote; } public IBinder asBinder() { return mRemote; } public void addService(String name, IBinder service, boolean allowIsolated, int dumpPriority) throws RemoteException { Parcel data = Parcel.obtain(); Parcel reply = Parcel.obtain(); data.writeInterfaceToken(IServiceManager.descriptor); data.writeString(name); data.writeStrongBinder(service); data.writeInt(allowIsolated ? 1 : 0); data.writeInt(dumpPriority); mRemote.transact(ADD_SERVICE_TRANSACTION, data, reply, 0); reply.recycle(); data.recycle(); } } writeStrongBinder记录BBinder /** * Write an object into the parcel at the current dataPosition(), * growing dataCapacity() if needed. */ public final void writeStrongBinder(IBinder val) { nativeWriteStrongBinder(mNativePtr, val); } frameworks/base/core/jni/android_os_Parcel.cpp\nstatic void android_os_Parcel_writeStrongBinder(JNIEnv* env, jclass clazz, jlong nativePtr, jobject object) { Parcel* parcel = reinterpret_cast\u0026lt;Parcel*\u0026gt;(nativePtr); if (parcel != NULL) { const status_t err = parcel-\u0026gt;writeStrongBinder(ibinderForJavaObject(env, object)); if (err != NO_ERROR) { signalExceptionForError(env, clazz, err); } } } frameworks/base/core/jni/android_util_Binder.cpp\nc和javaBinder对应 gBinderOffsets.mClass = MakeGlobalRefOrDie(env, clazz); gBinderOffsets.mExecTransact = GetMethodIDOrDie(env, clazz, \u0026#34;execTransact\u0026#34;, \u0026#34;(IJJI)Z\u0026#34;); gBinderOffsets.mObject = GetFieldIDOrDie(env, clazz, \u0026#34;mObject\u0026#34;, \u0026#34;J\u0026#34;); sp\u0026lt;IBinder\u0026gt; ibinderForJavaObject(JNIEnv* env, jobject obj) { if (obj == NULL) return NULL; // Instance of Binder?  if (env-\u0026gt;IsInstanceOf(obj, gBinderOffsets.mClass)) { JavaBBinderHolder* jbh = (JavaBBinderHolder*) env-\u0026gt;GetLongField(obj, gBinderOffsets.mObject); return jbh-\u0026gt;get(env, obj); } // Instance of BinderProxy?  if (env-\u0026gt;IsInstanceOf(obj, gBinderProxyOffsets.mClass)) { return getBPNativeData(env, obj)-\u0026gt;mObject; } ALOGW(\u0026#34;ibinderForJavaObject: %p is not a Binder object\u0026#34;, obj); return NULL; } frameworks/base/core/jni/android_util_Binder.cpp\nclass JavaBBinderHolder { public: sp\u0026lt;JavaBBinder\u0026gt; get(JNIEnv* env, jobject obj) { sp\u0026lt;JavaBBinder\u0026gt; b = mBinder.promote(); if (b == NULL) { b = new JavaBBinder(env, obj); mBinder = b; } return b; } wp\u0026lt;JavaBBinder\u0026gt; mBinder; } frameworks/native/libs/binder/Parcel.cpp\nstatus_t Parcel::writeStrongBinder(const sp\u0026lt;IBinder\u0026gt;\u0026amp; val) { return flatten_binder(ProcessState::self(), val, this); } 将BBinder设置为flat_binder_object的cookie status_t flatten_binder(const sp\u0026lt;ProcessState\u0026gt;\u0026amp; /*proc*/, const sp\u0026lt;IBinder\u0026gt;\u0026amp; binder, Parcel* out) { flat_binder_object obj; if (binder != NULL) { IBinder *local = binder-\u0026gt;localBinder();//本地Binder即BBinder,即Server端的Binder  if (!local) {//BBinder为空时  BpBinder *proxy = binder-\u0026gt;remoteBinder(); const int32_t handle = proxy ? proxy-\u0026gt;handle() : 0; obj.hdr.type = BINDER_TYPE_HANDLE; obj.binder = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ obj.handle = handle; obj.cookie = 0; } else { //进入该分支  obj.hdr.type = BINDER_TYPE_BINDER;//后续在binder_transaction时会被调整为BINDER_TYPE_HANDLE类型，进而保存到serviceManager的链表当中  obj.binder = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local-\u0026gt;getWeakRefs()); obj.cookie = reinterpret_cast\u0026lt;uintptr_t\u0026gt;(local);//BBinder设置为flat_binder_object的cookie  } } else { obj.hdr.type = BINDER_TYPE_BINDER; obj.binder = 0; obj.cookie = 0; } return finish_flatten_binder(binder, obj, out); } 将flat_binder_object写入Parcel inline static status_t finish_flatten_binder( const sp\u0026lt;IBinder\u0026gt;\u0026amp; , const flat_binder_object\u0026amp; flat, Parcel* out) { return out-\u0026gt;writeObject(flat, false);//将flat_binder_object写入out } transact(ADD_SERVICE_TRANSACTION\u0026hellip;) mRemote.transact(ADD_SERVICE_TRANSACTION, data, reply, 0); serverInit camefromzygote\nframeworks/native/libs/binder/ProcessState.cpp\n#define BINDER_VM_SIZE ((1 * 1024 * 1024) - sysconf(_SC_PAGE_SIZE) * 2) #define DEFAULT_MAX_BINDER_THREADS 15 ProcessState::self sp\u0026lt;ProcessState\u0026gt; ProcessState::self() { gProcess = new ProcessState(\u0026#34;/dev/binder\u0026#34;); return gProcess; } open_driver \u0026amp;\u0026amp; mmap ProcessState::ProcessState(const char *driver) : mDriverName(String8(driver)) , mDriverFD(open_driver(driver))//call open_driver  , mVMStart(MAP_FAILED) , mThreadCountLock(PTHREAD_MUTEX_INITIALIZER) , mThreadCountDecrement(PTHREAD_COND_INITIALIZER) , mExecutingThreadsCount(0) , mMaxThreads(DEFAULT_MAX_BINDER_THREADS) , mStarvationStartTimeMs(0) , mManagesContexts(false) , mBinderContextCheckFunc(NULL) , mBinderContextUserData(NULL) , mThreadPoolStarted(false) , mThreadPoolSeq(1) { if (mDriverFD \u0026gt;= 0) { // mmap the binder, providing a chunk of virtual address space to receive transactions.  mVMStart = mmap(0, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0); } } static int open_driver(const char *driver) { int fd = open(driver, O_RDWR | O_CLOEXEC); if (fd \u0026gt;= 0) { int vers = 0; status_t result = ioctl(fd, BINDER_VERSION, \u0026amp;vers); size_t maxThreads = DEFAULT_MAX_BINDER_THREADS; result = ioctl(fd, BINDER_SET_MAX_THREADS, \u0026amp;maxThreads); } else { ALOGW(\u0026#34;Opening \u0026#39;%s\u0026#39; failed: %s\\n\u0026#34;, driver, strerror(errno)); } return fd; } startThreadPool void ProcessState::startThreadPool() { AutoMutex _l(mLock); if (!mThreadPoolStarted) { mThreadPoolStarted = true; spawnPooledThread(true); } } spawnPooledThread void ProcessState::spawnPooledThread(bool isMain)//创建一个Thread用于提供Binder服务 { if (mThreadPoolStarted) { String8 name = makeBinderThreadName(); ALOGV(\u0026#34;Spawning new pooled thread, name=%s\\n\u0026#34;, name.string()); sp\u0026lt;Thread\u0026gt; t = new PoolThread(isMain); t-\u0026gt;run(name.string()); } } String8 ProcessState::makeBinderThreadName() { int32_t s = android_atomic_add(1, \u0026amp;mThreadPoolSeq); pid_t pid = getpid(); String8 name; name.appendFormat(\u0026#34;Binder:%d_%X\u0026#34;, pid, s); return name; } PoolThread::threadLoop │50 class PoolThread : public Thread │51 { 58 protected: │59 virtual bool threadLoop() │60 { \u0026gt;│61 IPCThreadState::self()-\u0026gt;joinThreadPool(mIsMain); │62 return false; │63 } 66 }; void IPCThreadState::threadDestructor(void *st) { IPCThreadState* const self = static_cast\u0026lt;IPCThreadState*\u0026gt;(st); if (self) { self-\u0026gt;flushCommands(); if (self-\u0026gt;mProcess-\u0026gt;mDriverFD \u0026gt; 0) { ioctl(self-\u0026gt;mProcess-\u0026gt;mDriverFD, BINDER_THREAD_EXIT, 0); } delete self; } } IPCThreadState::joinThreadPool 528 void IPCThreadState::joinThreadPool(bool isMain) │529 { │532 mOut.writeInt32(isMain ? BC_ENTER_LOOPER : BC_REGISTER_LOOPER); │533 │534 status_t result; │535 do { │536 processPendingDerefs(); │537 // now get the next command to be processed, waiting if necessary  \u0026gt;│538 result = getAndExecuteCommand(); │539 │540 if (result \u0026lt; NO_ERROR \u0026amp;\u0026amp; result != TIMED_OUT \u0026amp;\u0026amp; result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF) { │541 ALOGE(\u0026#34;getAndExecuteCommand(fd=%d) returned unexpected error %d, aborting\u0026#34;, │542 mProcess-\u0026gt;mDriverFD, result); │543 abort(); │544 } │545 │546 // Let this thread exit the thread pool if it is no longer  │547 // needed and it is not the main process thread.  │548 if(result == TIMED_OUT \u0026amp;\u0026amp; !isMain) { │549 break; │550 } │551 } while (result != -ECONNREFUSED \u0026amp;\u0026amp; result != -EBADF); │552 │556 mOut.writeInt32(BC_EXIT_LOOPER); │557 talkWithDriver(false); │558 } IPCThreadState::getAndExecuteCommand │435 status_t IPCThreadState::getAndExecuteCommand() │436 { │437 status_t result; │438 int32_t cmd; │439 │440 result = talkWithDriver(); 441 if (result \u0026gt;= NO_ERROR) { │442 size_t IN = mIn.dataAvail(); │443 if (IN \u0026lt; sizeof(int32_t)) return result; │444 cmd = mIn.readInt32(); \u0026gt;│458 result = executeCommand(cmd); │459 │460 pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); │461 mProcess-\u0026gt;mExecutingThreadsCount--; │471 pthread_cond_broadcast(\u0026amp;mProcess-\u0026gt;mThreadCountDecrement); │472 pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); │473 } │474 │475 return result; │476 } │477 IPCThreadState::executeCommand │998 status_t IPCThreadState::executeCommand(int32_t cmd) │999 { │1000 BBinder* obj; │1001 RefBase::weakref_type* refs; │1002 status_t result = NO_ERROR; │1003 │1004 switch ((uint32_t)cmd) { 1077 case BR_TRANSACTION: │1078 { │1079 binder_transaction_data tr; │1080 result = mIn.read(\u0026amp;tr, sizeof(tr)); │1103 Parcel reply; │1104 status_t error; │1116 if (tr.target.ptr) { │1117 // We only have a weak reference on the target object, so we must first try to  │1118 // safely acquire a strong reference before doing anything else with it.  │1119 if (reinterpret_cast\u0026lt;RefBase::weakref_type*\u0026gt;( │1120 tr.target.ptr)-\u0026gt;attemptIncStrong(this)) { \u0026gt;│1121 error = reinterpret_cast\u0026lt;BBinder*\u0026gt;(tr.cookie)-\u0026gt;transact(tr.code, buffer, │1122 \u0026amp;reply, tr.flags); │1123 reinterpret_cast\u0026lt;BBinder*\u0026gt;(tr.cookie)-\u0026gt;decStrong(this); │1124 } else { │1125 error = UNKNOWN_TRANSACTION; │1126 } │1127 │1128 } else { │1129 error = the_context_object-\u0026gt;transact(tr.code, buffer, \u0026amp;reply, tr.flags); │1130 } │1135 if ((tr.flags \u0026amp; TF_ONE_WAY) == 0) { │1136 LOG_ONEWAY(\u0026#34;Sending reply to %d!\u0026#34;, mCallingPid); │1137 if (error \u0026lt; NO_ERROR) reply.setError(error); │1138 sendReply(reply, 0); │1139 } else { │1140 LOG_ONEWAY(\u0026#34;NOT sending reply to %d!\u0026#34;, mCallingPid); │1141 } │1155 break; case BR_SPAWN_LOOPER: mProcess-\u0026gt;spawnPooledThread(false); break; binder_transaction_data.cookie作为BBinder,调用其transact │118 status_t BBinder::transact( │119 uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) │120 { │121 data.setDataPosition(0); │122 │123 status_t err = NO_ERROR; │124 switch (code) { │125 case PING_TRANSACTION: │126 reply-\u0026gt;writeInt32(pingBinder()); │127 break; │128 default: \u0026gt;│129 err = onTransact(code, data, reply, flags); │130 break; │131 } │132 │133 if (reply != NULL) { │134 reply-\u0026gt;setDataPosition(0); │135 } │136 │137 return err; │138 } JavaBBinder::onTransact调用java层Binder对应的execTransact方法 参考c和javabinder对应\nvirtual status_t onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0) { JNIEnv* env = javavm_to_jnienv(mVM); //printf(\u0026#34;Transact from %p to Java code sending: \u0026#34;, this);  //data.print();  //printf(\u0026#34;\\n\u0026#34;);  jboolean res = env-\u0026gt;CallBooleanMethod(mObject, gBinderOffsets.mExecTransact, code, reinterpret_cast\u0026lt;jlong\u0026gt;(\u0026amp;data), reinterpret_cast\u0026lt;jlong\u0026gt;(reply), flags); Binder.java\n// Entry point from android_util_Binder.cpp\u0026#39;s onTransact  private boolean execTransact(int code, long dataObj, long replyObj, int flags) { res = onTransact(code, data, reply, flags); } 其他关联知识点 system/core/libutils/Threads.cpp\nThreads::run status_t Thread::run(const char* name, int32_t priority, size_t stack) { if (mCanCallJava) { res = createThreadEtc(_threadLoop, this, name, priority, stack, \u0026amp;mThread); } else { res = androidCreateRawThreadEtc(_threadLoop, this, name, priority, stack, \u0026amp;mThread); } androidCreateRawThreadEtc int androidCreateRawThreadEtc(android_thread_func_t entryFunction, void *userData, const char* threadName __android_unused, int32_t threadPriority, size_t threadStackSize, android_thread_id_t *threadId) { int result = pthread_create(\u0026amp;thread, \u0026amp;attr, (android_pthread_entry)entryFunction, userData); } _threadLoop │711 int Thread::_threadLoop(void* user) │712 { 726 do { │727 bool result; │728 if (first) { │729 first = false; │730 self-\u0026gt;mStatus = self-\u0026gt;readyToRun(); │731 result = (self-\u0026gt;mStatus == NO_ERROR); │732 │733 if (result \u0026amp;\u0026amp; !self-\u0026gt;exitPending()) { │734 // Binder threads (and maybe others) rely on threadLoop  │735 // running at least once after a successful ::readyToRun()  │736 // (unless, of course, the thread has already been asked to exit  │737 // at that point).  │738 // This is because threads are essentially used like this:  │739 // (new ThreadSubclass())-\u0026gt;run();  │740 // The caller therefore does not retain a strong reference to  │741 // the thread and the thread would simply disappear after the  │742 // successful ::readyToRun() call instead of entering the  │743 // threadLoop at least once.  \u0026gt;│744 result = self-\u0026gt;threadLoop(); │745 } │746 } else { │747 result = self-\u0026gt;threadLoop(); │748 } 766 // Release our strong reference, to let a chance to the thread  │767 // to die a peaceful death.  │768 strong.clear(); │769 // And immediately, re-acquire a strong reference for the next loop  │770 strong = weak.promote(); │771 } while(strong != 0); frameworks/native/libs/binder/include/binder/IBinder.h\nIBinder /** * Base class and low-level protocol for a remotable object. * You can derive from this class to create an object for which other * processes can hold references to it. Communication between processes * (method calls, property get and set) is down through a low-level * protocol implemented on top of the transact() API. */ class IBinder : public virtual RefBase { /** * Check if this IBinder implements the interface named by * @a descriptor. If it does, the base pointer to it is returned, * which you can safely static_cast\u0026lt;\u0026gt; to the concrete C++ interface. */ virtual sp\u0026lt;IInterface\u0026gt; queryLocalInterface(const String16\u0026amp; descriptor); virtual status_t transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0) = 0; /** * Register the @a recipient for a notification if this binder * goes away. If this binder object unexpectedly goes away * (typically because its hosting process has been killed), * then DeathRecipient::binderDied() will be called with a reference * to this. * * The @a cookie is optional -- if non-NULL, it should be a * memory address that you own (that is, you know it is unique). * * @note You will only receive death notifications for remote binders, * as local binders by definition can\u0026#39;t die without you dying as well. * Trying to use this function on a local binder will result in an * INVALID_OPERATION code being returned and nothing happening. * * @note This link always holds a weak reference to its recipient. * * @note You will only receive a weak reference to the dead * binder. You should not try to promote this to a strong reference. * (Nor should you need to, as there is nothing useful you can * directly do with it now that it has passed on.) */ virtual status_t linkToDeath(const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie = NULL, uint32_t flags = 0) = 0; frameworks/native/libs/binder/include/binder/Binder.h\nBBinder class BBinder : public IBinder { public: virtual status_t transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0); virtual status_t linkToDeath(const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie = NULL, uint32_t flags = 0); protected: virtual ~BBinder(); virtual status_t onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags = 0); frameworks/native/libs/binder/include/binder/IInterface.h\nIInterface class IInterface : public virtual RefBase { public: IInterface(); static sp\u0026lt;IBinder\u0026gt; asBinder(const IInterface*); static sp\u0026lt;IBinder\u0026gt; asBinder(const sp\u0026lt;IInterface\u0026gt;\u0026amp;); protected: virtual ~IInterface(); virtual IBinder* onAsBinder() = 0; }; template\u0026lt;typename INTERFACE\u0026gt; class BnInterface : public INTERFACE, public BBinder { public: virtual sp\u0026lt;IInterface\u0026gt; queryLocalInterface(const String16\u0026amp; _descriptor); virtual const String16\u0026amp; getInterfaceDescriptor() const; protected: virtual IBinder* onAsBinder(); }; template\u0026lt;typename INTERFACE\u0026gt; class BpInterface : public INTERFACE, public BpRefBase { public: explicit BpInterface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; remote); protected: virtual IBinder* onAsBinder(); }; BinderInternal_setMaxThreads frameworks/base/core/jni/android_util_Binder.cpp\nstatic void android_os_BinderInternal_setMaxThreads(JNIEnv* env, jobject clazz, jint maxThreads)// called by SystemServer.java BinderInternal.setMaxThreads { ProcessState::self()-\u0026gt;setThreadPoolMaxThreadCount(maxThreads); } frameworks/native/libs/binder/BpBinder.cpp\nBpBinder::create BpBinder* BpBinder::create(int32_t handle) { int32_t trackedUid = -1; if (sCountByUidEnabled) { trackedUid = IPCThreadState::self()-\u0026gt;getCallingUid(); } return new BpBinder(handle, trackedUid); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/2livedata/",
	"title": "2livedata",
	"tags": [],
	"description": "",
	"content": "2livedata 探索总结2livedata知识\n 1MediatorLiveData     LiveData     LiveDataCoroutine     Transformations     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/2oom/",
	"title": "2OOM",
	"tags": [],
	"description": "",
	"content": "OOM原因分析 要定位OOM问题，首先需要弄明白Android中有哪些原因会导致OOM，Android中导致OOM的原因主要可以划分为以下几个类型：\nAndroid 虚拟机最终抛出OutOfMemoryError的代码位于/art/runtime/thread.cc。\nvoid Thread::ThrowOutOfMemoryError(const char* msg) 参数 msg 携带了 OOM 时的错误信息 下面两个地方都会调用上面方法抛出OutOfMemoryError错误，这也是Android中发生OOM的主要原因。\n堆内存分配失败 系统源码文件：/art/runtime/gc/heap.cc\nvoid Heap::ThrowOutOfMemoryError(Thread* self, size_t byte_count, AllocatorType allocator_type) 抛出时的错误信息： oss \u0026lt;\u0026lt; \u0026#34;Failed to allocate a \u0026#34; \u0026lt;\u0026lt; byte_count \u0026lt;\u0026lt; \u0026#34; byte allocation with \u0026#34; \u0026lt;\u0026lt; total_bytes_free \u0026lt;\u0026lt; \u0026#34; free bytes and \u0026#34; \u0026lt;\u0026lt; PrettySize(GetFreeMemoryUntilOOME()) \u0026lt;\u0026lt; \u0026#34; until OOM\u0026#34;; 这是在进行堆内存分配时抛出的OOM错误，这里也可以细分成两种不同的类型：\n 为对象分配内存时达到进程的内存上限。由Runtime.getRuntime.MaxMemory()可以得到Android中每个进程被系统分配的内存上限，当进程占用内存达到这个上限时就会发生OOM，这也是Android中最常见的OOM类型。 没有足够大小的连续地址空间。这种情况一般是进程中存在大量的内存碎片导致的，其堆栈信息会比第一种OOM堆栈多出一段信息：failed due to fragmentation (required continguous free “\u0026laquo; required_bytes \u0026laquo; “ bytes for a new buffer where largest contiguous free ” \u0026laquo; largest_continuous_free_pages \u0026laquo; “ bytes)”; 其详细代码在art/runtime/gc/allocator/rosalloc.cc中，这里不作详述。  创建线程失败 系统源码文件：/art/runtime/thread.cc\nvoid Thread::CreateNativeThread(JNIEnv* env, jobject java_peer, size_t stack_size, bool is_daemon) 抛出时的错误信息： \u0026#34;Could not allocate JNI Env\u0026#34; 或者 StringPrintf(\u0026#34;pthread_create (%s stack) failed: %s\u0026#34;, PrettySize(stack_size).c_str(), strerror(pthread_create_result))); 这是创建线程时抛出的OOM错误，且有多种错误信息。源码这里不展开详述了，下面是根据源码整理的Android中创建线程的步骤，其中两个关键节点是创建JNIEnv结构体和创建线程，而这两步均有可能抛出OOM。\n创建JNI失败 创建JNIEnv可以归为两个步骤：\n 通过Andorid的匿名共享内存（Anonymous Shared Memory）分配 4KB（一个page）内核态内存。 再通过Linux的mmap调用映射到用户态虚拟内存地址空间。  第一步创建匿名共享内存时，需要打开/dev/ashmem文件，所以需要一个FD（文件描述符）。此时，如果创建的FD数已经达到上限，则会导致创建JNIEnv失败，抛出错误信息如下：\nE/art: ashmem_create_region failed for \u0026#39;indirect ref table\u0026#39;: Too many open files java.lang.OutOfMemoryError: Could not allocate JNI Env at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:730) 第二步调用mmap时，如果进程虚拟内存地址空间耗尽，也会导致创建JNIEnv失败，抛出错误信息如下：\nE/art: Failed anonymous mmap(0x0, 8192, 0x3, 0x2, 116, 0): Operation not permitted. See process maps in the log. java.lang.OutOfMemoryError: Could not allocate JNI Env at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:1063) 创建线程失败 创建线程也可以归纳为两个步骤：\n 调用mmap分配栈内存。这里mmap flag中指定了MAP_ANONYMOUS，即匿名内存映射。这是在Linux中分配大块内存的常用方式。其分配的是虚拟内存，对应页的物理内存并不会立即分配，而是在用到的时候触发内核的缺页中断，然后中断处理函数再分配物理内存。 调用clone方法进行线程创建。  第一步分配栈内存失败是由于进程的虚拟内存不足，抛出错误信息如下：\nW/libc: pthread_create failed: couldn\u0026#39;t allocate 1073152-bytes mapped space: Out of memory W/tch.crowdsourc: Throwing OutOfMemoryError with VmSize 4191668 kB \u0026#34;pthread_create (1040KB stack) failed: Try again\u0026#34; java.lang.OutOfMemoryError: pthread_create (1040KB stack) failed: Try again at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:753) 第二步clone方法失败是因为线程数超出了限制，抛出错误信息如下：\nW/libc: pthread_create failed: clone failed: Out of memory W/art: Throwing OutOfMemoryError \u0026#34;pthread_create (1040KB stack) failed: Out of memory\u0026#34; java.lang.OutOfMemoryError: pthread_create (1040KB stack) failed: Out of memory at java.lang.Thread.nativeCreate(Native Method) at java.lang.Thread.start(Thread.java:1078) 线程监控 常见的 OOM 情况大多数是因为内存泄漏或申请大量内存造成的，比较少见的有下面这种跟线程相关情况，但在我们 crash 系统上有时能发现一些这样的问题。\njava.lang.OutOfMemoryError: pthread_create (1040KB stack) failed: Out of memory 原因分析\nOutOfMemoryError 这种异常根本原因在于申请不到足够的内存造成的，直接的原因是在创建线程时初始 stack size 的时候，分配不到内存导致的。这个异常是在 /art/runtime/thread.cc 中线程初始化的时候 throw 出来的。\nvoid Thread::CreateNativeThread(JNIEnv* env, jobject java_peer, size_t stack_size, bool is_daemon) { ... int pthread_create_result = pthread_create( \u0026amp;new_pthread, \u0026amp;attr, Thread::CreateCallback, child_thread); if (pthread_create_result != 0) { env-\u0026gt;SetLongField(java_peer, WellKnownClasses::java_lang_Thread_nativePeer, 0); { std::string msg(StringPrintf(\u0026#34;pthread_create (%s stack) failed: %s\u0026#34;, PrettySize(stack_size).c_str(), strerror(pthread_create_result))); ScopedObjectAccess soa(env); soa.Self()-\u0026gt;ThrowOutOfMemoryError(msg.c_str()); } } } 调用这个 pthread_create 的方法去 clone 一个线程，如果返回 pthread_create_result 不为 0，则代表初始化失败。什么情况下会初始化失败，pthread_create 的具体逻辑是在 /bionic/libc/bionic/pthread_create.cpp 中完成：\nint pthread_create(pthread_t* thread_out, pthread_attr_t const* attr, void* (*start_routine)(void*), void* arg) { ... pthread_internal_t* thread = NULL; void* child_stack = NULL; int result = __allocate_thread(\u0026amp;thread_attr, \u0026amp;thread, \u0026amp;child_stack); if (result != 0) { return result; } ... } static int __allocate_thread(pthread_attr_t* attr, pthread_internal_t** threadp, void** child_stack) { size_t mmap_size; uint8_t* stack_top; ... attr-\u0026gt;stack_base = __create_thread_mapped_space(mmap_size, attr-\u0026gt;guard_size); if (attr-\u0026gt;stack_base == NULL) { return EAGAIN; // EAGAIN != 0  } ... return 0; } 可以看到每个线程初始化都需要 mmap 一定的 stack size，在默认的情况下一般初始化一个线程需要 mmap 1M 左右的内存空间，在 32bit 的应用中有 4g 的 vmsize，实际能使用的有 3g+，按这种估算，一个进程最大能创建的线程数可达 3000+，当然这是理想的情况，在 linux 中对每个进程可创建的线程数也有一定的限制（/proc/pid/limits）而实际测试中，我们也发现不同厂商对这个限制也有所不同，而且当超过系统进程线程数限制时，同样会抛出这个类型的 OOM。\n可见对线程数量的限制，可以一定程度避免 OOM 的发生。所以我们也开始对微信的线程数进行了监控统计。\n监控上报\n我们在灰度版本中通过一个定时器 10 分钟 dump 出应用所有的线程，当线程数超过一定阈值时，将当前的线程上报并预警，通过对这种异常情况的捕捉，我们发现微信在某些特殊场景下，确实存在线程泄漏以及短时间内线程暴增，导致线程数过大（500+）的情况，这种情况下再创建线程往往容易出现 OOM。\n在定位并解决这几个问题后，我们的 crash 系统和厂商的反馈中这种类型 OOM 确实降低了不少。所以监控线程数，收敛线程也成为我们降低 OOM 的有效手段之一。\n堆内存不足 Android中最常见的OOM就是Java堆内存不足，对于堆内存不足导致的OOM问题，发生Crash时的堆栈信息往往只是“压死骆驼的最后一根稻草”，它并不能有效帮助我们准确地定位到问题。\n堆内存分配失败，通常说明进程中大部分的内存已经被占用了，且不能被垃圾回收器回收，一般来说此时内存占用都存在一些问题，例如内存泄漏等。要想定位到问题所在，就需要知道进程中的内存都被哪些对象占用，以及这些对象的引用链路。而这些信息都可以在Java内存快照文件中得到，调用Debug.dumpHprofData(String fileName)函数就可以得到当前进程的Java内存快照文件（即HPROF文件）。所以，关键在于要获得进程的内存快照，由于dump函数比较耗时，在发生OOM之后再去执行dump操作，很可能无法得到完整的内存快照文件。\n线上分析 首先，我们介绍几个基本概念：\n Dominator：从GC Roots到达某一个对象时，必须经过的对象，称为该对象的Dominator。例如在上图中，B就是E的Dominator，而B却不是F的Dominator。Dominator用于计算RetainSize,一旦object的dominator被释放，那么自身也会被释放。上图黄色node为dominator tree ShallowSize：对象自身占用的内存大小，不包括它引用的对象。 RetainSize：对象自身的ShallowSize和对象所支配的（可直接或间接引用到的）对象的ShallowSize总和，就是该对象GC之后能回收的内存总和。例如上图中，D的RetainSize就是D、H、I三者的ShallowSize之和。  Object Reference graph to Dominator Tree Conversion\nJVM在进行GC的时候会进行可达性分析，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是可回收的。\nGithub上有一个开源项目HAHA库，用于自动解析和分析Java内存快照文件（即HPROF文件）。下面是HAHA库的分析步骤：\nHAHA库 退出率定义 经过认真思考，我们认识到从前忽略了一个重要的基本事实，即应用的启动数和应用的退出数是守恒的。每次启动必然会有对应的退出，只要将所有的退出类型都枚举出来并监控上报，且总数能和启动数吻合，就能覆盖所有的稳定性问题。 基于以上思想，我们提出了退出率的概念，将退出分为以下十大类，每一类的退出率定义为 退出次数 / 启动次数。\n图4\n其中前五种退出类型是显著影响用户体验的问题，需要重点关注，crash(不含OOM)和OOM对应的是开头提到的通用指标；前台系统强杀指的是设备总内存紧张，应用在前台被系统强杀，比如iOS的jetsam，android的low memory killer，也包括其他一些资源问题，比如上文讲的wakeups；watchdog指的是卡顿引起的系统强杀，典型的即为iOS的watchdog和android的ANR；exit指的是我们主动在代码中自杀，通常情况下不应该有这样的逻辑存在。后五种退出类型绝大多数情况下是正常的退出行为，对用户体验无影响，我们只关注其中异常的情况，比如UI错乱导致的用户强杀，危险代码导致的系统重启等。\nAndroid OOM治理 图9\n回顾前文，OOM在稳定性重点关注问题中的占比非常高，和占比最高的前台系统强杀也有很高的相关性，而OOM问题的定位又特别困难，通常需要投入大量的人力和时间，进行人工复现，灰度收集数据，提交记录二分法暴力验证等等。占比高又定位困难，可以说OOM治理是稳定性治理皇冠上的明珠。 提到OOM，肯定绕不开神器LeakCanary，其原理也是面试题中的常客，作为Android内存泄漏监控的开创者，多年来一直为广大app保驾护航，解决了OOM治理从0到1的问题。那么直接接入LeakCanary上线不香么？还真不行，LeakCanary虽然非常优秀，但也存在以下几点硬伤：\n 无法线上部署  主动触发GC，造成卡顿 Dump内存镜像造成app冻结 解析镜像成功率低 不具备上报能力   适用范围有限  只能定位Activity\u0026amp;Fragment泄漏 无法定位大对象、频繁分配等问题   自动化程度低  需要人工埋点 无法对问题聚类    既然没有现成的轮子可用，只能自己动手，丰衣足食，经过一番努力，我们打造了一套可以线上部署、兼顾线下、配置灵活、适用范围广泛、高度自动化，埋点、监控、解析、上报、分发、跟进、报警一站式服务的闭环监控系统。\n核心流程图解 graph LR subgraph 解析单一引用链 LeakCanary3 end subgraph 解析大量引用链 KOOM3 end 监控模块--\u0026gt;LeakCannary1(\u0026quot;LeakCannary\u0026quot;)--\u0026gt;泄露发生实时,主动触发GC,会造成卡顿 监控模块--\u0026gt;KOOM--\u0026gt;内存阈值监控--\u0026gt;Java堆内存/线程数/文件描述符数突破阈值触发采集 内存阈值监控--\u0026gt;Java堆上涨速度突破阈值触发采集 内存阈值监控--\u0026gt;发生OOM时如果策略1,2未命中,触发采集 内存阈值监控--\u0026gt;泄漏判定延迟至解析时 采集模块--\u0026gt;LeakCannary2(\u0026quot;LeakCannary\u0026quot;)--\u0026gt;主进程DumpHprof,会造成app冻结 LeakCannary2--\u0026gt;Hprof文件过大 采集模块--\u0026gt;KOOM2(\u0026quot;KOOM\u0026quot;)--\u0026gt;Fork子进程DumpHprof,提前suspendAllThreads KOOM2--\u0026gt;HookWrite实时裁剪Hprof 解析模块--\u0026gt;LeakCanary3(\u0026quot;LeakCannary\u0026quot;)--\u0026gt;解析耗时过长 解析模块--\u0026gt;KOOM3(\u0026quot;KOOM\u0026quot;)--\u0026gt;客户端解析 KOOM3--\u0026gt;关键对象判定--\u0026gt;泄露 关键对象判定--\u0026gt;shallow/retainedSize超过阈值 KOOM3--\u0026gt;性能优化--\u0026gt;内存懒加载,存储对象在hprof中的位置,并为其建立索引方便按需解析 性能优化--\u0026gt;SortedBytesMap 性能优化--\u0026gt;类型剪枝,同类对象超过阈值不再搜索,缓存每个类的superClass,objectID类型从long改为int 其核心流程为三部分：\n 监控OOM，发生问题时触发内存镜像的采集，以便进一步分析问题 采集内存镜像，学名堆转储，将内存数据拷贝到文件中，以下简称dump hprof 解析镜像文件，对泄漏、超大对象等我们关注的对象进行可达性分析，解析出其到GC root的引用链以解决问题  为完成这样一套监控系统，我们攻克了以下技术难题\n 监控  主动触发GC，会造成卡顿   采集  Dump hprof，会造成app冻结 Hprof文件过大   解析  解析耗时过长 解析本身有OOM风险    接下来我们一一展开分析。\n解决GC卡顿 为什么LeakCanary需要主动触发GC呢？LeakCanary监控泄漏利用了弱引用的特性，为Activity创建弱引用，当Activity对象变成弱可达时(没有强引用)，弱引用会被加入到引用队列中，通过在Activity.onDestroy()后连续触发两次GC，并检查引用队列，可以判定Activity是否发生了泄漏。但频繁的GC会造成用户可感知的卡顿，为解决这一问题，我们设计了全新的监控模块，通过无性能损耗的内存阈值监控来触发镜像采集，具体策略如下：\n Java堆内存/线程数/文件描述符数突破阈值触发采集 Java堆上涨速度突破阈值触发采集 发生OOM时如果策略1、2未命中 触发采集 泄漏判定延迟至解析时  阈值监控只要在子线程定期获取关注的几个内存指标即可，性能损耗可以忽略不计；内存快速上涨用来定位对象频繁分配的问题；OOM作为最后兜底的策略，走到这里说明我们的阈值设计有漏洞，没有拦截住所有可能触发OOM的场景；最后，我们将对象是否泄漏的判断延迟到了解析时。还是以Activity为例，我们并不需要在运行时判定其是否泄漏，Activity有一个成员变mDestroyed，在onDestory时会被置为true，只要解析时发现有可达且mDestroyed为true的Activity，即可判定为泄漏(由于时序问题，这里可能有极小概率会发生误判，但不影响我们解决问题)，其他关注的对象可以根据其特点设计规则。用一张图总结：\n图11\n解决Dump hprof冻结app Dump hprof是通过虚拟机提供的API dumpHprofData实现的，这个过程会**“冻结”**整个应用进程，造成数秒甚至数十秒内用户无法操作，这也是LeakCanary无法线上部署的最主要原因，如果能将这一过程优化至用户无感知，将会给OOM治理带来很大的想象空间。\n面对这样一个问题，我们将其拆解，自然而然产生2个疑问： 1.为什么dumpHprofData会冻结app，虚拟机的实现原理是什么？ 2.这个过程能异步吗？ 我们来看dumpHprofData的虚拟机内部实现 art/runtime/hprof/hprof.cc\n// If \u0026#34;direct_to_ddms\u0026#34; is true, the other arguments are ignored, and data is sent directly to DDMS. // If \u0026#34;fd\u0026#34; is \u0026gt;= 0, the output will be written to that file descriptor. // Otherwise, \u0026#34;filename\u0026#34; is used to create an output file. void DumpHeap(const char* filename, int fd, bool direct_to_ddms) { CHECK(filename != nullptr); Thread* self = Thread::Current(); // Need to take a heap dump while GC isn\u0026#39;t running. See the comment in Heap::VisitObjects().  // Also we need the critical section to avoid visiting the same object twice. See b/34967844  gc::ScopedGCCriticalSection gcs(self, gc::kGcCauseHprof, gc::kCollectorTypeHprof); ScopedSuspendAll ssa(__FUNCTION__, true /* long suspend */); Hprof hprof(filename, fd, direct_to_ddms); hprof.Dump(); } 可以看到在dump前，通过ScopedSuspendAll(构造函数中执行SuspendAll)执行了暂停所有java线程的操作，以防止在dump的过程中java堆发生变化，当dump结束后通过ScopedSuspendAll析构函数进行ResumeAll。\n解决了第一个问题，接下来看第二个问题，既然要冻结所有线程，子线程异步处理是没有意义的，那么在子进程中处理呢？Android的内核是定制过的Linux， 而Linux fork子进程有一个著名的COW(Copy-on-write，写时复制)机制，即为了节省fork子进程的内存消耗和耗时，fork出的子进程并不会copy父进程的内存，而是和父进程共享内存空间。那么如何做到进程隔离呢，父子进程只在发生内存写入操作时，系统才会分配新的内存为写入方保留单独的拷贝，这就相当于子进程保留了fork瞬间时父进程的内存镜像，且后续父进程对内存的修改不会影响子进程，想到这里我们豁然开朗。说干就干，我们写了一个demo来验证这个思路，很快就遇到了棘手的新问题：dump前需要暂停所有java线程，而子进程只保留父进程执行fork操作的线程，在子进程中执行SuspendAll触发暂停是永远等不到其他线程返回结果的(详见thread_list.cc中行SuspendAll的实现，这里不展开讲了)，经过仔细分析SuspendAll的过程，我们发现，可以先在主进程执行SuspendAll，使ThreadList中保存的所有线程状态为suspend，之后fork，子进程共享父进程的ThreadList全局变量，可以欺骗虚拟机，使其以为全部线程已经完成了暂停操作，接下来子进程就可以愉快的dump hprof了，而父进程可以立刻执行ResumeAll恢复运行。\n这里有一个小技巧，SuspendAll没有对外暴露Java层的API，我们可以通过C层间接暴露的art::Dbg::SuspendVM来调用，dlsym拿到“_ZN3art3Dbg9SuspendVMEv”的地址调用即可，ResumeAll同理，注意这个函数在android 11以后已经被去除了，需要另行适配。Android 7之后对linker做了限制（即dlopen系统库失效），快手自研了kwai-linker组件，通过caller address替换和dl_iterate_phdr解析绕过了这一限制。 至此，我们完美解决了dump hprof冻结app的问题，用一张图总结：\n图12\n解决hprof文件过大 Hprof文件通常比较大，分析OOM时遇到500M以上的hprof文件并不稀奇，文件的大小，与dump成功率、dump速度、上传成功率负相关，且大文件额外浪费用户大量的磁盘空间和流量。我们因此想到了对hprof进行裁剪，只保留分析OOM必须的数据，另外，裁剪还有数据脱敏的好处，只上传内存中类与对象的组织结构，并不上传真实的业务数据（诸如字符串、byte数组等含有具体数据的内容），保护用户隐私。\n开发镜像裁剪，有两个衡量指标：一是裁剪率，即在不影响问题分析的前提下，裁剪掉的内容要足够多；二是裁剪性能损耗，如果性能不达标引发耗电、成功率低引入新的问题，就会使得内存镜像获取得不偿失。\n照例，我们将问题拆解：\n hprof存的内容都是些什么？数据如何组织的？哪些可以裁掉？ 内存中的数据结构和hprof文件二进制协议的映射关系？ 如何裁剪？  想要了解hprof的数据组织方式，推荐阅读openjdk官方文档[2]，Android在此基础上做了一些扩展，这里简要介绍一下核心内容：\n 文件按byte by byte顺序存储，u1,u2,u4分别代表1字节，2字节，4字节。 总体分为两部分，Header和Record，Header记录hprof的元信息，Record分很多条目，每一条有一个单独的TAG代表类型。  我们关注的Record类型主要是HEAP DUMP，其中又分五个子类，分别为GC ROOT、CLASS DUMP、INSTANCE DUMP、OBJECT ARRAY DUMP、PRIMITIVE ARRAY DUMP。图13以PRIMITIVE ARRAY DUMP(基本类型数组)为例展示Record中包含的信息，其他类型请查阅官方文档。内存中绝大部分数据是PRIMITIVE ARRAY DUMP，通常占据80%以上，而我们分析OOM只关系对象的大小和引用关系，并不关心内容，因此这部分是我们裁剪的突破口。\n图13\nAndroid对数据类型做了扩展，增加了一些GC ROOT\n// Android.  HPROF_HEAP_DUMP_INFO = 0xfe, HPROF_ROOT_INTERNED_STRING = 0x89, HPROF_ROOT_FINALIZING = 0x8a, // Obsolete.  HPROF_ROOT_DEBUGGER = 0x8b, HPROF_ROOT_REFERENCE_CLEANUP = 0x8c, // Obsolete.  HPROF_ROOT_VM_INTERNAL = 0x8d, HPROF_ROOT_JNI_MONITOR = 0x8e, HPROF_UNREACHABLE = 0x90, // Obsolete.  HPROF_PRIMITIVE_ARRAY_NODATA_DUMP = 0xc3, // Obsolete. 还有一个HEAP_DUMP_INFO，这里面保存的是堆空间(heap space)的类型，Android对堆空间做了划分，我们只关注HPROF_HEAP_APP即可，其余也是可以裁剪掉的，可以参考Android Studio中Memory Profiler的处理[3]。\nenum HprofHeapId { HPROF_HEAP_DEFAULT = 0, HPROF_HEAP_ZYGOTE = \u0026#39;Z\u0026#39;, HPROF_HEAP_APP = \u0026#39;A\u0026#39;, HPROF_HEAP_IMAGE = \u0026#39;I\u0026#39;, }; 接下来讨论如何裁剪，裁剪有两种办法，第一种是在dump完成后的hprof文件基础上裁剪，性能比较差，对磁盘空间要求也比较高，第二种是在dump的过程中实时裁剪，我们自然想要实现第二种。看一下Record写入的过程，先执行StartNewRecord，然后通过AddU1/U4/U8写入内存buffer，最后执行EndRecord将buffer写入文件。\nvoid StartNewRecord(uint8_t tag, uint32_t time) { if (length_ \u0026gt; 0) { EndRecord(); } DCHECK_EQ(length_, 0U); AddU1(tag); AddU4(time); AddU4(0xdeaddead); // Length, replaced on flush.  started_ = true; } void EndRecord() { // Replace length in header.  if (started_) { UpdateU4(sizeof(uint8_t) + sizeof(uint32_t), length_ - sizeof(uint8_t) - 2 * sizeof(uint32_t)); } HandleEndRecord(); sum_length_ += length_; max_length_ = std::max(max_length_, length_); length_ = 0; started_ = false; } void HandleFlush(const uint8_t* buffer, size_t length) override { if (!errors_) { errors_ = !fp_-\u0026gt;WriteFully(buffer, length); } } 这个过程中有两个hook点可以选择，一是hook AddUx，在写入buffer的过程中裁剪，二是hook write，在写入文件过程中裁剪。最终我们选择了方案二，理由是AddUx调用比较频繁，判断逻辑复杂容易出现兼容性问题，而write是public API，且只在Record写入文件的时候调用一次，厂商不会魔改相关实现，从hook原理上来讲，hook外部调用的PLT/GOT hook也比hook内部调用的inline hook要稳定得多。\n用一张图总结裁剪的流程：\n图14\n解决hprof解析的耗时与OOM 解析hprof文件，对关键对象进行可达性分析，得到引用链，是我们解决OOM最核心的一步，之前的监控和dump都是为解析做铺垫。解析分两种，一种是上传hprof文件由server解析，另一种是在客户端解析后上传报告(通常只有几KB)。最终我们选择了端上解析，这样做有两个好处：\n 节省用户流量 利用用户闲时算力，降低server压力，这样也符合分布式计算理念。  照例，我们依然将问题拆解：\n 哪些对象需要分析，全部分析性能开销太大，很难在端上完成，并且问题没有重点也不利于解决。 性能优化，作为一个debug组件，要在不影响用户体验的情况下完成解析，对性能有非常高的要求。  关键对象判定 回顾前文，我们只解析关键对象的引用链，并写入分析报告中上传，判定的准确性和覆盖度决定了分析的质量。\n我们将关键对象分为两类，一类是根据规则可以判断出对象已经泄露，且持有大量资源的，另外一类是对象shallow / retained size 超过阈值。\nActivity/fragment泄露判定即为第一种: 对于强可达的activity对象，其mDestroyed值为true时(onDestroy时赋值)，判定已经泄露。类似的，对于fragment，当mCalled值为true且mFragmentManager为null时，判定已经泄露 。 我们可以用同样的思路合理制定规则，来处理我们核心的业务组件，比如无处不在的presenter。\nBitmap/window/array/sufacetexture判定为第二种 检查bitmap/texture的数量、宽高、window数量、array长度等等是否超过阈值，再结合hprof中的相关业务信息，比如屏幕大小，view大小等进行判定。\n性能优化 一开始我们尝试了LeakCanary的解析引擎HAHA(Android Studio解析引擎perlib的Android移植版)，解析过程中非常容易OOM，且解析速度极慢，500M的hprof文件，内存峰值达到2G，绝大多数Andriod设备的Java堆内存上限只有512M，即使顶配的macbook解析耗时都在3分钟以上，如此性能，在端上解析成功率低到发指。一度使我们想放弃现有的轮子，用C重写解析库，恰好此时LeakCanary发布了新的解析引擎shark[4]，号称内存峰值可以降低10倍，解析速度可以提升6倍。我们实验了一下，发现小的demo hprof基本能达到其宣称的性能，线上真实环境拿到的包含百万级对象hprof文件，性能会急剧下降，分析时间突破10分钟。因此，我们需要进一步优化，优化之前，先来研究一下HAHA和shark的原理。\n为什么HAHA内存峰值高，速度慢呢，概括起来主要是以下几点：\n 没做懒加载，hprof内容全部load到内存里。 domanitor tree[5]全量计算，实际上我们只关心关键对象的retained size。 频繁触发GC，java的集合类没有针对计算密集型任务做优化，含有大量冗余的装箱、拆箱、扩容、拷贝等操作，大量创建对象，频繁触发GC，GC反过来进一步降低对象分配速度，陷入恶性循环。  Shark是如何优化的呢？ Shark是LeakCanary 2.0推出的全新解析组件，其设计思想详见作者的介绍[6]，主要做了以下几项优化：\n 索引，shark低内存开销的最根本原因就是通过索引做到了内存懒加载，遍历hprof时存储对象在hprof中的位置，并为其建立索引方便按需解析。 数据结构上做了深度优化，主要是使用了更高效的map，有2个：第一是对于key和value都是基础类型或字符串的使用hppc做map，第二是对于value不是基本类型的，使用SortedBytesMap存储内容。  具体的索引有：实例索引、类索引、字符串索引、类名索引、数组索引：\n/** * This class is not thread safe, should be used from a single thread. */ internal class HprofInMemoryIndex private constructor( private val positionSize: Int, private val hprofStringCache: LongObjectScatterMap\u0026lt;String\u0026gt;, private val classNames: LongLongScatterMap, private val classIndex: SortedBytesMap, private val instanceIndex: SortedBytesMap, private val objectArrayIndex: SortedBytesMap, private val primitiveArrayIndex: SortedBytesMap, private val gcRoots: List\u0026lt;GcRoot\u0026gt;, private val proguardMapping: ProguardMapping?, val primitiveWrapperTypes: Set\u0026lt;Long\u0026gt; ) { /** * Code from com.carrotsearch.hppc.LongLongScatterMap copy pasted, inlined and converted to Kotlin. * * See https://github.com/carrotsearch/hppc . */ class LongLongScatterMap constructor(expectedElements: Int = 4) { /** * A read only map of `id` =\u0026gt; `byte array` sorted by id, where `id` is a long if [longIdentifiers] * is true and an int otherwise. Each entry has a value byte array of size [bytesPerValue]. * * Instances are created by [UnsortedByteEntries] * * [get] and [contains] perform a binary search to locate a specific entry by key. */ internal class SortedBytesMap( private val longIdentifiers: Boolean, private val bytesPerValue: Int, private val sortedEntries: ByteArray ) { 复制代码 所谓hppc是High Performance Primitive Collection[7]的缩写，shark使用kotlin将其重写了。hppc只支持基本类型，所以没有了装、拆箱的性能损耗，相关集合操作也做了大量优化，其benchmark可以参考[8]。\n再来看一下一个普通的对象在虚拟机中的内存开销有多大（ps:这还只是截图了一部分，一个int4个字节，1个long8个字节）：\n图15\n前文提到，基于shark在解析大hprof时，性能依然不够理想，需要做进一步的优化。 先来分析一下shark的使用场景和我们解析需求的差异：\n LeakCanary中shark只用于解析单一泄漏对象的引用链，而我们要分析大量对象的引用链。 Shark对于结果的要求非常精准，而我们是线上大数据分析，允许丢弃个别对象的引用链。 Shark对于镜像中的对象所有字段都进行解析，用于查询字段的值，而我们并不关心基础类型的值。  经过一番探索与实践，中途还去研究了MAT的源码，我们对其主要做了以下几点优化：\n GC root剪枝，由于我们搜索Path to GC Root时，是从GC Root自顶向下BFS，如JavaFrame、MonitorUsed等此类GC Root可以直接剪枝。 基本类型、基本类型数组不搜索、不解析。 同类对象超过阈值时不再搜索。 增加预处理，缓存每个类的所有递归super class，减少重复计算。 将object ID的类型从long修改为int，Android虚拟机的object ID大小只有32位，目前shark里使用的都是long来存储的，OOM时百万级对象的情况下，可以节省10M内存。  另外，还有几项实验中的调优项：\n 将shark改用c++重写，从GC日志来看，大hprof解析时，GC还是十分频繁的，改用c++会降低这部分开销。 扩大okio segment池的大小，空间换时间，用更多的内存、来提升高频访问解析对象的性能。  经过以上优化，将解析时间在shark的基础上优化了2倍以上，内存峰值控制在100M以内。 用一张图总结解析的流程：\n图16\n分发与跟进 解析结果上传到server以后，还要做反混淆，聚类等工作。通过关键对象以及引用链，将问题聚合后自动分发给研发同学，分发的原则是引用链中最近提交代码的owner。图17\u0026amp;18摘录了跟进系统的关键信息:\n图17\n图18\n参考 https://github.com/KwaiAppTeam/KOOM\n快手客户端稳定性体系建设_查看Android部分\n抖音 Android 性能优化系列：Java 内存优化篇\n西瓜视频稳定性治理体系建设一：Tailor 原理及实践\n//Matrix ResourceCanary没有解决dump hprof慢的问题，无法在线上使用\nhttps://github.com/Tencent/matrix/wiki/Matrix-Android-ResourceCanary\nProbe：Android线上OOM问题定位组件\nhttps://www.eclipse.org/mat/\nhttps://git.eclipse.org/c/mat/org.eclipse.mat.git\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%93%8D%E5%BA%94%E5%BC%8F%E6%9E%B6%E6%9E%84/2provider/",
	"title": "2Provider",
	"tags": [],
	"description": "",
	"content": "总结 监听者_DefaultInheritedProviderScopeElement监听到回调通知后通过markNeedsBuild()进行rebuild,而Consumer会通过Provider.of获取到最新的model值\ngraph LR ChangeNotifierProvider(\u0026quot;ChangeNotifierProvider_T extends ChangeNotifier_\u0026quot;)--\u0026gt;|1:ListensTo|ChangeNotifier ChangeNotifier--\u0026gt;|2:notifyListeners|ChangeNotifierProvider--\u0026gt;|3:rebuildsAndNotifyDependentsDescendants|Consumer 类设计 在_InheritedProviderScopeMixin被unmount时，会通知ChangeNotifier进行dispose，可以用来进行结构化并发，取消异步数据请求。\nChangeNotifier Usage class Counter with ChangeNotifier { int value = 0; void increment() { value += 1; notifyListeners(); } } /// A class that can be extended or mixed in that provides a change notification /// API using [VoidCallback] for notifications. /// /// See also: /// /// * [ValueNotifier], which is a [ChangeNotifier] that wraps a single value. class ChangeNotifier implements Listenable { LinkedList\u0026lt;_ListenerEntry\u0026gt;? _listeners = LinkedList\u0026lt;_ListenerEntry\u0026gt;(); /// Register a closure to be called when the object changes.  ///  /// This method must not be called after [dispose] has been called.  @override void addListener(VoidCallback listener) { assert(_debugAssertNotDisposed()); _listeners.add(listener); } /// Remove a previously registered closure from the list of closures that are  /// notified when the object changes.  ///  /// If the given listener is not registered, the call is ignored.  ///  /// This method must not be called after [dispose] has been called.  @override void removeListener(VoidCallback listener) { assert(_debugAssertNotDisposed()); _listeners.remove(listener); } /// Discards any resources used by the object. After this is called, the  /// object is not in a usable state and should be discarded (calls to  /// [addListener] and [removeListener] will throw after the object is  /// disposed).  ///  /// This method should only be called by the object\u0026#39;s owner.  @mustCallSuper void dispose() { assert(_debugAssertNotDisposed()); _listeners = null; } } notifyListeners @protected @visibleForTesting void notifyListeners() { assert(_debugAssertNotDisposed()); if (_listeners != null) { final List\u0026lt;VoidCallback\u0026gt; localListeners = List\u0026lt;VoidCallback\u0026gt;.from(_listeners); for (VoidCallback listener in localListeners) { if (_listeners.contains(listener)) listener(); ChangeNotifierProvider Usage void main() { runApp( // Provide the model to all widgets within the app. We\u0026#39;re using  // ChangeNotifierProvider because that\u0026#39;s a simple way to rebuild  // widgets when a model changes. We could also just use  // Provider, but then we would have to listen to Counter ourselves.  //  // Read Provider\u0026#39;s docs to learn about all the available providers.  ChangeNotifierProvider( // Initialize the model in the builder. That way, Provider  // can own Counter\u0026#39;s lifecycle, making sure to call `dispose`  // when not needed anymore.  create: (context) =\u0026gt; Counter(), child: MyApp(), ), ); } /// Listens to a [ChangeNotifier], expose it to its descendants and rebuilds /// dependents whenever [ChangeNotifier.notifyListeners] is called. /// /// Depending on wether you want to **create** or **reuse** a [ChangeNotifier], /// you will want to use different constructors. ChangeNotifierProvider\u0026lt;T extends ChangeNotifier\u0026gt; extends ListenableProvider\u0026lt;T\u0026gt; { /// Creates a [ChangeNotifier] using `create` and automatically  /// dispose it when [ChangeNotifierProvider] is removed from the widget tree.  ///  /// `create` must not be `null`.  ChangeNotifierProvider({ Key key, @required Create\u0026lt;T\u0026gt; create, bool lazy, Widget child, }) : super( key: key, create: create, dispose: _dispose, lazy: lazy, child: child, ); } InheritedProvider.buildWithChild /// A generic implementation of an [InheritedWidget].通过buildWithChild返回的Widget:_DefaultInheritedProviderScope实现InheritedWidget  /// Any descendant of this widget can obtain `value` using [Provider.of].  InheritedProvider\u0026lt;T\u0026gt; { /// Creates a value, then expose it to its descendants.  ///  /// The value will be disposed of when [InheritedProvider] is removed from  /// the widget tree.  InheritedProvider({ Key key, Create\u0026lt;T\u0026gt; create, T update(BuildContext context, T value), UpdateShouldNotify\u0026lt;T\u0026gt; updateShouldNotify, void Function(T value) debugCheckInvalidValueType, StartListening\u0026lt;T\u0026gt; startListening, Dispose\u0026lt;T\u0026gt; dispose, bool lazy, Widget child, }) : _lazy = lazy, _delegate = _CreateInheritedProvider(//main  create: create,//main  update: update,//main  updateShouldNotify: updateShouldNotify, debugCheckInvalidValueType: debugCheckInvalidValueType, startListening: startListening, dispose: dispose,//main  ), super(key: key, child: child); } @override Widget buildWithChild(BuildContext context, Widget child) { return _DefaultInheritedProviderScope\u0026lt;T\u0026gt;(//main  owner: this, child: child, ); } _DefaultInheritedProviderScope.createElement _DefaultInheritedProviderScope\u0026lt;T\u0026gt; extends InheritedWidget { final InheritedProvider\u0026lt;T\u0026gt; owner; @override _DefaultInheritedProviderScopeElement\u0026lt;T\u0026gt; createElement() { return _DefaultInheritedProviderScopeElement\u0026lt;T\u0026gt;(this); } } _DefaultInheritedProviderScopeElement.performRebuild _DefaultInheritedProviderScopeElement\u0026lt;T\u0026gt; extends InheritedElement with _InheritedProviderScopeMixin\u0026lt;T\u0026gt; { } @override void performRebuild() { if (_firstBuild) { _firstBuild = false; _mountDelegate(); } super.performRebuild(); } _mountDelegate @override void _mountDelegate() { _delegateState = widget.owner._delegate.createState()..element = this; } _CreateInheritedProvider.createState _CreateInheritedProvider\u0026lt;T\u0026gt; { @override _CreateInheritedProviderState\u0026lt;T\u0026gt; createState() =\u0026gt; _CreateInheritedProviderState(); } build @override Widget build() { if (_isLazy(widget) == false) { value; // this will force the value to be computed. main  } _delegateState.build(_isBuildFromExternalSources); _isBuildFromExternalSources = false; if (_shouldNotifyDependents) { _shouldNotifyDependents = false; notifyClients(widget);//main  } return super.build(); } value @override T get value =\u0026gt; _delegateState.value; @override T get value { if (!_didInitValue) { _didInitValue = true; if (delegate.create != null) { _value = delegate.create(element);//main  } if (delegate.update != null) { _value = delegate.update(element, _value);//main  } } element._isNotifyDependentsEnabled = false; _removeListener ??= delegate.startListening?.call(element, _value);//main  element._isNotifyDependentsEnabled = true; return _value; D get delegate =\u0026gt; element._widgetToDelegate(element.widget) as D; @override _Delegate\u0026lt;T\u0026gt; _widgetToDelegate(_DefaultInheritedProviderScope\u0026lt;T\u0026gt; widget) { return widget.owner._delegate; } create T instance extends ChangeNotifier startListening static VoidCallback _startListening( InheritedContext\u0026lt;Listenable\u0026gt; e, Listenable value, ) { value?.addListener(e.markNeedsNotifyDependents);//监听者_DefaultInheritedProviderScopeElement监听到回调通知后通过markNeedsBuild()进行rebuild,而Consumer会通过Provider.of获取到最新的model值  return () =\u0026gt; value?.removeListener(e.markNeedsNotifyDependents); } e.markNeedsNotifyDependents @override void markNeedsNotifyDependents() { if (!_isNotifyDependentsEnabled) return; markNeedsBuild();//main,performBuild--\u0026gt;updateChild--\u0026gt;update--\u0026gt;notifyClients逐个notify dependent  _shouldNotifyDependents = true; } Consumer Usage class MyHomePage extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(\u0026#39;Flutter Demo Home Page\u0026#39;), ), body: Center( child: Column( mainAxisAlignment: MainAxisAlignment.center, children: \u0026lt;Widget\u0026gt;[ Text(\u0026#39;You have pushed the button this many times:\u0026#39;), // Consumer looks for an ancestor Provider widget  // and retrieves its model (Counter, in this case).  // Then it uses that model to build widgets, and will trigger  // rebuilds if the model is updated.  Consumer\u0026lt;Counter\u0026gt;(//main  builder: (context, counter, child) =\u0026gt; Text( \u0026#39;${counter.value}\u0026#39;, style: Theme.of(context).textTheme.headline4, ), ), ], ), ), //仅仅相当于Provider.of的封装，默认监听并会触发rebuild Consumer\u0026lt;T\u0026gt; extends SingleChildStatelessWidget { Consumer({ Key key, @required this.builder, Widget child, }) : assert(builder != null), super(key: key, child: child); } /// Build a widget tree based on the value from a [Provider\u0026lt;T\u0026gt;]. final Widget Function(BuildContext context, T value, Widget child) builder; @override Widget buildWithChild(BuildContext context, Widget child) { return builder( context, Provider.of\u0026lt;T\u0026gt;(context), child, ); } Provider.of static T of\u0026lt;T\u0026gt;(BuildContext context, {bool listen = true}) { InheritedContext\u0026lt;T\u0026gt; inheritedElement; if (context.widget is _DefaultInheritedProviderScope\u0026lt;T\u0026gt;) { // An InheritedProvider\u0026lt;T\u0026gt;\u0026#39;s update tries to obtain a parent provider of the same type.  context.visitAncestorElements((parent) { inheritedElement = parent.getElementForInheritedWidgetOfExactType\u0026lt;_DefaultInheritedProviderScope\u0026lt;T\u0026gt;\u0026gt;() as _DefaultInheritedProviderScopeElement\u0026lt;T\u0026gt;; return false; }); } else { inheritedElement = context.getElementForInheritedWidgetOfExactType\u0026lt;_DefaultInheritedProviderScope\u0026lt;T\u0026gt;\u0026gt;() as _DefaultInheritedProviderScopeElement\u0026lt;T\u0026gt;; } if (inheritedElement == null) { throw ProviderNotFoundException(T, context.widget.runtimeType); } if (listen) {//main  context.dependOnInheritedElement(inheritedElement as InheritedElement); } return inheritedElement.value; "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/1startup/2startup_embedder_framwwork/",
	"title": "2startup_embedder_framwwork",
	"tags": [],
	"description": "",
	"content": "graph LR FlutterView--\u0026gt;|对应|DartVM--\u0026gt;|对应|Engine attachToFlutterEngine图解 分别由FlutterRenderer控制渲染flutter UI到platform侧的FlutterView，由AndroidTouchProcessor控制platform侧的FlutterView的touchEvent到flutter\ngraph LR FlutterView--\u0026gt;|attachToFlutterEngine|FlutterEngine FlutterView--\u0026gt;|interaction events to|FlutterEngine FlutterEngine--\u0026gt;|renderTo|FlutterView FlutterEngine--\u0026gt;FlutterRenderer--\u0026gt;|notify|FlutterJNI RenderSurface--\u0026gt;|nofity surface event|FlutterRenderer FlutterView--\u0026gt;|contains|RenderSurface FlutterEngine--\u0026gt;|contains|PlatformViewsController--\u0026gt;|contains|AndroidTouchProcessor--\u0026gt;|sendTouchEvent|Flutter 下述为flutter1.12版本时的源码研究，新版2.0设计上已经进行优化见上面的图解\n1.12时在new FlutterView时进行Engine和DartVM的构造和初始化，而在2.0上功能分离到FlutterEngine这个java class中\nFlutterApplication.onCreate /** * Flutter implementation of {@link android.app.Application}, managing * application-level global initializations. */ //FlutterApplication @CallSuper public void onCreate() { super.onCreate(); FlutterMain.startInitialization(this); } /** FlutterMain * Starts initialization of the native system. * @param applicationContext The Android application context. */ public static void startInitialization(@NonNull Context applicationContext) { if (isRunningInRobolectricTest) { return; } FlutterLoader.getInstance().startInitialization(applicationContext); } FlutterLoader.startInitialization() /** Finds Flutter resources in an application APK and also loads Flutter\u0026#39;s native library.*/ //FlutterLoader  /** * Starts initialization of the native system. * @param applicationContext The Android application context. */ public void startInitialization(@NonNull Context applicationContext) { startInitialization(applicationContext, new Settings()); } /**Starts initialization of the native system. * \u0026lt;p\u0026gt; * This loads the Flutter engine\u0026#39;s native library to enable subsequent JNI calls. This also starts locating and unpacking Dart resources packaged in the app\u0026#39;s APK. * \u0026lt;p\u0026gt;*/ public void startInitialization(@NonNull Context applicationContext, @NonNull Settings settings) { if (Looper.myLooper() != Looper.getMainLooper()) { throw new IllegalStateException(\u0026#34;startInitialization must be called on the main thread\u0026#34;); } initConfig(applicationContext); initResources(applicationContext); System.loadLibrary(\u0026#34;flutter\u0026#34;);//flutter so源码位于engine\\shell\\platform\\android下的BUILD.gn配置  VsyncWaiter .getInstance((WindowManager) applicationContext.getSystemService(Context.WINDOW_SERVICE)) .init(); long initTimeMillis = SystemClock.uptimeMillis() - initStartTimestampMillis; FlutterJNI.nativeRecordStartTimestamp(initTimeMillis); } System.loadLibrary(\u0026ldquo;flutter\u0026rdquo;) //engine/shell/platform/android/library_loader.cc  // This is called by the VM when the shared library is first loaded. // flutter so的初始化 JNIEXPORT jint JNI_OnLoad(JavaVM* vm, void* reserved) { // Initialize the Java VM. //Android进程在由zygote fork过程中已创建了JavaVM，每一个进程对应一个JavaVM。在这里只是将当前进程的JavaVM实例保存在静态变量，再将当前线程和JavaVM建立关联，获取JNIEnv实例，每个线程对应一个JNIEnv实例  fml::jni::InitJavaVM(vm); JNIEnv* env = fml::jni::AttachCurrentThread(); bool result = false; //注册c和java层双向调用的函数信息  // Register FlutterMain.  result = flutter::FlutterMain::Register(env); // Register PlatformView  result = flutter::PlatformViewAndroid::Register(env); // Register VSyncWaiter.  result = flutter::VsyncWaiterAndroid::Register(env); return JNI_VERSION_1_4; } //engine/shell/platform/android/flutter_main.cc bool FlutterMain::Register(JNIEnv* env) { static const JNINativeMethod methods[] = { { .name = \u0026#34;nativeInit\u0026#34;, .signature = \u0026#34;(Landroid/content/Context;[Ljava/lang/String;Ljava/\u0026#34; \u0026#34;lang/String;Ljava/lang/String;Ljava/lang/String;)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;Init), }, { .name = \u0026#34;nativeRecordStartTimestamp\u0026#34;, .signature = \u0026#34;(J)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;RecordStartTimestamp), }, }; jclass clazz = env-\u0026gt;FindClass(\u0026#34;io/flutter/embedding/engine/FlutterJNI\u0026#34;); return env-\u0026gt;RegisterNatives(clazz, methods, fml::size(methods)) == 0; } VsyncWaiter.init //VsyncWaiter  private VsyncWaiter(@NonNull WindowManager windowManager) { this.windowManager = windowManager; } private final FlutterJNI.AsyncWaitForVsyncDelegate asyncWaitForVsyncDelegate = new FlutterJNI.AsyncWaitForVsyncDelegate() { @Override public void asyncWaitForVsync(long cookie) { Choreographer.getInstance().postFrameCallback(new Choreographer.FrameCallback() { @Override public void doFrame(long frameTimeNanos) { float fps = windowManager.getDefaultDisplay().getRefreshRate(); long refreshPeriodNanos = (long) (1000000000.0 / fps); FlutterJNI.nativeOnVsync(frameTimeNanos, frameTimeNanos + refreshPeriodNanos, cookie); } }); } }; public void init() { FlutterJNI.setAsyncWaitForVsyncDelegate(asyncWaitForVsyncDelegate); // TODO(mattcarroll): look into moving FPS reporting to a plugin  float fps = windowManager.getDefaultDisplay().getRefreshRate(); FlutterJNI.setRefreshRateFPS(fps); } //FlutterJNI  public static void setAsyncWaitForVsyncDelegate(@Nullable AsyncWaitForVsyncDelegate delegate) { asyncWaitForVsyncDelegate = delegate; } // Called by native.  private static void asyncWaitForVsync(final long cookie) { if (asyncWaitForVsyncDelegate != null) { asyncWaitForVsyncDelegate.asyncWaitForVsync(cookie); } else { throw new IllegalStateException(\u0026#34;An AsyncWaitForVsyncDelegate must be registered with FlutterJNI before asyncWaitForVsync() is invoked.\u0026#34;); } } public static native void nativeOnVsync(long frameTimeNanos, long frameTargetTimeNanos, long cookie); public static void setRefreshRateFPS(float refreshRateFPS) { FlutterJNI.refreshRateFPS = refreshRateFPS; } public static native void nativeRecordStartTimestamp(long initTimeMillis); FlutterActivity.onCreate FlutterActivity extends Activity implements FlutterView.Provider, PluginRegistry, ViewFactory { private final FlutterActivityDelegate delegate = new FlutterActivityDelegate(this, this); // These aliases ensure that the methods we forward to the delegate adhere  // to relevant interfaces versus just existing in FlutterActivityDelegate.  private final FlutterActivityEvents eventDelegate = delegate; private final FlutterView.Provider viewProvider = delegate; private final PluginRegistry pluginRegistry = delegate; public FlutterActivity() { this.eventDelegate = this.delegate; this.viewProvider = this.delegate; this.pluginRegistry = this.delegate; } /** * Returns the Flutter view used by this activity; will be null before * {@link #onCreate(Bundle)} is called. */ public FlutterView getFlutterView() { return this.viewProvider.getFlutterView();} } protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); this.eventDelegate.onCreate(savedInstanceState); } public final class FlutterActivityDelegate implements FlutterActivityEvents, FlutterView.Provider,PluginRegistry { private FlutterView flutterView; private final Activity activity; public FlutterActivityDelegate(Activity activity, FlutterActivityDelegate.ViewFactory viewFactory) { this.activity = (Activity)Preconditions.checkNotNull(activity); this.viewFactory = (FlutterActivityDelegate.ViewFactory)Preconditions.checkNotNull(viewFactory); } public FlutterView getFlutterView() { return this.flutterView; } // The implementation of PluginRegistry forwards to flutterView.  @Override public boolean hasPlugin(String key) { return flutterView.getPluginRegistry().hasPlugin(key); } @Override public Registrar registrarFor(String pluginKey) { return flutterView.getPluginRegistry().registrarFor(pluginKey); } } public void onCreate(Bundle savedInstanceState) { FlutterMain.ensureInitializationComplete(this.activity.getApplicationContext(), args); this.flutterView = this.viewFactory.createFlutterView(this.activity); if (this.flutterView == null) { FlutterNativeView nativeView = this.viewFactory.createFlutterNativeView(); this.flutterView = new FlutterView(this.activity, (AttributeSet)null, nativeView); this.flutterView.setLayoutParams(matchParent); this.activity.setContentView(this.flutterView); } if (loadIntent(activity.getIntent())) { return; } String appBundlePath = FlutterMain.findAppBundlePath(); if (appBundlePath != null) { runBundle(appBundlePath); } FlutterLoader.ensureInitializationComplete /** FlutterMain * Blocks until initialization of the native system has completed. * \u0026lt;p\u0026gt; * Calling this method multiple times has no effect.*/ public static void ensureInitializationComplete(@NonNull Context applicationContext, @Nullable String[] args) { if (isRunningInRobolectricTest) { return; } FlutterLoader.getInstance().ensureInitializationComplete(applicationContext, args); } /** FlutterLoader * Blocks until initialization of the native system has completed. */ public void ensureInitializationComplete(@NonNull Context applicationContext, @Nullable String[] args) { FlutterJNI.nativeInit(applicationContext, shellArgs.toArray(new String[0]), kernelPath, appStoragePath, engineCachesPath); public static native void nativeInit() new FlutterView //FlutterView extends SurfaceView public FlutterView(Context context, AttributeSet attrs, FlutterNativeView nativeView) { if (nativeView == null) { this.mNativeView = new FlutterNativeView(activity.getApplicationContext());//main  } else { this.mNativeView = nativeView; } this.mNativeView.attachViewAndActivity(this, activity); this.mSurfaceCallback = new Callback() { public void surfaceCreated(SurfaceHolder holder) { FlutterView.this.assertAttached(); FlutterView.this.mNativeView.getFlutterJNI().onSurfaceCreated(holder.getSurface());//main  } public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) { FlutterView.this.assertAttached(); FlutterView.this.mNativeView.getFlutterJNI().onSurfaceChanged(width, height); } public void surfaceDestroyed(SurfaceHolder holder) { FlutterView.this.assertAttached(); FlutterView.this.mNativeView.getFlutterJNI().onSurfaceDestroyed(); } }; this.getHolder().addCallback(this.mSurfaceCallback); this.navigationChannel = new NavigationChannel(this.dartExecutor); this.keyEventChannel = new KeyEventChannel(this.dartExecutor); this.lifecycleChannel = new LifecycleChannel(this.dartExecutor); this.localizationChannel = new LocalizationChannel(this.dartExecutor); this.platformChannel = new PlatformChannel(this.dartExecutor); this.systemChannel = new SystemChannel(this.dartExecutor); this.settingsChannel = new SettingsChannel(this.dartExecutor); public FlutterNativeView(@NonNull Context context, boolean isBackgroundView) { mContext = context; mPluginRegistry = new FlutterPluginRegistry(this, context); mFlutterJNI = new FlutterJNI(); mFlutterJNI.addIsDisplayingFlutterUiListener(flutterUiDisplayListener); this.dartExecutor = new DartExecutor(mFlutterJNI, context.getAssets()); mFlutterJNI.addEngineLifecycleListener(new EngineLifecycleListenerImpl()); attach(this, isBackgroundView); assertAttached(); } private void attach(FlutterNativeView view, boolean isBackgroundView) { mFlutterJNI.attachToNative(isBackgroundView); dartExecutor.onAttachedToJNI(); } attachToNative /** * Attaches this {@code FlutterJNI} instance to Flutter\u0026#39;s native engine, which allows * for communication between Android code and Flutter\u0026#39;s platform agnostic engine. * \u0026lt;p\u0026gt; * This method must not be invoked if {@code FlutterJNI} is already attached to native. */ @UiThread public void attachToNative(boolean isBackgroundView) { ensureRunningOnMainThread(); ensureNotAttachedToNative(); nativePlatformViewId = nativeAttach(this, isBackgroundView); } private void ensureNotAttachedToNative() { if (nativePlatformViewId != null) { throw new RuntimeException(\u0026#34;Cannot execute operation because FlutterJNI is attached to native.\u0026#34;); }} } private native long nativeAttach(@NonNull FlutterJNI flutterJNI, boolean isBackgroundView); //engine/shell/platform/android/platform_view_android_jni.cc bool RegisterApi(JNIEnv* env) { static const JNINativeMethod flutter_jni_methods[] = { // Start of methods from FlutterJNI  { .name = \u0026#34;nativeAttach\u0026#34;, .signature = \u0026#34;(Lio/flutter/embedding/engine/FlutterJNI;Z)J\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;AttachJNI), }, { .name = \u0026#34;nativeRunBundleAndSnapshotFromLibrary\u0026#34;, .signature = \u0026#34;(JLjava/lang/String;Ljava/lang/String;\u0026#34; \u0026#34;Ljava/lang/String;Landroid/content/res/AssetManager;)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;RunBundleAndSnapshotFromLibrary), }, } // Called By Java static jlong AttachJNI(JNIEnv* env, jclass clazz, jobject flutterJNI, jboolean is_background_view) { fml::jni::JavaObjectWeakGlobalRef java_object(env, flutterJNI); auto shell_holder = std::make_unique\u0026lt;AndroidShellHolder\u0026gt;( FlutterMain::Get().GetSettings(), java_object, is_background_view); if (shell_holder-\u0026gt;IsValid()) { return reinterpret_cast\u0026lt;jlong\u0026gt;(shell_holder.release()); } else { return 0; } } AndroidShellHolder::AndroidShellHolder //engine/shell/platform/android/android_shell_holder  ThreadHost thread_host_; fml::WeakPtr\u0026lt;PlatformViewAndroid\u0026gt; platform_view_; std::unique_ptr\u0026lt;Shell\u0026gt; shell_; AndroidShellHolder::AndroidShellHolder( flutter::Settings settings, fml::jni::JavaObjectWeakGlobalRef java_object, bool is_background_view) : settings_(std::move(settings)), java_object_(java_object) { if (is_background_view) { thread_host_ = {thread_label, ThreadHost::Type::UI}; } else { thread_host_ = {thread_label, ThreadHost::Type::UI | ThreadHost::Type::GPU | ThreadHost::Type::IO};//main  } fml::WeakPtr\u0026lt;PlatformViewAndroid\u0026gt; weak_platform_view; Shell::CreateCallback\u0026lt;PlatformView\u0026gt; on_create_platform_view = //main  [is_background_view, java_object, \u0026amp;weak_platform_view](Shell\u0026amp; shell) { std::unique_ptr\u0026lt;PlatformViewAndroid\u0026gt; platform_view_android; platform_view_android = std::make_unique\u0026lt;PlatformViewAndroid\u0026gt;( shell, // delegate  shell.GetTaskRunners(), // task runners  java_object, // java object handle for JNI interop  shell.GetSettings() .enable_software_rendering // use software rendering  ); weak_platform_view = platform_view_android-\u0026gt;GetWeakPtr(); return platform_view_android; }; Shell::CreateCallback\u0026lt;Rasterizer\u0026gt; on_create_rasterizer = [](Shell\u0026amp; shell) {//main  return std::make_unique\u0026lt;Rasterizer\u0026gt;(shell, shell.GetTaskRunners()); }; // The current thread will be used as the platform thread. Ensure that the  // message loop is initialized.  fml::MessageLoop::EnsureInitializedForCurrentThread(); fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; platform_runner = fml::MessageLoop::GetCurrent().GetTaskRunner(); gpu_runner = thread_host_.gpu_thread-\u0026gt;GetTaskRunner(); ui_runner = thread_host_.ui_thread-\u0026gt;GetTaskRunner(); io_runner = thread_host_.io_thread-\u0026gt;GetTaskRunner(); //main  flutter::TaskRunners task_runners(thread_label, // label  platform_runner, // platform  gpu_runner, // gpu  ui_runner, // ui  io_runner // io  ); //main  shell_ = Shell::Create(task_runners, // task runners  GetDefaultWindowData(), // window data  settings_, // settings  on_create_platform_view, // platform view create callback  on_create_rasterizer // rasterizer create callback  ); platform_view_ = weak_platform_view; Shell::Create class Shell final : public PlatformView::Delegate, public Animator::Delegate, public Engine::Delegate, public Rasterizer::Delegate, public ServiceProtocol::Handler { template \u0026lt;class T\u0026gt; using CreateCallback = std::function\u0026lt;std::unique_ptr\u0026lt;T\u0026gt;(Shell\u0026amp;)\u0026gt;; std::unique_ptr\u0026lt;Shell\u0026gt; Shell::Create( TaskRunners task_runners, const WindowData window_data, Settings settings, Shell::CreateCallback\u0026lt;PlatformView\u0026gt; on_create_platform_view, Shell::CreateCallback\u0026lt;Rasterizer\u0026gt; on_create_rasterizer) { PerformInitializationTasks(settings); PersistentCache::SetCacheSkSL(settings.cache_sksl); auto vm = DartVMRef::Create(settings);//main  FML_CHECK(vm) \u0026lt;\u0026lt; \u0026#34;Must be able to initialize the VM.\u0026#34;; auto vm_data = vm-\u0026gt;GetVMData(); //main  return Shell::Create(std::move(task_runners), //  std::move(window_data), //  std::move(settings), //  vm_data-\u0026gt;GetIsolateSnapshot(), // isolate snapshot  on_create_platform_view, //  on_create_rasterizer, //  std::move(vm) //  ); dart_vm_lifecycle.cc\nDartVMRef::Create DartVMRef DartVMRef::Create(Settings settings, fml::RefPtr\u0026lt;DartSnapshot\u0026gt; vm_snapshot, fml::RefPtr\u0026lt;DartSnapshot\u0026gt; isolate_snapshot) { std::scoped_lock lifecycle_lock(gVMMutex); // If there is already a running VM in the process, grab a strong reference to it.  if (auto vm = gVM.lock()) { FML_DLOG(WARNING) \u0026lt;\u0026lt; \u0026#34;Attempted to create a VM in a process where one was \u0026#34; \u0026#34;already running. Ignoring arguments for current VM \u0026#34; \u0026#34;create call and reusing the old VM.\u0026#34;; // There was already a running VM in the process,  return DartVMRef{std::move(vm)}; } ...... // If there is no VM in the process. Initialize one, hold the weak reference  // and pass a strong reference to the caller.  auto isolate_name_server = std::make_shared\u0026lt;IsolateNameServer\u0026gt;(); auto vm = DartVM::Create(std::move(settings), //  std::move(vm_snapshot), //  std::move(isolate_snapshot), //  isolate_name_server //  ); gVMData = vm-\u0026gt;GetVMData(); gVMServiceProtocol = vm-\u0026gt;GetServiceProtocol(); gVMIsolateNameServer = isolate_name_server; gVM = vm; if (settings.leak_vm) { gVMLeak = new std::shared_ptr\u0026lt;DartVM\u0026gt;(vm); } return DartVMRef{std::move(vm)}; std::unique_ptr\u0026lt;Shell\u0026gt; Shell::Create( TaskRunners task_runners, const WindowData window_data, Settings settings, fml::RefPtr\u0026lt;const DartSnapshot\u0026gt; isolate_snapshot, const Shell::CreateCallback\u0026lt;PlatformView\u0026gt;\u0026amp; on_create_platform_view, const Shell::CreateCallback\u0026lt;Rasterizer\u0026gt;\u0026amp; on_create_rasterizer, DartVMRef vm) { PerformInitializationTasks(settings); PersistentCache::SetCacheSkSL(settings.cache_sksl); fml::AutoResetWaitableEvent latch; std::unique_ptr\u0026lt;Shell\u0026gt; shell; fml::TaskRunner::RunNowOrPostTask( task_runners.GetPlatformTaskRunner(),//main  fml::MakeCopyable([\u0026amp;latch, //  vm = std::move(vm), //  \u0026amp;shell, //  task_runners = std::move(task_runners), //  window_data, //  settings, //  isolate_snapshot = std::move(isolate_snapshot), //  on_create_platform_view, //  on_create_rasterizer //  ]() mutable { shell = CreateShellOnPlatformThread(std::move(vm), std::move(task_runners), //  window_data, //  settings, //  std::move(isolate_snapshot), //  on_create_platform_view, //  on_create_rasterizer //  ); latch.Signal(); })); latch.Wait(); return shell; std::unique_ptr\u0026lt;Shell\u0026gt; Shell::CreateShellOnPlatformThread( DartVMRef vm, TaskRunners task_runners, const WindowData window_data, Settings settings, fml::RefPtr\u0026lt;const DartSnapshot\u0026gt; isolate_snapshot, const Shell::CreateCallback\u0026lt;PlatformView\u0026gt;\u0026amp; on_create_platform_view, const Shell::CreateCallback\u0026lt;Rasterizer\u0026gt;\u0026amp; on_create_rasterizer) { auto shell = std::unique_ptr\u0026lt;Shell\u0026gt;(new Shell(std::move(vm), task_runners, settings)); // Create the rasterizer on the GPU thread. ...... // Create the platform view on the platform thread (this thread).  auto platform_view = on_create_platform_view(*shell.get()); // Ask the platform view for the vsync waiter. This will be used by the engine  // to create the animator.  auto vsync_waiter = platform_view-\u0026gt;CreateVSyncWaiter(); // Create the IO manager on the IO thread. The IO manager must be initialized  // first because it has state that the other subsystems depend on. It must  // first be booted and the necessary references obtained to initialize the  // other subsystems. ...... // Create the engine on the UI thread.  std::promise\u0026lt;std::unique_ptr\u0026lt;Engine\u0026gt;\u0026gt; engine_promise; auto engine_future = engine_promise.get_future(); fml::TaskRunner::RunNowOrPostTask( shell-\u0026gt;GetTaskRunners().GetUITaskRunner(),//main  fml::MakeCopyable([\u0026amp;engine_promise, //  shell = shell.get(), //  \u0026amp;dispatcher_maker, //  \u0026amp;window_data, //  isolate_snapshot = std::move(isolate_snapshot), //  vsync_waiter = std::move(vsync_waiter), //  \u0026amp;weak_io_manager_future, //  \u0026amp;snapshot_delegate_future, //  \u0026amp;unref_queue_future //  ]() mutable { TRACE_EVENT0(\u0026#34;flutter\u0026#34;, \u0026#34;ShellSetupUISubsystem\u0026#34;); const auto\u0026amp; task_runners = shell-\u0026gt;GetTaskRunners(); // The animator is owned by the UI thread but it gets its vsync pulses  // from the platform.  auto animator = std::make_unique\u0026lt;Animator\u0026gt;(*shell, task_runners, std::move(vsync_waiter)); engine_promise.set_value(std::make_unique\u0026lt;Engine\u0026gt;(//main  *shell, //  dispatcher_maker, //  *shell-\u0026gt;GetDartVM(), //  std::move(isolate_snapshot), //  task_runners, //  window_data, //  shell-\u0026gt;GetSettings(), //  std::move(animator), //  weak_io_manager_future.get(), //  unref_queue_future.get(), //  snapshot_delegate_future.get() //  )); })); if (!shell-\u0026gt;Setup(std::move(platform_view), //main  engine_future.get(), //  rasterizer_future.get(), //  io_manager_future.get()) //  ) { return nullptr; } return shell; Engine::Engine Engine::Engine(Delegate\u0026amp; delegate, const PointerDataDispatcherMaker\u0026amp; dispatcher_maker, DartVM\u0026amp; vm, fml::RefPtr\u0026lt;const DartSnapshot\u0026gt; isolate_snapshot, TaskRunners task_runners, const WindowData window_data, Settings settings, std::unique_ptr\u0026lt;Animator\u0026gt; animator, fml::WeakPtr\u0026lt;IOManager\u0026gt; io_manager, fml::RefPtr\u0026lt;SkiaUnrefQueue\u0026gt; unref_queue, fml::WeakPtr\u0026lt;SnapshotDelegate\u0026gt; snapshot_delegate) : delegate_(delegate), settings_(std::move(settings)), animator_(std::move(animator)), activity_running_(true), have_surface_(false), image_decoder_(task_runners, vm.GetConcurrentWorkerTaskRunner(), io_manager), task_runners_(std::move(task_runners)), weak_factory_(this) { // Runtime controller is initialized here because it takes a reference to this  // object as its delegate. The delegate may be called in the constructor and  // we want to be fully initilazed by that point.  runtime_controller_ = std::make_unique\u0026lt;RuntimeController\u0026gt;( ...... pointer_data_dispatcher_ = dispatcher_maker(*this); Shell::Shell(DartVMRef vm, TaskRunners task_runners, Settings settings) { // Install service protocol handlers. ...... bool Shell::Setup(std::unique_ptr\u0026lt;PlatformView\u0026gt; platform_view, std::unique_ptr\u0026lt;Engine\u0026gt; engine, std::unique_ptr\u0026lt;Rasterizer\u0026gt; rasterizer, std::unique_ptr\u0026lt;ShellIOManager\u0026gt; io_manager) { ...... } activity.setContentView(flutterView) \u0026hellip;\u0026hellip;\nrunBundle(appBundlePath) private void runBundle(String appBundlePath) { if (!flutterView.getFlutterNativeView().isApplicationRunning()) { FlutterRunArguments args = new FlutterRunArguments(); args.bundlePath = appBundlePath; args.entrypoint = \u0026#34;main\u0026#34;; flutterView.runFromBundle(args);//main  } } public void runFromBundle(FlutterRunArguments args) { assertAttached(); preRun(); mNativeView.runFromBundle(args);//main  postRun(); } public void runFromBundle(FlutterRunArguments args) { mFlutterJNI.runBundleAndSnapshotFromLibrary(//main  args.bundlePath, args.entrypoint, args.libraryPath, mContext.getResources().getAssets() ); applicationIsRunning = true; /** FlutterJNI * Executes a Dart entrypoint. * \u0026lt;p\u0026gt; * This can only be done once per JNI attachment because a Dart isolate can only be * entered once. */ @UiThread public void runBundleAndSnapshotFromLibrary( @NonNull String bundlePath, @Nullable String entrypointFunctionName, @Nullable String pathToEntrypointFunction, @NonNull AssetManager assetManager ) { ensureRunningOnMainThread(); ensureAttachedToNative(); nativeRunBundleAndSnapshotFromLibrary( nativePlatformViewId, bundlePath, entrypointFunctionName, pathToEntrypointFunction, assetManager ); } //engine/shell/platform/android/platform_view_android_jni.cc static void RunBundleAndSnapshotFromLibrary(JNIEnv* env, jobject jcaller, jlong shell_holder, jstring jBundlePath, jstring jEntrypoint, jstring jLibraryUrl, jobject jAssetManager) { auto asset_manager = std::make_shared\u0026lt;flutter::AssetManager\u0026gt;(); ...... RunConfiguration config(std::move(isolate_configuration), std::move(asset_manager)); { auto entrypoint = fml::jni::JavaStringToString(env, jEntrypoint); auto libraryUrl = fml::jni::JavaStringToString(env, jLibraryUrl); if ((entrypoint.size() \u0026gt; 0) \u0026amp;\u0026amp; (libraryUrl.size() \u0026gt; 0)) { config.SetEntrypointAndLibrary(std::move(entrypoint), std::move(libraryUrl)); } else if (entrypoint.size() \u0026gt; 0) { config.SetEntrypoint(std::move(entrypoint)); } } ANDROID_SHELL_HOLDER-\u0026gt;Launch(std::move(config));//main AndroidShellHolder::Launch //engine/shell/platform/android/android_shell_holder void AndroidShellHolder::Launch(RunConfiguration config) { if (!IsValid()) { return; } shell_-\u0026gt;RunEngine(std::move(config)); } Shell::RunEngine void Shell::RunEngine(RunConfiguration run_configuration) { RunEngine(std::move(run_configuration), nullptr); } void Shell::RunEngine( RunConfiguration run_configuration, const std::function\u0026lt;void(Engine::RunStatus)\u0026gt;\u0026amp; result_callback) { ...... fml::TaskRunner::RunNowOrPostTask( task_runners_.GetUITaskRunner(),//main  fml::MakeCopyable( [run_configuration = std::move(run_configuration), weak_engine = weak_engine_, result]() mutable { if (!weak_engine) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not launch engine with configuration - no engine.\u0026#34;; result(Engine::RunStatus::Failure); return; } auto run_result = weak_engine-\u0026gt;Run(std::move(run_configuration));//main  if (run_result == flutter::Engine::RunStatus::Failure) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not launch engine with configuration.\u0026#34;; } result(run_result); })); Engine::Run Engine::RunStatus Engine::Run(RunConfiguration configuration) { auto isolate_launch_status = PrepareAndLaunchIsolate(std::move(configuration)); Engine::RunStatus Engine::PrepareAndLaunchIsolate( RunConfiguration configuration) { if (configuration.GetEntrypointLibrary().empty()) { if (!isolate-\u0026gt;Run(configuration.GetEntrypoint(),//main  settings_.dart_entrypoint_args)) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not run the isolate.\u0026#34;; return RunStatus::Failure; } } DartIsolate::Run bool DartIsolate::Run(const std::string\u0026amp; entrypoint_name, const std::vector\u0026lt;std::string\u0026gt;\u0026amp; args, const fml::closure\u0026amp; on_run) { auto user_entrypoint_function = Dart_GetField(Dart_RootLibrary(), tonic::ToDart(entrypoint_name.c_str())); auto entrypoint_args = tonic::ToDart(args); if (!InvokeMainEntrypoint(user_entrypoint_function, entrypoint_args)) {//main  return false; } static bool InvokeMainEntrypoint(Dart_Handle user_entrypoint_function, Dart_Handle args) { Dart_Handle start_main_isolate_function = tonic::DartInvokeField(Dart_LookupLibrary(tonic::ToDart(\u0026#34;dart:isolate\u0026#34;)), \u0026#34;_getStartMainIsolateFunction\u0026#34;, {}); if (tonic::LogIfError(tonic::DartInvokeField( Dart_LookupLibrary(tonic::ToDart(\u0026#34;dart:ui\u0026#34;)), \u0026#34;_runMainZoned\u0026#34;, {start_main_isolate_function, user_entrypoint_function, args}))) {//main  FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Could not invoke the main entrypoint.\u0026#34;; return false; } return true; _runMainZoned //hooks.dart @pragma(\u0026#39;vm:entry-point\u0026#39;) // ignore: unused_element void _runMainZoned(Function startMainIsolateFunction,//main  Function userMainFunction,//main  List\u0026lt;String\u0026gt; args) { startMainIsolateFunction((){ runZoned\u0026lt;void\u0026gt;(() { if (userMainFunction is _BinaryFunction) { // This seems to be undocumented but supported by the command line VM.  // Let\u0026#39;s do the same in case old entry-points are ported to Flutter.  (userMainFunction as dynamic)(args, \u0026#39;\u0026#39;); } else if (userMainFunction is _UnaryFunction) { (userMainFunction as dynamic)(args); } else { userMainFunction(); } }, onError: (Object error, StackTrace stackTrace) { _reportUnhandledException(error.toString(), stackTrace.toString()); }); }, null); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/2%E7%B1%BB%E5%8A%A0%E8%BD%BD/",
	"title": "2类加载",
	"tags": [],
	"description": "",
	"content": "2类加载 探索总结2类加载知识\n Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/anr/3anranalysisrootcause/",
	"title": "3ANRAnalysisRootCause",
	"tags": [],
	"description": "",
	"content": "Anr信息解释 \u0026#34;Signal Catcher\u0026#34; daemon prio=5 tid=6 Runnable | group=\u0026#34;system\u0026#34; sCount=0 dsCount=0 flags=0 obj=0x15b802d8 self=0x756d5cc2e000 | sysTid=7781 nice=0 cgrp=default sched=0/0 handle=0x756d5c9ffd50 | state=R schedstat=( 9996973 11775302 9 ) utm=0 stm=0 core=3 HZ=100 | stack=0x756d5c909000-0x756d5c90b000 stackSize=991KB | held mutexes= \u0026#34;mutator lock\u0026#34;(shared held) native: #00 pc 000000000048df0e /apex/com.android.runtime/lib64/libart.so (art::DumpNativeStack(std::__1::basic_ostream\u0026lt;char, std::__1::char_traits\u0026lt;char\u0026gt;\u0026gt;\u0026amp;, int, BacktraceMap*, char const*, art::ArtMethod*, void*, bool)+126) native: #01 pc 00000000005a77b3 /apex/com.android.runtime/lib64/libart.so (art::Thread::DumpStack(std::__1::basic_ostream\u0026lt;char, std::__1::char_traits\u0026lt;char\u0026gt;\u0026gt;\u0026amp;, bool, BacktraceMap*, bool) const+675) native: #02 pc 00000000005c49bb /apex/com.android.runtime/lib64/libart.so (art::DumpCheckpoint::Run(art::Thread*)+859) native: #03 pc 00000000005bcf18 /apex/com.android.runtime/lib64/libart.so (art::ThreadList::RunCheckpoint(art::Closure*, art::Closure*)+456) native: #04 pc 00000000005bc2d1 /apex/com.android.runtime/lib64/libart.so (art::ThreadList::Dump(std::__1::basic_ostream\u0026lt;char, std::__1::char_traits\u0026lt;char\u0026gt;\u0026gt;\u0026amp;, bool)+1601) native: #05 pc 00000000005bbb88 /apex/com.android.runtime/lib64/libart.so (art::ThreadList::DumpForSigQuit(std::__1::basic_ostream\u0026lt;char, std::__1::char_traits\u0026lt;char\u0026gt;\u0026gt;\u0026amp;)+840) native: #06 pc 00000000005621f9 /apex/com.android.runtime/lib64/libart.so (art::Runtime::DumpForSigQuit(std::__1::basic_ostream\u0026lt;char, std::__1::char_traits\u0026lt;char\u0026gt;\u0026gt;\u0026amp;)+201) native: #07 pc 00000000005763a2 /apex/com.android.runtime/lib64/libart.so (art::SignalCatcher::HandleSigQuit()+1618) native: #08 pc 00000000005752b4 /apex/com.android.runtime/lib64/libart.so (art::SignalCatcher::Run(void*)+244) native: #09 pc 0000000000100fce /apex/com.android.runtime/lib64/bionic/libc.so (__pthread_start(void*)+30) native: #10 pc 0000000000098fe7 /apex/com.android.runtime/lib64/bionic/libc.so (__start_thread+55) (no managed stack frames) 第1行：\u0026ldquo;Signal Catcher\u0026rdquo;：线程名称，daemon：是否是daemon线程（如果不是，则不打印“daemon”），prio=5：java线程Thread对象中的优先级，tid=3：vm中对应的 threadid，Runnable：线程在虚拟机中的状态；（如果当前线程没有attach，则第一行显示： “name” prio=num (not attached)）；\n第2行：group: ThreadGroup，sCount: Suspend count， dsCount: debugger suspend count（小于等于sCount），obj：对应java线程 java.lang.Thread对象，self：native 对应的 thread 指针；\n第3行：sysTid：对应linux线程 tid， nice：线程调度执行优先级，-20 ~ 20 之间，越小，优先级越高， -1代表获取优先级失败，cgrp:cgroup,cpu调度group，sched：调度策略和调度优先级，handle：当前线程对应的pthread_t\n第4行：state：linux线程的状态，schedstat：线程调度情况，utm=15：线程在用户态运行的时间， stm=6：线程在内核态运行的时间， core=4：线程最后运行在哪个cpu上， HZ=100：系统时钟频率。\nutm,stm 单位是jiffies，时钟中断次数;频率是周期的倒数，一般是一秒钟中断产生的次数，所以 1/100 = 0.01s = 10ms, 每10ms产生一次中断；\n第5行：stack=0x7fa1f14000-0x7fa1f16000 stackSize=1005KB。线程栈的start 和 end，以及 stack size；\n第6行：held mutexes= \u0026ldquo;mutator lock\u0026rdquo;(shared held)\n分析思路 在上面我们对各类日志的关键信息进行了基本释义，下面就来介绍一下，当我们日常遇到 ANR 问题时，是如何分析的，总结思路如下：\n 分析堆栈，看看是否存在明显业务问题(如死锁，业务严重耗时等等)，如果无上述明显问题，则进一步通过 ANR Info 观察系统负载是否过高，进而导致整体性能较差，如 CPU，Mem，IO。然后再进一步分析是本进程还是其它进程导致，最后再分析进程内部分析对比各个线程 CPU 占比，找出可疑线程。 综合上述信息，利用监控工具收集的信息，观察和找出 ANR 发生前一段时间内，主线程耗时较长的消息都有哪些，并查看这些耗时较长的消息执行过程中采样堆栈，根据堆栈聚合展示，进一步的对比当前耗时严重的接口或业务逻辑。  以上分析思路，进一步细分的话，可以分为以下几个步骤：\n  一看 Trace：    死锁堆栈： 观察 Trace 堆栈，确认是否有明显问题，如主线程是否与其他线程发生死锁，如果是进程内部发生了死锁，那么恭喜，这类问题就清晰多了，只需找到与当前线程死锁的线程，问题即可解决； 业务堆栈： 观察通过 Trace 堆栈，发现当前主线程堆栈正在执行业务逻辑，你找到对应的业务同学，他承认该业务逻辑确实存在性能问题，那么恭喜，你很有可能解决了该问题，为什么只是有可能解决该问题呢？因为有些问题取决于技术栈或框架设计，无法在短时间内解决。如果业务同学反馈当前业务很简单，基本不怎么耗时，而这种场景也是日常经常遇到的一类问题，那么就可能需要借助我们的监控工具，追溯历史消息耗时情况了； IPC Block 堆栈： 观察通过 Trace 堆栈，发现主线程堆栈是在跨进程(Binder)通信，那么这个情况并不能当即下定论就是 IPC block 导致，实际情况也有可能是刚发送 Binder 请求不久，以及想要进一步的分析定位，这时也需要借助我们的自研监控工具了； 系统堆栈： 通过观察 Trace，发现当前堆栈只是简单的系统堆栈，想要搞清楚是否发生严重耗时，以及进一步的分析定位，如我们常见的 NativePollOnce 场景，那么也需要借助我们的自研监控工具进一步确认了。    二看关键字：Load，CPU，Slow Operation，Kswapd，Mmcqd，Kwork，Lowmemkiller 等等   刚才我们介绍到，上面这些关键字是反应系统 CPU，Mem，IO 负载的关键信息，在分析完主线程堆栈信息之后，还需要进一步在 ANRInfo，logcat 或 Kernel 日志中搜索这些关键字，并根据这些关键字当前数值，判断当前系统是否存在资源(CPU，Mem，IO)紧张的情况；\n  三看系统负载分布：观察系统整体负载：User,Sys,IOWait   通过观察系统负载，则可以进一步明确是 CPU 资源紧张，还是 IO 资源紧张；如果系统负载过高，一定是有某个进程或多个进程引起的。反之系统负载过高又会影响到所有进程调度性能。通过观察 User，Sys 的 CPU 占比，可以进一步发分析当前负载过高是发生在应用空间，还是系统空间，如大量调用逻辑(如文件读写，内存紧张导致系统不断回收内存等等)，知道这些之后，排查方向又会进一步缩小范围。\n  四看进程 CPU：观察 Top 进程的 CPU 占比   从上面分析，在我们知道当前系统负载过高，是发生在用户空间还是内核空间之后，那么我们就要通过 Anrinfo 的提供的进程 CPU 列表，进一步锁定是哪个(些)进程导致的，这时则要进一步的观察每个进程的 CPU 占比，以及进程内部 user，sys 占比。\n 在分析进程 CPU 占比过程，有一个关键的信息，要看统计这些进程 CPU 过高的场景是发生在 ANR 之前的一段时间还是之后一段时间，如下图表示 ANR 之前 4339ms 到 22895ms 时间内进程的 CPU 使用率。    五看 CPU 占比定线程 ：对比各线程 CPU 占比，以及线程内部 user 和 kernel 占比   在通过系统负载(user,sys,iowait)锁定方向之后，又通过进程列表锁定目标进程，那么接下来我们就可以从目标进程内部分析各个线程的(utm,stm)，进一步分析是哪个线程有问题了。\n在 Trace 日志的线程信息里可以清晰的看到每个线程的 utm，stm 耗时。至此我们就完成了从系统到进程，再到进程内部线程方向的负载分析和排查。当然，有时候可能导致系统高负载的不是当前进程，而是其他进程导致，这时同样会影响其他进程，进而导致 ANR。\n  六看消息调度锁定细节 ：    在分析和明确系统负载是否正常，以及负载过高是哪个进程引起的结论之后，接下来便要通过我们的监控工具，进一步排查是当前消息调度耗时导致，历史消息调度耗时导致，还是消息过于频繁导致。同时通过我们的线程 CheckTime 调度情况分析当前进程的 CPU 调度是否及时以及影响程度，在锁定上述场景之后，再进一步分析耗时消息的采样堆栈，才算找到解决问题的终极之钥。当然耗时消息内部可能存在一个或多个耗时较长的函数接口，或者会有多个消息存在耗时较长的函数接口，这就是我们前文中提到的：“发生 ANR 时，没有一个消息是无辜的”    更多信息：\n除了上面的一些信息，我们还可以结合 logcat 日志分析 ANR 之前的一些信息，查看是否存在业务侧或系统侧的异常输出，如搜索“Slow operation”，\u0026ldquo;Slow delivery\u0026quot;等关键字。也可以观察当前进程和系统进程是否存在频繁 GC 等等，以帮忙我们更全面的分析系统状态。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/3binderclient/",
	"title": "3BinderClient",
	"tags": [],
	"description": "",
	"content": "Data Flow graph LR parcel_data--\u0026gt;flat_binder_object flat_binder_object--\u0026gt;binder_transaction_data getService SystemServiceRegistry ContextImpl.getSystemService @Override public Object getSystemService(String name) { return SystemServiceRegistry.getSystemService(this, name); } registerServices /** * Manages all of the system services that can be returned by {@link Context#getSystemService}. Used by {@link ContextImpl}. */ static { ...... registerService(Context.ACTIVITY_SERVICE, ActivityManager.class, new CachedServiceFetcher\u0026lt;ActivityManager\u0026gt;() { @Override public ActivityManager createService(ContextImpl ctx) { return new ActivityManager(ctx.getOuterContext(), ctx.mMainThread.getHandler()); }}); ...... registerService(Context.DISPLAY_SERVICE, DisplayManager.class, new CachedServiceFetcher\u0026lt;DisplayManager\u0026gt;() { @Override public DisplayManager createService(ContextImpl ctx) { return new DisplayManager(ctx.getOuterContext()); }}); registerService /** * Statically registers a system service with the context. * This method must be called during static initialization only. */ private static \u0026lt;T\u0026gt; void registerService(String serviceName, Class\u0026lt;T\u0026gt; serviceClass, ServiceFetcher\u0026lt;T\u0026gt; serviceFetcher) { SYSTEM_SERVICE_NAMES.put(serviceClass, serviceName); SYSTEM_SERVICE_FETCHERS.put(serviceName, serviceFetcher); } getSystemService public static Object getSystemService(ContextImpl ctx, String name) { ServiceFetcher\u0026lt;?\u0026gt; fetcher = SYSTEM_SERVICE_FETCHERS.get(name); return fetcher != null ? fetcher.getService(ctx) : null; } CachedServiceFetcher.getService static abstract class CachedServiceFetcher\u0026lt;T\u0026gt; implements ServiceFetcher\u0026lt;T\u0026gt; { @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public final T getService(ContextImpl ctx) { service = createService(ctx); cache[mCacheIndex] = service; return service; } } createService\u0026ndash;\u0026gt;ServiceManager.getService final IBinder b = ServiceManager.getService(Context.CONNECTIVITY_SERVICE);//getService final IConnectivityManager service = IConnectivityManager.Stub.asInterface(b);//asInterface final ProxyInfo proxyInfo = service.getProxyForNetwork(null);//useService ServiceManager getService /** * Returns a reference to a service with the given name. * * @param name the name of the service to get * @return a reference to the service, or \u0026lt;code\u0026gt;null\u0026lt;/code\u0026gt; if the service doesn\u0026#39;t exist */ public static IBinder getService(String name) { try { IBinder service = sCache.get(name); if (service != null) { return service; } else { return Binder.allowBlocking(rawGetService(name)); } } catch (RemoteException e) { Log.e(TAG, \u0026#34;error in getService\u0026#34;, e); } return null; } rawGetService private static IBinder rawGetService(String name) throws RemoteException { final IBinder binder = getIServiceManager().getService(name);//getService then useService  return binder; } getIServiceManager private static IServiceManager getIServiceManager() { if (sServiceManager != null) { return sServiceManager; } // Find the service manager  sServiceManager = ServiceManagerNative .asInterface(Binder.allowBlocking(BinderInternal.getContextObject())); return sServiceManager; } frameworks/base/core/java/com/android/internal/os/BinderInternal.java\nBinderInternal.getContextObject /** * Return the global \u0026#34;context object\u0026#34; of the system. This is usually * an implementation of IServiceManager, which you can use to find * other services. */ public static final native IBinder getContextObject(); frameworks/base/core/jni/android_util_Binder.cpp\nandroid_os_BinderInternal_getContextObject static jobject android_os_BinderInternal_getContextObject(JNIEnv* env, jobject clazz) { sp\u0026lt;IBinder\u0026gt; b = ProcessState::self()-\u0026gt;getContextObject(NULL); return javaObjectForIBinder(env, b); } system/libhwbinder/ProcessState.cpp\nProcessState::getContextObject sp\u0026lt;IBinder\u0026gt; ProcessState::getContextObject(const sp\u0026lt;IBinder\u0026gt;\u0026amp; /*caller*/) { return getStrongProxyForHandle(0); } ProcessState::getStrongProxyForHandle sp\u0026lt;IBinder\u0026gt; ProcessState::getStrongProxyForHandle(int32_t handle) { sp\u0026lt;IBinder\u0026gt; result; handle_entry* e = lookupHandleLocked(handle); if (e != NULL) { // We need to create a new BpHwBinder if there isn\u0026#39;t currently one, OR we  // are unable to acquire a weak reference on this current one. See comment  // in getWeakProxyForHandle() for more info about this.  IBinder* b = e-\u0026gt;binder; if (b == NULL || !e-\u0026gt;refs-\u0026gt;attemptIncWeak(this)) { b = new BpHwBinder(handle); e-\u0026gt;binder = b; if (b) e-\u0026gt;refs = b-\u0026gt;getWeakRefs(); result = b; } else { // This little bit of nastyness is to allow us to add a primary  // reference to the remote proxy when this team doesn\u0026#39;t have one  // but another team is sending the handle to us.  result.force_set(b); e-\u0026gt;refs-\u0026gt;decWeak(this); } } return result; } ProcessState::lookupHandleLocked Vector\u0026lt;handle_entry\u0026gt; mHandleToObject; ProcessState::handle_entry* ProcessState::lookupHandleLocked(int32_t handle) { const size_t N=mHandleToObject.size(); if (N \u0026lt;= (size_t)handle) { handle_entry e; e.binder = NULL; e.refs = NULL; status_t err = mHandleToObject.insertAt(e, N, handle+1-N); if (err \u0026lt; NO_ERROR) return NULL; } return \u0026amp;mHandleToObject.editItemAt(handle); } asInterface(cast IBinder into IxxxInterface) public abstract class ServiceManagerNative extends Binder implements IServiceManager { /** * Cast a Binder object into a service manager interface, generating * a proxy if needed. */ static public IServiceManager asInterface(IBinder obj) { if (obj == null) { return null; } IServiceManager in = (IServiceManager)obj.queryLocalInterface(descriptor); if (in != null) { return in; } return new ServiceManagerProxy(obj); } useService IServiceManager.getService(name) ServiceManagerProxy.getService class ServiceManagerProxy implements IServiceManager { public ServiceManagerProxy(IBinder remote) { mRemote = remote; } public IBinder asBinder() { return mRemote; } public IBinder getService(String name) throws RemoteException { Parcel data = Parcel.obtain(); Parcel reply = Parcel.obtain(); data.writeInterfaceToken(IServiceManager.descriptor); data.writeString(name); mRemote.transact(GET_SERVICE_TRANSACTION, data, reply, 0); IBinder binder = reply.readStrongBinder(); reply.recycle(); data.recycle(); return binder; } asInterface(cast IBinder into IxxxInterface) IConnectivityManager public interface IConnectivityManager extends android.os.IInterface Stub public static abstract class Stub extends android.os.Binder implements android.net.IConnectivityManager asInterface /** * Cast an IBinder object into an android.net.IConnectivityManager interface, * generating a proxy if needed. */ public static android.net.IConnectivityManager asInterface(android.os.IBinder obj) { if ((obj==null)) { return null; } android.os.IInterface iin = obj.queryLocalInterface(DESCRIPTOR); if (((iin!=null)\u0026amp;\u0026amp;(iin instanceof android.net.IConnectivityManager))) { return ((android.net.IConnectivityManager)iin); } return new android.net.IConnectivityManager.Stub.Proxy(obj); } Binder.queryLocalInterface /** * Use information supplied to attachInterface() to return the * associated IInterface if it matches the requested * descriptor. */ public @Nullable IInterface queryLocalInterface(@NonNull String descriptor) { if (mDescriptor != null \u0026amp;\u0026amp; mDescriptor.equals(descriptor)) { return mOwner; } return null; } BinderProxy.queryLocalInterface final class BinderProxy implements IBinder { public IInterface queryLocalInterface(String descriptor) { return null; } Proxy private static class Proxy implements android.net.IConnectivityManager { private android.os.IBinder mRemote; Proxy(android.os.IBinder remote) { mRemote = remote; } useService @Override public android.net.ProxyInfo getProxyForNetwork(android.net.Network nework) throws android.os.RemoteException { android.os.Parcel _data = android.os.Parcel.obtain(); android.os.Parcel _reply = android.os.Parcel.obtain(); android.net.ProxyInfo _result; try { _data.writeInterfaceToken(DESCRIPTOR); if ((nework!=null)) { _data.writeInt(1); nework.writeToParcel(_data, 0); } else { _data.writeInt(0); } mRemote.transact(Stub.TRANSACTION_getProxyForNetwork, _data, _reply, 0); _reply.readException(); if ((0!=_reply.readInt())) { _result = android.net.ProxyInfo.CREATOR.createFromParcel(_reply); } else { _result = null; } } finally { _reply.recycle(); _data.recycle(); } return _result; } Parcel obtain /** * Retrieve a new Parcel object from the pool. */ public static Parcel obtain() { final Parcel[] pool = sOwnedPool; synchronized (pool) { Parcel p; for (int i=0; i\u0026lt;POOL_SIZE; i++) { p = pool[i]; if (p != null) { pool[i] = null; if (DEBUG_RECYCLE) { p.mStack = new RuntimeException(); } p.mReadWriteHelper = ReadWriteHelper.DEFAULT; return p; } } } return new Parcel(0); } recycle /** * Put a Parcel object back into the pool. You must not touch * the object after this call. */ public final void recycle() { if (DEBUG_RECYCLE) mStack = null; freeBuffer(); final Parcel[] pool; if (mOwnsNativeParcelObject) { pool = sOwnedPool; } else { mNativePtr = 0; pool = sHolderPool; } synchronized (pool) { for (int i=0; i\u0026lt;POOL_SIZE; i++) { if (pool[i] == null) { pool[i] = this; return; } } } } transact BinderProxy /** * Java proxy for a native IBinder object. * Allocated and constructed by the native javaObjectforIBinder function. Never allocated * directly from Java code. */ final class BinderProxy implements IBinder { public boolean transact(int code, Parcel data, Parcel reply, int flags) throws RemoteException { Binder.checkParcel(this, code, data, \u0026#34;Unreasonably large binder buffer\u0026#34;); try { return transactNative(code, data, reply, flags); } finally { if (tracingEnabled) { Trace.traceEnd(Trace.TRACE_TAG_ALWAYS); } } } static const JNINativeMethod gBinderProxyMethods[] = { /* name, signature, funcPtr */ {\u0026#34;transactNative\u0026#34;, \u0026#34;(ILandroid/os/Parcel;Landroid/os/Parcel;I)Z\u0026#34;, (void*)android_os_BinderProxy_transact}, android_os_BinderProxy_transact static jboolean android_os_BinderProxy_transact(JNIEnv* env, jobject obj, jint code, jobject dataObj, jobject replyObj, jint flags) // throws RemoteException { Parcel* data = parcelForJavaObject(env, dataObj); Parcel* reply = parcelForJavaObject(env, replyObj); IBinder* target = getBPNativeData(env, obj)-\u0026gt;mObject.get(); //printf(\u0026#34;Transact from Java code to %p sending: \u0026#34;, target); data-\u0026gt;print();  status_t err = target-\u0026gt;transact(code, *data, reply, flags); //if (reply) printf(\u0026#34;Transact from Java code to %p received: \u0026#34;, target); reply-\u0026gt;print();  if (kEnableBinderSample) { if (time_binder_calls) { conditionally_log_binder_call(start_millis, target, code); } } ...... } parcelForJavaObject Parcel* parcelForJavaObject(JNIEnv* env, jobject obj) { if (obj) { Parcel* p = (Parcel*)env-\u0026gt;GetLongField(obj, gParcelOffsets.mNativePtr); return p; } return NULL; } getBPNativeData BinderProxyNativeData* getBPNativeData(JNIEnv* env, jobject obj) { return (BinderProxyNativeData *) env-\u0026gt;GetLongField(obj, gBinderProxyOffsets.mNativeData); } BpBinder status_t BpBinder::transact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { // Once a binder has died, it will never come back to life.  if (mAlive) { status_t status = IPCThreadState::self()-\u0026gt;transact( mHandle, code, data, reply, flags);//传递mHandle  if (status == DEAD_OBJECT) mAlive = 0; return status; } return DEAD_OBJECT; } IPCThreadState Parcel mIn; Parcel mOut; self IPCThreadState* IPCThreadState::self() { const pthread_key_t k = gTLS; IPCThreadState* st = (IPCThreadState*)pthread_getspecific(k); if (st) return st; return new IPCThreadState; IPCThreadState() 每个线程都有一个IPCThreadState，每个IPCThreadState中都有一个mIn、一个mOut。成员变量mProcess保存了ProcessState变量(每个进程只有一个)。\n mIn 用来接收来自Binder设备的数据，默认大小为256字节； mOut用来存储发往Binder设备的数据，默认大小为256字节。  IPCThreadState::IPCThreadState() : mProcess(ProcessState::self()), mStrictModePolicy(0), mLastTransactionBinderFlags(0) { pthread_setspecific(gTLS, this); clearCaller(); mIn.setDataCapacity(256); mOut.setDataCapacity(256); } transact status_t IPCThreadState::transact(int32_t handle, uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { flags |= TF_ACCEPT_FDS; err = writeTransactionData(BC_TRANSACTION, flags, handle, code, data, NULL);、//传递handle  if ((flags \u0026amp; TF_ONE_WAY) == 0) { if (reply) {//call waitForResponse with param reply not null  err = waitForResponse(reply); } else { Parcel fakeReply; err = waitForResponse(\u0026amp;fakeReply);//call waitForResponse with param reply null  } } else { //oneway，则不需要等待reply的场景  err = waitForResponse(NULL, NULL); } writeTransactionData status_t IPCThreadState::writeTransactionData(int32_t cmd, uint32_t binderFlags, int32_t handle, uint32_t code, const Parcel\u0026amp; data, status_t* statusBuffer) { binder_transaction_data tr; tr.target.ptr = 0; /* Don\u0026#39;t pass uninitialized stack data to a remote process */ tr.target.handle = handle;//准备写入handle  tr.code = code; //wrapped code  tr.flags = binderFlags; tr.cookie = 0; tr.sender_pid = 0; tr.sender_euid = 0; const status_t err = data.errorCheck(); if (err == NO_ERROR) { tr.data_size = data.ipcDataSize();// mDataSize,binder_transaction的数据大小  tr.data.ptr.buffer = data.ipcData();//mData, binder_transaction的数据的起始地址  tr.offsets_size = data.ipcObjectsCount()*sizeof(binder_size_t);//mObjectsSize,记录着flat_binder_object结构体的个数  tr.data.ptr.offsets = data.ipcObjects();//mObjects, 记录着flat_binder_object结构体在数据偏移量  } mOut.writeInt32(cmd);//cmd = BC_TRANSACTION  mOut.write(\u0026amp;tr, sizeof(tr));//写入binder_transaction_data数据  return NO_ERROR; } Parcel::ipcData uintptr_t Parcel::ipcData() const { return reinterpret_cast\u0026lt;uintptr_t\u0026gt;(mData); } waitForResponse status_t IPCThreadState::waitForResponse(Parcel *reply, status_t *acquireResult) { uint32_t cmd; int32_t err; while (1) { if ((err=talkWithDriver()) \u0026lt; NO_ERROR) break; err = mIn.errorCheck(); if (err \u0026lt; NO_ERROR) break; if (mIn.dataAvail() == 0) continue; cmd = (uint32_t)mIn.readInt32(); switch (cmd) { case BR_TRANSACTION_COMPLETE: if (!reply \u0026amp;\u0026amp; !acquireResult) goto finish; break; case BR_REPLY: { binder_transaction_data tr; err = mIn.read(\u0026amp;tr, sizeof(tr)); if (reply) { if ((tr.flags \u0026amp; TF_STATUS_CODE) == 0) { reply-\u0026gt;ipcSetDataReference( reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), freeBuffer, this); } else { err = *reinterpret_cast\u0026lt;const status_t*\u0026gt;(tr.data.ptr.buffer); freeBuffer(NULL, reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), this); } } else { freeBuffer(NULL, reinterpret_cast\u0026lt;const uint8_t*\u0026gt;(tr.data.ptr.buffer), tr.data_size, reinterpret_cast\u0026lt;const binder_size_t*\u0026gt;(tr.data.ptr.offsets), tr.offsets_size/sizeof(binder_size_t), this); continue; } ...... } goto finish; default: err = executeCommand(cmd); if (err != NO_ERROR) goto finish; break; Parcel::dataAvail size_t Parcel::dataAvail() const { size_t result = dataSize() - dataPosition(); if (result \u0026gt; INT32_MAX) { abort(); } return result; } talkWithDriver status_t IPCThreadState::talkWithDriver(bool doReceive) { binder_write_read bwr; // Is the read buffer empty?  const bool needRead = mIn.dataPosition() \u0026gt;= mIn.dataSize(); // We don\u0026#39;t want to write anything if we are still reading  // from data left in the input buffer and the caller  // has requested to read the next data.  const size_t outAvail = (!doReceive || needRead) ? mOut.dataSize() : 0; bwr.write_size = outAvail; bwr.write_buffer = (uintptr_t)mOut.data();//写入write buffer  // This is what we\u0026#39;ll read.  if (doReceive \u0026amp;\u0026amp; needRead) { bwr.read_size = mIn.dataCapacity(); bwr.read_buffer = (uintptr_t)mIn.data(); } else { bwr.read_size = 0; bwr.read_buffer = 0; } // Return immediately if there is nothing to do.  if ((bwr.write_size == 0) \u0026amp;\u0026amp; (bwr.read_size == 0)) return NO_ERROR; bwr.write_consumed = 0; bwr.read_consumed = 0; do { if (ioctl(mProcess-\u0026gt;mDriverFD, BINDER_WRITE_READ, \u0026amp;bwr) \u0026gt;= 0) err = NO_ERROR; else err = -errno; if (mProcess-\u0026gt;mDriverFD \u0026lt;= 0) { err = -EBADF; } } while (err == -EINTR); "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/1startup/3flutter_surface/",
	"title": "3flutter_surface",
	"tags": [],
	"description": "",
	"content": "RenderSurface类设计图解 classDiagram class FlutterSurfaceView { -FlutterRenderer flutterRenderer -SurfaceHolder_Callback surfaceCallback } class FlutterTextureView { -FlutterRenderer flutterRenderer; -Surface renderSurface; } class FlutterImageView { -FlutterRenderer flutterRenderer; -ImageReader imageReader } TextureView\u0026lt;|--FlutterTextureView RenderSurface\u0026lt;|--FlutterTextureView SurfaceView\u0026lt;|--FlutterSurfaceView RenderSurface\u0026lt;|--FlutterSurfaceView View\u0026lt;|--FlutterImageView RenderSurface\u0026lt;|--FlutterImageView class FlutterView classDiagram class AndroidSurface { +SetNativeWindow(AndroidNativeWindow) } class AndroidSurfaceGL { fml::RefPtr\u0026lt;AndroidNativeWindow\u0026gt; native_window_; std::unique_ptr\u0026lt;AndroidEGLSurface\u0026gt; onscreen_surface_; std::unique_ptr\u0026lt;AndroidEGLSurface\u0026gt; offscreen_surface_; } GPUSurfaceSoftwareDelegate\u0026lt;|--AndroidSurfaceSoftware AndroidSurface\u0026lt;|--AndroidSurfaceSoftware AndroidSurface\u0026lt;|--AndroidSurfaceGL GPUSurfaceGLDelegate\u0026lt;|--AndroidSurfaceGL AndroidSurface\u0026lt;|--AndroidSurfaceVulkan GPUSurfaceVulkanDelegate\u0026lt;|--AndroidSurfaceVulkan class GPUSurfaceGL { GPUSurfaceGLDelegate* delegate_ sk_sp\u0026lt;SkSurface\u0026gt; onscreen_surface_ } Surface\u0026lt;|--GPUSurfaceGL class AndroidEGLSurface { const EGLSurface surface_; const EGLDisplay display_; const EGLContext context_; bool SwapBuffers(); } Flutter通过Surface自绘图解 graph LR subgraph Platform Surface end Surface--\u0026gt;|flutterRenderer.startRenderingToSurface|Rasterizer'sSurface subgraph Native Rasterizer'sSurface end subgraph Flutter Rasterizer::DrawToSurface end Rasterizer::DrawToSurface--\u0026gt;|post and draw to|Rasterizer'sSurface public class FlutterView extends FrameLayout implements MouseCursorPlugin.MouseCursorViewDelegate { // Internal view hierarchy references.  @Nullable private FlutterSurfaceView flutterSurfaceView; @Nullable private FlutterTextureView flutterTextureView; @Nullable private FlutterImageView flutterImageView; @Nullable private RenderSurface renderSurface; @Nullable private RenderSurface previousRenderSurface; private final Set\u0026lt;FlutterUiDisplayListener\u0026gt; flutterUiDisplayListeners = new HashSet\u0026lt;\u0026gt;(); private boolean isFlutterUiDisplayed; // Connections to a Flutter execution context.  @Nullable private FlutterEngine flutterEngine; } public FlutterView(@NonNull Context context, @NonNull FlutterSurfaceView flutterSurfaceView) { this(context, null, flutterSurfaceView); } public FlutterView(@NonNull Context context, @NonNull FlutterTextureView flutterTextureView) { this(context, null, flutterTextureView); } public FlutterView(@NonNull Context context, @NonNull FlutterImageView flutterImageView) { this(context, null, flutterImageView); } private FlutterSurfaceView(//FlutterTextureView和FlutterImageView构造方法类似  @NonNull Context context, @Nullable AttributeSet attrs, boolean renderTransparently) { super(context, attrs); this.renderTransparently = renderTransparently; init(); } private void init() { Log.v(TAG, \u0026#34;Initializing FlutterView\u0026#34;); if (flutterSurfaceView != null) { Log.v(TAG, \u0026#34;Internally using a FlutterSurfaceView.\u0026#34;); addView(flutterSurfaceView); } else if (flutterTextureView != null) { Log.v(TAG, \u0026#34;Internally using a FlutterTextureView.\u0026#34;); addView(flutterTextureView); } else { Log.v(TAG, \u0026#34;Internally using a FlutterImageView.\u0026#34;); addView(flutterImageView); } // FlutterView needs to be focusable so that the InputMethodManager can interact with it.  setFocusable(true); setFocusableInTouchMode(true); if (Build.VERSION.SDK_INT \u0026gt;= Build.VERSION_CODES.O) { setImportantForAutofill(View.IMPORTANT_FOR_AUTOFILL_YES_EXCLUDE_DESCENDANTS); } } Platform surface配置到native层 flutterImageView /** * Invoked by the owner of this {@code FlutterImageView} when it wants to begin rendering a * Flutter UI to this {@code FlutterImageView}. */ @Override public void attachToRenderer(@NonNull FlutterRenderer flutterRenderer) { switch (kind) { case background: flutterRenderer.swapSurface(imageReader.getSurface());//main  break; case overlay: // Do nothing since the attachment is done by the handler of  // `FlutterJNI#createOverlaySurface()` in the native side.  break; } setAlpha(1.0f); this.flutterRenderer = flutterRenderer; isAttachedToFlutterRenderer = true; } flutterRenderer.swapSurface /** * Swaps the {@link Surface} used to render the current frame. * * \u0026lt;p\u0026gt;In hybrid composition, the root surfaces changes from {@link * android.view.SurfaceHolder#getSurface()} to {@link android.media.ImageReader#getSurface()} when * a platform view is in the current frame. */ public void swapSurface(@NonNull Surface surface) { this.surface = surface; flutterJNI.onSurfaceWindowChanged(surface); } flutterJNI.onSurfaceWindowChanged @UiThread public void onSurfaceWindowChanged(@NonNull Surface surface) { ensureRunningOnMainThread(); ensureAttachedToNative(); nativeSurfaceWindowChanged(nativeShellHolderId, surface); } flutterSurfaceView getHolder().addCallback private void init() { // If transparency is desired then we\u0026#39;ll enable a transparent pixel format and place  // our Window above everything else to get transparent background rendering.  if (renderTransparently) { getHolder().setFormat(PixelFormat.TRANSPARENT); setZOrderOnTop(true); } // Grab a reference to our underlying Surface and register callbacks with that Surface so we  // can monitor changes and forward those changes on to native Flutter code.  getHolder().addCallback(surfaceCallback); // Keep this SurfaceView transparent until Flutter has a frame ready to render. This avoids  // displaying a black rectangle in our place.  setAlpha(0.0f); } // Connects the {@code Surface} beneath this {@code SurfaceView} with Flutter\u0026#39;s native code.  // Callbacks are received by this Object and then those messages are forwarded to our  // FlutterRenderer, and then on to the JNI bridge over to native Flutter code.  private final SurfaceHolder.Callback surfaceCallback = new SurfaceHolder.Callback() { @Override public void surfaceCreated(@NonNull SurfaceHolder holder) { isSurfaceAvailableForRendering = true; if (isAttachedToFlutterRenderer) { connectSurfaceToRenderer(); } } @Override public void surfaceChanged( @NonNull SurfaceHolder holder, int format, int width, int height) { if (isAttachedToFlutterRenderer) { changeSurfaceSize(width, height); } } @Override public void surfaceDestroyed(@NonNull SurfaceHolder holder) { isSurfaceAvailableForRendering = false; if (isAttachedToFlutterRenderer) { disconnectSurfaceFromRenderer(); } } }; attachToRenderer /** * Invoked by the owner of this {@code FlutterSurfaceView} when it wants to begin rendering a * Flutter UI to this {@code FlutterSurfaceView}. * * \u0026lt;p\u0026gt;If an Android {@link android.view.Surface} is available, this method will give that {@link * android.view.Surface} to the given {@link FlutterRenderer} to begin rendering Flutter\u0026#39;s UI to * this {@code FlutterSurfaceView}. * * \u0026lt;p\u0026gt;If no Android {@link android.view.Surface} is available yet, this {@code FlutterSurfaceView} * will wait until a {@link android.view.Surface} becomes available and then give that {@link * android.view.Surface} to the given {@link FlutterRenderer} to begin rendering Flutter\u0026#39;s UI to * this {@code FlutterSurfaceView}. */ public void attachToRenderer(@NonNull FlutterRenderer flutterRenderer) { Log.v(TAG, \u0026#34;Attaching to FlutterRenderer.\u0026#34;); if (this.flutterRenderer != null) { Log.v( TAG, \u0026#34;Already connected to a FlutterRenderer. Detaching from old one and attaching to new one.\u0026#34;); this.flutterRenderer.stopRenderingToSurface(); this.flutterRenderer.removeIsDisplayingFlutterUiListener(flutterUiDisplayListener); } this.flutterRenderer = flutterRenderer; isAttachedToFlutterRenderer = true; this.flutterRenderer.addIsDisplayingFlutterUiListener(flutterUiDisplayListener); // If we\u0026#39;re already attached to an Android window then we\u0026#39;re now attached to both a renderer  // and the Android window. We can begin rendering now.  if (isSurfaceAvailableForRendering) { Log.v(TAG,\u0026#34;Surface is available for rendering. Connecting FlutterRenderer to Android surface.\u0026#34;); connectSurfaceToRenderer(); } } connectSurfaceToRenderer // FlutterRenderer and getSurfaceTexture() must both be non-null.  private void connectSurfaceToRenderer() { flutterRenderer.startRenderingToSurface(getHolder().getSurface()); } FlutterTextureView // Connects the {@code SurfaceTexture} beneath this {@code TextureView} with Flutter\u0026#39;s native  // code.  // Callbacks are received by this Object and then those messages are forwarded to our  // FlutterRenderer, and then on to the JNI bridge over to native Flutter code.  private final SurfaceTextureListener surfaceTextureListener = new SurfaceTextureListener() { @Override public void onSurfaceTextureAvailable( SurfaceTexture surfaceTexture, int width, int height) { Log.v(TAG, \u0026#34;SurfaceTextureListener.onSurfaceTextureAvailable()\u0026#34;); isSurfaceAvailableForRendering = true; // If we\u0026#39;re already attached to a FlutterRenderer then we\u0026#39;re now attached to both a  // renderer  // and the Android window, so we can begin rendering now.  if (isAttachedToFlutterRenderer) { connectSurfaceToRenderer(); } } } public FlutterTextureView(@NonNull Context context, @Nullable AttributeSet attrs) { super(context, attrs); init(); } setSurfaceTextureListener private void init() { // Listen for when our underlying SurfaceTexture becomes available, changes size, or  // gets destroyed, and take the appropriate actions.  setSurfaceTextureListener(surfaceTextureListener); } attachToRenderer /** * Invoked by the owner of this {@code FlutterTextureView} when it wants to begin rendering a * Flutter UI to this {@code FlutterTextureView}. * * \u0026lt;p\u0026gt;If an Android {@link SurfaceTexture} is available, this method will give that {@link * SurfaceTexture} to the given {@link FlutterRenderer} to begin rendering Flutter\u0026#39;s UI to this * {@code FlutterTextureView}. * * \u0026lt;p\u0026gt;If no Android {@link SurfaceTexture} is available yet, this {@code FlutterTextureView} will * wait until a {@link SurfaceTexture} becomes available and then give that {@link SurfaceTexture} * to the given {@link FlutterRenderer} to begin rendering Flutter\u0026#39;s UI to this {@code * FlutterTextureView}. */ public void attachToRenderer(@NonNull FlutterRenderer flutterRenderer) { Log.v(TAG, \u0026#34;Attaching to FlutterRenderer.\u0026#34;); if (this.flutterRenderer != null) { Log.v( TAG, \u0026#34;Already connected to a FlutterRenderer. Detaching from old one and attaching to new one.\u0026#34;); this.flutterRenderer.stopRenderingToSurface(); } this.flutterRenderer = flutterRenderer; isAttachedToFlutterRenderer = true; // If we\u0026#39;re already attached to an Android window then we\u0026#39;re now attached to both a renderer  // and the Android window. We can begin rendering now.  if (isSurfaceAvailableForRendering) { Log.v(TAG,\u0026#34;Surface is available for rendering. Connecting FlutterRenderer to Android surface.\u0026#34;); connectSurfaceToRenderer(); } } connectSurfaceToRenderer // FlutterRenderer and getSurfaceTexture() must both be non-null.  private void connectSurfaceToRenderer() { if (flutterRenderer == null || getSurfaceTexture() == null) { throw new IllegalStateException( \u0026#34;connectSurfaceToRenderer() should only be called when flutterRenderer and getSurfaceTexture() are non-null.\u0026#34;); } renderSurface = new Surface(getSurfaceTexture()); flutterRenderer.startRenderingToSurface(renderSurface); } /** * Create Surface from a {@link SurfaceTexture}. * * Images drawn to the Surface will be made available to the {@link * SurfaceTexture}, which can attach them to an OpenGL ES texture via {@link * SurfaceTexture#updateTexImage}. * * Please note that holding onto the Surface created here is not enough to * keep the provided SurfaceTexture from being reclaimed. In that sense, * the Surface will act like a * {@link java.lang.ref.WeakReference weak reference} to the SurfaceTexture. * * @param surfaceTexture The {@link SurfaceTexture} that is updated by this * Surface. * @throws OutOfResourcesException if the surface could not be created. */ public Surface(SurfaceTexture surfaceTexture) { if (surfaceTexture == null) { throw new IllegalArgumentException(\u0026#34;surfaceTexture must not be null\u0026#34;); } mIsSingleBuffered = surfaceTexture.isSingleBuffered(); synchronized (mLock) { mName = surfaceTexture.toString(); setNativeObjectLocked(nativeCreateFromSurfaceTexture(surfaceTexture)); } } flutterRenderer.startRenderingToSurface /** * Represents the rendering responsibilities of a {@code FlutterEngine}. * * \u0026lt;p\u0026gt;{@code FlutterRenderer} works in tandem with a provided {@link RenderSurface} to paint Flutter * pixels to an Android {@code View} hierarchy. * * \u0026lt;p\u0026gt;{@code FlutterRenderer} manages textures for rendering, and forwards some Java calls to native * Flutter code via JNI. The corresponding {@link RenderSurface} provides the Android {@link * Surface} that this renderer paints. * * \u0026lt;p\u0026gt;{@link io.flutter.embedding.android.FlutterSurfaceView} and {@link * io.flutter.embedding.android.FlutterTextureView} are implementations of {@link RenderSurface}. */ @TargetApi(Build.VERSION_CODES.JELLY_BEAN) public class FlutterRenderer implements TextureRegistry { @NonNull private final FlutterJNI flutterJNI; public void startRenderingToSurface(@NonNull Surface surface) { if (this.surface != null) { stopRenderingToSurface(); } this.surface = surface; flutterJNI.onSurfaceCreated(surface); } flutterJNI.onSurfaceCreated /** * Call this method when a {@link Surface} has been created onto which you would like Flutter to * paint. * * \u0026lt;p\u0026gt;See {@link android.view.SurfaceHolder.Callback#surfaceCreated(SurfaceHolder)} for an example * of where this call might originate. */ @UiThread public void onSurfaceCreated(@NonNull Surface surface) { ensureRunningOnMainThread(); ensureAttachedToNative(); nativeSurfaceCreated(nativeShellHolderId, surface); } private native void nativeSurfaceCreated(long nativeShellHolderId, @NonNull Surface surface); nativeSurfaceCreated shell/platform/android/platform_view_android_jni_impl.cc\nstatic void SurfaceCreated(JNIEnv* env, jobject jcaller, jlong shell_holder, jobject jsurface) { // Note: This frame ensures that any local references used by  // ANativeWindow_fromSurface are released immediately. This is needed as a  // workaround for https://code.google.com/p/android/issues/detail?id=68174  fml::jni::ScopedJavaLocalFrame scoped_local_reference_frame(env); auto window = fml::MakeRefCounted\u0026lt;AndroidNativeWindow\u0026gt;( ANativeWindow_fromSurface(env, jsurface)); ANDROID_SHELL_HOLDER-\u0026gt;GetPlatformView()-\u0026gt;NotifyCreated(std::move(window));//main } ANativeWindow_fromSurface frameworks/base/native/android/native_window_jni.cpp\nANativeWindow* ANativeWindow_fromSurface(JNIEnv* env, jobject surface) { sp\u0026lt;ANativeWindow\u0026gt; win = android_view_Surface_getNativeWindow(env, surface); if (win != NULL) { win-\u0026gt;incStrong((void*)ANativeWindow_fromSurface); } return win.get(); } frameworks/base/core/jni/android_view_Surface.cpp\nsp\u0026lt;ANativeWindow\u0026gt; android_view_Surface_getNativeWindow(JNIEnv* env, jobject surfaceObj) { return android_view_Surface_getSurface(env, surfaceObj); } sp\u0026lt;Surface\u0026gt; android_view_Surface_getSurface(JNIEnv* env, jobject surfaceObj) { sp\u0026lt;Surface\u0026gt; sur; jobject lock = env-\u0026gt;GetObjectField(surfaceObj, gSurfaceClassInfo.mLock); if (env-\u0026gt;MonitorEnter(lock) == JNI_OK) { sur = reinterpret_cast\u0026lt;Surface *\u0026gt;( env-\u0026gt;GetLongField(surfaceObj, gSurfaceClassInfo.mNativeObject)); env-\u0026gt;MonitorExit(lock); } env-\u0026gt;DeleteLocalRef(lock); return sur; } static struct { jclass clazz; jfieldID mNativeObject;//对应java对象Surface的long mNativeObject成员变量  jfieldID mLock; jmethodID ctor; } gSurfaceClassInfo; shell/platform/android/platform_view_android.cc\nPlatformViewAndroid::NotifyCreated void PlatformViewAndroid::NotifyCreated( fml::RefPtr\u0026lt;AndroidNativeWindow\u0026gt; native_window) { if (android_surface_) { InstallFirstFrameCallback(); fml::AutoResetWaitableEvent latch; fml::TaskRunner::RunNowOrPostTask( task_runners_.GetRasterTaskRunner(), [\u0026amp;latch, surface = android_surface_.get(), native_window = std::move(native_window)]() { surface-\u0026gt;SetNativeWindow(native_window); latch.Signal(); }); latch.Wait(); } PlatformView::NotifyCreated(); } AndroidSurfaceGL::SetNativeWindow bool AndroidSurfaceGL::SetNativeWindow( fml::RefPtr\u0026lt;AndroidNativeWindow\u0026gt; window) { FML_DCHECK(IsValid()); FML_DCHECK(window); native_window_ = window; // Ensure the destructor is called since it destroys the `EGLSurface` before  // creating a new onscreen surface.  onscreen_surface_ = nullptr; // Create the onscreen surface.  onscreen_surface_ = GLContextPtr()-\u0026gt;CreateOnscreenSurface(window); if (!onscreen_surface_-\u0026gt;IsValid()) { return false; } return true; } AndroidContextGL::CreateOnscreenSurface std::unique_ptr\u0026lt;AndroidEGLSurface\u0026gt; AndroidContextGL::CreateOnscreenSurface( fml::RefPtr\u0026lt;AndroidNativeWindow\u0026gt; window) const { EGLDisplay display = environment_-\u0026gt;Display(); const EGLint attribs[] = {EGL_NONE}; EGLSurface surface = eglCreateWindowSurface( display, config_, reinterpret_cast\u0026lt;EGLNativeWindowType\u0026gt;(window-\u0026gt;handle()), attribs); return std::make_unique\u0026lt;AndroidEGLSurface\u0026gt;(surface, display, context_); } PlatformView::NotifyCreated void PlatformView::NotifyCreated() { std::unique_ptr\u0026lt;Surface\u0026gt; surface; // Threading: We want to use the platform view on the non-platform thread.  // Using the weak pointer is illegal. But, we are going to introduce a latch  // so that the platform view is not collected till the surface is obtained.  auto* platform_view = this; fml::ManualResetWaitableEvent latch; fml::TaskRunner::RunNowOrPostTask( task_runners_.GetRasterTaskRunner(), [platform_view, \u0026amp;surface, \u0026amp;latch]() { surface = platform_view-\u0026gt;CreateRenderingSurface(); if (surface \u0026amp;\u0026amp; !surface-\u0026gt;IsValid()) { surface.reset(); } latch.Signal(); }); latch.Wait(); if (!surface) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to create platform view rendering surface\u0026#34;; return; } delegate_.OnPlatformViewCreated(std::move(surface));//main } // |PlatformView::Delegate| void Shell::OnPlatformViewCreated(std::unique_ptr\u0026lt;Surface\u0026gt; surface) { auto raster_task = fml::MakeCopyable([\u0026amp;waiting_for_first_frame = waiting_for_first_frame_, rasterizer = rasterizer_-\u0026gt;GetWeakPtr(), //  surface = std::move(surface), //  \u0026amp;latch]() mutable { if (rasterizer) { // Enables the thread merger which may be used by the external view  // embedder.  rasterizer-\u0026gt;EnableThreadMergerIfNeeded(); rasterizer-\u0026gt;Setup(std::move(surface)); } } Rasterizer::Setup void Rasterizer::Setup(std::unique_ptr\u0026lt;Surface\u0026gt; surface) { surface_ = std::move(surface); 绘制到surface上 Render //lib/ui/window/platform_configuration.cc void Render(Dart_NativeArguments args) { Scene* scene = tonic::DartConverter\u0026lt;Scene*\u0026gt;::FromArguments(args, 1, exception); UIDartState::Current()-\u0026gt;platform_configuration()-\u0026gt;client()-\u0026gt;Render(scene);//main } //runtime/runtime_controller.cc // |PlatformConfigurationClient| void RuntimeController::Render(Scene* scene) { client_.Render(scene-\u0026gt;takeLayerTree()); } //shell/common/engine.cc void Engine::Render(std::unique_ptr\u0026lt;flutter::LayerTree\u0026gt; layer_tree) { animator_-\u0026gt;Render(std::move(layer_tree)); } //shell/common/animator.cc void Animator::Render(std::unique_ptr\u0026lt;flutter::LayerTree\u0026gt; layer_tree) { delegate_.OnAnimatorDraw(layer_tree_pipeline_, std::move(frame_timings_recorder_)); } GetRasterTaskRunner()-\u0026gt;PostTask //shell/common/shell.cc // |Animator::Delegate| void Shell::OnAnimatorDraw( fml::RefPtr\u0026lt;Pipeline\u0026lt;flutter::LayerTree\u0026gt;\u0026gt; pipeline, std::unique_ptr\u0026lt;FrameTimingsRecorder\u0026gt; frame_timings_recorder) { task_runners_.GetRasterTaskRunner()-\u0026gt;PostTask(fml::MakeCopyable(//放置任务到rasterTaskRunner  [\u0026amp;waiting_for_first_frame = waiting_for_first_frame_, \u0026amp;waiting_for_first_frame_condition = waiting_for_first_frame_condition_, rasterizer = rasterizer_-\u0026gt;GetWeakPtr(), pipeline = std::move(pipeline), discard_callback = std::move(discard_callback), frame_timings_recorder = std::move(frame_timings_recorder)]() mutable { if (rasterizer) { rasterizer-\u0026gt;Draw(std::move(frame_timings_recorder), pipeline,//main  std::move(discard_callback)); if (waiting_for_first_frame.load()) { waiting_for_first_frame.store(false); waiting_for_first_frame_condition.notify_all(); } } })); } //shell/common/rasterizer.cc void Rasterizer::Draw( std::unique_ptr\u0026lt;FrameTimingsRecorder\u0026gt; frame_timings_recorder, fml::RefPtr\u0026lt;Pipeline\u0026lt;flutter::LayerTree\u0026gt;\u0026gt; pipeline, LayerTreeDiscardCallback discardCallback) { RasterStatus raster_status = RasterStatus::kFailed; Pipeline\u0026lt;flutter::LayerTree\u0026gt;::Consumer consumer = [\u0026amp;](std::unique_ptr\u0026lt;LayerTree\u0026gt; layer_tree) { if (discardCallback(*layer_tree.get())) { raster_status = RasterStatus::kDiscarded; } else { raster_status = DoDraw(std::move(frame_timings_recorder), std::move(layer_tree));//main  } }; PipelineConsumeResult consume_result = pipeline-\u0026gt;Consume(consumer); } RasterStatus Rasterizer::DoDraw( std::unique_ptr\u0026lt;FrameTimingsRecorder\u0026gt; frame_timings_recorder, std::unique_ptr\u0026lt;flutter::LayerTree\u0026gt; layer_tree) { RasterStatus raster_status = DrawToSurface(frame_timings_recorder-\u0026gt;GetBuildDuration(), *layer_tree); Rasterizer::DrawToSurface RasterStatus Rasterizer::DrawToSurface( const fml::TimeDelta frame_build_duration, flutter::LayerTree\u0026amp; layer_tree) { SkCanvas* embedder_root_canvas = nullptr; if (external_view_embedder_) { external_view_embedder_-\u0026gt;BeginFrame( layer_tree.frame_size(), surface_-\u0026gt;GetContext(), layer_tree.device_pixel_ratio(), raster_thread_merger_); embedder_root_canvas = external_view_embedder_-\u0026gt;GetRootCanvas(); } auto frame = surface_-\u0026gt;AcquireFrame(layer_tree.frame_size()); if (compositor_frame) { RasterStatus raster_status = compositor_frame-\u0026gt;Raster(layer_tree, false);//main  frame-\u0026gt;Submit();//main  } } //shell/platform/android/external_view_embedder/external_view_embedder.cc // |ExternalViewEmbedder| SkCanvas* AndroidExternalViewEmbedder::GetRootCanvas() { // On Android, the root surface is created from the on-screen render target.  return nullptr; } surface_-\u0026gt;AcquireFrame // |Surface| std::unique_ptr\u0026lt;SurfaceFrame\u0026gt; GPUSurfaceGL::AcquireFrame(const SkISize\u0026amp; size) { if (delegate_ == nullptr) { return nullptr; } auto context_switch = delegate_-\u0026gt;GLContextMakeCurrent(); const auto root_surface_transformation = GetRootTransformation(); sk_sp\u0026lt;SkSurface\u0026gt; surface = AcquireRenderSurface(size, root_surface_transformation); surface-\u0026gt;getCanvas()-\u0026gt;setMatrix(root_surface_transformation); SurfaceFrame::SubmitCallback submit_callback = [weak = weak_factory_.GetWeakPtr()](const SurfaceFrame\u0026amp; surface_frame, SkCanvas* canvas) { return weak ? weak-\u0026gt;PresentSurface(canvas) : false; }; return std::make_unique\u0026lt;SurfaceFrame\u0026gt;( surface, delegate_-\u0026gt;SurfaceSupportsReadback(), submit_callback, std::move(context_switch)); sk_sp\u0026lt;SkSurface\u0026gt; GPUSurfaceGL::AcquireRenderSurface( const SkISize\u0026amp; untransformed_size, const SkMatrix\u0026amp; root_surface_transformation) { if (!CreateOrUpdateSurfaces(transformed_size)) { return nullptr; } return onscreen_surface_; } bool GPUSurfaceGL::CreateOrUpdateSurfaces(const SkISize\u0026amp; size) { sk_sp\u0026lt;SkSurface\u0026gt; onscreen_surface; GLFrameInfo frame_info = {static_cast\u0026lt;uint32_t\u0026gt;(size.width()), static_cast\u0026lt;uint32_t\u0026gt;(size.height())}; const uint32_t fbo_id = delegate_-\u0026gt;GLContextFBO(frame_info); onscreen_surface = WrapOnscreenSurface(context_.get(), // GL context  size, // root surface size  fbo_id // window FBO ID  ); onscreen_surface_ = std::move(onscreen_surface); fbo_id_ = fbo_id; return true; } compositor_frame-\u0026gt;Raster layer_tree.Paint //flow/compositor_context.cc RasterStatus CompositorContext::ScopedFrame::Raster( flutter::LayerTree\u0026amp; layer_tree, bool ignore_raster_cache) { layer_tree.Paint(*this, ignore_raster_cache); } void LayerTree::Paint(CompositorContext::ScopedFrame\u0026amp; frame, bool ignore_raster_cache) const { if (root_layer_-\u0026gt;needs_painting(context)) { root_layer_-\u0026gt;Paint(context);//main  } } void ContainerLayer::Paint(PaintContext\u0026amp; context) const { FML_DCHECK(needs_painting(context)); PaintChildren(context); } //下面的两个Paint相关方法会递归进行调用，直到进入PhysicalShapeLayerg或PictureLayer等具体的child layer void ContainerLayer::PaintChildren(PaintContext\u0026amp; context) const { // We can no longer call FML_DCHECK here on the needs_painting(context)  // condition as that test is only valid for the PaintContext that  // is initially handed to a layer\u0026#39;s Paint() method. By the time the  // layer calls PaintChildren(), though, it may have modified the  // PaintContext so the test doesn\u0026#39;t work in this \u0026#34;context\u0026#34;.  // Intentionally not tracing here as there should be no self-time  // and the trace event on this common function has a small overhead.  for (auto\u0026amp; layer : layers_) { if (layer-\u0026gt;needs_painting(context)) { layer-\u0026gt;Paint(context); } } } void TransformLayer::Paint(PaintContext\u0026amp; context) const { SkAutoCanvasRestore save(context.internal_nodes_canvas, true); context.internal_nodes_canvas-\u0026gt;concat(transform_); PaintChildren(context); } void PhysicalShapeLayer::Paint(PaintContext\u0026amp; context) const { // Call drawPath without clip if possible for better performance.  SkPaint paint; paint.setColor(color_); paint.setAntiAlias(true); if (clip_behavior_ != Clip::antiAliasWithSaveLayer) { context.leaf_nodes_canvas-\u0026gt;drawPath(path_, paint);//main  } void SkCanvas::drawPath(const SkPath\u0026amp; path, const SkPaint\u0026amp; paint) { TRACE_EVENT0(\u0026#34;skia\u0026#34;, TRACE_FUNC); this-\u0026gt;onDrawPath(path, paint); } void SkCanvas::onDrawPath(const SkPath\u0026amp; path, const SkPaint\u0026amp; paint) { AutoLayerForImageFilter layer(this, paint, \u0026amp;pathBounds); this-\u0026gt;topDevice()-\u0026gt;drawPath(path, layer.paint()); } void SkGpuDevice::drawPath(const SkPath\u0026amp; origSrcPath, const SkPaint\u0026amp; paint, bool pathIsMutable) { if (!paint.getMaskFilter()) { fSurfaceDrawContext-\u0026gt;drawPath(this-\u0026gt;clip(), std::move(grPaint), fSurfaceDrawContext-\u0026gt;chooseAA(paint), this-\u0026gt;localToDevice(), origSrcPath, GrStyle(paint)); return; } } void GrSurfaceDrawContext::drawPath(const GrClip* clip, GrPaint\u0026amp;\u0026amp; paint, GrAA aa, const SkMatrix\u0026amp; viewMatrix, const SkPath\u0026amp; path, const GrStyle\u0026amp; style) { GrStyledShape shape(path, style, DoSimplify::kNo); this-\u0026gt;drawShape(clip, std::move(paint), aa, viewMatrix, std::move(shape)); } void GrSurfaceDrawContext::drawShape(const GrClip* clip, GrPaint\u0026amp;\u0026amp; paint, GrAA aa, const SkMatrix\u0026amp; viewMatrix, GrStyledShape\u0026amp;\u0026amp; shape) { // If we get here in drawShape(), we definitely need to use path rendering  this-\u0026gt;drawShapeUsingPathRenderer(clip, std::move(paint), aa, viewMatrix, std::move(shape), /* attemptDrawSimple */ true); } addDrawOp #通过这里后续的条用堆栈可以看出，draw过程在native层也是添加drawOperation进行绘制命令的配置 GrOpsTask::OpChain::appendOp(std::__1::unique_ptr\u0026lt;GrOp, std::__1::default_delete\u0026lt;GrOp\u0026gt; \u0026gt;, GrProcessorSet::Analysis, GrXferProcessor::DstProxyView const*, GrAppliedClip const*, GrCaps const\u0026amp;, SkArenaAlloc*, GrAuditTrail*) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrOpsTask.cpp:335) GrOpsTask::recordOp(std::__1::unique_ptr\u0026lt;GrOp, std::__1::default_delete\u0026lt;GrOp\u0026gt; \u0026gt;, GrProcessorSet::Analysis, GrAppliedClip*, GrXferProcessor::DstProxyView const*, GrCaps const\u0026amp;) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrOpsTask.cpp:988) GrOpsTask::addDrawOp(GrDrawingManager*, std::__1::unique_ptr\u0026lt;GrOp, std::__1::default_delete\u0026lt;GrOp\u0026gt; \u0026gt;, GrDrawOp::FixedFunctionFlags, GrProcessorSet::Analysis const\u0026amp;, GrAppliedClip\u0026amp;\u0026amp;, GrXferProcessor::DstProxyView const\u0026amp;, GrTextureResolveManager, GrCaps const\u0026amp;) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrOpsTask.cpp:434) GrSurfaceDrawContext::addDrawOp(GrClip const*, std::__1::unique_ptr\u0026lt;GrOp, std::__1::default_delete\u0026lt;GrOp\u0026gt; \u0026gt;, std::__1::function\u0026lt;void (GrOp*, unsigned int)\u0026gt; const\u0026amp;) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrSurfaceDrawContext.cpp:1972) GrSurfaceDrawContext::drawFilledQuad(GrClip const*, GrPaint\u0026amp;\u0026amp;, GrAA, DrawQuad*, GrUserStencilSettings const*) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrSurfaceDrawContext.cpp:646) GrSurfaceDrawContext::fillRectToRect(GrClip const*, GrPaint\u0026amp;\u0026amp;, GrAA, SkMatrix const\u0026amp;, SkRect const\u0026amp;, SkRect const\u0026amp;) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrSurfaceDrawContext.cpp:836) GrSurfaceDrawContext::drawRect(GrClip const*, GrPaint\u0026amp;\u0026amp;, GrAA, SkMatrix const\u0026amp;, SkRect const\u0026amp;, GrStyle const*) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrSurfaceDrawContext.cpp:761) GrSurfaceDrawContext::drawSimpleShape(GrClip const*, GrPaint*, GrAA, SkMatrix const\u0026amp;, GrStyledShape const\u0026amp;) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrSurfaceDrawContext.cpp:1729) GrSurfaceDrawContext::drawShapeUsingPathRenderer(GrClip const*, GrPaint\u0026amp;\u0026amp;, GrAA, SkMatrix const\u0026amp;, GrStyledShape\u0026amp;\u0026amp;, bool) (/Users/qianpianpian/git/flutter/fork/engine/src/third_party/skia/src/gpu/GrSurfaceDrawContext.cpp:1814) frame-\u0026gt;Submit bool SurfaceFrame::Submit() { submitted_ = PerformSubmit();//main  return submitted_; } bool SurfaceFrame::PerformSubmit() { if (submit_callback_(*this, SkiaCanvas())) {//submit_callback_为前面acquireFrame时配置的submit_callback  return true; } return false; } SurfaceFrame::SubmitCallback submit_callback = [weak = weak_factory_.GetWeakPtr()](const SurfaceFrame\u0026amp; surface_frame, SkCanvas* canvas) { return weak ? weak-\u0026gt;PresentSurface(canvas) : false;//main  }; bool GPUSurfaceGL::PresentSurface(SkCanvas* canvas) { onscreen_surface_-\u0026gt;getCanvas()-\u0026gt;flush(); } void SkCanvas::flush() { this-\u0026gt;onFlush(); } void SkCanvas::onFlush() { #if SK_SUPPORT_GPU  auto dContext = GrAsDirectContext(this-\u0026gt;recordingContext()); if (dContext) { dContext-\u0026gt;flushAndSubmit();//main  } #endif } /** engine/src/third_party/skia/include/gpu/GrDirectContext.h * Call to ensure all drawing to the context has been flushed and submitted to the underlying 3D * API. This is equivalent to calling GrContext::flush with a default GrFlushInfo followed by * GrContext::submit(syncCpu). */ void flushAndSubmit(bool syncCpu = false) { this-\u0026gt;flush(GrFlushInfo()); this-\u0026gt;submit(syncCpu); } flush ///engine/src/third_party/skia/src/gpu/GrDirectContext.cpp GrSemaphoresSubmitted GrDirectContext::flush(const GrFlushInfo\u0026amp; info) { return this-\u0026gt;drawingManager()-\u0026gt;flushSurfaces({}, SkSurface::BackendSurfaceAccess::kNoAccess, info, nullptr); } submit bool GrDirectContext::submit(bool syncCpu) { if (!fGpu) { return false; } return fGpu-\u0026gt;submitToGpu(syncCpu); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/3hprof_binary_dump_format/",
	"title": "3Hprof_binary_dump_format",
	"tags": [],
	"description": "",
	"content": "JVM HPROF_查看_Binary Dump Format (format=b) graph LR STRING_IN_UTF8--\u0026gt;xxxx HEAP_DUMP_SEGMENT--\u0026gt;ROOT_UNKNOWN HEAP_DUMP_SEGMENT--\u0026gt;ROOT_JNI_GLOBAL HEAP_DUMP_SEGMENT--\u0026gt;...... HEAP_DUMP_SEGMENT--\u0026gt;CLASS_DUMP HEAP_DUMP_SEGMENT--\u0026gt;INSTANCE_DUMP HEAP_DUMP_SEGMENT--\u0026gt;OBJECT_ARRAY_DUMP HEAP_DUMP_SEGMENT--\u0026gt;PRIMITIVE_ARRAY_DUMP HEAP_DUMP_END--\u0026gt;xxx Binary Dump Format (format=b) The basic fields in the binary output are u1 (1 byte), u2 (2 byte), u4 (4 byte), and u8 (8 byte). An ID in this implementation is a u4, however the size of an ID is really determined by the \u0026ldquo;size of identifiers\u0026rdquo; field in the header.\nWARNING: This format is still considered highly experimental, however, all attempts were made to match the format of past HPROF implementations.\nThe binary output begins with the information:\nHeader    [u1]* An initial NULL terminated series of bytes representing the format name and version, in this implementation and historically, the string \u0026ldquo;JAVA PROFILE 1.0.1\u0026rdquo; (18 u1 bytes) followed by a NULL byte. If the TAG \u0026ldquo;HEAP DUMP SEGMENT\u0026rdquo; is used this string will be \u0026ldquo;JAVA PROFILE 1.0.2\u0026rdquo;.     u4 size of identifiers. Identifiers are used to represent UTF8 strings, objects, stack traces, etc. They can have the same size as host pointers or sizeof(void*), but are not required to be.   u4 high word of number of milliseconds since 0:00 GMT, 1/1/70   u4 low word of number of milliseconds since 0:00 GMT, 1/1/70    Records Followed by a sequence of records that look like:\n   u1 TAG: denoting the type of the record     u4 TIME: number of microseconds since the time stamp in the header   u4 LENGTH: number of bytes that follow this u4 field and belong to this record   [u1]* BODY: as many bytes as specified in the above u4 field    The following TAGs are supported:\n\u0026hellip;\u0026hellip;\nHEAP DUMP or HEAP DUMP SEGMENT    HEAP DUMP or HEAP DUMP SEGMENT 0x0C or 0x1C Contains any number of sub-tags(as body), each begins a u1 field (no order implied here):     HEAP DUMP END 0x2C Terminates a series of HEAP DUMP SEGMENTS. Concatenation of HEAP DUMP SEGMENTS equals a HEAP DUMP.       ROOT UNKNOWN 0xFF ID object ID     ROOT JNI GLOBAL 0x01 ID object ID ID JNI global ref ID   ROOT JNI LOCAL 0x02 ID object ID u4 thread serial number u4 frame number in stack trace (-1 for empty)   ROOT JAVA FRAME 0x03 ID object ID u4 thread serial number u4 frame number in stack trace (-1 for empty)   ROOT NATIVE STACK 0x04 ID object ID u4 thread serial number   ROOT STICKY CLASS 0x05 ID object ID   ROOT THREAD BLOCK 0x06 ID object ID u4 thread serial number   ROOT MONITOR USED 0x07 ID object ID   ROOT THREAD OBJECT 0x08 ID thread object ID u4 thread serial number u4 stack trace serial number   CLASS DUMP 0x20    INSTANCE DUMP 0x21    OBJECT ARRAY DUMP 0x22    PRIMITIVE ARRAY DUMP 0x23     CLASS DUMP    ID class object ID     u4 stack trace serial number   ID super class object ID   ID class loader object ID   ID signers object ID   ID protection domain object ID   ID reserved   ID reserved   u4 instance size (in bytes)   u2 size of constant pool and number of records that follow: u2 constant pool index u1 type of entry: (See Basic Type) value value of entry (u1, u2, u4, or u8 based on type of entry)   u2 Number of static fields: ID static field name string ID u1 type of field: (See Basic Type) value value of entry (u1, u2, u4, or u8 based on type of field)   u2 Number of instance fields (not including super class\u0026rsquo;s) ID field name string ID u1 type of field: (See Basic Type)    INSTANCE DUMP    ID object ID     u4 stack trace serial number   ID class object ID   u4 number of bytes that follow   [value]* instance field values (this class, followed by super class, etc)    OBJECT ARRAY DUMP    ID array object ID     u4 stack trace serial number   u4 number of elements   ID array class object ID   [ID]* elements    PRIMITIVE ARRAY DUMP    ID array object ID     u4 stack trace serial number   u4 number of elements   u1 element type (See Basic Type)   [u1]* elements (packed array)    HEAP DUMP INFO\u0026ndash;Android meaning that heap type have changed\nAndroid Studio Hprof Android Hprof\nsrc/main/java/com/android/tools/perflib/heap/HprofParser.java\nShark Hprof shark-hprof/src/main/java/shark/Hprof.kt\n/** * Reads the headers of the provided [hprofFile] and returns an opened [Hprof]. Don\u0026#39;t forget * to call [close] once done. */ fun open(hprofFile: File): Hprof { val endOfVersionString = source.indexOf(0) val versionName = source.readUtf8(endOfVersionString) // Skip the 0 at the end of the version string.  source.skip(1) val identifierByteSize = source.readInt() // heap dump timestamp  val heapDumpTimestamp = source.readLong() val reader = HprofReader(source, identifierByteSize, byteReadCount) return Hprof( channel, source, reader, heapDumpTimestamp, hprofVersion, fileLength ) "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/3viewmodel/",
	"title": "3viewmodel",
	"tags": [],
	"description": "",
	"content": "3viewmodel 探索总结3viewmodel知识\n SaveAndRestoreInstanceState     SavedStateHandle     SavingStates     ViewModel     ViewModelScope_Delegate     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%93%8D%E5%BA%94%E5%BC%8F%E6%9E%B6%E6%9E%84/3%E5%BC%82%E6%AD%A5_%E5%93%8D%E5%BA%94%E5%BC%8F_%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/",
	"title": "3异步_响应式_状态管理",
	"tags": [],
	"description": "",
	"content": "状态管理 graph LR StateMangement--\u0026gt;BLOC/Stream+StreamBuilder/Rxdart StateMangement--\u0026gt;Redux StateMangement--\u0026gt;Provider/ScopedModel rxdart https://pub.dev/packages/rxdart\n   Dart RxDart     Stream Observable   StreamController Subject    redux Flutter Fish Redux架构演进2.0\nhttps://pub.dev/packages/flutter_redux\nhttps://pub.dev/packages/fish_redux\nStroreProver和ChangeNotifierProvider是基于InheritedWidget，而BlocProvider不是\nProvider基于context.getElementForInheritedWidgetOfExactType\u0026lt;_DefaultInheritedProviderScope\u0026gt;跨组件获取数据\n而BlocProvider是基于: BlocProviderprovider = context.ancestorWidgetOfExactType(type);跨组件获取数据\ngraph LR subgraph redux StoreProvider StoreConnector Store end StoreProvider--\u0026gt;|similar|ChangeNotifierProvider StoreConnector--\u0026gt;|similar|Consumer Store--\u0026gt;|similar|ChangeNotifier subgraph provider ChangeNotifierProvider Consumer ChangeNotifier end subgraph BLOC/Stream+StreamBuilder ChangeNotifierProvider--\u0026gt;|similar|BlocProvider ChangeNotifier--\u0026gt;|similar|XxxBloc Consumer--\u0026gt;|similar|BlocProvider.of end  state-mgmt https://flutter.dev/docs/development/data-and-backend/state-mgmt\nhttps://flutter.dev/docs/development/data-and-backend/state-mgmt/options\nephemeral state and app state When asked about React’s setState versus Redux’s store, the author of Redux, Dan Abramov, replied:\n“The rule of thumb is: Do whatever is less awkward.”\nIn summary, there are two conceptual types of state in any Flutter app. Ephemeral state can be implemented using State and setState(), and is often local to a single widget. The rest is your app state. Both types have their place in any Flutter app, and the split between the two depends on your own preference and the complexity of the app.\nSimple app state management On this page, we are going to be using the provider package. If you are new to Flutter and you don’t have a strong reason to choose another approach (Redux, Rx, hooks, etc.), this is probably the approach you should start with. ==The provider package== is easy to understand and it doesn’t use much code. It also uses concepts that are applicable in every other approach.\nWith provider, you don’t need to worry about callbacks or InheritedWidgets. But you do need to understand 3 concepts:\n ChangeNotifier ChangeNotifierProvider Consumer   provider https://pub.dev/packages/provider\nhttps://pub.dev/documentation/provider/latest/\nConsumer Selector 参考 Future https://api.dartlang.org/stable/2.0.0/dart-async/Future-class.html\nsetState+globalKey 实现按需build setState重绘的核心有两个:\n ==Model值的变更== ==适当节点的rebuild替换==  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/4binderkernel/",
	"title": "4BinderKernel",
	"tags": [],
	"description": "",
	"content": "图解binder_ioctl graph TB binder_ioctl--\u0026gt;|case BINDER_WRITE_READ|binder_ioctl_write_read binder_ioctl_write_read--\u0026gt;copy_from_user(\u0026quot;copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr));\u0026quot;) binder_ioctl_write_read--\u0026gt;|bwr.write_size \u0026gt; 0|binder_thread_write binder_ioctl_write_read--\u0026gt;|bwr.read_size \u0026gt; 0|binder_thread_read binder_ioctl_write_read--\u0026gt;copy_to_user(\u0026quot;copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr))\u0026quot;) binder_thread_write--\u0026gt;|拷贝用户空间的cmd命令|get_user(\u0026quot;get_user(cmd, (uint32_t __user *)ptr)\u0026quot;)--\u0026gt;|case BC_TRANSACTION:拷贝用户空间的binder_transaction_data|binder_transaction(\u0026quot;binder_transaction(proc, thread, \u0026amp;tr,cmd == BC_REPLY, 0)\u0026quot;)--\u0026gt;|handle=0则找到servicemanager实体|service_manager(\u0026quot;context-\u0026gt;binder_context_mgr_node\u0026quot;) subgraph 得到binder_node-\u0026gt;proc,也就是binder_proc*类型的target_proc binder_get_node_refs_for_txn end subgraph open系统调用时返回的fd信息的private_data里是binder_proc,而mmap过程会修改这个binder_proc的alloc字段信息,从而确保申请的内存位于target process对应的内核空间 binder_alloc_new_buf end service_manager--\u0026gt;binder_get_node_refs_for_txn(\u0026quot;binder_get_node_refs_for_txn(target_node, \u0026amp;target_proc,\u0026amp;return_error);\u0026quot;) subgraph 从rbTree中找到ref-\u0026gt;data.desc等于入参handle的binder_ref将其返回 binder_get_ref_olocked end binder_transaction--\u0026gt;|target.handle \u0026gt; 0|binder_get_ref_olocked(\u0026quot;binder_get_ref_olocked(proc, tr-\u0026gt;target.handle,true)\u0026quot;) binder_get_ref_olocked--\u0026gt;|传递ref-\u0026gt;node作为binder_node参数|binder_get_node_refs_for_txn binder_get_node_refs_for_txn--\u0026gt;binder_alloc_new_buf(\u0026quot;t-\u0026gt;buffer = binder_alloc_new_buf(\u0026amp;target_proc-\u0026gt;alloc,...\u0026quot;) subgraph queues a transaction to binder_proc, find a thread in binder_proc to handle the transaction and wake it up. If no thread is found, the work is queued to the proc waitqueue. subgraph If the thread parameter is not NULL, the transaction is always queued to the waitlist of that specific thread. binder_proc_transaction end end binder_alloc_new_buf--\u0026gt;binder_proc_transaction(\u0026quot;binder_proc_transaction(struct binder_transaction *t, struct binder_proc *proc,struct binder_thread *thread)\u0026quot;) subgraph Linux系统API wake_up_interruptible end binder_proc_transaction--\u0026gt;wake_up_interruptible binder_write_read struct binder_write_read { binder_size_t\twrite_size;\t/* bytes to write */ binder_size_t\twrite_consumed;\t/* bytes consumed by driver */ binder_uintptr_t\twrite_buffer; binder_size_t\tread_size;\t/* bytes to read */ binder_size_t\tread_consumed;\t/* bytes consumed by driver */ binder_uintptr_t\tread_buffer; }; binder_transaction_data struct binder_transaction_data { /* The first two are only used for bcTRANSACTION and brTRANSACTION, * identifying the target and contents of the transaction. */ union { /* target descriptor of command transaction */ __u32\thandle; /* target descriptor of return transaction */ binder_uintptr_t ptr; } target; binder_uintptr_t\tcookie;\t/* target object cookie */ __u32\tcode;\t/* transaction command */ /* General information about the transaction. */ __u32\tflags; pid_t\tsender_pid; uid_t\tsender_euid; binder_size_t\tdata_size;\t/* number of bytes of data */ binder_size_t\toffsets_size;\t/* number of bytes of offsets */ /* If this transaction is inline, the data immediately * follows here; otherwise, it ends with a pointer to * the data buffer. */ union { struct { /* transaction data */ binder_uintptr_t\tbuffer; /* offsets from buffer to flat_binder_object structs */ binder_uintptr_t\toffsets; } ptr; __u8\tbuf[8]; } data; }; drivers/android/binder.c\nbinder.c binder_ioctl static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { int ret; struct binder_proc *proc = filp-\u0026gt;private_data; switch (cmd) { case BINDER_WRITE_READ: ret = binder_ioctl_write_read(filp, cmd, arg, thread); } } binder_ioctl_write_read static int binder_ioctl_write_read(struct file *filp, unsigned int cmd, unsigned long arg, struct binder_thread *thread) { int ret = 0; struct binder_proc *proc = filp-\u0026gt;private_data; unsigned int size = _IOC_SIZE(cmd); void __user *ubuf = (void __user *)arg; struct binder_write_read bwr; //将用户空间bwr结构体拷贝到内核空间  copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr)); binder_debug(BINDER_DEBUG_READ_WRITE, \u0026#34;%d:%d write %lld at %016llx, read %lld at %016llx\\n\u0026#34;, proc-\u0026gt;pid, thread-\u0026gt;pid, (u64)bwr.write_size, (u64)bwr.write_buffer, (u64)bwr.read_size, (u64)bwr.read_buffer); if (bwr.write_size \u0026gt; 0) { //将数据放入目标进程 \tret = binder_thread_write(proc, thread, bwr.write_buffer, bwr.write_size, \u0026amp;bwr.write_consumed); } if (bwr.read_size \u0026gt; 0) { //读取自己队列的数据 \tret = binder_thread_read(proc, thread, bwr.read_buffer, bwr.read_size, \u0026amp;bwr.read_consumed, filp-\u0026gt;f_flags \u0026amp; O_NONBLOCK); } //将内核空间bwr结构体拷贝到用户空间  copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr)) return ret; } binder_thread_write static int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed) { uint32_t cmd; struct binder_context *context = proc-\u0026gt;context; void __user *buffer = (void __user *)(uintptr_t)binder_buffer; void __user *ptr = buffer + *consumed; void __user *end = buffer + size; while (ptr \u0026lt; end \u0026amp;\u0026amp; thread-\u0026gt;return_error.cmd == BR_OK) { if (get_user(cmd, (uint32_t __user *)ptr))////拷贝用户空间的cmd命令，此时为BC_TRANSACTION \treturn -EFAULT; ptr += sizeof(uint32_t); switch (cmd) { case BC_TRANSACTION: case BC_REPLY: { struct binder_transaction_data tr; //拷贝用户空间的binder_transaction_data \tif (copy_from_user(\u0026amp;tr, ptr, sizeof(tr))) return -EFAULT; ptr += sizeof(tr); binder_transaction(proc, thread, \u0026amp;tr, cmd == BC_REPLY, 0); break; } } binder_transaction static void binder_transaction(struct binder_proc *proc, struct binder_thread *thread, struct binder_transaction_data *tr, int reply, binder_size_t extra_buffers_size) { struct binder_proc *target_proc = NULL; struct binder_thread *target_thread = NULL; struct binder_node *target_node = NULL; if (reply) { ...... } else { if (tr-\u0026gt;target.handle) { struct binder_ref *ref; binder_proc_lock(proc); ref = binder_get_ref_olocked(proc, tr-\u0026gt;target.handle, true); if (ref) { target_node = binder_get_node_refs_for_txn( ref-\u0026gt;node, \u0026amp;target_proc, \u0026amp;return_error); } else { binder_user_error(\u0026#34;%d:%d got transaction to invalid handle\\n\u0026#34;,proc-\u0026gt;pid, thread-\u0026gt;pid);...... } binder_proc_unlock(proc); } else { // handle=0则找到servicemanager实体 \tmutex_lock(\u0026amp;context-\u0026gt;context_mgr_node_lock); target_node = context-\u0026gt;binder_context_mgr_node; if (target_node) target_node = binder_get_node_refs_for_txn( target_node, \u0026amp;target_proc, \u0026amp;return_error); else return_error = BR_DEAD_REPLY; mutex_unlock(\u0026amp;context-\u0026gt;context_mgr_node_lock); } t-\u0026gt;buffer = binder_alloc_new_buf(\u0026amp;target_proc-\u0026gt;alloc, tr-\u0026gt;data_size, tr-\u0026gt;offsets_size, extra_buffers_size, !reply \u0026amp;\u0026amp; (t-\u0026gt;flags \u0026amp; TF_ONE_WAY)); ...... if (reply) { ...... } else if (!(t-\u0026gt;flags \u0026amp; TF_ONE_WAY)) { BUG_ON(t-\u0026gt;buffer-\u0026gt;async_transaction != 0); /* * Defer the TRANSACTION_COMPLETE, so we don\u0026#39;t return to * userspace immediately; this allows the target process to * immediately start processing this transaction, reducing * latency. We will then return the TRANSACTION_COMPLETE when * the target replies (or there is an error). */ binder_enqueue_deferred_thread_work_ilocked(thread, tcomplete); t-\u0026gt;need_reply = 1; t-\u0026gt;from_parent = thread-\u0026gt;transaction_stack; thread-\u0026gt;transaction_stack = t; if (!binder_proc_transaction(t, target_proc, target_thread)) { ...... goto err_dead_proc_or_thread; } } else { BUG_ON(target_node == NULL); BUG_ON(t-\u0026gt;buffer-\u0026gt;async_transaction != 1); binder_enqueue_thread_work(thread, tcomplete); if (!binder_proc_transaction(t, target_proc, NULL)) goto err_dead_proc_or_thread; } binder_alloc_new_buf /** * binder_alloc_new_buf() - Allocate a new binder buffer * @alloc: binder_alloc for this proc * @data_size: size of user data buffer * @offsets_size: user specified buffer offset * @extra_buffers_size: size of extra space for meta-data (eg, security context) * @is_async: buffer for async transaction * * Allocate a new buffer given the requested sizes. Returns * the kernel version of the buffer pointer. The size allocated * is the sum of the three given sizes (each rounded up to * pointer-sized boundary) * * Return:\tThe allocated buffer or %NULL if error */ struct binder_buffer *binder_alloc_new_buf(struct binder_alloc *alloc, size_t data_size, size_t offsets_size, size_t extra_buffers_size, int is_async) { struct binder_buffer *buffer; mutex_lock(\u0026amp;alloc-\u0026gt;mutex); buffer = binder_alloc_new_buf_locked(alloc, data_size, offsets_size, extra_buffers_size, is_async); mutex_unlock(\u0026amp;alloc-\u0026gt;mutex); return buffer; } binder_get_ref_olocked static struct binder_ref *binder_get_ref_olocked(struct binder_proc *proc, u32 desc, bool need_strong_ref) { struct rb_node *n = proc-\u0026gt;refs_by_desc.rb_node; struct binder_ref *ref; while (n) { ref = rb_entry(n, struct binder_ref, rb_node_desc); if (desc \u0026lt; ref-\u0026gt;data.desc) { n = n-\u0026gt;rb_left; } else if (desc \u0026gt; ref-\u0026gt;data.desc) { n = n-\u0026gt;rb_right; } else if (need_strong_ref \u0026amp;\u0026amp; !ref-\u0026gt;data.strong) { binder_user_error(\u0026#34;tried to use weak ref as strong ref\\n\u0026#34;); return NULL; } else { return ref; } } return NULL; } binder_get_node_refs_for_txn /** Return: The target_node with refs taken or NULL if no @node-\u0026gt;proc is NULL. * Also sets @proc if valid. If the @node-\u0026gt;proc is NULL indicating that the * target proc has died, @error is set to BR_DEAD_REPLY */ static struct binder_node *binder_get_node_refs_for_txn( struct binder_node *node, struct binder_proc **procp, uint32_t *error) { struct binder_node *target_node = NULL; binder_node_inner_lock(node); if (node-\u0026gt;proc) { target_node = node; binder_inc_node_nilocked(node, 1, 0, NULL); binder_inc_node_tmpref_ilocked(node); node-\u0026gt;proc-\u0026gt;tmp_ref++; *procp = node-\u0026gt;proc; } else *error = BR_DEAD_REPLY; binder_node_inner_unlock(node); return target_node; } struct binder_ref struct binder_ref { /* Lookups needed: */ /* node + proc =\u0026gt; ref (transaction) */ /* desc + proc =\u0026gt; ref (transaction, inc/dec ref) */ /* node =\u0026gt; refs + procs (proc exit) */ struct binder_ref_data data; struct rb_node rb_node_desc; struct rb_node rb_node_node; struct hlist_node node_entry; struct binder_proc *proc; struct binder_node *node; struct binder_ref_death *death; }; binder_proc_transaction /** * binder_proc_transaction() - sends a transaction to a process and wakes it up * @t:\ttransaction to send * @proc:\tprocess to send the transaction to * @thread:\tthread in @proc to send the transaction to (may be NULL) * * This function queues a transaction to the specified process. It will try * to find a thread in the target process to handle the transaction and * wake it up. If no thread is found, the work is queued to the proc * waitqueue. * * If the @thread parameter is not NULL, the transaction is always queued * to the waitlist of that specific thread. * * Return:\ttrue if the transactions was successfully queued *\tfalse if the target process or thread is dead */ static bool binder_proc_transaction(struct binder_transaction *t, struct binder_proc *proc, struct binder_thread *thread) { struct binder_node *node = t-\u0026gt;buffer-\u0026gt;target_node; struct binder_priority node_prio; bool oneway = !!(t-\u0026gt;flags \u0026amp; TF_ONE_WAY); bool pending_async = false; if (oneway) { BUG_ON(thread); if (node-\u0026gt;has_async_transaction) { pending_async = true; } else { node-\u0026gt;has_async_transaction = 1; } } if (!thread \u0026amp;\u0026amp; !pending_async) thread = binder_select_thread_ilocked(proc); if (thread) { binder_transaction_priority(thread-\u0026gt;task, t, node_prio, node-\u0026gt;inherit_rt); binder_enqueue_thread_work_ilocked(thread, \u0026amp;t-\u0026gt;work); } else if (!pending_async) { binder_enqueue_work_ilocked(\u0026amp;t-\u0026gt;work, \u0026amp;proc-\u0026gt;todo); } else { binder_enqueue_work_ilocked(\u0026amp;t-\u0026gt;work, \u0026amp;node-\u0026gt;async_todo); } if (!pending_async) binder_wakeup_thread_ilocked(proc, thread, !oneway /* sync */); return true; } binder_wakeup_thread_ilocked /** * binder_wakeup_thread_ilocked() - wakes up a thread for doing proc work. * @proc:\tprocess to wake up a thread in * @thread:\tspecific thread to wake-up (may be NULL) * @sync:\twhether to do a synchronous wake-up * * This function wakes up a thread in the @proc process. * The caller may provide a specific thread to wake-up in * the @thread parameter. If @thread is NULL, this function * will wake up threads that have called poll(). * * Note that for this function to work as expected, callers * should first call binder_select_thread() to find a thread * to handle the work (if they don\u0026#39;t have a thread already), * and pass the result into the @thread parameter. */ static void binder_wakeup_thread_ilocked(struct binder_proc *proc, struct binder_thread *thread, bool sync) { assert_spin_locked(\u0026amp;proc-\u0026gt;inner_lock); if (thread) { if (sync) wake_up_interruptible_sync(\u0026amp;thread-\u0026gt;wait); else wake_up_interruptible(\u0026amp;thread-\u0026gt;wait); return; } /* Didn\u0026#39;t find a thread waiting for proc work; this can happen * in two scenarios: * 1. All threads are busy handling transactions * In that case, one of those threads should call back into * the kernel driver soon and pick up this work. * 2. Threads are using the (e)poll interface, in which case * they may be blocked on the waitqueue without having been * added to waiting_threads. For this case, we just iterate * over all threads not handling transaction work, and * wake them all up. We wake all because we don\u0026#39;t know whether * a thread that called into (e)poll is handling non-binder * work currently. */ binder_wakeup_poll_threads_ilocked(proc, sync); } include/linux/wait.h\nwait.h #define wake_up_interruptible(x)\t__wake_up(x, TASK_INTERRUPTIBLE, 1, NULL) #define wake_up_interruptible_nr(x, nr)\t__wake_up(x, TASK_INTERRUPTIBLE, nr, NULL) #define wake_up_interruptible_all(x)\t__wake_up(x, TASK_INTERRUPTIBLE, 0, NULL) #define wake_up_interruptible_sync(x)\t__wake_up_sync((x), TASK_INTERRUPTIBLE, 1) drivers/android/binder_alloc.h\nbinder_alloc.h struct binder_alloc /** * struct binder_alloc - per-binder proc state for binder allocator * @vma: vm_area_struct passed to mmap_handler * (invarient after mmap) * @tsk: tid for task that called init for this proc * (invariant after init) * @vma_vm_mm: copy of vma-\u0026gt;vm_mm (invarient after mmap) * @buffer: base of per-proc address space mapped via mmap * @user_buffer_offset: offset between user and kernel VAs for buffer * @buffers: list of all buffers for this proc * @free_buffers: rb tree of buffers available for allocation * sorted by size * @allocated_buffers: rb tree of allocated buffers sorted by address * @free_async_space: VA space available for async buffers. This is * initialized at mmap time to 1/2 the full VA space * @pages: array of binder_lru_page * @buffer_size: size of address space specified via mmap * @pid: pid for associated binder_proc (invariant after init) * @pages_high: high watermark of offset in @pages * * Bookkeeping structure for per-proc address space management for binder * buffers. It is normally initialized during binder_init() and binder_mmap() * calls. The address space is used for both user-visible buffers and for * struct binder_buffer objects used to track the user buffers */ //open系统调用时返回的fd信息的private_data里是binder_proc，而mmap过程会修改这个binder_proc的alloc字段信息，从而确保申请的内存位于target process对应的内核空间 struct binder_alloc { } include/linux/rbtree.h\nrbtree.h//红黑树 rb_node struct rb_node { unsigned long __rb_parent_color; struct rb_node *rb_right; struct rb_node *rb_left; } __attribute__((aligned(sizeof(long)))); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/4dumphprof/",
	"title": "4DumpHprof",
	"tags": [],
	"description": "",
	"content": "graph LR subgraph Visit runtime.VisitRoots runtime.heap.VisitObjectsPaused end subgraph suspend ScopedSuspendAll end subgraph Dump DumpHeapClass DumpHeapInstanceObject DumpHeapArray end hprof::DumpHeap--\u0026gt;ScopedSuspendAll hprof::DumpHeap--\u0026gt;runtime.VisitRoots--\u0026gt;Hprof::VisitRoot hprof::DumpHeap--\u0026gt;runtime.heap.VisitObjectsPaused--\u0026gt;DumpHeapObject DumpHeapObject--\u0026gt;obj.VisitReferences DumpHeapObject--\u0026gt;DumpHeapClass DumpHeapObject--\u0026gt;DumpHeapInstanceObject DumpHeapObject--\u0026gt;DumpHeapArray art/runtime/native/dalvik_system_VMDebug.cc\nVMDebug_dumpHprofData /* * static void dumpHprofData(String fileName, FileDescriptor fd) * * Cause \u0026#34;hprof\u0026#34; data to be dumped. We can throw an IOException if an * error occurs during file handling. */ static void VMDebug_dumpHprofData(JNIEnv* env, jclass, jstring javaFilename, jint javaFd) { std::string filename; if (javaFilename != nullptr) { ScopedUtfChars chars(env, javaFilename); if (env-\u0026gt;ExceptionCheck()) { return; } filename = chars.c_str(); } else { filename = \u0026#34;[fd]\u0026#34;; } int fd = javaFd; hprof::DumpHeap(filename.c_str(), fd, false); libnativehelper/header_only_include/nativehelper/scoped_utf_chars.h\nScopedUtfChars(JNIEnv* env, jstring s) : env_(env), string_(s) { if (s == nullptr) { utf_chars_ = nullptr; jniThrowNullPointerException(env, nullptr); } else { utf_chars_ = env-\u0026gt;GetStringUTFChars(s, nullptr); } } art/runtime/hprof/hprof.cc\nclass Hprof : public SingleRootVisitor { hprof::DumpHeap // If \u0026#34;direct_to_ddms\u0026#34; is true, the other arguments are ignored, and data is // sent directly to DDMS. // If \u0026#34;fd\u0026#34; is \u0026gt;= 0, the output will be written to that file descriptor. // Otherwise, \u0026#34;filename\u0026#34; is used to create an output file. void DumpHeap(const char* filename, int fd, bool direct_to_ddms) { CHECK(filename != nullptr); Thread* self = Thread::Current(); // Need to take a heap dump while GC isn\u0026#39;t running. See the comment in Heap::VisitObjects().  // Also we need the critical section to avoid visiting the same object twice. See b/34967844  gc::ScopedGCCriticalSection gcs(self, gc::kGcCauseHprof, gc::kCollectorTypeHprof); ScopedSuspendAll ssa(__FUNCTION__, true /* long suspend */); Hprof hprof(filename, fd, direct_to_ddms); hprof.Dump(); } art/runtime/thread_list.cc\nScopedSuspendAll ScopedSuspendAll::ScopedSuspendAll(const char* cause, bool long_suspend) { Runtime::Current()-\u0026gt;GetThreadList()-\u0026gt;SuspendAll(cause, long_suspend); } hprof.Dump void Dump() REQUIRES(Locks::mutator_lock_) REQUIRES(!Locks::heap_bitmap_lock_, !Locks::alloc_tracker_lock_) { { // First pass to measure the size of the dump.  size_t overall_size; size_t max_length; { EndianOutput count_output; output_ = \u0026amp;count_output; ProcessHeap(false); overall_size = count_output.SumLength(); max_length = count_output.MaxLength(); output_ = nullptr; } void ProcessHeap(bool header_first) REQUIRES(Locks::mutator_lock_) { ...... if (header_first) { ProcessHeader(true); ProcessBody(); } else { ProcessBody(); ProcessHeader(false); } } ProcessBody void ProcessBody() REQUIRES(Locks::mutator_lock_) { Runtime* const runtime = Runtime::Current(); // Walk the roots and the heap.  output_-\u0026gt;StartNewRecord(HPROF_TAG_HEAP_DUMP_SEGMENT, kHprofTime); simple_roots_.clear(); runtime-\u0026gt;VisitRoots(this); runtime-\u0026gt;VisitImageRoots(this); //method callback params  auto dump_object = [this](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_) { DCHECK(obj != nullptr); DumpHeapObject(obj); }; runtime-\u0026gt;GetHeap()-\u0026gt;VisitObjectsPaused(dump_object); output_-\u0026gt;StartNewRecord(HPROF_TAG_HEAP_DUMP_END, kHprofTime); output_-\u0026gt;EndRecord(); } StartNewRecord void StartNewRecord(uint8_t tag, uint32_t time) { if (length_ \u0026gt; 0) { EndRecord(); } AddU1(tag); AddU4(time); AddU4(0xdeaddead); // Length, replaced on flush.  started_ = true; } runtime-\u0026gt;VisitRoots(this)\u0026ndash;\u0026gt;Hprof::VisitRoot void Hprof::VisitRoot(mirror::Object* obj, const RootInfo\u0026amp; info) { static const HprofHeapTag xlate[] = { HPROF_ROOT_UNKNOWN, HPROF_ROOT_JNI_GLOBAL, HPROF_ROOT_JNI_LOCAL, HPROF_ROOT_JAVA_FRAME, HPROF_ROOT_NATIVE_STACK, HPROF_ROOT_STICKY_CLASS, HPROF_ROOT_THREAD_BLOCK, HPROF_ROOT_MONITOR_USED, HPROF_ROOT_THREAD_OBJECT, HPROF_ROOT_INTERNED_STRING, HPROF_ROOT_FINALIZING, HPROF_ROOT_DEBUGGER, HPROF_ROOT_REFERENCE_CLEANUP, HPROF_ROOT_VM_INTERNAL, HPROF_ROOT_JNI_MONITOR, }; CHECK_LT(info.GetType(), sizeof(xlate) / sizeof(HprofHeapTag)); if (obj == nullptr) { return; } MarkRootObject(obj, 0, xlate[info.GetType()], info.GetThreadId()); } void Hprof::MarkRootObject(const mirror::Object* obj, jobject jni_obj, HprofHeapTag heap_tag, uint32_t thread_serial) { switch (heap_tag) { // ID: object ID  case HPROF_ROOT_UNKNOWN: case HPROF_ROOT_STICKY_CLASS: case HPROF_ROOT_MONITOR_USED: case HPROF_ROOT_INTERNED_STRING: case HPROF_ROOT_DEBUGGER: case HPROF_ROOT_VM_INTERNAL: { uint64_t key = (static_cast\u0026lt;uint64_t\u0026gt;(heap_tag) \u0026lt;\u0026lt; 32) | PointerToLowMemUInt32(obj); if (simple_roots_.insert(key).second) { __ AddU1(heap_tag); __ AddObjectId(obj); } break; } ...... // ID: thread object ID  // U4: thread serial number  // U4: stack trace serial number  case HPROF_ROOT_THREAD_OBJECT: __ AddU1(heap_tag); __ AddObjectId(obj); __ AddU4(thread_serial); __ AddU4((uint32_t)-1); // xxx  break; case HPROF_CLASS_DUMP: case HPROF_INSTANCE_DUMP: case HPROF_OBJECT_ARRAY_DUMP: case HPROF_PRIMITIVE_ARRAY_DUMP: case HPROF_HEAP_DUMP_INFO: case HPROF_PRIMITIVE_ARRAY_NODATA_DUMP: // Ignored.  break; case HPROF_ROOT_FINALIZING: case HPROF_ROOT_REFERENCE_CLEANUP: case HPROF_UNREACHABLE: LOG(FATAL) \u0026lt;\u0026lt; \u0026#34;obsolete tag \u0026#34; \u0026lt;\u0026lt; static_cast\u0026lt;int\u0026gt;(heap_tag); break; } ++objects_in_segment_; runtime-\u0026gt;GetHeap()-\u0026gt;VisitObjectsPaused(dump_object)\u0026ndash;\u0026gt;DumpHeapObject obj-\u0026gt;VisitReferences void Hprof::DumpHeapObject(mirror::Object* obj) { // Ignore classes that are retired.  if (obj-\u0026gt;IsClass() \u0026amp;\u0026amp; obj-\u0026gt;AsClass()-\u0026gt;IsRetired()) { return; } ++total_objects_; RootCollector visitor; // Collect all native roots.  if (!obj-\u0026gt;IsClass()) { obj-\u0026gt;VisitReferences(visitor, VoidFunctor()); } ...... mirror::Class* c = obj-\u0026gt;GetClass(); if (c == nullptr) { // This object will bother HprofReader, because it has a null  // class, so just don\u0026#39;t dump it. It could be  // gDvm.unlinkedJavaLangClass or it could be an object just  // allocated which hasn\u0026#39;t been initialized yet.  } else { if (obj-\u0026gt;IsClass()) { DumpHeapClass(obj-\u0026gt;AsClass()); //HPROF_CLASS_DUMP  } else if (c-\u0026gt;IsArrayClass()) { DumpHeapArray(obj-\u0026gt;AsArray(), c); //HPROF_OBJECT_ARRAY_DUMP or HPROF_PRIMITIVE_ARRAY_DUMP  } else { DumpHeapInstanceObject(obj, c, visitor.GetRoots()); //HPROF_INSTANCE_DUMP  } } ++objects_in_segment_; DumpHeapInstanceObject void Hprof::DumpHeapInstanceObject(mirror::Object* obj, mirror::Class* klass, const std::set\u0026lt;mirror::Object*\u0026gt;\u0026amp; fake_roots) { // obj is an instance object.  __ AddU1(HPROF_INSTANCE_DUMP); __ AddObjectId(obj); __ AddStackTraceSerialNumber(LookupStackTraceSerialNumber(obj)); __ AddClassId(LookupClassId(klass)); // Reserve some space for the length of the instance data, which we won\u0026#39;t  // know until we\u0026#39;re done writing it.  size_t size_patch_offset = output_-\u0026gt;Length(); __ AddU4(0x77777777); // Write the instance data; fields for this class, followed by super class fields, and so on.  do { const size_t instance_fields = klass-\u0026gt;NumInstanceFields(); for (size_t i = 0; i \u0026lt; instance_fields; ++i) { ArtField* f = klass-\u0026gt;GetInstanceField(i); size_t size; HprofBasicType t = SignatureToBasicTypeAndSize(f-\u0026gt;GetTypeDescriptor(), \u0026amp;size); switch (t) { case hprof_basic_byte: __ AddU1(f-\u0026gt;GetByte(obj)); break; case hprof_basic_boolean: __ AddU1(f-\u0026gt;GetBoolean(obj)); break; case hprof_basic_char: __ AddU2(f-\u0026gt;GetChar(obj)); break; ...... case hprof_basic_double: case hprof_basic_long: __ AddU8(f-\u0026gt;Get64(obj)); break; } } klass = klass-\u0026gt;GetSuperClass(); } while (klass != nullptr); // Patch the instance field length.  __ UpdateU4(size_patch_offset, output_-\u0026gt;Length() - (size_patch_offset + 4)); "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/1startup/4startup_dart_framework/",
	"title": "4startup_dart_framework",
	"tags": [],
	"description": "",
	"content": "类设计 runApp main.dart\nvoid main() =\u0026gt; runApp(MyApp()); widgets/binding.dart\nvoid runApp(Widget app) { WidgetsFlutterBinding.ensureInitialized() ..attachRootWidget(app) ..scheduleWarmUpFrame(); } WidgetsFlutterBinding.ensureInitialized() /// A concrete binding for applications based on the Widgets framework. /// This is the glue that binds the framework to the Flutter engine.  class WidgetsFlutterBinding extends BindingBase with GestureBinding, ServicesBinding, SchedulerBinding, PaintingBinding, SemanticsBinding, RendererBinding, WidgetsBinding { /// Returns an instance of the [WidgetsBinding], creating and  /// initializing it if necessary. If one is created, it will be a  /// [WidgetsFlutterBinding]. If one was previously initialized, then  /// it will at least implement [WidgetsBinding].  ///  /// You only need to call this method if you need the binding to be  /// initialized before calling [runApp].  ///  /// In the `flutter_test` framework, [testWidgets] initializes the  /// binding instance to a [TestWidgetsFlutterBinding], not a  /// [WidgetsFlutterBinding].  static WidgetsBinding ensureInitialized() { if (WidgetsBinding.instance == null) WidgetsFlutterBinding(); return WidgetsBinding.instance; } } /// Default abstract constructor for bindings.  ///  /// First calls [initInstances] to have bindings initialize their  /// instance pointers and other state, then calls  /// [initServiceExtensions] to have bindings initialize their  /// observatory service extensions, if any.  BindingBase() { initInstances(); initServiceExtensions(); } SchedulerBinding.initInstances @override void initInstances() { super.initInstances(); _instance = this; window.onBeginFrame = _handleBeginFrame; window.onDrawFrame = _handleDrawFrame; ensureVisualUpdate void ensureVisualUpdate() { switch (schedulerPhase) { case SchedulerPhase.idle: case SchedulerPhase.postFrameCallbacks: scheduleFrame(); return; case SchedulerPhase.transientCallbacks: case SchedulerPhase.midFrameMicrotasks: case SchedulerPhase.persistentCallbacks: return; }} RendererBinding.initInstances PipelineOwner() @override void initInstances() { super.initInstances(); _instance = this; _pipelineOwner = PipelineOwner( onNeedVisualUpdate: ensureVisualUpdate, onSemanticsOwnerCreated: _handleSemanticsOwnerCreated, onSemanticsOwnerDisposed: _handleSemanticsOwnerDisposed, ); initRenderView(); addPersistentFrameCallback(_handlePersistentFrameCallback); initRenderView /// Creates a [RenderView] object to be the root of the  /// [RenderObject] rendering tree, and initializes it so that it  /// will be rendered when the engine is next ready to display a  /// frame.  ///  /// Called automatically when the binding is created.  void initRenderView() { assert(renderView == null); renderView = RenderView(configuration: createViewConfiguration(), window: window); renderView.scheduleInitialFrame(); } /// Bootstrap the rendering pipeline by scheduling the first frame.  ///  /// This should only be called once, and must be called before changing  /// [configuration]. It is typically called immediately after calling the  /// constructor.  void scheduleInitialFrame() { scheduleInitialLayout(); scheduleInitialPaint(_updateMatricesAndCreateNewRootLayer());//配置TransformLayer  owner.requestVisualUpdate(); } _handlePersistentFrameCallback void _handlePersistentFrameCallback(Duration timeStamp) { drawFrame(); } drawFrame /// Pump the rendering pipeline to generate a frame.  ///  /// This method is called by [handleDrawFrame], which itself is called  /// automatically by the engine when it is time to lay out and paint a frame.  ///  /// Each frame consists of the following phases: /// 1. The animation phase /// 2. Microtasks /// 3. The layout phase /// 4. The compositing bits phase /// 5. The paint phase /// 6. The compositing phase /// 7. The semantics phase /// 8. The finalization phase  @protected void drawFrame() { assert(renderView != null); pipelineOwner.flushLayout(); pipelineOwner.flushCompositingBits(); pipelineOwner.flushPaint(); renderView.compositeFrame(); // this sends the bits to the GPU  pipelineOwner.flushSemantics(); // this also sends the semantics to the OS.  } WidgetsBinding.initInstances @override void initInstances() { super.initInstances(); _instance = this; buildOwner.onBuildScheduled = _handleBuildScheduled; drawFrame /// Pump the build and rendering pipeline to generate a frame.  ///  /// This method is called by [handleDrawFrame], which itself is called  /// automatically by the engine when when it is time to lay out and paint a  /// frame. @override void drawFrame() { if (renderViewElement != null) buildOwner.buildScope(renderViewElement); super.drawFrame(); } _handleBuildScheduled void _handleBuildScheduled() { ensureVisualUpdate();} attachRootWidget /// The glue between the widgets layer and the Flutter engine.  mixin WidgetsBinding on BindingBase, SchedulerBinding, GestureBinding, RendererBinding, SemanticsBinding { /// Takes a widget and attaches it to the [renderViewElement], creating it if  /// necessary.  ///  /// This is called by [runApp] to configure the widget tree.  ///  /// See also [RenderObjectToWidgetAdapter.attachToRenderTree].  void attachRootWidget(Widget rootWidget) { _renderViewElement = RenderObjectToWidgetAdapter\u0026lt;RenderBox\u0026gt;( container: renderView, debugShortDescription: \u0026#39;[root]\u0026#39;, child: rootWidget, ).attachToRenderTree(buildOwner, renderViewElement); } /// A bridge from a [RenderObject] to an [Element] tree. class RenderObjectToWidgetAdapter\u0026lt;T extends RenderObject\u0026gt; extends RenderObjectWidget { /// Inflate this widget and actually set the resulting [RenderObject] as the  /// child of [container].  ///  /// If `element` is null, this function will create a new element. Otherwise,  /// the given element will have an update scheduled to switch to this widget.  ///  /// Used by [runApp] to bootstrap applications.  RenderObjectToWidgetElement\u0026lt;T\u0026gt; attachToRenderTree(BuildOwner owner, [ RenderObjectToWidgetElement\u0026lt;T\u0026gt; element ]) { if (element == null) { owner.lockState(() { element = createElement(); assert(element != null); element.assignOwner(owner); }); owner.buildScope(element, () {//main  element.mount(null, null); }); } else { element._newWidget = this; element.markNeedsBuild(); } return element; } } 参考渲染/widget/buildscope\nmixin SchedulerBinding\nscheduleWarmUpFrame void scheduleWarmUpFrame() { handleBeginFrame(null); handleDrawFrame(); if (hadScheduledFrame) scheduleFrame(); } handleBeginFrame void handleBeginFrame(Duration rawTimeStamp) { assert(schedulerPhase == SchedulerPhase.idle); _hasScheduledFrame = false; try { // TRANSIENT FRAME CALLBACKS  Timeline.startSync(\u0026#39;Animate\u0026#39;, arguments: timelineWhitelistArguments); _schedulerPhase = SchedulerPhase.transientCallbacks; final Map\u0026lt;int, _FrameCallbackEntry\u0026gt; callbacks = _transientCallbacks; _transientCallbacks = \u0026lt;int, _FrameCallbackEntry\u0026gt;{}; callbacks.forEach((int id, _FrameCallbackEntry callbackEntry) { if (!_removedIds.contains(id)) _invokeFrameCallback(callbackEntry.callback, _currentFrameTimeStamp, callbackEntry.debugStack); }); _removedIds.clear(); } finally { _schedulerPhase = SchedulerPhase.midFrameMicrotasks; } handleDrawFrame /// Called by the engine to produce a new frame. void handleDrawFrame() {//将会调用drawFrame // PERSISTENT FRAME CALLBACKS  _schedulerPhase = SchedulerPhase.persistentCallbacks; for (FrameCallback callback in _persistentCallbacks) _invokeFrameCallback(callback, _currentFrameTimeStamp); // POST-FRAME CALLBACKS  _schedulerPhase = SchedulerPhase.postFrameCallbacks; final List\u0026lt;FrameCallback\u0026gt; localPostFrameCallbacks = List\u0026lt;FrameCallback\u0026gt;.from(_postFrameCallbacks); _postFrameCallbacks.clear(); for (FrameCallback callback in localPostFrameCallbacks) _invokeFrameCallback(callback, _currentFrameTimeStamp); void _invokeFrameCallback(FrameCallback callback, Duration timeStamp, [ StackTrace callbackStack ]) { callback(timeStamp); /// If necessary, schedules a new frame by calling [Window.scheduleFrame]. void scheduleFrame() { if (_hasScheduledFrame || !_framesEnabled) return; ensureFrameCallbacksRegistered(); window.scheduleFrame(); _hasScheduledFrame = true; } /// Ensures callbacks for `window.onBeginFrame` and `window.onDrawFrame` are registered.  @protected void ensureFrameCallbacksRegistered() { window.onBeginFrame ??= _handleBeginFrame; window.onDrawFrame ??= _handleDrawFrame; } 其他 Window /// The most basic interface to the host operating system\u0026rsquo;s user interface.\nscheduleFrame /// Requests that, at the next appropriate opportunity, the [onBeginFrame]  /// and [onDrawFrame] callbacks be invoked.  void scheduleFrame() native \u0026#39;Window_scheduleFrame\u0026#39;; /// A callback that is invoked to notify the application that it is an  /// appropriate time to provide a scene using the [SceneBuilder] API and the  /// [render] method. When possible, this is driven by the hardware VSync  /// signal. This is only called if [scheduleFrame] has been called since the  /// last time this callback was invoked.  /// The [onDrawFrame] callback is invoked immediately after [onBeginFrame],  /// after draining any microtasks (e.g. completions of any [Future]s) queued  /// by the [onBeginFrame] handler.  FrameCallback get onBeginFrame =\u0026gt; _onBeginFrame; set onBeginFrame(FrameCallback callback) { _onBeginFrame = callback; VoidCallback get onDrawFrame =\u0026gt; _onDrawFrame; set onDrawFrame(VoidCallback callback) { render /// Updates the application\u0026#39;s rendering on the GPU with the newly provided  /// [Scene]. This function must be called within the scope of the  /// [onBeginFrame] or [onDrawFrame] callbacks being invoked.  /// To record graphical operations, first create a [PictureRecorder], then  /// construct a [Canvas], passing that [PictureRecorder] to its constructor.  /// After issuing all the graphical operations, call the  /// [PictureRecorder.endRecording] function on the [PictureRecorder] to obtain  /// the final [Picture] that represents the issued graphical operations.  ///  /// Next, create a [SceneBuilder], and add the [Picture] to it using  /// [SceneBuilder.addPicture]. With the [SceneBuilder.build] method you can  /// then obtain a [Scene] object, which you can display to the user via this  /// [render] function.  void render(Scene scene) native \u0026#39;Window_render\u0026#39;; PipelineOwner /// The pipeline owner manages the rendering pipeline.  /// The [RendererBinding] holds the pipeline owner for the render objects that  /// are visible on screen. You can create other pipeline owners to manage  /// off-screen objects, which can flush their pipelines independently of the  /// on-screen render objects.  PipelineOwner /// The unique object managed by this pipeline that has no parent.  ///  /// This object does not have to be a [RenderObject].  AbstractNode get rootNode =\u0026gt; _rootNode; AbstractNode _rootNode; List\u0026lt;RenderObject\u0026gt; _nodesNeedingLayout = \u0026lt;RenderObject\u0026gt;[]; List\u0026lt;RenderObject\u0026gt; _nodesNeedingPaint = \u0026lt;RenderObject\u0026gt;[]; final List\u0026lt;RenderObject\u0026gt; _nodesNeedingCompositingBitsUpdate = \u0026lt;RenderObject\u0026gt;[]; final VoidCallback onNeedVisualUpdate; requestVisualUpdate /// Used to notify the pipeline owner that an associated render object wishes  /// to update its visual appearance.  void requestVisualUpdate() { if (onNeedVisualUpdate != null) onNeedVisualUpdate(); } flushLayout /// Update the layout information for all dirty render objects.  void flushLayout() { while (_nodesNeedingLayout.isNotEmpty) { final List\u0026lt;RenderObject\u0026gt; dirtyNodes = _nodesNeedingLayout; _nodesNeedingLayout = \u0026lt;RenderObject\u0026gt;[]; for (RenderObject node in dirtyNodes..sort((RenderObject a, RenderObject b) =\u0026gt; a.depth - b.depth)) { if (node._needsLayout \u0026amp;\u0026amp; node.owner == this) node._layoutWithoutResize(); } flushCompositingBits /// Updates the [RenderObject.needsCompositing] bits.  void flushCompositingBits() { _nodesNeedingCompositingBitsUpdate.sort((RenderObject a, RenderObject b) =\u0026gt; a.depth - b.depth); for (RenderObject node in _nodesNeedingCompositingBitsUpdate) { if (node._needsCompositingBitsUpdate \u0026amp;\u0026amp; node.owner == this) node._updateCompositingBits(); } _nodesNeedingCompositingBitsUpdate.clear(); flushPaint /// Update the display lists for all render objects.  ///  /// This function is one of the core stages of the rendering pipeline.  /// Painting occurs after layout and before the scene is recomposited so that  /// scene is composited with up-to-date display lists for every render object.  ///  /// See [RendererBinding] for an example of how this function is used.  void flushPaint() { final List\u0026lt;RenderObject\u0026gt; dirtyNodes = _nodesNeedingPaint; _nodesNeedingPaint = \u0026lt;RenderObject\u0026gt;[]; // Sort the dirty nodes in reverse order (deepest first).  for (RenderObject node in dirtyNodes..sort((RenderObject a, RenderObject b) =\u0026gt; b.depth - a.depth)) { assert(node._layer != null); if (node._needsPaint \u0026amp;\u0026amp; node.owner == this) { if (node._layer.attached) { PaintingContext.repaintCompositedChild(node);//main  } else { node._skippedPaintingOnLayer(); } } RenderObjectToWidgetAdapter /// A bridge from a [RenderObject] to an [Element] tree. class RenderObjectToWidgetAdapter\u0026lt;T extends RenderObject\u0026gt; extends RenderObjectWidget /// The widget below this widget in the tree.  ///  /// {@macro flutter.widgets.child}  final Widget child; /// The [RenderObject] that is the parent of the [Element] created by this widget.  final RenderObjectWithChildMixin\u0026lt;T\u0026gt; container; @override RenderObjectToWidgetElement\u0026lt;T\u0026gt; createElement() =\u0026gt; RenderObjectToWidgetElement\u0026lt;T\u0026gt;(this); @override RenderObjectWithChildMixin\u0026lt;T\u0026gt; createRenderObject(BuildContext context) =\u0026gt; container; RenderObjectToWidgetElement\u0026lt;T\u0026gt; attachToRenderTree(BuildOwner owner, [ RenderObjectToWidgetElement\u0026lt;T\u0026gt; element ]) {} RootRenderObjectElement /// The element at the root of the tree.  ///  /// Only root elements may have their owner set explicitly. All other  /// elements inherit their owner from their parent.  RootRenderObjectElement extends RenderObjectElement mount @override void mount(Element parent, dynamic newSlot) { // Root elements should never have parents.  assert(parent == null); assert(newSlot == null); super.mount(parent, newSlot); } RenderObjectToWidgetElement RenderObjectToWidgetElement\u0026lt;T extends RenderObject\u0026gt; { Element _child; @override RenderObjectWithChildMixin\u0026lt;T\u0026gt; get renderObject =\u0026gt; super.renderObject; } mount @override void mount(Element parent, dynamic newSlot) { assert(parent == null); super.mount(parent, newSlot);//1将自己挂在父节点上  _rebuild();//2：通过调用updateChild逐个将child挂在自己上 } update @override void update(RenderObjectToWidgetAdapter\u0026lt;T\u0026gt; newWidget) { super.update(newWidget); assert(widget == newWidget); _rebuild(); } _rebuild void _rebuild() { _child = updateChild(_child, widget.child, _rootChildSlot); insertChildRenderObject @override void insertChildRenderObject(RenderObject child, dynamic slot) { renderObject.child = child; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/5leakcanary2/",
	"title": "5LeakCanary2",
	"tags": [],
	"description": "",
	"content": "Procedure https://square.github.io/leakcanary/fundamentals-how-leakcanary-works/\ngraph TB Procedure--\u0026gt;|useReferenceQueue|Detect(Detecting retained objects.) Procedure--\u0026gt;|Debug.dump|Dump(Dumping the heap.) Procedure--\u0026gt;|Shark|Analyze(Analyzing the heap.) Procedure--\u0026gt;category(Categorizing leaks.) Module依赖 graph TB leakcanary-android-sample--\u0026gt;leakcanary-android leakcanary-android--\u0026gt;leakcanary-android-core "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/6leakcanary2analyze/",
	"title": "6LeakCanary2Analyze",
	"tags": [],
	"description": "",
	"content": "Procedure graph TB subgraph binarySearch二分查找 SortedBytesMap end subgraph 广度优先遍历 State.findPathsFromGcRoots:BFS end HeapAnalyzer.analyze--\u0026gt;Hprof.open:HprofFile HeapAnalyzer.analyze--\u0026gt;HprofHeapGraph.indexHprof HeapAnalyzer.analyze--\u0026gt;FindLeakInput.analyzeGraph HprofHeapGraph.indexHprof--\u0026gt;reader.readHprofRecords--\u0026gt;|callback HprofRecord|indexBuilderListener.onHprofRecord--\u0026gt;UnsortedByteEntries(\u0026quot;UnsortedByteEntries,ScatterMap\u0026quot;) HprofHeapGraph.indexHprof--\u0026gt;indexBuilderListener.buildIndex--\u0026gt;|Sort entries by keys|SortedBytesMap--\u0026gt;HprofInMemoryIndex--\u0026gt;HprofHeapGraph FindLeakInput.analyzeGraph--\u0026gt;FindLeakInput.findLeaks FindLeakInput.findLeaks--\u0026gt;State.findPathsFromGcRoots:BFS--\u0026gt;|start by enqueueGcRoots|findObjectById(\u0026quot;graph.findObjectById\u0026quot;)--\u0026gt;readFieldsAndEnqueue Data Flow graph TB HprofFile--\u0026gt;HprofRecord HprofRecord--\u0026gt;UnsortedByteEntries(\u0026quot;UnsortedByteEntries(class,instance,objectArray,primitiveArray)\u0026quot;) UnsortedByteEntries--\u0026gt;|Sort entries by keys|SortedBytesMap(SortedBytesMap: get perform binarySearch) SortedBytesMap--\u0026gt;HprofInMemoryIndex SortedBytesMap--\u0026gt;|get return|ByteSubArray ByteSubArray--\u0026gt;|indexedObjectOrNull|IndexedObject IndexedObject--\u0026gt;|wrapIndexedObject|HeapObject HprofRecord--\u0026gt;ScatterMap(\u0026quot;ScatterMap(hprofStringCache, classNames)\u0026quot;) ScatterMap--\u0026gt;HprofInMemoryIndex HprofInMemoryIndex--\u0026gt;HprofHeapGraph LruCache:objectCache--\u0026gt;|cached when readObjectRecord|HprofHeapGraph //ScatterMap contains: classNames and hprofStringCache  // LRU cache size of 3000 is a sweet spot to balance hits vs memory usage. // This is based on running InstrumentationLeakDetectorTest a bunch of time on a // Pixel 2 XL API 28. Hit count was ~120K, miss count ~290K private val objectCache = LruCache\u0026lt;Long, ObjectRecord\u0026gt;(3000) HprofRecord Hierarchy graph LR HprofRecord--\u0026gt;StringRecord HprofRecord--\u0026gt;LoadClassRecord HprofRecord--\u0026gt;StackFrameRecord HprofRecord--\u0026gt;StackTraceRecord HprofRecord--\u0026gt;HeapDumpRecord HeapDumpRecord--\u0026gt;GcRootRecord HeapDumpRecord--\u0026gt;ObjectRecord ObjectRecord--\u0026gt;ClassDumpRecord ObjectRecord--\u0026gt;InstanceDumpRecord ObjectRecord--\u0026gt;ObjectArrayDumpRecord ObjectRecord--\u0026gt;PrimitiveArrayDumpRecord ReferencePathNode Hierarchy graph LR ReferencePathNode--\u0026gt;RootNode ReferencePathNode--\u0026gt;ChildNode RootNode--\u0026gt;LibraryLeakRootNode RootNode--\u0026gt;NormalRootNode ChildNode--\u0026gt;NormalNode:ContainsParent ChildNode--\u0026gt;LibraryLeakChildNode:ContainsParent /** * Analyzes heap dumps to look for leaks. */ HeapAnalyzer analyze /** * Searches the heap dump for leaking instances and then computes the shortest strong reference * path from those instances to the GC roots. */ fun analyze( heapDumpFile: File, leakingObjectFinder: LeakingObjectFinder, referenceMatchers: List\u0026lt;ReferenceMatcher\u0026gt; = emptyList(), computeRetainedHeapSize: Boolean = false, objectInspectors: List\u0026lt;ObjectInspector\u0026gt; = emptyList(), metadataExtractor: MetadataExtractor = MetadataExtractor.NO_OP, proguardMapping: ProguardMapping? = null ): HeapAnalysis { Hprof.open(heapDumpFile) .use { hprof -\u0026gt; val graph = HprofHeapGraph.indexHprof(hprof, proguardMapping) val helpers = FindLeakInput(graph, referenceMatchers, computeRetainedHeapSize, objectInspectors) helpers.analyzeGraph( metadataExtractor, leakingObjectFinder, heapDumpFile, analysisStartNanoTime ) } indexhprof\nFindLeakInput private class FindLeakInput( val graph: HeapGraph, val referenceMatchers: List\u0026lt;ReferenceMatcher\u0026gt;, val computeRetainedHeapSize: Boolean, val objectInspectors: List\u0026lt;ObjectInspector\u0026gt; ) FindLeakInput.analyzeGraph private fun FindLeakInput.analyzeGraph( metadataExtractor: MetadataExtractor, leakingObjectFinder: LeakingObjectFinder, heapDumpFile: File, analysisStartNanoTime: Long ): HeapAnalysisSuccess { listener.onAnalysisProgress(EXTRACTING_METADATA) val metadata = metadataExtractor.extractMetadata(graph) listener.onAnalysisProgress(FINDING_RETAINED_OBJECTS) val leakingObjectIds = leakingObjectFinder.findLeakingObjectIds(graph) val (applicationLeaks, libraryLeaks) = findLeaks(leakingObjectIds) return HeapAnalysisSuccess( heapDumpFile = heapDumpFile, createdAtTimeMillis = System.currentTimeMillis(), analysisDurationMillis = since(analysisStartNanoTime), metadata = metadata, applicationLeaks = applicationLeaks, libraryLeaks = libraryLeaks ) } FindLeakInput.findLeaks private fun FindLeakInput.findLeaks(leakingObjectIds: Set\u0026lt;Long\u0026gt;): Pair\u0026lt;List\u0026lt;ApplicationLeak\u0026gt;, List\u0026lt;LibraryLeak\u0026gt;\u0026gt; { val pathFinder = PathFinder(graph, listener, referenceMatchers) val pathFindingResults = pathFinder.findPathsFromGcRoots(leakingObjectIds, computeRetainedHeapSize) SharkLog.d { \u0026#34;Found ${leakingObjectIds.size}retained objects\u0026#34; } return buildLeakTraces(pathFindingResults) } findpathsfromgcroots\nPathFinder /** * Finds the shortest path from leaking references to a gc root, first ignoring references * identified as \u0026#34;to visit last\u0026#34; and then visiting them as needed if no path is * found. */ internal class PathFinder( private class State( val leakingObjectIds: Set\u0026lt;Long\u0026gt;, val sizeOfObjectInstances: Int, val computeRetainedHeapSize: Boolean ) { /** Set of objects to visit */ val toVisitQueue: Deque\u0026lt;ReferencePathNode\u0026gt; = ArrayDeque() /** * Objects to visit when [toVisitQueue] is empty. Should contain [JavaFrame] gc roots first, * then [LibraryLeakNode]. */ val toVisitLastQueue: Deque\u0026lt;ReferencePathNode\u0026gt; = ArrayDeque() /** * Enables fast checking of whether a node is already in the queue. */ val toVisitSet = HashSet\u0026lt;Long\u0026gt;() val toVisitLastSet = HashSet\u0026lt;Long\u0026gt;() val visitedSet = LongScatterSet() findPathsFromGcRoots fun findPathsFromGcRoots( leakingObjectIds: Set\u0026lt;Long\u0026gt;, computeRetainedHeapSize: Boolean ): PathFindingResults { listener.onAnalysisProgress(FINDING_PATHS_TO_RETAINED_OBJECTS) val sizeOfObjectInstances = determineSizeOfObjectInstances(graph) val state = State(leakingObjectIds, sizeOfObjectInstances, computeRetainedHeapSize) return state.findPathsFromGcRoots() } State /** * Map of objects to their leaking dominator. key: currentObjectId --\u0026gt; value: directDominatorObjectId * If an object has been added to [toVisitSet] or [visitedSet] and is missing from * [dominatedObjectIds] then it\u0026#39;s considered \u0026#34;undomitable\u0026#34; ie it is dominated by gc roots * and cannot be dominated by a leaking object. */ val dominatedObjectIds = LongLongScatterMap() State.findPathsFromGcRoots() //main algorithm to find the shortest path to GCRoot, BFS is useful because when the first time we visit leakObject, the shortest path is found. Use ChildNode to find the parent ReferencePathNode private fun State.findPathsFromGcRoots(): PathFindingResults { //iterate different type GcRoot and enqueue them into toVisitQueue or toVisitLastQueue  enqueueGcRoots() val shortestPathsToLeakingObjects = mutableListOf\u0026lt;ReferencePathNode\u0026gt;() visitingQueue@ while (queuesNotEmpty) { val node = poll() if (checkSeen(node)) { throw IllegalStateException( \u0026#34;Node $nodeobjectId=${node.objectId}should not be enqueued when already visited or enqueued\u0026#34; ) } if (node.objectId in leakingObjectIds) { shortestPathsToLeakingObjects.add(node) // Found all refs, stop searching (unless computing retained size)  if (shortestPathsToLeakingObjects.size == leakingObjectIds.size) { if (computeRetainedHeapSize) { listener.onAnalysisProgress(FINDING_DOMINATORS) } else { break@visitingQueue } } } when (val heapObject = graph.findObjectById(node.objectId)) { is HeapClass -\u0026gt; visitClassRecord(heapObject, node) is HeapInstance -\u0026gt; visitInstance(heapObject, node) is HeapObjectArray -\u0026gt; visitObjectArray(heapObject, node) } } return PathFindingResults(shortestPathsToLeakingObjects, dominatedObjectIds) } findobjectbyid\nState.visitInstance private fun State.visitInstance( instance: HeapInstance, parent: ReferencePathNode ) { val fieldNamesAndValues = instance.readFields() .filter { it.value.isNonNullReference }//only reference type need to be iterate, primitive is not.  .toMutableList() fieldNamesAndValues.sortBy { it.name } fieldNamesAndValues.forEach { field -\u0026gt; val objectId = field.value.asObjectId!! if (computeRetainedHeapSize) { updateDominatorWithSkips(parent.objectId, objectId) } val node = when (val referenceMatcher = fieldReferenceMatchers[field.name]) { null -\u0026gt; NormalNode( objectId = objectId, parent = parent, refFromParentType = INSTANCE_FIELD, refFromParentName = field.name ) is LibraryLeakReferenceMatcher -\u0026gt; LibraryLeakChildNode( objectId = objectId, parent = parent, refFromParentType = INSTANCE_FIELD, refFromParentName = field.name, matcher = referenceMatcher ) is IgnoredReferenceMatcher -\u0026gt; null } if (node != null) { enqueue(node) } } State.enqueue @Suppress(\u0026#34;ReturnCount\u0026#34;) private fun State.enqueue( node: ReferencePathNode ) { val visitLast = node is LibraryLeakNode || // We deprioritize thread objects because on Lollipop the thread local values are stored  // as a field.  (node is RootNode \u0026amp;\u0026amp; node.gcRoot is ThreadObject) || (node is NormalNode \u0026amp;\u0026amp; node.parent is RootNode \u0026amp;\u0026amp; node.parent.gcRoot is JavaFrame) if (toVisitLastSet.contains(node.objectId)) { // Already enqueued =\u0026gt; shorter or equal distance amongst library leak ref patterns.  if (visitLast) { return } else { toVisitQueue.add(node) toVisitSet.add(node.objectId) val nodeToRemove = toVisitLastQueue.first { it.objectId == node.objectId } toVisitLastQueue.remove(nodeToRemove) toVisitLastSet.remove(node.objectId) return } } val isLeakingObject = node.objectId in leakingObjectIds if (!isLeakingObject) { val skip = when (val graphObject = graph.findObjectById(node.objectId)) { is HeapClass -\u0026gt; false is HeapInstance -\u0026gt; when { graphObject.isPrimitiveWrapper -\u0026gt; true graphObject.instanceClassName == \u0026#34;java.lang.String\u0026#34; -\u0026gt; true graphObject.instanceClass.instanceByteSize \u0026lt;= sizeOfObjectInstances -\u0026gt; true else -\u0026gt; false } is HeapObjectArray -\u0026gt; when { graphObject.isPrimitiveWrapperArray -\u0026gt; true else -\u0026gt; false } is HeapPrimitiveArray -\u0026gt; true } if (skip) { return } } if (visitLast) { toVisitLastQueue.add(node) toVisitLastSet.add(node.objectId) } else { toVisitQueue.add(node) toVisitSet.add(node.objectId) } State.enqueueGcRoots() private fun State.enqueueGcRoots() { val gcRoots = sortedGcRoots() ...... } State.updateDominator private fun State.updateDominator(//contains very detail doc about the algorithm to generate dominator tree /** * A [HeapGraph] that reads from an indexed [Hprof]. Create a new instance with [indexHprof]. */ HprofHeapGraph constructor class HprofHeapGraph internal constructor( private val hprof: Hprof, private val index: HprofInMemoryIndex ) : HeapGraph { indexHprof companion object { fun indexHprof( hprof: Hprof, proguardMapping: ProguardMapping? = null, indexedGcRootTypes: Set\u0026lt;KClass\u0026lt;out GcRoot\u0026gt;\u0026gt; = setOf( JniGlobal::class, JavaFrame::class, JniLocal::class, MonitorUsed::class, NativeStack::class, StickyClass::class, ThreadBlock::class, // ThreadObject points to threads, which we need to find the thread that a JavaLocalPattern  // belongs to  ThreadObject::class, JniMonitor::class /* Not included here: VmInternal: Ignoring because we\u0026#39;ve got 150K of it, but is this the right thing to do? What\u0026#39;s VmInternal exactly? History does not go further than https://android.googlesource.com/platform/dalvik2/+/refs/heads/master/hit/src/com/android/hit/HprofParser.java#77  We should log to figure out what objects VmInternal points to. ReferenceCleanup: We used to keep it, but the name doesn\u0026#39;t seem like it should create a leak. Unknown: it\u0026#39;s unknown, should we care? We definitely don\u0026#39;t care about those for leak finding: InternedString, Finalizing, Debugger, Unreachable */ ) ): HeapGraph { val index = HprofInMemoryIndex.createReadingHprof(hprof, proguardMapping, indexedGcRootTypes) return HprofHeapGraph(hprof, index) } } createreadinghprof\nfindClassByName override fun findClassByName(className: String): HeapClass? { val classId = index.classId(className) return if (classId == null) { null } else { return findObjectById(classId) as HeapClass } } findObjectById override fun findObjectById(objectId: Long): HeapObject { return findObjectByIdOrNull(objectId) ?: throw IllegalArgumentException( \u0026#34;Object id $objectIdnot found in heap dump.\u0026#34; ) } findObjectByIdOrNull override fun findObjectByIdOrNull(objectId: Long): HeapObject? { if (objectId == javaLangObjectClass?.objectId) return javaLangObjectClass val indexedObject = index.indexedObjectOrNull(objectId) ?: return null return wrapIndexedObject(indexedObject, objectId) } indexedobjectornull\nwrapIndexedObject private fun wrapIndexedObject( indexedObject: IndexedObject, objectId: Long ): HeapObject { return when (indexedObject) { is IndexedClass -\u0026gt; HeapClass(this, indexedObject, objectId) is IndexedInstance -\u0026gt; { val isPrimitiveWrapper = index.primitiveWrapperTypes.contains(indexedObject.classId) HeapInstance(this, indexedObject, objectId, isPrimitiveWrapper) } is IndexedObjectArray -\u0026gt; { val isPrimitiveWrapperArray = index.primitiveWrapperTypes.contains(indexedObject.arrayClassId) HeapObjectArray(this, indexedObject, objectId, isPrimitiveWrapperArray) } is IndexedPrimitiveArray -\u0026gt; HeapPrimitiveArray(this, indexedObject, objectId) } } HprofInMemoryIndex createReadingHprof fun createReadingHprof( hprof: Hprof, proguardMapping: ProguardMapping?, indexedGcRootTypes: Set\u0026lt;KClass\u0026lt;out GcRoot\u0026gt;\u0026gt; ): HprofInMemoryIndex { val recordTypes = setOf( StringRecord::class, LoadClassRecord::class, ClassSkipContentRecord::class, InstanceSkipContentRecord::class, ObjectArraySkipContentRecord::class, PrimitiveArraySkipContentRecord::class, GcRootRecord::class ) val reader = hprof.reader // First pass to count and correctly size arrays once and for all.  var classCount = 0 var instanceCount = 0 var objectArrayCount = 0 var primitiveArrayCount = 0 reader.readHprofRecords(setOf( LoadClassRecord::class, InstanceSkipContentRecord::class, ObjectArraySkipContentRecord::class, PrimitiveArraySkipContentRecord::class ), OnHprofRecordListener { position, record -\u0026gt; when (record) { is LoadClassRecord -\u0026gt; classCount++ is InstanceSkipContentRecord -\u0026gt; instanceCount++ is ObjectArraySkipContentRecord -\u0026gt; objectArrayCount++ is PrimitiveArraySkipContentRecord -\u0026gt; primitiveArrayCount++ } }) hprof.moveReaderTo(reader.startPosition) val indexBuilderListener = Builder( reader.identifierByteSize == 8, hprof.fileLength, classCount, instanceCount, objectArrayCount, primitiveArrayCount, indexedGcRootTypes.map { it.java } .toSet() ) reader.readHprofRecords(recordTypes, indexBuilderListener) return indexBuilderListener.buildIndex(proguardMapping) readhprofrecords\nBuilder /** * Map of string id to string * This currently keeps all the hprof strings that we could care about: class names, * static field names and instance fields names */ // TODO Replacing with a radix trie reversed into a sparse array of long to trie leaf could save // memory. Can be stored as 3 arrays: array of keys, array of values which are indexes into // a large array of string bytes. Each \u0026#34;entry\u0026#34; consists of a size, the index of the previous // segment and then the segment content.  private val hprofStringCache = LongObjectScatterMap\u0026lt;String\u0026gt;() /** * class id to string id */ private val classNames = LongLongScatterMap(expectedElements = classCount) private val classIndex = UnsortedByteEntries( bytesPerValue = positionSize + identifierSize + 4, longIdentifiers = longIdentifiers, initialCapacity = classCount ) private val instanceIndex = UnsortedByteEntries( bytesPerValue = positionSize + identifierSize, longIdentifiers = longIdentifiers, initialCapacity = instanceCount ) private val objectArrayIndex = UnsortedByteEntries( bytesPerValue = positionSize + identifierSize, longIdentifiers = longIdentifiers, initialCapacity = objectArrayCount ) private val primitiveArrayIndex = UnsortedByteEntries( bytesPerValue = positionSize + 1, longIdentifiers = longIdentifiers, initialCapacity = primitiveArrayCount ) onHprofRecord override fun onHprofRecord( position: Long, record: HprofRecord ) { when (record) { is StringRecord -\u0026gt; { if (PRIMITIVE_WRAPPER_TYPES.contains(record.string)) { primitiveWrapperClassNames.add(record.id) } // JVM heap dumps use \u0026#34;/\u0026#34; for package separators (vs \u0026#34;.\u0026#34; for Android heap dumps)  hprofStringCache[record.id] = record.string.replace(\u0026#39;/\u0026#39;, \u0026#39;.\u0026#39;) } is LoadClassRecord -\u0026gt; { classNames[record.id] = record.classNameStringId if (primitiveWrapperClassNames.contains(record.classNameStringId)) { primitiveWrapperTypes.add(record.id) } } is GcRootRecord -\u0026gt; { val gcRoot = record.gcRoot if (gcRoot.id != ValueHolder.NULL_REFERENCE \u0026amp;\u0026amp; indexedGcRootsTypes.contains(gcRoot.javaClass) ) { gcRoots += gcRoot } } is ClassSkipContentRecord -\u0026gt; { classIndex.append(record.id)//write id in an entry  .apply {//write value bytes  writeTruncatedLong(position, positionSize) writeId(record.superclassId) writeInt(record.instanceSize) } } is InstanceSkipContentRecord -\u0026gt; { instanceIndex.append(record.id) .apply { writeTruncatedLong(position, positionSize) writeId(record.classId) } } is ObjectArraySkipContentRecord -\u0026gt; { objectArrayIndex.append(record.id) .apply { writeTruncatedLong(position, positionSize) writeId(record.arrayClassId) } } is PrimitiveArraySkipContentRecord -\u0026gt; { primitiveArrayIndex.append(record.id) .apply { writeTruncatedLong(position, positionSize) writeByte(record.type.ordinal.toByte()) } } } } buildIndex fun buildIndex( proguardMapping: ProguardMapping? ): HprofInMemoryIndex { val sortedInstanceIndex = instanceIndex.moveToSortedMap() val sortedObjectArrayIndex = objectArrayIndex.moveToSortedMap() val sortedPrimitiveArrayIndex = primitiveArrayIndex.moveToSortedMap() val sortedClassIndex = classIndex.moveToSortedMap() // Passing references to avoid copying the underlying data structures.  return HprofInMemoryIndex( positionSize, hprofStringCache, classNames, sortedClassIndex, sortedInstanceIndex, sortedObjectArrayIndex, sortedPrimitiveArrayIndex, gcRoots, proguardMapping, primitiveWrapperTypes ) } movetosortedmap\nindexedObjectOrNull fun indexedObjectOrNull(objectId: Long): IndexedObject? { var array: ByteSubArray? = classIndex[objectId] if (array != null) { return IndexedClass( position = array.readTruncatedLong(positionSize), superclassId = array.readId(), instanceSize = array.readInt() ) } array = instanceIndex[objectId] if (array != null) { return IndexedInstance( position = array.readTruncatedLong(positionSize), classId = array.readId() ) } array = objectArrayIndex[objectId] if (array != null) { return IndexedObjectArray( position = array.readTruncatedLong(positionSize), arrayClassId = array.readId() ) } array = primitiveArrayIndex[objectId] if (array != null) { return IndexedPrimitiveArray( position = array.readTruncatedLong(positionSize), primitiveType = PrimitiveType.values()[array.readByte() .toInt()] ) } return null } shark-hprof/src/main/java/shark/HprofReader.kt\nHprofReader readHprofRecords /** * Reads all hprof records from [source]. * Assumes the [reader] was has a source that currently points to the start position of hprof * records. */ @Suppress(\u0026#34;ComplexMethod\u0026#34;, \u0026#34;LongMethod\u0026#34;) fun readHprofRecords( recordTypes: Set\u0026lt;KClass\u0026lt;out HprofRecord\u0026gt;\u0026gt;, listener: OnHprofRecordListener ) { while (!exhausted()) { // type of the record  val tag = readUnsignedByte() // number of microseconds since the time stamp in the header  skip(intByteSize) // number of bytes that follow and belong to this record  val length = readUnsignedInt() when (tag) { STRING_IN_UTF8 -\u0026gt; { if (readStringRecord) { val recordPosition = position val id = readId() val stringLength = length - identifierByteSize val string = readUtf8(stringLength) val record = StringRecord(id, string) listener.onHprofRecord(recordPosition, record) } else { skip(length) } } LOAD_CLASS -\u0026gt; { if (readLoadClassRecord) { val recordPosition = position val classSerialNumber = readInt() val id = readId() val stackTraceSerialNumber = readInt() val classNameStringId = readId() reusedLoadClassRecord.apply { this.classSerialNumber = classSerialNumber this.id = id this.stackTraceSerialNumber = stackTraceSerialNumber this.classNameStringId = classNameStringId } listener.onHprofRecord(recordPosition, reusedLoadClassRecord) } else { skip(length) } } STACK_FRAME -\u0026gt; {} STACK_TRACE -\u0026gt; {} HEAP_DUMP, HEAP_DUMP_SEGMENT -\u0026gt; { val heapDumpStart = position var previousTag = 0 var previousTagPosition = 0L while (position - heapDumpStart \u0026lt; length) { val heapDumpTagPosition = position val heapDumpTag = readUnsignedByte()//position increase  when (heapDumpTag) { ROOT_UNKNOWN -\u0026gt; { if (readGcRootRecord) { val recordPosition = position val record = GcRootRecord(gcRoot = Unknown(id = readId())) listener.onHprofRecord(recordPosition, record) } else { skip(identifierByteSize)//position increase  } } ROOT_JNI_GLOBAL -\u0026gt; { if (readGcRootRecord) { val recordPosition = position val gcRootRecord = GcRootRecord(gcRoot = JniGlobal(id = readId(), jniGlobalRefId = readId())) listener.onHprofRecord(recordPosition, gcRootRecord) } else { skip(identifierByteSize + identifierByteSize) } } } HEAP_DUMP_END -\u0026gt; { if (readHeapDumpEndRecord) { val recordPosition = position val record = HeapDumpEndRecord listener.onHprofRecord(recordPosition, record) } } else -\u0026gt; { skip(length) } HprofRecord /** * A Hprof record. These data structure map 1:1 with how records are written in hprof files. */ sealed class HprofRecord { class StringRecord( val id: Long, val string: String ) : HprofRecord() class LoadClassRecord( classSerialNumber: Int, id: Long, stackTraceSerialNumber: Int, classNameStringId: Long ) : HprofRecord() { ...... ObjectRecord sealed class ObjectRecord : HeapDumpRecord() { class ClassDumpRecord( val id: Long, val stackTraceSerialNumber: Int, val superclassId: Long, val classLoaderId: Long, val signersId: Long, val protectionDomainId: Long, val instanceSize: Int, val staticFields: List\u0026lt;StaticFieldRecord\u0026gt;, val fields: List\u0026lt;FieldRecord\u0026gt; ) : ObjectRecord() { } class InstanceDumpRecord( val id: Long, val stackTraceSerialNumber: Int, val classId: Long, /** * Instance field values (this class, followed by super class, etc) */ val fieldValues: ByteArray ) : ObjectRecord() class ObjectArrayDumpRecord( val id: Long, val stackTraceSerialNumber: Int, val arrayClassId: Long, val elementIds: LongArray ) : ObjectRecord() sealed class PrimitiveArrayDumpRecord : ObjectRecord() { } /** * An object in the heap dump. */ HeapObject /** * This [HeapObject] as a [HeapClass] if it is one, or null otherwise */ val asClass: HeapClass? get() = if (this is HeapClass) this else null /** * This [HeapObject] as a [HeapInstance] if it is one, or null otherwise */ val asInstance: HeapInstance? get() = if (this is HeapInstance) this else null /** * A class in the heap dump. */ class HeapClass internal constructor( private val hprofGraph: HprofHeapGraph, private val indexedObject: IndexedClass, override val objectId: Long ) : HeapObject() { /** * Returns a [HeapField] object that reflects the specified declared * field of the class represented by this [HeapClass] object, or null if this field does not * exist. The [name] parameter specifies the simple name of the desired field. * * Also available as a convenience operator: [get] * * This may trigger IO reads. */ fun readStaticField(fieldName: String): HeapField? { for (fieldRecord in readRecord().staticFields) { if (hprofGraph.staticFieldName(objectId, fieldRecord) == fieldName) { return HeapField( this, hprofGraph.staticFieldName(objectId, fieldRecord), HeapValue(hprofGraph, fieldRecord.value) ) } } return null } } /** * An instance in the heap dump. */ class HeapInstance internal constructor( private val hprofGraph: HprofHeapGraph, internal val indexedObject: IndexedInstance, override val objectId: Long, /** * Whether this is an instance of a primitive wrapper type. */ val isPrimitiveWrapper: Boolean ) : HeapObject() { /** * Returns a [HeapField] object that reflects the specified declared * field of the instance represented by this [HeapInstance] object, or null if this field does * not exist. The [declaringClassName] specifies the class in which the desired field is * declared, and the [fieldName] parameter specifies the simple name of the desired field. * * Also available as a convenience operator: [get] * * This may trigger IO reads. */ fun readField( declaringClassName: String, fieldName: String ): HeapField? { return readFields().firstOrNull { field -\u0026gt; field.declaringClass.name == declaringClassName \u0026amp;\u0026amp; field.name == fieldName } } } readFields /** * The fields of this instance, as a sequence of [HeapField]. * * This may trigger IO reads. */ fun readFields(): Sequence\u0026lt;HeapField\u0026gt; { val fieldReader by lazy { hprofGraph.createFieldValuesReader(readRecord()) } return instanceClass.classHierarchy .map { heapClass -\u0026gt; heapClass.readRecord() .fields.asSequence() .map { fieldRecord -\u0026gt; val fieldName = hprofGraph.fieldName(heapClass.objectId, fieldRecord) val fieldValue = fieldReader.readValue(fieldRecord) HeapField(heapClass, fieldName, HeapValue(hprofGraph, fieldValue)) } } .flatten()//change two dimensional sequence into one dimensional } IndexedObject internal sealed class IndexedObject { abstract val position: Long class IndexedClass( override val position: Long, val superclassId: Long, val instanceSize: Int ) : IndexedObject() class IndexedInstance( override val position: Long, val classId: Long ) : IndexedObject() class IndexedObjectArray( override val position: Long, val arrayClassId: Long ) : IndexedObject() class IndexedPrimitiveArray( override val position: Long, primitiveType: PrimitiveType ) : IndexedObject() { private val primitiveTypeOrdinal: Byte = primitiveType.ordinal.toByte() val primitiveType: PrimitiveType get() = PrimitiveType.values()[primitiveTypeOrdinal.toInt()] } } UnsortedByteEntries /** * Wraps a byte array of entries where each entry is an id followed by bytes for the value. * `id` is a long if [longIdentifiers] is true and an int otherwise. Each entry has [bytesPerValue] * value bytes. Entries are appended into the array via [append]. Once done, the backing array * is sorted and turned into a [SortedBytesMap] by calling [moveToSortedMap]. */ internal class UnsortedByteEntries( private val bytesPerValue: Int, private val longIdentifiers: Boolean, private val initialCapacity: Int = 4, private val growthFactor: Double = 2.0 ) { private val bytesPerEntry = bytesPerValue + if (longIdentifiers) 8 else 4 private var entries: ByteArray? = null private val subArray = MutableByteSubArray() private var subArrayIndex = 0 private var assigned: Int = 0 private var currentCapacity = 0 append fun append( key: Long ): MutableByteSubArray { if (entries == null) { currentCapacity = initialCapacity entries = ByteArray(currentCapacity * bytesPerEntry) } else { if (currentCapacity == assigned) { val newCapacity = (currentCapacity * growthFactor).toInt() growEntries(newCapacity) currentCapacity = newCapacity } } assigned++ subArrayIndex = 0 subArray.writeId(key) return subArray } moveToSortedMap fun moveToSortedMap(): SortedBytesMap { if (assigned == 0) { return SortedBytesMap(longIdentifiers, bytesPerValue, ByteArray(0)) } val entries = entries!! // Sort entries by keys, which are ids of 4 or 8 bytes.  ByteArrayTimSort.sort(entries, 0, assigned, bytesPerEntry, object : ByteArrayComparator { override fun compare( entrySize: Int, o1Array: ByteArray, o1Index: Int, o2Array: ByteArray, o2Index: Int ): Int { return if (longIdentifiers) { readLong(o1Array, o1Index * entrySize) .compareTo( readLong(o2Array, o2Index * entrySize) ) } else { readInt(o1Array, o1Index * entrySize) .compareTo( readInt(o2Array, o2Index * entrySize) ) } } }) val sortedEntries = if (entries.size \u0026gt; assigned * bytesPerEntry) { entries.copyOf(assigned * bytesPerEntry) } else entries this.entries = null assigned = 0 return SortedBytesMap( longIdentifiers, bytesPerValue, sortedEntries ) } SortedBytesMap /** * A read only map of `id` =\u0026gt; `byte array` sorted by id, where `id` is a long if [longIdentifiers] * is true and an int otherwise. Each entry has a value byte array of size [bytesPerValue]. * * Instances are created by [UnsortedByteEntries] * * [get] and [contains] perform a binary search to locate a specific entry by key. */ internal class SortedBytesMap( private val longIdentifiers: Boolean, private val bytesPerValue: Int, private val sortedEntries: ByteArray ) { private val bytesPerKey = if (longIdentifiers) 8 else 4 private val bytesPerEntry = bytesPerKey + bytesPerValue private val size = sortedEntries.size / bytesPerEntry operator get operator fun get(key: Long): ByteSubArray? { val keyIndex = binarySearch(key) if (keyIndex \u0026lt; 0) { return null } val valueIndex = keyIndex * bytesPerEntry + bytesPerKey return ByteSubArray(sortedEntries, valueIndex, bytesPerValue, longIdentifiers) } binarySearch(二分查找) private fun binarySearch( key: Long ): Int { val startIndex = 0 val endIndex = size var lo = startIndex var hi = endIndex - 1 while (lo \u0026lt;= hi) { val mid = (lo + hi).ushr(1) val midVal = keyAt(mid) when { midVal \u0026lt; key -\u0026gt; lo = mid + 1 midVal \u0026gt; key -\u0026gt; hi = mid - 1 else -\u0026gt; return mid } } return lo.inv() } LongLongScatterMap getSlot /** * Being given a key looks it up in the map and returns the slot where element sits, so it later * can be retrieved with [getSlotValue]; return \u0026#39;-1\u0026#39; if element not found. * Why so complicated and not just make [get] return null if value not found? The reason is performance: * this approach prevents unnecessary boxing of the primitive long that would happen with nullable Long? */ fun getSlot(key: Long): Int { if (key == 0L) { return if (hasEmptyKey) mask + 1 else -1 } else { val keys = this.keys val mask = this.mask var slot = hashKey(key) and mask var existing = keys[slot] while (existing != 0L) { if (existing == key) { return slot } slot = slot + 1 and mask existing = keys[slot] } return -1 } } getSlotValue * Being given a slot of element retrieves it from the collection */ fun getSlotValue(slot: Int): Long = values[slot] "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/7koomsource/",
	"title": "7KOOMSource",
	"tags": [],
	"description": "",
	"content": "Module Dependencies graph TB demo--\u0026gt;java-oom java-oom--\u0026gt;koom-kwailinker java-oom--\u0026gt;koom-xhook java-oom--\u0026gt;koom-shark LeakDetector Hierarchy graph TB LeakDetector--\u0026gt;ActivityLeakDetector LeakDetector--\u0026gt;NativeAllocationRegistryLeakDetector LeakDetector--\u0026gt;WindowLeakDetector LeakDetector--\u0026gt;BitmapLeakDetector LeakDetector--\u0026gt;FragmentLeakDetector HprofStrip Detail KOOM.init /** * KOOM entry point, make sure be called in the main thread! * * @param application application needed */ public static void init(Application application) { if (koom == null) { koom = new KOOM(application); } koom.start(); } private KOOM(Application application) { internal = new KOOMInternal(application); } public KOOMInternal(Application application) { KUtils.startup(); buildConfig(application); heapDumpTrigger = new HeapDumpTrigger(); heapAnalysisTrigger = new HeapAnalysisTrigger(); ProcessLifecycleOwner.get().getLifecycle().addObserver(heapAnalysisTrigger); } buildConfig private void buildConfig(Application application) { //setApplication must be the first  KGlobalConfig.setApplication(application); KGlobalConfig.setKConfig(KConfig.defaultConfig()); } new HeapDumpTrigger implements KTrigger\npublic HeapDumpTrigger() { monitorManager = new MonitorManager(); monitorManager.addMonitor(new HeapMonitor()); heapDumper = new ForkJvmHeapDumper(); } MonitorManager public MonitorManager() { monitors = new ArrayList\u0026lt;\u0026gt;(); monitorThread = new MonitorThread(); } public void addMonitor(Monitor monitor) { monitors.add(monitor); } MonitorThread public MonitorThread() { thread = new HandlerThread(\u0026#34;MonitorThread\u0026#34;); thread.start(); handler = new Handler(thread.getLooper()); } HeapMonitor /* HeapMonitor watch JVM heap running info, * and trigger when heap is over threshold * several times as HeapThreshold set. */ class HeapMonitor implements Monitor @Override public boolean isTrigger() { return currentTimes \u0026gt;= heapThreshold.overTimes(); } new ForkJvmHeapDumper // A jvm hprof dumper which use fork and don\u0026rsquo;t block main process.\npublic ForkJvmHeapDumper() { soLoaded = KGlobalConfig.getSoLoader().loadLib(\u0026#34;koom-java\u0026#34;); if (soLoaded) { initForkDump(); } } new HeapAnalysisTrigger implements KTrigger\n两个Trigger监听前后台切换通知 startInKOOMThread public void start() { internal.start(); } public void start() { HandlerThread koomThread = new HandlerThread(\u0026#34;koom\u0026#34;); koomThread.start(); koomHandler = new Handler(koomThread.getLooper()); startInKOOMThread(); } private void startInKOOMThread() { koomHandler.postDelayed(this::startInternal, KConstants.Perf.START_DELAY); } private void startInternal() { heapDumpTrigger.setHeapDumpListener(this); heapAnalysisTrigger.setHeapAnalysisListener(this); ReanalysisChecker reanalysisChecker = new ReanalysisChecker(); if (reanalysisChecker.detectReanalysisFile() != null) { KLog.i(TAG, \u0026#34;detected reanalysis file\u0026#34;); heapAnalysisTrigger.trigger(TriggerReason.analysisReason(TriggerReason.AnalysisReason.REANALYSIS)); return; } heapDumpTrigger.startTrack(); } setHeapDumpAndAnalysisListener \u0026hellip;\nTryTriggerAnalysisWhenDetectReanalysisFile heapDumpTrigger.startTrack() @Override public void startTrack() { monitorManager.start(); monitorManager.setTriggerListener((monitorType, reason) -\u0026gt; { trigger(reason); return true; }); } monitorManager.start\npublic void start() { monitorThread.start(monitors); } MonitorThread.start public void start(List\u0026lt;Monitor\u0026gt; monitors) { stop = false; List\u0026lt;Runnable\u0026gt; runnables = new ArrayList\u0026lt;\u0026gt;(); for (Monitor monitor : monitors) { monitor.start(); runnables.add(new MonitorRunnable(monitor)); } for (Runnable runnable : runnables) { handler.post(runnable); } } HeapMonitor.start @Override public void start() { started = true; if (heapThreshold == null) { heapThreshold = KGlobalConfig.getHeapThreshold(); } } MonitorRunnable.run class MonitorRunnable implements Runnable { @Override public void run() { if (monitor.isTrigger()) { stop = monitorTriggerListener.onTrigger(monitor.monitorType(), monitor.getTriggerReason()); } if (!stop) { handler.postDelayed(this, monitor.pollInterval()); } } } monitorManager.setTriggerListener \u0026hellip;\nHeapDumpTrigger.trigger @Override public void trigger(TriggerReason reason) { if (triggered) { KLog.e(TAG, \u0026#34;Only once trigger!\u0026#34;); return; } triggered = true; monitorManager.stop(); KLog.i(TAG, \u0026#34;trigger reason:\u0026#34; + reason.dumpReason); if (heapDumpListener != null) { heapDumpListener.onHeapDumpTrigger(reason.dumpReason); } try { doHeapDump(reason.dumpReason); } catch (Exception e) { KLog.e(TAG, \u0026#34;doHeapDump failed\u0026#34;); e.printStackTrace(); if (heapDumpListener != null) { heapDumpListener.onHeapDumpFailed(); } } KVData.addTriggerTime(KGlobalConfig.getRunningInfoFetcher().appVersion()); } public void doHeapDump(TriggerReason.DumpReason reason) { KLog.i(TAG, \u0026#34;doHeapDump\u0026#34;); KHeapFile.getKHeapFile().buildFiles(); HeapAnalyzeReporter.addDumpReason(reason); HeapAnalyzeReporter.addDeviceRunningInfo(); boolean res = heapDumper.dump(KHeapFile.getKHeapFile().hprof.path); if (res) { heapDumpListener.onHeapDumped(reason); } else { KLog.e(TAG, \u0026#34;heap dump failed!\u0026#34;); heapDumpListener.onHeapDumpFailed(); KHeapFile.delete(); } } ForkJvmHeapDumper.dump @Override public boolean dump(String path) { boolean dumpRes = false; try { int pid = trySuspendVMThenFork(); if (pid == 0) { Debug.dumpHprofData(path); KLog.i(TAG, \u0026#34;notifyDumped:\u0026#34; + dumpRes); //System.exit(0);  exitProcess(); } else { resumeVM(); dumpRes = waitDumping(pid); KLog.i(TAG, \u0026#34;hprof pid:\u0026#34; + pid + \u0026#34; dumped: \u0026#34; + path); } } catch (IOException e) { e.printStackTrace(); KLog.e(TAG, \u0026#34;dump failed caused by IOException!\u0026#34;); } return dumpRes; } trySuspendVMThenFork /** * First do suspend vm, then do fork. * @return result of fork */ private native int trySuspendVMThenFork();//C层对应_ZN3art3Dbg9SuspendVMEv这个符号方法调用以及fork系统调用 forked process Debug.dumpHprofData exitProcess main Process resumeVM /** * Resume the VM. */ private native void resumeVM();//对应的方法符号为“_ZN3art3Dbg8ResumeVMEv” waitPid private boolean waitDumping(int pid) { waitPid(pid); return true; } /** * Wait process exit. * * @param pid waited process. */ private native void waitPid(int pid);//系统调用 heapDumpListener.onHeapDumped KOOMInternal\n@Override public void onHeapDumped(TriggerReason.DumpReason reason) { KLog.i(TAG, \u0026#34;onHeapDumped\u0026#34;); changeProgress(KOOMProgressListener.Progress.HEAP_DUMPED); //Crash cases need to reanalyze next launch and not do analyze right now.  if (reason != TriggerReason.DumpReason.MANUAL_TRIGGER_ON_CRASH) { heapAnalysisTrigger.startTrack(); } else { KLog.i(TAG, \u0026#34;reanalysis next launch when trigger on crash\u0026#34;); } } heapAnalysisTrigger.startTrack @Override public void startTrack() { KTriggerStrategy strategy = strategy(); if (strategy == KTriggerStrategy.RIGHT_NOW) { trigger(TriggerReason.analysisReason(TriggerReason.AnalysisReason.RIGHT_NOW)); } } @Override public void trigger(TriggerReason triggerReason) { doAnalysis(KGlobalConfig.getApplication()); HeapAnalyzeService.runAnalysis public void doAnalysis(Application application) { HeapAnalyzeService.runAnalysis(application, heapAnalysisListener); } public static void runAnalysis(Application application, HeapAnalysisListener heapAnalysisListener) { KLog.i(TAG, \u0026#34;runAnalysis startService\u0026#34;); Intent intent = new Intent(application, HeapAnalyzeService.class); IPCReceiver ipcReceiver = buildAnalysisReceiver(heapAnalysisListener); intent.putExtra(KConstants.ServiceIntent.RECEIVER, ipcReceiver); KHeapFile heapFile = KHeapFile.getKHeapFile(); intent.putExtra(KConstants.ServiceIntent.HEAP_FILE, heapFile); application.startService(intent); } private static IPCReceiver buildAnalysisReceiver(HeapAnalysisListener heapAnalysisListener) { return new IPCReceiver(new IPCReceiver.ReceiverCallback() { @Override public void onSuccess() { KLog.i(TAG, \u0026#34;IPC call back, heap analysis success\u0026#34;); heapAnalysisListener.onHeapAnalyzed(); } @Override public void onError() { KLog.i(TAG, \u0026#34;IPC call back, heap analysis failed\u0026#34;); heapAnalysisListener.onHeapAnalyzeFailed(); } }); } onHandleIntent @Override protected void onHandleIntent(Intent intent) { boolean res = false; beforeAnalyze(intent); res = doAnalyze(); if (ipcReceiver != null) { ipcReceiver.send(res ? IPCReceiver.RESULT_CODE_OK : IPCReceiver.RESULT_CODE_FAIL, null); } } heapAnalyzer.analyze /** run in the heap_analysis process */ private boolean doAnalyze() { return heapAnalyzer.analyze(); } KHeapAnalyzer.analyze public KHeapAnalyzer(KHeapFile heapFile) { leaksFinder = new SuspicionLeaksFinder(heapFile.hprof); } public boolean analyze() { KLog.i(TAG, \u0026#34;analyze\u0026#34;); Pair\u0026lt;List\u0026lt;ApplicationLeak\u0026gt;, List\u0026lt;LibraryLeak\u0026gt;\u0026gt; leaks = leaksFinder.find(); if (leaks == null) { return false; } //Add gc path to report file.  HeapAnalyzeReporter.addGCPath(leaks, leaksFinder.leakReasonTable); //Add done flag to report file.  HeapAnalyzeReporter.done(); return true; } SuspicionLeaksFinder.find public SuspicionLeaksFinder(KHeapFile.Hprof hprof) { leakingObjects = new HashSet\u0026lt;\u0026gt;(); leakDetectors = new ArrayList\u0026lt;\u0026gt;(); computeGenerations = new HashSet\u0026lt;\u0026gt;(); this.hprofFile = hprof; } public Pair\u0026lt;List\u0026lt;ApplicationLeak\u0026gt;, List\u0026lt;LibraryLeak\u0026gt;\u0026gt; find() { boolean indexed = buildIndex();//just as shark in leakcannary  if (!indexed) { return null; } initLeakDetectors(); findLeaks(); return findPath(); } buildIndex \u0026hellip;\u0026hellip;\ninitLeakDetectors private void initLeakDetectors() { addDetector(new ActivityLeakDetector(heapGraph)); addDetector(new FragmentLeakDetector(heapGraph)); addDetector(new BitmapLeakDetector(heapGraph)); addDetector(new NativeAllocationRegistryLeakDetector(heapGraph)); addDetector(new WindowLeakDetector(heapGraph)); ClassHierarchyFetcher.initComputeGenerations(computeGenerations); leakReasonTable = new HashMap\u0026lt;\u0026gt;(); } private void addDetector(LeakDetector leakDetector) { leakDetectors.add(leakDetector); computeGenerations.add(leakDetector.generation()); } findLeaks //use for findLeaks, corresponding to find the leak instance during monitoring in leakcanary public void findLeaks() { KLog.i(TAG, \u0026#34;start find leaks\u0026#34;); //遍历镜像的所有instance  Sequence\u0026lt;HeapObject.HeapInstance\u0026gt; instances = heapGraph.getInstances(); Iterator\u0026lt;HeapObject.HeapInstance\u0026gt; instanceIterator = instances.iterator(); while (instanceIterator.hasNext()) { HeapObject.HeapInstance instance = instanceIterator.next(); if (instance.isPrimitiveWrapper()) { continue; } ClassHierarchyFetcher.process(instance.getInstanceClassId(), instance.getInstanceClass().getClassHierarchy()); for (LeakDetector leakDetector : leakDetectors) { if (leakDetector.isSubClass(instance.getInstanceClassId()) \u0026amp;\u0026amp; leakDetector.isLeak(instance)) { ClassCounter classCounter = leakDetector.instanceCount(); if (classCounter.leakInstancesCount \u0026lt;= SAME_CLASS_LEAK_OBJECT_GC_PATH_THRESHOLD) { leakingObjects.add(instance.getObjectId()); leakReasonTable.put(instance.getObjectId(), leakDetector.leakReason()); } } } } //关注class和对应instance数量，加入json  HeapAnalyzeReporter.addClassInfo(leakDetectors); findPrimitiveArrayLeaks(); findObjectArrayLeaks(); } findPath public Pair\u0026lt;List\u0026lt;ApplicationLeak\u0026gt;, List\u0026lt;LibraryLeak\u0026gt;\u0026gt; findPath() { KLog.i(TAG, \u0026#34;findPath object size:\u0026#34; + leakingObjects.size()); HeapAnalyzer.FindLeakInput findLeakInput = new HeapAnalyzer.FindLeakInput(heapGraph, AndroidReferenceMatchers.Companion.getAppDefaults(), false, Collections.emptyList()); kotlin.Pair\u0026lt;List\u0026lt;ApplicationLeak\u0026gt;, List\u0026lt;LibraryLeak\u0026gt;\u0026gt; pair = new HeapAnalyzer(step -\u0026gt; KLog.i(TAG, \u0026#34;step:\u0026#34; + step.name())) .findLeaks(findLeakInput, leakingObjects, true); return new Pair\u0026lt;\u0026gt;((List\u0026lt;ApplicationLeak\u0026gt;) pair.getFirst(), (List\u0026lt;LibraryLeak\u0026gt;) pair.getSecond()); } HeapAnalyzeReporter.addGCPath \u0026hellip;\nHeapAnalyzeReporter.done onSuccess\u0026ndash;\u0026gt;heapAnalysisListener.onHeapAnalyzed 参考 KGlobalConfig public static String getReportDir() { return reportDir = getRootDir() + File.separator + REPORT_DIR; } public static String getHprofDir() { return hprofDir = getRootDir() + File.separator + HPROF_DIR; } //* See KHeapFile, each contains a pair of hprof and report which file prefix is same.\nReanalysisChecker public KHeapFile detectReanalysisFile() { File reportDir = new File(KGlobalConfig.getReportDir()); File[] reports = reportDir.listFiles(); if (reports == null) { return null; } for (File report : reports) { HeapReport heapReport = loadFile(report); if (analysisNotDone(heapReport)) { if (!overReanalysisMaxTimes(heapReport)) { KLog.i(TAG, \u0026#34;find reanalyze report\u0026#34;); return buildKHeapFile(report); } else { KLog.e(TAG, \u0026#34;Reanalyze \u0026#34; + report.getName() + \u0026#34; too many times\u0026#34;); //Reanalyze too many times, and the hporf is abnormal, so delete them.  File hprof = findHprof(getReportFilePrefix(report)); if (hprof != null) { hprof.delete(); } report.delete(); } } } return null; } buildKHeapFile private KHeapFile buildKHeapFile(File report) { String reportPrefix = getReportFilePrefix(report); File hprof = findHprof(reportPrefix); if (hprof != null) { return KHeapFile.buildInstance(hprof, report); } else { KLog.e(TAG, \u0026#34;Reanalyze hprof file not found!\u0026#34;); report.delete(); } return null; } KHeapFile implements Parcelable public Hprof hprof; public Report report; buildInstance public static KHeapFile buildInstance(File hprof, File report) { kHeapFile = getKHeapFile(); kHeapFile.hprof = new Hprof(hprof.getAbsolutePath()); kHeapFile.report = new Report(report.getAbsolutePath()); return kHeapFile; } HeapAnalyzer FindLeakInput.findLeaks //corresponding to shark in leakcanary //增加同类对象数量阈值剪枝 public fun FindLeakInput.findLeaks(leakingObjectIds: Set\u0026lt;Long\u0026gt;, enableSameInstanceThreshold: Boolean): Pair\u0026lt;List\u0026lt;ApplicationLeak\u0026gt;, List\u0026lt;LibraryLeak\u0026gt;\u0026gt; { SharkLog.d { \u0026#34;start findLeaks\u0026#34; } val pathFinder = PathFinder(graph, listener, referenceMatchers, enableSameInstanceThreshold) val pathFindingResults = pathFinder.findPathsFromGcRoots(leakingObjectIds, computeRetainedHeapSize) SharkLog.d { \u0026#34;Found ${leakingObjectIds.size}retained objects\u0026#34; } return buildLeakTraces(pathFindingResults) } ClassHierarchyFetcher // key: current class ; value: subclass according to every detector class private Map\u0026lt;Long, List\u0026lt;ClassGeneration\u0026gt;\u0026gt; classGenerations; getIdOfGeneration public static long getIdOfGeneration(long classId, int generation) { List\u0026lt;ClassGeneration\u0026gt; generations = getClassGenerations().get(classId); if (generations == null) { return 0; } for (ClassGeneration classGeneration : generations) { if (classGeneration.generation == generation) { return classGeneration.id; } } return 0; } LeakDetector isSubClass /** * LeakDetector try\u0026#39;s to find the detect class\u0026#39;s leaked instance and first we need to judge * whether the object\u0026#39;s class is sub class of LeakDetector\u0026#39;s detect class. * \u0026lt;p\u0026gt; * See generation(), if the instance\u0026#39;s class is sub class of detect class, then it\u0026#39;s * \u0026#39;Generation\u0026#39; position class id is same with the detect class. * \u0026lt;p\u0026gt; * Using generation to judge subclass instance is the relatively more efficient way. * * @param classId instance class id * @return whether the instance class id is sub class of this leak detector\u0026#39;s detect class. */ boolean isSubClass(long classId) { return ClassHierarchyFetcher.getIdOfGeneration(classId, generation()) == classId(); } Hprof_dump.cpp JNIEXPORT jboolean JNICALL Java_com_kwai_koom_javaoom_dump_ForkJvmHeapDumper_initForkDump(JNIEnv *env, jobject jObject) { return initForkVMSymbols(); } bool initForkVMSymbols() { bool res = false; void *libHandle = kwai::linker::DlFcn::dlopen(\u0026#34;libart.so\u0026#34;, RTLD_NOW); suspendVM = (void (*)())kwai::linker::DlFcn::dlsym(libHandle, \u0026#34;_ZN3art3Dbg9SuspendVMEv\u0026#34;); resumeVM = (void (*)())kwai::linker::DlFcn::dlsym(libHandle, \u0026#34;_ZN3art3Dbg8ResumeVMEv\u0026#34;); kwai::linker::DlFcn::dlclose(libHandle); return suspendVM != nullptr \u0026amp;\u0026amp; resumeVM != nullptr; } exitProcess/waitPid JNIEXPORT void JNICALL Java_com_kwai_koom_javaoom_dump_ForkJvmHeapDumper_exitProcess(JNIEnv *env, jobject jObject) { _exit(0); } JNIEXPORT void JNICALL Java_com_kwai_koom_javaoom_dump_ForkJvmHeapDumper_waitPid(JNIEnv *env, jobject jObject, jint pid) { int status; waitpid(pid, \u0026amp;status, 0); } initStripDump(used by StripHprofHeapDumper) JNIEXPORT void JNICALL Java_com_kwai_koom_javaoom_dump_StripHprofHeapDumper_initStripDump(JNIEnv *env, jobject jObject) { hprofFd = -1; hprofName = nullptr; isDumpHookSucc = false; xhook_enable_debug(0); /** * * android 7.x，write方法在libc.so中 * android 8-9，write方法在libart.so中 * android 10，write方法在libartbase.so中 * libbase.so是一个保险操作，防止前面2个so里面都hook不到(: * * android 7-10版本，open方法都在libart.so中 * libbase.so与libartbase.so，为保险操作 */ xhook_register(\u0026#34;libart.so\u0026#34;, \u0026#34;open\u0026#34;, (void *)hook_open, nullptr); xhook_register(\u0026#34;libbase.so\u0026#34;, \u0026#34;open\u0026#34;, (void *)hook_open, nullptr); xhook_register(\u0026#34;libartbase.so\u0026#34;, \u0026#34;open\u0026#34;, (void *)hook_open, nullptr); xhook_register(\u0026#34;libc.so\u0026#34;, \u0026#34;write\u0026#34;, (void *)hook_write, nullptr); xhook_register(\u0026#34;libart.so\u0026#34;, \u0026#34;write\u0026#34;, (void *)hook_write, nullptr); xhook_register(\u0026#34;libbase.so\u0026#34;, \u0026#34;write\u0026#34;, (void *)hook_write, nullptr); xhook_register(\u0026#34;libartbase.so\u0026#34;, \u0026#34;write\u0026#34;, (void *)hook_write, nullptr); xhook_refresh(0); xhook_clear(); } hook_write ssize_t hook_write(int fd, const void *buf, size_t count) { if (fd != hprofFd) { ssize_t total_write = write(fd, buf, count); return total_write; } //每次hook_write，初始化重置  reset(); const unsigned char tag = ((unsigned char *)buf)[0]; //删除掉无关record tag类型匹配，只匹配heap相关提高性能  switch (tag) { case HPROF_TAG_HEAP_DUMP: case HPROF_TAG_HEAP_DUMP_SEGMENT: { processHeap(buf, HEAP_TAG_BYTE_SIZE + RECORD_TIME_BYTE_SIZE + RECORD_LENGTH_BYTE_SIZE, count, heapSerialNum, 0); heapSerialNum++; } break; default: break; } //根据裁剪掉的zygote space和image space更新length  int recordLength = 0; if (tag == HPROF_TAG_HEAP_DUMP || tag == HPROF_TAG_HEAP_DUMP_SEGMENT) { recordLength = getIntFromBytes((unsigned char *)buf, HEAP_TAG_BYTE_SIZE + RECORD_TIME_BYTE_SIZE); recordLength -= stripBytesSum; int index = HEAP_TAG_BYTE_SIZE + RECORD_TIME_BYTE_SIZE; ((unsigned char *)buf)[index] = (unsigned char)(((unsigned int)recordLength \u0026amp; 0xff000000u) \u0026gt;\u0026gt; 24u); ((unsigned char *)buf)[index + 1] = (unsigned char)(((unsigned int)recordLength \u0026amp; 0x00ff0000u) \u0026gt;\u0026gt; 16u); ((unsigned char *)buf)[index + 2] = (unsigned char)(((unsigned int)recordLength \u0026amp; 0x0000ff00u) \u0026gt;\u0026gt; 8u); ((unsigned char *)buf)[index + 3] = (unsigned char)((unsigned int)recordLength \u0026amp; 0x000000ffu); } ssize_t total_write = 0; int startIndex = 0; for (int i = 0; i \u0026lt; stripIndex; i++) { //将裁剪掉的区间，通过写时过滤掉, that is, only write stripIndexListPair[i * 2 + 1] —— stripIndexListPair[（i + 1） * 2] area  void *writeBuf = (void *)((unsigned char *)buf + startIndex); auto writeLen = (size_t)(stripIndexListPair[i * 2] - startIndex); if (writeLen \u0026gt; 0) { total_write += write(fd, writeBuf, writeLen); } else if (writeLen \u0026lt; 0) { __android_log_print(ANDROID_LOG_ERROR, \u0026#34;HprofDump\u0026#34;, \u0026#34;hook_write array i:%d writeLen\u0026lt;0:%lu\u0026#34;, i, writeLen); } startIndex = stripIndexListPair[i * 2 + 1]; } //write tail bytes  auto writeLen = (size_t)(count - startIndex); if (writeLen \u0026gt; 0) { void *writeBuf = (void *)((unsigned char *)buf + startIndex); total_write += write(fd, writeBuf, count - startIndex); } hookWriteSerialNum++; if (total_write != count) { __android_log_print(ANDROID_LOG_INFO, \u0026#34;HprofDump\u0026#34;, \u0026#34;hook write, hprof strip happens\u0026#34;); } return count; } processHeap int processHeap(const void *buf, int firstIndex, int maxLen, int heapSerialNo, int arraySerialNo) { if (firstIndex \u0026gt;= maxLen) { return arraySerialNo; } const unsigned char subtag = ((unsigned char *)buf)[firstIndex]; switch (subtag) { case HPROF_OBJECT_ARRAY_DUMP: { int length = getIntFromBytes((unsigned char *)buf, firstIndex + HEAP_TAG_BYTE_SIZE + OBJECT_ID_BYTE_SIZE + STACK_TRACE_SERIAL_NUMBER_BYTE_SIZE); //裁剪掉system space  //stripBytesSum = 本次记录的stripIndexListPair区间(待裁剪掉的区域)长度，  //stripIndex++固定一次;  if (isCurrentSystemHeap) { stripIndexListPair[stripIndex * 2] = firstIndex; stripIndexListPair[stripIndex * 2 + 1] = firstIndex + HEAP_TAG_BYTE_SIZE + OBJECT_ID_BYTE_SIZE + STACK_TRACE_SERIAL_NUMBER_BYTE_SIZE + U4 /*Length*/ + CLASS_ID_BYTE_SIZE + U4 /*Id*/ * length; stripIndex++; stripBytesSum += HEAP_TAG_BYTE_SIZE + OBJECT_ID_BYTE_SIZE + STACK_TRACE_SERIAL_NUMBER_BYTE_SIZE + U4 /*Length*/ + CLASS_ID_BYTE_SIZE + U4 /*Id*/ * length; } arraySerialNo = processHeap(buf, firstIndex + HEAP_TAG_BYTE_SIZE + OBJECT_ID_BYTE_SIZE + STACK_TRACE_SERIAL_NUMBER_BYTE_SIZE + U4 /*Length*/ + CLASS_ID_BYTE_SIZE + U4 /*Id*/ * length, maxLen, heapSerialNo, arraySerialNo); } break; } } reset const int STRIP_LIST_LENGTH = 65536 * 2 * 2 + 2; int stripIndexListPair[STRIP_LIST_LENGTH];//stripIndex*2 —— stripIndex*2+1 indicate that area need to be stripped int stripIndex = 0; int stripBytesSum = 0; void reset() { stripIndex = 0; stripBytesSum = 0; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/jni/_%E8%A7%A3%E9%87%8A%E6%89%A7%E8%A1%8C7_0/",
	"title": "_解释执行7_0",
	"tags": [],
	"description": "",
	"content": "quick_entrypoints_x86.S art_quick_invoke_stub /*这段注释来自于源码，它展示了调用art_quick_invoke_stub函数时，相关参数在栈中的布局 * Quick invocation stub (non-static). * On entry: * [sp] = return address 返回值地址，这是由函数调用指令自动压入栈的 * [sp + 4] = method pointer 代表方法C的ArtMethod对象 * [sp + 8] = argument array or null for no argument methods * [sp + 12] = size of argument array in bytes * [sp + 16] = (managed) thread pointer 这是代表调用线程的Thread对象 * [sp + 20] = JValue* result * [sp + 24] = shorty */ DEFINE_FUNCTION art_quick_invoke_stub #定义art_quick_invoke_stub函数  PUSH ebp // save ebp PUSH ebx // save ebx PUSH esi // save esi PUSH edi // save edi ...... //处理浮点寄存器、扩展栈空间等 //下面的循环用于从args中拷贝参数到栈上。此处保留代码中原有的注释 movl 28(%ebp), %ecx // ECX = size of args movl 24(%ebp), %esi // ESI = argument array leal 4(%esp), %edi // EDI = just after Method* in stack arguments rep movsb // while (ecx--) { *edi++ = *esi++ } ...... //略过其他代码 .Lgpr_setup_finished: #至此，参数已经准备好。下面将进入ArtMethod对象的机器码入口  mov 20(%ebp), %eax //EBP+20处保存着ArtMethod* C对象，将其拷贝 到EAX中 #跳转到这个ArtMethod对象机器码入口对应的地方。main  call *ART_METHOD_QUICK_CODE_OFFSET_32(%eax) ..... //恢复栈，设置返回值到result中 ret END_FUNCTION art_quick_invoke_stub art_quick_to_interpreter_bridge #DEFINE_FUNCTION是一个宏，用于定义一个函数。下面将定义 #art_quick_to_interpreter_bridge函数 DEFINE_FUNCTION art_quick_to_interpreter_bridge #下面这个宏在10.1.3.1.3节介绍过了，执行其中的汇编指令后，栈的布局将变成如图10-4所示的样子。  SETUP_REFS_AND_ARGS_CALLEE_SAVE_FRAME ebx, ebx mov %esp, %edx #将ESP保存到EDX中  PUSH eax #EAX入栈，EAX寄存器的值代表被调用方法的ArtMethod对象。  PUSH edx #EDX入栈，  pushl %fs:THREAD_SELF_OFFSET #获取当前线程的Thread对象，并压入栈中  PUSH eax #EAX入栈。  call SYMBOL(artQuickToInterpreterBridge) #main  #调用目标函数  #参数出栈，恢复到SETUP_REFS_AND_ARGS_CALLEE_SAVE_FRAME执行后的栈状态  addl LITERAL(16), %esp ...... #下面三行代码用于处理返回值，xmm为浮点寄存，64位长，而eax，edx为32位长。  #下面这三行代码执行往后，xmm0的低32位的值来自EAX，高32位的值来自EDX。  movd %eax, %xmm0 movd %edx, %xmm1 punpckldq %xmm1, %xmm0 #将xmm1和xmm0低32位的值组合起来存储到xmm0中。  #调整栈顶位置  addl LITERAL(48), %esp POP ebp POP esi POP edi RETURN_OR_DELIVER_PENDING_EXCEPTION #函数返回或抛异常（10.6节将介绍它）,main END_FUNCTION art_quick_to_interpreter_bridge quick_trampoline_entrypoints.cc artQuickToInterpreterBridge extern \u0026#34;C\u0026#34; uint64_t artQuickToInterpreterBridge(ArtMethod* method, Thread* self, ArtMethod** sp) { //参数method代表当前被调用的Java方法，我们用图10-7中的ArtMethod* B表示它  ScopedQuickEntrypointChecks sqec(self); JValue tmp_value; /*PopStackedShadowFrame和Thread对栈的管理有关。此处假设是从机器码跳转到解释执行模式， 并且不是HDeoptimize的情况，那么，该函数返回值deopt_frame为nullptr。 */ ShadowFrame* deopt_frame = self-\u0026gt;PopStackedShadowFrame( StackedShadowFrameType::kSingleFrameDeoptimizationShadowFrame, false); ManagedStack fragment; //重要：构造一个ManagedStack对象。  uint32_t shorty_len = 0; //如果不是代理方法的话，non_proxy_method就是ArtMethod* B本身。  ArtMethod* non_proxy_method = method-\u0026gt;GetInterfaceMethodIfProxy(sizeof(void*)); const DexFile::CodeItem* code_item = non_proxy_method-\u0026gt;GetCodeItem(); const char* shorty = non_proxy_method-\u0026gt;GetShorty(\u0026amp;shorty_len); JValue result; //存储方法调用的返回值  if (deopt_frame != nullptr) { ..... //和HDeoptimize有关，后续章节再介绍它  } else { const char* old_cause = ......; uint16_t num_regs = code_item-\u0026gt;registers_size_; //创建代表ArtMethod B的栈帧对象ShawFrame。注意，它的link_取值为nullptr，  //dex_pc_取值为0  ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, /* link */ nullptr, method, /* dex pc */ 0); ShadowFrame* shadow_frame = shadow_frame_unique_ptr.get(); size_t first_arg_reg = code_item-\u0026gt;registers_size_ - code_item-\u0026gt;ins_size_; //借助BuildQuickShadowFrameVisitor将调用参数放到shadow_frame对象中  BuildQuickShadowFrameVisitor shadow_frame_builder(sp, method-\u0026gt;IsStatic(), shorty, shorty_len, shadow_frame, first_arg_reg); shadow_frame_builder.VisitArguments(); //判断ArtMethod* B所属的类是否已经初始化  const bool needs_initialization = method-\u0026gt;IsStatic() \u0026amp;\u0026amp; !method-\u0026gt;GetDeclaringClass()-\u0026gt;IsInitialized(); //重要：下面两行代码将fragment和shadow_frame放到Thread类对应的成员变量中去处理  //我们后续再讨论这部分内容  self-\u0026gt;PushManagedStackFragment(\u0026amp;fragment); self-\u0026gt;PushShadowFrame(shadow_frame); ...... //如果ArtMethod B所属类没有初始化，则先初始化它。类初始化就是调用ClassLinker的Ensure-  //Initialized函数  if (needs_initialization) { StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Class\u0026gt; h_class(hs.NewHandle( shadow_frame-\u0026gt;GetMethod()-\u0026gt;GetDeclaringClass())); if (!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized( self, h_class, true, true)) {......} } //解释执行的入口函数  result = interpreter::EnterInterpreterFromEntryPoint(self, code_item, shadow_frame);//main  } //和Thread对栈的管理有关  self-\u0026gt;PopManagedStackFragment(fragment); //根据sp的位置找到本方法的调用者，以图10-7为例，即找到ArtMethod* A，是它调用了本方  //法（对应为ArtMethod* B）。  ArtMethod* caller = QuickArgumentVisitor::GetCallingMethod(sp); if (UNLIKELY(Dbg::IsForcedInterpreterNeededForUpcall(self, caller))) { //和HDeoptimize有关  //和HDeoptimize有关  self-\u0026gt;PushDeoptimizationContext(result, shorty[0] == \u0026#39;L\u0026#39;, /* from_code */ false, self-\u0026gt;GetException()); self-\u0026gt;SetException(Thread::GetDeoptimizationException()); } return result.GetJ(); //artQuickToInterpreterBridge返回  } } interpreter.h/cc EnterInterpreterFromEntryPoint extern JValue EnterInterpreterFromEntryPoint( Thread* self, //代表调用线程的Thread对象  const DexFile::CodeItem* code_item, //方法B的dex指令码内容  ShadowFrame* shadow_frame //方法B所需的参数 ); JValue EnterInterpreterFromEntryPoint(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame* shadow_frame) { ...... //下面这段代码和JIT有关，相关知识见本章后续对JIT的介绍  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;NotifyCompiledCodeToInterpreterTransition(self, shadow_frame-\u0026gt;GetMethod()); } //关键函数  return Execute(self, code_item, *shadow_frame, JValue());//main } Execute static inline JValue Execute(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame\u0026amp; shadow_frame,JValue result_register, bool stay_in_interpreter = false) { /*注意stay_in_interpreter参数，它表示是否强制使用解释执行模式。默认为false，它表示如果 方法B存在jit编译得到的机器码，则转到jit去执行。 */ /*下面这个if条件的判断很有深意。我们在本章解释图10-5里ShadowFrame成员变量时曾说过，如果 是HDeoptimize的情况，ShadowFrame的dex_pc_不是0（这表示有一部分指令以机器码方式执 行）。如果dex_pc_为0的话，则表示该方法从一开始就将以解释方式执行。我们称这种情况为纯解 释执行的方法，此时，我们就需要检查它是否存在JIT的情况。 */ if (LIKELY(shadow_frame.GetDexPC() == 0)) { instrumentation::Instrumentation* instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); ArtMethod *method = shadow_frame.GetMethod(); if (UNLIKELY(instrumentation-\u0026gt;HasMethodEntryListeners())) { instrumentation-\u0026gt;MethodEnterEvent(self, shadow_frame.GetThisObject(code_item-\u0026gt;ins_size_), method, 0); } //判断这个需要纯解释执行的方法是否经过JIT编译了  if (!stay_in_interpreter) { jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;MethodEntered(self, shadow_frame.GetMethod()); if (jit-\u0026gt;CanInvokeCompiledCode(method)) { ...... //转入jit编译的机器码去执行并返回结果  } } } } //dex_pc_是否为0判断结束  ...... //下面是解释执行的处理逻辑  ArtMethod* method = shadow_frame.GetMethod(); //transaction_active和dex2oat编译逻辑有关，完整虚拟机运行时候返回false  bool transaction_active = Runtime::Current()-\u0026gt;IsActiveTransaction(); //是否略过Access检查，即判断是否有权限执行本方法。大部分情况下该if条件是满足的  if (LIKELY(method-\u0026gt;SkipAccessChecks())) { /*main,在ART虚拟机中，解释执行的实现方式有三种，由kInterpreterImplKind取值来控制： （1）kMterpImplKind：根据不同CPU平台，采用对应汇编语言编写的，基于goto逻辑的实现。 这也是kInterpreterImplKind的默认取值。 （2）kSwitchImplKind：由C++编写，基于switch/case逻辑实现。 （3）kComputedGotoImplKind：由C++编写，基于goto逻辑实现。根据代码中的注释所述， 这种实现的代码不支持使用clang编译器。 这三种实现的思路大同小异，首选自然是速度更快的汇编处理kMterpImplKind模式。 为了展示一些dex指令的处理逻辑，笔者拟讨论kSwtichImplKind模式的相关代码。 */ if (kInterpreterImplKind == kMterpImplKind) { if (transaction_active) {.....} else if (UNLIKELY(!Runtime::Current()-\u0026gt;IsStarted())) { ...... //针对dex2oat的情况  } else { ...... //ExecuteMterpImpl函数的定义由汇编代码实现,main  bool returned = ExecuteMterpImpl(self, code_item, \u0026amp;shadow_frame, \u0026amp;result_register); } } else if (kInterpreterImplKind == kSwitchImplKind) { if (transaction_active) {...... } else { //kSwitchImplKind的入口函数。注意，最后一个参数的值为false。main  return ExecuteSwitchImpl\u0026lt;false, false\u0026gt;(self, code_item, shadow_frame, result_register, false); } } else {　//kInterpreterImplKind取值为kComputedGotoImplKind的情况,main  if (transaction_active) {......} else { return ExecuteGotoImpl\u0026lt;false, false\u0026gt;(self, code_item, shadow_frame, result_register); } } } ...... } interpreter_switch_impl.cc ExecuteSwitchImpl template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; JValue ExecuteSwitchImpl(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame\u0026amp; shadow_frame, JValue result_register, bool interpret_one_instruction) { //注意上文Execute代码中调用ExeucteSwitchImpl时设置的最后一个参数为false，所以此处inter-  //pret_one_instruction为false。  constexpr bool do_assignability_check = do_access_check; ...... //dex_pc指向要执行的dex指令  uint32_t dex_pc = shadow_frame.GetDexPC(); const auto* const instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); //insns代表方法B的dex指令码数组  const uint16_t* const insns = code_item-\u0026gt;insns_; const Instruction* inst = Instruction::At(insns + dex_pc); uint16_t inst_data; //方法B对应的ArtMethod对象  ArtMethod* method = shadow_frame.GetMethod(); jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); ...... do { //遍历方法B的dex指令码数组，main  dex_pc = inst-\u0026gt;GetDexPc(insns); shadow_frame.SetDexPC(dex_pc); ...... inst_data = inst-\u0026gt;Fetch16(0); /*main,借助switch/case，针对每一种dex指令进行处理。注意，处理每种dex指令前，都有一个PREAMBLE 宏，该宏就是调用instrumentation的DexPcMovedEvent函数。10.5节将单独介绍和instrumentation相关的内容。 */ switch (inst-\u0026gt;Opcode(inst_data)) {//main  case Instruction::NOP: //处理NOP指令  PREAMBLE(); //Next_1xx是Instruction类的成员函数，用于跳过本指令的参数，使之指向下一条  //指令的开头。1xx是dex指令码存储格式的一种。读者可不用管它。  inst = inst-\u0026gt;Next_1xx(); break; ...... //其他dex指令码的处理  case Instruction::INVOKE_DIRECT: { //invoke-direct指令码的处理  PREAMBLE(); //DoInvoke的分析见下文。main  bool success = DoInvoke\u0026lt;kDirect, false, do_access_check\u0026gt;( self, shadow_frame, inst, inst_data, \u0026amp;result_register); /*Next_3xx也是Instruction类的成员函数。下面的POSSIBLY_HANDLE_PENDING_EXCEPTION 是一个宏，如果有异常发生，则进入异常处理，否则将调用Next_3xx函数使得inst指向 下一条指令。整个解释执行的流程就这样循环直到所有指令码处理完毕。main */ POSSIBLY_HANDLE_PENDING_EXCEPTION(!success, Next_3xx); break; } ...... } } while (!interpret_one_instruction); //循环  //记录dex指令执行的位置并更新到shadow_frame中  shadow_frame.SetDexPC(inst-\u0026gt;GetDexPc(insns)); return result_register; } interpreter_common.h/cc DoInvoke template\u0026lt;InvokeType type, bool is_range, bool do_access_check\u0026gt; static inline bool DoInvoke(Thread* self, ShadowFrame\u0026amp; shadow_frame, const Instruction* inst, uint16_t inst_data, JValue* result) { /*先观察DoInvoke的参数： （1）模板参数type：指明调用类型，比如kStatic、kDirect等。 （2）模板参数is_range：如果该方法有多于五个参数的话，则需要使用invoke-xxx-range这样 的指令。 （3）模板参数do_access_check：是否需要访问检查。即检查是否有权限调用invoke指令的目标 方法C。 （4）shadow_frame：方法B对应的ShadowFrame对象。 （5）inst：invoke指令对应的Instruction对象。 （6）inst_data：invoke指令对应的参数。 （7）result：用于存储方法C执行的结果。 */ //method_idx为方法C在dex文件里method_ids数组中的索引  const uint32_t method_idx = (is_range) ? inst-\u0026gt;VRegB_3rc() : inst-\u0026gt;VRegB_35c(); //找到方法C对应的对象。它作为参数存储在方法B的ShawdowFrame对象中。  const uint32_t vregC = (is_range) ? inst-\u0026gt;VRegC_3rc() : inst-\u0026gt;VRegC_35c(); Object* receiver = (type == kStatic) ? nullptr : shadow_frame.GetVRegReference(vregC); //sf_method代表ArtMethod* B。  ArtMethod* sf_method = shadow_frame.GetMethod(); /*FindMethodFromCode用于查找代表目标方法C对应的ArtMethod对象，即ArtMethod* C。其内 部会根据do_access_check的情况检查方法B是否有权限调用方法C。 注意，FindMethodFromCode函数是根据不同调用类型（kStatic、kDirect、kVirtual、kSuper、 kInterface）以找到对应的ArtMethod对象的关键代码。这部分内容请读者自行阅读。*/ ArtMethod* const called_method = FindMethodFromCode\u0026lt;type, do_access_check\u0026gt;( method_idx, \u0026amp;receiver, sf_method, self); //假设方法C对应的ArtMethod对象找到了，所以，called_method不为空。  if (UNLIKELY(called_method == nullptr)) {.......} else if (UNLIKELY(!called_method-\u0026gt;IsInvokable())) {......} else { //下面这段代码和JIT有关，我们留待后续章节再来介绍。  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) {......} ...... //instrumentation的处理  return DoCall\u0026lt;is_range, do_access_check\u0026gt;(called_method, self, shadow_frame, inst, inst_data,result); } } DoCall template\u0026lt;bool is_range, bool do_assignability_check\u0026gt; bool DoCall(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame,const Instruction* inst, uint16_t inst_data, JValue* result) { const uint16_t number_of_inputs = (is_range) ? inst-\u0026gt;VRegA_3rc(inst_data) : inst-\u0026gt;VRegA_35c(inst_data); //kMaxVarArgsRegs为编译常量，值为5  uint32_t arg[Instruction::kMaxVarArgRegs] = {}; uint32_t vregC = 0; if (is_range) {......} else { vregC = inst-\u0026gt;VRegC_35c(); inst-\u0026gt;GetVarArgs(arg, inst_data); //将调用方法C的参数存储到arg数组中,main  } //调用DoCallCommon，我们接着看这个函数  return DoCallCommon\u0026lt;is_range, do_assignability_check\u0026gt;( called_method, self, shadow_frame,result, number_of_inputs, arg, vregC); } DoCallCommon template \u0026lt;bool is_range, bool do_assignability_check, size_t kVarArgMax\u0026gt; static inline bool DoCallCommon(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame, JValue* result, uint16_t number_of_inputs,uint32_t (\u0026amp;arg)[kVarArgMax],uint32_t vregC) { bool string_init = false; //和String类的构造函数有关。此处不拟讨论。  if (UNLIKELY(called_method-\u0026gt;GetDeclaringClass()-\u0026gt;IsStringClass() \u0026amp;\u0026amp; called_method-\u0026gt;IsConstructor())) {.....} const DexFile::CodeItem* code_item = called_method-\u0026gt;GetCodeItem(); uint16_t num_regs; if (LIKELY(code_item != nullptr)) { num_regs = code_item-\u0026gt;registers_size_; } else { num_regs = number_of_inputs; } uint32_t string_init_vreg_this = is_range ? vregC : arg[0]; if (UNLIKELY(string_init)) {......} size_t first_dest_reg = num_regs - number_of_inputs; ...... //创建方法C所需的ShadowFrame对象。  ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, \u0026amp;shadow_frame, called_method, 0); ShadowFrame* new_shadow_frame = shadow_frame_unique_ptr.get(); if (do_assignability_check) { ...... //不考虑这种情况，读者可自行阅读  } else { size_t arg_index = 0; if (is_range) {......} else { //从调用方法B的ShadowFrame对象中拷贝方法C所需的参数到C的ShadowFrame对象里  for (; arg_index \u0026lt; number_of_inputs; ++arg_index) { AssignRegister(new_shadow_frame, shadow_frame, first_dest_reg + arg_index, arg[arg_index]); } } ...... } //准备方法C对应的ShadowFrame对象后，现在将考虑如何跳转到目标方法C。  if (LIKELY(Runtime::Current()-\u0026gt;IsStarted())) { ArtMethod* target = new_shadow_frame-\u0026gt;GetMethod(); //如果处于调试模式，或者方法C不存在机器码，则调用  //ArtInterpreterToInterpreterBridge函数，显然，它是解释执行的继续。  if (ClassLinker::ShouldUseInterpreterEntrypoint( target, target-\u0026gt;GetEntryPointFromQuickCompiledCode())) { ArtInterpreterToInterpreterBridge(self, code_item, new_shadow_frame,result);//main  } else { //如果可以用机器码方式执行方法C，则调用ArtInterpreterToCompiledCodeBridge，  //它将从解释执行模式进入机器码执行模式。  ArtInterpreterToCompiledCodeBridge( self, shadow_frame.GetMethod(), code_item, new_shadow_frame, result); } } else { //dex2oat中的处理。因为dex2oat要执行诸如类的初始化方法\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;，这些方法都  //采用解释执行模式来处理的。  UnstartedRuntime::Invoke(self, code_item, new_shadow_frame, result, first_dest_reg); } } ...... return !self-\u0026gt;IsExceptionPending(); } ArtInterpreterToInterpreterBridge void ArtInterpreterToInterpreterBridge(Thread* self, const DexFile::CodeItem* code_item, ShadowFrame* shadow_frame, JValue* result) { ...... self-\u0026gt;PushShadowFrame(shadow_frame); //方法C对应的ShadowFrame对象入栈  ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); const bool is_static = method-\u0026gt;IsStatic(); if (is_static) { //如果方法C为静态方法，则判断该方法所属的类是否初始化过了，如果没有，则先初始化这个类。  mirror::Class* declaring_class = method-\u0026gt;GetDeclaringClass(); if (UNLIKELY(!declaring_class-\u0026gt;IsInitialized())) { StackHandleScope\u0026lt;1\u0026gt; hs(self); HandleWrapper\u0026lt;Class\u0026gt; h_declaring_class(hs.NewHandleWrapper( \u0026amp;declaring_class)); if (UNLIKELY(!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized( self, h_declaring_class, true, true))) {......} } } //如果不是JNI方法，则调用Execute执行该方法。Execute函数我们在10.2.3节介绍过它了。  if (LIKELY(!shadow_frame-\u0026gt;GetMethod()-\u0026gt;IsNative())) { result-\u0026gt;SetJ(Execute(self, code_item, *shadow_frame,//main  JValue()).GetJ()); } else {...... /*dex2oat中的处理*/ } self-\u0026gt;PopShadowFrame(); //方法C对应的ShadowFrame出栈 } ArtInterpreterToCompiledCodeBridge void ArtInterpreterToCompiledCodeBridge(Thread* self, ArtMethod* caller, const DexFile::CodeItem* code_item, ShadowFrame* shadow_frame, JValue* result) { ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); if (method-\u0026gt;IsStatic()) { //检查方法C所属类是否完成了初始化，如果没有，则先初始化该类。  ...... } uint16_t arg_offset = (code_item == nullptr) ? 0 : code_item-\u0026gt;registers_size_ - code_item-\u0026gt;ins_size_; jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); ...... //JIT相关，此处先略过  //调用ArtMethod* C的Invoke函数。直接来看这个函数的代码。  method-\u0026gt;Invoke(self, shadow_frame-\u0026gt;GetVRegArgs(arg_offset), (shadow_frame-\u0026gt;NumberOfVRegs() - arg_offset) * sizeof(uint32_t), result, method-\u0026gt;GetInterfaceMethodIfProxy(sizeof(void*))-\u0026gt;GetShorty()); } art_method.cc Invoke void ArtMethod::Invoke(Thread* self, uint32_t* args, uint32_t args_size, JValue* result,const char* shorty) { /* 注意参数 （1）args：方法C所需的参数。它是一个数组，元素个数为args_size。 （2）result：存储方法C调用结果的对象。 （3）shorty：方法C的简短描述。 */ //栈操作，详情见下文分析  ManagedStack fragment; self-\u0026gt;PushManagedStackFragment(\u0026amp;fragment);//  Runtime* runtime = Runtime::Current(); if (UNLIKELY(!runtime-\u0026gt;IsStarted() || Dbg::IsForcedInterpreterNeededForCalling(self, this))) {......} else { //再次判断方法C是否存在机器码  bool have_quick_code = GetEntryPointFromQuickCompiledCode() != nullptr; if (LIKELY(have_quick_code)) { //如果是非静态函数，则调用art_quick_invoke_stub函数，否则调用  //art_quick_invoke_static_stub函数。这两个函数也是由汇编代码编写。我们看  //其中的art_quick_invoke_stub函数。  if (!IsStatic()) { (*art_quick_invoke_stub)(this, args, args_size, self, result, shorty); } else { (*art_quick_invoke_static_stub)(this, args, args_size, self, result, shorty); } //和HDeoptimize有关。详情见下文。  if (UNLIKELY(self-\u0026gt;GetException() == Thread::GetDeoptimizationException())) { self-\u0026gt;DeoptimizeWithDeoptimizationException(result); } } ...... self-\u0026gt;PopManagedStackFragment(fragment); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/",
	"title": "alloc_gc",
	"tags": [],
	"description": "",
	"content": "alloc_gc 探索总结alloc_gc知识\n 1Space     2Alloc     AllocRelated     GC     GC1_MS_CMS     GC2_ConcurrentCopying     GC3_MarkCompact     GC4_Semi_Space     Runtime_VisitRoots     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/allocrelated/",
	"title": "AllocRelated",
	"tags": [],
	"description": "",
	"content": "Instruction::NEW_INSTANCE ExecuteSwitchImplCpp template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; void ExecuteSwitchImplCpp(SwitchImplContext* ctx) { switch (inst-\u0026gt;Opcode(inst_data)) { case Instruction::NEW_INSTANCE: { PREAMBLE(); ObjPtr\u0026lt;mirror::Object\u0026gt; obj = nullptr; ObjPtr\u0026lt;mirror::Class\u0026gt; c = ResolveVerifyAndClinit(dex::TypeIndex(inst-\u0026gt;VRegB_21c()), shadow_frame.GetMethod(), self, false, do_access_check); if (LIKELY(c != nullptr)) { if (UNLIKELY(c-\u0026gt;IsStringClass())) { gc::AllocatorType allocator_type = Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator(); obj = mirror::String::AllocEmptyString\u0026lt;true\u0026gt;(self, allocator_type); } else { obj = AllocObjectFromCode\u0026lt;true\u0026gt;( c.Ptr(), self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()); } } if (UNLIKELY(obj == nullptr)) { HANDLE_PENDING_EXCEPTION(); } else { obj-\u0026gt;GetClass()-\u0026gt;AssertInitializedOrInitializingInThread(self); // Don\u0026#39;t allow finalizable objects to be allocated during a transaction since these can\u0026#39;t  // be finalized without a started runtime.  if (transaction_active \u0026amp;\u0026amp; obj-\u0026gt;GetClass()-\u0026gt;IsFinalizable()) { AbortTransactionF(self, \u0026#34;Allocating finalizable object in transaction: %s\u0026#34;, obj-\u0026gt;PrettyTypeOf().c_str()); HANDLE_PENDING_EXCEPTION(); break; } shadow_frame.SetVRegReference(inst-\u0026gt;VRegA_21c(inst_data), obj.Ptr()); inst = inst-\u0026gt;Next_2xx(); } break; } art/runtime/entrypoints/entrypoint_utils-inl.h\nAllocObjectFromCode // Allocate an instance of klass. Throws InstantationError if klass is not instantiable, // or IllegalAccessError if klass is j.l.Class. Performs a clinit check too. template \u0026lt;bool kInstrumented\u0026gt; ALWAYS_INLINE inline mirror::Object* AllocObjectFromCode(mirror::Class* klass, Thread* self, gc::AllocatorType allocator_type) { bool slow_path = false; klass = CheckObjectAlloc(klass, self, \u0026amp;slow_path); if (UNLIKELY(slow_path)) { if (klass == nullptr) { return nullptr; } // CheckObjectAlloc can cause thread suspension which means we may now be instrumented.  return klass-\u0026gt;Alloc\u0026lt;/*kInstrumented*/true\u0026gt;( self, Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetCurrentAllocator()).Ptr(); } DCHECK(klass != nullptr); return klass-\u0026gt;Alloc\u0026lt;kInstrumented\u0026gt;(self, allocator_type).Ptr(); } ALWAYS_INLINE inline mirror::Class* CheckObjectAlloc(mirror::Class* klass, Thread* self, bool* slow_path) { if (UNLIKELY(!klass-\u0026gt;IsInitialized())) { StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Class\u0026gt; h_klass(hs.NewHandle(klass)); // EnsureInitialized (the class initializer) might cause a GC.  // may cause us to suspend meaning that another thread may try to  // change the allocator while we are stuck in the entrypoints of  // an old allocator. Also, the class initialization may fail. To  // handle these cases we mark the slow path boolean as true so  // that the caller knows to check the allocator type to see if it  // has changed and to null-check the return value in case the  // initialization fails.  *slow_path = true; if (!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized(self, h_klass, true, true)) { DCHECK(self-\u0026gt;IsExceptionPending()); return nullptr; // Failure  } else { DCHECK(!self-\u0026gt;IsExceptionPending()); } return h_klass.Get(); } return klass; art/runtime/gc/heap.h\nAllocatorType GetCurrentAllocator() const { return current_allocator_; } art/runtime/mirror/class-inl.h\nClass::Alloc template\u0026lt;bool kIsInstrumented, bool kCheckAddFinalizer\u0026gt; inline ObjPtr\u0026lt;Object\u0026gt; Class::Alloc(Thread* self, gc::AllocatorType allocator_type) { CheckObjectAlloc(); gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); const bool add_finalizer = kCheckAddFinalizer \u0026amp;\u0026amp; IsFinalizable(); if (!kCheckAddFinalizer) { DCHECK(!IsFinalizable()); } // Note that the this pointer may be invalidated after the allocation.  ObjPtr\u0026lt;Object\u0026gt; obj = heap-\u0026gt;AllocObjectWithAllocator\u0026lt;kIsInstrumented, false\u0026gt;(self, this, this-\u0026gt;object_size_, allocator_type, VoidFunctor()); if (add_finalizer \u0026amp;\u0026amp; LIKELY(obj != nullptr)) { heap-\u0026gt;AddFinalizerReference(self, \u0026amp;obj); if (UNLIKELY(self-\u0026gt;IsExceptionPending())) { // Failed to allocate finalizer reference, it means that the whole allocation failed.  obj = nullptr; } } return obj.Ptr(); } art/runtime/gc/heap-inl.h\nHeap::AllocObjectWithAllocator template \u0026lt;bool kInstrumented, bool kCheckLargeObject, typename PreFenceVisitor\u0026gt; inline mirror::Object* Heap::AllocObjectWithAllocator(Thread* self, ObjPtr\u0026lt;mirror::Class\u0026gt; klass, size_t byte_count, AllocatorType allocator, const PreFenceVisitor\u0026amp; pre_fence_visitor) { obj = TryToAllocate\u0026lt;kInstrumented, false\u0026gt;(self, allocator, byte_count, \u0026amp;bytes_allocated, \u0026amp;usable_size, \u0026amp;bytes_tl_bulk_allocated); Heap::TryToAllocate template \u0026lt;const bool kInstrumented, const bool kGrow\u0026gt; inline mirror::Object* Heap::TryToAllocate(Thread* self, AllocatorType allocator_type, size_t alloc_size, size_t* bytes_allocated, size_t* usable_size, size_t* bytes_tl_bulk_allocated) { mirror::Object* ret; switch (allocator_type) { case kAllocatorTypeBumpPointer: { DCHECK(bump_pointer_space_ != nullptr); alloc_size = RoundUp(alloc_size, space::BumpPointerSpace::kAlignment); ret = bump_pointer_space_-\u0026gt;AllocNonvirtual(alloc_size); if (LIKELY(ret != nullptr)) { *bytes_allocated = alloc_size; *usable_size = alloc_size; *bytes_tl_bulk_allocated = alloc_size; } break; } case kAllocatorTypeNonMoving: { ret = non_moving_space_-\u0026gt;Alloc(self, alloc_size, bytes_allocated, usable_size, bytes_tl_bulk_allocated); break; case kAllocatorTypeTLAB: FALLTHROUGH_INTENDED; case kAllocatorTypeRegionTLAB: { DCHECK_ALIGNED(alloc_size, kObjectAlignment); static_assert(space::RegionSpace::kAlignment == space::BumpPointerSpace::kAlignment, \u0026#34;mismatched alignments\u0026#34;); static_assert(kObjectAlignment == space::BumpPointerSpace::kAlignment, \u0026#34;mismatched alignments\u0026#34;); if (UNLIKELY(self-\u0026gt;TlabSize() \u0026lt; alloc_size)) { // kAllocatorTypeTLAB may be the allocator for region space TLAB if the GC is not marking,  // that is why the allocator is not passed down.  return AllocWithNewTLAB(self, alloc_size, kGrow, bytes_allocated, usable_size, bytes_tl_bulk_allocated); } libcore/ojluni/src/main/native/Runtime.c\nRuntime_freeMemory JNIEXPORT jlong JNICALL Runtime_freeMemory(JNIEnv *env, jobject this) { return JVM_FreeMemory(); } art/openjdkjvm/OpenjdkJvm.cc\nJVM_FreeMemory JNIEXPORT jlong JVM_FreeMemory(void) { return art::Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetFreeMemory(); } art/runtime/gc/heap.h\nheap.h::GetFreeMemory // Returns how much free memory we have until we need to grow the heap to perform an allocation. // Similar to GetFreeMemoryUntilGC. Implements java.lang.Runtime.freeMemory. size_t GetFreeMemory() const { size_t byte_allocated = num_bytes_allocated_.LoadSequentiallyConsistent(); size_t total_memory = GetTotalMemory(); // Make sure we don\u0026#39;t get a negative number.  return total_memory - std::min(total_memory, byte_allocated); }  art/runtime/class_linker.cc\nDefineClass\u0026rsquo;s Alloc ClassLinker::DefineClass mirror::Class* ClassLinker::DefineClass(Thread* self, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def) { StackHandleScope\u0026lt;3\u0026gt; hs(self); auto klass = hs.NewHandle\u0026lt;mirror::Class\u0026gt;(nullptr); // Load the class from the dex file.  if (klass == nullptr) { // Allocate a class with the status of not ready.  // Interface object should get the right size here. Regular class will  // figure out the right size later and be replaced with one of the right  // size when the class becomes resolved.  klass.Assign(AllocClass(self, SizeOfClassWithoutEmbeddedTables(dex_file, dex_class_def))); } ClassLinker::SizeOfClassWithoutEmbeddedTables uint32_t ClassLinker::SizeOfClassWithoutEmbeddedTables(const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def) { const uint8_t* class_data = dex_file.GetClassData(dex_class_def); ...... // We allow duplicate definitions of the same field in a class_data_item  // but ignore the repeated indexes here, b/21868015.  uint32_t last_field_idx = dex::kDexNoIndex; for (ClassDataItemIterator it(dex_file, class_data); it.HasNextStaticField(); it.Next()) { uint32_t field_idx = it.GetMemberIndex(); // Ordering enforced by DexFileVerifier.  DCHECK(last_field_idx == dex::kDexNoIndex || last_field_idx \u0026lt;= field_idx); if (UNLIKELY(field_idx == last_field_idx)) { continue; } last_field_idx = field_idx; const DexFile::FieldId\u0026amp; field_id = dex_file.GetFieldId(field_idx); const char* descriptor = dex_file.GetFieldTypeDescriptor(field_id); char c = descriptor[0]; switch (c) { case \u0026#39;L\u0026#39;: case \u0026#39;[\u0026#39;: num_ref++; break; case \u0026#39;J\u0026#39;: case \u0026#39;D\u0026#39;: num_64++; break; case \u0026#39;I\u0026#39;: case \u0026#39;F\u0026#39;: num_32++; break; case \u0026#39;S\u0026#39;: case \u0026#39;C\u0026#39;: num_16++; break; case \u0026#39;B\u0026#39;: case \u0026#39;Z\u0026#39;: num_8++; break; default: LOG(FATAL) \u0026lt;\u0026lt; \u0026#34;Unknown descriptor: \u0026#34; \u0026lt;\u0026lt; c; UNREACHABLE(); } } return mirror::Class::ComputeClassSize(false, 0, num_8, num_16, num_32, num_64, num_ref, image_pointer_size_); } ClassLinker::AllocClass mirror::Class* ClassLinker::AllocClass(Thread* self, uint32_t class_size) { return AllocClass(self, GetClassRoot(kJavaLangClass), class_size); } mirror::Class* ClassLinker::AllocClass(Thread* self, ObjPtr\u0026lt;mirror::Class\u0026gt; java_lang_Class, uint32_t class_size) { DCHECK_GE(class_size, sizeof(mirror::Class)); gc::Heap* heap = Runtime::Current()-\u0026gt;GetHeap(); mirror::Class::InitializeClassVisitor visitor(class_size); ObjPtr\u0026lt;mirror::Object\u0026gt; k = kMovingClasses ? heap-\u0026gt;AllocObject\u0026lt;true\u0026gt;(self, java_lang_Class, class_size, visitor) : heap-\u0026gt;AllocNonMovableObject\u0026lt;true\u0026gt;(self, java_lang_Class, class_size, visitor); if (UNLIKELY(k == nullptr)) { self-\u0026gt;AssertPendingOOMException(); return nullptr; } return k-\u0026gt;AsClass(); } heap.h::AllocObject // Allocates and initializes storage for an object instance. template \u0026lt;bool kInstrumented, typename PreFenceVisitor\u0026gt; mirror::Object* AllocObject(Thread* self, ObjPtr\u0026lt;mirror::Class\u0026gt; klass, size_t num_bytes, const PreFenceVisitor\u0026amp; pre_fence_visitor) REQUIRES_SHARED(Locks::mutator_lock_) REQUIRES(!*gc_complete_lock_, !*pending_task_lock_, !*backtrace_lock_, !Roles::uninterruptible_) { return AllocObjectWithAllocator\u0026lt;kInstrumented, true\u0026gt;(self, klass, num_bytes, GetCurrentAllocator(), pre_fence_visitor); } 其他 art/runtime/gc/allocator_type.h\nallocator_type.h // Different types of allocators. enum AllocatorType { kAllocatorTypeBumpPointer, // Use BumpPointer allocator, has entrypoints.  kAllocatorTypeTLAB, // Use TLAB allocator, has entrypoints.  kAllocatorTypeRosAlloc, // Use RosAlloc allocator, has entrypoints.  kAllocatorTypeDlMalloc, // Use dlmalloc allocator, has entrypoints.  kAllocatorTypeNonMoving, // Special allocator for non moving objects, doesn\u0026#39;t have entrypoints.  kAllocatorTypeLOS, // Large object space, also doesn\u0026#39;t have entrypoints.  kAllocatorTypeRegion, kAllocatorTypeRegionTLAB, }; GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(DlMalloc, gc::kAllocatorTypeDlMalloc) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(RosAlloc, gc::kAllocatorTypeRosAlloc) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(BumpPointer, gc::kAllocatorTypeBumpPointer) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(TLAB, gc::kAllocatorTypeTLAB) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(Region, gc::kAllocatorTypeRegion) GENERATE_ENTRYPOINTS_FOR_ALLOCATOR(RegionTLAB, gc::kAllocatorTypeRegionTLAB) "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/andfix/",
	"title": "AndFix",
	"tags": [],
	"description": "",
	"content": "Foo.bar()这种直接调用与反射调用Foo.class.getDeclaredMethod(“bar”).invoke(null) 有什么区别吗？这个问题后续再谈\nprivate native Object invoke(Object receiver, Object[] args, boolean accessible) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException; 这个invoke是一个native方法，它的native实现在 art/runtime/native/java_lang_reflect_Method.cc 里面，这个jni方法最终调用了 art/runtime/reflection.cc 的 InvokeMethod方法：\nobject InvokeMethod(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject javaMethod, jobject javaReceiver, jobject javaArgs, bool accessible) { // 略...  mirror::ArtMethod* m = mirror::ArtMethod::FromReflectedMethod(soa, javaMethod); mirror::Class* declaring_class = m-\u0026gt;GetDeclaringClass(); } AndFix的实现里面，也正是使用这个 FromReflectedMethod 方法拿到Java层Method对应native层的ArtMethod指针，然后执行替换的\n首先简单介绍下ART上的方法调用原理（本文不讨论解释模式，所有entrypoint均指compiled_code_entry_point)。在ART中，每一个Java方法在虚拟机（注：ART与虚拟机虽有细微差别，但本文不作区分，两者含义相同，下同）内部都由一个ArtMethod对象表示（native层，实际上是一个C++对象），这个native 的 ArtMethod对象包含了此Java方法的所有信息，比如名字，参数类型，方法本身代码的入口地址（entrypoint)等；暂时放下trampoline以及interpreter和jit不谈，一个Java方法的执行非常简单：\n 想办法拿到这个Java方法所代表的ArtMethod对象 取出其entrypoint，然后跳转到此处开始执行  AndFix就是基于这个原理来做热修复的，Sophix 对这个方案做了一些改进，也即整体替换，不过原理上都一样。二者在替换方法之后把原方法直接丢弃，因此无法实现AOP\n 《深入探索Android热修复技术原理》\u0026ndash;Sophix团队\n两种情况不适用：\n 引起原有类中发生结构变化的修改 修复了非静态方法会被反射调用  参考 ART深度探索开篇：从Method Hook谈起\n我为Dexposed续一秒——论ART上运行时 Method AOP实现\nhttps://github.com/tiann/epic\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/andfixsource/",
	"title": "AndFixSource",
	"tags": [],
	"description": "",
	"content": "核心方法addReplaceMethod(Method src, Method dest)\nAndFixManager.java fix public synchronized void fix(String patchPath) { fix(new File(patchPath), mContext.getClassLoader(), null); } //加载补丁包中所有类所有方法,如果拥有注解methodReplace，则触发replaceMethod public synchronized void fix(File file, ClassLoader classLoader, List\u0026lt;String\u0026gt; classes) { final DexFile dexFile = DexFile.loadDex(file.getAbsolutePath(), optfile.getAbsolutePath(), Context.MODE_PRIVATE); ClassLoader patchClassLoader = new ClassLoader(classLoader) {//以当前classLoader作为parentClassLoader优先查找 \t@Override protected Class\u0026lt;?\u0026gt; findClass(String className) throws ClassNotFoundException { Class\u0026lt;?\u0026gt; clazz = dexFile.loadClass(className, this); if (clazz == null \u0026amp;\u0026amp; className.startsWith(\u0026#34;com.alipay.euler.andfix\u0026#34;)) { return Class.forName(className);// annotation’s class \t// not found \t} if (clazz == null) { throw new ClassNotFoundException(className); } return clazz; } }; Enumeration\u0026lt;String\u0026gt; entrys = dexFile.entries(); Class\u0026lt;?\u0026gt; clazz = null; while (entrys.hasMoreElements()) { String entry = entrys.nextElement(); if (classes != null \u0026amp;\u0026amp; !classes.contains(entry)) { continue;// skip, not need fix \t} clazz = dexFile.loadClass(entry, patchClassLoader); if (clazz != null) { fixClass(clazz, classLoader); } } fixClass private void fixClass(Class\u0026lt;?\u0026gt; clazz, ClassLoader classLoader) { Method[] methods = clazz.getDeclaredMethods(); MethodReplace methodReplace; String clz; String meth; for (Method method : methods) { methodReplace = method.getAnnotation(MethodReplace.class); if (methodReplace == null) continue; clz = methodReplace.clazz(); meth = methodReplace.method(); if (!isEmpty(clz) \u0026amp;\u0026amp; !isEmpty(meth)) { replaceMethod(classLoader, clz, meth, method); } } } replaceMethod /** * replace method * * @param classLoader classloader * @param clz class * @param meth name of target method * @param method source method */ private void replaceMethod(ClassLoader classLoader, String clz, String meth, Method method) { try { String key = clz + \u0026#34;@\u0026#34; + classLoader.toString(); Class\u0026lt;?\u0026gt; clazz = mFixedClass.get(key); if (clazz == null) {// class not load  Class\u0026lt;?\u0026gt; clzz = classLoader.loadClass(clz); // initialize target class  clazz = AndFix.initTargetClass(clzz); } if (clazz != null) {// initialize class OK  mFixedClass.put(key, clazz); Method src = clazz.getDeclaredMethod(meth, method.getParameterTypes()); AndFix.addReplaceMethod(src, method); } } catch (Exception e) { Log.e(TAG, \u0026#34;replaceMethod\u0026#34;, e); } } AndFix.java addReplaceMethod public static void addReplaceMethod(Method src, Method dest) { try { replaceMethod(src, dest); initFields(dest.getDeclaringClass()); } catch (Throwable e) { Log.e(TAG, \u0026#34;addReplaceMethod\u0026#34;, e); } } private static native void replaceMethod(Method dest, Method src); andfix.cpp replaceMethod static void replaceMethod(JNIEnv* env, jclass clazz, jobject src, jobject dest) { if (isArt) { art_replaceMethod(env, src, dest); } else { dalvik_replaceMethod(env, src, dest); } } art_method_replace.cpp art_replaceMethod extern void __attribute__ ((visibility (\u0026#34;hidden\u0026#34;))) art_replaceMethod( JNIEnv* env, jobject src, jobject dest) { if (apilevel \u0026gt; 23) { replace_7_0(env, src, dest); } else if (apilevel \u0026gt; 22) { replace_6_0(env, src, dest); } else if (apilevel \u0026gt; 21) { replace_5_1(env, src, dest); } else if (apilevel \u0026gt; 19) { replace_5_0(env, src, dest); }else{ replace_4_4(env, src, dest); } } art_method_replace_7_0.cpp replace_7_0 void replace_7_0(JNIEnv* env, jobject src, jobject dest) { art::mirror::ArtMethod* smeth = (art::mirror::ArtMethod*) env-\u0026gt;FromReflectedMethod(src); art::mirror::ArtMethod* dmeth = (art::mirror::ArtMethod*) env-\u0026gt;FromReflectedMethod(dest); //\treinterpret_cast\u0026lt;art::mirror::Class*\u0026gt;(smeth-\u0026gt;declaring_class_)-\u0026gt;class_loader_ = //\treinterpret_cast\u0026lt;art::mirror::Class*\u0026gt;(dmeth-\u0026gt;declaring_class_)-\u0026gt;class_loader_; //for plugin classloader \treinterpret_cast\u0026lt;art::mirror::Class*\u0026gt;(dmeth-\u0026gt;declaring_class_)-\u0026gt;clinit_thread_id_ = reinterpret_cast\u0026lt;art::mirror::Class*\u0026gt;(smeth-\u0026gt;declaring_class_)-\u0026gt;clinit_thread_id_; reinterpret_cast\u0026lt;art::mirror::Class*\u0026gt;(dmeth-\u0026gt;declaring_class_)-\u0026gt;status_ = reinterpret_cast\u0026lt;art::mirror::Class*\u0026gt;(smeth-\u0026gt;declaring_class_)-\u0026gt;status_ -1; //for reflection invoke \treinterpret_cast\u0026lt;art::mirror::Class*\u0026gt;(dmeth-\u0026gt;declaring_class_)-\u0026gt;super_class_ = 0; smeth-\u0026gt;declaring_class_ = dmeth-\u0026gt;declaring_class_; smeth-\u0026gt;access_flags_ = dmeth-\u0026gt;access_flags_ | 0x0001; smeth-\u0026gt;dex_code_item_offset_ = dmeth-\u0026gt;dex_code_item_offset_; smeth-\u0026gt;dex_method_index_ = dmeth-\u0026gt;dex_method_index_; smeth-\u0026gt;method_index_ = dmeth-\u0026gt;method_index_; smeth-\u0026gt;hotness_count_ = dmeth-\u0026gt;hotness_count_; smeth-\u0026gt;ptr_sized_fields_.dex_cache_resolved_methods_ = dmeth-\u0026gt;ptr_sized_fields_.dex_cache_resolved_methods_; smeth-\u0026gt;ptr_sized_fields_.dex_cache_resolved_types_ = dmeth-\u0026gt;ptr_sized_fields_.dex_cache_resolved_types_; smeth-\u0026gt;ptr_sized_fields_.entry_point_from_jni_ = dmeth-\u0026gt;ptr_sized_fields_.entry_point_from_jni_; smeth-\u0026gt;ptr_sized_fields_.entry_point_from_quick_compiled_code_ = dmeth-\u0026gt;ptr_sized_fields_.entry_point_from_quick_compiled_code_; LOGD(\u0026#34;replace_7_0: %d , %d\u0026#34;, smeth-\u0026gt;ptr_sized_fields_.entry_point_from_quick_compiled_code_, dmeth-\u0026gt;ptr_sized_fields_.entry_point_from_quick_compiled_code_); } 参考 https://github.com/alibaba/AndFix\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/",
	"title": "android",
	"tags": [],
	"description": "",
	"content": "android 探索总结android知识\n aop    ASM访客者模式     JDK动态代理     编译插桩和动态代理      art    1类编译    dex2oat     dex2oat介绍      2类加载    Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层      alloc_gc    1Space     2Alloc     AllocRelated     GC     GC1_MS_CMS     GC2_ConcurrentCopying     GC3_MarkCompact     GC4_Semi_Space     Runtime_VisitRoots      ART_Lock     jni    _解释执行7_0     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常      启动流程    ART启动流程      基础数据结构     混合编译_运行    JVM_JIT     混合编译_运行       gradlejenkins    AndroidPlugin     android打包    Android打包      GradleDebug     GradlePlugin     Gradle打包过程     Transform      jetpack    arch    1lifecycle    Lifecycle     LifecycleCoroutine      2livedata    1MediatorLiveData     LiveData     LiveDataCoroutine     Transformations      3viewmodel    SaveAndRestoreInstanceState     SavedStateHandle     SavingStates     ViewModel     ViewModelScope_Delegate      Coroutines     databinding    Databinding     TwoWayDataBinding      di    DI     HiltSource      架构实现    KaptGenerateViewModel     架构思考和实现     架构思考和实现Inner       compose    Compose     ComposeSource     LayoutNode     ReComposition      SupportToAndroidx     workmanager    WorkManager       ndk    ELF文件结构     JNI     native_hook      system    ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Epoll     Looper     ThreadLocal      input    touchEventNative      kernel    kernel      layoutinflater    LayoutInflater      surfaceview    SurfaceViewSource      textureview    TextureViewSource      thread    StackTraceElement     ThreadState      zygote    SystemServerSource     ZygoteSource     Zygote进程      后台任务    后台任务处理      多进程    binder    1BinderServiceManager     2BinderServer     3BinderClient     4BinderKernel     BinderDeath     Binder原理      mmkv    MMKV       应用启动退出    应用启动      源码研究方法    Syscall查找方式      系统绘制    Graphics     measurelayoutdraw    measure      Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制       ui    webview    WebView      动画    AnimatorSource       包体积    包体积压缩      埋点    埋点     易观方舟      存储    sharedpreferences    SharedPreferences       安全    app签名     应用安全     网络请求安全      性能优化    apm    MatrixGradlePlugin     MatrixSource     Matrix接入后遇到的问题     Matrix研究     resource    MatrixResourcePlugin       内存优化    1manageMemory     2OOM     3Hprof_binary_dump_format     4DumpHprof     5LeakCanary2     6LeakCanary2Analyze     7KOOMSource      布局优化    布局优化       插件化    1插件化面临的问题     apk安装和卸载    应用安装和卸载过程      Hook     qigsaw    Qigsaw      shadow    Shadow     ShadowPlugin     ShadowSource      插件化技术选型      热修复字节码    1hotfixResearch     AndFix     AndFixSource     Dex文件格式     MultiDex     tinker    源码分析    Resource.arsc生成和结构     TinkerGradlePluginSource     TinkerSource        稳定性    异常    1javacrash    JavaCrashSystemHandle      anr    1ANRSystmHandle     2ANRMonitor_CollectInfo     3ANRAnalysisRootCause      nativecrash    1nativeCrash选型和整体流程     nativeCrash1SystemHandle     nativeCrash2Monitor_CollectStack     nativeCrash3SymbolRecovery     nativeCrash4AnalysisRootCause      xcrash    1xCrash原理     linuxApi     xCrashAnr     xCrashNativeCrash        自动化测试    android代码自测      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/2%E7%B1%BB%E5%8A%A0%E8%BD%BD/android_n%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AF%B9%E7%83%AD%E8%A1%A5%E4%B8%81%E5%BD%B1%E5%93%8D%E8%A7%A3%E6%9E%90/",
	"title": "Android_N混合编译与对热补丁影响解析",
	"tags": [],
	"description": "",
	"content": "Android_N混合编译与对热补丁影响解析.md\n入口文件位于dex2oat.cc中，在这里并不想贴具体的调用函数，简单的描述一下流程：若dex2oat参数中有输入profile文件，会读取profile中的数据。与以往不同的是，这里不仅会根据profile文件来生成base.odex文件，同时还会生成称为app_image的base.art文件。与boot.art类似，base.art文件主要为了加快应用的对“热代码”的加载与缓存。\n那么我们就剩下最后一个问题，app image文件是什么时候被加载，并且为什么它会影响热补丁的机制？\n###App image文件的加载 在apk启动时我们需要加载应用的oat文件以及可能存在的app image文件，它的大致流程如下：\n 通过OpenDexFilesFromOat加载oat时，若app image存在，则通过调用OpenImageSpace函数加载； 在加载app image文件时，通过UpdateAppImageClassLoadersAndDexCaches函数，将art文件中的dex_cache中dex的所有class插入到ClassTable，同时将method更新到dex_cache; 在类加载时，使用时ClassLinker::LookupClass会先从ClassTable中去查找，找不到时才会走到DefineClass中。   非常简单的说，app image的作用是记录已经编译好的“热代码”，并且在启动时一次性把它们加载到缓存。预先加载代替用时查找以提升应用的性能，到这里我们终于明白为什么base.art会影响热补丁的机制。\n无论是使用插入pathlist还是parent classloader的方式，若补丁修改的class已经存在与app image，它们都是无法通过热补丁更新的。它们在启动app时已经加入到PathClassLoader的ClassTable中，系统在查找类时会直接使用base.apk中的class。\n最后我们再来总结一下Android N混合编译运行的整个流程，它就像一个小型生态系统那样和谐。\n##Android N上热补丁的出路 假设base.art文件在补丁前已经存在，这里存在三种情况：\n 补丁修改的类都不app image中；这种情况是最理想的，此时补丁机制依然有效； 补丁修改的类部分在app image中；这种情况我们只能更新一部分的类，此时是最危险的。一部分类是新的，一部分类是旧的，app可能会出现地址错乱而出现crash。 补丁修改的类全部在app image中；这种情况只是造成补丁不生效，app并不会因此造成crash。  ###运行时替换PathClassLoader方案 事实上，App image中的class是插入到PathClassloader中的ClassTable中。假设我们完全废弃掉PathClassloader，而采用一个新建Classloader来加载后续的所有类，即可达到将cache无用化的效果。\n实际代码对应AndroidNClassLoader中的findClass和findLibrary方法，通过调用super.findClass和super.findLibrary来避开调用原本应用PathClassLoader的find方法，原本的findClass方法会先查找classTable造成修复的class无法加载到\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/androidplugin/",
	"title": "AndroidPlugin",
	"tags": [],
	"description": "",
	"content": "调试android plugin源码 在buildSrc下的build.gradle中添加如下依赖，用来查看其源码并debug\ndependencies { implementation(\u0026#34;com.android.tools.build:gradle:3.2.1\u0026#34;) } 源码为于External Libraries中:\nGradle: gradle-3.2.1 其META-INF中定义了多个android plugin的入口Class如com.android.application的入口com.android.build.gradle.AppPlugin\nGradle: gradle-api-3.2.1 AppExtension定义在这\nGradle: builder-3.2.1，d8,r8源码都在此处\n调试gradle源码 而gradle源码(gradle/wrapper/gradle-wrapper.properties中定义的gradle版本)\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-5.6.4-all.zip 位于External Libraries中:\nGradle: gradle-api-5.6.4\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/android%E4%BB%A3%E7%A0%81%E8%87%AA%E6%B5%8B/",
	"title": "android代码自测",
	"tags": [],
	"description": "",
	"content": "TDD https://www.raywenderlich.com/7109-test-driven-development-tutorial-for-android-getting-started\nAndroid应用功能测试 https://developer.android.com/training/testing/\n编写自测代码的好处 Testing also provides you with the following advantages:\n  Rapid feedback on failures.\u0026ndash;解放双手，提升测试效率\n  Early failure detection in the development cycle. \u0026ndash;开发提前发现错误\n  Safer code refactoring, letting you optimize code without worrying about regressions. \u0026ndash;保证重构不影响功能，很关键\n  Stable development velocity, helping you minimize technical debt. \u0026ndash;提前发现错误漏洞，提前纠正不合理的设计\n   测试驱动开发概念，迭代开发工作流 When developing a feature iteratively, you start by either writing a new test or by adding cases and assertions to an existing unit test. The test fails at first because the feature isn\u0026rsquo;t implemented yet.\nIt\u0026rsquo;s important to consider the units of responsibility that emerge as you design the new feature. For each unit, you write a corresponding unit test. Your unit tests should nearly exhaust all possible interactions with the unit, including standard interactions, invalid inputs, and cases where resources aren\u0026rsquo;t available.\nFigure 1. The two cycles associated with iterative, test-driven development\nThe full workflow, as shown in Figure 1, contains a series of nested, iterative cycles where a long, slow, UI-driven cycle tests the integration of code units. You test the units themselves using shorter, faster development cycles. This set of cycles continues until your app satisfies every use case.\n 如何编写具有可测试性的代码 https://www.cnblogs.com/wenpeng/p/8266472.html\n很多人在开发过程中都强调测试驱动开发，单元测试，代码测试覆盖率。那么为什么大家要强调这些？这些工作非做不可么？ 其实并非绝对。不论是驱动测试开发，还是代码测试覆盖率，本质上都只是方法，而不是目的。人们的真正的目的，是编写出优秀的，高质量的具有可维护性的，能够很好扩展的代码。\n什么是具有可测试的代码？ 　所谓具有可测试的代码，是指能够很轻松的执行各种测试的代码。\n具有可测试性的代码有什么特点？  　控制性\u0026ndash;输入参数或插桩数据。  　控制性是指测试者给在被测试的软件提供固定的输入数据的方便程度。换句话说就是软件本身接受定义明确的参数，并且这些参数可由测试者灵活的传入，软件在接受到这些参数后通过一系列运算返回固定的结果。任何软件都应该清楚的表明自己需要什么参数，以及将会生成什么返回值。此外任何软件都应该应该抽象它的依赖，譬如参数或底层模块，并为外部调用者提供随意注入的方式。当然软件代码本身应该清晰，整洁，目标明确。 2. 可见性\u0026ndash;返回或回调。\n　可见性是指测试者观察正在测试的软件的当前状态以及它所产生的任何输出的能力。换句话说就是软件应该将内部运算的状态（一般是指错误状态）和输出结果清晰明确的告知测试者。可见性一般都是通过方法执行后验证后置条件完成。 3. 简约性。\n　一般而言，简约性对任何系统在任何情况下都是一个正面的属性，测试毫无疑问也不例外。简单和极其内聚的组件非常适合测试，因为他们暴露出来的方法少，需要的测试也就少，而需要的测试越少，就越能做得可靠，快速。\n如何得到编写具有可测试性的代码和程序呢？  坚持面向对象编码原则:   单一责任原则 开放/封闭原则 里氏代换原则 接口分离原则 依赖反转原则  坚持编码建议 使用设计模式   编写了测试，我们仅仅完成了测试驱动开发的一部分。测试仅仅是基础工程，我们后期可以依托测试，进行持续的重构，而丝毫不用担心破坏了原有的代码逻辑和返回结果。重构，才是坚持测试驱动开发的核心部分。而持续的重构，最终我们得到的就是设计良好的代码，还附带一堆高代码覆盖率的测试作为奖励。\n功能测试类型 Unit test \u0026ndash; 单元测试  build unit tests that run on your local machine. Build Instrumented Unit Tests \u0026mdash; build unit tests that run on an Android device or emulator.  Integrate test \u0026ndash; 集成测试  junit + Mockito AndroidJunitRunner  UI test \u0026ndash; UI自动化  Test UI for a single app \u0026mdash;Espresso testing framework. Test UI for multiple apps \u0026mdash; UI Automator testing framework.   Mockito https://site.mockito.org/\nhttps://static.javadoc.io/org.mockito/mockito-core/2.23.4/org/mockito/Mockito.html#do_family_methods_stubs\nMockito关键api    方法名 方法描述     thenReturn(T value) 设置要返回的值   thenThrow(Throwable… throwables) 设置要抛出的异常   thenAnswer(Answer\u0026lt;?\u0026gt; answer) 对结果进行拦截   doReturn(Object toBeReturned) 提前设置要返回的值   doThrow(Throwable… toBeThrown) 提前设置要抛出的异常   doAnswer(Answer answer) 提前对结果进行拦截   doCallRealMethod() 调用某一个方法的真实实现   doNothing() 设置void方法什么也不做    graph LR Ax1(测试输入数据x1)--\u0026gt; B(测试单个功能或方法代码x) Ax2(测试输入数据x2)--\u0026gt; B Ax3(测试流程插桩数据x3)--\u0026gt; B Ax4(测试流程插桩数据x4)--\u0026gt; B B--\u0026gt; C(单个可测试功能代码x) 封装思路:\n左边的数据，封装成一个model/bean，传递给测试方法，可以动态新增字段来支持新的功能\n输入数据和插桩数据会有多个，每个是为了测试方法内部的不同分支流程，达到更高的覆盖率\nrobolectric http://robolectric.org/\nhttps://github.com/robolectric/robolectric\n@VisibleForTesting 可以把这个注解标注到类、方法或者字段上，以便在测试的时候可以使用。 这个Annotation只是一个指示作用，告诉其他开发者该函数为什么有这么大的可见程度（为了测试单元或者其他类对其测试使用）\n因此经常用来修饰public和protected，用其修饰private不会报错，但是意义很小。它不能改变任何权限。\nGuava has a @VisibleForTesting annotation, but it\u0026rsquo;s only for documentation purpose.\nA simple annotation that tells you why a particular property access restriction has been relaxed.A common trick to use in testing is to relax access restrictions to default for a particular property, so that you can use it in a unit test, which resides in the same package (though in different catalog). Whether you thing it\u0026rsquo;s good or bad, remember to give a hint about that to the developer.\n该注解用来说明，为什么该变量或者函数私有访问权限被释放成“公有”或者“package可见”。 单元测试是有访问权限的。所以加上@VisibleForTesting是说明，为什么你定义其他类似函数需要用private，这里这个test123函数需要释放私有访问权限呢？哦，原来是需要对测试单元可见（private函数 测试类是访问不了的）。\n类似的，该注解经常和public一起使用，告诉大家为什么这个函数我现在设计成public的，是为了给其他测试的类使用的。总的来说@VisibleForTesting就是一个标记（Marker）。\nVisibleForTesting并不能改变权限，在单元测试以及其他package中，访问权限加不加该注解没有任何改变。 @VisibleForTesting没有那么强大，它只是一个很基本的注解。\nThis annotation is better than nothing in such a case because it at least makes it clear to others using the construct that there is a reason for its otherwise surprisingly relaxed visibility.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/android%E6%89%93%E5%8C%85/android%E6%89%93%E5%8C%85/",
	"title": "Android打包",
	"tags": [],
	"description": "",
	"content": "打包过程 aapt-\u0026gt;aidl -\u0026gt; javac-\u0026gt; dx(dex)-\u0026gt; apkbuilder-\u0026gt; jarsigner-\u0026gt; zipalign\n步骤中提到的工具如下表：\n   名称 功能介绍 在操作系统中的路径     aapt Android资源打包工具 ${ANDROID_SDK_HOME}/platform-tools/appt   aidl Android接口描述语言转化为.java文件的工具 ${ANDROID_SDK_HOME}/platform-tools/aidl   javac Java Compiler ${JDK_HOME}/javac或/usr/bin/javac   dex 转化.class文件为Davik VM能识别的.dex文件 ${ANDROID_SDK_HOME}/platform-tools/dx   apkbuilder 生成apk包 ${ANDROID_SDK_HOME}/tools/opkbuilder   jarsigner .jar文件的签名工具 ${JDK_HOME}/jarsigner或/usr/bin/jarsigner   zipalign 字节码对齐工具 ${ANDROID_SDK_HOME}/tools/zipalign    第一步：打包资源文件，生成R.java文件 编译R.java类需要用到AndroidSDK提供的aapt工具,aapt参数众多,以下是主要参数:\n-d one or more device assets to include, separated by commas\n-f force overwrite of existing files\n-g specify a pixel tolerance to force images to grayscale, default 0\n-j specify a jar or zip file containing classes to include\n-k junk path of file(s) added\n-m make package directories under location specified by -J\n-u update existing packages (add new, replace older, remove deleted files)\n-v verbose output\n-x create extending (non-application) resource IDs\n-z require localization of resource attributes marked with\nlocalization=\u0026ldquo;suggested\u0026rdquo;\n-A additional directory in which to find raw asset files\n-G A file to output proguard options into.\n-F specify the apk file to output\n-I add an existing package to base include set\n-J specify where to output R.java resource constant definitions\n-M specify full path to AndroidManifest.xml to include in zip\n-P specify where to output public resource definitions\n-S directory in which to find resources. Multiple directories will be scann\n第二步：处理AIDL文件，生成对应的.java文件 （当然，有很多工程没有用到AIDL，那这个过程就可以省了）\n将.aidl文件生成.java文件需要用到AndroidSDK自带的aidl工具,此工具具体参数如下:\n-Isearch path for import statements.\n-dgenerate dependency file.\n-pfile created by \u0026ndash;preprocess to import.\n-obase output folder for generated files.\n-b fail when trying to compile a parcelable.\n第三步：编译Java文件，生成对应的.class文件 javac命令用法如下:\n其中，可能的选项包括：\n-g 生成所有调试信息\n-g:none 不生成任何调试信息\n-g:{lines,vars,source} 只生成某些调试信息\n-nowarn 不生成任何警告\n-verbose 输出有关编译器正在执行的操作的消息\n-deprecation 输出使用已过时的 API 的源位置\n-classpath \u0026lt;路径\u0026gt; 指定查找用户类文件和注释处理程序的位置\n-cp \u0026lt;路径\u0026gt; 指定查找用户类文件和注释处理程序的位置\n-sourcepath \u0026lt;路径\u0026gt; 指定查找输入源文件的位置\n-bootclasspath \u0026lt;路径\u0026gt; 覆盖引导类文件的位置\n-extdirs \u0026lt;目录\u0026gt; 覆盖安装的扩展目录的位置\n-endorseddirs \u0026lt;目录\u0026gt; 覆盖签名的标准路径的位置\n-proc:{none,only} 控制是否执行注释处理和/或编译。\n-processor [,,\u0026hellip;]要运行的注释处理程序的名称；绕过默认的搜索进程\n-processorpath \u0026lt;路径\u0026gt; 指定查找注释处理程序的位置\n-d \u0026lt;目录\u0026gt; 指定存放生成的类文件的位置\n-s \u0026lt;目录\u0026gt; 指定存放生成的源文件的位置\n-implicit:{none,class} 指定是否为隐式引用文件生成类文件\n-encoding \u0026lt;编码\u0026gt; 指定源文件使用的字符编码\n-source \u0026lt;版本\u0026gt; 提供与指定版本的源兼容性\n-target \u0026lt;版本\u0026gt; 生成特定 VM 版本的类文件\n-version 版本信息\n-help 输出标准选项的提要\n-Akey[=value] 传递给注释处理程序的选项\n-X 输出非标准选项的提要\n-J\u0026lt;标志\u0026gt; 直接将 \u0026lt;标志\u0026gt; 传递给运行时系统\n第四步：把.class文件转化成Davik VM支持的.dex文件 将工程bin目录下的class文件编译成classes.dex，Android虚拟机只能执行dex文件!\n第五步：打包生成未签名的.apk文件 【输入】打包后的资源文件、打包后类文件（.dex文件）、libs文件（包括.so文件，当然很多工程都没有这样的文件，如果你不使用C/C++开发的话）\n【输出】未签名的.apk文件\n【工具】apkbuilder工具\napkbuilder工具用法如下：\n-v Verbose.\n-d Debug Mode: Includes debug files in the APK file.\n-u Creates an unsigned package.\n-storetype Forces the KeyStore type. If ommited the default is used.\n-z Followed by the path to a zip archive.\nAdds the content of the application package.\n-f Followed by the path to a file.\nAdds the file to the application package.\n-rf Followed by the path to a source folder.\nAdds the java resources found in that folder to the application\npackage, while keeping their path relative to the source folder.\n-rj Followed by the path to a jar file or a folder containing\njar files.\nAdds the java resources found in the jar file(s) to the application\npackage.\n-nf Followed by the root folder containing native libraries to\ninclude in the application package.\n第六步：对未签名.apk文件进行签名 【输入】未签名的.apk文件\n【输出】签名的.apk文件\n【工具】jarsigner\n用法：jarsigner [选项] jar 文件别名\njarsigner -verify [选项] jar 文件\n[-keystore ] 密钥库位置\n[-storepass \u0026lt;口令\u0026gt;] 用于密钥库完整性的口令\n[-storetype \u0026lt;类型\u0026gt;] 密钥库类型\n[-keypass \u0026lt;口令\u0026gt;] 专用密钥的口令（如果不同）\n[-sigfile \u0026lt;文件\u0026gt;] .SF/.DSA 文件的名称\n[-signedjar \u0026lt;文件\u0026gt;] 已签名的 JAR 文件的名称\n[-digestalg \u0026lt;算法\u0026gt;] 摘要算法的名称\n[-sigalg \u0026lt;算法\u0026gt;] 签名算法的名称\n[-verify] 验证已签名的 JAR 文件\n[-verbose] 签名/验证时输出详细信息\n[-certs] 输出详细信息和验证时显示证书\n[-tsa ] 时间戳机构的位置\n[-tsacert \u0026lt;别名\u0026gt;] 时间戳机构的公共密钥证书\n[-altsigner \u0026lt;类\u0026gt;] 替代的签名机制的类名\n[-altsignerpath \u0026lt;路径列表\u0026gt;] 替代的签名机制的位置\n[-internalsf] 在签名块内包含 .SF 文件\n[-sectionsonly] 不计算整个清单的散列\n[-protected] 密钥库已保护验证路径\n[-providerName \u0026lt;名称\u0026gt;] 提供者名称\n[-providerClass \u0026lt;类\u0026gt; 加密服务提供者的名称\n[-providerArg \u0026lt;参数\u0026gt;]] \u0026hellip; 主类文件和构造函数参数\n第七步：对签名后的.apk文件进行对齐处理 （不进行对齐处理是不能发布到Google Market的）\n【输入】签名后的.apk文件\n【输出】对齐后的.apk文件\n【工具】zipalign工具\n知道了这些细节之后，我们就可以实现很多我们想实现东西了，比如：自动化，我们可以使用某种脚本，像Windows下的批处理，linux下的Bash，Java下的Ant，Python、Perl这样的脚本语言，甚至直接用Java、.net这们的强类型语言也是可以的。\n参考 http://www.jb51.net/article/106101.htm\nR.java位置：\nMoule path/build/generated/source/r/debug/…R.java\n资源打包流程:\nhttp://blog.csdn.net/luoshengyang/article/details/8744683\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/android%E6%89%93%E5%8C%85/",
	"title": "android打包",
	"tags": [],
	"description": "",
	"content": "android打包 探索总结android打包知识\n Android打包     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/ui/%E5%8A%A8%E7%94%BB/animatorsource/",
	"title": "AnimatorSource",
	"tags": [],
	"description": "",
	"content": "Animator类设计 插值器和估值器设计 参考doanimationframe\nclassDiagram class TimeInterpolator { +getInterpolation(float input) float } class BaseInterpolator { -int mChangingConfiguration } class LinearInterpolator { +getInterpolation(float input) float } class AccelerateDecelerateInterpolator { +getInterpolation(float input) float } TimeInterpolator\u0026lt;|--Interpolator Interpolator \u0026lt;|-- BaseInterpolator BaseInterpolator \u0026lt;|-- LinearInterpolator BaseInterpolator\u0026lt;|-- AccelerateDecelerateInterpolator class Keyframes{ setEvaluator(TypeEvaluator evaluator) } class FloatKeyframes{ getFloatValue(float fraction) float } class KeyframeSet { TypeEvaluator mEvaluator } class FloatKeyframeSet { getFloatValue(float fraction) float } class TypeEvaluator~T~{ +evaluate(float fraction, T startValue, T endValue) T } Keyframes\u0026lt;|--FloatKeyframes Keyframes\u0026lt;|--KeyframeSet KeyframeSet\u0026lt;|--FloatKeyframeSet KeyframeSet--*TypeEvaluator~T~ 图解 sequenceDiagram AnimatorSet-\u0026gt;\u0026gt;AnimatorSet: start participant Animator participant FloatPropertyValuesHolder activate AnimatorSet AnimatorSet-\u0026gt;\u0026gt;AnimationHandler: handler.addAnimationFrameCallback AnimationHandler-\u0026gt;\u0026gt;AnimationFrameCallbackProvider: getProvider().postFrameCallback(mFrameCallback) AnimationFrameCallbackProvider-\u0026gt;\u0026gt;Choreographer: mChoreographer.postFrameCallback(callback); AnimatorSet-\u0026gt;\u0026gt;Animator: startWithoutPulsing Note right of AnimatorSet: AinmatorSet启动时会接管pluseFrame,不调用Animator自生的frame回调 Animator-\u0026gt;\u0026gt;Animator: start Animator-\u0026gt;\u0026gt;AnimationHandler: getAnimationHandler().addAnimationFrameCallback Choreographer-\u0026gt;\u0026gt;Choreographer: Choreographer.FrameCallback.doFrame activate Choreographer Choreographer-\u0026gt;\u0026gt;AnimatorSet: 对每个mAnimationCallbacks(AnimatorSet或ValueAnimator实例),调用doAnimationFrame AnimatorSet-\u0026gt;\u0026gt;Animator: animateValue Choreographer-\u0026gt;\u0026gt;Animator: doAnimationFrame Animator-\u0026gt;\u0026gt;Animator: animateValue activate Animator Animator-\u0026gt;\u0026gt;FloatPropertyValuesHolder: super.animateValue(fraction)计算更新mValues值 activate Animator Note right of Animator: fraction = mInterpolator.getInterpolation(fraction)//先插值器 Note right of Animator: mValues[i].calculateValue(fraction)//后估值器 deactivate Animator Animator-\u0026gt;\u0026gt;FloatPropertyValuesHolder:mValues[i].setAnimatedValue(target); Note right of FloatPropertyValuesHolder: jni或反射调用对应view的属性修改方法,优先jni,其次反射 deactivate Animator Choreographer-\u0026gt;\u0026gt;AnimationFrameCallbackProvider: getProvider().postFrameCallback(this); deactivate Choreographer deactivate AnimatorSet AnimatorSet.start @Override public void start() { start(false, true); } private void start(boolean inReverse, boolean selfPulse) { if (Looper.myLooper() == null) { throw new AndroidRuntimeException(\u0026#34;Animators may only be run on Looper threads\u0026#34;); } initAnimation(); // Now that all dependencies are set up, start the animations that should be started.  boolean isEmptySet = isEmptySet(this); if (!isEmptySet) { startAnimation();//main  } if (mListeners != null) { ArrayList\u0026lt;AnimatorListener\u0026gt; tmpListeners = (ArrayList\u0026lt;AnimatorListener\u0026gt;) mListeners.clone(); int numListeners = tmpListeners.size(); for (int i = 0; i \u0026lt; numListeners; ++i) { tmpListeners.get(i).onAnimationStart(this, inReverse); } } } private void startAnimation() { addDummyListener(); // Register animation callback  addAnimationCallback(0); ...... if (mReversing || mStartDelay == 0 || mSeekState.isActive()) { long playTime; // If no delay, we need to call start on the first animations to be consistent with old  // behavior.  if (mSeekState.isActive()) { mSeekState.updateSeekDirection(mReversing); playTime = mSeekState.getPlayTime(); } else { playTime = 0; } int toId = findLatestEventIdForTime(playTime); handleAnimationEvents(-1, toId, playTime);//main  for (int i = mPlayingSet.size() - 1; i \u0026gt;= 0; i--) { if (mPlayingSet.get(i).mEnded) { mPlayingSet.remove(i); } } mLastEventId = toId; } } private void addAnimationCallback(long delay) { if (!mSelfPulse) { return; } AnimationHandler handler = AnimationHandler.getInstance(); handler.addAnimationFrameCallback(this, delay); } @Override public boolean doAnimationFrame(long frameTime) {//callback  // Pump a frame to the on-going animators  for (int i = 0; i \u0026lt; mPlayingSet.size(); i++) { Node node = mPlayingSet.get(i); if (!node.mEnded) { pulseFrame(node, getPlayTimeForNode(unscaledPlayTime, node));//main  } } if (finished) { endAnimation(); return true; } } animationHandler.addAnimationCallback public final static ThreadLocal\u0026lt;AnimationHandler\u0026gt; sAnimatorHandler = new ThreadLocal\u0026lt;\u0026gt;(); public static AnimationHandler getInstance() { if (sAnimatorHandler.get() == null) { sAnimatorHandler.set(new AnimationHandler()); } return sAnimatorHandler.get(); } private AnimationFrameCallbackProvider mProvider; /** * Register to get a callback on the next frame after the delay. */ public void addAnimationFrameCallback(final AnimationFrameCallback callback, long delay) { if (mAnimationCallbacks.size() == 0) { getProvider().postFrameCallback(mFrameCallback); } if (!mAnimationCallbacks.contains(callback)) { mAnimationCallbacks.add(callback); } if (delay \u0026gt; 0) { mDelayedCallbackStartTime.put(callback, (SystemClock.uptimeMillis() + delay)); } } interface AnimationFrameCallbackProvider { void postFrameCallback(Choreographer.FrameCallback callback); void postCommitCallback(Runnable runnable); long getFrameTime(); long getFrameDelay(); void setFrameDelay(long delay); } /** * Default provider of timing pulse that uses Choreographer for frame callbacks. */ private class MyFrameCallbackProvider implements AnimationFrameCallbackProvider { final Choreographer mChoreographer = Choreographer.getInstance(); @Override public void postFrameCallback(Choreographer.FrameCallback callback) { mChoreographer.postFrameCallback(callback); } } mFrameCallback.doFrame private final Choreographer.FrameCallback mFrameCallback = new Choreographer.FrameCallback() { @Override public void doFrame(long frameTimeNanos) { doAnimationFrame(getProvider().getFrameTime()); if (mAnimationCallbacks.size() \u0026gt; 0) { getProvider().postFrameCallback(this); } } }; /** Callbacks that receives notifications for animation timing and frame commit timing.*/ interface AnimationFrameCallback { boolean doAnimationFrame(long frameTime); void commitAnimationFrame(long frameTime); } private void doAnimationFrame(long frameTime) { for (int i = 0; i \u0026lt; size; i++) { final AnimationFrameCallback callback = mAnimationCallbacks.get(i); callback.doAnimationFrame(frameTime);//callback为AnimatorSet或ValueAnimator实例  } } Animator.start /** * When playing forward, we call start() at the animation\u0026#39;s scheduled start time, and make sure * to pump a frame at the animation\u0026#39;s scheduled end time. * * When playing in reverse, we should reverse the animation when we hit animation\u0026#39;s end event, * and expect the animation to end at the its delay ended event, rather than start event. */ private void handleAnimationEvents(int startId, int latestId, long playTime) { if (mReversing) { ...... } else { for (int i = startId + 1; i \u0026lt;= latestId; i++) { AnimationEvent event = mEvents.get(i); Node node = event.mNode; if (event.mEvent == AnimationEvent.ANIMATION_START) { mPlayingSet.add(event.mNode); if (node.mAnimation.isStarted()) { // If the animation has already been started before its due time (i.e.  // the child animator is being manipulated outside of the AnimatorSet), we  // need to cancel the animation to reset the internal state (e.g. frame  // time tracking) and remove the self pulsing callbacks  node.mAnimation.cancel(); } node.mEnded = false; node.mAnimation.startWithoutPulsing(false); pulseFrame(node, 0); } else if (event.mEvent == AnimationEvent.ANIMATION_END \u0026amp;\u0026amp; !node.mEnded) { // start event:  pulseFrame(node, getPlayTimeForNode(playTime, node)); } } } } /** * Internal use only. * This call starts the animation in regular or reverse direction without requiring them to * register frame callbacks. The caller will be responsible for all the subsequent animation * pulses. Specifically, the caller needs to call doAnimationFrame(...) for the animation on * every frame. * * @param inReverse whether the animation should play in reverse direction */ void startWithoutPulsing(boolean inReverse) { if (inReverse) { reverse(); } else { start(); } } @Override public void start() { start(false); } private void start(boolean playBackwards) { if (Looper.myLooper() == null) { throw new AndroidRuntimeException(\u0026#34;Animators may only be run on Looper threads\u0026#34;); } addAnimationCallback(0); } addAnimationCallback private void addAnimationCallback(long delay) { if (!mSelfPulse) { return; } getAnimationHandler().addAnimationFrameCallback(this, delay); } public final boolean doAnimationFrame(long frameTime) { boolean finished = animateBasedOnTime(currentTime);//1  if (finished) { endAnimation();//2  } return finished; } boolean animateBasedOnTime(long currentTime) { animateValue(currentIterationFraction);//main } private void endAnimation() { removeAnimationCallback(); } private void removeAnimationCallback() { getAnimationHandler().removeCallback(this); } pulseFrame /** * This method pulses frames into child animations. It scales the input animation play time * with the duration scale and pass that to the child animation via pulseAnimationFrame(long). * * @param node child animator node * @param animPlayTime unscaled play time (including start delay) for the child animator */ private void pulseFrame(Node node, long animPlayTime) { if (!node.mEnded) { float durationScale = ValueAnimator.getDurationScale(); durationScale = durationScale == 0 ? 1 : durationScale; node.mEnded = node.mAnimation.pulseAnimationFrame( (long) (animPlayTime * durationScale)); } } doAnimationFrame //ValueAnimator boolean pulseAnimationFrame(long frameTime) { return doAnimationFrame(frameTime); } public final boolean doAnimationFrame(long frameTime) { boolean finished = animateBasedOnTime(currentTime); } boolean animateBasedOnTime(long currentTime) { animateValue(currentIterationFraction); } animateValue //ObjectAnimator @Override void animateValue(float fraction) { final Object target = getTarget(); super.animateValue(fraction); int numValues = mValues.length; for (int i = 0; i \u0026lt; numValues; ++i) { mValues[i].setAnimatedValue(target); } } //ValueAnimator void animateValue(float fraction) { fraction = mInterpolator.getInterpolation(fraction);//先插值器  mCurrentFraction = fraction; int numValues = mValues.length; for (int i = 0; i \u0026lt; numValues; ++i) { mValues[i].calculateValue(fraction);//后估值器  } } setAnimatedValue //PropertyValuesHolder static class FloatPropertyValuesHolder extends PropertyValuesHolder { Keyframes.FloatKeyframes mFloatKeyframes; @Override void calculateValue(float fraction) { mFloatAnimatedValue = mFloatKeyframes.getFloatValue(fraction); } @Override void setAnimatedValue(Object target) { //使用jni或反射调用对应view的属性修改方法，优先jni，其次反射  if (mJniSetter != 0) { //jni调用之后，会调用对应view进行属性设置，如View.setTranslationX  nCallFloatMethod(target, mJniSetter, mFloatAnimatedValue); return; } native static private void nCallFloatMethod(Object target, long methodID, float arg); /frameworks/base/core/jni/android_animation_PropertyValuesHolder.cpp\n142static const JNINativeMethod gMethods[] = { 143 { \u0026#34;nGetIntMethod\u0026#34;, \u0026#34;(Ljava/lang/Class;Ljava/lang/String;)J\u0026#34;, 144 (void*)android_animation_PropertyValuesHolder_getIntMethod }, 145 { \u0026#34;nGetFloatMethod\u0026#34;, \u0026#34;(Ljava/lang/Class;Ljava/lang/String;)J\u0026#34;, 146 (void*)android_animation_PropertyValuesHolder_getFloatMethod }, 167}; 41static jlong android_animation_PropertyValuesHolder_getFloatMethod( 42 JNIEnv* env, jclass pvhClass, jclass targetClass, jstring methodName) 43{ 44 const char *nativeString = env-\u0026gt;GetStringUTFChars(methodName, 0); 45 jmethodID mid = env-\u0026gt;GetMethodID(targetClass, nativeString, \u0026#34;(F)V\u0026#34;); 46 env-\u0026gt;ReleaseStringUTFChars(methodName, nativeString); 47 return reinterpret_cast\u0026lt;jlong\u0026gt;(mid); 48} nCallFloatMethod /frameworks/base/tools/layoutlib/bridge/src/android/animation/PropertyValuesHolder_Delegate.java @LayoutlibDelegate /*package*/ static void nCallFloatMethod(Object target, long methodID, float arg) { callMethod(target, methodID, arg); } private static void callMethod(Object target, long methodID, Object... args) { Method method = ID_TO_METHOD.get(methodID); assert method != null; try { method.setAccessible(true); method.invoke(target, args); } catch (IllegalAccessException | InvocationTargetException e) { Bridge.getLog().error(null, \u0026#34;Unable to update property during animation\u0026#34;, e, null); } } View.setTranslationX //View //nCallFloatMethod调用之后如果是本属性则会调用到这里 public void setTranslationX(float translationX) { if (translationX != getTranslationX()) { invalidateViewProperty(true, false); mRenderNode.setTranslationX(translationX); invalidateViewProperty(false, true); invalidateParentIfNeededAndWasQuickRejected(); notifySubtreeAccessibilityStateChangedIfNeeded(); } } 其他 Choreographer // The display event receiver can only be accessed by the looper thread to which  // it is attached. We take care to ensure that we post message to the looper  // if appropriate when interacting with the display event receiver.  private final FrameDisplayEventReceiver mDisplayEventReceiver; private final class FrameDisplayEventReceiver extends DisplayEventReceiver implements Runnable { @Override public void onVsync(long timestampNanos, int builtInDisplayId, int frame) { Message msg = Message.obtain(mHandler, this);//call run method  msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, timestampNanos / TimeUtils.NANOS_PER_MS); } } @Override public void run() { mHavePendingVsync = false; doFrame(mTimestampNanos, mFrame); } void doFrame(long frameTimeNanos, int frame) { mFrameInfo.markInputHandlingStart(); doCallbacks(Choreographer.CALLBACK_INPUT, frameTimeNanos); mFrameInfo.markAnimationsStart(); doCallbacks(Choreographer.CALLBACK_ANIMATION, frameTimeNanos); mFrameInfo.markPerformTraversalsStart(); doCallbacks(Choreographer.CALLBACK_TRAVERSAL, frameTimeNanos); } void doCallbacks(int callbackType, long frameTimeNanos) { CallbackRecord callbacks; synchronized (mLock) { // We use \u0026#34;now\u0026#34; to determine when callbacks become due because it\u0026#39;s possible  // for earlier processing phases in a frame to post callbacks that should run  // in a following phase, such as an input event that causes an animation to start.  final long now = System.nanoTime(); callbacks = mCallbackQueues[callbackType].extractDueCallbacksLocked( now / TimeUtils.NANOS_PER_MS); for (CallbackRecord c = callbacks; c != null; c = c.next) { c.run(frameTimeNanos); } } CallbackRecord private static final class CallbackRecord { public CallbackRecord next; public long dueTime; public Object action; // Runnable or FrameCallback  public Object token; public void run(long frameTimeNanos) { if (token == FRAME_CALLBACK_TOKEN) { ((FrameCallback)action).doFrame(frameTimeNanos); } else { ((Runnable)action).run(); } } public interface FrameCallback { public void doFrame(long frameTimeNanos); } Handler public void dispatchMessage(Message msg) {} private static void handleCallback(Message message) { message.callback.run(); } ViewRootImpl final class TraversalRunnable implements Runnable { @Override public void run() { doTraversal(); } } doTraversal() { performTraversals(); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/anr/",
	"title": "anr",
	"tags": [],
	"description": "",
	"content": "anr 探索总结anr知识\n 1ANRSystmHandle     2ANRMonitor_CollectInfo     3ANRAnalysisRootCause     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/aop/",
	"title": "aop",
	"tags": [],
	"description": "",
	"content": "aop 探索总结aop知识\n ASM访客者模式     JDK动态代理     编译插桩和动态代理     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/apk%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD/",
	"title": "apk安装和卸载",
	"tags": [],
	"description": "",
	"content": "apk安装和卸载 探索总结apk安装和卸载知识\n 应用安装和卸载过程     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/apm/",
	"title": "apm",
	"tags": [],
	"description": "",
	"content": "apm 探索总结apm知识\n MatrixGradlePlugin     MatrixSource     Matrix接入后遇到的问题     Matrix研究     resource    MatrixResourcePlugin      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%AE%89%E5%85%A8/app%E7%AD%BE%E5%90%8D/",
	"title": "app签名",
	"tags": [],
	"description": "",
	"content": "ECDSA数字签名算法\nAndroid N Signature Scheme v2 渠道打包\n如果您使用 APK Signature Scheme v2 签署您的应用，并对应用进行了进一步更改，则应用的签名将无效。出于这个原因，请在使用 APK Signature Scheme v2 签署您的应用之前、而非之后使用 zipalign 等工具。 如需了解详细信息，请阅读相关的 Android Studio 文档，这些文档介绍了如何在 Android Studio 中签署应用以及如何使用 Android Plugin for Gradle 为签署应用配置构建文件。\nAPK文件格式 apk 本身是个 zip 格式, 格式可以参考http://blog.sina.com.cn/s/blog_4c3591bd0100zzm6.html.\napksigner https://www.jianshu.com/p/4a07d902066f\napksigner.bat sign \u0026ndash;ks 签名文件 \u0026ndash;ks-pass 密码 \u0026ndash;ks-key-alias 别名\nSdk\\build-tools\\28.0.3\u0026gt;apksigner.bat sign \u0026ndash;help\nSdk\\build-tools\\28.0.3\\lib\\apksigner.jar\n–ks 你的jks路径 //jks签名证书路径\n–ks-key-alias 你的alias //生成jks时指定的alias\n–ks-pass pass:你的密码 //KeyStore密码\n–key-pass pass:你的密码 //签署者的密码，即生成jks时指定alias对应的密码\n–out output.apk //输出路径\ninput.apk //被签名的apk\n示例：\njava -jar apksigner.jar sign --ks key.jks --ks-key-alias releasekey --ks-pass pass:pp123456 --key-pass pass:pp123456 --out output.apk input.apk java -jar Sdk\\build-tools\\28.0.3\\lib\\apksigner.jar sign --ks $keystoreFilePath --ks-key-alias $keyAlias --ks-pass pass:$ksPass --key-pass pass:$keyPass --out xxx\\output.apk input.apk 数字签名 数字签名和签名验证的大体流程如下图所示： Android 签名机制 v1、v2、v3\nAndroid v1、v2、v3签名详解\n v1 方案：基于 JAR 签名。 v2 方案：APK 签名方案 v2，在 Android 7.0 引入。 v3 方案：APK 签名方案v3，在 Android 9.0 引入  其中，v1 到 v2 是颠覆性的，主要是为了解决 JAR 签名方案的安全性问题，而到了 v3 方案，其实结构上并没有太大的调整，可以理解为 v2 签名方案的升级版。\nv1 到 v2 方案的升级，对开发者影响是最大的，就是渠道签署的问题。v2的签名也是为了让不同渠道、市场的安装包有所区别，携带渠道的唯一标识，也即是我们俗称的渠道包。好在各大厂都开源了自己的签渠道方案，例如：Walle（美团）、VasDolly（腾讯）都是非常优秀的方案。\n新一代开源Android渠道包生成工具Walle\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/",
	"title": "arch",
	"tags": [],
	"description": "",
	"content": "arch 探索总结arch知识\n 1lifecycle    Lifecycle     LifecycleCoroutine      2livedata    1MediatorLiveData     LiveData     LiveDataCoroutine     Transformations      3viewmodel    SaveAndRestoreInstanceState     SavedStateHandle     SavingStates     ViewModel     ViewModelScope_Delegate      Coroutines     databinding    Databinding     TwoWayDataBinding      di    Compose     ComposeSource     LayoutNode     ReComposition      架构实现    KaptGenerateViewModel     架构思考和实现     架构思考和实现Inner      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/",
	"title": "art",
	"tags": [],
	"description": "",
	"content": "art 探索总结art知识\n 1类编译    dex2oat     dex2oat介绍      2类加载    Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层      alloc_gc    1Space     2Alloc     AllocRelated     GC     GC1_MS_CMS     GC2_ConcurrentCopying     GC3_MarkCompact     GC4_Semi_Space     Runtime_VisitRoots      ART_Lock     jni    _解释执行7_0     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常      启动流程    ART启动流程      基础数据结构     混合编译_运行    JVM_JIT     混合编译_运行      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/art_lock/",
	"title": "ART_Lock",
	"tags": [],
	"description": "",
	"content": "ObjectLock\u0026lt;mirror::Class\u0026gt; lock(self, klass); art/runtime/object_lock.cc\nobject_lock.cc ObjectLock template \u0026lt;typename T\u0026gt; ObjectLock\u0026lt;T\u0026gt;::ObjectLock(Thread* self, Handle\u0026lt;T\u0026gt; object) : self_(self), obj_(object) { CHECK(object != nullptr); obj_-\u0026gt;MonitorEnter(self_); } ~ObjectLock template \u0026lt;typename T\u0026gt; ObjectLock\u0026lt;T\u0026gt;::~ObjectLock() { obj_-\u0026gt;MonitorExit(self_); } art/runtime/mirror/object-inl.h\nobject-inl.h MonitorEnter inline mirror::Object* Object::MonitorEnter(Thread* self) { return Monitor::MonitorEnter(self, this, /*trylock*/false); } art/runtime/monitor.cc\nmonitor.cc MonitorEnter mirror::Object* Monitor::MonitorEnter(Thread* self, mirror::Object* obj, bool trylock) { StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Object\u0026gt; h_obj(hs.NewHandle(obj)); while (true) { // We initially read the lockword with ordinary Java/relaxed semantics. When stronger  // semantics are needed, we address it below. Since GetLockWord bottoms out to a relaxed load,  // we can fix it later, in an infrequently executed case, with a fence.  LockWord lock_word = h_obj-\u0026gt;GetLockWord(false); switch (lock_word.GetState()) { case LockWord::kUnlocked: { // No ordering required for preceding lockword read, since we retest.  LockWord thin_locked(LockWord::FromThinLockId(thread_id, 0, lock_word.GCState())); if (h_obj-\u0026gt;CasLockWordWeakAcquire(lock_word, thin_locked)) { AtraceMonitorLock(self, h_obj.Get(), false /* is_wait */); return h_obj.Get(); // Success!  } continue; // Go again.  } case LockWord::kThinLocked: { case LockWord::kFatLocked: { art/runtime/lock_word.h\nlock_word.h LockState enum LockState { kUnlocked, // No lock owners.  kThinLocked, // Single uncontended owner.  kFatLocked, // See associated monitor.  kHashCode, // Lock word contains an identity hash.  kForwardingAddress, // Lock word contains the forwarding address of an object. }; "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/art%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/",
	"title": "ART启动流程",
	"tags": [],
	"description": "",
	"content": "graph TB Init(\u0026quot;init进程通过解析配置脚本\u0026quot;)--\u0026gt;|fork子进程运行Zygote服务|AppProcess(\u0026quot;/system/bin/app_process:frameworks\\base\\cmds\\app_process\\app_main.cc\u0026quot;) AppProcess--\u0026gt;JniInvocation::Init AppProcess--\u0026gt;AndroidRuntime::StartVm AppProcess--\u0026gt;C调用Java层ZygoteInit的main方法 zygoteinit.main后续流程参考zygotesource\nframeworks\\base\\cmds\\app_process\\app_main.cpp\nint main(int argc, char* const argv[]) { if (zygote) { runtime.start(\u0026#34;com.android.internal.os.ZygoteInit\u0026#34;, args, zygote); } else if (className) { runtime.start(\u0026#34;com.android.internal.os.RuntimeInit\u0026#34;, args, zygote); } else { fprintf(stderr, \u0026#34;Error: no class name or --zygote supplied.\\n\u0026#34;); app_usage(); LOG_ALWAYS_FATAL(\u0026#34;app_process: no class name or --zygote supplied.\u0026#34;); return 10; } void AndroidRuntime::start(const char* className, const Vector\u0026lt;String8\u0026gt;\u0026amp; options, bool zygote){ ...... JniInvocation jni_invocation; jni_invocation.Init(NULL);//1. 它将加载ART虚拟机的核心动态库。  JNIEnv* env; if (startVm(\u0026amp;mJavaVM, \u0026amp;env, zygote) != 0) { return; }//2. 在ART虚拟机对应的核心动态库加载到zyogte进程后，该函数将启动ART虚拟机。  onVmCreated(env); ...... jclass stringClass; jobjectArray strArray; jstring classNameStr; ...... char* slashClassName = toSlashClassName(className);//\u0026#34;com.android.internal.os.ZygoteInit\u0026#34;  //找到目标类对应的mirror Class对象  jclass startClass = env-\u0026gt;FindClass(slashClassName);//main  if (startClass == NULL) {} else { //找到该类中的静态main函数对应的ArtMethod对象  jmethodID startMeth = env-\u0026gt;GetStaticMethodID(startClass, \u0026#34;main\u0026#34;,//main  \u0026#34;([Ljava/lang/String;)V\u0026#34;); if (startMeth == NULL) {} else { //调用这个main函数  env-\u0026gt;CallStaticVoidMethod(startClass, startMeth, strArray);//3. main  ...... } } ...... JniInvocation::Init bool JniInvocation::Init(const char* library) { library = GetLibrary(library, buffer); const int kDlopenFlags = RTLD_NOW | RTLD_NODELETE; handle_ = dlopen(library, kDlopenFlags);//动态加载libart.so,main  //初始化三个函数指针,main  if (!FindSymbol(reinterpret_cast\u0026lt;void**\u0026gt;(\u0026amp;JNI_GetDefaultJavaVMInitArgs_), \u0026#34;JNI_GetDefaultJavaVMInitArgs\u0026#34;)) { return false; } if (!FindSymbol(reinterpret_cast\u0026lt;void**\u0026gt;(\u0026amp;JNI_CreateJavaVM_),//赋值创建虚拟机的入口函数,main  \u0026#34;JNI_CreateJavaVM\u0026#34;)) { return false; } if (!FindSymbol(reinterpret_cast\u0026lt;void**\u0026gt;(\u0026amp;JNI_GetCreatedJavaVMs_), \u0026#34;JNI_GetCreatedJavaVMs\u0026#34;)) { return false; } AndroidRuntime::startVm int AndroidRuntime::startVm(JavaVM** pJavaVM, JNIEnv** pEnv, bool zygote) { initArgs.version = JNI_VERSION_1_4; initArgs.options = mOptions.editArray(); initArgs.nOptions = mOptions.size(); initArgs.ignoreUnrecognized = JNI_FALSE; /* * Initialize the VM. * * The JavaVM* is essentially per-process, and the JNIEnv* is per-thread. * If this call succeeds, the VM is ready, and we can start issuing * JNI calls. */ if (JNI_CreateJavaVM(pJavaVM, pEnv, \u0026amp;initArgs) \u0026lt; 0) { ALOGE(\u0026#34;JNI_CreateJavaVM failed\\n\u0026#34;); return -1; } return 0; extern \u0026#34;C\u0026#34; jint JNI_CreateJavaVM(JavaVM** p_vm, JNIEnv** p_env, void* vm_args) { return JniInvocation::GetJniInvocation().JNI_CreateJavaVM(p_vm, p_env, vm_args); } jint JniInvocation::JNI_CreateJavaVM(JavaVM** p_vm, JNIEnv** p_env, void* vm_args) { return JNI_CreateJavaVM_(p_vm, p_env, vm_args);//调用libart.so中的实现 } java_vm_ext.cc\nJNI_CreateJavaVM extern \u0026#34;C\u0026#34; jint JNI_CreateJavaVM(JavaVM** p_vm, JNIEnv** p_env,void* vm_args) { ScopedTrace trace(__FUNCTION__); const JavaVMInitArgs* args = static_cast\u0026lt;JavaVMInitArgs*\u0026gt;(vm_args); .....//为虚拟机准备参数  bool ignore_unrecognized = args-\u0026gt;ignoreUnrecognized; //①创建Runtime对象，它就是ART虚拟机的化身  if (!Runtime::Create(options, ignore_unrecognized)) {...} //加载其他关键动态库，它们的文件路径由/etc/public.libraries.txt文件描述  android::InitializeNativeLoader(); Runtime* runtime = Runtime::Current();//获取刚创建的Runtime对象  bool started = runtime-\u0026gt;Start();//②启动runtime。注意，这部分内容留待下一章介绍  .... //获取JNI Env和Java VM对象  *p_env = Thread::Current()-\u0026gt;GetJniEnv(); *p_vm = runtime-\u0026gt;GetJavaVM(); return JNI_OK; } runtime.cc\nRuntime::Create bool Runtime::Create(const RuntimeOptions\u0026amp; raw_options, bool ignore_unrecognized) { /*虚拟机是一个复杂系统，所以它有很多控制参数。创建Runtime时，调用者将这些参数信息放在本函数的入参raw_options对象中，该对象的类型是RuntimeOptions。不过，Runtime内部却使用类型为RuntimeArgumentMap的对象来存储参数。下面这段代码中，ParseOptions函数将存储在raw_options里的参数信息提取并保存到runtime_options对象里，而runtime_options的类型就是RuntimeArgumentMap。*/ RuntimeArgumentMap runtime_options; return ParseOptions(raw_options, ignore_unrecognized, \u0026amp;runtime_options) \u0026amp;\u0026amp; Create(std::move(runtime_options)); } bool Runtime::Create(RuntimeArgumentMap\u0026amp;\u0026amp; runtime_options) { //一个虚拟机进程中只有一个Runtime对象，名为instance_，采用单例方式来创建  if (Runtime::instance_ != nullptr) { return false; } instance_ = new Runtime; //创建Runtime对象  //用保存了虚拟机控制参数信息的runtime_options来初始化这个runtime对象。  //重点来看Init函数  if (!instance_-\u0026gt;Init(std::move(runtime_options))) {....} return true; } Runtime::Init bool Runtime::Init(RuntimeArgumentMap\u0026amp;\u0026amp; runtime_options_in) { RuntimeArgumentMap runtime_options(std::move(runtime_options_in)); //关键模块之MemMap：用于管理内存映射。ART大量使用了内存映射技术。比如.oat文件  //就会通过mmap映射到虚拟机进程的虚拟内存中来。  MemMap::Init(); using Opt = RuntimeArgumentMap;//C++11里using的用法  QuasiAtomic::Startup(); //MIPS架构中需要使用它，其他CPU架构可不考虑  //关键模块之OatFileManager：art虚拟机会打开多个oat文件，通过该模块可统一管理它们  oat_file_manager_ = new OatFileManager; Thread::SetSensitiveThreadHook(runtime_options.GetOrDefault( Opt::HookIsSensitiveThread)); //关键模块之Monitor：和Java中的monitor有关，用于实现线程同步的模块。其详情见本书第12章的内容  Monitor::Init(runtime_options.GetOrDefault(Opt::LockProfThreshold)); /*从runtime_options中提取参数。Opt是RuntimeArgumentMap的别名，而BootClassPath是runtime_options.def中定义的一个控制参数的名称。该控制参数的数据类型是vector\u0026lt;unique_ptr\u0026lt;const DexFile\u0026gt;\u0026gt;。从RuntimeArgumentMap中获取一个控制参数的值的函数有两个： （1）GetOrDefault：从指定参数中获取其值，如果外界没有设置该控制参数，则返回参数配置文件里的配置的默认值。这里的参数配置文件就是上文提到的runtime_options.def。 （2）ReleaseOrDefault：功能和GetOrDefault一样，唯一的区别在于如果外界设置了该参数，该函数将通过std::move函数将参数的值返回给调用者。std move的含义我们在第5章中已做过介绍。使用move的话，外界传入的参数将移动到返回值所在对象里，从而节省了一份内存。比如，假设参数值存储在一个string对象中，如果不使用move的话，那么RuntimeArgumentMap内部将保留一份string，而调用者拿到作为返回值的另外一份string。显然，不使用move的话，将会有两个string对象，内存会浪费一些。所以，ReleaseOrDefault用于获取类类型的控制参数的值，而对于int等基础数据类型，使用GetOrDefault即可。*/ boot_class_path_string_ = runtime_options.ReleaseOrDefault(Opt::BootClassPath); ......//从runtime_options中获取其他控制参数的值  /*接下来的关键模块为： （1）MointorList：它维护了一组Monitor对象 （2）MonitorPool：用于创建Monitor对象 （3）ThreadList：用于管理ART中的线程对象（线程对象的数据类型为Thread）的模块 （4）InternTable：该模块和string intern table有关。它其实就是字符串常量池。根据Java语言规范（Java Language Specification，简写为JLS）的要求，内容完全相同的字符串常量（string literal）应该共享同一份资源。比如，假设String a=\u0026#34;hello\u0026#34;，String b=\u0026#34;hello\u0026#34;，那么a==b（直接比较对象a是否等于对象b）应该返回true。intern table的目的很好理解，就是减少内存占用。另外，String类中有一个intern方法，它可以将某个String对象添加到intern table中。*/ monitor_list_ = new MonitorList; monitor_pool_ = MonitorPool::Create(); thread_list_ = new ThreadList; intern_table_ = new InternTable; .....//从runtime_options中获取控制参数  //关键模块之Heap：heap是art虚拟机中非常重要的模块。详情见下文分析  heap_ = new gc::Heap(......); .... //和lambda有关，以后碰见它时再来介绍  lambda_box_table_ = MakeUnique\u0026lt;lambda::BoxTable\u0026gt;(); /*关键模块ArenaPool及LinearAlloc：runtime内部也需要创建很多对象或者需要存储一些信息。为了更好地管理虚拟机自己的内存使用，runtime设计了： （1）内存池类ArenaPool。ArenaPool可管理多个内存单元（由Arena表示）。 （2）对内存使用者而言，使用内存分配器（LinearAlloc）即可在ArenaPool上分配任意大小的内存。该模块的代码非常简单，请读者自行阅读。*/ const bool use_malloc = IsAotCompiler(); arena_pool_.reset(new ArenaPool(use_malloc, false)); jit_arena_pool_.reset(new ArenaPool(false, false, \u0026#34;CompilerMetadata\u0026#34;)); linear_alloc_.reset(CreateLinearAlloc()); //接下来的一段代码和信号处理有关。ART虚拟机进程需要截获来自操作系统的某些信号  BlockSignals();//阻塞SIGPIPE、SIGQUIT和SIGUSER1信号  /*为某些信号设置自定义的信号处理函数。该函数在linux和android平台上的处理不尽相同。在android（也就是针对设备的编译）平台上，这段代码并未启用。详情可参考该函数在runtime_android.cc中的实现*/ InitPlatformSignalHandlers(); if (!no_sig_chain_) {//对在目标设备上运行的art虚拟机来说，该变量取默认值false  //获取sigaction和sigprocmask两个函数的函数指针。这和linux信号处理  //函数的调用方法有关。此处不拟讨论它，感兴趣的读者可参考代码中的注释  InitializeSignalChain(); /*下面三个变量的介绍如下： （1）implicit_null_checks_：是否启用隐式空指针检查，此处取值为true。 （2）implict_so_checkes_：是否启用隐式堆栈溢出（stackoverflow）检查，此处取值为true。 （3）implict_suspend_checks_：是否启用隐式线程暂停（thread suspension）检查，此处取值为false。suspend check相关内容将在第11章做详细介绍。*/ if (implicit_null_checks_ || implicit_so_checks_ || implicit_suspend_checks_) { //关键模块之FaultManager：该模块用于处理SIGSEV信号  fault_manager.Init(); /*下面的SuspensionHandler、StackOverflowHandler和NullPointerHandler有共同的基类FaultHandler，笔者将它们归为关键模块FaultManager之中。这部分内容 留待下文再介绍*/ if (implicit_suspend_checks_) { new SuspensionHandler(\u0026amp;fault_manager); } if (implicit_so_checks_) { new StackOverflowHandler(\u0026amp;fault_manager); } if (implicit_null_checks_) { new NullPointerHandler(\u0026amp;fault_manager); } ..... } } /*关键模块之JavaVmExt：JavaVmExt就是JNI中代表Java虚拟机的对象，其基类为JavaVM，真实类型为JavaVmExt。根据JNI规范，一个进程只有唯一的一个JavaVm对象。对art虚拟机来说，这个JavaVm对象就是此处的java_vm_。*/ java_vm_ = new JavaVMExt(this, runtime_options); //关键模块之Thread：Thread是虚拟机中代表线程的类，下面两个函数调用Thread类的  //Startup和Attach以初始化虚拟机主线程  Thread::Startup(); Thread* self = Thread::Attach(\u0026#34;main\u0026#34;, false, nullptr, false); self-\u0026gt;TransitionFromSuspendedToRunnable(); //关键模块之ClassLinker：ClassLinker也是非常重要的模块。从其命名可以看出，它处理  //和Class有关的工作，比如解析某个类、寻找某个类等  class_linker_ = new ClassLinker(intern_table_); if (GetHeap()-\u0026gt;HasBootImageSpace()) { std::string error_msg; //从oat镜像文件中初始化class linker，也就是从oat文件中获取类等信息。  bool result = class_linker_-\u0026gt;InitFromBootImage(\u0026amp;error_msg); { ScopedTrace trace2(\u0026#34;AddImageStringsToTable\u0026#34;); //处理和intern table有关的初始化  GetInternTable()-\u0026gt;AddImagesStringsToTable(heap_-\u0026gt;GetBootImageSpaces()); } { ScopedTrace trace2(\u0026#34;MoveImageClassesToClassTable\u0026#34;); //art虚拟机中每一个class loader都有一个class table，它存储了该loader  //所加载的各种class。下面这个函数将把来自镜像中的类信息添加到boot class loader  //对应的ClassTable中。这部分内容将在ClassLinker一节中介绍  GetClassLinker()-\u0026gt;AddBootImageClassesToClassTable(); } } ...... //关键模块之MethodVerifier：用于校验Java方法的模块。下一章介绍类校验方面知识时  //将接触MethodVerifier类。本书不拟对该类做过多介绍。  verifier::MethodVerifier::Init(); /*下面这段代码用于创建两个异常对象。注意，此处ThrowNewException将创建异常对象，而ClearException将清除异常对象。这样的话，Init函数返回后将不会导致异常投递。这是JNI函数中常用的做法。读者可以先不用了解这么多，后续章节介绍JNI及异常投递时还会详细介绍。 pre_allocated_OutOfMemoryError_和pre_allocated_NoClassDefFoundError_代表Java层OutOfMemoryError对象和NoClassDefFoundError对象。*/ self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/OutOfMemoryError;\u0026#34;,....); pre_allocated_OutOfMemoryError_ = GcRoot\u0026lt;mirror::Throwable\u0026gt;(self-\u0026gt;GetException()); self-\u0026gt;ClearException(); self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/NoClassDefFoundError;\u0026#34;,...); pre_allocated_NoClassDefFoundError_ = GcRoot\u0026lt;mirror::Throwable\u0026gt;(self-\u0026gt;GetException()); self-\u0026gt;ClearException(); ......//native bridge library加载，本文不涉及相关内容  return true; } MemMap\nstatic MemMap* MapAnonymous(const char* name, uint8_t* addr, size_t byte_count, int prot, bool low_4gb, bool reuse, std::string* error_msg, bool use_ashmem = true); static MemMap* MapFile(size_t byte_count,int prot, int flags, int fd,off_t start, bool low_4gb, const char* filename, std::string* error_msg) { return MapFileAtAddress(nullptr,....);//最终调用这个函数完成内存映射  } static MemMap* MapFileAtAddress(uint8_t* addr, size_t byte_count, .....std::string* error_msg); static Maps* maps_ GUARDED_BY(Locks::mem_maps_lock_); MemMap(const std::string\u0026amp; name,uint8_t* begin,size_t size, void* base_begin,size_t base_size,int prot, bool reuse,size_t redzone_size = 0) REQUIRES(!Locks::mem_maps_lock_); //该函数内部将调用mmap来完成实际的内存映射操作，读者可自行查看其代码  static void* MapInternal(void* addr, size_t length,int prot, int flags,int fd, off_t offset, bool low_4gb); .....; }; void MemMap::Init() { MutexLock mu(Thread::Current(), *Locks::mem_maps_lock_); if (maps_ == nullptr) {//Init中使用了mem_maps_lock_锁  maps_ = new Maps; } } C调用Java层ZygoteInit的main方法 jni_internal.FindClass static jclass FindClass(JNIEnv* env, const char* name) { CHECK_NON_NULL_ARGUMENT(name); Runtime* runtime = Runtime::Current(); ClassLinker* class_linker = runtime-\u0026gt;GetClassLinker(); std::string descriptor(NormalizeJniClassDescriptor(name)); ScopedObjectAccess soa(env); mirror::Class* c = nullptr; if (runtime-\u0026gt;IsStarted()) { StackHandleScope\u0026lt;1\u0026gt; hs(soa.Self()); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle(GetClassLoader(soa))); c = class_linker-\u0026gt;FindClass(soa.Self(), descriptor.c_str(), class_loader);//main  } else { c = class_linker-\u0026gt;FindSystemClass(soa.Self(), descriptor.c_str()); } return soa.AddLocalReference\u0026lt;jclass\u0026gt;(c); } jni_internal.GetStaticMethodID static jmethodID GetStaticMethodID(JNIEnv* env, jclass java_class, const char* name, const char* sig) { CHECK_NON_NULL_ARGUMENT(java_class); CHECK_NON_NULL_ARGUMENT(name); CHECK_NON_NULL_ARGUMENT(sig); ScopedObjectAccess soa(env); return FindMethodID(soa, java_class, name, sig, true); } static jmethodID FindMethodID(ScopedObjectAccess\u0026amp; soa, jclass jni_class, const char* name, const char* sig, bool is_static) SHARED_REQUIRES(Locks::mutator_lock_) { mirror::Class* c = EnsureInitialized(soa.Self(), soa.Decode\u0026lt;mirror::Class*\u0026gt;(jni_class)); if (c == nullptr) { return nullptr; } ArtMethod* method = nullptr; auto pointer_size = Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;GetImagePointerSize(); if (is_static) { method = c-\u0026gt;FindDirectMethod(name, sig, pointer_size); } else if (c-\u0026gt;IsInterface()) { method = c-\u0026gt;FindInterfaceMethod(name, sig, pointer_size); } else { method = c-\u0026gt;FindVirtualMethod(name, sig, pointer_size); if (method == nullptr) { // No virtual method matching the signature. Search declared  // private methods and constructors.  method = c-\u0026gt;FindDeclaredDirectMethod(name, sig, pointer_size); } } ...... return soa.EncodeMethod(method); } jni_internal.CallStaticVoidMethod static void CallStaticVoidMethod(JNIEnv* env, jclass, jmethodID mid, ...) { va_list ap; va_start(ap, mid); CHECK_NON_NULL_ARGUMENT_RETURN_VOID(mid); ScopedObjectAccess soa(env); InvokeWithVarArgs(soa, nullptr, mid, ap); va_end(ap); } static jobject CallStaticObjectMethod(JNIEnv* env, jclass, jmethodID mid, ...) { va_list ap; va_start(ap, mid); ScopedObjectAccess soa(env); //先调用InvokeWithVarArgs，返回值存储在result中  JValue result(InvokeWithVarArgs(soa, nullptr, mid, ap)); jobject local_result = soa.AddLocalReference\u0026lt;jobject\u0026gt;(result.GetL()); va_end(ap); return local_result; } reflection.InvokeWithVarArgs JValue InvokeWithVarArgs(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject obj, jmethodID mid, va_list args) { ..... ArtMethod* method = soa.DecodeMethod(mid); bool is_string_init = .....; if (is_string_init) {......} mirror::Object* receiver = method-\u0026gt;IsStatic() ? nullptr : soa.Decode\u0026lt;mirror::Object*\u0026gt;(obj); uint32_t shorty_len = 0; const char* shorty = method-\u0026gt;GetInterfaceMethodIfProxy( sizeof(void*))-\u0026gt;GetShorty(\u0026amp;shorty_len); JValue result; ArgArray arg_array(shorty, shorty_len); arg_array.BuildArgArrayFromVarArgs(soa, receiver, args); //调用InvokeWithArgArray  InvokeWithArgArray(soa, method, \u0026amp;arg_array, \u0026amp;result, shorty); ..... return result; } static void InvokeWithArgArray(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, ArtMethod* method, ArgArray* arg_array, JValue* result, const char* shorty) { uint32_t* args = arg_array-\u0026gt;GetArray(); ...... //调用ArtMethod的Invoke函数  method-\u0026gt;Invoke(soa.Self(), args, arg_array-\u0026gt;GetNumBytes(), result, shorty); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/ashmem/",
	"title": "ashmem",
	"tags": [],
	"description": "",
	"content": "ashmem 探索总结ashmem知识\n 匿名共享内存Ashmem     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/aop/asm%E8%AE%BF%E5%AE%A2%E8%80%85%E6%A8%A1%E5%BC%8F/",
	"title": "ASM访客者模式",
	"tags": [],
	"description": "",
	"content": "ASM访客者 is = new FileInputStream(classFile); ClassReader classReader = new ClassReader(is); ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_MAXS); ClassVisitor classVisitor = new TraceClassAdapter(Opcodes.ASM5, classWriter); classReader.accept(classVisitor, ClassReader.EXPAND_FRAMES); is.close(); if (output.isDirectory()) { os = new FileOutputStream(changedFileOutput); } else { os = new FileOutputStream(output); } os.write(classWriter.toByteArray()); os.close(); classReader用来读取来自inputstream的class字节码，并在遍历到类和方法时分别调用到visit和visitMethod方法，参数为解析出的信息\ngraph LR FileInputStream--\u0026gt;classReader classReader--\u0026gt;ClassVisitor ClassVisitor--\u0026gt;ClassWriter ClassWriter--\u0026gt;FileOutputStream @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) { 在方法开始处插桩AppMethodBeat.i(methodId)方法\n@Override protected void onMethodEnter() { TraceMethod traceMethod = collectedMethodMap.get(methodName); if (traceMethod != null) { traceMethodCount.incrementAndGet(); mv.visitLdcInsn(traceMethod.id); mv.visitMethodInsn(INVOKESTATIC, TraceBuildConstants.MATRIX_TRACE_CLASS, \u0026#34;i\u0026#34;, \u0026#34;(I)V\u0026#34;, false); } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/",
	"title": "binder",
	"tags": [],
	"description": "",
	"content": "binder 探索总结binder知识\n 1BinderServiceManager     2BinderServer     3BinderClient     4BinderKernel     BinderDeath     Binder原理     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binderdeath/",
	"title": "BinderDeath",
	"tags": [],
	"description": "",
	"content": "原理总结 Binder死亡通知机制之linkToDeath\nUnlinkToDeath流程类似，参考上文，不做记录\n死亡通知是为了让Bp端(客户端进程)进能知晓Bn端(服务端进程)的生死情况，当Bn端进程死亡后能通知到Bp端。\n 定义：AppDeathRecipient是继承IBinder::DeathRecipient类，主要需要实现其binderDied()来进行死亡通告。 注册：binder-\u0026gt;linkToDeath(AppDeathRecipient)是为了将AppDeathRecipient死亡通知注册到Binder上。  Bp端只需要覆写binderDied()方法，实现一些后尾清除类的工作，则在Bn端死掉后，会回调binderDied()进行相应处理。\nlinkToDeath android_os_BinderProxy_linkToDeath static void android_os_BinderProxy_linkToDeath(JNIEnv* env, jobject obj, jobject recipient, jint flags) { //获取BinderProxy.mObject成员变量值, 即BpBinder对象  IBinder* target = (IBinder*)env-\u0026gt;GetLongField(obj, gBinderProxyOffsets.mObject); sp\u0026lt;JavaDeathRecipient\u0026gt; jdr = new JavaDeathRecipient(env, recipient, list); //建立死亡通知[见小节2.2]  status_t err = target-\u0026gt;linkToDeath(jdr, NULL, flags); }  获取DeathRecipientList: 其成员变量mList记录该BinderProxy的JavaDeathRecipient列表信息；  一个BpBinder可以注册多个死亡回调   创建JavaDeathRecipient: 继承于IBinder::DeathRecipient  linkToDeath status_t BpBinder::linkToDeath( const sp\u0026lt;DeathRecipient\u0026gt;\u0026amp; recipient, void* cookie, uint32_t flags) { IPCThreadState* self = IPCThreadState::self(); self-\u0026gt;requestDeathNotification(mHandle, this); self-\u0026gt;flushCommands(); } requestDeathNotification status_t IPCThreadState::requestDeathNotification(int32_t handle, BpBinder* proxy) { mOut.writeInt32(BC_REQUEST_DEATH_NOTIFICATION); mOut.writeInt32((int32_t)handle); mOut.writePointer((uintptr_t)proxy); return NO_ERROR; } flushCommands void IPCThreadState::flushCommands() { if (mProcess-\u0026gt;mDriverFD \u0026lt;= 0) return; talkWithDriver(false); } binder_ioctl_write_read static int binder_ioctl_write_read(struct file *filp, unsigned int cmd, unsigned long arg, struct binder_thread *thread) { int ret = 0; struct binder_proc *proc = filp-\u0026gt;private_data; void __user *ubuf = (void __user *)arg; struct binder_write_read bwr; if (copy_from_user(\u0026amp;bwr, ubuf, sizeof(bwr))) { //把用户空间数据ubuf拷贝到bwr  ret = -EFAULT; goto out; } if (bwr.write_size \u0026gt; 0) { //此时写缓存有数据【见小节3.2】  ret = binder_thread_write(proc, thread, bwr.write_buffer, bwr.write_size, \u0026amp;bwr.write_consumed); ... } if (bwr.read_size \u0026gt; 0) { //此时读缓存没有数据  ... } if (copy_to_user(ubuf, \u0026amp;bwr, sizeof(bwr))) { //将内核数据bwr拷贝到用户空间ubuf  ret = -EFAULT; goto out; } out: return ret; } binder_thread_write static int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed) { uint32_t cmd; //proc, thread都是指当前发起端进程的信息  while (ptr \u0026lt; end \u0026amp;\u0026amp; thread-\u0026gt;return_error == BR_OK) { get_user(cmd, (uint32_t __user *)ptr); //获取BC_REQUEST_DEATH_NOTIFICATION  ptr += sizeof(uint32_t); switch (cmd) { case BC_REQUEST_DEATH_NOTIFICATION:{ //注册死亡通知  uint32_t target; void __user *cookie; struct binder_ref *ref; struct binder_ref_death *death; get_user(target, (uint32_t __user *)ptr); //获取target  ptr += sizeof(uint32_t); get_user(cookie, (void __user * __user *)ptr); //获取BpBinder  ptr += sizeof(void *); ref = binder_get_ref(proc, target); //拿到目标服务的binder_ref  if (cmd == BC_REQUEST_DEATH_NOTIFICATION) { //native Bp可注册多个，但Kernel只允许注册一个死亡通知  if (ref-\u0026gt;death) { break; } death = kzalloc(sizeof(*death), GFP_KERNEL); INIT_LIST_HEAD(\u0026amp;death-\u0026gt;work.entry); death-\u0026gt;cookie = cookie; //BpBinder指针  ref-\u0026gt;death = death;//将death注册到binder_ref中,main  //当目标binder服务所在进程已死,则直接发送死亡通知。这是非常规情况  if (ref-\u0026gt;node-\u0026gt;proc == NULL) { ref-\u0026gt;death-\u0026gt;work.type = BINDER_WORK_DEAD_BINDER; //当前线程为binder线程,则直接添加到当前线程的todo队列.  if (thread-\u0026gt;looper \u0026amp; (BINDER_LOOPER_STATE_REGISTERED | BINDER_LOOPER_STATE_ENTERED)) { list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;thread-\u0026gt;todo); } else { list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;proc-\u0026gt;todo); wake_up_interruptible(\u0026amp;proc-\u0026gt;wait); } } } else { ... } 在处理BC_REQUEST_DEATH_NOTIFICATION过程，正好遇到对端目标binder服务所在进程已死的情况， 向todo队列增加BINDER_WORK_DEAD_BINDER事务，直接发送死亡通知，但这属于非常规情况。\n更常见的场景是binder服务所在进程死亡后,会调用binder_release方法, 然后调用binder_node_release.这个过程便会发出死亡通知的回调.\n触发死亡通知 当Binder服务所在进程死亡后，会释放进程相关的资源，Binder也是一种资源。 binder_open打开binder驱动/dev/binder，这是字符设备，获取文件描述符。在进程结束的时候会有一个关闭文件系统的过程中会调用驱动close方法，该方法相对应的是release()方法。当binder的fd被释放后，此处调用相应的方法是binder_release().\n但并不是每个close系统调用都会触发调用release()方法. 只有真正释放设备数据结构才调用release(),内核维持一个文件结构被使用多少次的计数，即便是应用程序没有明显地关闭它打开的文件也适用: 内核在进程exit()时会释放所有内存和关闭相应的文件资源, 通过使用close系统调用最终也会release binder.\n触发和处理死亡通知图解 graph TB subgraph binder_init时,调用create_singlethread_workqueue,创建了名叫binder的workqueue,是kernel提供的一种实现简单而有效的内核线程机制,可延迟执行任务 queue_work end subgraph 释放binder_thread,binder_node,binder_ref,binder_work,binder_buf. __free_page binder_deferred_release end subgraph 遍历该binder_node所有binder_ref,存在binder死亡通知则向binder_ref所在进程的todo队列添加BINDER_WORK_DEAD_BINDER事务并唤醒处于proc-\u0026gt;wait的binder线程,执行binder_thread_read binder_node_release end subgraph 从thread或process的todo队列拿出前面放入的binder_work,此时type为BINDER_WORK_DEAD_BINDER,写入death-\u0026gt;cookie也就是BpBinder,将命令BR_DEAD_BINDER写到用户空间 binder_thread_read end subgraph mObituaries的每个元素调用其recipient-\u0026gt;binderDied BpBinder::sendObituary end binder_fops--\u0026gt;binder_relase(\u0026quot;.release = binder_release\u0026quot;)--\u0026gt;|向工作队列添加binder_deferred_work|queue_work(\u0026quot;queue_work(binder_deferred_workqueue, \u0026amp;binder_deferred_work);\u0026quot;) --\u0026gt;binder_deferred_func--\u0026gt;binder_deferred_release--\u0026gt;binder_node_release--\u0026gt;binder_thread_read--\u0026gt;IPCThreadState::executeCommand--\u0026gt;|case BR_DEAD_BINDER:mIn.readPointer得到BpBinder*|BpBinder::sendObituary [-\u0026gt; binder.c]\nbinder_fops static const struct file_operations binder_fops = { .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .compat_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release, //对应于release的方法 }; binder_release static int binder_release(struct inode *nodp, struct file *filp) { struct binder_proc *proc = filp-\u0026gt;private_data; debugfs_remove(proc-\u0026gt;debugfs_entry); binder_defer_work(proc, BINDER_DEFERRED_RELEASE); return 0; } binder_defer_work static void binder_defer_work(struct binder_proc *proc, enum binder_deferred_state defer) { mutex_lock(\u0026amp;binder_deferred_lock); //获取锁  //添加BINDER_DEFERRED_RELEASE  proc-\u0026gt;deferred_work |= defer; if (hlist_unhashed(\u0026amp;proc-\u0026gt;deferred_work_node)) { hlist_add_head(\u0026amp;proc-\u0026gt;deferred_work_node, \u0026amp;binder_deferred_list); //向工作队列添加binder_deferred_work [见小节4.4]  queue_work(binder_deferred_workqueue, \u0026amp;binder_deferred_work); } mutex_unlock(\u0026amp;binder_deferred_lock); //释放锁 } queue_work //全局工作队列 static struct workqueue_struct *binder_deferred_workqueue; static int __init binder_init(void) { int ret; //创建了名叫“binder”的工作队列  binder_deferred_workqueue = create_singlethread_workqueue(\u0026#34;binder\u0026#34;); if (!binder_deferred_workqueue) return -ENOMEM; ... } device_initcall(binder_init); 关于binder_deferred_work的定义：\nstatic DECLARE_WORK(binder_deferred_work, binder_deferred_func); 在Binder设备驱动初始化的过程执行binder_init()方法中，调用 create_singlethread_workqueue(“binder”)，创建了名叫“binder”的工作队列(workqueue)。 workqueue是kernel提供的一种实现简单而有效的内核线程机制，可延迟执行任务。\n此处binder_deferred_work的func为binder_deferred_func，接下来看该方法。\nbinder_deferred_func static void binder_deferred_func(struct work_struct *work) { struct binder_proc *proc; struct files_struct *files; int defer; do { mutex_lock(\u0026amp;binder_main_lock); //获取binder_main_lock  mutex_lock(\u0026amp;binder_deferred_lock); preempt_disable(); //禁止CPU抢占  if (!hlist_empty(\u0026amp;binder_deferred_list)) { proc = hlist_entry(binder_deferred_list.first, struct binder_proc, deferred_work_node); hlist_del_init(\u0026amp;proc-\u0026gt;deferred_work_node); defer = proc-\u0026gt;deferred_work; proc-\u0026gt;deferred_work = 0; } else { proc = NULL; defer = 0; } mutex_unlock(\u0026amp;binder_deferred_lock); files = NULL; if (defer \u0026amp; BINDER_DEFERRED_PUT_FILES) { files = proc-\u0026gt;files; if (files) proc-\u0026gt;files = NULL; } if (defer \u0026amp; BINDER_DEFERRED_FLUSH) binder_deferred_flush(proc); if (defer \u0026amp; BINDER_DEFERRED_RELEASE) binder_deferred_release(proc); //[见小节4.6]  mutex_unlock(\u0026amp;binder_main_lock); //释放锁  preempt_enable_no_resched(); if (files) put_files_struct(files); } while (proc); } binder_deferred_release 此处proc是来自Bn端的binder_proc\nstatic void binder_deferred_release(struct binder_proc *proc) { struct binder_transaction *t; struct rb_node *n; int threads, nodes, incoming_refs, outgoing_refs, buffers, active_transactions, page_count; hlist_del(\u0026amp;proc-\u0026gt;proc_node); //删除proc_node节点  if (binder_context_mgr_node \u0026amp;\u0026amp; binder_context_mgr_node-\u0026gt;proc == proc) { binder_context_mgr_node = NULL; } //释放binder_thread[见小节4.6.1]  threads = 0; active_transactions = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;threads))) { struct binder_thread *thread; thread = rb_entry(n, struct binder_thread, rb_node); threads++; active_transactions += binder_free_thread(proc, thread); } //释放binder_node [见小节4.6.2]  nodes = 0; incoming_refs = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;nodes))) { struct binder_node *node; node = rb_entry(n, struct binder_node, rb_node); nodes++; rb_erase(\u0026amp;node-\u0026gt;rb_node, \u0026amp;proc-\u0026gt;nodes); incoming_refs = binder_node_release(node, incoming_refs);//key  } //释放binder_ref [见小节4.6.3]  outgoing_refs = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;refs_by_desc))) { struct binder_ref *ref; ref = rb_entry(n, struct binder_ref, rb_node_desc); outgoing_refs++; binder_delete_ref(ref); } //释放binder_work [见小节4.6.4]  binder_release_work(\u0026amp;proc-\u0026gt;todo); binder_release_work(\u0026amp;proc-\u0026gt;delivered_death); buffers = 0; while ((n = rb_first(\u0026amp;proc-\u0026gt;allocated_buffers))) { struct binder_buffer *buffer; buffer = rb_entry(n, struct binder_buffer, rb_node); t = buffer-\u0026gt;transaction; if (t) { t-\u0026gt;buffer = NULL; buffer-\u0026gt;transaction = NULL; } //释放binder_buf [见小节4.6.5]  binder_free_buf(proc, buffer); buffers++; } binder_stats_deleted(BINDER_STAT_PROC); page_count = 0; if (proc-\u0026gt;pages) { int i; for (i = 0; i \u0026lt; proc-\u0026gt;buffer_size / PAGE_SIZE; i++) { void *page_addr; if (!proc-\u0026gt;pages[i]) continue; page_addr = proc-\u0026gt;buffer + i * PAGE_SIZE; unmap_kernel_range((unsigned long)page_addr, PAGE_SIZE); __free_page(proc-\u0026gt;pages[i]); page_count++; } kfree(proc-\u0026gt;pages); vfree(proc-\u0026gt;buffer); } put_task_struct(proc-\u0026gt;tsk); kfree(proc); } binder_deferred_release的主要工作有：\n binder_free_thread： proc-\u0026gt;threads所有线程  binder_send_failed_reply(send_reply, BR_DEAD_REPLY)：将发起方线程的return_error值设置为BR_DEAD_REPLY，让其直接返回；   binder_node_release: proc-\u0026gt;nodes所有节点  binder_release_work(\u0026amp;node-\u0026gt;async_todo) node-\u0026gt;refs的所有死亡回调   binder_delete_ref: proc-\u0026gt;refs_by_desc所有引用  清除引用   binder_release_work: proc-\u0026gt;todo, proc-\u0026gt;delivered_death  binder_send_failed_reply(t, BR_DEAD_REPLY)   binder_free_buf: proc-\u0026gt;allocated_buffers所有已分配buffer  释放已分配的buffer   __free_page: proc-\u0026gt;pages所有物理内存页  static int binder_node_release(struct binder_node *node, int refs) { struct binder_ref *ref; int death = 0; list_del_init(\u0026amp;node-\u0026gt;work.entry); //[见小节4.6.4]  binder_release_work(\u0026amp;node-\u0026gt;async_todo); if (hlist_empty(\u0026amp;node-\u0026gt;refs)) { kfree(node); //引用为空，则直接删除节点  binder_stats_deleted(BINDER_STAT_NODE); return refs; } node-\u0026gt;proc = NULL; node-\u0026gt;local_strong_refs = 0; node-\u0026gt;local_weak_refs = 0; hlist_add_head(\u0026amp;node-\u0026gt;dead_node, \u0026amp;binder_dead_nodes); hlist_for_each_entry(ref, \u0026amp;node-\u0026gt;refs, node_entry) { refs++; if (!ref-\u0026gt;death) continue; death++; if (list_empty(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry)) { //添加BINDER_WORK_DEAD_BINDER事务到todo队列 [见小节5.1]  ref-\u0026gt;death-\u0026gt;work.type = BINDER_WORK_DEAD_BINDER; list_add_tail(\u0026amp;ref-\u0026gt;death-\u0026gt;work.entry, \u0026amp;ref-\u0026gt;proc-\u0026gt;todo); wake_up_interruptible(\u0026amp;ref-\u0026gt;proc-\u0026gt;wait); } } return refs; } 该方法会遍历该binder_node所有的binder_ref, 当存在binder死亡通知，则向相应的binder_ref 所在进程的todo队列添加BINDER_WORK_DEAD_BINDER事务并唤醒处于proc-\u0026gt;wait的binder线程,执行binder_thread_read\n处理死亡通知 binder_thread_read static int binder_thread_read(struct binder_proc *proc, struct binder_thread *thread, binder_uintptr_t binder_buffer, size_t size, binder_size_t *consumed, int non_block) ... //唤醒等待中的binder线程  wait_event_freezable_exclusive(proc-\u0026gt;wait, binder_has_proc_work(proc, thread)); binder_lock(__func__); //加锁  if (wait_for_proc_work) proc-\u0026gt;ready_threads--; //空闲的binder线程减1  thread-\u0026gt;looper \u0026amp;= ~BINDER_LOOPER_STATE_WAITING; while (1) { uint32_t cmd; struct binder_transaction_data tr; struct binder_work *w; struct binder_transaction *t = NULL; //从todo队列拿出前面放入的binder_work, 此时type为BINDER_WORK_DEAD_BINDER  if (!list_empty(\u0026amp;thread-\u0026gt;todo)) { w = list_first_entry(\u0026amp;thread-\u0026gt;todo, struct binder_work, entry); } else if (!list_empty(\u0026amp;proc-\u0026gt;todo) \u0026amp;\u0026amp; wait_for_proc_work) { w = list_first_entry(\u0026amp;proc-\u0026gt;todo, struct binder_work, entry); } switch (w-\u0026gt;type) { case BINDER_WORK_DEAD_BINDER: { struct binder_ref_death *death; uint32_t cmd; death = container_of(w, struct binder_ref_death, work); if (w-\u0026gt;type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) ... else cmd = BR_DEAD_BINDER; //进入此分支  put_user(cmd, (uint32_t __user *)ptr);//拷贝到用户空间[见小节5.2]  ptr += sizeof(uint32_t); //此处的cookie是前面传递的BpBinder  put_user(death-\u0026gt;cookie, (binder_uintptr_t __user *)ptr); ptr += sizeof(binder_uintptr_t); if (w-\u0026gt;type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) { ... } else //把该work加入到delivered_death队列  list_move(\u0026amp;w-\u0026gt;entry, \u0026amp;proc-\u0026gt;delivered_death); if (cmd == BR_DEAD_BINDER) goto done; } break; } } ... return 0; } 将命令BR_DEAD_BINDER写到用户空间，此时用户空间执行过程：\ngetAndExecuteCommand status_t IPCThreadState::getAndExecuteCommand() { status_t result; int32_t cmd; result = talkWithDriver(); //该Binder Driver进行交互  if (result \u0026gt;= NO_ERROR) { size_t IN = mIn.dataAvail(); if (IN \u0026lt; sizeof(int32_t)) return result; cmd = mIn.readInt32(); //读取命令  pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount++; pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); result = executeCommand(cmd); //【见小节5.3】  pthread_mutex_lock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); mProcess-\u0026gt;mExecutingThreadsCount--; pthread_cond_broadcast(\u0026amp;mProcess-\u0026gt;mThreadCountDecrement); pthread_mutex_unlock(\u0026amp;mProcess-\u0026gt;mThreadCountLock); set_sched_policy(mMyThreadId, SP_FOREGROUND); } return result; } executeCommand status_t IPCThreadState::executeCommand(int32_t cmd) { BBinder* obj; RefBase::weakref_type* refs; status_t result = NO_ERROR; switch ((uint32_t)cmd) { case BR_DEAD_BINDER: { BpBinder *proxy = (BpBinder*)mIn.readPointer(); proxy-\u0026gt;sendObituary(); //[见小节5.4]  mOut.writeInt32(BC_DEAD_BINDER_DONE); mOut.writePointer((uintptr_t)proxy); } break; ... } ... return result; } 同一个bp端即便注册多次死亡通知，但只会发送一次死亡回调。\nsendObituary void BpBinder::sendObituary() { mAlive = 0; if (mObitsSent) return; mLock.lock(); Vector\u0026lt;Obituary\u0026gt;* obits = mObituaries; if(obits != NULL) { IPCThreadState* self = IPCThreadState::self(); //清空死亡通知[见小节6.2]  self-\u0026gt;clearDeathNotification(mHandle, this); self-\u0026gt;flushCommands(); mObituaries = NULL; } mObitsSent = 1; mLock.unlock(); if (obits != NULL) { const size_t N = obits-\u0026gt;size(); for (size_t i=0; i\u0026lt;N; i++) { //发送死亡通知 [见小节5.5]  reportOneDeath(obits-\u0026gt;itemAt(i)); } delete obits; } } reportOneDeath void BpBinder::reportOneDeath(const Obituary\u0026amp; obit) { //将弱引用提升到sp  sp\u0026lt;DeathRecipient\u0026gt; recipient = obit.recipient.promote(); if (recipient == NULL) return; //回调死亡通知的方法  recipient-\u0026gt;binderDied(this); } 本文开头的实例传递的是AppDeathRecipient，那么回调如下方法。\nprivate final class AppDeathRecipient implements IBinder.DeathRecipient { ... public void binderDied() { synchronized(ActivityManagerService.this) { appDiedLocked(mApp, mPid, mAppThread, true); } } } 结论 对于Binder IPC进程都会打开/dev/binder文件，当进程异常退出时，Binder驱动会保证释放将要退出的进程中没有正常关闭的/dev/binder文件，实现机制是binder驱动通过调用/dev/binder文件所对应的release回调函数，执行清理工作，并且检查BBinder是否有注册死亡通知，当发现存在死亡通知时，那么就向其对应的BpBinder端发送死亡通知消息。\n死亡回调DeathRecipient只有Bp才能正确使用，因为DeathRecipient用于监控Bn端挂掉的情况， 如果Bn建立跟自己的死亡通知，自己进程都挂了，也就无法通知。\n每个BpBinder都有一个记录DeathRecipient列表的对象DeathRecipientList。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/binder/binder%E5%8E%9F%E7%90%86/",
	"title": "Binder原理",
	"tags": [],
	"description": "",
	"content": "写给 android 应用工程师的 binder 原理剖析\n架构设计分析（三）Android 9.0 Binder机制\n彻底理解Android Binder通信架构 Android 6.0\nBinder系列5—注册服务(addService)\nAndroid IPC: Part 2 - Binder and Service Manager Perspective\n深入理解Binder通信原理及面试问题\nBinder | 内存拷贝的本质和变迁\nLinux 背景知识 传统 IPC 通信原理 Binder IPC 原理 BinderProcedure flow struct binder_write_read transact total "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/bitmap/bitmap/",
	"title": "Bitmap",
	"tags": [],
	"description": "",
	"content": "Bitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/bitmap/",
	"title": "bitmap",
	"tags": [],
	"description": "",
	"content": "bitmap 探索总结bitmap知识\n Bitmap     BitmapSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/bitmap/bitmapsource/",
	"title": "BitmapSource",
	"tags": [],
	"description": "",
	"content": "类设计 NativeAllocationRegistry procedure ART reclaim NativeAllocationRegistry procedure(only object which will be reclaim(GC not reachable) would be enqueued)\ngraph TB ReferenceQueueDaemon.runInernal--\u0026gt;ReferenceQueue.enqueuePending ReferenceQueue.enqueuePending--\u0026gt;ReferenceQueue.enqueueLocked ReferenceQueue.enqueueLocked--\u0026gt;Cleaner.clean Cleaner.clean--\u0026gt;CleanerChunk.run CleanerChunk.run--\u0026gt;NativeAllocationRegistry.applyFreeFunction ImageDecoder decodeDrawable public static Drawable decodeDrawable(@NonNull Source src, @NonNull OnHeaderDecodedListener listener) throws IOException { return decodeDrawableImpl(src, listener); } decodeDrawableImpl private static Drawable decodeDrawableImpl(@NonNull Source src, @Nullable OnHeaderDecodedListener listener) throws IOException { ImageDecoder decoder = src.createImageDecoder() decoder.mSource = src; decoder.callHeaderDecoded(listener, src); Bitmap bm = decoder.decodeBitmapInternal(); return new BitmapDrawable(res, bm); } decodeBitmapInternal private Bitmap decodeBitmapInternal() throws IOException { checkState(); return nDecodeBitmap(mNativePtr, this, mPostProcessor != null, mDesiredWidth, mDesiredHeight, mCropRect, mMutable, mAllocator, mUnpremultipliedRequired, mConserveMemory, mDecodeAsAlphaMask, mDesiredColorSpace); } Source frameworks/base/core/jni/android/graphics/ImageDecoder.cpp\nImageDecoder.cpp ImageDecoder_nDecodeBitmap static jobject ImageDecoder_nDecodeBitmap(JNIEnv* env, jobject /*clazz*/, jlong nativePtr, jobject jdecoder, jboolean jpostProcess, jint desiredWidth, jint desiredHeight, jobject jsubset, jboolean requireMutable, jint allocator, jboolean requireUnpremul, jboolean preferRamOverQuality, jboolean asAlphaMask, jobject jcolorSpace) {\t...... SkBitmap bm; auto bitmapInfo = decodeInfo; if (asAlphaMask \u0026amp;\u0026amp; colorType == kGray_8_SkColorType) { bitmapInfo = bitmapInfo.makeColorType(kAlpha_8_SkColorType); } if (!bm.setInfo(bitmapInfo)) { doThrowIOE(env, \u0026#34;Failed to setInfo properly\u0026#34;); return nullptr; } sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap; // If we are going to scale or subset, we will create a new bitmap later on,  // so use the heap for the temporary.  // FIXME: Use scanline decoding on only a couple lines to save memory. b/70709380.  if (allocator == ImageDecoder::kSharedMemory_Allocator \u0026amp;\u0026amp; !scale \u0026amp;\u0026amp; !jsubset) { nativeBitmap = Bitmap::allocateAshmemBitmap(\u0026amp;bm); } else { nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;bm);//nativeBitmap和bm都被赋值完毕  } ...... return bitmap::createBitmap(env, nativeBitmap.release(), bitmapCreateFlags, ninePatchChunk, ninePatchInsets); } allocateheapbitmap\ncreateBitmap\nBitmap.java android/graphics/Bitmap.java\ncreateBitmap public static Bitmap createBitmap(@Nullable DisplayMetrics display, int width, int height, @NonNull Config config, boolean hasAlpha, @NonNull ColorSpace colorSpace) { bm = nativeCreate(null, 0, width, width, height, config.nativeInt, true, null, null); return bm; nativeCreate\nBitmapCons() /** * Private constructor that must received an already allocated native bitmap * int (pointer). */ // called from JNI Bitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { mWidth = width; mHeight = height; mIsMutable = isMutable; mRequestPremultiplied = requestPremultiplied; mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); } frameworks/base/core/jni/android/graphics/\nBitmap.cpp(graphics) gBitmapMethods nativeCreate \u0026ndash;\u0026gt; Bitmap_creator\nstatic const JNINativeMethod gBitmapMethods[] = { { \u0026#34;nativeCreate\u0026#34;, \u0026#34;([IIIIIIZ[FLandroid/graphics/ColorSpace$Rgb$TransferParameters;)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_creator }, { \u0026#34;nativeCopy\u0026#34;, \u0026#34;(JIZ)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copy }, { \u0026#34;nativeCopyAshmem\u0026#34;, \u0026#34;(J)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copyAshmem }, { \u0026#34;nativeCopyAshmemConfig\u0026#34;, \u0026#34;(JI)Landroid/graphics/Bitmap;\u0026#34;, (void*)Bitmap_copyAshmemConfig }, { \u0026#34;nativeGetNativeFinalizer\u0026#34;, \u0026#34;()J\u0026#34;, (void*)Bitmap_getNativeFinalizer }, { \u0026#34;nativeRecycle\u0026#34;, \u0026#34;(J)Z\u0026#34;, (void*)Bitmap_recycle }, { \u0026#34;nativeReconfigure\u0026#34;, \u0026#34;(JIIIZ)V\u0026#34;, (void*)Bitmap_reconfigure }, { \u0026#34;nativeCompress\u0026#34;, \u0026#34;(JIILjava/io/OutputStream;[B)Z\u0026#34;, (void*)Bitmap_compress }, { \u0026#34;nativeErase\u0026#34;, \u0026#34;(JI)V\u0026#34;, (void*)Bitmap_erase }, { \u0026#34;nativeRowBytes\u0026#34;, \u0026#34;(J)I\u0026#34;, (void*)Bitmap_rowBytes }, { \u0026#34;nativeGetPixel\u0026#34;, \u0026#34;(JII)I\u0026#34;, (void*)Bitmap_getPixel }, { \u0026#34;nativeGetPixels\u0026#34;, \u0026#34;(J[IIIIIII)V\u0026#34;, (void*)Bitmap_getPixels }, { \u0026#34;nativeSetPixel\u0026#34;, \u0026#34;(JIII)V\u0026#34;, (void*)Bitmap_setPixel }, { \u0026#34;nativeSetPixels\u0026#34;, \u0026#34;(J[IIIIIII)V\u0026#34;, (void*)Bitmap_setPixels }, { \u0026#34;nativeCopyPixelsToBuffer\u0026#34;, \u0026#34;(JLjava/nio/Buffer;)V\u0026#34;, (void*)Bitmap_copyPixelsToBuffer }, { \u0026#34;nativeCopyPixelsFromBuffer\u0026#34;, \u0026#34;(JLjava/nio/Buffer;)V\u0026#34;, (void*)Bitmap_copyPixelsFromBuffer }, }; Bitmap_creator static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkBitmap bitmap; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;bitmap); if (!nativeBitmap) { ALOGE(\u0026#34;OOM allocating Bitmap with dimensions %i x %i\u0026#34;, width, height); doThrowOOME(env); return NULL; } if (jColors != NULL) { GraphicsJNI::SetPixels(env, jColors, offset, stride, 0, 0, width, height, bitmap); } return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); allocateheapbitmap\ncreateBitmap\nbitmap::createBitmap jobject createBitmap(JNIEnv* env, Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { bool isMutable = bitmapCreateFlags \u0026amp; kBitmapCreateFlag_Mutable; bool isPremultiplied = bitmapCreateFlags \u0026amp; kBitmapCreateFlag_Premultiplied; // The caller needs to have already set the alpha type properly, so the  // native SkBitmap stays in sync with the Java Bitmap.  BitmapWrapper* bitmapWrapper = new BitmapWrapper(bitmap); jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmapWrapper), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); return obj; } bitmapcons\nBitmap_getNativeFinalizer static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } Bitmap_destruct static void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } libcore/luni/src/main/java/libcore/util\nNativeAllocationRegistry.java /** * A NativeAllocationRegistry is used to associate native allocations with * Java objects and register them with the runtime. * There are two primary benefits of registering native allocations associated * with Java objects: * \u0026lt;ol\u0026gt; * \u0026lt;li\u0026gt;The runtime will account for the native allocations when scheduling * garbage collection to run.\u0026lt;/li\u0026gt; * \u0026lt;li\u0026gt;The runtime will arrange for the native allocation to be automatically * freed by a user-supplied function when the associated Java object becomes * unreachable.\u0026lt;/li\u0026gt; * \u0026lt;/ol\u0026gt; * A separate NativeAllocationRegistry should be instantiated for each kind * of native allocation, where the kind of a native allocation consists of the * native function used to free the allocation and the estimated size of the * allocation. Once a NativeAllocationRegistry is instantiated, it can be * used to register any number of native allocations of that kind. * @hide */ public class NativeAllocationRegistry { public NativeAllocationRegistry(ClassLoader classLoader, long freeFunction, long size) { this.classLoader = classLoader; this.freeFunction = freeFunction; this.size = size; } } registerNativeAllocation /** * Registers a new native allocation and associated Java object with the * runtime. * This NativeAllocationRegistry\u0026#39;s \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; will * automatically be called with \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; as its sole * argument when \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable. If you * maintain copies of \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; outside * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt;, you must not access these after * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable, because they may be dangling * pointers. * \u0026lt;p\u0026gt; * The returned Runnable can be used to free the native allocation before * \u0026lt;code\u0026gt;referent\u0026lt;/code\u0026gt; becomes unreachable. The runnable will have no * effect if the native allocation has already been freed by the runtime * or by using the runnable. * \u0026lt;p\u0026gt; * WARNING: This unconditionally takes ownership, i.e. deallocation * responsibility of nativePtr. nativePtr will be DEALLOCATED IMMEDIATELY * if the registration attempt throws an exception (other than one reporting * a programming error). * * @param referent Non-null java object to associate the native allocation with * @param nativePtr Non-zero address of the native allocation * @return runnable to explicitly free native allocation * @throws IllegalArgumentException if either referent or nativePtr is null. * @throws OutOfMemoryError if there is not enough space on the Java heap * in which to register the allocation. In this * case, \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; will be * called with \u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt; as its * argument before the OutOfMemoryError is * thrown. */ public Runnable registerNativeAllocation(Object referent, long nativePtr) { if (referent == null) { throw new IllegalArgumentException(\u0026#34;referent is null\u0026#34;); } if (nativePtr == 0) { throw new IllegalArgumentException(\u0026#34;nativePtr is null\u0026#34;); } CleanerThunk thunk; CleanerRunner result; try { thunk = new CleanerThunk(); Cleaner cleaner = Cleaner.create(referent, thunk); result = new CleanerRunner(cleaner); registerNativeAllocation(this.size); } catch (VirtualMachineError vme /* probably OutOfMemoryError */) { applyFreeFunction(freeFunction, nativePtr); throw vme; } // Other exceptions are impossible.  // Enable the cleaner only after we can no longer throw anything, including OOME.  thunk.setNativePtr(nativePtr); return result; } CleanerThunk private class CleanerThunk implements Runnable { private long nativePtr; public CleanerThunk() { this.nativePtr = 0; } public void run() { if (nativePtr != 0) { applyFreeFunction(freeFunction, nativePtr); registerNativeFree(size); } } public void setNativePtr(long nativePtr) { this.nativePtr = nativePtr; } } applyFreeFunction /** * Calls \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt;(\u0026lt;code\u0026gt;nativePtr\u0026lt;/code\u0026gt;). * Provided as a convenience in the case where you wish to manually free a * native allocation using a \u0026lt;code\u0026gt;freeFunction\u0026lt;/code\u0026gt; without using a * NativeAllocationRegistry. */ public static native void applyFreeFunction(long freeFunction, long nativePtr); registerNativeFree private static void registerNativeFree(long size) { VMRuntime.getRuntime().registerNativeFree((int)Math.min(size, Integer.MAX_VALUE)); } registerNativeAllocation private static void registerNativeAllocation(long size) { VMRuntime.getRuntime().registerNativeAllocation((int)Math.min(size,Integer.MAX_VALUE)); } CleanerRunner private static class CleanerRunner implements Runnable { private final Cleaner cleaner; public CleanerRunner(Cleaner cleaner) { this.cleaner = cleaner; } public void run() { cleaner.clean(); } } libcore/ojluni/src/main/java/sun/misc/Cleaner.java\nCleaner create public class Cleaner extends PhantomReference\u0026lt;Object\u0026gt; { /** * Creates a new cleaner. * * @param ob the referent object to be cleaned * @param thunk * The cleanup code to be run when the cleaner is invoked. The * cleanup code is run directly from the reference-handler thread, * so it should be as simple and straightforward as possible. * * @return The new cleaner */ public static Cleaner create(Object ob, Runnable thunk) { if (thunk == null) return null; return add(new Cleaner(ob, thunk)); } add private static synchronized Cleaner add(Cleaner cl) { if (first != null) { cl.next = first; first.prev = cl;//双向链表，插入表头  } first = cl; return cl; }\tclean /** * Runs this cleaner, if it has not been run before. */ public void clean() { if (!remove(this)) return; try { thunk.run(); } } libcore/libart/src/main/java/dalvik/system/\nVMRuntime.java registerNativeAllocation /** * Registers a native allocation so that the heap knows about it and performs GC as required. * If the number of native allocated bytes exceeds the native allocation watermark, the * function requests a concurrent GC. If the native bytes allocated exceeds a second higher * watermark, it is determined that the application is registering native allocations at an * unusually high rate and a GC is performed inside of the function to prevent memory usage * from excessively increasing. Memory allocated via system malloc() should not be included * in this count. The argument must be the same as that later passed to registerNativeFree(), * but may otherwise be approximate. */ @UnsupportedAppUsage @libcore.api.CorePlatformApi public native void registerNativeAllocation(long bytes); frameworks/base/libs/hwui/hwui/Bitmap.cpp\nBitmap.cpp(hwui) class ANDROID_API Bitmap : public SkPixelRef {} AllocPixelRef function typedef sk_sp\u0026lt;Bitmap\u0026gt; (*AllocPixelRef)(size_t allocSize, const SkImageInfo\u0026amp; info, size_t rowBytes); allocateHeapBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateHeapBitmap(SkBitmap* bitmap) { return allocateBitmap(bitmap, \u0026amp;android::allocateHeapBitmap); } allocateBitmap static sk_sp\u0026lt;Bitmap\u0026gt; allocateBitmap(SkBitmap* bitmap, AllocPixelRef alloc) { const SkImageInfo\u0026amp; info = bitmap-\u0026gt;info(); // we must respect the rowBytes value already set on the bitmap instead of  // attempting to compute our own.  const size_t rowBytes = bitmap-\u0026gt;rowBytes(); if (!computeAllocationSize(rowBytes, bitmap-\u0026gt;height(), \u0026amp;size)) { return nullptr; } auto wrapper = alloc(size, info, rowBytes); if (wrapper) { wrapper-\u0026gt;getSkBitmap(bitmap); } return wrapper; alloc\nandroid::allocateHeapBitmap static sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { void* addr = calloc(size, 1);//申请bitmap内存空间,单位bytes，默认初始化为0  if (!addr) { return nullptr; } return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } getSkBitmap void Bitmap::getSkBitmap(SkBitmap* outBitmap) { outBitmap-\u0026gt;setHasHardwareMipMap(mHasHardwareMipMap); if (isHardware()) { if (uirenderer::Properties::isSkiaEnabled()) { outBitmap-\u0026gt;allocPixels(SkImageInfo::Make(info().width(), info().height(), info().colorType(), info().alphaType(), nullptr)); } else { outBitmap-\u0026gt;allocPixels(info()); } uirenderer::renderthread::RenderProxy::copyGraphicBufferInto(graphicBuffer(), outBitmap); if (mInfo.colorSpace()) { sk_sp\u0026lt;SkPixelRef\u0026gt; pixelRef = sk_ref_sp(outBitmap-\u0026gt;pixelRef()); outBitmap-\u0026gt;setInfo(mInfo); outBitmap-\u0026gt;setPixelRef(std::move(pixelRef), 0, 0); } return; } outBitmap-\u0026gt;setInfo(mInfo, rowBytes()); outBitmap-\u0026gt;setPixelRef(sk_ref_sp(this), 0, 0); } setinfo\nsetpixelref\nallocateAshmemBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateAshmemBitmap(SkBitmap* bitmap) { return allocateBitmap(bitmap, \u0026amp;Bitmap::allocateAshmemBitmap); } allocatebitmap\nallocateAshmemBitmap sk_sp\u0026lt;Bitmap\u0026gt; Bitmap::allocateAshmemBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { // Create new ashmem region with read/write priv  int fd = ashmem_create_region(\u0026#34;bitmap\u0026#34;, size); if (fd \u0026lt; 0) { return nullptr; } void* addr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if (addr == MAP_FAILED) { close(fd); return nullptr; } if (ashmem_set_prot_region(fd, PROT_READ) \u0026lt; 0) { munmap(addr, size); close(fd); return nullptr; } return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, fd, size, info, rowBytes)); } external/skia/src/core/\nSkBitmap.cpp setInfo bool SkBitmap::setInfo(const SkImageInfo\u0026amp; info, size_t rowBytes) { fPixelRef = nullptr; // Free pixels.  fPixmap.reset(info.makeAlphaType(newAT), nullptr, SkToU32(rowBytes)); return true; makealphatype\nsetPixelRef void SkBitmap::setPixelRef(sk_sp\u0026lt;SkPixelRef\u0026gt; pr, int dx, int dy) { fPixelRef = kUnknown_SkColorType != this-\u0026gt;colorType() ? std::move(pr) : nullptr; void* p = nullptr; size_t rowBytes = this-\u0026gt;rowBytes(); // ignore dx,dy if there is no pixelref  if (fPixelRef) { rowBytes = fPixelRef-\u0026gt;rowBytes(); // TODO(reed): Enforce that PixelRefs must have non-null pixels.  p = fPixelRef-\u0026gt;pixels(); if (p) { p = (char*)p + dy * rowBytes + dx * this-\u0026gt;bytesPerPixel(); } } SkPixmapPriv::ResetPixmapKeepInfo(\u0026amp;fPixmap, p, rowBytes); pixels\nexternal/skia/include/core/SkPixelRef.h\nSkPixelRef pixels void* pixels() const { return fPixels; } size_t rowBytes() const { return fRowBytes; } external/skia/include/core/\nSkImageInfo.h makeAlphaType SkImageInfo makeAlphaType(SkAlphaType newAlphaType) const { return Make(fWidth, fHeight, fColorType, newAlphaType, fColorSpace); } external/skia/src/core/\nSkPixmap reset void SkPixmap::reset(const SkImageInfo\u0026amp; info, const void* addr, size_t rowBytes) { fPixels = addr; fRowBytes = rowBytes; fInfo = info; } "
},
{
	"uri": "https://huanle19891345.github.io/en/java/blockingqueue/",
	"title": "BlockingQueue",
	"tags": [],
	"description": "",
	"content": "https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/BlockingQueue.html\nBlockingQueue methods come in four forms, with different ways of handling operations that cannot be satisfied immediately, but may be satisfied at some point in the future:\n one throws an exception, the second returns a special value (either null or false, depending on the operation), the third blocks the current thread indefinitely until the operation can succeed, and the fourth blocks for only a given maximum time limit before giving up. These methods are summarized in the following table:      Throws exception Special value Blocks Times out     Insert add(e) offer(e) put(e) [offer(e, time, unit)](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/BlockingQueue.html#offer(E, long, java.util.concurrent.TimeUnit))   Remove remove() [poll()](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/BlockingQueue.html#poll(long, java.util.concurrent.TimeUnit)) take() [poll(time, unit)](https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/BlockingQueue.html#poll(long, java.util.concurrent.TimeUnit))   Examine element() peek() not applicable not applicable    "
},
{
	"uri": "https://huanle19891345.github.io/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/compose/compose/",
	"title": "Compose",
	"tags": [],
	"description": "",
	"content": "Jetpack Compose Beta 版现已发布！\nhttps://developer.android.google.cn/jetpack/compose/documentation\nhttps://github.com/android/compose-samples\n深入详解 Jetpack Compose | 实现原理\njetpack compse原理解析\nView 嵌套太深会卡？来用 Jetpack Compose，随便套\nState In Compose @Composable fun HelloScreen() { var name by rememberSaveable { mutableStateOf(\u0026#34;\u0026#34;) } HelloContent(name = name, onNameChange = { name = it }) } @Composable fun HelloContent(name: String, onNameChange: (String) -\u0026gt; Unit) { Column(modifier = Modifier.padding(16.dp)) { Text( text = \u0026#34;Hello, $name\u0026#34;, modifier = Modifier.padding(bottom = 8.dp), style = MaterialTheme.typography.h5 ) OutlinedTextField( value = name, onValueChange = { onNameChange(it) }, label = { Text(\u0026#34;Name\u0026#34;) } ) } } Compose和DataBinding State对应 graph TB subgraph DataBinding ViewAttribute--\u0026gt;|event|BackData BackData--\u0026gt;|state|ViewAttribute end subgraph Compose HelloContent--\u0026gt;|event|HelloScreen HelloScreen(\u0026quot;HelloScreen(stateful)\u0026quot;)--\u0026gt;|state|HelloContent(\u0026quot;HelloContent(stateless)\u0026quot;) end Key Point: When hoisting state, there are three rules to help you figure out where state should go:\n State should be hoisted to at least the lowest common parent of all composables that use the state (read). State should be hoisted to at least the highest level it may be changed (write). If two states change in response to the same events they should be hoisted together.  You can hoist state higher than these rules require, but underhoisting state will make it difficult or impossible to follow unidirectional data flow.\ninterface MutableState\u0026lt;T\u0026gt; : State\u0026lt;T\u0026gt; { override var value: T } Any changes to value will schedule recomposition of any composable functions that read value. Compose will automatically recompose from reading State objects.\nIf you use another observable type such as LiveData in Compose, you should convert it to State\u0026lt;T\u0026gt; before reading it in a composable using a composable extension function like LiveData\u0026lt;T\u0026gt;.observeAsState().\nState should be modified by events in a composable. If you modify state when running a composable instead of in an event, this is a side-effect of the composable, which should be avoided. For more information about side-effects in Jetpack Compose, see Thinking in Compose.\nA Composition can only be produced by an initial composition and updated by recomposition. The only way to modify a Composition is through recomposition.\nIf during a recomposition a composable calls different composables than it did during the previous composition, Compose will identify which composables were called or not called and for the composables that were called in both compositions, Compose will avoid recomposing them if their inputs haven\u0026rsquo;t changed.\nKey Point: Use the key composable to help Compose identify composable instances in Composition. It\u0026rsquo;s important when multiple composables are called from the same call site and contain side-effects or internal state.\nSkipping if the inputs haven\u0026rsquo;t changed If a composable is already in the Composition, it can skip recomposition if all the inputs are stable and haven\u0026rsquo;t changed.\nA stable type must comply with the following contract:\n The result of equals for two instances will forever be the same for the same two instances. If a public property of the type changes, Composition will be notified. All public property types are also stable.  There are some important common types that fall into this contract that the compose compiler will treat as @Stable, even though they are not explicitly marked as @Stable.\n All primitive value types: Boolean, Int, Long, Float, Char, etc. Strings All Function types (lambdas)  All of these types are able to follow the contract of @Stable because they are immutable. Since immutable types never change, they never have to notify Composition of the change, so it is much easier to follow this contract.\nNote: All deeply immutable types can safely be considered stable types.\nOne notable type that is stable but is mutable is Compose’s MutableState type. If a value is held in a MutableState, the state object overall is considered to be stable as Compose will be notified of any changes to the .value property of State.\nWhen all types passed as parameters to a composable are stable, the parameter values are compared for equality based on the composable position in the UI tree. Recomposition is skipped if all the values are unchanged since the previous call.\nKey Point: Compose skips the recomposition of a composable if all the inputs are stable and haven\u0026rsquo;t changed. The comparison uses the equals method.\ngraph LR Coroutine--\u0026gt;|InsideComposable|LaunchedEffect Coroutine--\u0026gt;|OutsideComposable|rememberCoroutineScope ViewModels in Compose If you use the Architecture Components ViewModel library, you can access a ViewModel from any composable by calling the [viewModel()](https://developer.android.google.cn/reference/kotlin/androidx/compose/ui/viewinterop/package-summary#viewModel(kotlin.String, androidx.lifecycle.ViewModelProvider.Factory)) function, as explained in the Compose integration with common libraries documentation.\nWhen adopting Compose, be careful about using the same ViewModel type in different composables as ViewModel elements follow View-lifecycle scopes. The scope will be either the host activity, fragment or the navigation graph if the Navigation library is used.\nNote: The same instance of a ViewModel type will be used in all composables unless the composable is a destination of the navigation graph or different activity or fragment instances.\nUnidirectional data flow in Jetpack Compose Key Points:\nmutableStateOf(value) creates a MutableState, which is an observable type in Compose. Any changes to its value will schedule recomposition of any composable functions that read that value.\nremember stores objects in the composition, and forgets the object when the composable that called remember is removed from the composition.\nrememberSaveable retains the state across configuration changes by saving it in a Bundle.\nEvents in your architecture Prefer passing immutable values for state and event handler lambdas. This approach has the following benefits:\n You improve reusability. You ensure that your UI doesn\u0026rsquo;t change the value of the state directly. You avoid concurrency issues because you make sure that the state isn\u0026rsquo;t mutated from another thread. Often, you reduce code complexity.  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/compose/",
	"title": "compose",
	"tags": [],
	"description": "",
	"content": "compose 探索总结compose知识\n Compose     ComposeSource     LayoutNode     ReComposition     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/compose/composesource/",
	"title": "ComposeSource",
	"tags": [],
	"description": "",
	"content": "View层次结构 graph TB contentFrameLayout--\u0026gt;ComposeView--\u0026gt;AndroidComposeView--\u0026gt;ViewLayerContainer ViewLayerContainer--\u0026gt;ViewLayer1 ViewLayerContainer--\u0026gt;ViewLayer2 ViewLayerContainer--\u0026gt;ViewLayer3 ViewLayerContainer--\u0026gt;ViewLayer... View类继承结构 classDiagram class ComposeView { -val content } class AndroidComposeView { +onMeasure(widthMeasureSpec: Int, heightMeasureSpec: Int) } class OwnedLayer { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +resize(size: IntSize) +drawLayer(canvas: Canvas) +updateDisplayList() +invalidate() } class GraphicLayerInfo { \u0026lt;\u0026lt;interface\u0026gt; +layerId: Long } View\u0026lt;|--ViewGroup ViewGroup\u0026lt;|--AbstractComposeView AbstractComposeView\u0026lt;|--ComposeView ViewGroup\u0026lt;|--AndroidComposeView ViewGroup\u0026lt;|--ViewLayerContainer View\u0026lt;|--ViewLayer OwnedLayer\u0026lt;|--ViewLayer OwnedLayer\u0026lt;|--RenderNodeLayer GraphicLayerInfo\u0026lt;|--OwnedLayer 图解 sequenceDiagram ComposeView-\u0026gt;\u0026gt;ComposeView: onAttachedToWindow activate ComposeView ComposeView-\u0026gt;\u0026gt;ComposeView: ensureCompositionCreated activate ComposeView deactivate ComposeView ComposeView-\u0026gt;\u0026gt;ComposeView: setOnViewTreeOwnersAvailable{闭包} activate ComposeView Note right of ComposeView: AndroidComposeView.onAttachedToWindow后执行闭包 deactivate ComposeView AndroidComposeView-\u0026gt;\u0026gt;AndroidComposeView: onAttachedToWindow AndroidComposeView-\u0026gt;\u0026gt;CompositionImpl:setContent CompositionImpl-\u0026gt;\u0026gt;ComposerImpl: composeContent ComposerImpl-\u0026gt;\u0026gt;ComposableLambdaImpl: invoke ComposableLambdaImpl-\u0026gt;\u0026gt;ComposableLambdaImpl: c.startRestartGroup ComposableLambdaImpl-\u0026gt;\u0026gt;ComposableLambdaImpl: (_block as (c: Composer, changed: Int) -\u0026gt; Any?) ComposableLambdaImpl-\u0026gt;\u0026gt;ComposableLambdaImpl: c.endRestartGroup().updateScope ComposableLambdaImpl-\u0026gt;\u0026gt;ComposeView: Content() ComposeView-\u0026gt;\u0026gt;ComposeView:content.value?.invoke() Note right of ComposeView: Activity调用setContent设置下来的闭包 deactivate ComposeView setContent class MainActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) val appContainer = (application as JetnewsApplication).container setContent {//main  JetnewsApp(appContainer, navigationViewModel) } } } public fun ComponentActivity.setContent( parent: CompositionContext? = null, content: @Composable () -\u0026gt; Unit ) { val existingComposeView = window.decorView .findViewById\u0026lt;ViewGroup\u0026gt;(android.R.id.content) .getChildAt(0) as? ComposeView if (existingComposeView != null) with(existingComposeView) { setParentCompositionContext(parent) setContent(content) } else ComposeView(this).apply { // Set content and parent **before** setContentView  // to have ComposeView create the composition on attach  setParentCompositionContext(parent) setContent(content) setContentView(this, DefaultActivityContentLayoutParams) } } ComposeView //AbstractComposeView override fun onAttachedToWindow() { super.onAttachedToWindow() if (shouldCreateCompositionOnAttachedToWindow) { ensureCompositionCreated()//main  } } AbstractComposeView.ensureCompositionCreated abstract class AbstractComposeView @JvmOverloads constructor( context: Context, attrs: AttributeSet? = null, defStyleAttr: Int = 0 ) : ViewGroup(context, attrs, defStyleAttr) { @Suppress(\u0026#34;DEPRECATION\u0026#34;) // Still using ViewGroup.setContent for now private fun ensureCompositionCreated() { if (composition == null) { try { creatingComposition = true composition = setContent( parentContext ?: findViewTreeCompositionContext() ?: windowRecomposer ) { Content() } } finally { creatingComposition = false } } } internal fun ViewGroup.setContent( parent: CompositionContext, content: @Composable () -\u0026gt; Unit ): Composition { GlobalSnapshotManager.ensureStarted() val composeView = if (childCount \u0026gt; 0) { getChildAt(0) as? AndroidComposeView } else { removeAllViews(); null } ?: AndroidComposeView(context).also { addView(it.view, DefaultLayoutParams) } return doSetContent(composeView, parent, content)//main } @OptIn(InternalComposeApi::class) private fun doSetContent( owner: AndroidComposeView, parent: CompositionContext, content: @Composable () -\u0026gt; Unit ): Composition { if (inspectionWanted(owner)) { owner.setTag( R.id.inspection_slot_table_set, Collections.newSetFromMap(WeakHashMap\u0026lt;CompositionData, Boolean\u0026gt;()) ) enableDebugInspectorInfo() } val original = Composition(UiApplier(owner.root), parent) val wrapped = owner.view.getTag(R.id.wrapped_composition_tag) as? WrappedComposition ?: WrappedComposition(owner, original).also { owner.view.setTag(R.id.wrapped_composition_tag, it) } wrapped.setContent(content) return wrapped } //WrappedComposition @OptIn(InternalComposeApi::class) override fun setContent(content: @Composable () -\u0026gt; Unit) { owner.setOnViewTreeOwnersAvailable { ......//AndroidComposeView.onAttachedToWindow之后才会被执行闭包中的逻辑  } AndroidComposeView AndroidComposeView.onAttachedToWindow internal class AndroidComposeView(context: Context) : ViewGroup(context), Owner, ViewRootForTest, PositionCalculator { override fun onAttachedToWindow() { super.onAttachedToWindow() invalidateLayoutNodeMeasurement(root) invalidateLayers(root) ...... onViewTreeOwnersAvailable?.invoke(viewTreeOwners) WrappedComposition.setContent private class WrappedComposition( val owner: AndroidComposeView, val original: Composition ) : Composition, LifecycleEventObserver { @OptIn(InternalComposeApi::class) override fun setContent(content: @Composable () -\u0026gt; Unit) { owner.setOnViewTreeOwnersAvailable { if (!disposed) { val lifecycle = it.lifecycleOwner.lifecycle lastContent = content//important,为ensureCompositionCreated()时setContent时配置的闭包Content()  if (addedToLifecycle == null) { addedToLifecycle = lifecycle // this will call ON_CREATE synchronously if we already created  lifecycle.addObserver(this)//main  //WrappedComposition override fun onStateChanged(source: LifecycleOwner, event: Lifecycle.Event) { if (event == Lifecycle.Event.ON_DESTROY) { dispose() } else if (event == Lifecycle.Event.ON_CREATE) { if (!disposed) { setContent(lastContent)//main  } } } @OptIn(InternalComposeApi::class) override fun setContent(content: @Composable () -\u0026gt; Unit) { owner.setOnViewTreeOwnersAvailable { ...... else if (lifecycle.currentState.isAtLeast(Lifecycle.State.CREATED)) { original.setContent {//main  @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) val inspectionTable = owner.getTag(R.id.inspection_slot_table_set) as? MutableSet\u0026lt;CompositionData\u0026gt; ?: (owner.parent as? View)?.getTag(R.id.inspection_slot_table_set) as? MutableSet\u0026lt;CompositionData\u0026gt; if (inspectionTable != null) { @OptIn(InternalComposeApi::class) inspectionTable.add(currentComposer.compositionData) currentComposer.collectParameterInformation() } LaunchedEffect(owner) { owner.keyboardVisibilityEventLoop() } LaunchedEffect(owner) { owner.boundsUpdatesEventLoop() } CompositionLocalProvider(LocalInspectionTables provides inspectionTable) { ProvideAndroidCompositionLocals(owner, content) } } CompositionImpl.setContent internal class CompositionImpl( private val parent: CompositionContext, applier: Applier\u0026lt;*\u0026gt;, private val onDispose: (() -\u0026gt; Unit)? = null, recomposeContext: CoroutineContext? = null ) : ControlledComposition { override fun setContent(content: @Composable () -\u0026gt; Unit) { check(!disposed) { \u0026#34;The composition is disposed\u0026#34; } this.composable = content parent.composeInitial(this, composable)//main  } Recomposer.composeInitial @OptIn(InternalComposeApi::class) class Recomposer( effectCoroutineContext: CoroutineContext ) : CompositionContext() { internal override fun composeInitial( composition: ControlledComposition, content: @Composable () -\u0026gt; Unit ) { val composerWasComposing = composition.isComposing composing(composition, null) { composition.composeContent(content)//main  } CompositionImpl.composeContent //CompositionImpl  private val composer: ComposerImpl = ComposerImpl(applier, parent, this).also { parent.registerComposer(it) } override fun composeContent(content: @Composable () -\u0026gt; Unit) { // TODO: This should raise a signal to any currently running recompose calls  // to halt and return  synchronized(lock) { drainPendingModificationsForCompositionLocked() composer.composeContent(content)//main  } } ComposerImpl.composeContent internal class ComposerImpl( /** * An adapter that applies changes to the tree using the Applier abstraction. */ override val applier: Applier\u0026lt;*\u0026gt;, /** * Parent of this composition; a [Recomposer] for root-level compositions. */ private val parentContext: CompositionContext, /** * The composition that owns this composer */ override val composition: ControlledComposition ) : Composer { internal fun composeContent(content: @Composable () -\u0026gt; Unit) { check(changes.isEmpty()) { \u0026#34;Expected applyChanges() to have been called\u0026#34; } trace(\u0026#34;Compose:recompose\u0026#34;) { var complete = false val wasComposing = isComposing isComposing = true try { startRoot() startGroup(invocationKey, invocation) invokeComposable(this, content)//main  endGroup() endRoot() complete = true } finally { isComposing = wasComposing if (!complete) abortRoot() } } } internal fun invokeComposable(composer: Composer, composable: @Composable () -\u0026gt; Unit) { @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) val realFn = composable as Function2\u0026lt;Composer, Int, Unit\u0026gt; realFn(composer, 1) } ComposableLambdaImpl.invoke internal class ComposableLambdaImpl( val key: Int, private val tracked: Boolean, private val sourceInformation: String? ) : ComposableLambda { override operator fun invoke(c: Composer, changed: Int): Any? { val c = c.startRestartGroup(key, sourceInformation) trackRead(c) val dirty = changed or if (c.changed(this)) differentBits(0) else sameBits(0) val result = (_block as (c: Composer, changed: Int) -\u0026gt; Any?)(c, dirty)//main  c.endRestartGroup()?.updateScope(this as (Composer, Int) -\u0026gt; Unit) return result } CompositionLocalProvider original.setContent { .... LaunchedEffect(owner) { owner.keyboardVisibilityEventLoop() } LaunchedEffect(owner) { owner.boundsUpdatesEventLoop() } CompositionLocalProvider(LocalInspectionTables provides inspectionTable) {//main  ProvideAndroidCompositionLocals(owner, content)//main  } } ProvideAndroidCompositionLocals @Composable @OptIn(ExperimentalComposeUiApi::class) internal fun ProvideAndroidCompositionLocals( owner: AndroidComposeView, content: @Composable () -\u0026gt; Unit ) { val view = owner val context = view.context ...... CompositionLocalProvider(//main  LocalConfiguration provides configuration, LocalContext provides context, LocalLifecycleOwner provides viewTreeOwners.lifecycleOwner, LocalSavedStateRegistryOwner provides viewTreeOwners.savedStateRegistryOwner, LocalSaveableStateRegistry provides saveableStateRegistry, LocalView provides owner.view ) { ProvideCommonCompositionLocals(//main  owner = owner, uriHandler = uriHandler, content = content ) } ProvideCommonCompositionLocals @ExperimentalComposeUiApi @Composable internal fun ProvideCommonCompositionLocals( owner: Owner, uriHandler: UriHandler, content: @Composable () -\u0026gt; Unit ) { CompositionLocalProvider(//main  LocalAccessibilityManager provides owner.accessibilityManager, LocalAutofill provides owner.autofill, LocalAutofillTree provides owner.autofillTree, LocalClipboardManager provides owner.clipboardManager, LocalDensity provides owner.density, LocalFocusManager provides owner.focusManager, LocalFontLoader provides owner.fontLoader, LocalHapticFeedback provides owner.hapticFeedBack, LocalLayoutDirection provides owner.layoutDirection, LocalTextInputService provides owner.textInputService, LocalTextToolbar provides owner.textToolbar, LocalUriHandler provides uriHandler, LocalViewConfiguration provides owner.viewConfiguration, LocalWindowInfo provides owner.windowInfo, content = content//main  ) } ComposeView.Content 执行ensureCompositionCreated()时配置的闭包回调Content()\nclass ComposeView @JvmOverloads constructor( context: Context, attrs: AttributeSet? = null, defStyleAttr: Int = 0 ) : AbstractComposeView(context, attrs, defStyleAttr) { @Composable override fun Content() { content.value?.invoke()//value类型为ComposableLambdaImpl,也就是Activity调用setContent设置下来的闭包 } 其他 CompositionLocalProvider @Composable @OptIn(InternalComposeApi::class) fun CompositionLocalProvider(vararg values: ProvidedValue\u0026lt;*\u0026gt;, content: @Composable () -\u0026gt; Unit) { currentComposer.startProviders(values) content() currentComposer.endProviders() } observeAsState @Composable fun \u0026lt;T\u0026gt; LiveData\u0026lt;T\u0026gt;.observeAsState(): State\u0026lt;T?\u0026gt; = observeAsState(value) @Composable fun \u0026lt;R, T : R\u0026gt; LiveData\u0026lt;T\u0026gt;.observeAsState(initial: R): State\u0026lt;R\u0026gt; { val lifecycleOwner = LocalLifecycleOwner.current val state = remember { mutableStateOf(initial) } DisposableEffect(this, lifecycleOwner) { val observer = Observer\u0026lt;T\u0026gt; { state.value = it } observe(lifecycleOwner, observer) onDispose { removeObserver(observer) } } return state } LocalLifecycleOwner val LocalLifecycleOwner = staticCompositionLocalOf\u0026lt;LifecycleOwner\u0026gt; { noLocalProvidedFor(\u0026#34;LocalLifecycleOwner\u0026#34;) } staticCompositionLocalOf fun \u0026lt;T\u0026gt; staticCompositionLocalOf(defaultFactory: () -\u0026gt; T): ProvidableCompositionLocal\u0026lt;T\u0026gt; = StaticProvidableCompositionLocal(defaultFactory) mutableStateOf fun \u0026lt;T\u0026gt; mutableStateOf( value: T, policy: SnapshotMutationPolicy\u0026lt;T\u0026gt; = structuralEqualityPolicy() ): MutableState\u0026lt;T\u0026gt; = SnapshotMutableStateImpl(value, policy) SnapshotMutableStateImpl private class SnapshotMutableStateImpl\u0026lt;T\u0026gt;( value: T, override val policy: SnapshotMutationPolicy\u0026lt;T\u0026gt; ) : StateObject, SnapshotMutableState\u0026lt;T\u0026gt; { @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) override var value: T get() = next.readable(this).value set(value) = next.withCurrent { if (!policy.equivalent(it.value, value)) { next.writable(this) { this.value = value } } } remember rememberUpdatedState @Composable fun \u0026lt;T\u0026gt; rememberUpdatedState(newValue: T): State\u0026lt;T\u0026gt; = remember { mutableStateOf(newValue) }.apply { value = newValue } remember @OptIn(ComposeCompilerApi::class) @Composable inline fun \u0026lt;T\u0026gt; remember(calculation: @DisallowComposableCalls () -\u0026gt; T): T = currentComposer.cache(false, calculation)//composerImpl实例 @ComposeCompilerApi inline fun \u0026lt;T\u0026gt; Composer.cache(invalid: Boolean, block: () -\u0026gt; T): T { @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) return rememberedValue().let { if (invalid || it === Composer.Empty) {//invalid或没有cache数据时，走block初始化value并记住  val value = block() updateRememberedValue(value) value } else it } as T } //ComposerImpl override fun rememberedValue(): Any? = nextSlot() @PublishedApi @OptIn(InternalComposeApi::class) internal fun nextSlot(): Any? = if (inserting) { validateNodeNotExpected() Composer.Empty } else reader.next() //composerImpl override fun updateRememberedValue(value: Any?) = updateValue(value) ComposerImpl.updateValue @PublishedApi @OptIn(InternalComposeApi::class) internal fun updateValue(value: Any?) { if (inserting) { writer.update(value)//main  if (value is RememberObserver) { record { _, _, rememberManager -\u0026gt; rememberManager.remembering(value) } } } else { val groupSlotIndex = reader.groupSlotIndex - 1 recordSlotTableOperation(forParent = true) { _, slots, rememberManager -\u0026gt; if (value is RememberObserver) { abandonSet.add(value) rememberManager.remembering(value) } when (val previous = slots.set(groupSlotIndex, value)) { is RememberObserver -\u0026gt; rememberManager.forgetting(previous) is RecomposeScopeImpl -\u0026gt; { if (previous.composer != null) { previous.composer = null pendingInvalidScopes = true } } } } SlotWriter图解 internal class SlotWriter( /** * The [SlotTable] for whom this is writer. */ internal val table: SlotTable ) { /** * The gap buffer for groups. This might change as groups are inserted and the array needs to * be expanded to account groups. The current valid groups occupy 0 until [groupGapStart] * followed [groupGapStart] + [groupGapLen] until groups.size where [groupGapStart] * until [groupGapStart] + [groupGapLen] is the gap. */ private var groups: IntArray = table.groups /** * The gap buffer for the slots. This might change as slots are inserted an and the array * needs to be expanded to account for the new slots. The current valid slots occupy 0 until * [slotsGapStart] and [slotsGapStart] + [slotsGapLen] until slots.size where [slotsGapStart] * until [slotsGapStart] + [slotsGapLen] is the gap. */ private var slots: Array\u0026lt;Any?\u0026gt; = table.slots private var slotsGapLen: Int = slots.size - table.slotsSize private fun dataIndexToDataAddress(dataIndex: Int) = if (dataIndex \u0026lt; slotsGapStart) dataIndex else dataIndex + slotsGapLen fun update(value: Any?): Any? { val result = skip() set(value) return result } fun skip(): Any? { if (insertCount \u0026gt; 0) { insertSlots(1, parent) } return slots[dataIndexToDataAddress(currentSlot++)] } SlotTable internal class SlotTable : CompositionData, Iterable\u0026lt;CompositionGroup\u0026gt; { Anchor /** * An [Anchor] tracks a groups as its index changes due to other groups being inserted and * removed before it. If the group the [Anchor] is tracking is removed, directly or indirectly, * [valid] will return false. The current index of the group can be determined by passing either * the [SlotTable] or [SlotWriter] to [toIndexFor]. If a [SlotWriter] is active, it must be used * instead of the [SlotTable] as the anchor index could have shifted due to operations performed * on the writer. */ internal class Anchor(loc: Int) { internal var location: Int = loc val valid get() = location != Int.MIN_VALUE fun toIndexFor(slots: SlotTable) = slots.anchorIndex(this) fun toIndexFor(writer: SlotWriter) = writer.anchorIndex(this) } State @Stable interface State\u0026lt;T\u0026gt; { val value: T } "
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/coroutine/",
	"title": "coroutine",
	"tags": [],
	"description": "",
	"content": "coroutine 探索总结coroutine知识\n kotlin协程     kotlin协程Source     kotlin协程取消     kotlin协程异常     使用挂起函数来封装回调     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/coroutines/",
	"title": "Coroutines",
	"tags": [],
	"description": "",
	"content": "https://developer.android.com/topic/libraries/architecture/coroutines\n理解协程、livedata 和 flow\n协程 flow 最佳实践 | 基于 android 开发者峰会应用\n如果您想将一个基于回调的流 API 转换为使用 Flow，您可以使用 channelFlow 函数 (当然也可以使用 callbackFlow，它们都基于相同的实现)。\n  Flow 非常适合需要开始/停止数据的产生来匹配观察者的场景。\n  如果生产者和消费者的生命周期不同或者彼此完全独立运行时，请使用 BroadcastChannel。\n  架构思考 graph LR archetecture--\u0026gt;|Async|Scope subgraph AutoCancel Scope--\u0026gt;StructuredConcurrency end archetecture--\u0026gt;|LiveData|UnMutableLiveDataExposeToView--\u0026gt;LiveDataCoroutine archetecture--\u0026gt;|EmitMultiData|Flow oneshot--\u0026gt;suspendCancellableCoroutine multishots--\u0026gt;callbackFlow lifecycle 从 API 1 开始，处理 Activity 的生命周期 (lifecycle) 就是个老大难的问题，基本上开发者们都看过这两张生命周期流程图:\n△ Activity 生命周期流程图\n随着 Fragment 的加入，这个问题也变得更加复杂:\n△ Fragment 生命周期流程图\n而开发者们面对这个挑战，给出了非常稳健的解决方案: 分层架构。\n分层架构 △ 表现层 (Presentation Layer)、域层 (Domain Layer) 和数据层 (Data Layer)\n如上图所示，通过将应用分为三层，现在只有最上面的 Presentation 层 (以前叫 UI 层) 才知道生命周期的细节，而应用的其他部分则可以安全地忽略掉它。\nViewModel 而在 Presentation 层内部也有进一步的解决方案: 让一个对象可以在 Activity 和 Fragment 被销毁、重新创建时依然留存，这个对象就是架构组件的 ViewModel 类。下面让我们详细看看 ViewModel 工作的细节。\n如上图，当一个视图 (View) 被创建，它有对应的 ViewModel 的引用地址 (注意 ViewModel 并没有 View 的引用地址)。ViewModel 会暴露出若干个 LiveData，视图会通过数据绑定或者手动订阅的方式来观察这些 LiveData。\n当设备配置改变时 (比如屏幕发生旋转)，之前的 View 被销毁，新的 View 被创建:\n这时新的 View 会重新订阅 ViewModel 里的 LiveData，而 ViewModel 对这个变化的过程完全不知情。\nScope 归根到底，开发者在执行一个操作时，需要认真选择好这个操作的作用域 (scope)。这取决于这个操作具体是做什么，以及它的内容是否需要贯穿整个屏幕内容的生命周期。比如通过网络获取一些数据，或者是在绘图界面中计算一段曲线的控制锚点，可能所适用的作用域不同。如何取消该操作的时间太晚，可能会浪费很多额外的资源；而如果取消的太早，又会出现频繁重启操作的情况。\n在实际应用中，以我们的 Android Dev Summit 应用为例，里面涉及到的作用域非常多。比如，我们这里有一个活动计划页面，里面包含多个 Fragment 实例，而与之对应的 ViewModel 的作用域就是计划页面。与之相类似的，日程和信息页面相关的 Fragment 以及 ViewModel 也是一样的作用域。\n此外我们还有很多 Activity，而和它们相关的 ViewModel 的作用域就是这些 Activity。\n您也可以自定义作用域。比如针对导航组件，您可以将作用域限制在登录流程或者结账流程中。我们甚至还有针对整个 Application 的作用域。\n有如此多的操作会同时进行，我们需要有一个更好的方法来管理它们的取消操作。也就是 Kotlin 的协程 (Coroutine)。\n协程的优势 协程的优点主要来自三个方面:\n 很容易离开主线程。我们试过很多方法来让操作远离主线程，AsyncTask、Loaders、ExecutorServices……甚至有开发者用到了 RxJava。但协程可以让开发者只需要一行代码就完成这个工作，而且没有累人的回调处理。 样板代码最少。协程完全活用了 Kotlin 语言的能力，包括 suspend 方法。编写协程的过程就和编写普通的代码块差不多，编译器则会帮助开发者完成异步化处理。 结构并发性。这个可以理解为针对操作的垃圾搜集器，当一个操作不再需要被执行时，协程会自动取消它。  如何启动和取消协程 viewModelScope 在 Jetpack 组件里，我们为各个组件提供了对应的 scope，比如 ViewModel 就有与之对应的 viewModelScope，如果您想在这个作用域里启动协程，使用如下代码即可:\nclass MainActivityViewModel : ViewModel { init { viewModelScope.launch { // Start  } } } lifecycleScope.launch 如果您在使用 AppCompatActivity 或 Fragment，则可以使用 lifecycleScope，当 lifeCycle 被销毁时，操作也会被取消。代码如下:\nclass MyActivity : AppCompatActivity() { override fun onCreate(state: Bundle?) { super.onCreate(savedInstanceState) lifecycleScope.launch { // Run  } } } lifecycleScope.launchWhenXxx 有些时候，您可能还需要在生命周期的某个状态 (启动时/恢复时等) 执行一些操作，这时您可以使用 launchWhenStarted、launchWhenResumed、launchWhenCreated 这些方法:\nclass MyActivity : Activity { override fun onCreate(state: Bundle?) { super.onCreate(savedInstanceState) lifecycleScope.launch { // Run  } lifecycleScope.launchWhenResumed { // Run  } } } 注意，如果您在 launchWhenStarted 中设置了一个操作，当 Activity 被停止时，这个操作也会被暂停，直到 Activity 被恢复 (Resume)。\nApplicationScope\u0026ndash;WorkManager 最后一种作用域的情况是贯穿整个应用。如果这个操作非常重要，您需要确保它一定被执行，这时请考虑使用 WorkManager。比如您编写了一个发推的应用，希望撰写的推文被发送到服务器上，那这个操作就需要使用 WorkManager 来确保执行。而如果您的操作只是清理一下本地存储，那可以考虑使用 Application Scope，因为这个操作的重要性不是很高，完全可以等到下次应用启动时再做。\n  WorkManager\nhttps://developer.android.google.cn/topic/libraries/architecture/workmanager/basics\n  WorkManager 不是本文介绍的重点，感兴趣的朋友请参考 《WorkManager 进阶课堂 | AndroidDevSummit 中文字幕视频》。\nviewModelScope 里使用 LiveData 接下来我们看看如何在 viewModelScope 里使用 LiveData。以前我们想在协程里做一些操作，并将结果反馈到 ViewModel 需要这么操作:\nclass MyViewModel : ViewModel { private val _result = MutableLiveData\u0026lt;String\u0026gt;() val result: LiveData\u0026lt;String\u0026gt; = _result init { viewModelScope.launch { val computationResult = doComputation() _result.value = computationResult } } } 看看我们做了什么:\n 准备一个 ViewModel 私有的 MutableLiveData (MLD) 暴露一个不可变的 LiveData 启动协程，然后将其操作结果赋给 MLD  LiveData 协程构造方法 这个做法并不理想。在 LifeCycle 2.2.0 之后，同样的操作可以用更精简的方法来完成，也就是 LiveData 协程构造方法 (coroutine builder):\nclass MyViewModel { val result = liveData { emit(doComputation()) } } 这个 liveData 协程构造方法提供了一个协程代码块，这个块就是 LiveData 的作用域，当 LiveData 被观察的时候，里面的操作就会被执行，当 LiveData 不再被使用时，里面的操作就会取消。而且该协程构造方法产生的是一个不可变的 LiveData，可以直接暴露给对应的视图使用。而 emit() 方法则用来更新 LiveData 的数据。\n数据之间的依赖\u0026ndash;switchMap 让我们来看另一个常见用例，比如当用户在 UI 中选中一些元素，然后将这些选中的内容显示出来。一个常见的做法是，把被选中的项目的 ID 保存在一个 MutableLiveData 里，然后运行 switchMap。现在在 switchMap 里，您也可以使用协程构造方法:\nprivate val itemId = MutableLiveData\u0026lt;String\u0026gt;() val result = itemId.switchMap { liveData { emit(fetchItem(it)) } } liveData使用Dispatchers LiveData 协程构造方法还可以接收一个 Dispatcher 作为参数，这样您就可以将这个协程移至另一个线程。\nliveData(Dispatchers.IO) { } emitSource 最后，您还可以使用 emitSource() 方法从另一个 LiveData 获取更新的结果:\nliveData(Dispatchers.IO) { emit(LOADING_STRING) emitSource(dataSource.fetchWeather()) } 如何取消协程 接下来我们来看如何取消协程。绝大部分情况下，协程的取消操作是自动的，毕竟我们在对应的作用域里启动一个协程时，也同时明确了它会在何时被取消。但我们有必要讲一讲如何在协程内部来手动取消协程。\n这里补充一个大前提: 所有 kotlin.coroutines 的 suspend 方法都是可取消的。比如这种:\nsuspend fun printPrimes() { while(true) { // Compute  delay(1000) } } 在上面这个无限循环里，每一个 delay 都会检查协程是否处于有效状态，一旦发现协程被取消，循环的操作也会被取消。\n那问题来了，如果您在 suspend 方法里调用的是一个不可取消的方法呢？这时您需要使用 isActivate 来进行检查并手动决定是否继续执行操作:\nsuspend fun printPrimes() { while(isActive) { // Compute  } } LiveData 操作实践 在进入具体的操作实践环节之前，我们需要区分一下两种操作: 单次 (One-Shot) 操作和监听 (observers) 操作。比如 Twitter 的应用:\n单次操作，比如获取用户头像和推文，只需要执行一次即可。\n监听操作，比如界面下方的转发数和点赞数，就会持续更新数据。\n单值 让我们先看看单次操作时的内容架构:\n如前所述，我们使用 LiveData 连接 View 和 ViewModel，而在 ViewModel 这里我们则使用刚刚提到的 liveData 协程构造方法来打通 LiveData 和协程，再往右就是调用 suspend 方法了。\n多值 如果我们想监听多个值的话，该如何操作呢？\n传递LiveData 第一种选择是在 ViewModel 之外也使用 LiveData:\n△ Reopsitory 监听 Data Source 暴露出来的 LiveData，同时自己也暴露出 LiveData 供 ViewModel 使用\nFlow 但是这种实现方式无法体现并发性，比如每次用户登出时，就需要手动取消所有的订阅。LiveData 本身的设计并不适合这种情况，这时我们就需要使用第二种选择: 使用 Flow。\nViewModel 模式 无数据转换 当 ViewModel 监听 LiveData，而且没有对数据进行任何转换操作时，可以直接将 dataSource 中的 LiveData 赋值给 ViewModel 暴露出来的 LiveData:\nval currentWeather: LiveData\u0026lt;String\u0026gt; = dataSource.fetchWeather() 如果使用 Flow 的话就需要用到 liveData 协程构造方法。我们从 Flow 中使用 collect 方法获取每一个结果，然后 emit 出来给 liveData 协程构造方法使用:\nval currentWeatherFlow: LiveData\u0026lt;String\u0026gt; = liveData { dataSource.fetchWeatherFlow().collect { emit(it) } } 不过 Flow 给我们准备了更简单的写法:\nval currentWeatherFlow: LiveData\u0026lt;String\u0026gt; = dataSource.fetchWeatherFlow().asLiveData() 接下来一个场景是，我们先发送一个一次性的结果，然后再持续发送多个数值:\nval currentWeather: LiveData\u0026lt;String\u0026gt; = liveData { emit(LOADING_STRING) emitSource(dataSource.fetchWeather()) } 在 Flow 中我们可以沿用上面的思路，使用 emit 和 emitSource:\nval currentWeatherFlow: LiveData\u0026lt;String\u0026gt; = liveData { emit(LOADING_STRING) emitSource( dataSource.fetchWeatherFlow().asLiveData() ) } 但同样的，这种情况 Flow 也有更直观的写法:\nval currentWeatherFlow: LiveData\u0026lt;String\u0026gt; = dataSource.fetchWeatherFlow() .onStart { emit(LOADING_STRING) } .asLiveData() 数据转换 接下来我们看看需要为接收到的数据做转换时的情况。\n使用 LiveData 时，如果用 map 方法做转换，操作会进入主线程，这显然不是我们想要的结果。这时我们可以使用 switchMap，从而可以通过 liveData 协程构造方法获得一个 LiveData，而且 switchMap 的方法会在每次数据源 LiveData 更新时调用。而在方法体内部我们可以使用 heavyTransformation 函数进行数据转换，并发送其结果给 liveData 协程构造方法:\nval currentWeatherLiveData: LiveData\u0026lt;String\u0026gt; = dataSource.fetchWeather().switchMap { liveData { emit(heavyTransformation(it)) } } 使用 Flow 的话会简单许多，直接从 dataSource 获得数据，然后调用 map 方法 (这里用的是 Flow 的 map 方法，而不是 LiveData 的)，然后转化为 LiveData 即可:\nval currentWeatherFlow: LiveData\u0026lt;String\u0026gt; = dataSource.fetchWeatherFlow() .map { heavyTransformation(it) } .asLiveData() Repository 模式 Repository 一般用来进行复杂的数据转换和处理，而 LiveData 没有针对这种情况进行设计。现在通过 Flow 就可以完成各种复杂的操作:\nval currentWeatherFlow: Flow\u0026lt;String\u0026gt; = dataSource.fetchWeatherFlow() .map { ... } .filter { ... } .dropWhile { ... } .combine { ... } .flowOn(Dispatchers.IO) .onCompletion { ... } ... 数据源模式 而在涉及到数据源时，情况变得有些复杂，因为这时您可能是在和其他代码库或者远程数据源进行交互，但是您又无法控制这些数据源。这里我们分两种情况介绍:\n1. 单次操作 如果使用 Retrofit 从远程数据源获取数值，直接将方法标记为 suspend 方法即可*:\nsuspend fun doOneShot(param: String) : String = retrofitClient.doSomething(param) ** Retrofit 从 2.6.0 开始支持 suspend 方法，Room 从 2.1.0 开始支持 suspend 方法。*\n如果您的数据源尚未支持协程，比如是一个 Java 代码库，而且使用的是回调机制。这时您可以使用 suspendCancellableCoroutine 协程构造方法，这个方法是协程和回调之间的适配器，会在内部提供一个 continuation 供开发者使用:\nsuspend fun doOneShot(param: String) : Result\u0026lt;String\u0026gt; = suspendCancellableCoroutine { continuation -\u0026gt; api.addOnCompleteListener { result -\u0026gt; continuation.resume(result) }.addOnFailureListener { error -\u0026gt; continuation.resumeWithException(error) } } 如上所示，在回调方法取得结果后会调用 continuation.resume()，如果报错的话调用的则是 continuation.resumeWithException()。\n注意，如果这个协程已经被取消，则 resume 调用也会被忽略。开发者可以在协程被取消时主动取消 API 请求。\n2. 监听操作 如果数据源会持续发送数值的话，使用 flow 协程构造方法会很好地满足需求，比如下面这个方法就会每隔 2 秒发送一个新的天气值:\noverride fun fetchWeatherFlow(): Flow\u0026lt;String\u0026gt; = flow { var counter = 0 while(true) { counter++ delay(2000) emit(weatherConditions[counter % weatherConditions.size]) } } 如果开发者使用的是不支持 Flow 而是使用回调的代码库，则可以使用 callbackFlow。比如下面这段代码，api 支持三个回调分支 onNextValue、onApiError 和 onCompleted，我们可以得到结果的分支里使用 offer 方法将值传给 Flow，在发生错误的分支里 close 这个调用并传回一个错误原因 (cause)，而在顺利调用完成后直接 close 调用:\nfun flowFrom(api: CallbackBasedApi): Flow\u0026lt;T\u0026gt; = callbackFlow { val callback = object : Callback { override fun onNextValue(value: T) { offer(value) } override fun onApiError(cause: Throwable) { close(cause) } override fun onCompleted() = close() } api.register(callback) awaitClose { api.unregister(callback) } } 注意在这段代码的最后，如果 API 不会再有更新，则使用 awaitClose 彻底关闭这条数据通道。\n相信看到这里，您对如何在实际应用中使用协程、LiveData 和 Flow 已经有了比较系统的认识。您可以重温 Android Dev Summit 上 Jose Alcérreca 和 Yigit Boyar 的演讲来巩固理解:\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/databinding/databinding/",
	"title": "Databinding",
	"tags": [],
	"description": "",
	"content": "类设计 在liveData数据变化回调onChanged之后，触发requestRebind,在executeBindings时根据dirtyFlags通过BindingAdapter方法刷新View属性\n基于androidx.databinding:databinding-runtime:4.0.1\nDataBindingUtil private static DataBinderMapper sMapper = new DataBinderMapperImpl(); private static DataBindingComponent sDefaultComponent = null; setContentView public static \u0026lt;T extends ViewDataBinding\u0026gt; T setContentView(@NonNull Activity activity, int layoutId) { return setContentView(activity, layoutId, sDefaultComponent); } public static \u0026lt;T extends ViewDataBinding\u0026gt; T setContentView(@NonNull Activity activity, int layoutId, @Nullable DataBindingComponent bindingComponent) { activity.setContentView(layoutId); View decorView = activity.getWindow().getDecorView(); ViewGroup contentView = (ViewGroup) decorView.findViewById(android.R.id.content); return bindToAddedViews(bindingComponent, contentView, 0, layoutId); } bindToAddedViews private static \u0026lt;T extends ViewDataBinding\u0026gt; T bindToAddedViews(DataBindingComponent component, ViewGroup parent, int startChildren, int layoutId) { final int endChildren = parent.getChildCount(); final int childrenAdded = endChildren - startChildren; if (childrenAdded == 1) { final View childView = parent.getChildAt(endChildren - 1); return bind(component, childView, layoutId); } else { final View[] children = new View[childrenAdded]; for (int i = 0; i \u0026lt; childrenAdded; i++) { children[i] = parent.getChildAt(i + startChildren); } return bind(component, children, layoutId); } } bind static \u0026lt;T extends ViewDataBinding\u0026gt; T bind(DataBindingComponent bindingComponent, View[] roots, int layoutId) { return (T) sMapper.getDataBinder(bindingComponent, roots, layoutId); } sMapper\nMergedDataBinderMapper public class MergedDataBinderMapper extends DataBinderMapper { private List\u0026lt;DataBinderMapper\u0026gt; mMappers = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); } getDataBinder @Override public ViewDataBinding getDataBinder(DataBindingComponent bindingComponent, View view, int layoutId) { for(DataBinderMapper mapper : mMappers) { ViewDataBinding result = mapper.getDataBinder(bindingComponent, view, layoutId); if (result != null) { return result; } } return null; } androidx.databinding.DataBinderMapperImpl public class DataBinderMapperImpl extends MergedDataBinderMapper { DataBinderMapperImpl() { addMapper(new com.example.myapplication.DataBinderMapperImpl()); } } com.example.myapplication.DataBinderMapperImpl getDataBinder @Override public ViewDataBinding getDataBinder(DataBindingComponent component, View view, int layoutId) { int localizedLayoutId = INTERNAL_LAYOUT_ID_LOOKUP.get(layoutId); final Object tag = view.getTag(); switch(localizedLayoutId) { case LAYOUT_ACTIVITYLOGIN: { if (\u0026#34;layout/activity_login_0\u0026#34;.equals(tag)) { return new ActivityLoginBindingImpl(component, view); } } } } ViewDatabinding mFrameCallback private final Choreographer.FrameCallback mFrameCallback; CREATE_LIVE_DATA_LISTENER private static final CreateWeakListener CREATE_LIVE_DATA_LISTENER = new CreateWeakListener() { @Override public WeakListener create(ViewDataBinding viewDataBinding, int localFieldId) { return new LiveDataListener(viewDataBinding, localFieldId).getListener(); } }; livedatalistener\nconstructor protected ViewDataBinding(DataBindingComponent bindingComponent, View root, int localFieldCount) { mBindingComponent = bindingComponent; mLocalFieldObservers = new WeakListener[localFieldCount]; this.mRoot = root; mChoreographer = Choreographer.getInstance(); mFrameCallback = new Choreographer.FrameCallback() { @Override public void doFrame(long frameTimeNanos) { mRebindRunnable.run(); } }; } mrebindrunnable\nsetLifecycleOwner public void setLifecycleOwner(@Nullable LifecycleOwner lifecycleOwner) { ...... mLifecycleOwner = lifecycleOwner; if (lifecycleOwner != null) { if (mOnStartListener == null) { mOnStartListener = new OnStartListener(this); } lifecycleOwner.getLifecycle().addObserver(mOnStartListener); } for (WeakListener\u0026lt;?\u0026gt; weakListener : mLocalFieldObservers) { if (weakListener != null) { weakListener.setLifecycleOwner(lifecycleOwner); } } } OnStartListener static class OnStartListener implements LifecycleObserver { final WeakReference\u0026lt;ViewDataBinding\u0026gt; mBinding; private OnStartListener(ViewDataBinding binding) { mBinding = new WeakReference\u0026lt;\u0026gt;(binding); } @OnLifecycleEvent(Lifecycle.Event.ON_START) public void onStart() { ViewDataBinding dataBinding = mBinding.get(); if (dataBinding != null) { dataBinding.executePendingBindings(); } } } executependingbindings\nrequestRebind protected void requestRebind() { if (mContainingBinding != null) { mContainingBinding.requestRebind(); } else { final LifecycleOwner owner = this.mLifecycleOwner; if (owner != null) { Lifecycle.State state = owner.getLifecycle().getCurrentState(); if (!state.isAtLeast(Lifecycle.State.STARTED)) { return; // wait until lifecycle owner is started  } } mChoreographer.postFrameCallback(mFrameCallback); } } mFrameCallback\nmRebindRunnable private final Runnable mRebindRunnable = new Runnable() { @Override public void run() { processReferenceQueue(); executePendingBindings(); } }; executePendingBindings public void executePendingBindings() { if (mContainingBinding == null) { executeBindingsInternal(); } else { mContainingBinding.executePendingBindings(); } } executeBindingsInternal private void executeBindingsInternal() { ....... executeBindings(); ...... } executebindings\nupdateLiveDataRegistration protected boolean updateLiveDataRegistration(int localFieldId, LiveData\u0026lt;?\u0026gt; observable) { mInLiveDataRegisterObserver = true; try { return updateRegistration(localFieldId, observable, CREATE_LIVE_DATA_LISTENER); } finally { mInLiveDataRegisterObserver = false; } } updateRegistration private boolean updateRegistration(int localFieldId, Object observable, CreateWeakListener listenerCreator) { ...... if (listener.getTarget() == observable) { return false;//nothing to do, same object  } unregisterFrom(localFieldId); registerTo(localFieldId, observable, listenerCreator); return true; } registerTo protected void registerTo(int localFieldId, Object observable, CreateWeakListener listenerCreator) { if (observable == null) { return; } WeakListener listener = mLocalFieldObservers[localFieldId]; if (listener == null) { listener = listenerCreator.create(this, localFieldId); mLocalFieldObservers[localFieldId] = listener; if (mLifecycleOwner != null) { listener.setLifecycleOwner(mLifecycleOwner); } } listener.setTarget(observable); } listener\nsettarget\nhandleFieldChange private void handleFieldChange(int mLocalFieldId, Object object, int fieldId) { boolean result = onFieldChange(mLocalFieldId, object, fieldId); if (result) { requestRebind(); } } onfieldchange\nrequestrebind\nLiveDataListener private static class LiveDataListener implements Observer, ObservableReference\u0026lt;LiveData\u0026lt;?\u0026gt;\u0026gt; { final WeakListener\u0026lt;LiveData\u0026lt;?\u0026gt;\u0026gt; mListener; LifecycleOwner mLifecycleOwner; public LiveDataListener(ViewDataBinding binder, int localFieldId) { mListener = new WeakListener(binder, localFieldId, this); } } getListener @Override public WeakListener\u0026lt;LiveData\u0026lt;?\u0026gt;\u0026gt; getListener() { return mListener; } addListener @Override public void addListener(LiveData\u0026lt;?\u0026gt; target) { if (mLifecycleOwner != null) { target.observe(mLifecycleOwner, this); } } onChanged @Override public void onChanged(@Nullable Object o) { ViewDataBinding binder = mListener.getBinder(); if (binder != null) { binder.handleFieldChange(mListener.mLocalFieldId, mListener.getTarget(), 0); } } handlefieldchange\nWeakListener private final ObservableReference\u0026lt;T\u0026gt; mObservable; setTarget public void setTarget(T object) { unregister(); mTarget = object; if (mTarget != null) { mObservable.addListener(mTarget); } } addlistener\nActivityLoginBindingImpl private ActivityLoginBindingImpl(androidx.databinding.DataBindingComponent bindingComponent, View root, Object[] bindings) { super(bindingComponent, root, 3 , (android.widget.Button) bindings[3] , (android.widget.EditText) bindings[2] , (com.example.myapplication.arch.login.CustomTextView) bindings[4] , (android.widget.EditText) bindings[1] ); this.login.setTag(null); this.mboundView0 = (androidx.constraintlayout.widget.ConstraintLayout) bindings[0]; this.mboundView0.setTag(null); this.password.setTag(null); this.uid.setTag(null); this.userName.setTag(null); setRootTag(root); // listeners  mCallback1 = new com.example.myapplication.generated.callback.OnClickListener(this, 1); invalidateAll(); } invalidateAll public void invalidateAll() { synchronized(this) { mDirtyFlags = 0x10L; } requestRebind(); } requestrebind\nsetVm public void setVm(@Nullable com.example.myapplication.arch.login.LoginViewModel Vm) { this.mVm = Vm; synchronized(this) { mDirtyFlags |= 0x8L; } notifyPropertyChanged(BR.vm); super.requestRebind(); } onFieldChange @Override protected boolean onFieldChange(int localFieldId, Object object, int fieldId) { switch (localFieldId) { case 0 : return onChangeVmUserNameLiveData((androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt;) object, fieldId); case 1 : return onChangeVmUidLiveData((androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt;) object, fieldId); case 2 : return onChangeVmPasswordLiveData((androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt;) object, fieldId); } return false; } onChangeVmUidLiveData private boolean onChangeVmUidLiveData(androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; VmUidLiveData, int fieldId) { if (fieldId == BR._all) { synchronized(this) { mDirtyFlags |= 0x2L; } return true; } return false; } executeBindings @Override protected void executeBindings() { long dirtyFlags = 0; synchronized(this) { dirtyFlags = mDirtyFlags; mDirtyFlags = 0; } java.lang.String vmUserNameLiveDataGetValue = null; androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; vmUserNameLiveData = null; androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; vmUidLiveData = null; com.example.myapplication.arch.login.LoginViewModel vm = mVm; java.lang.String vmUidLiveDataGetValue = null; java.lang.String vmPasswordLiveDataGetValue = null; androidx.lifecycle.MutableLiveData\u0026lt;java.lang.String\u0026gt; vmPasswordLiveData = null; ...... if ((dirtyFlags \u0026amp; 0x1aL) != 0) { if (vm != null) { // read vm.uidLiveData  vmUidLiveData = vm.getUidLiveData(); } updateLiveDataRegistration(1, vmUidLiveData); if (vmUidLiveData != null) { // read vm.uidLiveData.getValue()  vmUidLiveDataGetValue = vmUidLiveData.getValue(); } //从LiveData的T中提取嵌套子数据data时,会生成如下的提取field代码  //xml中绑定的数据为: @{vm.uidLiveData.data}  if (vmUidLiveDataGetValue != null) { // read vm.uidLiveData.getValue().data  vmUidLiveDataData = vmUidLiveDataGetValue.getData(); } } if ((dirtyFlags \u0026amp; 0x1aL) != 0) { // api target 1  //从LiveData的T中提取嵌套子数据data时, 会用vmUidLiveDataData替代vmUidLiveDataGetValue  androidx.databinding.adapters.TextViewBindingAdapter.setText(this.uid, vmUidLiveDataGetValue); com.example.myapplication.arch.login.CustomTextView.changeBgIfLong(this.uid, vmUidLiveDataGetValue); } } updatelivedataregistration\n参考 RecyclerView https://developer.android.google.cn/guide/topics/ui/layout/recyclerview\nAndroid Data Binding: RecyclerView\nRefactoring RecyclerView adapter to data binding\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/databinding/",
	"title": "databinding",
	"tags": [],
	"description": "",
	"content": "databinding 探索总结databinding知识\n Databinding     TwoWayDataBinding     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/1%E7%B1%BB%E7%BC%96%E8%AF%91/dex2oat/",
	"title": "dex2oat",
	"tags": [],
	"description": "",
	"content": "dex2oat原理图 sequenceDiagram installd-\u0026gt;\u0026gt;dex2oat: main activate dex2oat dex2oat-\u0026gt;\u0026gt;dex2oat: art:dex2oat() activate dex2oat dex2oat-\u0026gt;\u0026gt;dex2oat: Setup() Note right of dex2oat: MethodVerified回调时deVirtual deactivate dex2oat activate dex2oat dex2oat-\u0026gt;\u0026gt;dex2oat: CompileImage() Note right of dex2oat: 三种编译处理模式:dex2dex,jni,dex2Native activate dex2oat dex2oat-\u0026gt;\u0026gt;dex2oat: LoadClassProfileDescriptors() deactivate dex2oat activate dex2oat dex2oat-\u0026gt;\u0026gt;dex2oat: Compile() dex2oat-\u0026gt;\u0026gt;CompilerDriver: CompileAll CompilerDriver-\u0026gt;\u0026gt;CompilerDriver: PreCompile activate CompilerDriver Note right of CompilerDriver: Resolve,Verity,InitializeClasses deactivate CompilerDriver activate CompilerDriver CompilerDriver-\u0026gt;\u0026gt;CompilerDriver: Compile() activate CompilerDriver CompilerDriver-\u0026gt;\u0026gt;CompilerDriver: CompileDexFile() Note right of CompilerDriver: 多线程编译,传递dex中的class_ids索引 activate CompilerDriver CompilerDriver-\u0026gt;\u0026gt;CompilerDriver: CompileClassVisitor activate CompilerDriver CompilerDriver-\u0026gt;\u0026gt;CompilerDriver: CompileMethod() Note right of CompilerDriver: AddCompiledMethod to CompilerDriver deactivate CompilerDriver deactivate CompilerDriver deactivate CompilerDriver deactivate CompilerDriver deactivate dex2oat deactivate dex2oat deactivate dex2oat dex2oat-\u0026gt;\u0026gt;dex2oat: WriteOatFiles() Note right of dex2oat: 输出.oat文件 dex2oat-\u0026gt;\u0026gt;dex2oat: HandleImage() Note right of dex2oat: 输出.art文件 oat和art文件格式和关系 graph LR OatDexFile(\u0026quot;OatDexFile[N]\u0026quot;)--\u0026gt;DexFile(\u0026quot;DexFile[N]\u0026quot;)--\u0026gt;TypeLookup-Table(\u0026quot;TypeLookup-Table[N]\u0026quot;)--\u0026gt;ClassOffsets(\u0026quot;ClassOffsets[N]\u0026quot;) ClassOffsets--\u0026gt;OatClass0 ClassOffsets--\u0026gt;OatClass1 ClassOffsets--\u0026gt;OatClassXxx OatClass1--\u0026gt;CompliedMethod0 OatClass1--\u0026gt;CompliedMethod1 OatClass1--\u0026gt;CompliedMethodXxx dex2oat dex2oat main函数 int main(int argc, char** argv) { int result = art::dex2oat(argc, argv); ... } static int dex2oat(int argc, char** argv) { ... dex2oat-\u0026gt;ParseArgs(argc, argv); if (dex2oat-\u0026gt;UseProfileGuidedCompilation()) { if (!dex2oat-\u0026gt;LoadProfile()) { return EXIT_FAILURE; } } dex2oat-\u0026gt;Setup(); bool result; if (dex2oat-\u0026gt;IsImage()) { result = CompileImage(*dex2oat); } else { result = CompileApp(*dex2oat); } ... 当使用profile-guide 编译app时，会先 LoadProfile()，这里就是 load /data/misc/profiles/cur/0/packagename/primary.prof，进行解析出 class index 和 method index，放到 ProfileCompilationinfo 中;\n如果当前的编译要生成 image时，走CompileImage流程，否则走CompileApp流程;\nbool IsImage() const { return IsAppImage() || IsBootImage();//不论是编译boot image（boot.art）或者时 app 要生成image. } CompileApp和CompileImage    static int CompileApp(Dex2Oat\u0026amp; dex2oat) {dex2oat.Compile();if (!dex2oat.WriteOatFiles()) {dex2oat.EraseOatFiles();return EXIT_FAILURE;}\u0026hellip;dex2oat.DumpTiming();return EXIT_SUCCESS;} static int CompileImage(Dex2Oat\u0026amp; dex2oat) {dex2oat.LoadClassProfileDescriptors();dex2oat.Compile();if (!dex2oat.WriteOatFiles()) {dex2oat.EraseOatFiles();return EXIT_FAILURE;}\u0026hellip;// Creates the boot.art and patches the oat files.if (!dex2oat.HandleImage()) {return EXIT_FAILURE;}\u0026hellip;dex2oat.DumpTiming();return EXIT_SUCCESS;          区别是：\n  编译image时需要 LoadClassProfileDescriptors() 产生 image_classes_ 集合\n  生成 image（HandleImage()）;\n  在生成的app image中将会包含 image_classes_ 集合中类的对象，不在 image_classes_集合中的app的类的对象，将不会被生成到 app-image中。\nLoadClassProfileDescriptors（）在从 profile信息中获取 image_classes_集合时，将会把 app dex 中的类以外的类，都过滤掉，比如 classpath dex 对应的类将不会生成到 app-image;\nvoid LoadClassProfileDescriptors() { if (profile_compilation_info_ != nullptr \u0026amp;\u0026amp; app_image_) { std::set\u0026lt;DexCacheResolvedClasses\u0026gt; resolved_classes(profile_compilation_info_-\u0026gt;GetResolvedClasses()); // 获取 profile信息中记录的所有 class  // Filter out class path classes since we don\u0026#39;t want to include these in the image.  std::unordered_set\u0026lt;std::string\u0026gt; dex_files_locations; for (const DexFile* dex_file : dex_files_) { dex_files_locations.insert(dex_file-\u0026gt;GetLocation()); // 当前app的所有dex file  } for (auto it = resolved_classes.begin(); it != resolved_classes.end(); ) { if (dex_files_locations.find(it-\u0026gt;GetDexLocation()) == dex_files_locations.end()) { // 如果这个类不在当前app 的dex file中，则过滤掉  VLOG(compiler) \u0026lt;\u0026lt; \u0026#34;Removed profile samples for non-app dex file \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;GetDexLocation(); it = resolved_classes.erase(it); } else { ++it; } } image_classes_.reset(new std::unordered_set\u0026lt;std::string\u0026gt;(runtime-\u0026gt;GetClassLinker()-\u0026gt;GetClassDescriptorsForProfileKeys(resolved_classes))); } dex2oat流程总结  根据dex2oat接收到的参数，组织编译参数 如果是 profile-guide 编译，则先进行 load app对应的 profile 收集参数中包含的所有dex file，启动 Compiler 编译这些dex file（classpath中对应的dex file，即uses-library 引用的jar文件，不会被编译），编译生成的数据放在compiler-driver中 使用 compiler-driver 中的数据，依据 oat文件设计的格式，组织成oat文件，嵌入到 ELF文件中 如果指定需要生成 app-image，则使用 HandleImage()， 生成app-image， 即 ***.art 文件  Compile 流程 // Create and invoke the compiler driver. This will compile all the dex files.  void Compile() { ... driver_.reset(new CompilerDriver(compiler_options_.get(), verification_results_.get(), \u0026amp;method_inliner_map_, compiler_kind_, instruction_set_, instruction_set_features_.get(), IsBootImage(), IsAppImage(), image_classes_.release(), compiled_classes_.release(), /* compiled_methods */ nullptr, thread_count_, dump_stats_, dump_passes_, compiler_phases_timings_.get(), swap_fd_, profile_compilation_info_.get())); driver_-\u0026gt;SetDexFilesForOatFile(dex_files_); driver_-\u0026gt;CompileAll(class_loader_, dex_files_, timings_); 编译dex文件时在 CompilerDriver 中完成， 其中LoadProfile时构造的 ==profile_compilation_info_也会指导 将要编译哪些class和 methods==。\ndriver_-\u0026gt;SetDexFilesForOatFile(dex_files_);//表示将要编译的所有 dex file，这个集合是 \u0026ndash;dex-file=/data/app/com.facebook.katana-1/base.apk 这个文件中包含的所有dex文件，比如facebook的apk中有 12个 dex文件，则会依次编译这12个文件。\nvoid CompilerDriver::CompileAll(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { InitializeThreadPools(); // Precompile:  // 1) Load image classes  // 2) Resolve all classes  // 3) Attempt to verify all classes  // 4) Attempt to initialize image classes, and trivially initialized classes  PreCompile(class_loader, dex_files, timings); // Compile:  // 1) Compile all classes and methods enabled for compilation.  if (!GetCompilerOptions().VerifyAtRuntime()) { Compile(class_loader, dex_files, timings); } } void CompilerDriver::PreCompile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { LoadImageClasses(timings); //这里只针对 bootimage的编译  Resolve(class_loader, dex_files, timings); Verify(class_loader, dex_files, timings); InitializeClasses(class_loader, dex_files, timings); } void CompilerDriver::Verify(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { for (const DexFile* dex_file : dex_files) { CHECK(dex_file != nullptr); VerifyDexFile(class_loader, *dex_file, dex_files, parallel_thread_pool_.get(), parallel_thread_count_, timings); } } void CompilerDriver::VerifyDexFile(...){ ... VerifyClassVisitor visitor(\u0026amp;context, log_level); context.ForAll(0, dex_file.NumClassDefs(), \u0026amp;visitor, thread_count); } class VerifyClassVisitor : public CompilationVisitor { public: VerifyClassVisitor(const ParallelCompilationManager* manager, LogSeverity log_level) : manager_(manager), log_level_(log_level) {} virtual void Visit(size_t class_def_index) REQUIRES(!Locks::mutator_lock_) OVERRIDE { if (!manager_-\u0026gt;GetCompiler()-\u0026gt;ShouldVerifyClassBasedOnProfile(dex_file, class_def_index)) { // Skip verification since the class is not in the profile.  return; } ... } } bool CompilerDriver::ShouldVerifyClassBasedOnProfile(const DexFile\u0026amp; dex_file, uint16_t class_idx) const { ... bool result = profile_compilation_info_-\u0026gt;ContainsClass(dex_file, class_idx); return result; 在这里可以看到，==前面从 profile中load出来的信息，将会决定只有这些 class才会进行Verify==。\n接下来看下真正的编译，实际上编译对应的是 dalvik bytecode到 native code的转换，主要针对的 method;\nvoid CompilerDriver::Compile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { for (const DexFile* dex_file : dex_files) { CHECK(dex_file != nullptr); CompileDexFile(class_loader, *dex_file, dex_files, parallel_thread_pool_.get(), parallel_thread_count_, timings); // 按照dexfile 依次编译  } ... } void CompilerDriver::CompileDexFile(jobject class_loader, const DexFile\u0026amp; dex_file, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, ThreadPool* thread_pool, size_t thread_count, TimingLogger* timings) { TimingLogger::ScopedTiming t(\u0026#34;Compile Dex File\u0026#34;, timings); ParallelCompilationManager context(Runtime::Current()-\u0026gt;GetClassLinker(), class_loader, this, \u0026amp;dex_file, dex_files, thread_pool); CompileClassVisitor visitor(\u0026amp;context); context.ForAll(0, dex_file.NumClassDefs(), \u0026amp;visitor, thread_count); //从dexfile的第一个class，直到最后一个class  编译的工作在 CompileClassVisitor 的Visit方法中进行;\nclass CompileClassVisitor : public CompilationVisitor { public: explicit CompileClassVisitor(const ParallelCompilationManager* manager) : manager_(manager) {} virtual void Visit(size_t class_def_index) REQUIRES(!Locks::mutator_lock_) OVERRIDE { // 传递的参数为 class在 dexfile中的 index，以此来查找class 数据  const DexFile::ClassDef\u0026amp; class_def = dex_file.GetClassDef(class_def_index); const char* descriptor = dex_file.GetClassDescriptor(class_def); Handle\u0026lt;mirror::Class\u0026gt; klass(hs.NewHandle(class_linker-\u0026gt;FindClass(soa.Self(), descriptor, class_loader))); const uint8_t* class_data = dex_file.GetClassData(class_def); ClassDataItemIterator it(dex_file, class_data); while (it.HasNextDirectMethod()) { // 编译direct mothod  uint32_t method_idx = it.GetMemberIndex(); CompileMethod(soa.Self(), driver, it.GetMethodCodeItem(), it.GetMethodAccessFlags(), it.GetMethodInvokeType(class_def), class_def_index, method_idx, jclass_loader, dex_file, dex_to_dex_compilation_level, compilation_enabled, dex_cache); it.Next(); } while (it.HasNextVirtualMethod()) { // 编译virtual methods  uint32_t method_idx = it.GetMemberIndex(); CompileMethod(soa.Self(), driver, it.GetMethodCodeItem(), it.GetMethodAccessFlags(), it.GetMethodInvokeType(class_def), class_def_index, method_idx, jclass_loader, dex_file, dex_to_dex_compilation_level, compilation_enabled, dex_cache); it.Next(); } ... } 从这一步中，我们可以看到，编译代码工作，主要的就是编译 method成为 native code;\nCompileMethod static void CompileMethod(Thread* self, CompilerDriver* driver, const DexFile::CodeItem* code_item, uint32_t access_flags, InvokeType invoke_type, uint16_t class_def_idx, uint32_t method_idx, jobject class_loader, const DexFile\u0026amp; dex_file, optimizer::DexToDexCompilationLevel dex_to_dex_compilation_level, bool compilation_enabled, Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache) REQUIRES(!driver-\u0026gt;compiled_methods_lock_) { MethodReference method_ref(\u0026amp;dex_file, method_idx); if ((access_flags \u0026amp; kAccNative) != 0) { // 编译 JNI 函数  compiled_method = driver-\u0026gt;GetCompiler()-\u0026gt;JniCompile(access_flags, method_idx, dex_file); } else if((access_flags \u0026amp; kAccAbstract) != 0) { // abstract 函数没有代码，不需要编译  } else { //编译其他函数  const VerifiedMethod* verified_method = driver-\u0026gt;GetVerificationResults()-\u0026gt;GetVerifiedMethod(method_ref); bool compile = compilation_enabled \u0026amp;\u0026amp; driver-\u0026gt;GetVerificationResults() -\u0026gt;IsCandidateForCompilation(method_ref, access_flags) \u0026amp;\u0026amp; verified_method != nullptr \u0026amp;\u0026amp; !verified_method-\u0026gt;HasRuntimeThrow() \u0026amp;\u0026amp; (verified_method-\u0026gt;GetEncounteredVerificationFailures() \u0026amp; (verifier::VERIFY_ERROR_FORCE_INTERPRETER | verifier::VERIFY_ERROR_LOCKING)) == 0 \u0026amp;\u0026amp; driver-\u0026gt;IsMethodToCompile(method_ref) \u0026amp;\u0026amp; driver-\u0026gt;ShouldCompileBasedOnProfile(method_ref);// 如果是profile-guide编译，需要检查是否是 profile中指定的函数，如果不是，则不编译该函数  if (compile) { // NOTE: if compiler declines to compile this method, it will return null.  compiled_method = driver-\u0026gt;GetCompiler()-\u0026gt;Compile(code_item, access_flags, invoke_type, class_def_idx, method_idx, class_loader, dex_file, dex_cache); } ... driver-\u0026gt;AddCompiledMethod(method_ref, compiled_method, non_relative_linker_patch_count);//把编译得到的 compiled-method 添加到 compiler-driver中，以便后面生成oat文件时使用  } bool CompilerDriver::ShouldCompileBasedOnProfile(const MethodReference\u0026amp; method_ref) const { if (profile_compilation_info_ == nullptr) { // If we miss profile information it means that we don\u0026#39;t do a profile guided compilation.  // Return true, and let the other filters decide if the method should be compiled.  return true; } bool result = profile_compilation_info_-\u0026gt;ContainsMethod(method_ref);// 判断当前method是不是在前面 load到的 profile 中  return result; compiled-method 的生成过程，是真正ART编译器工作的过程，使用了图等算法进行编译，非常复杂，这里不再详述，总之，这个过程中，完成了dalvik bytecode 到 native code的转化以及一定的优化，到这一步，我们得到了产出： compiled-method，ART运行过程中，执行函数时，如果这个函数被编译过，那么就会执行其对应的 compiled-method，否则继续解释执行其对应的 dalvik bytecode。\nCompile流程总结  PreCompile 做一些准备工作，ResolveClass（可以认为是从dex文件中构造class到内存中），VerifyClass（验证错误），InitializeClass（初始化）等动作，做一些过滤动作，比如把verify失败的class过滤掉 Compile过程，多线成编译，线程数目是 CPU count -1， 最小编译单位是 method，依次按照method所在 dex，所在class进行编译 ==如果存在profile的情况下，Verify过程只对profile中存在的Class进行verify，CompileMethod过程，只对profile中存在的method进行编译== 编译后生成的compiled-method 放到 compiler-driver中，以备在dex2oat中，准备写入OAT文件时使用  OAT 文件写入流程 在Compile流程结束后，会进行OAT文件的写入操作。\nenum class WriteState { kAddingDexFileSources, // 添加dex文件到 oat文件中  kPrepareLayout, //准备文件布局  kWriteRoData, //写入RoData  kWriteText, //写入代码段  kWriteHeader, // 写入 oat header  kDone // 写入完成  } 从OatWriteState可以看到，其写入oat文件的流程。\n AddDexFileSource，在dex2oat Setup时，就已经将将要编译的dex file 写入到 OatWriter 中，并设置 write_state_ = WriteState::kPrepareLayout; 后续的步骤都在编译完成后，由 WriteOatFiles 完成 kPrepareLayout，初始化 OatClass，OatMaps，OatCode， 准备OatMethod信息 和 bss段的DexCacheArray kWriteRoData，写入 readOnly 数据，依次写入 ClassOffset，写入 OatClass，写入函数的vmap Table，写入 padding kWriteText，对于要生成 bootimage时，写入trampoline，对与app只写入quick code kWriteHeader，填充 Oat Header信息，写入到oat文件  bool Setup() { CreateOatWriters(); if (!AddDexFileSources()) { return false; } } bool WriteOatFiles() { if (IsImage()) { // 如果本次dex2oat要生成 image，则会在写入 oat文件时，做准备工作  image_writer_.reset(new ImageWriter(*driver_, image_base_, compiler_options_-\u0026gt;GetCompilePic(),IsAppImage(), image_storage_mode_, oat_filenames_, dex_file_oat_index_map_)); if (!image_writer_-\u0026gt;PrepareImageAddressSpace()) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to prepare image address space.\u0026#34;; return false; } } oat_writer-\u0026gt;PrepareLayout(driver_.get(), image_writer_.get(), dex_files, \u0026amp;patcher); size_t rodata_size = oat_writer-\u0026gt;GetOatHeader().GetExecutableOffset(); size_t text_size = oat_writer-\u0026gt;GetSize() - rodata_size; elf_writer-\u0026gt;SetLoadedSectionSizes(rodata_size, text_size, oat_writer-\u0026gt;GetBssSize()); if (!oat_writer-\u0026gt;WriteRodata(rodata)) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to write .rodata section to the ELF file \u0026#34; \u0026lt;\u0026lt; oat_file-\u0026gt;GetPath(); return false; } OutputStream* text = elf_writer-\u0026gt;StartText(); if (!oat_writer-\u0026gt;WriteCode(text)) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to write .text section to the ELF file \u0026#34; \u0026lt;\u0026lt; oat_file-\u0026gt;GetPath(); return false; } if (!oat_writer-\u0026gt;WriteHeader(elf_writer-\u0026gt;GetStream(), image_file_location_oat_checksum_, image_file_location_oat_data_begin_, image_patch_delta_)) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to write oat header to the ELF file \u0026#34; \u0026lt;\u0026lt; oat_file-\u0026gt;GetPath(); return false; } OAT文件的写入流程就是按照这几个步骤完成，可以参照oat文件的加载完成OAT文件格式的详细了解。\nToc of my detailed dex2oat.vsdx below ParseArgs(argc, argv)\u0026ndash;\u0026gt;创建CompilerOptions OpenFile()创建目标oat文件 Setup() 创建VerificationResults verification_results_.reset(new VerificationResults(compiler_options_.get())); 配置QuickCompilerCallbacks 在做类校验时，外界可以传递一个回调接口对象。\n·当类校验失败时，该接口对象的ClassRejected函数将被调用。\n·当类的Java方法校验通过时，该接口对象的MethodVerified函数将被调用。\ncallbacks_.reset(new QuickCompilerCallbacks( verification_results_.get(),\u0026amp;method_inliner_map_, IsBootImage() ? CompilerCallbacks::CallbackMode::kCompileBootImage : CompilerCallbacks::CallbackMode::kCompileApp)); ClassRejected() MethodVerified() 去虚拟化de virtual得到concrete_method const VerifiedMethod* VerifiedMethod::Create( verifier::MethodVerifier* method_verifier, bool compile) { if (compile) {//compile为true时表示这个方法将会被编译。  //如果这个Java方法中有invoke-virtual或invoke-interface相关的指令，则下面if的条  //件满足  if (method_verifier-\u0026gt;HasVirtualOrInterfaceInvokes()) { //去虚拟化de virtual。下面将介绍这个函数  verified_method-\u0026gt;GenerateDevirtMap(method_verifier); } 创建elf_writers_和oat_writers_ 配置oat_writers_[0]中的oat_dex_files_ WriteAndOpenDexFiles_WriteTypeLookupTables CompileImage 在dex2oat中，一个Java方法根据其具体情况有三种编译处理模式\n1: dex到dex的编译\n2: jni方法的编译\n3: dex字节码到机器码的编译\ndex2oat.Compile compilerDriver.CompileAll ClassLinker.ResolveType,ResolveField和ResolveMethod void CompilerDriver::PreCompile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files,....) { ...... if ((never_verify || verification_enabled) \u0026amp;\u0026amp; !verify_only_profile) { /*下面的Resolve函数主要工作为遍历dex文件，然后： （1）解析其中的类型，即遍历dex文件里的type_ids数组。内部将调用ClassLinker的ResolveType函数。 （2）解析dex里的类、成员变量、成员函数。内部将调用ClassLinker的ResolveType、ResolveField和ResolveMethod等函数。读者可回顾8.7.8.1节的内容。 */ Resolve(class_loader, dex_files, timings); } /*下面两个函数的作用： （1）Verify：遍历dex文件，校验其中的类。校验结果通过QuickCompilationCallback存储在 CompilerDriver的verification_results_中。 （2）InitializeClasses：遍历dex文件，确保类的初始化。*/ Verify(class_loader, dex_files, timings); InitializeClasses(class_loader, dex_files, timings); } CompileDexFile void CompilerDriver::Compile(jobject class_loader, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, TimingLogger* timings) { for (const DexFile* dex_file : dex_files) { CompileDexFile(class_loader,*dex_file,dex_files,......); ...... } void CompilerDriver::CompileDexFile(jobject class_loader, const DexFile\u0026amp; dex_file, const std::vector\u0026lt;const DexFile*\u0026gt;\u0026amp; dex_files, ThreadPool* thread_pool, size_t thread_count, TimingLogger* timings) { CompileClassVisitor visitor(\u0026amp;context); /*context.ForAll将触发线程池进行编译工作。注意，编译是以类为单位进行处理的，每一个待编译 的类都会交由CompileClassVisitor的Visit函数进行处理。*/ context.ForAll(0, dex_file.NumClassDefs(), \u0026amp;visitor, thread_count); } //编译时，编译线程将调用下面的这个Visit函数，参数为待处理类在dex文件里class_ids数组中的索引  virtual void Visit(size_t class_def_index) ..... { //遍历direct的Java方法  int64_t previous_direct_method_idx = -1; while (it.HasNextDirectMethod()) { uint32_t method_idx = it.GetMemberIndex(); ..... previous_direct_method_idx = method_idx; CompileMethod(soa.Self(), driver, it.GetMethodCodeItem(), it.GetMethodAccessFlags(),it.GetMethodInvokeType(class_def), class_def_index, method_idx, jclass_loader, dex_file, dex_to_dex_compilation_level,compilation_enabled, dex_cache); it.Next(); } //编译虚函数，也是调用CompileMethod函数  } CompileMethod() driver-\u0026gt;AddCompiledMethod() WriteOatFiles输出.oat文件 HandleImage处理.art文件 Detail in dex2oat.vsdx "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/1%E7%B1%BB%E7%BC%96%E8%AF%91/dex2oat%E4%BB%8B%E7%BB%8D/",
	"title": "dex2oat介绍",
	"tags": [],
	"description": "",
	"content": "pre-compilation的好处 graph LR AOT--\u0026gt;Fast AOT--\u0026gt;cleanMemory Code pre-compilation: We pre-compile all the hot code. When the apps execute, the most important parts of the code are already optimized and ready to be natively executed. The app no longer needs to wait for the JIT compiler to kick in.\nThe benefit is that the code is mapped as clean memory (compared to the JIT dirty memory) which improves the overall memory efficiency. The clean memory can be released by the kernel when under memory pressure while the dirty memory cannot, lessening the chances that the kernel will kill the app.\noat文件 JVM执行 java 字节码， Dalvik执行 dalvik 字节码。\nART（Android Runtime），是Android4.4上开始提供的另一个 JVM实现，在4.4时，默认的虚拟机还是 dalvik，ART作为可选项，到Android5.0，开始作为Android默认的虚拟机。\n同样的，ART也支持运行 dalvik bytecode（否则没有办法兼容之前的app），另外 ART 提出了一个 AOT（Ahead of time）的方法。\n这个 AOT就是相对于 1.2节中提到的 JIT， AOT是说在代码运行之前进行编译。即把dex文件中的 dalvik bytecode编译为处理器可识别执行的汇编指令，我们把编译后生成的代码称为Native code。\n而==OAT文件就是包含了dex文件，dex文件编译出的 native Code，以及OAT header，OAT class等组织文件的数据==。\n在==使用oat文件的时候，通过这些组织关系，来查找一个类中java函数对应的 native code，从而在执行时去运行 native code==;\n实际上app编译出来的==OAT文件是一种特殊的ELF文件，在这个ELF文件的 oatdata 和 oatlastword之间的数据为oat数据。也即 oat文件数据是嵌入在ELF文件中的==。\nART运行的时候，会查询当前app对应的 oat文件进行执行，当找不到oat文件时再解释dex的 bytecode 执行。\n简单来讲：ART执行 oat文件，执行其中 java 函数对应 native code; 当函数没有对应的native code或者app没有对应的oat文件时，仍然解释执行dex文件中其对应的 dalvik bytecode。\nprofile文件 图解 graph LR createProfile--\u0026gt;|create_app_data|installd recordProfile--\u0026gt;|start thread|LoadedApk.getClassLoader--\u0026gt;|record classId and methodId|record(\u0026quot;ProfileSaver::Start(profilName)\u0026quot;) recordProfile--\u0026gt;|record|BackgroundDexOptService 参考应用启动流程\nAndroid7.0之后，ART使用的文件，用来进行 profile-guide编译，即指导 dex2oat 如何编译 dex文件\nprofile文件：/data/misc/profiles/cur/0/com.***.home/primary.prof\n==每个app的profile文件都在 /data/misc/profiles/ 目录下==。profile文件用来记录运行比较频繁的代码，用来进行 profile-guide 编译，使得 dex2oat编译代码更精准。\nprofile的创建： App安装的过程中，会调用到 installd的 create_app_data()函数，\n如果当前支持profile编译，则会为app创建 profile文件。\nAndroid7.1:\n/frameworks/native/cmds/installd/commands.cpp int create_app_data(const char *uuid, const char *pkgname, userid_t userid, int flags, appid_t appid, const char* seinfo, int target_sdk_version) { ... if (property_get_bool(\u0026#34;dalvik.vm.usejitprofiles\u0026#34;)) { std::string profile_file = create_primary_profile(profile_path);//组织 profile文件所在路径  if (fs_prepare_file_strict(profile_file.c_str(), 0600, uid, uid) != 0) {//在这里创建 profile文件，且只对owner Read-Write  return -1; } ... } profile信息的收集 在App启动的时候，开启profile的收集线程：\n-\u0026gt;ActivityThread.main() -\u0026gt;... -\u0026gt;ActivityThread.performLaunchActivity() -\u0026gt;ActivityClientRecord.packageInfo.getClassLoader() -\u0026gt;LoadedApk.getClassLoader() -\u0026gt;setupJitProfileSupport() VMRuntime.registerAppInfo(profileName） Runtime::RegisterAppInfo(profileName) jit_-\u0026gt; StartProfileSaver(profileName) ProfileSaver::Start(profilName)//在这里会创建一个thread 用来收集 resolved class与method  ProfileSaver::Run() { FetchAndCacheResolvedClassesAndMethods(); bool profile_saved_to_disk = ProcessProfilingInfo(\u0026amp;new_methods); // 在这个方法中会把达到条件的 methodId 和 classid记录到 profile文件  在这个方法中，会编译当前进程中所有已经Load的Class，如果这些class是apk中的class，则将会被添加到 profile信息中。\n对于要记录的 method则需要达到一定的条件（函数的调用次数）,函数调用次数有以下几个 threshold：\nuint16_t hot_method_threshold_; uint16_t warm_method_threshold_; uint16_t osr_method_threshold_; 在解释执行一个函数时，会调用 AddSamples函数，从而会记录函数的调用次数。从而生成profile文件。生成的profile文件格式如下：\nprofile文件格式： /** * Serialization format: * magic,version,number_of_lines * dex_location1,number_of_methods1,number_of_classes1,dex_location_checksum1, \\ * method_id11,method_id12...,class_id1,class_id2... * dex_location2,number_of_methods2,number_of_classes2,dex_location_checksum2, \\ * method_id21,method_id22...,,class_id1,class_id2... * ..... **/ profile文件 的查看:\nxxxx:/data/misc/profiles/cur/0/com.***.home # profman --profile-file=primary.prof --dump-only  === profile === ProfileInfo: XXXHome.apk methods: 1824,1837,1843,1846,1907,1908,...... classes: 62,63,64,68,69,74,75,77,79,83,86,...... 其中：\nXXXHome.apk表示 dex文件的位置，如果这个apk中有多个dex，比如 classes.dex 和 classes2.dex，则classes2.dex中的类，则以 XXXHome.apk:classes2.dex 命名。\nmethods 和 classes 后面的数据，表示他们在dex文件中的index。\n我们使用profile模式 dex2oat编译时，会只编译profile中记录的这些 class 和 methods。\nApp-image 文件 /data/app/com.facebook.katana-1/oat/arm/base.art /data/app/com.facebook.katana-1/oat/arm/base.odex base.art就是对应的 app-image文件。\nbase.art文件主要记录已经编译好的类的具体信息以及函数在oat文件的位置，相当于缓存，在app运行的时候会加载到虚拟机，可以加快启动速度。\napp-image文件是Android7.0之后，ART使用的文件，它是App使用的类以及函数数据的缓存，在app启动的使用mmap到内存空间，以加快app启动速度，App启动过程越复杂，使用app-image时的提升越明显\nApp Images: We use the start up classes to build a pre-populated heap where the classes are pre-initialized (called an app image). When the application starts, we map the image directly into memory so that all the startup classes are readily available.\nThe benefit here is that the app\u0026rsquo;s execution saves cycles since it doesn\u0026rsquo;t need to do the work again, leading to a faster startup time.\napp-image如何使用 app-image在App启动的过程中加载，加载流程如下：\n参考应用启动流程\n-\u0026gt;ActivityThread.main() -\u0026gt;... -\u0026gt;ActivityThread.performLaunchActivity() -\u0026gt;ActivityClientRecord.packageInfo.getClassLoader() -\u0026gt;LoadedApk.getClassLoader() -\u0026gt;LoadedApk.createOrUpdateClassLoaderLocked() -\u0026gt;ApplicationLoaders.getDefault().getClassLoader() -\u0026gt;new PathClassLoader() -\u0026gt;new BaseDexClassLoader() -\u0026gt;new DexPathList() -\u0026gt;makePathElements -\u0026gt;loadDexFile -\u0026gt;new DexFile（） -\u0026gt;openDexFile() -\u0026gt;openDexFileNative -\u0026gt;openDexFilesFromOat() -\u0026gt;OpenImageSpace(source_oat_file)// 在这里尝试打开oat文件对应的image文件， -\u0026gt; heap -\u0026gt;AddSpace(image_space); -\u0026gt; class_linker -\u0026gt;AddImageSpace(image-space) class_linker的 AddImageSpace中会调用 UpdateAppImageClassLoadersAndDexCaches()方法:\nbool ClassLinker::UpdateAppImageClassLoadersAndDexCaches( ... ClassTable* table = InsertClassTableForClassLoader(class_loader.Get()); for (size_t i = 0; i \u0026lt; num_dex_caches; i++) { mirror::DexCache* const dex_cache = dex_caches-\u0026gt;Get(i); const DexFile* const dex_file = dex_cache-\u0026gt;GetDexFile(); RegisterDexFileLocked(*dex_file, hs3.NewHandle(dex_cache)); GcRoot\u0026lt;mirror::Class\u0026gt;* const types = dex_cache-\u0026gt;GetResolvedTypes(); const size_t num_types = dex_cache-\u0026gt;NumResolvedTypes(); for (int32_t j = 0; j \u0026lt; static_cast\u0026lt;int32_t\u0026gt;(num_types); j++) { mirror::Class* klass = types[j].Read(); if (space-\u0026gt;HasAddress(klass)) { klass-\u0026gt;SetClassLoader(class_loader.Get()); } table-\u0026gt;Insert(klass); } ... ==在这个函数中，会把app-image中的所有类的 classLoader更新为当前的 classLoader，并将它们添加到当前的ClassLoader的class table中;之后在当前进程中有使用相关类时，在FindClass过程中，直接就能在 class table中找到，即可使用，免去了类的加载。至此，app进程在后续的运行中，就可以直接使用app-image中的类了==。\noatdump xxx:/data/dalvik-cache/arm # oatdump --app-image=system@priv-app@Browser@Browser.apk@classes.art --app-oat=system@priv-app@Browser@Browser.apk@classes.dex --image=/system/framework/boot.art --instruction-set=arm --header-only 获取完整数据可以把 header-only 参数去掉即可。\ndex2oat dex2oat 是什么 dex2oat是一个可执行程序，在手机的 /system/bin/dex2oat，它的作用是编译dex文件，生成oat文件。\ndex文件被编译为 oat文件的过程，就是由 /system/bin/dex2oat 程序触发的; 而实际上编译业务是在 libart-compiler.so中做的。\n== dex2oat（dex文件） =\u0026gt; oat文件/image文件==\ndex2oat 什么时候被触发 dex2oat进程的启动，可以分为两大类：一类是 installd进程触发的dex2oat；另一类是由 app中直接调用的 dex2oat。\ninstalld 中触发的 dex2oat 有以下几个场景：\n1.应用安装，（包括普通安装和通过shellCmd安装），安装一个app时，安装过程中需要编译dex文件，会通知installd来触发一个dex2oat进程;\n2.开机扫描，开机过程中，PMS扫描已安装app过程，判断需要优化时，则会对install发出通知;\n3.BackgroundDexOptService，（空闲时段或者开机之后触发的Backgroud的 Job），会通知installd进行dex2oat;\n4.OTADexoptService，好象是OTA过程中的触发的，这个场景没有进行过实际的验证;\napp中调用 dex2oat 一般是App的进程fork出一个子进程，子进程用来执行dex2oat，编译相关的dex，而父进程进行 waitpid 等待，等待完成后再运行其他逻辑。\n比如：\n1.微信安装后的首次启动，是有dex2oat的调用\n2.淘宝安装后的首次搜索，也有dex2oat的调用\n这个也是其首次启动或者搜索的一个耗时点。\ndex2oat生成oat和app-image文件 dex2oat --dex-file=/data/app/com.facebook.katana-1/base.apk --app-image-file=/data/app/com.facebook.katana-1/oat/arm/base.art --oat-file=/data/app/com.facebook.katana-1/oat/arm/base.odex --instruction-set=arm --instruction-set-variant=kryo --instruction-set-features=default --runtime-arg -Xms64m --runtime-arg -Xmx512m --compiler-filter=interpret-only --image-format=lz4 --runtime-arg -classpath --runtime-arg /system/framework/com.google.android.maps.jar 三段式编译模型 图2 基于LLVM架构开发的编译器执行过程\n图3 利用现成的与语言无关的优化器和后端为语言相关的前端生成各种体系结构相关的机器指令\nELF格式的oat文件 图4 ART翻译classes.dex后得到的ELF格式的oat文件\n参考 Other site Android profile-guided dex2oat\nhttps://android-developers.googleblog.com/2019/04/improving-app-performance-with-art.html\nAndroid运行时ART简要介绍和学习计划\nAndroid运行时ART加载OAT文件的过程分析\ndex2oat源码流程分析\nART世界探险(16) - 快速编译器下的方法编译\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/dex%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/",
	"title": "Dex文件格式",
	"tags": [],
	"description": "",
	"content": "Dex文件格式 https://source.android.com/devices/tech/dalvik/dex-format\nFile layout\n   名称 格式 说明     header header_item 标头   string_ids string_id_item[] 字符串标识符列表。这些是此文件使用的所有字符串的标识符，用于内部命名（例如类型描述符）或用作代码引用的常量对象。此列表必须使用 UTF-16 代码点值按字符串内容进行排序（不采用语言区域敏感方式），且不得包含任何重复条目。   type_ids type_id_item[] 类型标识符列表。这些是此文件引用的所有类型（类、数组或原始类型）的标识符（无论文件中是否已定义）。此列表必须按 string_id 索引进行排序，且不得包含任何重复条目。   proto_ids proto_id_item[] 方法原型标识符列表。这些是此文件引用的所有原型的标识符。此列表必须按返回类型（按 type_id 索引排序）主要顺序进行排序，然后按参数列表（按 type_id 索引排序的各个参数，采用字典排序方法）进行排序。该列表不得包含任何重复条目。   field_ids field_id_item[] 字段标识符列表。这些是此文件引用的所有字段的标识符（无论文件中是否已定义）。此列表必须进行排序，其中定义类型（按 type_id 索引排序）是主要顺序，字段名称（按 string_id 索引排序）是中间顺序，而类型（按 type_id 索引排序）是次要顺序。该列表不得包含任何重复条目。   method_ids method_id_item[] 方法标识符列表。这些是此文件引用的所有方法的标识符（无论文件中是否已定义）。此列表必须进行排序，其中定义类型（按 type_id 索引排序）是主要顺序，方法名称（按 string_id 索引排序）是中间顺序，而方法原型（按 proto_id 索引排序）是次要顺序。该列表不得包含任何重复条目。   class_defs class_def_item[] 类定义列表。这些类必须进行排序，以便所指定类的超类和已实现的接口比引用类更早出现在该列表中。此外，对于在该列表中多次出现的同名类，其定义是无效的。   call_site_ids call_site_id_item[] 调用站点标识符列表。这些是此文件引用的所有调用站点的标识符（无论文件中是否已定义）。此列表必须按 call_site_off 以升序进行排序。   method_handles method_handle_item[] 方法句柄列表。此文件引用的所有方法句柄的列表（无论文件中是否已定义）。此列表未进行排序，而且可能包含将在逻辑上对应于不同方法句柄实例的重复项。   data ubyte[] 数据区，包含上面所列表格的所有支持数据。不同的项有不同的对齐要求；如有必要，则在每个项之前插入填充字节，以实现所需的对齐效果。   link_data ubyte[] 静态链接文件中使用的数据。本文档尚未指定本区段中数据的格式。此区段在未链接文件中为空，而运行时实现可能会在适当的情况下使用这些数据。    Dalvik-Bytecode https://source.android.google.cn/devices/tech/dalvik/dalvik-bytecode\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/di/di/",
	"title": "DI",
	"tags": [],
	"description": "",
	"content": "依赖注入进化过程 graph LR HardCode(HardCodeDependency)--\u0026gt;|进化|ServiceLocator HardCode--\u0026gt;|进化|ManualDI--\u0026gt;|进化|Dagger subgraph AutomatedDI Dagger--\u0026gt;Hilt end Dependency injection in Android Dependency injection (DI) is a technique widely used in programming and well suited to Android development. By following the principles of DI, you lay the groundwork for good app architecture.\nImplementing dependency injection provides you with the following advantages:\n Reusability of classes and decoupling of dependencies: It\u0026rsquo;s easier to swap out implementations of a dependency. Code reuse is improved because of inversion of control, and classes no longer control how their dependencies are created, but instead work with any configuration.通过替换被依赖者的具体实现，提升依赖者的复用性 Ease of refactoring,The dependencies become a verifiable part of the API surface, so they can be checked at object-creation time or at compile time rather than being hidden as implementation details. Ease of testing,A class doesn\u0026rsquo;t manage its dependencies, so when you\u0026rsquo;re testing it, you can pass in different implementations to test all of your different cases.方便测试时进行mock替换被依赖者，完成不同场景的测试用例覆盖 对象的构造和对象的使用分离，上层的使用者不用关心在哪里以及如何获取下层实例，直接使用构造方法传入的实例即可 依赖者内部自行构造被依赖者，造成两者耦合，无法替换新的被依赖者实现  What is dependency injection? Classes often require references to other classes. For example, a Car class might need a reference to an Engine class. These required classes are called dependencies, and in this example the Car class is dependent on having an instance of the Engine class to run.\nThere are three ways for a class to get an object it needs:\n The class constructs the dependency it needs. In the example above, Car would create and initialize its own instance of Engine. Grab it from somewhere else. Some Android APIs, such as Context getters and getSystemService(), work this way. Have it supplied as a parameter. The app can provide these dependencies when the class is constructed or pass them in to the functions that need each dependency. In the example above, the Car constructor would receive Engine as a parameter.  The third option is dependency injection! With this approach you take the dependencies of a class and provide them rather than having the class instance obtain them itself.\nWays to do dependency injection There are two major ways to do dependency injection in Android:\n Constructor Injection. This is the way described above. You pass the dependencies of a class to its constructor. Field Injection (or Setter Injection). Certain Android framework classes such as activities and fragments are instantiated by the system, so constructor injection is not possible. With field injection, dependencies are instantiated after the class is created. The code would look like this:  Manual dependency injection Manual dependency injection also presents several problems:\n For big apps, taking all the dependencies and connecting them correctly can require a large amount of boilerplate code. In a multi-layered architecture, in order to create an object for a top layer, you have to provide all the dependencies of the layers below it. As a concrete example, to build a real car you might need an engine, a transmission, a chassis, and other parts; and an engine in turn needs cylinders and spark plugs. When you\u0026rsquo;re not able to construct dependencies before passing them in — for example when using lazy initializations or scoping objects to flows of your app — you need to write and maintain a custom container (or graph of dependencies) that manages the lifetimes of your dependencies in memory.  Automated dependency injection There are libraries that solve this problem by automating the process of creating and providing dependencies. They fit into two categories:\n Reflection-based solutions that connect dependencies at runtime. Static solutions that generate the code to connect dependencies at compile time.  Dagger is a popular dependency injection library for Java, Kotlin, and Android that is maintained by Google. Dagger facilitates using DI in your app by creating and managing the graph of dependencies for you. It provides fully static and compile-time dependencies addressing many of the development and performance issues of reflection-based solutions such as Guice.\nAlternatives to dependency injection:ServiceLocator object ServiceLocator { fun getEngine(): Engine = Engine() } class Car { private val engine = ServiceLocator.getEngine() fun start() { engine.start() } } fun main(args: Array) { val car = Car() car.start() } The service locator pattern is different from dependency injection in the way the elements are consumed. With the service locator pattern, classes have control and ask for objects to be injected; with dependency injection, the app has control and proactively injects the required objects.\nCompared to dependency injection:\n The collection of dependencies required by a service locator makes code harder to test because all the tests have to interact with the same global service locator. Dependencies are encoded in the class implementation, not in the API surface. As a result, it\u0026rsquo;s harder to know what a class needs from the outside. As a result, changes to Car or the dependencies available in the service locator might result in runtime or test failures by causing references to fail. Managing lifetimes of objects is more difficult if you want to scope to anything other than the lifetime of the entire app.  Use Hilt in your Android app Hilt is Jetpack\u0026rsquo;s recommended library for dependency injection in Android. Hilt defines a standard way to do DI in your application by providing containers for every Android class in your project and managing their lifecycles automatically for you.\nHilt is built on top of the popular DI library Dagger to benefit from the compile time correctness, runtime performance, scalability, and Android Studio support that Dagger provides.\nTo learn more about Hilt see Dependency Injection with Hilt.\n总结  架构中上层需要通过构造方法传入下层的依赖 上述依赖的对象要通过依赖注入框架注入  依赖注入框架 graph TB subgraph hilt subgraph dagger javax.inject end end Dagger https://developer.android.com/training/dependency-injection/dagger-basics\ngraph TB Providers1(\u0026quot;@Provides1\u0026quot;)--\u0026gt;|dependency|Providers2(\u0026quot;@Provides2\u0026quot;) Providers1--\u0026gt;|dependency|Inject1(\u0026quot;@Inject1\u0026quot;) Providers2--\u0026gt;|dependency|Inject2(\u0026quot;@Inject2\u0026quot;) Providers2--\u0026gt;|dependency|Inject3(\u0026quot;@Inject3\u0026quot;) Inject3--\u0026gt;|dependency|Provides3(\u0026quot;@Provides3\u0026quot;) @Inject constructor Add an @Inject annotation to the UserRepository constructor so Dagger knows how to create a UserRepository:\n// @Inject lets Dagger know how to create instances of this object class UserRepository @Inject constructor( private val localDataSource: UserLocalDataSource, private val remoteDataSource: UserRemoteDataSource ) { ... } In the above snippet of code, you\u0026rsquo;re telling Dagger:\n How to create a UserRepository instance with the @Inject annotated constructor. What its dependencies are: UserLocalDataSource and UserRemoteDataSource.  Now Dagger knows how to create an instance of UserRepository, but it doesn\u0026rsquo;t know how to create its dependencies. If you annotate the other classes too, Dagger knows how to create them:\n// @Inject lets Dagger know how to create instances of these objects class UserLocalDataSource @Inject constructor() { ... } class UserRemoteDataSource @Inject constructor() { ... } field Instead of creating the dependencies an activity requires in the onCreate() method, you want Dagger to populate those dependencies for you. For field injection, you instead apply the @Inject annotation to the fields that you want to get from the Dagger graph.\nclass LoginActivity: Activity() { // You want Dagger to provide an instance of LoginViewModel from the graph  @Inject lateinit var loginViewModel: LoginViewModel } ,you need to tell Dagger about an object (LoginActivity in this case) that requires a dependency to be injected. For that, you expose a function that takes as a parameter the object that requests injection.\n@Component interface ApplicationComponent { // This tells Dagger that LoginActivity requests injection so the graph needs to  // satisfy all the dependencies of the fields that LoginActivity is requesting.  fun inject(activity: LoginActivity) } class LoginActivity: Activity() { // You want Dagger to provide an instance of LoginViewModel from the graph  @Inject lateinit var loginViewModel: LoginViewModel override fun onCreate(savedInstanceState: Bundle?) { // Make Dagger instantiate @Inject fields in LoginActivity  (applicationContext as MyApplication).appComponent.inject(this) // Now loginViewModel is available  super.onCreate(savedInstanceState) } } // @Inject tells Dagger how to create instances of LoginViewModel class LoginViewModel @Inject constructor( private val userRepository: UserRepository ) { ... } @Component @Component tells Dagger to generate a container with all the dependencies required to satisfy the types it exposes. This is called a Dagger component; it contains a graph that consists of the objects that Dagger knows how to provide and their respective dependencies.\n// @Component makes Dagger create a graph of dependencies @Component interface ApplicationGraph { // The return type of functions inside the component interface is  // what can be provided from the container  fun repository(): UserRepository } // The \u0026#34;modules\u0026#34; attribute in the @Component annotation tells Dagger what Modules // to include when building the graph @Component(modules = [NetworkModule::class]) interface ApplicationComponent { ... } Scoping To have a unique instance of a UserRepository when you ask for the repository in ApplicationGraph, use the same scope annotation for the @Component interface and UserRepository. You can use the @Singleton annotation that already comes with the javax.inject package that Dagger uses:\n// Scope annotations on a @Component interface informs Dagger that classes annotated // with this annotation (i.e. @Singleton) are bound to the life of the graph and so // the same instance of that type is provided every time the type is requested. @Singleton @Component interface ApplicationGraph { fun repository(): UserRepository } // Scope this class to a component using @Singleton scope (i.e. ApplicationGraph) @Singleton class UserRepository @Inject constructor( private val localDataSource: UserLocalDataSource, private val remoteDataSource: UserRemoteDataSource ) { ... } Alternatively, you can create and use a custom scope annotation. You can create a scope annotation as follows:\n// Creates MyCustomScope @Scope @MustBeDocumented @Retention(value = AnnotationRetention.RUNTIME) annotation class MyCustomScope Then, you can use it as before:\n@MyCustomScope @Component interface ApplicationGraph { fun repository(): UserRepository } @MyCustomScope class UserRepository @Inject constructor( private val localDataSource: UserLocalDataSource, private val service: UserService ) { ... } In both cases, the object is provided with the same scope used to annotate the @Component interface. Thus, every time you call applicationGraph.repository(), you get the same instance of UserRepository.\nval applicationGraph: ApplicationGraph = DaggerApplicationGraph.create() val userRepository: UserRepository = applicationGraph.repository() val userRepository2: UserRepository = applicationGraph.repository() assert(userRepository == userRepository2) @Module Apart from the @Inject annotation, there\u0026rsquo;s another way to tell Dagger how to provide an instance of a class: the information inside Dagger modules. A Dagger module is a class that is annotated with @Module. There, you can define dependencies with the @Provides annotation.\n// @Module informs Dagger that this class is a Dagger Module @Module class NetworkModule { // @Provides tell Dagger how to create instances of the type that this function  // returns (i.e. LoginRetrofitService).  // Function parameters are the dependencies of this type.  @Provides fun provideLoginRetrofitService(): LoginRetrofitService { // Whenever Dagger needs to provide an instance of type LoginRetrofitService,  // this code (the one inside the @Provides method) is run.  return Retrofit.Builder() .baseUrl(\u0026#34;https://example.com\u0026#34;) .build() .create(LoginService::class.java) } } You can use the @Provides annotation in Dagger modules to tell Dagger how to provide classes that your project doesn\u0026rsquo;t own (e.g. an instance of Retrofit).\n@Provides @Provides, the most common construct for configuring a binding, serves three functions:\n Declare which type (possibly qualified) is being provided — this is the return type Declare dependencies — these are the method parameters Provide an implementation for exactly how the instance is provided — this is the method body  @Binds Annotates abstract methods of a Module that delegate bindings. For example, to bind Random to SecureRandom a module could declare the following: @Binds abstract Random bindRandom(SecureRandom secureRandom);\n@Binds methods are a drop-in replacement for Provides methods that simply return an injected parameter. Prefer @Binds because the generated implementation is likely to be more efficient.\nA @Binds method:\n Must be abstract. May be scoped. May be qualified. Must have a single parameter whose type is assignable to the return type. The return type declares the bound type (just as it would for a @Provides method) and the parameter is the type to which it is bound.  @Subcomponent // @Subcomponent annotation informs Dagger this interface is a Dagger Subcomponent @Subcomponent interface LoginComponent { // This tells Dagger that LoginActivity requests injection from LoginComponent  // so that this subcomponent graph needs to satisfy all the dependencies of the  // fields that LoginActivity is injecting  fun inject(loginActivity: LoginActivity) } You also must define a subcomponent factory inside LoginComponent so that ApplicationComponent knows how to create instances of LoginComponent.\n@Subcomponent interface LoginComponent { // Factory that is used to create instances of this subcomponent  @Subcomponent.Factory interface Factory { fun create(): LoginComponent } fun inject(loginActivity: LoginActivity) } To tell Dagger that LoginComponent is a subcomponent of ApplicationComponent, you have to indicate it by:\n Creating a new Dagger module (e.g. SubcomponentsModule) passing the subcomponent\u0026rsquo;s class to the subcomponents attribute of the annotation.  // The \u0026#34;subcomponents\u0026#34; attribute in the @Module annotation tells Dagger what // Subcomponents are children of the Component this module is included in. @Module(subcomponents = LoginComponent::class) class SubcomponentsModule {} Adding the new module (i.e. SubcomponentsModule) to ApplicationComponent:  // Including SubcomponentsModule, tell ApplicationComponent that // LoginComponent is its subcomponent. @Singleton @Component(modules = [NetworkModule::class, SubcomponentsModule::class]) interface ApplicationComponent { } Consumers of ApplicationComponent need to know how to create instances of LoginComponent. The parent component must add a method in its interface to let consumers create instances of the subcomponent out of an instance of the parent component:\nExpose the factory that creates instances of LoginComponentin the interface:  @Singleton @Component(modules = [NetworkModule::class, SubcomponentsModule::class]) interface ApplicationComponent { // This function exposes the LoginComponent Factory out of the graph so consumers // can use it to obtain new instances of LoginComponent fun loginComponent(): LoginComponent.Factory } Assigning scopes to subcomponents What\u0026rsquo;s the lifecycle of LoginComponent? One of the reasons why you needed LoginComponent is because you needed to share the same instance of the LoginViewModel between Login-related fragments. But also, you want different instances of LoginViewModel whenever there\u0026rsquo;s a new login flow. LoginActivity is the right lifetime for LoginComponent: for every new activity, you need a new instance of LoginComponent and fragments that can use that instance of LoginComponent.\nBecause LoginComponent is attached to the LoginActivity lifecycle, you have to keep a reference to the component in the activity in the same way you kept the reference to the applicationComponent in the application class. That way, fragments can access it.\nclass LoginActivity: Activity() { // Reference to the Login graph  lateinit var loginComponent: LoginComponent ... } Notice that the variable loginComponent is not annotated with @Inject because you\u0026rsquo;re not expecting that variable to be provided by Dagger.\nYou can use the ApplicationComponent to get a reference to LoginComponent and then inject LoginActivity as follows:\nclass LoginActivity: Activity() { // Reference to the Login graph  lateinit var loginComponent: LoginComponent // Fields that need to be injected by the login graph  @Inject lateinit var loginViewModel: LoginViewModel override fun onCreate(savedInstanceState: Bundle?) { // Creation of the login graph using the application graph  loginComponent = (applicationContext as MyDaggerApplication) .appComponent.loginComponent().create() // Make Dagger instantiate @Inject fields in LoginActivity  loginComponent.inject(this) // Now loginViewModel is available  super.onCreate(savedInstanceState) } } LoginComponent is created in the activity\u0026rsquo;s onCreate() method, and it\u0026rsquo;ll get implicitly destroyed when the activity gets destroyed.\nThe LoginComponent must always provide the same instance of LoginViewModel each time it\u0026rsquo;s requested. You can ensure this by creating a custom annotation scope and annotating both LoginComponent and LoginViewModel with it. Note that you cannot use the @Singleton annotation because it\u0026rsquo;s already been used by the parent component and that\u0026rsquo;d make the object an application singleton (unique instance for the whole app). You need to create a different annotation scope.\nBest practices when building a Dagger graph When building the Dagger graph for your application:\n When you create a component, you should consider what element is responsible for the lifetime of that component. In this case, the application class was in charge of ApplicationComponent and LoginActivity in charge of LoginComponent. Use scoping only when it makes sense. Overusing scoping can have a negative effect on your app\u0026rsquo;s runtime performance: the object is in memory as long as the component is in memory and getting a scoped object is more expensive. When Dagger provides the object, it uses DoubleCheck locking instead of a factory-type provider.  Hilt https://developer.android.com/training/dependency-injection/hilt-android\nEntryPoint @HiltAndroidApp @HiltAndroidApp triggers Hilt\u0026rsquo;s code generation, including a base class for your application that serves as the application-level dependency container.\n@HiltAndroidApp class ExampleApplication : Application() { ... } @AndroidEntryPoint generates an individual Hilt component for each Android class in your project. These components can receive dependencies from their respective parent classes as described in Component hierarchy.\nTo obtain dependencies from a component, use the @Inject annotation to perform field injection:\n@AndroidEntryPoint @AndroidEntryPoint class ExampleActivity : AppCompatActivity() { @Inject lateinit var analytics: AnalyticsAdapter ... } Define Hilt bindings To perform field injection, Hilt needs to know how to provide instances of the necessary dependencies from the corresponding component. A binding contains the information necessary to provide instances of a type as a dependency.\nOne way to provide binding information to Hilt is constructor injection. Use the @Inject annotation on the constructor of a class to tell Hilt how to provide instances of that class:\n@Inject constructor class AnalyticsAdapter @Inject constructor( private val service: AnalyticsService ) { ... } The parameters of an annotated constructor of a class are the dependencies of that class. In the example, AnalyticsAdapter has AnalyticsService as a dependency. Therefore, Hilt must also know how to provide instances of AnalyticsService.\nNote: At build time, Hilt generates Dagger components for Android classes. Then, Dagger walks through your code and performs the following steps:\n Builds and validates dependency graphs, ensuring that there are no unsatisfied dependencies and no dependency cycles. Generates the classes that it uses at runtime to create the actual objects and their dependencies.  Hilt modules Sometimes a type cannot be constructor-injected. This can happen for multiple reasons. For example, you cannot constructor-inject an interface. You also cannot constructor-inject a type that you do not own, such as a class from an external library. In these cases, you can provide Hilt with binding information by using Hilt modules.\nA Hilt module is a class that is annotated with @Module. Like a Dagger module, it informs Hilt how to provide instances of certain types. Unlike Dagger modules, you must annotate Hilt modules with @InstallIn to tell Hilt which Android class each module will be used or installed in.\n@InstallIn The Hilt module AnalyticsModule is annotated with @InstallIn(ActivityComponent::class) because you want Hilt to inject that dependency into ExampleActivity. This annotation means that all of the dependencies in AnalyticsModule are available in all of the app\u0026rsquo;s activities.\n@Binds The @Binds annotation tells Hilt which implementation to use when it needs to provide an instance of an interface.\nThe annotated function provides the following information to Hilt:\n The function return type tells Hilt what interface the function provides instances of. The function parameter tells Hilt which implementation to provide.  interface AnalyticsService { fun analyticsMethods() } // Constructor-injected, because Hilt needs to know how to // provide instances of AnalyticsServiceImpl, too. class AnalyticsServiceImpl @Inject constructor( ... ) : AnalyticsService { ... } @Module @InstallIn(ActivityComponent::class) abstract class AnalyticsModule { @Binds abstract fun bindAnalyticsService( analyticsServiceImpl: AnalyticsServiceImpl ): AnalyticsService } @Provides The annotated function supplies the following information to Hilt:\n The function return type tells Hilt what type the function provides instances of. The function parameters tell Hilt the dependencies of the corresponding type. The function body tells Hilt how to provide an instance of the corresponding type. Hilt executes the function body every time it needs to provide an instance of that type.  @Module @InstallIn(ActivityComponent::class) object AnalyticsModule { @Provides fun provideAnalyticsService( // Potential dependencies of this type  ): AnalyticsService { return Retrofit.Builder() .baseUrl(\u0026#34;https://example.com\u0026#34;) .build() .create(AnalyticsService::class.java) } } In cases where you need Hilt to provide different implementations of the same type as dependencies, you must provide Hilt with multiple bindings. You can define multiple bindings for the same type with qualifiers.\nA qualifier is an annotation that you use to identify a specific binding for a type when that type has multiple bindings defined.\nConsider the example. If you need to intercept calls to AnalyticsService, you could use an OkHttpClient object with an interceptor. For other services, you might need to intercept calls in a different way. In that case, you need to tell Hilt how to provide two different implementations of OkHttpClient.\nFirst, define the qualifiers that you will use to annotate the @Binds or @Provides methods:\n@Qualifier @Retention(AnnotationRetention.BINARY) annotation class AuthInterceptorOkHttpClient @Qualifier @Retention(AnnotationRetention.BINARY) annotation class OtherInterceptorOkHttpClient Then, Hilt needs to know how to provide an instance of the type that corresponds with each qualifier. In this case, you could use a Hilt module with @Provides. Both methods have the same return type, but the qualifiers label them as two different bindings:\n@Module @InstallIn(SingletonComponent::class) object NetworkModule { @AuthInterceptorOkHttpClient @Provides fun provideAuthInterceptorOkHttpClient( authInterceptor: AuthInterceptor ): OkHttpClient { return OkHttpClient.Builder() .addInterceptor(authInterceptor) .build() } @OtherInterceptorOkHttpClient @Provides fun provideOtherInterceptorOkHttpClient( otherInterceptor: OtherInterceptor ): OkHttpClient { return OkHttpClient.Builder() .addInterceptor(otherInterceptor) .build() } } You can inject the specific type that you need by annotating the field or parameter with the corresponding qualifier\nAs a best practice, if you add a qualifier to a type, add qualifiers to all the possible ways to provide that dependency. Leaving the base or common implementation without a qualifier is error-prone and could result in Hilt injecting the wrong dependency.\n参考 https://developer.android.com/training/dependency-injection\nScoping in Android and Hilt\nhttps://docs.oracle.com/javaee/6/api/javax/inject/package-summary.html\nDependency injection is based on the Inversion of Control principle in which generic code controls the execution of specific code.\nNote: By default, bindings in Hilt are unscoped. They are not part of any component and they can be accessed throughout the entire project. A different instance of that type will be provided every time it is requested. When you scope a binding to a component, it limits where that binding can be used and which dependencies the type can have.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/di/",
	"title": "di",
	"tags": [],
	"description": "",
	"content": "di 探索总结di知识\n DI     HiltSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/ndk/elf%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/",
	"title": "ELF文件结构",
	"tags": [],
	"description": "",
	"content": "文件结构 \u0026laquo;深入理解Android：Java虚拟机ART\u0026raquo;\u0026ndash;elf章的内容\nAs you can see from the description above, an ELF file consists of two sections – an ELF header, and file data. The file data section can consist of a program header table describing zero or more segments, a section header table describing zero or more sections, that is followed by data referred to by entries from the program header table, and the section header table. ==Each segment contains information that is necessary for run-time execution of the file, while sections contain important data for linking and relocation==. Figure 1 illustrates this schematically.\nThe ELF Header The ELF header is 32 bytes long, and identifies the format of the file. It starts with a sequence of four unique bytes that are 0x7F followed by 0x45, 0x4c, and 0x46 which translates into the three letters E, L, and F.\nAmong other values, the header also indicates\n whether it is an ELF file for 32 or 64-bit format, uses little or big endianness shows the ELF version for which operating system the file was compiled for in order to interoperate with the right application binary interface (ABI) and cpu instruction set.  Debian GNU/Linux offers the readelf command that is provided in the GNU ‘binutils’ package. Accompanied by the switch -h (short version for “–file-header”) it nicely displays the header of an ELF file. Listing 3 illustrates this for the command touch.\n.Listing 3: Displaying the header of an ELF file real command: Sdk\\ndk-bundle\\toolchains\\llvm\\prebuilt\\windows-x86_64\\bin\\x86_64-linux-android-readelf.exe -h git\\demo\\xCrash\\src\\native\\libxcrash\\obj\\local\\x86_64\\libxcrash.so ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2\u0026#39;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: DYN (Shared object file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 64 (bytes into file) Start of section headers: 382432 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 8 Size of section headers: 64 (bytes) Number of section headers: 39 Section header string table index: 38 The Program Header The program header shows the segments used at run-time, and tells the system how to create a process image. The header from Listing 2 shows that the ELF file consists of 9 program headers that have a size of 56 bytes each table item, and the first header starts at byte 64.\nAgain, the readelf command helps to extract the information from the ELF file. The switch -l (short for –program-headers or –segments) reveals more details as shown in Listing 4.\n.Listing 4: Display information about the program headers real command: Sdk\\ndk-bundle\\toolchains\\llvm\\prebuilt\\windows-x86_64\\bin\\x86_64-linux-android-readelf.exe -l git\\demo\\xCrash\\src\\native\\libxcrash\\obj\\local\\x86_64\\libxcrash.so Elf file type is DYN (Shared object file) Entry point 0x0 There are 8 program headers, starting at offset 64 Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align PHDR 0x0000000000000040 0x0000000000000040 0x0000000000000040 0x00000000000001c0 0x00000000000001c0 R 8 LOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x00000000000135e8 0x00000000000135e8 R E 1000 LOAD 0x0000000000013830 0x0000000000014830 0x0000000000014830 0x00000000000009a0 0x0000000000001648 RW 1000 DYNAMIC 0x0000000000013a68 0x0000000000014a68 0x0000000000014a68 0x0000000000000240 0x0000000000000240 RW 8 NOTE 0x0000000000000200 0x0000000000000200 0x0000000000000200 0x00000000000000bc 0x00000000000000bc R 4 GNU_EH_FRAME 0x0000000000013154 0x0000000000013154 0x0000000000013154 0x0000000000000494 0x0000000000000494 R 4 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 10 GNU_RELRO 0x0000000000013830 0x0000000000014830 0x0000000000014830 0x00000000000007d0 0x00000000000007d0 RW 10 Section to Segment mapping: Segment Sections... 00 01 .note.android.ident .note.gnu.build-id .dynsym .dynstr .hash .gnu.version .gnu.version_d .gnu.version_r .rela.dyn .rela.plt .plt .text .rodata .eh_frame .eh_frame_hdr 02 .fini_array .data.rel.ro .init_array .dynamic .got .got.plt .data .bss 03 .dynamic 04 .note.android.ident .note.gnu.build-id 05 .eh_frame_hdr 06 07 .fini_array .data.rel.ro .init_array .dynamic .got .got.plt The Section Header The third part of the ELF structure is the section header. It is meant to list the single sections of the binary. The switch -S (short for –section-headers or –sections) lists the different headers. As for the touch command, there are 27 section headers, and Listing 5 shows the first four of them plus the last one, only. Each line covers the\n section size, section type its address memory offset.  .Listing 5: Section details revealed by readelf windows real command: Sdk\\ndk-bundle\\toolchains\\llvm\\prebuilt\\windows-x86_64\\bin\\x86_64-linux-android-readelf.exe -S git\\demo\\xCrash\\src\\native\\libxcrash\\obj\\local\\x86_64\\libxcrash.so Ubuntu real command: Sdk/ndk/21.3.6528147/toolchains/llvm/prebuilt/linux-x86_64/bin/x86_64-linux-android-readelf 或使用环境变量中指定的: ~/Android/Source/android-9.0.0_r3$ which readelf /usr/bin/readelf There are 39 section headers, starting at offset 0x5d5e0: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .note.android.ide NOTE 0000000000000200 00000200 0000000000000098 0000000000000000 A 0 0 2 [ 2] .note.gnu.build-i NOTE 0000000000000298 00000298 0000000000000024 0000000000000000 A 0 0 4 [ 3] .dynsym DYNSYM 00000000000002c0 000002c0 0000000000000b70 0000000000000018 A 4 1 8 [ 4] .dynstr STRTAB 0000000000000e30 00000e30 00000000000005fc 0000000000000000 A 0 0 1 [ 5] .hash HASH 0000000000001430 00001430 0000000000000374 0000000000000004 A 3 0 8 [ 6] .gnu.version VERSYM 00000000000017a4 000017a4 00000000000000f4 0000000000000002 A 3 0 2 [ 7] .gnu.version_d VERDEF 0000000000001898 00001898 000000000000001c 0000000000000000 A 4 1 4 [ 8] .gnu.version_r VERNEED 00000000000018b4 000018b4 0000000000000040 0000000000000000 A 4 2 4 [ 9] .rela.dyn RELA 00000000000018f8 000018f8 0000000000000708 0000000000000018 A 3 0 8 [10] .rela.plt RELA 0000000000002000 00002000 0000000000000990 0000000000000018 AI 3 11 8 [11] .plt PROGBITS 0000000000002990 00002990 0000000000000670 0000000000000010 AX 0 0 16 [12] .text PROGBITS 0000000000003000 00003000 000000000000c6f6 0000000000000000 AX 0 0 16 [13] .rodata PROGBITS 000000000000f700 0000f700 0000000000002070 0000000000000000 A 0 0 16 [14] .eh_frame PROGBITS 0000000000011770 00011770 00000000000019e4 0000000000000000 A 0 0 8 [15] .eh_frame_hdr PROGBITS 0000000000013154 00013154 0000000000000494 0000000000000000 A 0 0 4 [16] .fini_array FINI_ARRAY 0000000000014830 00013830 0000000000000010 0000000000000008 WA 0 0 8 [17] .data.rel.ro PROGBITS 0000000000014840 00013840 0000000000000220 0000000000000000 WA 0 0 16 [18] .init_array INIT_ARRAY 0000000000014a60 00013a60 0000000000000008 0000000000000008 WA 0 0 8 [19] .dynamic DYNAMIC 0000000000014a68 00013a68 0000000000000240 0000000000000010 WA 4 0 8 [20] .got PROGBITS 0000000000014ca8 00013ca8 0000000000000010 0000000000000000 WA 0 0 8 [21] .got.plt PROGBITS 0000000000014cb8 00013cb8 0000000000000348 0000000000000000 WA 0 0 8 [22] .data PROGBITS 0000000000015000 00014000 00000000000001d0 0000000000000000 WA 0 0 16 [23] .bss NOBITS 0000000000015200 00014200 0000000000000c78 0000000000000000 WA 0 0 64 [24] .comment PROGBITS 0000000000000000 000141d0 0000000000000065 0000000000000001 MS 0 0 1 [25] .debug_str PROGBITS 0000000000000000 00014235 0000000000006eff 0000000000000001 MS 0 0 1 [26] .debug_loc PROGBITS 0000000000000000 0001b134 0000000000014b4c 0000000000000000 0 0 1 [27] .debug_abbrev PROGBITS 0000000000000000 0002fc80 00000000000026fa 0000000000000000 0 0 1 [28] .debug_info PROGBITS 0000000000000000 0003237a 0000000000018d5f 0000000000000000 0 0 1 [29] .debug_ranges PROGBITS 0000000000000000 0004b0d9 00000000000018b0 0000000000000000 0 0 1 [30] .debug_macinfo PROGBITS 0000000000000000 0004c989 0000000000000012 0000000000000000 0 0 1 [31] .debug_pubnames PROGBITS 0000000000000000 0004c99b 00000000000013f5 0000000000000000 0 0 1 [32] .debug_pubtypes PROGBITS 0000000000000000 0004dd90 00000000000026ed 0000000000000000 0 0 1 [33] .debug_line PROGBITS 0000000000000000 0005047d 0000000000009205 0000000000000000 0 0 1 [34] .debug_aranges PROGBITS 0000000000000000 00059682 0000000000000060 0000000000000000 0 0 1 [35] .note.gnu.gold-ve NOTE 0000000000000000 000596e4 000000000000001c 0000000000000000 0 0 4 [36] .symtab SYMTAB 0000000000000000 00059700 0000000000002058 0000000000000018 37 224 8 [37] .strtab STRTAB 0000000000000000 0005b758 0000000000001cd7 0000000000000000 0 0 1 [38] .shstrtab STRTAB 0000000000000000 0005d42f 00000000000001ac 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) section解读 hook 关系比较大的几个 section 是：\n .dynstr：保存了所有的字符串常量信息。 .dynsym：保存了符号（symbol）的信息（符号的类型、起始地址、大小、符号名称在 .dynstr 中的索引编号等）。函数也是一种符号。 .text：程序代码经过编译后生成的机器指令。 .dynamic：供动态链接器使用的各项信息，记录了当前 ELF 的外部依赖，以及其他各个重要 section 的起始位置等信息。 .got：Global Offset Table。用于记录外部调用的入口地址。动态链接器（linker）执行重定位（relocate）操作时，这里会被填入真实的外部调用的绝对地址。 .plt：Procedure Linkage Table。外部调用的跳板，主要用于支持 lazy binding 方式的外部调用重定位。（Android 目前只有 MIPS 架构支持 lazy binding） .rel.plt：对外部函数直接调用的重定位信息。 .rel.dyn：除 .rel.plt 以外的重定位信息。（比如通过全局函数指针来调用外部函数）  graph LR .dynamic--\u0026gt;当前ELF的外部依赖 .dynamic--\u0026gt;其他各个重要section的起始位置等信息 如果你理解了动态链接的过程，我们再回头来思考一下“.got”和“.plt”它们的具体含义。\n The Global Offset Table (GOT)。简单来说就是在数据段的地址表，假定我们有一些代码段的指令引用一些地址变量，编译器会引用 GOT 表来替代直接引用绝对地址，因为绝对地址在编译期是无法知道的，只有重定位后才会得到 ，GOT 自己本身将会包含函数引用的绝对地址。 The Procedure Linkage Table (PLT)。PLT 不同于 GOT，它位于代码段，动态库的每一个外部函数都会在 PLT 中有一条记录，每一条 PLT 记录都是一小段可执行代码。一般来说，外部代码都是在调用 PLT 表里的记录，然后 PLT 的相应记录会负责调用实际的函数。我们一般把这种设定叫作“蹦床”（Trampoline）。  PLT 和 GOT 记录是一一对应的，并且 GOT 表第一次解析后会包含调用函数的实际地址。既然这样，那 PLT 的意义究竟是什么呢？PLT 从某种意义上赋予我们一种懒加载的能力。当动态库首次被加载时，所有的函数地址并没有被解析。下面让我们结合图来具体分析一下首次函数调用，请注意图中黑色箭头为跳转，紫色为指针。\n 我们在代码中调用 func，编译器会把这个转化为 func@plt，并在 PLT 表插入一条记录。 PLT 表中第一条（或者说第 0 条）PLT[0] 是一条特殊记录，它是用来帮助我们解析地址的。通常在类 Linux 系统，这个的实现会位于动态加载器，就是专栏前面文章提到的 /system/bin/linker。 其余的 PLT 记录都均包含以下信息：  \u0026ndash; 跳转 GOT 表的指令（jmp *GOT[n]）。 \u0026ndash; 为上面提到的第 0 条解析地址函数准备参数。 \u0026ndash; 调用 PLT[0]，这里 resovler 的实际地址是存储在 GOT[2] 。\n在解析前 GOT[n] 会直接指向 jmp *GOT[n] 的下一条指令。在解析完成后，我们就得到了 func 的实际地址，动态加载器会将这个地址填入 GOT[n]，然后调用 func。\n如果你对上面的这个调用流程还有疑问，你可以参考《GOT 表和 PLT 表》这篇文章，它里面有一张图非常清晰。\n当第一次调用发生后，之后再调用函数 func 就高效简单很多。首先调用 PLT[n]，然后执行 jmp *GOT[n]。GOT[n] 直接指向 func，这样就高效的完成了函数调用。 总结一下，因为很多函数可能在程序执行完时都不会被用到，比如错误处理函数或一些用户很少用到的功能模块等，那么一开始把所有函数都链接好实际就是一种浪费。为了提升动态链接的性能，我们可以使用 PLT 来实现延迟绑定的功能。\n对于函数运行的实际地址，我们依然需要通过 GOT 表得到，整个简化过程如下：\n看到这里，相信你已经有了如何 Hack 这一过程的初步想法。这里业界通常会根据修改 PLT 记录或者 GOT 记录区分为 GOT Hook 和 PLT Hook，但其本质原理十分接近。\n动态链接器linker 安卓中的动态链接器程序是 linker。源码在 这里。\n动态链接（比如执行 dlopen）的大致步骤是：\n 检查已加载的 ELF 列表。（如果 libtest.so 已经加载，就不再重复加载了，仅把 libtest.so 的引用计数加一，然后直接返回。） 从 libtest.so 的 .dynamic section 中读取 libtest.so 的外部依赖的 ELF 列表，从此列表中剔除已加载的 ELF，最后得到本次需要加载的 ELF 完整列表（包括 libtest.so 自身）。 逐个加载列表中的 ELF。加载步骤：  用 mmap 预留一块足够大的内存，用于后续映射 ELF。（MAP_PRIVATE 方式） 读 ELF 的 PHT，用 mmap 把所有类型为 PT_LOAD 的 segment 依次映射到内存中。 从 .dynamic segment 中读取各信息项，主要是各个 section 的虚拟内存相对地址，然后计算并保存各个 section 的虚拟内存绝对地址。 执行重定位操作（relocate），这是最关键的一步。重定位信息可能存在于下面的一个或多个 secion 中：.rel.plt, .rela.plt, .rel.dyn, .rela.dyn, .rel.android, .rela.android。动态链接器需要逐个处理这些 .relxxx section 中的重定位诉求。根据已加载的 ELF 的信息，动态链接器查找所需符号的地址（比如 libtest.so 的符号 malloc），找到后，将地址值填入 .relxxx 中指明的目标地址中，这些“目标地址”一般存在于.got 或 .data 中。 ELF 的引用计数加一。   逐个调用列表中 ELF 的构造函数（constructor），这些构造函数的地址是之前从 .dynamic segment 中读取到的（类型为 DT_INIT 和 DT_INIT_ARRAY）。各 ELF 的构造函数是按照依赖关系逐层调用的，先调用被依赖 ELF 的构造函数，最后调用 libtest.so 自己的构造函数。（ELF 也可以定义自己的析构函数（destructor），在 ELF 被 unload 的时候会被自动调用）  图解如下 graph LR dlopen(\u0026quot;动态链接(执行dlopen)\u0026quot;)--\u0026gt;check(\u0026quot;检查已加载的 ELF 列表\u0026quot;) dlopen--\u0026gt;read(\u0026quot;.dynamic section 中读取 libtest.so 的外部依赖的 ELF 列表\u0026quot;) dlopen--\u0026gt;loadEach(\u0026quot;逐个加载列表中的 ELF。加载步骤\u0026quot;) loadEach--\u0026gt;mmap(\u0026quot;用 mmap 预留一块足够大的内存，用于后续映射 ELF\u0026quot;) loadEach--\u0026gt;mmapPT_LOAD(\u0026quot;读ELF的PHT用mmap把所有类型为PT_LOAD的segment依次映射到内存中\u0026quot;) loadEach--\u0026gt;dynamic(\u0026quot;从.dynamic segment中读取各信息项，主要是各个section的虚拟内存相对地址，计算绝对地址。\u0026quot;) loadEach--\u0026gt;|relocate|relocate(\u0026quot;逐个处理.relxxx section中的重定位诉求,找所需符号的地址，找到后将地址值填入.relxxx 中指明的目标地址.got或.data中\u0026quot;) loadEach--\u0026gt;ELFRefCount(\u0026quot;ELF 的引用计数加一\u0026quot;) dlopen--\u0026gt;cons(\u0026quot;逐个调用列表中 ELF 的构造函数constructor\u0026quot;) Hook问题 graph LR issue(\u0026quot;直接替换掉地址中的方法有三个问题\u0026quot;)--\u0026gt;基地址--\u0026gt;|solution|maps(\u0026quot;/proc/self/maps\u0026quot;) issue--\u0026gt;内存访问权限--\u0026gt;|solution|mprotect issue--\u0026gt;指令缓存--\u0026gt;|solution|__builtin___clear_cache PLT hook流程 总结一下 xhook 中执行 PLT hook 的流程：\n 读 maps，获取 ELF 的内存首地址（start address）。 验证 ELF 头信息。 从 PHT 中找到类型为 PT_LOAD 且 offset 为 0 的 segment。计算 ELF 基地址。 从 PHT 中找到类型为 PT_DYNAMIC 的 segment，从中获取到 .dynamic section，从 .dynamic section中获取其他各项 section 对应的内存地址。 在 .dynstr section 中找到需要 hook 的 symbol 对应的 index 值。 遍历所有的.relxxx section（重定位 section），查找 symbol index 和 symbol type 都匹配的项，对于这项重定位项，执行 hook 操作。hook 流程如下：  读 maps，确认当前 hook 地址的内存访问权限。 如果权限不是可读也可写，则用 mprotect 修改访问权限为可读也可写。 如果调用方需要，就保留 hook 地址当前的值，用于返回。 将 hook 地址的值替换为新的值。（执行 hook） 如果之前用 mprotect 修改过内存访问权限，现在还原到之前的权限。 清除 hook 地址所在内存页的处理器指令缓存。    elf分析工具  file readelf objdump  elfpltgot elfview readelf https://linux.die.net/man/1/readelf\nhttps://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/readelf.html\nhttps://en.wikipedia.org/wiki/Executable_and_Linkable_Format\n参考 https://github.com/iqiyi/xHook/blob/master/docs/overview/android_plt_hook_overview.zh-CN.md\nhttps://linuxhint.com/understanding_elf_file_format/\nandroid native hook技术你知道多少？\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/engine/engine/",
	"title": "Engine",
	"tags": [],
	"description": "",
	"content": "window.dart lib/ui\n/// Requests that, at the next appropriate opportunity, the [onBeginFrame]  /// and [onDrawFrame] callbacks be invoked.  ///  /// See also:  ///  /// * [SchedulerBinding], the Flutter framework class which manages the  /// scheduling of frames.  void scheduleFrame() native \u0026#39;PlatformConfiguration_scheduleFrame\u0026#39;; lib/ui/window/platform_configuration.cc\nPlatformConfiguration void PlatformConfiguration::RegisterNatives( tonic::DartLibraryNatives* natives) { natives-\u0026gt;Register({ {\u0026#34;PlatformConfiguration_defaultRouteName\u0026#34;, DefaultRouteName, 1, true}, {\u0026#34;PlatformConfiguration_scheduleFrame\u0026#34;, ScheduleFrame, 1, true}, {\u0026#34;PlatformConfiguration_sendPlatformMessage\u0026#34;, _SendPlatformMessage, 4, true}, {\u0026#34;PlatformConfiguration_respondToPlatformMessage\u0026#34;, _RespondToPlatformMessage, 3, true}, {\u0026#34;PlatformConfiguration_render\u0026#34;, Render, 2, true}, {\u0026#34;PlatformConfiguration_updateSemantics\u0026#34;, UpdateSemantics, 2, true}, {\u0026#34;PlatformConfiguration_setIsolateDebugName\u0026#34;, SetIsolateDebugName, 2, true}, {\u0026#34;PlatformConfiguration_reportUnhandledException\u0026#34;, ReportUnhandledException, 2, true}, {\u0026#34;PlatformConfiguration_setNeedsReportTimings\u0026#34;, SetNeedsReportTimings, 2, true}, {\u0026#34;PlatformConfiguration_getPersistentIsolateData\u0026#34;, GetPersistentIsolateData, 1, true}, {\u0026#34;PlatformConfiguration_computePlatformResolvedLocale\u0026#34;, _ComputePlatformResolvedLocale, 2, true}, }); } void ScheduleFrame(Dart_NativeArguments args) { UIDartState::ThrowIfUIOperationsProhibited(); UIDartState::Current()-\u0026gt;platform_configuration()-\u0026gt;client()-\u0026gt;ScheduleFrame(); } runtime/runtime_controller.cc\nRuntimeController:PlatformConfigurationClient //------------------------------------------------------------------------------ /// Represents an instance of a running root isolate with window bindings. In /// normal operation, a single instance of this object is owned by the engine /// per shell. This object may only be created, used, and collected on the UI /// task runner. Window state queried by the root isolate is stored by this /// object. In cold-restart scenarios, the engine may collect this before /// installing a new runtime controller in its place. The Clone method may be /// used by the engine to copy the currently accumulated window state so it can /// be referenced by the new runtime controller. /// class RuntimeController : public PlatformConfigurationClient { // |PlatformConfigurationClient|  void RuntimeController::ScheduleFrame() { client_.ScheduleFrame(); } } shell/common/engine.cc\nEngine:RuntimeDelegate class Engine final : public RuntimeDelegate, public HintFreedDelegate, PointerDataDispatcher::Delegate { private: Delegate\u0026amp; delegate_; void Engine::ScheduleFrame(bool regenerate_layer_tree) { animator_-\u0026gt;RequestFrame(regenerate_layer_tree); } } Shell:Engine::Delegate class Shell final : public PlatformView::Delegate, public Animator::Delegate, public Engine::Delegate, public Rasterizer::Delegate, public ServiceProtocol::Handler { shell/common/animator.cc\nvoid Animator::RequestFrame(bool regenerate_layer_tree) { // The AwaitVSync is going to call us back at the next VSync. However, we want  // to be reasonably certain that the UI thread is not in the middle of a  // particularly expensive callout. We post the AwaitVSync to run right after  // an idle. This does NOT provide a guarantee that the UI thread has not  // started an expensive operation right after posting this message however.  // To support that, we need edge triggered wakes on VSync.  task_runners_.GetUITaskRunner()-\u0026gt;PostTask([self = weak_factory_.GetWeakPtr(), frame_number = frame_number_]() { if (!self) { return; } TRACE_EVENT_ASYNC_BEGIN0(\u0026#34;flutter\u0026#34;, \u0026#34;Frame Request Pending\u0026#34;, frame_number); self-\u0026gt;AwaitVSync(); }); frame_scheduled_ = true; } void Animator::AwaitVSync() { waiter_-\u0026gt;AsyncWaitForVsync( [self = weak_factory_.GetWeakPtr()](fml::TimePoint vsync_start_time, fml::TimePoint frame_target_time) { if (self) { if (self-\u0026gt;CanReuseLastLayerTree()) { self-\u0026gt;DrawLastLayerTree(); } else { self-\u0026gt;BeginFrame(vsync_start_time, frame_target_time); } } }); delegate_.OnAnimatorNotifyIdle(dart_frame_deadline_); } shell/common/vsync_waiter.cc\n// Public method invoked by the animator. void VsyncWaiter::AsyncWaitForVsync(const Callback\u0026amp; callback) { if (!callback) { return; } TRACE_EVENT0(\u0026#34;flutter\u0026#34;, \u0026#34;AsyncWaitForVsync\u0026#34;); { std::scoped_lock lock(callback_mutex_); if (callback_) { // The animator may request a frame more than once within a frame  // interval. Multiple calls to request frame must result in a single  // callback per frame interval.  TRACE_EVENT_INSTANT0(\u0026#34;flutter\u0026#34;, \u0026#34;MultipleCallsToVsyncInFrameInterval\u0026#34;); return; } callback_ = std::move(callback); if (secondary_callback_) { // Return directly as `AwaitVSync` is already called by  // `ScheduleSecondaryCallback`.  return; } } AwaitVSync(); } 参考 https://api.flutter.dev/javadoc/io/flutter/embedding/engine/FlutterEngine.html\nhttps://engine.chinmaygarde.com/classtonic_1_1_dart_persistent_value.html\nhttps://fuchsia.googlesource.com/tonic/\nhttps://flutter.dev/docs/development/add-to-app/performance\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/engine/",
	"title": "engine",
	"tags": [],
	"description": "",
	"content": "engine 探索总结engine知识\n Engine     FlutterEngineCache     FlutterEngineDebug环境搭建     FlutterEngineGroup     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/handler/epoll/",
	"title": "Epoll",
	"tags": [],
	"description": "",
	"content": "原理总结 graph LR epoll_create--\u0026gt;|1创建|fileNode(\u0026quot;创建并初始化eventpoll结构体ep,将ep放入file-\u0026gt;private,并返回fd\u0026quot;) epoll_create--\u0026gt;|1创建|RBTree(\u0026quot;红黑树用于存储以后epoll_ctl传来的fd\u0026quot;) epoll_create--\u0026gt;|1创建|epitems(\u0026quot;链表,用于存储准备就绪的事件\u0026quot;) epoll_ctl--\u0026gt;|2 fd对应到|RBTree epoll_ctl--\u0026gt;|2 注册回调ep_poll_callback,回调时将fd对应的epitem实例放入就绪链表并唤醒进程|RBTree epoll_wait--\u0026gt;|3 ep_poll观察是否有数据|epitems--\u0026gt;|3|isEvent{是否有数据?}--\u0026gt;|3有|返回数据 isEvent--\u0026gt;|3否|sleepTimeoutThenReturn--\u0026gt;被唤醒后从队列中移除wait,再传输就绪事件到用户空间 epoll使用RB-Tree红黑树去监听并维护所有文件描述符，RB-Tree的根节点。调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个 红黑树 用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件.当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait仅需要从内核态copy少量的句柄到用户态而已.\n那么，这个准备就绪list链表是怎么维护的呢？\n当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。\nepoll相比于select并不是在所有情况下都要高效，例如在如果有少于1024个文件描述符监听，且大多数socket都是出于活跃繁忙的状态，这种情况下，select要比epoll更为高效，因为epoll会有更多次的系统调用，用户态和内核态会有更加频繁的切换。\nepoll高效的本质在于：\n 减少了用户态和内核态的文件句柄拷贝 减少了对可读可写文件句柄的遍历 mmap 加速了内核与用户空间的信息传递，epoll是通过内核与用户mmap同一块内存，避免了无谓的内存拷贝 IO性能不会随着监听的文件描述的数量增长而下降 使用红黑树存储fd，以及对应的回调函数，其插入，查找，删除的性能不错，相比于hash，不必预先分配很多的空间  fs/eventpoll.c\nepoll_create // /usr/include/x86_64-linux-gnu/sys/epoll.h  /* Creates an epoll instance. Returns an fd for the new instance. The \u0026#34;size\u0026#34; parameter is a hint specifying the number of file descriptors to be associated with the new instance. The fd returned by epoll_create() should be closed with close(). */ extern int epoll_create (int __size) __THROW; SYSCALL_DEFINE1(epoll_create, int, size) { if (size \u0026lt;= 0) return -EINVAL; return sys_epoll_create1(0); } epoll_create1 /* * Open an eventpoll file descriptor. */ SYSCALL_DEFINE1(epoll_create1, int, flags) { int error, fd; struct eventpoll *ep = NULL; struct file *file; /* * Create the internal data structure (\u0026#34;struct eventpoll\u0026#34;). */ error = ep_alloc(\u0026amp;ep); /* * Creates all the items needed to setup an eventpoll file. That is, * a file structure and a free file descriptor. */ fd = get_unused_fd_flags(O_RDWR | (flags \u0026amp; O_CLOEXEC)); file = anon_inode_getfile(\u0026#34;[eventpoll]\u0026#34;, \u0026amp;eventpoll_fops, ep, O_RDWR | (flags \u0026amp; O_CLOEXEC)); ep-\u0026gt;file = file; fd_install(fd, file); return fd; } epoll_ctl // /usr/include/x86_64-linux-gnu/sys/epoll.h /* Valid opcodes ( \u0026#34;op\u0026#34; parameter ) to issue to epoll_ctl(). */ #define EPOLL_CTL_ADD 1\t/* Add a file descriptor to the interface. */#define EPOLL_CTL_DEL 2\t/* Remove a file descriptor from the interface. */#define EPOLL_CTL_MOD 3\t/* Change file descriptor epoll_event structure. */ /* Manipulate an epoll instance \u0026#34;epfd\u0026#34;. Returns 0 in case of success, -1 in case of error ( the \u0026#34;errno\u0026#34; variable will contain the specific error code ) The \u0026#34;op\u0026#34; parameter is one of the EPOLL_CTL_* constants defined above. The \u0026#34;fd\u0026#34; parameter is the target of the operation. The \u0026#34;event\u0026#34; parameter describes which events the caller is interested in and any associated user data. */ extern int epoll_ctl (int __epfd, int __op, int __fd, struct epoll_event *__event) __THROW; /* * The following function implements the controller interface for * the eventpoll file that enables the insertion/removal/change of * file descriptors inside the interest set. */ SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd, struct epoll_event __user *, event) { int error; int full_check = 0; struct fd f, tf; struct eventpoll *ep; struct epitem *epi; struct epoll_event epds; struct eventpoll *tep = NULL; ep_op_has_event(op) \u0026amp;\u0026amp; copy_from_user(\u0026amp;epds, event, sizeof(struct epoll_event) f = fdget(epfd); /* Get the \u0026#34;struct file *\u0026#34; for the target file */ tf = fdget(fd); /* * At this point it is safe to assume that the \u0026#34;private_data\u0026#34; contains * our own data structure. */ ep = f.file-\u0026gt;private_data; } ep_op_has_event /* Tells if the epoll_ctl(2) operation needs an event copy from userspace */ static inline int ep_op_has_event(int op) { return op != EPOLL_CTL_DEL; } epoll_wait // /usr/include/x86_64-linux-gnu/sys/epoll.h /* Wait for events on an epoll instance \u0026#34;epfd\u0026#34;. Returns the number of triggered events returned in \u0026#34;events\u0026#34; buffer. Or -1 in case of error with the \u0026#34;errno\u0026#34; variable set to the specific error code. The \u0026#34;events\u0026#34; parameter is a buffer that will contain triggered events. The \u0026#34;maxevents\u0026#34; is the maximum number of events to be returned ( usually size of \u0026#34;events\u0026#34; ). The \u0026#34;timeout\u0026#34; parameter specifies the maximum wait time in milliseconds (-1 == infinite). This function is a cancellation point and therefore not marked with __THROW. */ extern int epoll_wait (int __epfd, struct epoll_event *__events, int __maxevents, int __timeout); /* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). */ SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { } 其他 struct eventpoll /* * This structure is stored inside the \u0026#34;private_data\u0026#34; member of the file * structure and represents the main data structure for the eventpoll * interface. */ struct eventpoll { /* Protect the access to this structure */ spinlock_t lock; /* * This mutex is used to ensure that files are not removed * while epoll is using them. This is held during the event * collection loop, the file cleanup path, the epoll file exit * code and the ctl operations. */ struct mutex mtx; /* Wait queue used by sys_epoll_wait() */ wait_queue_head_t wq; /* Wait queue used by file-\u0026gt;poll() */ wait_queue_head_t poll_wait; /* List of ready file descriptors */ struct list_head rdllist; /* RB tree root used to store monitored fd structs */ struct rb_root rbr; /* * This is a single linked list that chains all the \u0026#34;struct epitem\u0026#34; that * happened while transferring ready events to userspace w/out * holding -\u0026gt;lock. */ struct epitem *ovflist; /* wakeup_source used when ep_scan_ready_list is running */ struct wakeup_source *ws; /* The user that created the eventpoll descriptor */ struct user_struct *user; struct file *file; /* used to optimize loop detection check */ int visited; struct list_head visited_list_link; }; struct epoll_event struct epoll_event { uint32_t events;\t/* Epoll events */ epoll_data_t data;\t/* User data variable */ } __EPOLL_PACKED; epoll_data(_t) typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; eventpoll_fops /* File callbacks that implement the eventpoll file behaviour */ static const struct file_operations eventpoll_fops = { #ifdef CONFIG_PROC_FS \t.show_fdinfo\t= ep_show_fdinfo, #endif \t.release\t= ep_eventpoll_release, .poll\t= ep_eventpoll_poll, .llseek\t= noop_llseek, }; 参考 Linux 下 Epoll 机制概述\nhttps://man7.org/linux/man-pages/man7/epoll.7.html\n源码解读epoll内核机制\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/eventchannel/",
	"title": "EventChannel",
	"tags": [],
	"description": "",
	"content": "技术依赖 graph TB EventChannel--\u0026gt;|baseOn|MethodChannel EventChannel--\u0026gt;|baseOn|Stream 核心原理 sequenceDiagram rect rgb(199, 237, 204) Dart-\u0026gt;\u0026gt;Dart: stream.listen activate Dart Dart-\u0026gt;\u0026gt;Platform: methodChannel.invokeMethod(listen) deactivate Dart activate Platform Platform-\u0026gt;\u0026gt;Platform: onListen activate Platform Platform-\u0026gt;\u0026gt;Platform: handler.onListen(EventSink) deactivate Platform deactivate Platform end rect rgb(199, 237, 204) Platform-\u0026gt;\u0026gt;Platform: eventSink.success activate Platform Platform-\u0026gt;\u0026gt;Dart: messenger.send deactivate Platform activate Dart Dart-\u0026gt;\u0026gt;Dart: StreamController.add(T event) deactivate Dart end Usage Dart StreamBuilder Use demo参考/Users/qianpianpian/git/flutter/samples/platform_channels/lib/src/event_channel_demo.dart\n使用StreamBuilder包裹stream\nchild: StreamBuilder\u0026lt;AccelerometerReadings\u0026gt;( stream: Accelerometer.readings,//stream  builder: (context, snapshot) { if (snapshot.hasError) { return Text((snapshot.error as PlatformException).message); } else if (snapshot.hasData) { return Column( mainAxisAlignment: MainAxisAlignment.center, children: [ Text( \u0026#39;x axis: \u0026#39; + snapshot.data.x.toStringAsFixed(3), style: textStyle, ), Text( \u0026#39;y axis: \u0026#39; + snapshot.data.y.toStringAsFixed(3), style: textStyle, ), Text( \u0026#39;z axis: \u0026#39; + snapshot.data.z.toStringAsFixed(3), style: textStyle, ) ], ); } /// This class includes the implementation for [EventChannel] to listen to value /// changes from the Accelerometer sensor from native side. It has a [readings] /// getter to provide a stream of [AccelerometerReadings]. class Accelerometer { static final _eventChannel = const EventChannel(\u0026#39;eventChannelDemo\u0026#39;); /// Method responsible for providing a stream of [AccelerometerReadings] to listen  /// to value changes from the Accelerometer sensor.  static Stream\u0026lt;AccelerometerReadings\u0026gt; get readings { return _eventChannel.receiveBroadcastStream().map( (dynamic event) =\u0026gt; AccelerometerReadings( event[0] as double, event[1] as double, event[2] as double, ), ); } } Direct Use _eventChannel.receiveBroadcastStream().listen((event) { { print(\u0026#34;NativeNetworkApi it = ${event}\u0026#34;); } }); Native EventChannel(flutterEngine.dartExecutor, \u0026#34;eventChannelDemo\u0026#34;) .setStreamHandler(AccelerometerStreamHandler(sensorManger, accelerometerSensor)) class AccelerometerStreamHandler(sManager: SensorManager, s: Sensor) : EventChannel.StreamHandler, SensorEventListener { private val sensorManager: SensorManager = sManager private val accelerometerSensor: Sensor = s private lateinit var eventSink: EventChannel.EventSink override fun onListen(arguments: Any?, events: EventChannel.EventSink?) { if (events != null) { eventSink = events//main  sensorManager.registerListener(this, accelerometerSensor, SensorManager.SENSOR_DELAY_UI) } } override fun onCancel(arguments: Any?) { sensorManager.unregisterListener(this) } override fun onAccuracyChanged(sensor: Sensor?, accuracy: Int) {} override fun onSensorChanged(sensorEvent: SensorEvent?) { if (sensorEvent != null) { val axisValues = listOf(sensorEvent.values[0], sensorEvent.values[1], sensorEvent.values[2]) eventSink.success(axisValues)//main  } } } EventChannel(FlutterEngineCache.getInstance().get(FlutterBoost.ENGINE_ID)?.dartExecutor, networkEventChannel) .setStreamHandler(object : EventChannel.StreamHandler { override fun onListen(arguments: Any?, events: EventChannel.EventSink?) { eventSink = events//main  } override fun onCancel(arguments: Any?) { eventSink = null } }) Messages.NativeNetworkApi.setup(FlutterEngineCache.getInstance().get(FlutterBoost.ENGINE_ID)?.dartExecutor, object : Messages.NativeNetworkApi { override fun request(arg: Messages.RequestParams?, result: Messages.Result\u0026lt;Messages.Resource\u0026gt;?) { eventSink?.success(mockNetworkResource(\u0026#34;testEventChannel1\u0026#34;).toMap())//main  eventSink?.success(mockNetworkResource(\u0026#34;testEventChannel2\u0026#34;).toMap()) eventSink?.success(mockNetworkResource(\u0026#34;testEventChannel3\u0026#34;).toMap()) eventSink?.success(mockNetworkResource(\u0026#34;testEventChannel4\u0026#34;).toMap()) } }) NativeSide public final class EventChannel { private final BinaryMessenger messenger; private final String name; private final MethodCodec codec; } public EventChannel(BinaryMessenger messenger, String name) { this(messenger, name, StandardMethodCodec.INSTANCE); } public EventChannel(BinaryMessenger messenger, String name, MethodCodec codec) { this.messenger = messenger; this.name = name; this.codec = codec; } EventChannel.setStreamHandler @UiThread public void setStreamHandler(final StreamHandler handler) { messenger.setMessageHandler( name, handler == null ? null : new IncomingStreamRequestHandler(handler)); } IncomingStreamRequestHandler.onMessage private final class IncomingStreamRequestHandler implements BinaryMessageHandler { private final StreamHandler handler; private final AtomicReference\u0026lt;EventSink\u0026gt; activeSink = new AtomicReference\u0026lt;\u0026gt;(null); IncomingStreamRequestHandler(StreamHandler handler) { this.handler = handler; } @Override public void onMessage(ByteBuffer message, final BinaryReply reply) { final MethodCall call = codec.decodeMethodCall(message); if (call.method.equals(\u0026#34;listen\u0026#34;)) { onListen(call.arguments, reply); } else if (call.method.equals(\u0026#34;cancel\u0026#34;)) { onCancel(call.arguments, reply); } else { reply.reply(null); } } private void onListen(Object arguments, BinaryReply callback) { final EventSink eventSink = new EventSinkImplementation(); final EventSink oldSink = activeSink.getAndSet(eventSink); if (oldSink != null) { // Repeated calls to onListen may happen during hot restart.  // We separate them with a call to onCancel.  try { handler.onCancel(null); } catch (RuntimeException e) { Log.e(TAG + name, \u0026#34;Failed to close existing event stream\u0026#34;, e); } } try { handler.onListen(arguments, eventSink); callback.reply(codec.encodeSuccessEnvelope(null)); } catch (RuntimeException e) { activeSink.set(null); Log.e(TAG + name, \u0026#34;Failed to open event stream\u0026#34;, e); callback.reply(codec.encodeErrorEnvelope(\u0026#34;error\u0026#34;, e.getMessage(), null)); } } private void onCancel(Object arguments, BinaryReply callback) { final EventSink oldSink = activeSink.getAndSet(null);//cancel之后会将activeSink设置为null，后续不能在使用之前的sink进行发送，发送前校验  if (oldSink != null) { try { handler.onCancel(arguments); callback.reply(codec.encodeSuccessEnvelope(null)); public final class EventChannel { private final class IncomingStreamRequestHandler implements BinaryMessageHandler { private final class EventSinkImplementation implements EventSink { final AtomicBoolean hasEnded = new AtomicBoolean(false); @Override @UiThread public void success(Object event) { if (hasEnded.get() || activeSink.get() != this) { return; } EventChannel.this.messenger.send(name, codec.encodeSuccessEnvelope(event)); } @Override @UiThread public void error(String errorCode, String errorMessage, Object errorDetails) { if (hasEnded.get() || activeSink.get() != this) {//发送前校验activeSink是否是最新的，不是则不发送  return; } EventChannel.this.messenger.send( name, codec.encodeErrorEnvelope(errorCode, errorMessage, errorDetails)); } DartSide class EventChannel { /// The logical channel on which communication happens, not null.  final String name; /// The message codec used by this channel, not null.  final MethodCodec codec; /// The messenger used by this channel to send platform messages, not null.  BinaryMessenger get binaryMessenger =\u0026gt; _binaryMessenger ?? defaultBinaryMessenger; final BinaryMessenger? _binaryMessenger; final _eventChannel = const EventChannel(\u0026#39;platform_channel_events/connectivity\u0026#39;); EventChannel.receiveBroadcastStream Stream\u0026lt;dynamic\u0026gt; receiveBroadcastStream([ dynamic arguments ]) { final MethodChannel methodChannel = MethodChannel(name, codec); late StreamController\u0026lt;dynamic\u0026gt; controller; controller = StreamController\u0026lt;dynamic\u0026gt;.broadcast( onListen: () async { binaryMessenger.setMessageHandler(name, (ByteData? reply) async { if (reply == null) { controller.close(); } else { try { controller.add(codec.decodeEnvelope(reply)); } on PlatformException catch (e) { controller.addError(e); } } return null; }); await methodChannel.invokeMethod\u0026lt;void\u0026gt;(\u0026#39;listen\u0026#39;, arguments); }, onCancel: () async { binaryMessenger.setMessageHandler(name, null); await methodChannel.invokeMethod\u0026lt;void\u0026gt;(\u0026#39;cancel\u0026#39;, arguments); }); return controller.stream; } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/ffmpeg/examples/",
	"title": "examples",
	"tags": [],
	"description": "",
	"content": "examples 探索总结examples知识\n TranscodingSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/ffmpeg/",
	"title": "ffmpeg",
	"tags": [],
	"description": "",
	"content": "ffmpeg 探索总结ffmpeg知识\n examples    TranscodingSource      FFmpegDebug     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/ffmpeg/ffmpegdebug/",
	"title": "FFmpegDebug",
	"tags": [],
	"description": "",
	"content": "How to debug The small program uses the mac machine. First complete the preparation of FFmpeg source code download and compilation.\n(0)Download FFmpeg source code\u0026ndash;success  git clone git://source.ffmpeg.org/ffmpeg.git ffmpeg\n As for the tools used to open these source files, readers should consider tools that are suitable for them and suitable for large projects, such as sourceinsight, sublime, vim, emacs, xcode, Android Studio, etc.\n(1) Compile FFmpeg\u0026ndash;success #实际操作的命令 brew install yasm brew install automake fdk-aac git lame libass libtool libvorbis libvpx \\ opus sdl shtool texi2html theora wget x264 x265 xvid nasm ./configure --disable-optimizations --enable-debug make Compilation to use the compiler, the easiest way to install xcode on the mac machine is to ensure that the compiler clang is there.\nFor debugging, this compilation can be very simple, just remove the optimization option, then make:\n make clean ./configure \u0026ndash;disable-optimizations make\n Configure is a configuration script provided by FFmpeg to generate Makefile and config.h files. Makefile is used at compile time, and config.h (the definition of various macros inside) is used by FFmpeg source code, which also affects the function clipping of FFmpeg.\nFor configure parameters, readers can also view all options via ./configure \u0026ndash;help and then find options for optimization.\nThe make clean here is to clear the previous compilation pollution. If it has not been compiled before, it does not need to be executed.\nIn addition, if you execute make install after make, you will install FFmpeg to the mac system. This is not necessary for debugging, just make a binary library.\nAfter successful compilation, you can see these files: (2) Debug FFmpeg with gdb For readers who prefer to use the command line, using gdb or lldb for debugging is a good choice.\nBefore using gdb, you need to install and sign gdb. If the reader is not ready for gdb and is interested in using gdb, you can read the contents of the split line. This also includes the commands commonly used by gdb.\n Install gdb:\n brew install homebrew/dupes/gdb\n Authorize gdb, refer to:https://blog.csdn.net/cairo123/article/details/52054280\nWrite a test example:\n touch gdbtest.c: int main() { int a = 10; printf(\u0026quot;%d\\n\u0026quot;); }\n Compile:\n gcc -o gdbtest gdbtest.c -g\n Note that you must bring -g to generate the symbol dSYM file.\nThen you can debug it. Common commands have these:\n Gdb gdbtest \u0026ndash; load the executable r \u0026ndash;run, run, can take parameters i b \u0026ndash;info break, breakpoint information b 3 \u0026ndash;break 3, breakpoint on line 3 b main \u0026ndash;main function breaks the first line b other_c:fun1 \u0026ndash; the breakpoint of the first line of the fun1 function of the file other_c b 120 \u0026ndash; breakpoints at 120 lines clear \u0026ndash; delete all breakpoints d 3 \u0026ndash;delete 3, delete breakpoint 3 disable 1 \u0026ndash; disable breakpoint 1 enable 1 \u0026ndash; enable breakpoint 1 s \u0026ndash;step, jump in f \u0026ndash;finish, jump out n \u0026ndash;next, execute one line n 3 \u0026ndash;next 3, execute 3 lines c \u0026ndash;continue, continue until the next breakpoint or end p a \u0026ndash;print a, output the value of the variable a list/l \u0026ndash; view the code q/kill \u0026ndash; Exit this debug bt \u0026ndash; view the call stack return \u0026ndash; return the current function\n  For convenience, the small program directly uses FFmpeg\u0026rsquo;s program to cut into debugging (of course, you can also write your own code to call FFmpeg), for example, you can choose ffplay_g this program to cut in, debug the basis on which it depends, FFmpeg.\nDebugging ffplay_g requires input parameters. After gdb ffplay_g, r \u0026ldquo;xxx/file.mp3\u0026rdquo; can be used to play ffplay_g to play this file.\nHere\u0026rsquo;s a demo video of a small snippet using gdb for simple debugging:\nNeed to pay attention, with _g is a program with debugging information, that is needed for debugging.\n(3) Debug FFmpeg with xcode\u0026ndash;success Obviously, using gdb for debugging is not too intuitive for reading code or operations. In this case, readers can consider using xcode to debug FFmpeg.\nXiao Cheng does not introduce each configuration link here, because readers can refer to the following illustrated article, step by step: 使用Xcode断点调试ffmpeg\nAt this point, I have already explained how to debug FFmpeg.\n 创建Xcode新项目  这里选择Command Line Tool\n4 . 引用FFmpeg\n5 .添加linked 信息(图中少了一个／)\n首先添加Header Search Paths\n接着添加Library Search Paths\n6 .添加target\n添加文件夹路径\n配置ffmpeg_make运行信息\n配置executable\n最后结果是这样的\n7 .大功告成 现在到ffmpeg.c main函数打个断点试试\nTo sum up, this article describes how to debug FFmpeg source code on macos, including using gdb or xcode to debug, and also how to compile FFmpeg with debugging information.\nDebug examples(transcoding)    qianpianpian@zhenghuanMacbookPro ffmpeg % make examples Library Search Paths添加:  $(SRCROOT)/../ffmpeg/doc/examples\nAdd Target:  Info\u0026ndash;\u0026gt;External Build Tool Configuration\u0026ndash;\u0026gt;Directory:../ffmpeg/doc/examples\nEdit New Target:  Arguments:\n/Users/qianpianpian/git/demo/FFmpegDebug/FFmpegDebug/video_480x360_mp4_h264_1350kbps_30fps_aac_stereo_192kbps_44100hz.mp4 /Users/qianpianpian/git/demo/FFmpegDebug/FFmpegDebug/output.avi\nInfo\u0026ndash;\u0026gt;Executable选中doc/examples/transcoding_g\nadd breakPoint and Run Debug  运行时遇到如下错误待处理:\nError: cannot create compression session: -12903\nTry -allow_sw 1. The hardware encoder may be busy, or not supported.\n对应源码\n//videotoolboxenc.c static int vtenc_create_encoder(AVCodecContext *avctx, CMVideoCodecType codec_type, CFStringRef profile_level, CFNumberRef gamma_level, CFDictionaryRef enc_info, CFDictionaryRef pixel_buffer_info, VTCompressionSessionRef *session) { VTEncContext *vtctx = avctx-\u0026gt;priv_data; SInt32 bit_rate = avctx-\u0026gt;bit_rate; .... int status = VTCompressionSessionCreate(kCFAllocatorDefault, avctx-\u0026gt;width, avctx-\u0026gt;height, codec_type, enc_info, pixel_buffer_info, kCFAllocatorDefault, vtenc_output_callback, avctx, session); if (status || !vtctx-\u0026gt;session) { av_log(avctx, AV_LOG_ERROR, \u0026#34;Error: cannot create compression session: %d\\n\u0026#34;, status); #if !TARGET_OS_IPHONE  if (!vtctx-\u0026gt;allow_sw) { av_log(avctx, AV_LOG_ERROR, \u0026#34;Try -allow_sw 1. The hardware encoder may be busy, or not supported.\\n\u0026#34;); } #endif  return AVERROR_EXTERNAL; } ./configure \u0026ndash;disable-optimizations \u0026ndash;enable-debug \u0026ndash;disable-videotoolbox会导致找不到encoder\n./configure \u0026ndash;disable-optimizations \u0026ndash;enable-debug \u0026ndash;disable-videotoolbox \u0026ndash;enable-gpl \u0026ndash;enable-libx264能够正常调试(视频长度是音频长度的两倍)\n解决方案参考:\n \u0026gt; However, having done that, libAVCodec appears to be failing when it calls \u0026gt; through to the OSX VideoToolbox.framework. \u0026gt; \u0026gt; [h264_videotoolbox @ 0x106806800]\nThis (not the error message) indicates that libavcodec was compiled without support for libx264, recompile with \u0026ndash;enable-libx264 (after installing libx264)\n I had problem too with videotoolbox encoder, and I didn\u0026rsquo;t figure how to make it work, so I built a version of ffmpeg without videotoolbox and with libx264, to be sure libx264 was used as default encoder for h264.\nHere is my configuration options if interested:\nexport MACOSX_DEPLOYMENT_TARGET=10.8\n./configure \u0026ndash;disable-videotoolbox \u0026ndash;disable-audiotoolbox \u0026ndash;enable-libx264 \u0026ndash;enable-libfdk-aac \u0026ndash;enable-nonfree \u0026ndash;enable-gpl \u0026ndash;sysroot=/Users/gabry/MacOSX10.8.sdk/\n\u0026hellip; this removes also a lot of OSX frameworks dependencies (you have to configure/compile/install libfdk-aac and libx264 before compiling ffmpeg)\n参考 https://trac.ffmpeg.org/wiki/CompilationGuide\nhttps://stackoverflow.com/questions/9211163/debugging-ffmpeg\nhow to debug ffmpeg in linux\nFFMPEG debugging\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/",
	"title": "flutter",
	"tags": [],
	"description": "",
	"content": "flutter 探索总结flutter知识\n 1startup    1startup     2startup_embedder_framwwork     3flutter_surface     4startup_dart_framework      engine    Engine     FlutterEngineCache     FlutterEngineDebug环境搭建     FlutterEngineGroup      touch     动画    动画      响应式架构    1跨组件传递数据     2Provider     3异步_响应式_状态管理     stream    Stream       混合开发    FlutterBoost     FlutterBoost3     混合开发      渲染    Widget     渲染      路由    路由      通信    EventChannel     MessageLoop     MethodChannel     Pigeon      "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/flutterboost/",
	"title": "FlutterBoost",
	"tags": [],
	"description": "",
	"content": "BoostFlutterActivity.onCreate BoostFlutterActivity implements FlutterActivityAndFragmentDelegate.Host { private FlutterActivityAndFragmentDelegate delegate; public static class NewEngineIntentBuilder { public Intent build(@NonNull Context context) { SerializableMap serializableMap = new SerializableMap(); serializableMap.setMap(params); return new Intent(context, activityClass) .putExtra(EXTRA_BACKGROUND_MODE, backgroundMode) .putExtra(EXTRA_DESTROY_ENGINE_WITH_ACTIVITY, false) .putExtra(EXTRA_URL, url) .putExtra(EXTRA_PARAMS, serializableMap); } @Override public String getContainerUrl() { if (getIntent().hasExtra(EXTRA_URL)) { return getIntent().getStringExtra(EXTRA_URL); } } @Override protected void onCreate(@Nullable Bundle savedInstanceState) { delegate = new FlutterActivityAndFragmentDelegate(this); delegate.onAttach(this); setContentView(createFlutterView()); } FlutterActivityAndFragmentDelegate implements IFlutterViewContainer { protected IOperateSyncer mSyncer; FlutterActivityAndFragmentDelegate(@NonNull Host host) { this.host = host; } void onAttach(@NonNull Context context) { // When \u0026#34;retain instance\u0026#34; is true, the FlutterEngine will survive configuration  // changes. Therefore, we create a new one only if one does not already exist.  if (flutterEngine == null) { setupFlutterEngine(); } } private void setupFlutterEngine() { // Second, defer to subclasses for a custom FlutterEngine.  flutterEngine = host.provideFlutterEngine(host.getContext()); if (flutterEngine != null) { isFlutterEngineFromHost = true; return; } } } provideFlutterEngine /** \\* Hook for subclasses to easily provide a custom {@link FlutterEngine}. \\* \u0026lt;p\u0026gt; \\* This hook is where a cached {@link FlutterEngine} should be provided, if a cached \\* {@link FlutterEngine} is desired. */ @Nullable @Override public FlutterEngine provideFlutterEngine(@NonNull Context context) { // No-op. Hook for subclasses.  return FlutterBoost.instance().engineProvider(); } setContentView(createFlutterView()) @NonNull protected View createFlutterView() { return delegate.onCreateView( null /* inflater */, null /* container */, null /* savedInstanceState */); } View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) { Log.v(TAG, \u0026#34;Creating FlutterView.\u0026#34;); flutterEngine.getActivityControlSurface().attachToActivity( host.getActivity(), host.getLifecycle() ); mSyncer = FlutterBoost.instance().containerManager().generateSyncer(this); mSyncer.onCreate(); } mSyncer.onCreate() ContainerRecord implements IContainerRecord implements IOperateSyncer { private MethodChannelProxy mProxy = new MethodChannelProxy(); @Override public void onCreate() { mState = STATE_CREATED; mProxy.create(); } private class MethodChannelProxy { private void create() { if (mState == STATE_UNKNOW) { invokeChannelUnsafe(\u0026#34;didInitPageContainer\u0026#34;, mContainer.getContainerUrl(), mContainer.getContainerUrlParams(), mUniqueId ); //Debuger.log(\u0026#34;didInitPageContainer\u0026#34;);  mState = STATE_CREATED; } } public void invokeChannelUnsafe(String method, String url, Map params, String uniqueId) { HashMap\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;pageName\u0026#34;, url); args.put(\u0026#34;params\u0026#34;, params); args.put(\u0026#34;uniqueId\u0026#34;, uniqueId); FlutterBoost.instance().channel().invokeMethodUnsafe(method, args);//goto dart ContainerCoordinator._onMethodCall,利用flutter自带的methodChannel机制，反向调用native-\u0026gt;dart  } } ContainerCoordinator._onMethodCall //ContainerCoordinator Future\u0026lt;dynamic\u0026gt; _onMethodCall(MethodCall call) { Logger.log(\u0026#34;onMetohdCall ${call.method}\u0026#34;); switch (call.method) { case \u0026#34;didInitPageContainer\u0026#34;: { String pageName = call.arguments[\u0026#34;pageName\u0026#34;]; Map params = call.arguments[\u0026#34;params\u0026#34;]; String uniqueId = call.arguments[\u0026#34;uniqueId\u0026#34;]; _nativeContainerDidInit(pageName, params, uniqueId); } break; case \u0026#34;didShowPageContainer\u0026#34;: { String pageName = call.arguments[\u0026#34;pageName\u0026#34;]; Map params = call.arguments[\u0026#34;params\u0026#34;]; String uniqueId = call.arguments[\u0026#34;uniqueId\u0026#34;]; nativeContainerDidShow(pageName, params, uniqueId); } break; _nativeContainerDidInit bool _nativeContainerDidInit(String name, Map params, String pageId) { performContainerLifeCycle(_createContainerSettings(name, params, pageId),ContainerLifeCycle.Init); return true; } _createContainerSettings BoostContainerSettings _createContainerSettings( String name, Map params, String pageId) { Widget page; final BoostContainerSettings routeSettings = BoostContainerSettings(//main  uniqueId: pageId, name: name, params: params, builder: (BuildContext ctx) {//main  //Try to build a page using keyed builder.  if (_pageBuilders[name] != null) { page = _pageBuilders[name](name, params, pageId);//main  } //Build a page using default builder.  if (page == null \u0026amp;\u0026amp; _defaultPageBuilder != null) { page = _defaultPageBuilder(name, params, pageId); } assert(page != null); Logger.log(\u0026#39;build widget:$pagefor page:$name($pageId)\u0026#39;); return page; }); return routeSettings; } BoostFlutterActivity.onResume @Override protected void onResume() { super.onResume(); lifecycle.handleLifecycleEvent(Lifecycle.Event.ON_RESUME); delegate.onResume(); } void onResume() { mSyncer.onAppear();//main  ensureAlive(); flutterEngine.getLifecycleChannel().appIsResumed(); BoostPluginRegistry registry = (BoostPluginRegistry) FlutterBoost.instance().getPluginRegistry(); ActivityPluginBinding binding = registry.getRegistrarAggregate().getActivityPluginBinding(); if (binding != null \u0026amp;\u0026amp; (binding.getActivity() != this.host.getActivity())) { flutterEngine.getActivityControlSurface().attachToActivity( host.getActivity(), host.getLifecycle() ); } } mSyncer.onAppear() //ContainerRecord @Override public void onAppear() { Utils.assertCallOnMainThread(); if (mState != STATE_CREATED \u0026amp;\u0026amp; mState != STATE_DISAPPEAR) { Debuger.exception(\u0026#34;state error\u0026#34;); } mState = STATE_APPEAR; mManager.pushRecord(this); mProxy.appear(); mContainer.getBoostFlutterView().onAttach(); } ContainerCoordinator.nativeContainerDidShow bool nativeContainerDidShow(String name, Map params, String pageId) { FlutterBoost.containerManager?.showContainer(_createContainerSettings(name, params, pageId)); ContainerManagerState.showContainer BoostContainerManager extends StatefulWidget { @override ContainerManagerState createState() =\u0026gt; ContainerManagerState(); } ContainerManagerState extends State\u0026lt;BoostContainerManager\u0026gt; { BoostContainer _onstage; //Current visible container.  BoostContainerState get onstageContainer =\u0026gt; _stateOf(_onstage); List\u0026lt;_ContainerOverlayEntry\u0026gt; _leastEntries; final GlobalKey\u0026lt;OverlayState\u0026gt; _overlayKey = GlobalKey\u0026lt;OverlayState\u0026gt;(); //If container exists bring it to front else create a container.  void showContainer(BoostContainerSettings settings) { if (settings.uniqueId == _onstage.settings.uniqueId) { _onShownContainerChanged(null, settings.uniqueId); return; } final int index = _offstage.indexWhere((BoostContainer container) =\u0026gt; container.settings.uniqueId == settings.uniqueId); if (index \u0026gt; -1) { _offstage.add(_onstage); _onstage = _offstage.removeAt(index); setState(() {}); } else { pushContainer(settings);//main  } } } pushContainer void pushContainer(BoostContainerSettings settings) { assert(settings.uniqueId != _onstage.settings.uniqueId); assert(_offstage.every((BoostContainer container) =\u0026gt; container.settings.uniqueId != settings.uniqueId)); _offstage.add(_onstage); _onstage = BoostContainer.obtain(widget.initNavigator, settings);//main  setState(() {}); } BoostContainer.obtain BoostContainer extends Navigator { final BoostContainerSettings settings; @override BoostContainerState createState() =\u0026gt; BoostContainerState(); @override StatefulElement createElement() =\u0026gt; ContainerElement(this); factory BoostContainer.obtain( Navigator navigator, BoostContainerSettings settings) =\u0026gt; BoostContainer( key: GlobalKey\u0026lt;BoostContainerState\u0026gt;(), settings: settings, onGenerateRoute: (RouteSettings routeSettings) {//main  if (routeSettings.name == \u0026#39;/\u0026#39;) { return BoostPageRoute\u0026lt;dynamic\u0026gt;(//main  pageName: settings.name, params: settings.params, uniqueId: settings.uniqueId, animated: false, settings: routeSettings, builder: settings.builder);//main  } else { return navigator.onGenerateRoute(routeSettings); } }, observers: \u0026lt;NavigatorObserver\u0026gt;[ ContainerNavigatorObserver.bindContainerManager() ], onUnknownRoute: navigator.onUnknownRoute); } BoostContainerState extends NavigatorState ContainerManagerState.setState @override void setState(VoidCallback fn) { if (SchedulerBinding.instance.schedulerPhase == SchedulerPhase.persistentCallbacks) { SchedulerBinding.instance.addPostFrameCallback((Duration duration) { _refreshOverlayEntries(); }); } else { _refreshOverlayEntries();//main  } fn(); //return super.setState(fn);  } void _refreshOverlayEntries() { final OverlayState overlayState = _overlayKey.currentState; final List\u0026lt;BoostContainer\u0026gt; containers = \u0026lt;BoostContainer\u0026gt;[]; containers.addAll(_offstage); assert(_onstage != null, \u0026#39;Should have a least one BoostContainer\u0026#39;); containers.add(_onstage); _leastEntries = containers .map\u0026lt;_ContainerOverlayEntry\u0026gt;( (BoostContainer container) =\u0026gt; _ContainerOverlayEntry(container)) .toList(growable: false); overlayState.insertAll(_leastEntries);//main  SchedulerBinding.instance.addPostFrameCallback((Duration timeStamp) { final String now = _onstage.settings.uniqueId; if (_lastShownContainer != now) { final String old = _lastShownContainer; _lastShownContainer = now; _onShownContainerChanged(old, now);//main  } updateFocuse(); }); void _onShownContainerChanged(String old, String now) { FlutterBoost.singleton.channel.invokeMethod(\u0026#39;onShownContainerChanged\u0026#39;,properties); } BoostPageRoute BoostPageRoute\u0026lt;T\u0026gt; extends MaterialPageRoute\u0026lt;T\u0026gt; { final String pageName; final String uniqueId; final Map params; final bool animated; final WidgetBuilder builder; final RouteSettings settings; static BoostPageRoute\u0026lt;T\u0026gt; of\u0026lt;T\u0026gt;(BuildContext context) { final Route\u0026lt;T\u0026gt; route = ModalRoute.of(context); if (route != null \u0026amp;\u0026amp; route is BoostPageRoute\u0026lt;T\u0026gt;) { return route; } else { throw Exception(\u0026#39;not in a BoostPageRoute\u0026#39;); } } BoostPageRoute( {Key stubKey, this.pageName, this.params, this.uniqueId, this.animated, this.builder, this.settings}) : super( builder: (BuildContext context) =\u0026gt; Stub(stubKey, builder(context)), settings: settings); @immutable class Stub extends StatefulWidget { final Widget child; const Stub(Key key, this.child) : super(key: key); @override _StubState createState() =\u0026gt; _StubState(); } class _StubState extends State\u0026lt;Stub\u0026gt; { @override Widget build(BuildContext context) =\u0026gt; widget.child; } } main.dart main void main() { runApp(MyApp()); } class MyApp extends StatefulWidget { @override _MyAppState createState() =\u0026gt; _MyAppState(); } class _MyAppState extends State\u0026lt;MyApp\u0026gt; { @override void initState() { super.initState(); FlutterBoost.singleton.registerPageBuilders({//main  \u0026#39;embeded\u0026#39;: (pageName, params, _)=\u0026gt;EmbededFirstRouteWidget(), \u0026#39;first\u0026#39;: (pageName, params, _) =\u0026gt; FirstRouteWidget(), \u0026#39;second\u0026#39;: (pageName, params, _) =\u0026gt; SecondRouteWidget(), \u0026#39;tab\u0026#39;: (pageName, params, _) =\u0026gt; TabRouteWidget(), \u0026#39;platformView\u0026#39;: (pageName, params, _) =\u0026gt; PlatformRouteWidget(), \u0026#39;flutterFragment\u0026#39;: (pageName, params, _) =\u0026gt; FragmentRouteWidget(params), ///可以在native层通过 getContainerParams 来传递参数  \u0026#39;flutterPage\u0026#39;: (pageName, params, _) { print(\u0026#34;flutterPage params:$params\u0026#34;); return FlutterRouteWidget(params:params); }, }); } @override Widget build(BuildContext context) { return MaterialApp( title: \u0026#39;Flutter Boost example\u0026#39;, builder: FlutterBoost.init(postPush: _onRoutePushed),//main  home: Container()); } void _onRoutePushed( String pageName, String uniqueId, Map params, Route route, Future _) { } registerPageBuilders FlutterBoost\ntypedef Widget PageBuilder(String pageName, Map params, String uniqueId); ///Register a map builders  void registerPageBuilders(Map\u0026lt;String, PageBuilder\u0026gt; builders) { ContainerCoordinator.singleton.registerPageBuilders(builders); } ContainerCoordinator\nvoid registerPageBuilders(Map\u0026lt;String, PageBuilder\u0026gt; builders) { if (builders?.isNotEmpty == true) { _pageBuilders.addAll(builders);//main  } } init FlutterBoost\nstatic TransitionBuilder init( {TransitionBuilder builder, PrePushRoute prePush, PostPushRoute postPush}) { if (Platform.isAndroid) { onPageStart(); } return (BuildContext context, Widget child) { assert(child is Navigator, \u0026#39;child must be Navigator, what is wrong?\u0026#39;); final BoostContainerManager manager = BoostContainerManager( key: _instance.containerManagerKey, initNavigator: child, prePushRoute: prePush, postPushRoute: postPush); if (builder != null) { return builder(context, manager); } else { return manager; } }; 总结  初始化engine，调用dart main方法，注册页面url和widget的映射关系 startActivity前在intent里配置页面url container_manager控制showContainer重绘，重新build时选择新的route 为什么不使用官方的routes+Navigator控制当前的flutter页面?  参考 FlutterBoost open Future\u0026lt;Map\u0026lt;dynamic, dynamic\u0026gt;\u0026gt; open(String url, {Map\u0026lt;dynamic, dynamic\u0026gt; urlParams, Map\u0026lt;dynamic, dynamic\u0026gt; exts}) { Map\u0026lt;dynamic, dynamic\u0026gt; properties = new Map\u0026lt;dynamic, dynamic\u0026gt;(); properties[\u0026#34;url\u0026#34;] = url; properties[\u0026#34;urlParams\u0026#34;] = urlParams; properties[\u0026#34;exts\u0026#34;] = exts; return channel.invokeMethod\u0026lt;Map\u0026lt;dynamic, dynamic\u0026gt;\u0026gt;(\u0026#39;openPage\u0026#39;, properties); } FlutterEngine /* \u0026lt;p\u0026gt; * To start rendering Flutter content to the screen, use {@link #getRenderer()} to obtain a * {@link FlutterRenderer} and then attach a {@link RenderSurface}. Consider using a * {@link io.flutter.embedding.android.FlutterView} as a {@link RenderSurface}.*/ FlutterEngine /** \\* The rendering system associated with this {@code FlutterEngine}. \\* \u0026lt;p\u0026gt; \\* To render a Flutter UI that is produced by this {@code FlutterEngine}\u0026#39;s Dart code, attach \\* a {@link RenderSurface} to this \\* {@link FlutterRenderer}. */ @NonNull public FlutterRenderer getRenderer() { return renderer; } FlutterRenderer private final FlutterJNI flutterJNI; startRenderingToSurface /** \\* Notifies Flutter that the given {@code surface} was created and is available for Flutter \\* rendering. \\* \u0026lt;p\u0026gt; \\* See {@link android.view.SurfaceHolder.Callback} and \\* {@link android.view.TextureView.SurfaceTextureListener} */ public void startRenderingToSurface(@NonNull Surface surface) { if (this.surface != null) { stopRenderingToSurface(); } this.surface = surface; flutterJNI.onSurfaceCreated(surface); } RenderSurface /** \\* Owns a {@code Surface} that {@code FlutterRenderer} would like to paint. \\* \u0026lt;p\u0026gt; \\* {@code RenderSurface} is responsible for providing a {@code Surface} to a given \\* {@code FlutterRenderer} when requested, and then notify that {@code FlutterRenderer} when \\* the {@code Surface} changes, or is destroyed. \\* \u0026lt;p\u0026gt; \\* The behavior of providing a {@code Surface} is delegated to this interface because the timing \\* of a {@code Surface}\u0026#39;s availability is determined by Android. Therefore, an accessor method \\* would not fulfill the requirements. Therefore, a {@code RenderSurface} is given a \\* {@code FlutterRenderer}, which the {@code RenderSurface} is expected to notify as a \\* {@code Surface} becomes available, changes, or is destroyed. */ RenderSurface { /** \\* Returns the {@code FlutterRenderer} that is attached to this {@code RenderSurface}, or \\* null if no {@code FlutterRenderer} is currently attached. */ @Nullable FlutterRenderer getAttachedRenderer(); /** \\* Instructs this {@code RenderSurface} to give its {@code Surface} to the given \\* {@code FlutterRenderer} so that Flutter can paint pixels on it. \\* \u0026lt;p\u0026gt; \\* After this call, {@code RenderSurface} is expected to invoke the following methods on \\* {@link FlutterRenderer} at the appropriate times: \\* \u0026lt;ol\u0026gt; \\* \u0026lt;li\u0026gt;{@link FlutterRenderer#startRenderingToSurface(Surface)}\u0026lt;/li\u0026gt; \\* \u0026lt;li\u0026gt;{@link FlutterRenderer#surfaceChanged(int, int)}}\u0026lt;/li\u0026gt; \\* \u0026lt;li\u0026gt;{@link FlutterRenderer#stopRenderingToSurface()}\u0026lt;/li\u0026gt; \\* \u0026lt;/ol\u0026gt; */ void attachToRenderer(@NonNull FlutterRenderer renderer); } XFlutterView attachToFlutterEngine public void attachToFlutterEngine( @NonNull FlutterEngine flutterEngine ) { Log.d(TAG, \u0026#34;Attaching to a FlutterEngine: \u0026#34; + flutterEngine); if (isAttachedToFlutterEngine()) { if (flutterEngine == this.flutterEngine) { // We are already attached to this FlutterEngine  Log.d(TAG, \u0026#34;Already attached to this engine. Doing nothing.\u0026#34;); return; } // Detach from a previous FlutterEngine so we can attach to this new one.  Log.d(TAG, \u0026#34;Currently attached to a different engine. Detaching and then attaching\u0026#34; \\+ \u0026#34; to new engine.\u0026#34;); detachFromFlutterEngine(); } this.flutterEngine = flutterEngine; // Instruct our FlutterRenderer that we are now its designated RenderSurface.  FlutterRenderer flutterRenderer = this.flutterEngine.getRenderer(); flutterRenderer.attachToRenderSurface(renderSurface); ContainerManagerState _ContainerOverlayEntry ContainerManagerState extends State\u0026lt;BoostContainerManager\u0026gt; { class _ContainerOverlayEntry extends OverlayEntry { bool _removed = false; _ContainerOverlayEntry(BoostContainer container) : super( builder: (BuildContext ctx) =\u0026gt; container, opaque: true, maintainState: true); @override Widget build(BuildContext context) { return Overlay( key: _overlayKey, initialEntries: const \u0026lt;OverlayEntry\u0026gt;[], ); } } providePlatformPlugin public PlatformPlugin providePlatformPlugin(@Nullable Activity activity, @NonNull FlutterEngine flutterEngine) { if (activity != null) { return new PlatformPlugin(getActivity(), flutterEngine.getPlatformChannel()); } } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/flutterboost3/",
	"title": "FlutterBoost3",
	"tags": [],
	"description": "",
	"content": "Native层设计 FlutterBoostPlugin类设计 FlutterBoost.setup 1. initialize default engine public void setup(Application application, FlutterBoostDelegate delegate, Callback callback, FlutterBoostOptions options) { // 1. initialize default engine  FlutterEngine engine = FlutterEngineCache.getInstance().get(ENGINE_ID); if (engine == null) { if (options == null) options = FlutterBoostOptions.createDefault(); engine = new FlutterEngine(application, options.shellArgs()); engine.getNavigationChannel().setInitialRoute(options.initialRoute()); engine.getDartExecutor().executeDartEntrypoint(new DartExecutor.DartEntrypoint( FlutterMain.findAppBundlePath(), options.dartEntrypoint())); if(callback != null) callback.onStart(engine); FlutterEngineCache.getInstance().put(ENGINE_ID, engine); } // 2. set delegate  getPlugin().setDelegate(delegate); //3. register ActivityLifecycleCallbacks  setupActivityLifecycleCallback(application); } 2. setDelegateToPlugin public FlutterEngine(@NonNull Context context, @Nullable String[] dartVmArgs) { this(context, /* flutterLoader */ null, new FlutterJNI(), dartVmArgs, true);//最后的参数true表示automaticallyRegisterPlugins } public FlutterEngine( @NonNull Context context, @Nullable FlutterLoader flutterLoader, @NonNull FlutterJNI flutterJNI, @Nullable String[] dartVmArgs, boolean automaticallyRegisterPlugins) { this( context, flutterLoader, flutterJNI, new PlatformViewsController(), dartVmArgs, automaticallyRegisterPlugins); } //最终在FlutterEngine构造方法结尾进行如下操作  if (automaticallyRegisterPlugins) { registerPlugins(); } //反射调用自动生成的注册类的注册方法  private void registerPlugins() { try { Class\u0026lt;?\u0026gt; generatedPluginRegistrant = Class.forName(\u0026#34;io.flutter.plugins.GeneratedPluginRegistrant\u0026#34;); Method registrationMethod = generatedPluginRegistrant.getDeclaredMethod(\u0026#34;registerWith\u0026#34;, FlutterEngine.class); registrationMethod.invoke(null, this); } catch (Exception e) { Log.w( TAG, \u0026#34;Tried to automatically register plugins with FlutterEngine (\u0026#34; + this + \u0026#34;) but could not find and invoke the GeneratedPluginRegistrant.\u0026#34;); } } package io.flutter.plugins; /** * Generated file. Do not edit. * This file is generated by the Flutter tool based on the * plugins that support the Android platform. */ @Keep public final class GeneratedPluginRegistrant { public static void registerWith(@NonNull FlutterEngine flutterEngine) { flutterEngine.getPlugins().add(new com.idlefish.flutterboost.FlutterBoostPlugin()); flutterEngine.getPlugins().add(new io.flutter.plugins.flutter_plugin_android_lifecycle.FlutterAndroidLifecyclePlugin()); flutterEngine.getPlugins().add(new io.flutter.plugins.imagepicker.ImagePickerPlugin()); flutterEngine.getPlugins().add(new io.flutter.plugins.videoplayer.VideoPlayerPlugin()); } } public FlutterBoostPlugin getPlugin() { if (plugin == null) { FlutterEngine engine = FlutterEngineCache.getInstance().get(ENGINE_ID); if (engine == null) { throw new RuntimeException(\u0026#34;FlutterBoost might *not* have been initialized yet!!!\u0026#34;); } plugin = getFlutterBoostPlugin(engine); } return plugin; } public class FlutterBoostPlugin implements FlutterPlugin, Messages.NativeRouterApi { @Override public void onAttachedToEngine(FlutterPluginBinding binding) { Messages.NativeRouterApi.setup(binding.getBinaryMessenger(), this); channel = new Messages.FlutterRouterApi(binding.getBinaryMessenger()); } @Override public void onDetachedFromEngine(FlutterPluginBinding binding) { channel = null; } } 3. register ActivityLifecycleCallbacks private void setupActivityLifecycleCallback(Application application) { application.registerActivityLifecycleCallbacks(new BoostActivityLifecycle()); } private class BoostActivityLifecycle implements Application.ActivityLifecycleCallbacks { private int activityReferences = 0; private boolean isActivityChangingConfigurations = false; private void dispatchForegroundEvent() { FlutterBoost.instance().setAppIsInBackground(false); FlutterBoost.instance().getPlugin().onForeground(); } private void dispatchBackgroundEvent() { FlutterBoost.instance().setAppIsInBackground(true); FlutterBoost.instance().getPlugin().onBackground(); } } NativeStartFlutterActivity 正常native方式启动FlutterBoostActivity 对应FlutterBoostDelegate中pushFlutterRoute方法的执行\nIntent intent = new FlutterBoostActivity.CachedEngineIntentBuilder(FlutterBoostActivity.class, FlutterBoost.ENGINE_ID) .backgroundMode(FlutterActivityLaunchConfigs.BackgroundMode.opaque) .destroyEngineWithActivity(false) .url(\u0026#34;flutterPage\u0026#34;) .urlParams(params) .build(this); startActivityForResult(intent, REQUEST_CODE); FlutterBoostActivity public class FlutterBoostActivity extends FlutterActivity implements FlutterViewContainer { private static final String TAG = \u0026#34;FlutterBoostActivity\u0026#34;; private FlutterView flutterView; private FlutterViewContainerObserver observer; onCreate @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); observer = FlutterBoostPlugin.ContainerShadowNode.create(this, FlutterBoost.instance().getPlugin()); observer.onCreateView(); } onResume @Override public void onResume() { if (flutterView == null) { findFlutterView(getWindow().getDecorView());//递归遍历找到flutterView  } super.onResume(); if (Build.VERSION.SDK_INT == Build.VERSION_CODES.Q) { if (FlutterBoost.instance().isAppInBackground() \u0026amp;\u0026amp; !FlutterBoost.instance().getPlugin().isTopContainer(getUniqueId())) { Log.w(TAG, \u0026#34;Unexpected activity lifecycle event on Android Q. \u0026#34; + \u0026#34;See https://issuetracker.google.com/issues/185693011 for more details.\u0026#34;); return; } } observer.onAppear();//main  ActivityAndFragmentPatch.onResumeAttachToFlutterEngine(flutterView, getFlutterEngine(), this);//main } //class ContainerShadowNode @Override public void onAppear() { plugin.reorderContainer(getUniqueId(), this); plugin.pushRoute(getUniqueId(), getUrl(), getUrlParams(), null);//main  plugin.onContainerShow(getUniqueId()); Log.v(TAG, \u0026#34;#onAppear: \u0026#34; + getUniqueId() + \u0026#34;, \u0026#34; + plugin.getContainers()); } //FlutterBoostPlugin public void pushRoute(String uniqueId, String pageName, Map\u0026lt;String, Object\u0026gt; arguments, final Reply\u0026lt;Void\u0026gt; callback) { if (channel != null) { Messages.CommonParams params = new Messages.CommonParams(); params.setUniqueId(uniqueId); params.setPageName(pageName); params.setArguments((Map\u0026lt;Object, Object\u0026gt;)(Object) arguments); channel.pushRoute(params, reply -\u0026gt; { if (callback != null) { callback.reply(null); } }); } else { throw new RuntimeException(\u0026#34;FlutterBoostPlugin might *NOT* have attached to engine yet!\u0026#34;); } } BoostFlutterRouterApi_pushRoute /// The MessageChannel counterpart on the Dart side. class BoostFlutterRouterApi extends FlutterRouterApi { final FlutterBoostAppState appState; static BoostFlutterRouterApi _instance; @override void pushRoute(CommonParams arg) { appState.push( arg.pageName, uniqueId: arg.uniqueId, arguments: Map\u0026lt;String, dynamic\u0026gt;.from(arg.arguments ?? \u0026lt;String, dynamic\u0026gt;{}), withContainer: true, ); } void push(String pageName, {String uniqueId, Map\u0026lt;String, dynamic\u0026gt; arguments, bool withContainer}) { _cancelActivePointers(); final existed = _findContainerByUniqueId(uniqueId); if (existed != null) { if (topContainer?.pageInfo?.uniqueId != uniqueId) { containers.remove(existed); containers.add(existed); //move the overlayEntry which matches this existing container to the top  refreshOnMoveToTop(existed); } } else { final pageInfo = PageInfo( pageName: pageName, uniqueId: uniqueId ?? _createUniqueId(pageName), arguments: arguments, withContainer: withContainer); if (withContainer) { final container = _createContainer(pageInfo); final previousContainer = topContainer; containers.add(container); BoostLifecycleBinding.instance .containerDidPush(container, previousContainer); // Add a new overlay entry with this container  refreshOnPush(container);//main  } else { // In this case , we don\u0026#39;t need to change the overlayEntries data,  // so we don\u0026#39;t call any refresh method  topContainer.pages.add(BoostPage.create(pageInfo)); topContainer.refresh(); } } Logger.log(\u0026#39;push page, uniqueId=$uniqueId, existed=$existed,\u0026#39; \u0026#39; withContainer=$withContainer, arguments:$arguments, $containers\u0026#39;); } void refreshOnPush(BoostContainer container) { refreshSpecificOverlayEntries(container, BoostSpecificEntryRefreshMode.add); assert(() { _saveStackForHotRestart(); return true; }()); } ///Refresh an specific entry instead of all of entries to enhance the performace /// ///[container] : The container you want to operate, it is related with /// internal [OverlayEntry] ///[mode] : The [BoostSpecificEntryRefreshMode] you want to choose void refreshSpecificOverlayEntries( BoostContainer container, BoostSpecificEntryRefreshMode mode) { //Get OverlayState from global key  final overlayState = overlayKey.currentState; if (overlayState == null) { return; } final hasScheduledFrame = SchedulerBinding.instance.hasScheduledFrame; final framesEnabled = SchedulerBinding.instance.framesEnabled; //deal with different situation  switch (mode) { case BoostSpecificEntryRefreshMode.add: final entry = _ContainerOverlayEntry(container); _lastEntries.add(entry); overlayState.insert(entry);//main  break; /// Insert the given entry into the overlay. /// /// If `below` is non-null, the entry is inserted just below `below`. /// If `above` is non-null, the entry is inserted just above `above`. /// Otherwise, the entry is inserted on top. /// /// It is an error to specify both `above` and `below`. void insert(OverlayEntry entry, { OverlayEntry? below, OverlayEntry? above }) { assert(_debugVerifyInsertPosition(above, below)); assert(!_entries.contains(entry), \u0026#39;The specified entry is already present in the Overlay.\u0026#39;); assert(entry._overlay == null, \u0026#39;The specified entry is already present in another Overlay.\u0026#39;); entry._overlay = this; setState(() { _entries.insert(_insertionIndex(below, above), entry); }); } Native侧onResumeAttachToFlutterEngine public static void onResumeAttachToFlutterEngine(FlutterView flutterView, FlutterEngine flutterEngine, FlutterViewContainer container) { flutterView.attachToFlutterEngine(flutterEngine);//main  flutterEngine.getLifecycleChannel().appIsResumed(); } NativeStartNativeActivity 直接启动即可\ncontext.startActivity(intent); FlutterStartNativeActivity BoostNavigator.instance.push(\u0026#34;native\u0026#34;), instance /// A object that manages a set of pages with a hybrid stack. /// class BoostNavigator { BoostNavigator._(); static final BoostNavigator _instance = BoostNavigator._(); static BoostNavigator get instance { _instance.appState ??= overlayKey.currentContext ?.findAncestorStateOfType\u0026lt;FlutterBoostAppState\u0026gt;(); return _instance; } } push /// Push the page with the given [name] onto the hybrid stack. Future\u0026lt;T\u0026gt; push\u0026lt;T extends Object\u0026gt;(String name, {Map\u0026lt;String, dynamic\u0026gt; arguments, bool withContainer = false}) async { return future.then((dynamic _state) { final state = _state as InterceptorState\u0026lt;dynamic\u0026gt;; if (state.data is BoostInterceptorOption) { assert(state.type == InterceptorResultType.next); pushOption = state.data; if (isFlutterPage(pushOption.name)) {//根据main.dart中的routeFactory和配置的routerMap，判断是否是flutter page  //flutter start flutter page  return appState.pushWithResult(pushOption.name, arguments: pushOption.arguments, withContainer: withContainer); } else { //flutter start native page  final params = CommonParams() ..pageName = pushOption.name ..arguments = pushOption.arguments; appState.nativeRouterApi.pushNativeRoute(params); return appState.pendNativeResult(pushOption.name); } } else { assert(state.type == InterceptorResultType.resolve); return Future\u0026lt;T\u0026gt;.value(state.data as T); } }); NativeRouterApi.pushNativeRoute channel通信 // Autogenerated from Pigeon class NativeRouterApi { Future\u0026lt;void\u0026gt; pushNativeRoute(CommonParams arg) async { final Object encoded = arg.encode(); const BasicMessageChannel\u0026lt;Object\u0026gt; channel = BasicMessageChannel\u0026lt;Object\u0026gt;(\u0026#39;dev.flutter.pigeon.NativeRouterApi.pushNativeRoute\u0026#39;, StandardMessageCodec()); final Map\u0026lt;Object, Object\u0026gt; replyMap = await channel.send(encoded) as Map\u0026lt;Object, Object\u0026gt;; if (replyMap == null) { throw PlatformException( code: \u0026#39;channel-error\u0026#39;, message: \u0026#39;Unable to establish connection on channel.\u0026#39;, details: null, ); } else if (replyMap[\u0026#39;error\u0026#39;] != null) { final Map\u0026lt;Object, Object\u0026gt; error = (replyMap[\u0026#39;error\u0026#39;] as Map\u0026lt;Object, Object\u0026gt;); throw PlatformException( code: (error[\u0026#39;code\u0026#39;] as String), message: error[\u0026#39;message\u0026#39;] as String, details: error[\u0026#39;details\u0026#39;], ); } else { // noop  } } // Autogenerated from Pigeon (v0.1.23)  /** Sets up an instance of `NativeRouterApi` to handle messages through the `binaryMessenger`. */ static void setup(BinaryMessenger binaryMessenger, NativeRouterApi api) { { BasicMessageChannel\u0026lt;Object\u0026gt; channel = new BasicMessageChannel\u0026lt;\u0026gt;(binaryMessenger, \u0026#34;dev.flutter.pigeon.NativeRouterApi.pushNativeRoute\u0026#34;, new StandardMessageCodec()); if (api != null) { channel.setMessageHandler((message, reply) -\u0026gt; { Map\u0026lt;String, Object\u0026gt; wrapped = new HashMap\u0026lt;\u0026gt;(); try { @SuppressWarnings(\u0026#34;ConstantConditions\u0026#34;) CommonParams input = CommonParams.fromMap((Map\u0026lt;String, Object\u0026gt;)message); api.pushNativeRoute(input);//main  wrapped.put(\u0026#34;result\u0026#34;, null); } catch (Error | RuntimeException exception) { wrapped.put(\u0026#34;error\u0026#34;, wrapError(exception)); } reply.reply(wrapped); }); } else { channel.setMessageHandler(null); } } //FlutterBoostPlugin @Override public void pushNativeRoute(Messages.CommonParams params) { if (delegate != null) { delegate.pushNativeRoute(params.getPageName(), (Map\u0026lt;String, Object\u0026gt;) (Object)params.getArguments()); } else { throw new RuntimeException(\u0026#34;FlutterBoostPlugin might *NOT* set delegate!\u0026#34;); } } 调用FlutterBoostDelegate的实现类启动native页面 public class MyFlutterBoostDelegate implements FlutterBoostDelegate { private final int REQUEST_CODE = 999; @Override public void pushNativeRoute(String pageName, Map\u0026lt;String, Object\u0026gt; arguments) { Intent intent = new Intent(FlutterBoost.instance().currentActivity(), NativePageActivity.class); FlutterBoost.instance().currentActivity().startActivityForResult(intent, REQUEST_CODE); } FlutterStartFlutterPage 继续上述的\nreturn future.then((dynamic _state) { final state = _state as InterceptorState\u0026lt;dynamic\u0026gt;; if (state.data is BoostInterceptorOption) { assert(state.type == InterceptorResultType.next); pushOption = state.data; if (isFlutterPage(pushOption.name)) {//flutter start flutter page  return appState.pushWithResult(pushOption.name, arguments: pushOption.arguments, withContainer: withContainer); Future\u0026lt;T\u0026gt; pushWithResult\u0026lt;T extends Object\u0026gt;(String pageName, {String uniqueId, Map\u0026lt;String, dynamic\u0026gt; arguments, bool withContainer}) { final completer = Completer\u0026lt;T\u0026gt;(); assert(uniqueId == null); uniqueId = _createUniqueId(pageName); if (withContainer) {//如果需要native层Activity容器包裹即将启动的页面  final params = CommonParams() ..pageName = pageName ..uniqueId = uniqueId ..arguments = arguments ?? \u0026lt;String, dynamic\u0026gt;{}; nativeRouterApi.pushFlutterRoute(params);//channel通知native启动flutter页面  } else {//否则，push到overlay  push(pageName, uniqueId: uniqueId, arguments: arguments, withContainer: false); } _pendingResult[uniqueId] = completer; return completer.future; } 这里的push参考上面的overlay添加流程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/engine/flutterenginecache/",
	"title": "FlutterEngineCache",
	"tags": [],
	"description": "",
	"content": "BaseOnFlutter2.0\nFlutterEngineCache public class FlutterEngineCache { private static FlutterEngineCache instance; private final Map\u0026lt;String, FlutterEngine\u0026gt; cachedEngines = new HashMap\u0026lt;\u0026gt;(); } FlutterEngineInit graph LR FlutterApplication--\u0026gt;|after onCreate|flutterLoader.startInit--\u0026gt;similarToFlutter1.12 FlutterEngine--\u0026gt;initAssetManager FlutterEngine--\u0026gt;initDartExecutor FlutterEngine--\u0026gt;initMultipleChannels FlutterEngine--\u0026gt;flutterLoader.startInitAndBlockUtilComplete FlutterEngine--\u0026gt;flutterJNI.attachToNativeShell/Engine--\u0026gt;similarToFlutter1.12WhenConstuctFlutterView FlutterEngine--\u0026gt;initFlutterRendererAndPlatformViewsController FlutterEngine--\u0026gt;automaticallyRegisterPlugins FlutterEngine Constructor public FlutterEngine(@NonNull Context context, @Nullable String[] dartVmArgs) { this(context, /* flutterLoader */ null, new FlutterJNI(), dartVmArgs, true); } /** Fully configurable {@code FlutterEngine} constructor. */ public FlutterEngine( @NonNull Context context, @Nullable FlutterLoader flutterLoader, @NonNull FlutterJNI flutterJNI, @NonNull PlatformViewsController platformViewsController, @Nullable String[] dartVmArgs, boolean automaticallyRegisterPlugins, boolean waitForRestorationData) { AssetManager assetManager; try { assetManager = context.createPackageContext(context.getPackageName(), 0).getAssets(); } catch (NameNotFoundException e) { assetManager = context.getAssets(); } this.dartExecutor = new DartExecutor(flutterJNI, assetManager); this.dartExecutor.onAttachedToJNI(); DeferredComponentManager deferredComponentManager = FlutterInjector.instance().deferredComponentManager(); accessibilityChannel = new AccessibilityChannel(dartExecutor, flutterJNI); deferredComponentChannel = new DeferredComponentChannel(dartExecutor); keyEventChannel = new KeyEventChannel(dartExecutor); lifecycleChannel = new LifecycleChannel(dartExecutor); localizationChannel = new LocalizationChannel(dartExecutor); mouseCursorChannel = new MouseCursorChannel(dartExecutor); navigationChannel = new NavigationChannel(dartExecutor); platformChannel = new PlatformChannel(dartExecutor); restorationChannel = new RestorationChannel(dartExecutor, waitForRestorationData); settingsChannel = new SettingsChannel(dartExecutor); systemChannel = new SystemChannel(dartExecutor); textInputChannel = new TextInputChannel(dartExecutor); if (deferredComponentManager != null) { deferredComponentManager.setDeferredComponentChannel(deferredComponentChannel); } this.localizationPlugin = new LocalizationPlugin(context, localizationChannel); this.flutterJNI = flutterJNI; if (flutterLoader == null) { flutterLoader = FlutterInjector.instance().flutterLoader(); } if (!flutterJNI.isAttached()) { flutterLoader.startInitialization(context.getApplicationContext()); flutterLoader.ensureInitializationComplete(context, dartVmArgs); } flutterJNI.addEngineLifecycleListener(engineLifecycleListener); flutterJNI.setPlatformViewsController(platformViewsController); flutterJNI.setLocalizationPlugin(localizationPlugin); flutterJNI.setDeferredComponentManager(FlutterInjector.instance().deferredComponentManager()); // It should typically be a fresh, unattached JNI. But on a spawned engine, the JNI instance  // is already attached to a native shell. In that case, the Java FlutterEngine is created around  // an existing shell.  if (!flutterJNI.isAttached()) { attachToJni(); } // TODO(mattcarroll): FlutterRenderer is temporally coupled to attach(). Remove that coupling if  // possible.  this.renderer = new FlutterRenderer(flutterJNI); this.platformViewsController = platformViewsController; this.platformViewsController.onAttachedToJNI(); this.pluginRegistry = new FlutterEngineConnectionRegistry(context.getApplicationContext(), this, flutterLoader); if (automaticallyRegisterPlugins) { registerPlugins(); } } getNavigationChannel /** System channel that sends Flutter navigation commands from Android to Flutter. */ @NonNull public NavigationChannel getNavigationChannel() { return navigationChannel; } NavigationChannel public class NavigationChannel { private static final String TAG = \u0026#34;NavigationChannel\u0026#34;; @NonNull public final MethodChannel channel; public NavigationChannel(@NonNull DartExecutor dartExecutor) { this.channel = new MethodChannel(dartExecutor, \u0026#34;flutter/navigation\u0026#34;, JSONMethodCodec.INSTANCE); } public void setInitialRoute(@NonNull String initialRoute) { Log.v(TAG, \u0026#34;Sending message to set initial route to \u0026#39;\u0026#34; + initialRoute + \u0026#34;\u0026#39;\u0026#34;); channel.invokeMethod(\u0026#34;setInitialRoute\u0026#34;, initialRoute); } public void pushRoute(@NonNull String route) { Log.v(TAG, \u0026#34;Sending message to push route \u0026#39;\u0026#34; + route + \u0026#34;\u0026#39;\u0026#34;); channel.invokeMethod(\u0026#34;pushRoute\u0026#34;, route); } public void popRoute() { Log.v(TAG, \u0026#34;Sending message to pop route.\u0026#34;); channel.invokeMethod(\u0026#34;popRoute\u0026#34;, null); } public void setMethodCallHandler(@Nullable MethodChannel.MethodCallHandler handler) { channel.setMethodCallHandler(handler); } } FlutterActivity.cachedEngineId @Override protected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); delegate = new FlutterActivityAndFragmentDelegate(this); delegate.onAttach(this);//main  delegate.onRestoreInstanceState(savedInstanceState); } //FlutterActivityAndFragmentDelegate void onAttach(@NonNull Context context) { ensureAlive(); // When \u0026#34;retain instance\u0026#34; is true, the FlutterEngine will survive configuration  // changes. Therefore, we create a new one only if one does not already exist.  if (flutterEngine == null) { setupFlutterEngine(); } ...... } //FlutterActivityAndFragmentDelegate /* package */ void setupFlutterEngine() { // First, check if the host wants to use a cached FlutterEngine.  String cachedEngineId = host.getCachedEngineId(); if (cachedEngineId != null) { flutterEngine = FlutterEngineCache.getInstance().get(cachedEngineId); isFlutterEngineFromHost = true; if (flutterEngine == null) { throw new IllegalStateException( \u0026#34;The requested cached FlutterEngine did not exist in the FlutterEngineCache: \u0026#39;\u0026#34; + cachedEngineId + \u0026#34;\u0026#39;\u0026#34;); } return; } /** * Returns the ID of a statically cached {@link FlutterEngine} to use within this {@code * FlutterActivity}, or {@code null} if this {@code FlutterActivity} does not want to use a cached * {@link FlutterEngine}. */ @Override @Nullable public String getCachedEngineId() { return getIntent().getStringExtra(EXTRA_CACHED_ENGINE_ID); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/engine/flutterenginedebug%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/",
	"title": "FlutterEngineDebug环境搭建",
	"tags": [],
	"description": "",
	"content": "FlutterEngine开发环境 https://github.com/flutter/flutter/wiki/Setting-up-the-Engine-development-environment\nEditor autocomplete support VSCode with C/C++ Intellisense VSCode can provide some IDE features using the C/C++ extension. It will provide basic support on install without needing any additional configuration. There will probably be some issues, like header not found errors and incorrect jump to definitions.\nIntellisense can also use our compile_commands.json for more robust functionality. Either symlink src/out/compile_commands.json to the project root at src/flutter or provide an absolute path to it in the c_cpp_properties.json config file. See \u0026ldquo;compile commands\u0026rdquo; in the c_cpp_properties.json reference. This will likely resolve the basic issues mentioned above.\nFor adding IDE support to the Java code in the engine with VSCode, see \u0026ldquo;Using VSCode as an IDE for the Android Embedding\u0026rdquo;.\nUsing VSCode as an IDE for the Android Embedding Create a .classpath file in engine/src/flutter/shell/platform/android so that the IDE can understand the project structure. Here\u0026rsquo;s an example file that worked as of the time of this writing.实测.classpath是放入engine\\shell\\platform\\android下\nIt should contain links to all of the engine\u0026rsquo;s JAR dependencies in third_party, including the Android SDK. It should also list the test/ subdirectory as a src directory to fix incorrect package errors on the unit test files.\nFlutterEngine编译 搭建Flutter Engine源码编译环境\nhttps://chromium.googlesource.com/external/github.com/flutter/engine/+/b7358b33dbd61e124720165dd939fa49cbd0ecb6/CONTRIBUTING.md\nhttps://github.com/flutter/flutter/wiki/Compiling-the-engine#general-compilation-tips\n按照上述官网步骤配置(位置/Users/qianpianpian/git/flutter/fork/engine):\n git pull upstream master in src/flutter to update the Flutter Engine repo. gclient sync in engine directory to update dependencies. ./flutter/tools/gn \u0026ndash;android \u0026ndash;android-cpu x64 \u0026ndash;unoptimized in src directory ninja -C out/android_debug_unopt_x64 in src directory ./flutter/tools/gn \u0026ndash;unoptimized in src directory ninja -C out/host_debug_unopt in src directory  还需:\n 将本地用户目录/.ssh/中的公钥复制添加到GitHub个人settings下的ssh keys配置中。 安装Xcode:  2.1. Install Xcode (get it from https://appstore.com/mac/apple/xcode) if you don\u0026rsquo;t have it yet.\n2.2. Accept the Terms and Conditions.\n2.3. Ensure Xcode app is in the /Applications directory (NOT /Users/{user}/Applications).\n2.4. Point xcode-select to the Xcode app Developer directory using the following command: sudo xcode-select -s /Applications/Xcode.app/Contents/Developer\n输出的unstripped so:/Users/qianpianpian/git/flutter/fork/engine/src/out/android_debug_unopt_x64/libflutter.so\nFlutterEngine Debug https://github.com/flutter/flutter/wiki/Debugging-the-engine\nFlutter Engine源码调试\nFlutter Engine C++ 源码调试初探\nhttps://github.com/lizhangqu/flutter_lldb\njava和dart使用Android Studio调试，两边对应native层用VSCode调试\nVisual Studio Code LLDB Debug VSCode中调试相对比较简单(且支持源码点击跳转,AS不支持)，你除了要安装VSCode外，你还需要安装两个VSCode的插件。VS Code调试时栈帧源码显示为汇编的原因是没有找到源码文件，找到之后就会是正确的源码文件\n C/C++ for Visual Studio Code CodeLLDB   在需要启动的flutter app目录(例如flutterboost项目)下执行  flutter run --local-engine-src-path=/Users/qianpianpian/git/flutter/fork/engine/src --local-engine=/Users/qianpianpian/git/flutter/fork/engine/src/out/android_debug_unopt_x64  将out目录下的compile_commands.json文件拷贝到src/futter目录下，然后用VSCode打开src/flutter目录即可。\n  在/Users/qianpianpian/git/flutter/flutter_lldb下执行\n  ./flutter_lldb \\ --local-engine-src-path=/Users/qianpianpian/git/flutter/fork/engine/src \\ --local-engine=android_debug_unopt_x64 \\ com.idlefish.flutterboost.example 这里提示killall: lldb-server: No such process也不影响正常调试\n  failed to listen: Address already in use\u0026hellip;..returned non-zero exit status 255,需要虚拟机重新启动\n  更换编译的cpu架构时，需要修改flutter_lldb脚本中的_get_android_lldb_server方法，返回正确的lldb_server路径\n  复制第一个json到.vscode/launch.json中  { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;remote_lldb\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;lldb\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;attach\u0026#34;, \u0026#34;pid\u0026#34;: \u0026#34;4427\u0026#34;, \u0026#34;initCommands\u0026#34;: [ \u0026#34;platform select remote-android\u0026#34;, \u0026#34;platform connect unix-abstract-connect:///data/data/com.idlefish.flutterboost.example/debug.socket\u0026#34; ], \u0026#34;postRunCommands\u0026#34;: [ \u0026#34;add-dsym /Users/qianpianpian/git/flutter/fork/engine/src/out/android_debug_unopt_x64/libflutter.so\u0026#34;, \u0026#34;settings set target.source-map /Users/qianpianpian/git/flutter/fork/engine/src /Users/qianpianpian/git/flutter/fork/engine/src\u0026#34; ], } ] }  开始调试remote_lldb，在debug tab中点击remote_lldb启动attach，同时配合着lldb命令设置断点(未涉及到pause和resume debugger)\n  操作flutter app，能够触发前面设置的断点处流程\n  VSCode调试时查看字符数组内容:\nprint message_data (uint8_t *) $7 = 0x00000000730ac820 \u0026#34;{\\\u0026#34;textScaleFactor\\\u0026#34;:1,\\\u0026#34;alwaysUse24HourFormat\\\u0026#34;:false,\\\u0026#34;platformBrightness\\\u0026#34;:\\\u0026#34;light\\\u0026#34;}\u0026#34; Android Studio LLDB Debug(可调试，但堆栈有误)   debug前导入engine/src/flutter/shell/platform/android到android studio，提示framework detected，不要点击进行配置，如果不小心点击了，删除.idea和gen即可(这个步骤没多大用，c代码不能点击跳转到定义)\n  在需要启动的flutter app目录下执行: flutter run \u0026ndash;local-engine=android_debug_unopt_x64\n  AS打开android文件夹，attach debugger(dual Java+native),此时AS弹出Java和C两个调试窗口，进入C的lldb调试窗口，依次选择debugger，LLDB选项卡；pause调试器\n   (lldb) add-dsym /Users/qianpianpian/git/flutter/fork/engine/src/out/android_debug_unopt_x64/libflutter.so symbol file \u0026#39;/Users/qianpianpian/git/flutter/fork/engine/src/out/android_debug_unopt_x64/libflutter.so\u0026#39; has been added to \u0026#39;/Users/qianpianpian/.lldb/module_cache/remote-android/.cache/688819DF-8C91-5E9A-5BD5-CD0B02CB2AE1-B35E2C42/libflutter.so\u0026#39; br s -n DispatchPlatformMessage resume debugger 操作flutter app，能够触发前面设置的断点处流程  其他参考 https://flutter.dev/docs/development/tools/sdk/upgrading\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/engine/flutterenginegroup/",
	"title": "FlutterEngineGroup",
	"tags": [],
	"description": "",
	"content": "FlutterEngineGroup构造 public class FlutterEngineGroup { final List\u0026lt;FlutterEngine\u0026gt; activeEngines = new ArrayList\u0026lt;\u0026gt;(); /** Create a FlutterEngineGroup whose child engines will share resources. */ public FlutterEngineGroup(@NonNull Context context) { this(context, null); } /** * Create a FlutterEngineGroup whose child engines will share resources. Use {@code dartVmArgs} to * pass flags to the Dart VM during initialization. */ public FlutterEngineGroup(@NonNull Context context, @Nullable String[] dartVmArgs) { FlutterLoader loader = FlutterInjector.instance().flutterLoader(); if (!loader.initialized()) { loader.startInitialization(context.getApplicationContext()); loader.ensureInitializationComplete(context, dartVmArgs); } } } createAndRunEngine public FlutterEngine createAndRunDefaultEngine(@NonNull Context context) { return createAndRunEngine(context, null); } public FlutterEngine createAndRunEngine( @NonNull Context context, @Nullable DartEntrypoint dartEntrypoint) { FlutterEngine engine = null; if (dartEntrypoint == null) { dartEntrypoint = DartEntrypoint.createDefault(); } if (activeEngines.size() == 0) { engine = createEngine(context); engine.getDartExecutor().executeDartEntrypoint(dartEntrypoint); } else { engine = activeEngines.get(0).spawn(context, dartEntrypoint); } activeEngines.add(engine); @VisibleForTesting /* package */ FlutterEngine createEngine(Context context) { return new FlutterEngine(context); } FlutterEngine.spawn @NonNull /*package*/ FlutterEngine spawn( @NonNull Context context, @NonNull DartEntrypoint dartEntrypoint) { if (!isAttachedToJni()) { throw new IllegalStateException( \u0026#34;Spawn can only be called on a fully constructed FlutterEngine\u0026#34;); } FlutterJNI newFlutterJNI = flutterJNI.spawn( dartEntrypoint.dartEntrypointFunctionName, dartEntrypoint.dartEntrypointLibrary); return new FlutterEngine( context, // Context.  null, // FlutterLoader. A null value passed here causes the constructor to get it from the  // FlutterInjector.  newFlutterJNI); // FlutterJNI. } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/gc/",
	"title": "GC",
	"tags": [],
	"description": "",
	"content": "类设计 runtime.cc\nRuntime::VisitRoots void Runtime::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) { /*RootVisitor是一个纯虚类，其定义了几个函数，供root访问时调用。参数flags有一个默认 值，为kVisitRootFlagAllRoots，表示要访问所有的root。*/ VisitNonConcurrentRoots(visitor); VisitConcurrentRoots(visitor, flags); } Runtime::VisitNonConcurrentRoots void Runtime::VisitNonConcurrentRoots(RootVisitor* visitor) { //1：调用所有Thread对象的VisitRoots函数  thread_list_-\u0026gt;VisitRoots(visitor); VisitNonThreadRoots(visitor);//接着看该函数的代码 } Thread::VisitRoots void Thread::VisitRoots(RootVisitor* visitor) { /*GetThreadId返回的是Thread tlsPtr_ thin_lock_thread_id thin_lock_id。 我们在12.2.1节中介绍过它。该id并不是代表操作系统里线程的tid，而是由虚拟机自己维护的用 于线程同步的id。*/ const uint32_t thread_id = GetThreadId(); //tlsPtr_opeer指向一个Java层Thread对象，它是一个mirror Thread对象在Java层  //的对应物。这类根对象的类型为kRootThreadObject  visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.opeer, RootInfo(kRootThreadObject, thread_id)); /*tlsPtr_ exception指向一个Java异常对象。注意，GetDeoptimizationException返 回的值非常特殊（为-1）。所以，它并不是一个真正的Java异常对象，只是用-1来表示和 HDeoptimize有关的处理（详情可参考10.4节的内容） */ if (tlsPtr_.exception != nullptr \u0026amp;\u0026amp; tlsPtr_.exception != GetDeoptimizationException()) { //使用kRootNativeStack作为tlsPtr_ exception的root类型  visitor-\u0026gt;VisitRoot(reinterpret_cast\u0026lt;mirror::Object**\u0026gt;( \u0026amp;tlsPtr_.exception), RootInfo(kRootNativeStack, thread_id)); } //tlsPtr_ monitor_enter_object指向用于monitor-enter的那个Java对象。详情可参考  //12.3.2.1.1节的内容  visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.monitor_enter_object,RootInfo(kRootNativeStack, thread_id)); /*tlsPtr_ jni_env locals的类型为IndirectReferenceTable（简写为IRTable）， 而tlsPtr_ jni_env monitors与synchronized修饰的java native函数的调用有关， 用于同步native函数的调用。本书关于JNI的部分中并未对synchronized修饰的native 函数做过讲解，读者可结合第11章的内容自行研究它。*/ tlsPtr_.jni_env-\u0026gt;locals.VisitRoots(visitor, RootInfo(kRootJNILocal,thread_id)); tlsPtr_.jni_env-\u0026gt;monitors.VisitRoots(visitor, RootInfo(kRootJNIMonitor, thread_id)); /*HandleScopeVisitRoots也和JNI有关，读者可回顾9.5.3节的内容。调用jni函数时，引用型参 数会借助一个HandleScope保存在栈上。而HandleScopeVisitRoots函数将遍历tlsPtr_top_ handle_scope链表，然后访问其中的引用型对象。简单点说，下面这个函数将找到那些传递 给了native函数的引用型对象。 */ HandleScopeVisitRoots(visitor, thread_id); .....//其他一些情况下root Object的遍历。与之相关的内容建议读者在本书基础上自行研究  /*下面来看最关键的一个知识。我们先举个例子，假设有这样一段代码，funcA函数中创建一个 Object对象obj，然后用它作为参数调用funcB： void funcA(){ Object obj= new Object();//创建一个对象 funcB(obj);//如果屏蔽这行代码，那么obj就是垃圾对象 } 在上述代码中，如果没有funcB调用的那行代码，obj就是一个没有人用的垃圾对象，否则，我们就需 要特殊考虑。因为对funcB调用而言，obj被用到了。但这种被用的方式显然和对象的某个引用型成员 变量的引用方式不同，它是通过作为函数调用的引用型参数来引用的。从某种意义上说，它和JNI HandleScope 里的引用型参数一样。对于这种和函数调用有关的对象，就需要遍历线程的调用栈帧，找到其中所有引 用型的参数，把它们视为根对象。下面几行代码就是干这个工作的，我们重点介绍它们。 */ Context* context = GetLongJumpContext(); RootCallbackVisitor visitor_to_callback(visitor, thread_id); ReferenceMapVisitor\u0026lt;RootCallbackVisitor\u0026gt; mapper(this, context,visitor_to_callback); //ReferenceMapVisitor派生自StackVisitor类。10.2.4节曾详细介绍过StackVisitor。  mapper.WalkStack(); ReleaseLongJumpContext(context); ...... } Runtime::VisitNonThreadRoots void Runtime::VisitNonThreadRoots(RootVisitor* visitor) { //java_vm_类型为JavaVmExt，2：调用它的VisitRoots函数  java_vm_-\u0026gt;VisitRoots(visitor); /*3: sentinel_是Runtime的成员变量，类型为GcRoot\u0026lt;Object\u0026gt;，它对应一个Java层的java.lang. Object对象。其作用我们后续碰到时再介绍。 */ sentinel_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); /*:3: preallocated_OutOfMemoryError_以及pre_allocated_NoClassDefFoundError_是Runtime 的成员变量，类型为GcRoot\u0026lt;Throwable\u0026gt;。它们属于由虚拟机直接创建的JavaObject对象。创建 它们的代码可参考7.2.2节所示Runtime Init函数的最后几行。 */ pre_allocated_OutOfMemoryError_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); pre_allocated_NoClassDefFoundError_.VisitRootIfNonNull(visitor,RootInfo(kRootVMInternal)); //4: 调用RegTypeCache的VisitStaticRoots函数  verifier::MethodVerifier::VisitStaticRoots(visitor); //下面这个函数的内容和dex2oat的编译流程有关，我们不拟介绍它  VisitTransactionRoots(visitor); } Runtime::VisitConcurrentRoots void Runtime::VisitConcurrentRoots(RootVisitor* visitor, VisitRootFlags flags) { //5: intern_table_的类型为InternTable，和Intern String有关  intern_table_-\u0026gt;VisitRoots(visitor, flags); //6: 调用ClassLinker的VisitRoots函数  class_linker_-\u0026gt;VisitRoots(visitor, flags); .... if ((flags \u0026amp; kVisitRootFlagNewRoots) == 0) { VisitConstantRoots(visitor);//7  } Dbg::VisitRoots(visitor);//和调试有关，本书不拟介绍它 } heap.cc\nHeap初始化时对Collector的设置 Heap::Heap(... CollectorType foreground_collector_type, CollectorType background_collector_type, ...) : ... foreground_collector_type_(foreground_collector_type), background_collector_type_(background_collector_type), desired_collector_type_(foreground_collector_type_), ...{ //设置回收器类型和回收策略，详情见下文代码分析  ChangeCollector(desired_collector_type_); //创建Space对象等工作，比较复杂，这也是Heap难度较大的原因之一。Android后续版本  //对此处的代码逻辑做了一些优化和调整  ...... /*创建回收器。garbage_collectors_是一个数组，元素类型为GarbageCollector*。 下面的MayUseCollector函数将检查前台回收器类型（foreground_collector_type_）或后台 回收器类型（background_collector_type_）是否为输入的回收器类型，只要有一个回收器类型 满足条件，则MayUseCollector返回true。如果回收器类型为CMS或MS，下面这段for循环代码中 的if代码块只会执行一次，不论哪一次执行都会创建三个垃圾回收器对象，它们分别是MarkSweep、 PartialMarkSweep和StickyMarkSweep。CMS和MS区别之处在于这三个回收器对象是否用 concurrent gc功能。*/ for (size_t i = 0; i \u0026lt; 2; ++i) { const bool concurrent = i != 0; if ((MayUseCollector(kCollectorTypeCMS) \u0026amp;\u0026amp; concurrent) || (MayUseCollector(kCollectorTypeMS) \u0026amp;\u0026amp; !concurrent)) { garbage_collectors_.push_back(new collector::MarkSweep(this, concurrent)); garbage_collectors_.push_back(new collector::PartialMarkSweep(this, concurrent)); garbage_collectors_.push_back(new collector::StickyMarkSweep(this, concurrent)); } } if (kMovingCollector) {//kMovingCollector默认为true  if (MayUseCollector(kCollectorTypeSS) || MayUseCollector(kCollectorTypeGSS) || MayUseCollector(kCollectorTypeHomogeneousSpaceCompact) || use_homogeneous_space_compaction_for_oom_) { //前台回收器类型为GSS时，generational才为true  const bool generational = foreground_collector_type_ == kCollectorTypeGSS; //如果使用SS、GSSS或HSC，则再创建一个SemiSpace collector对象  semi_space_collector_ = new collector::SemiSpace(this, generational, generational ? \u0026#34;generational\u0026#34; : \u0026#34;\u0026#34;); garbage_collectors_.push_back(semi_space_collector_); } ......//其他回收器类型的处理，读者可自行阅读  } ...... } void Heap::ChangeCollector(CollectorType collector_type) { if (collector_type != collector_type_) { ...... //collector_tyoe_和gc_plan_均为Heap成员变量  collector_type_ = collector_type;//设置回收器类型  gc_plan_.clear(); switch (collector_type_) { ...... case kCollectorTypeMC: // Fall-through.  case kCollectorTypeSS: // Fall-through.  case kCollectorTypeGSS: { //gc_plan_为数组，保存了回收策略。ART在GC时将用到它  gc_plan_.push_back(collector::kGcTypeFull); ......//设置内存分配器的类型为kAllocatorTypeBumpPointer  break; } ...... case kCollectorTypeCMS: { gc_plan_.push_back(collector::kGcTypeSticky); gc_plan_.push_back(collector::kGcTypePartial); gc_plan_.push_back(collector::kGcTypeFull); .....//设置内存分配器的类型为kAllocatorTypeRosAlloc  break; } ...... } // IsGcConcurrent判断collector_type_是否为CMS或CC（kCollectorTypeCC，意为Concurrent Copying）  if (IsGcConcurrent()) { //concurrent_start_bytes_和concurrent gc有关。其用途我们后续代码分析时候  //将看到。kMinConcurrentRemainingBytes取值为128KB  concurrent_start_bytes_ = std::max(max_allowed_footprint_, kMinConcurrentRemainingBytes) – kMinConcurrentRemainingBytes; } else { concurrent_start_bytes_ = std::numeric_limits\u0026lt;size_t\u0026gt;::max(); } } } garbage_collector.cc\nGarbageCollector::Run void GarbageCollector::Run(GcCause gc_cause, bool clear_soft_references) { //GcCause为枚举变量，表示触发本次gc的原因。后文介绍相关代码时将了解到不同的Gc原因  ..... Thread* self = Thread::Current(); uint64_t start_time = NanoTime();//本次GC的GC开始时间  /*GetCurrentIteration返回Heap current_gc_iteration_成员变量。由上文所述可知， 它用于统计GC的执行效果。Iteration Reset将重新设置相关的统计参数。*/ Iteration* current_iteration = GetCurrentIteration(); current_iteration-\u0026gt;Reset(gc_cause, clear_soft_references); RunPhases(); // RunPhase由GarbageCollector子类实现，它将完成真正的GC工作,main  //RunPhases之后，本次GC也就算执行完了。下面的代码用于统计此次GC的执行效果  cumulative_timings_.AddLogger(*GetTimings()); /*total_freed_objects_和total_freed_bytes_GarbageCollector的成员变量，代表虚拟机 从运行开始所有GC操作释放的对象总个数以及内存大小总数。Iteration的GetFreedObjects和 GetFreedLargeObjects、GetFreedBytes和GetFreedLargeObjectBytes返回一次GC （也就是调用每次调用Run函数）所释放的对象个数以及内存大小（包括非大内存对象以及大内存对 象）。 */ total_freed_objects_ += current_iteration-\u0026gt;GetFreedObjects() + current_iteration-\u0026gt;GetFreedLargeObjects(); total_freed_bytes_ += current_iteration-\u0026gt;GetFreedBytes() + _iteration-\u0026gt;GetFreedLargeObjectBytes(); uint64_t end_time = NanoTime(); //本次GC的结束时间  //设置本次GC的耗时时间  current_iteration-\u0026gt;SetDurationNs(end_time - start_time); //更新暂停时间以及总的GC运行时间等统计信息。这里省略部分代码，建议读者学习完本章后，再  //来看它。  ..... total_time_ns_ += current_iteration-\u0026gt;GetDurationNs(); ...... } 其他: gc_root.h\nRoot enum RootType enum RootType { kRootUnknown = 0, kRootJNIGlobal,kRootJNILocal, kRootJavaFrame, kRootNativeStack, kRootStickyClass, kRootThreadBlock, kRootMonitorUsed, kRootThreadObject, kRootInternedString, //下面三种root类型和HPROF(A Heap/CPU Profiling Tool，性能调优工具)以及调试有关，  //本书不拟介绍它们  kRootFinalizing, kRootDebugger,kRootReferenceCleanup, //最后两种root的类型  kRootVMInternal, kRootJNIMonitor, }; RootInfo //RootInfo用于描述一个root的信息。具体而言，root信息包括该root的类型以及它所在的 //线程id。 class RootInfo { public: //由于不是所有root信息都和线程有关系，所有下面这个构造函数中，thread_id默认值为0  explicit RootInfo(RootType type, uint32_t thread_id = 0) : type_(type), thread_id_(thread_id) { } .... private: const RootType type_;//该root的类型  const uint32_t thread_id_;//该root所在的线程 }; GcRootSource class GcRootSource {//它仅包含两个成员变量。  ..... private: ArtField* const field_; ArtMethod* const method_; }; GcRoot template\u0026lt;class MirrorType\u0026gt; class GcRoot { //一个GcRoot实例就代表一个被认为是根的Object对象  private: /*GcRoot只有下面一个成员变量，其类型为CompressedReference。CompressedReference 中只有一个reference_（类型为uint32_t）成员。这个成员也就是某个Object对象的内存 地址。所以，简单来说，root_也就是代表某个Object对象。*/ mutable mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;root_; public: /*GcRoot提供了几个成员函数用于很方便地访问root_。如上文所述，一个GcRoot对象代表一个 被认为是根的Object对象（以后我们称之为root Object或根Object）。所以，下面的几个 root访问函数其实访问的就是root_的一个对象。*/ void VisitRoot(RootVisitor* visitor, const RootInfo\u0026amp; info) const{ mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* roots[1] = { \u0026amp;root_ }; visitor-\u0026gt;VisitRoots(roots, 1u, info); } void VisitRootIfNonNull(RootVisitor* visitor, const RootInfo\u0026amp; info) const { if (!IsNull()) {//如果root_不为空指针，则访问它  VisitRoot(visitor, info); } } bool IsNull() const { return root_.IsNull(); } ..... }; RootVisitor class RootVisitor { public: virtual ~RootVisitor() { } //下面两个VisitRoots为虚函数，由RootVisitor的子类实现。它们用于访问一组root Object对象  virtual void VisitRoots(mirror::Object*** roots, size_t count, const RootInfo\u0026amp; info) = 0; virtual void VisitRoots(mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;** roots, size_t count, const RootInfo\u0026amp; info) = 0; //下面两个函数为辅助函数，用于访问单个root Object对象  void VisitRoot(mirror::Object** root, const RootInfo\u0026amp; info) { VisitRoots(\u0026amp;root, 1, info); } void VisitRootIfNonNull(mirror::Object** root, const RootInfo\u0026amp; info) { if (*root != nullptr) { VisitRoot(root, info); } } ...... }; BufferedRootVisitor template \u0026lt;size_t kBufferSize\u0026gt; class BufferedRootVisitor { private: RootVisitor* const visitor_; //roots_数组，数组最大容量由模板参数kBufferSize决定。该数组中的root Object对应  //同一种RootType（由root_info_的type_表示）  mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* roots_[kBufferSize]; RootInfo root_info_; size_t buffer_pos_;//roots_数组中元素的个数  public: template \u0026lt;class MirrorType\u0026gt; void VisitRoot(mirror::CompressedReference\u0026lt;MirrorType\u0026gt;* root){ if (UNLIKELY(buffer_pos_ \u0026gt;= kBufferSize)) { Flush();//如果roots_数组已满，则调用Flush  } //如果roots_数组还没有填满，则仅仅是把root存到roots_数组中  roots_[buffer_pos_++] = root; } void Flush() { //一次性访问roots_数组中的root Object内容  visitor_-\u0026gt;VisitRoots(roots_, buffer_pos_, root_info_); buffer_pos_ = 0; } //其他访问函数  template \u0026lt;class MirrorType\u0026gt; void VisitRootIfNonNull(GcRoot\u0026lt;MirrorType\u0026gt;\u0026amp; root) { if (!root.IsNull()) { VisitRoot(root); } } template \u0026lt;class MirrorType\u0026gt; void VisitRootIfNonNull(mirror::CompressedReference\u0026lt;MirrorType\u0026gt;* root) { if (!root-\u0026gt;IsNull()) { VisitRoot(root); } } .... }; collector_type.h\nenum CollectorType enum CollectorType { kCollectorTypeNone, //下面两个枚举值和MarkSweep类有关。详情见本章对应小节的分析  kCollectorTypeMS,kCollectorTypeCMS, //下面两个枚举值和SemiSpace类有关  kCollectorTypeSS,kCollectorTypeGSS, //和MarkCompact类有关  kCollectorTypeMC, //和GarbageCollector类家族无关，其作用见后续代码分析  kCollectorTypeHeapTrim, //和ConcurrentCopying类有关  kCollectorTypeCC, kCollectorTypeInstrumentation, //和GarbageCollector类家族无关，其作用见后续代码分析  kCollectorTypeAddRemoveAppImageSpace, //和CMS有关。详情见后续代码分析  kCollectorTypeHomogeneousSpaceCompact, //和GarbageCollector类家族无关，其作用见后续代码分析  kCollectorTypeClassLinker, }; gc_type.h\nenum GcType //从某种意义上来说，GcType反应的是回收工作的力度。枚举值越大，力度越高，工作也越“辛苦” enum GcType { kGcTypeNone, //表示仅扫描和回收上次GC到本次GC这个时间段内所创建的对象  kGcTypeSticky, /*仅扫描和回收应用进程自己的堆，不处理zygote的堆。这种方式和Android中Java应用程序的创建 方式有关。在Android中，应用进程是zygote进程fork出来的。*/ kGcTypePartial, //力度最大的一种回收策略，扫描APP自己以及它从父进程zygote继承得到的堆  kGcTypeFull, kGcTypeMax, }; Mutator the program that modifies the objects in heap (simply, the user program)\nmutator和collector：我们在第13章中曾提到过它们。这两个词是由已故世界级计算机科学先驱Edsger W.Dijkstra于1976年左右提出的。简单来说，collector表示内存回收相关的功能模块。而mutator和collector相对，一般情况下代表应用程序中除collector之外的其他部分。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/gc1_ms_cms/",
	"title": "GC1_MS_CMS",
	"tags": [],
	"description": "",
	"content": "MarkSweep类家族 表14-1　MarkSweep类家族GetGcType取值情况\n集合Live和集合Mark构成 CMS时Heap space相关成员变量取值情况 CMS时Heap位图相关成员变量取值情况 图14-7　CMS时Heap位图相关成员变量取值情况\n一个HeapBitmap对象可以管理多个ContinuousSpace的某一种位图对象\nCMS时Heap mark_stack_等成员变量的情况 MarkSweep::MarkSweep MarkSweep::MarkSweep(Heap* heap, bool is_concurrent, const std::string\u0026amp; name_prefix) : GarbageCollector(heap, name_prefix + (is_concurrent ? \u0026#34;concurrent mark sweep\u0026#34;: \u0026#34;mark sweep\u0026#34;)), current_space_bitmap_(nullptr), mark_bitmap_(nullptr), mark_stack_(nullptr), ..... is_concurrent_(is_concurrent),...... { /*MarkSweep构造函数并不复杂，此处先介绍下它的几个成员变量（其作用留待后续代码分析时时再详细讲解）： current_space_bitmap_：类型为ContinuousSpaceBitmap*。 mark_bitmap_：类型为HeapBitmap*。 mark_stack_：类型为ObjectStack*。 */ ..... /*下面的代码行将创建一个内存映射对象。ART内部大量使用内存映射对象。下面的 sweep_array_free_buffer_mem_map_的用法需要到介绍StickyMarkSweep时才能见到。总之，读者将它看作一块内存即可。*/ MemMap* mem_map = MemMap::MapAnonymous(......); sweep_array_free_buffer_mem_map_.reset(mem_map); ..... } MarkSweep::RunPhases 图解 graph TB IsConcurrent{IsConcurrent}--\u0026gt;|yes|MarkingPhaseC(MarkingPhase) MarkingPhaseC--\u0026gt;pauseC(pause) pauseC--\u0026gt;PausePhaseC(\u0026quot;PausePhase_reMark\u0026quot;) PausePhaseC--\u0026gt;RevokeAllThreadLocalBuffers RevokeAllThreadLocalBuffers--\u0026gt;ReclaimPhase ReclaimPhase--\u0026gt;FinishPhase IsConcurrent--\u0026gt;|no|pause pause--\u0026gt;MarkingPhase MarkingPhase--\u0026gt;PausePhase PausePhase--\u0026gt;RevokeAllThreadLocalBuffers void MarkSweep::RunPhases() { Thread* self = Thread::Current(); //初始化MarkSweep类的几个成员变量。其中，MarkSweep的mark_bitmap_将设置为Heap的成员变量mark_bitmap_（读者可回顾图14-7）  InitializePhase(); if (IsConcurrent()) {//if条件为true，则是CMS的行为  ...... { /*CMS和MS的区别：下面代码中ReaderMutexLock为辅助类，真正用于同步的关键对象为 mutator_lock_。它是一个全局定义的读写互斥锁。即支持多个线程同时进行读操作。但如果 某个线程要执行写操作的话，必须等待所有执行读操作的线程释放这个锁。同理，执行写操作的 线程如果先抢到这个锁的话，其他想做读操作或写操作的线程都必须要等待当前拥有这个锁的写 线程释放该锁。ReaderMutextLock在构造函数中将针对mutator_lock_申请一个读锁，而在析构函数中释放读锁。*/ ReaderMutexLock mu(self, *Locks::mutator_lock_); MarkingPhase();//①标记工作，详情见下文代码分析,main  } /*ScopedPause也是一个辅助类，其构造函数中会暂停除调用线程外其他所有Java线程的运行，其内部 调用ThreadList的SuspendAll，详情可参考12.2.3节的内容。ScopedPause的析构函数中会恢复这些线程的运行。 简单来说，下面的这段代码运行时，其他Java线程将停止运行。 */ ScopedPause pause(this); .... PausePhase();//②PausePhase的详情见下文代码分析,main  /*撤销线程对象的TLAB空间。此后Thread TLAB空间为0，TLAB的作用在于加速内存分配的速度。 TLAB所需的内存资源来自对应的空间对象，例如BumpPointerSpace、RegionSpace等。请读者 注意，Revoke是撤销的意思，不是Free（释放）。撤销TLAB之后那些创建在TLAB上的对象依然存在。 这些对象中的垃圾对象将在后续清除阶段回收。*/ RevokeAllThreadLocalBuffers(); } else { //如果回收器类型为MS，则先暂停其他Java线程的运行，  ScopedPause pause(this); ..... MarkingPhase(); ...... PausePhase(); RevokeAllThreadLocalBuffers(); } //标记相关的工作结束，开始准备清除工作  { //注意，mutator_lock_被用作读锁。这和上面CMS逻辑中调用MarkingPhase函数的处理  //一样。这说明无论CMS还是MS，清除任务（Reclaim Phase）可以和mutator同时执行  ReaderMutexLock mu(self, *Locks::mutator_lock_); ReclaimPhase();//③回收工作，详情见下文代码分析,main  } ..... FinishPhase();//④GC的收尾，详情见下文代码分析,main } InitializePhase \u0026hellip;\u0026hellip;\nMarkingPhase 图解 graph LR MarkingPhase--\u0026gt;|标记根对象|MarkRoots--\u0026gt;VisitRoots(\u0026quot;Runtime::Current()-\u0026gt;VisitRoots(this)\u0026quot;) MarkRoots--\u0026gt;PushOnMarkStack MarkingPhase--\u0026gt;|从根对象触发编辑所有能追踪到的对象|MarkReachableObjects--\u0026gt;Object.VisitReferences void MarkSweep::MarkingPhase() { TimingLogger::ScopedTiming t(__FUNCTION__, GetTimings()); Thread* self = Thread::Current(); //①我们单独介绍下面三个函数调用，笔者将它们归为标记前的准备工作  BindBitmaps(); FindDefaultSpaceBitmap(); /*调用Heap ProcessCards函数，该函数的作用见下文解释。此处请注意最后一个参数的取值： (1) MarkSweep GetGcType返回kGcTypeFull，所以最后一个参数取值为false。 (2) PartialMarkSweep GetGcType返回kGcTypePartial，所以最后一个参数取值为false。 (3) StickyMarkSweep GetGcType返回值为kGcTypeSticky，所以最后一个参数取值为 true。 */ heap_-\u0026gt;ProcessCards(GetTimings(), false, true, GetGcType() != kGcTypeSticky); WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); //②标记相关函数，，标记的信息保存在各个空间的mark_bitmap_中  MarkRoots(self);//MarkRoots用于标记根对象  MarkReachableObjects();//从根对象出发以标记所有能追踪到的对象  //③下面这个函数和CMS有关，我们后续统一介绍它  PreCleanCards(); } BeforeMark BindBitmaps void MarkSweep::BindBitmaps() { ...... WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); /*搜索Heap continuous_spaces_数组中的空间对象，如果某个空间对象的gc_retention_policy_ 成员变量取值为kGcRetentionPolicyNeverCollect，则将它加入MarkSweep immune_spaces_ （类型为ImmuneSpace，其内部有一个std set容器）中。回顾13.7.1节的内容可知，只有ImageSpace （结合14.3.3节的图14-6可知，它就是boot.art文件映射到内存后得到的空间对象）满足这个条 件。再次请读者注意，kGcRetentionPolicyNeverCollect表示不用对该空间的对象进行垃圾回收。*/ for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyNeverCollect) { immune_spaces_.AddSpace(space);//AddSpace的代码见下文介绍  } } } immune_spaces.cc\nImmuneSpaces::AddSpace void ImmuneSpaces::AddSpace(space::ContinuousSpace* space) { //ImageSpace重载了GetLiveBitmap和GetMarkBitmap函数，返回的都是  //ImageSpace的live_bitmap_成员。所以，下面的if条件对ImageSpace而言并不满足  if (space-\u0026gt;GetLiveBitmap() != space-\u0026gt;GetMarkBitmap()) { //调用ContinuousMemMapAllocSpace BindLiveToMarkBitmap函数。它的作用我们  //在StickyMarkSweep类中再来介绍。MarkSweep还用不到它  space-\u0026gt;AsContinuousMemMapAllocSpace()-\u0026gt;BindLiveToMarkBitmap(); } //spaces_是ImmuneSpace的成员，为一个std set集合  spaces_.insert(space); //ImmuneSpaces是一个辅助类的数据结构  CreateLargestImmuneRegion(); } FindDefaultSpaceBitmap void MarkSweep::FindDefaultSpaceBitmap() { ...... //遍历Heap continuous_space_数组，读者可回顾图14-6了解CMS情况下Heap continuous_space_数组的取值情况  for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { accounting::ContinuousSpaceBitmap* bitmap = space-\u0026gt;GetMarkBitmap(); /*参考13.7.1节的内容可知，DlMallocSpace和RosAllocSpace 都满足下面的if条件（它们的回收策略为kGcRetentionPolicyAlwaysCollect）。 if条件满足后，将把空间对象中的mark_bitmap_赋值给MarkSweep的成员变量 current_space_bitmap_。*/ if (bitmap != nullptr \u0026amp;\u0026amp; space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyAlwaysCollect) { //current_space_bitmap_为MarkSweep的成员变量，指向一个ContinuousSpaceBitmap对象  current_space_bitmap_ = bitmap; //从下面这个if条件来看，current_space_bitmap_取值来自Heap main_space_的  //mark_bitmap_。读者可回顾14.3.3节中的图14-6  if (space != heap_-\u0026gt;GetNonMovingSpace()) { break; } } } } Heap::ProcessCards void Heap::ProcessCards(..., bool use_rem_sets, bool process_alloc_space_cards, bool clear_alloc_space_cards) { /*注意参数，MarkSweep 调用它时，所传入的参数值为： use_rem_sets为false。 process_alloc_space_cards为true。clear_alloc_space_cards为true。 */ //遍历continuous_spaces_数组  for (const auto\u0026amp; space : continuous_spaces_) { //找到和这个space关联的ModUnionTable或者RememberedSet对象  //无论使用ModUnionTable还是RememberedSet，最终操作的都是Heap card_table_  accounting::ModUnionTable* table = FindModUnionTableFromSpace(space); accounting::RememberedSet* rem_set = FindRememberedSetFromSpace(space); /*在Heap PreZygoteFork被调用前，Heap中space对象的情况见图14-6。在那里， ImageSpace对象关联了一个ModUnionTable对象，其余两个空间对象各关联了 一个RememberedSet对象。 */ if (table != nullptr) { /*调用ModUnionTable的ClearCards函数，其作用我们在13.8.2.4节中曾介绍过。 该函数调用的结果是： 这个ModUnionTable管理的空间对象在Heap CardTable中对应card的值将发生如下变化： (1) 如果card旧值为kCardDirty，则设置其新值为kCardDirty - 1， (2) 否则设置其新值为0。*/ table-\u0026gt;ClearCards(); } else if (use_rem_sets\u0026amp;\u0026amp; rem_set != nullptr) { /*在本例中，use_rem_sets取值为false，if条件不满足。RememberedSet ClearCards 函数的代码见13.8.2.3.1节。其效果和上面ModUnionTableClearCards一样。 */ rem_set-\u0026gt;ClearCards(); } else if (process_alloc_space_cards) {//对本例而言，该参数为true  if (clear_alloc_space_cards) {//满足条件  /*下面将处理card_table_中覆盖space对象的card信息。ClearCardRange函数 将设置对应card的值为0。*/ uint8_t* end = space-\u0026gt;End(); ...... card_table_-\u0026gt;ClearCardRange(space-\u0026gt;Begin(), end); } else { /*如果clear_alloc_space_cards为false，则调用CardTable的 ModifyCardsAtomic函数修改对应内存范围的card的值。其中： (1) 如果card的旧值为kCardDirty，则新值为kCardDirty-1 (2) card的旧值为非kCardDirty时，新值为0。*/ card_table_-\u0026gt;ModifyCardsAtomic(space-\u0026gt;Begin(), space-\u0026gt;End(), AgeCardVisitor(),VoidFunctor()); } } } } Mark MarkRoots void MarkSweep::MarkRoots(Thread* self) { ...... if (Locks::mutator_lock_-\u0026gt;IsExclusiveHeld(self)) { /*如果if条件为true，说明其他Java线程已暂停运行。14.2节中我们已经介绍过Runtime VisitRoots函数了。此处，MarkSweep实现了RootVisitor接口。下面将直接介绍MarkSweep 所实现的RootVisitor VisitRoots接口函数。*/ Runtime::Current()-\u0026gt;VisitRoots(this); /*下面这个函数将遍历所有Thread对象，设置它们的tlsPtr_thread_local_alloc_stack_ end和thread_local_alloc_stack_top为空，即收回线程的Allocation Stack空间。 注意，结合图14-8的内容和13.6.4.3节的相关知识可知，此处只是将线程的Allocation Stack 空间大小设置为0，而存储在Allocation Stack中的信息依然存在（因为Heap allocation_ stack_没有被修改）。*/ RevokeAllThreadLocalAllocationStacks(self); } else { ......//和CMS有关，详见14.4.9节  } } VisitRoots void MarkSweep::VisitRoots(mirror::Object*** roots, size_t count,const RootInfo\u0026amp; info) { for (size_t i = 0; i \u0026lt; count; ++i) { MarkObjectNonNull(*roots[i]); } } void MarkSweep::VisitRoots(CompressedReference\u0026lt;Object\u0026gt;** roots, size_t count,const RootInfo\u0026amp; info) { for (size_t i = 0; i \u0026lt; count; ++i) { MarkObjectNonNull(roots[i]-\u0026gt;AsMirrorPtr()); } } MarkObjectNonNull //对Obj进行标记。标记就是设置该Obj所在空间对象的mark_bimap_位图对应位的值为1。 //这个新被标记的Obj保存到MarkSweep mark_sweep_容器中。 inline void MarkSweep::MarkObjectNonNull(mirror::Object* obj, mirror::Object* holder, MemberOffset offset) { //MarkObjectNonNull最后两个参数有默认值，分别为nullptr和MemberOffset(0)  ...... //如果obj位于immune_spaces_所包含的空间对象中，则无须标记，详情见if中的解释  if (immune_spaces_.IsInImmuneRegion(obj)) { ...... /*注意下面这句调试时才会执行的代码。MarkSweep成员变量mark_bitmap_类型为HeapBitmap， 它其实就是Heap的mark_bitmap_成员。回顾本章的图14-6可知，HeapBitmap包含了所有 连续空间对象的mark_bitmap_成员。不过，对ImageSpace来说，它的live_bitmap_也被 包含在Heap mark_bitmap_中了。 在下面这行代码中，Test函数将测试obj在位图中对应的位是否为1。如果Test返回值为0， DCHECK会打印一条错误信息（如果打开调试的话）。这说明一个Obj如果位于ImageSpace空 间的话，它一定是存活的（同时也是早就被标记了的。因为ImageSpaceGetMarkBitmap返回 的也是live_bitmap_）。但是，请读者注意，尽管位于ImageSpace空间中的对象是长久存 活的，但是这些对象的引用型成员变量所指向的对象却可能位于其他空间，而这些对象就可能 是垃圾。*/ DCHECK(mark_bitmap_-\u0026gt;Test(obj)); } else if (LIKELY(current_space_bitmap_-\u0026gt;HasAddress(obj))) { /*根据“准备工作”一节FindDefaultSpaceBitmap函数可知，current_space_bitmap_ 为某个空间对象的mark_bitmap_。判断一个Obj是否被标记的标准就是该Obj 在mark_bitmap_中对应位的值是否为1。所以，本段代码的主要工作可总结为： (1) HasAddress检查current_space_bitmap_对应的内存空间是否包含了obj对象 (2) 如果满足条件，则调用Set函数设置obj对应位的值为1。于是，这个Obj就算被标记了。 (3) Set函数返回该位的旧值。如果旧值为0，说明这个obj之前没有被标记。调用 PushOnMarkStack将obj加入到MarkSweep mark_stack_容器中。mark_stack_为 一个ObjectStack对象。 */ if (UNLIKELY(!current_space_bitmap_-\u0026gt;Set(obj))) { PushOnMarkStack(obj); } } else { /*说明obj不在current_space_bitmap_所关联的那个空间对象中，此时就需要搜索Heap 所有的空间对象，显然这比直接操作current_space_bitmap_要耗时。从这里可以看出， 使用current_space_bitmap_是一种优化处理。后面我们还会看到类似的这种优化处理。*/ ...... /*mark_bitmap_指向一个HeapBitmap对象，它就是Heap中的mark_bitmap_。根据图 14-8的介绍，HeapBitmap管理了所有空间对象的SpaceBitmap。下面的Set函数将搜索 所有空间对象，找到包含这个Obj的Space对象，然后设置对应位的值。 */ if (!mark_bitmap_-\u0026gt;Set(obj,...)) { PushOnMarkStack(obj); } } } MarkReachableObjects void MarkSweep::MarkReachableObjects() { //处理immune_spaces_空间中的对象，对理解card table的作用非常关键，请读者注意  UpdateAndMarkModUnion(); RecursiveMark();//我们重点介绍这个函数 } UpdateAndMarkModUnion void MarkSweep::UpdateAndMarkModUnion() { for (const auto\u0026amp;space : immune_spaces_.GetSpaces()) { ....... /*space要么是ImageSpace，要么是ZygoteSpace。如果它们关联了一个ModUnionTable 对象，则通过ModUnionTable的UpdateAndMarkReference函数来处理。否则通过它们的 live_bitmap_来处理。其中： UpdateAndMarkReference的参数是一个MarkObjectVisitor类型的函数调用对象，MarkSweep 类实现了它的MarkObject和MarkHeapReference接口函数。 而live_bimap_ VisitMarkedRange函数最后一个参数为函数调用对象。最终，不管下面 代码中的if和else哪个条件满足，MarkSweep的MarkObjectNonNull都将被调用。 */ accounting::ModUnionTable* mod_union_table = heap_-\u0026gt;FindModUnionTableFromSpace(space); if (mod_union_table != nullptr) { mod_union_table-\u0026gt;UpdateAndMarkReferences(this); } else { //如果该空间没有关联ModUnionTable，则只能遍历该空间的所有存活对象了  space-\u0026gt;GetLiveBitmap()-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;End()), ScanObjectVisitor(this)); } } } RecursiveMark void MarkSweep::RecursiveMark() { ...... if (kUseRecursiveMark) {//kUseRecursiveMark为编译常量，默认值为false  ....//这部分代码中有和parallel处理有关的内容，感兴趣的读者可自行阅读  } ProcessMarkStack(false);//此处传递的参数为false } ProcessMarkStack void MarkSweep::ProcessMarkStack(bool paused) { /*ProcessMarkStack就是遍历mark_stack_中的obj对象，追踪它们的引用型参数。 注意，追踪根对象的引用型成员变量是一个非常耗时的工作，所以可以利用多线程来处理，这就是 parallel collection的一个体现。根据下面的if条件判断，是否使用parallel gc需要 满足一定条件，即： (1) kParallelProcessMarkStack：编译常量，默认取值为true. (2) GetThreadCount返回值大于1。 (3) mark_stack_所保存的Obj对象个数大于128（kMinimumParallelMarkStackSize的值） GetThreadCount的代码请读者自行阅读。其中会涉及kProcessStateJankPerceptible枚举 变量。我们在10.3.2.2节中曾介绍过它。当应用处于前台时，它的进程状态会被设置为这个值，表 示如果应用发生卡顿，用户是能感受到的。*/ size_t thread_count = GetThreadCount(paused);//  if (kParallelProcessMarkStack \u0026amp;\u0026amp; thread_count \u0026gt; 1 \u0026amp;\u0026amp; mark_stack_-\u0026gt;Size() \u0026gt;= kMinimumParallelMarkStackSize) { ProcessMarkStackParallel(thread_count);//后文再详细介绍这个函数  } else { /*else代码块为不使用parallel collection的处理。处理方式很简单，就是遍历 mark_stack_中的元素，调用它们的VisitReference函数。每找到一个引用型参数就调用 MarkSweep MarkObject函数进行标记。如果是新标记的对象，就将其加入mark_stack_ 容器中。如此往复直到mark_stack_中的元素都处理完为止。 */ static const size_t kFifoSize = 4; BoundedFifoPowerOfTwo\u0026lt;mirror::Object*, kFifoSize\u0026gt; prefetch_fifo; for (;;) { mirror::Object* obj = nullptr; if (kUseMarkStackPrefetch) {//kUseMarkStackPrefetch默认为true  /*这段代码为一种优化实现，利用了GCC的__builtin_prefetch功能加速获取 mark_stack_中的元素。感兴趣的读者可以自行研究它。*/ ..... } else { //如果不使用优化实现的话，遍历mark_stack_的代码逻辑就非常简单了  if (mark_stack_-\u0026gt;IsEmpty()) { break; } obj = mark_stack_-\u0026gt;PopBack(); } /*ScanObject将调用Object VisitReferences，所设置的函数调用对象最终会通过MarkSweep MarkObject函数来标记所找到的引用型成员变量。我们在13.8.3节中曾介绍过VisitReferences 函数。注意，对Reference类型的对象有一些特殊处理。我们后文将介绍这部分内容。 */ ScanObject(obj); } } } PausePhase void MarkSweep::PausePhase() { Thread* self = Thread::Current(); if (IsConcurrent()) {//①如果是CMS，则需要调用下面两个函数  WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); /*回顾MarkSweep RunPhases可知，在CMS情况下gc线程执行MarkingPhase的时候，mutator 线程可同时运行。也就是说，对CMS而言，MarkingPhase标记的对象可能还不全面，所以在 PausePhase的时候要重新做一次标记。当然，这次标记不会像MarkingPhase那样耗时，否则 CMS就没有什么价值了。 */ ReMarkRoots(); RecursiveMarkDirtyObjects(true, accounting::CardTable::kCardDirty); } { ...... //写锁，使用全局静态变量heap_bitmap_lock_同步对象  WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); /*②调用Heap SwapStack函数，内部将执行下面这条语句： allocation_stack_.swap(live_stack_)。它将live_stack_和allocation_stack_ 的内容进行交换。 */ heap_-\u0026gt;SwapStacks(); live_stack_freeze_size_ = heap_-\u0026gt;GetLiveStack()-\u0026gt;Size(); /*再次清空Thread的Allocation Stack空间。注意，我们在MarkRoots函数中也 调用过这个函数。两次执行它的原因是因为在MarkRoots中清空之后直到代码运行到这里时， 可能有mutator线程又重新分配和使用了Allocation Stack。*/ RevokeAllThreadLocalAllocationStacks(self); } //③下文将简单介绍Runtime DisallowNewSystemWeaks的内容  Runtime::Current()-\u0026gt;DisallowNewSystemWeaks(); //④下面这行代码和Java Reference对象的处理有关，我们后续单独介绍这部分知识  GetHeap()-\u0026gt;GetReferenceProcessor()-\u0026gt;EnableSlowPath(); } RecursiveMarkDirtyObjects void MarkSweep::RecursiveMarkDirtyObjects(bool paused, uint8_t minimum_age) { /*ScanGrayObjects是一个比较复杂的函数，但理解它并不难，笔者仅介绍其功能，感兴趣的 读者可以自行研究它的代码。 在StickyMarkSweep MarkReachableObjects中，mark_stack_被清空。这并不是说 StickyMarkSweep不需要它，而是StickyMarkSweep需要往mark_stack_填充自己的内 容（MarkRoots往mark_stack_填充的对象算MarkSweep的）—该工作由下面的 ScanGrayObjects完成。ScanGrayObjects的功能很简单： (1) 遍历Heap continuous_spaces_中的空间对象。每找到一个mark_bitmap_不为空指针 的空间对象，就转到2去执行。 (2) 调用Heap card_table_的Scan函数。找到那些card值大于或等于minimum_age的card， 然后根据这个card再到空间对象去找到对应的mirror Object对象。注意，这些对象必须 是在空间对象mark_bitmap_所标记过了的。 (3) 每找到这样的一个mirror Object对象就调用MarkSweep的ScanObject以标记它的 引用型成员变量。ScanObject内部会调用MarkSweep MarkObject进行标记处理。 现在我们以某个空间对象A为例来说明和ScanGrayObjects有关的处理逻辑： (1) BindBitmaps中，A的mark_bitmap_的内容替换成了live_bitmap_。这表示 mark_bitmap_保存了上次GC后留存的对象。 (2) A对应的card在Heap ProcessCards中被修改为kCardDirty – 1或者0。 值为kCardDirty – 1的card表示对应的对象的引用型成员变量被修改过。 (3) ScanGrayObject扫描属于A的并且值为kCardDirty -1的card。然后找到这些card 中被标记了的对象（对象是否被标记由于A的mark_bitmap_决定）。 (4) 每找到一个这样的对象就调用MarkObject对它们的引用型成员变量进行标记。 简单来说，ScanGrayObjects就是确定被标记过的对象中有哪些对象的引用型成员变量被 修改过。main*/ ScanGrayObjects(paused, minimum_age); //下面这个函数在14.4.3.2.2节中介绍过该函数  ProcessMarkStack(paused); } runtime.cc\nDisallowNewSystemWeaks void Runtime::DisallowNewSystemWeaks() { //DisallocwNewSystemWeaks涉及ART虚拟机的很多个模块，比如下面的monitor_list_、  //intern_table_、java_vm_等。出于篇幅考虑，本节仅介绍java_vm_的情况  monitor_list_-\u0026gt;DisallowNewMonitors(); intern_table_-\u0026gt;ChangeWeakRootState(gc::kWeakRootStateNoReadsOrWrites); //禁止JNI层创建新的WeakGlobal对象，或者解析一个WeakGlobal对象。我们简单介绍它对创建WeakGlobal型对象的影响  java_vm_-\u0026gt;DisallowNewWeakGlobals(); heap_-\u0026gt;DisallowNewAllocationRecords(); lambda_box_table_-\u0026gt;DisallowNewWeakBoxedLambdas(); } void JavaVMExt::DisallowNewWeakGlobals() { Thread* const self = Thread::Current(); MutexLock mu(self, weak_globals_lock_); //下面这个变量的数据类型为Atomic\u0026lt;bool\u0026gt;，设置其值为false  allow_accessing_weak_globals_.StoreSequentiallyConsistent(false); } ReclaimPhase 图解 graph LR SweepWalk--\u0026gt;|在live_bitmap中但不在mark_bitmap中,认为是垃圾对象,回调|SweepCallback--\u0026gt;从live_bitmap中清除 SweepCallback--\u0026gt;space.free释放空间 void MarkSweep::ReclaimPhase() { Thread* const self = Thread::Current(); ProcessReferences(self);//①对Java Reference对象的处理，我们后续统一介绍  //②清除系统中\u0026#34;Weak\u0026#34;型的垃圾对象。我们将介绍JNI WeakGlobal型对象的清除  SweepSystemWeaks(self); Runtime* const runtime = Runtime::Current(); runtime-\u0026gt;AllowNewSystemWeaks();//重新允许\u0026#34;Weak\u0026#34;对象的创建和解析  //清除不再需要的ClassLoader对象。请感兴趣的读者自行研究  runtime-\u0026gt;GetClassLinker()-\u0026gt;CleanupClassLoaders(); { WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); GetHeap()-\u0026gt;RecordFreeRevoke(); //③下面的Sweep函数是关键，用于清理之前未被标记的对象  Sweep(false);//注意，此处调用Sweep的参数为false  //下面这两个函数用于处理空间对象中的位图  SwapBitmaps(); //UnBindBitmaps的处理需结合StickyMarkSweep来介绍  GetHeap()-\u0026gt;UnBindBitmaps(); } } SweepSystemWeaks void MarkSweep::SweepSystemWeaks(Thread* self) { ReaderMutexLock mu(self, *Locks::heap_bitmap_lock_); /*调用Runtime SweepSystemWeaks函数，参数为一个IsMarkedVisitor类型的对象。 根据14.3.1节的介绍可知，IsMarkedVisitor是一个虚基类，仅定义 了一个IsMarked虚函数。GarbageCollector类继承了IsMarkedVistior类。而 IsMarked由GarbageCollector的具体子类来实现。*/ Runtime::Current()-\u0026gt;SweepSystemWeaks(this); } inline mirror::Object* MarkSweep::IsMarked(mirror::Object* object) { //先看看这个object是否属于immue_spaces_空间中的对象  if (immune_spaces_.IsInImmuneRegion(object)) { return object; } //current_space_bitmap_来自某个Space对象的mark_bitmap_，先检查这个object是否  //属于该空间，然后判断它是否被标记  if (current_space_bitmap_-\u0026gt;HasAddress(object)) { return current_space_bitmap_-\u0026gt;Test(object) ? object : nullptr; } //mark_bitmap_就是Heap mark_bitmap_的成员，它将遍历Heap的所有space对象，  //先判断object属于哪个空间，然后检查是否被标记。  return mark_bitmap_-\u0026gt;Test(object) ? object : nullptr; } void Runtime::SweepSystemWeaks(IsMarkedVisitor* visitor) { GetInternTable()-\u0026gt;SweepInternTableWeaks(visitor); GetMonitorList()-\u0026gt;SweepMonitorList(visitor); //笔者仅介绍JNI层对WeakGlobal型对象的清除过程  GetJavaVM()-\u0026gt;SweepJniWeakGlobals(visitor); GetHeap()-\u0026gt;SweepAllocationRecords(visitor); GetLambdaBoxTable()-\u0026gt;SweepWeakBoxedLambdas(visitor); } java_vm_ext.cc\nvoid JavaVMExt::SweepJniWeakGlobals(IsMarkedVisitor* visitor) { MutexLock mu(Thread::Current(), weak_globals_lock_); Runtime* const runtime = Runtime::Current(); /*weak_globals_的类型为IndirectReferenceTable（笔者简写其为IRTable）， 在下面这段C++11的for each循环中，entry的类型为GcRoot\u0026lt;mirror::Object\u0026gt;*。 它直接来自IRTable的成员变量table_。如果修改了entry的值，也就是修改了 weak_globals_的内容。*/ for (auto* entry : weak_globals_) { //遍历weak_globals_中的元素，元素是一个WeakGlobal型的对象  if (!entry-\u0026gt;IsNull()) { //调用GcRoot的Read函数，不使用ReadBarrier。GcRoot的Read函数其实很有讲究，  //主要和Read Barrier的处理有关。本书所使用的例子均不使用Read barrier  mirror::Object* obj = entry-\u0026gt;Read\u0026lt;kWithoutReadBarrier\u0026gt;(); /*调用IsMarkedVisitor的IsMarked函数。对MS而言，此处调用的是MarkSweep类 的IsMarked函数，下文将看到它的代码。IsMarked返回值为一个Object对象。如果 MarkSweep IsMarked返回为空指针，说明输入obj没有被标记—说明该obj是 垃圾对象。 */ mirror::Object* new_obj = visitor-\u0026gt;IsMarked(obj); if (new_obj == nullptr) { /*new_obj为空指针，说明这个WeakGlobal型对象指向的那个对象是垃圾，将会被清除。 这时我们需要修改WeakGlobal型对象的内容，使它指向另外一个有特殊含义的对象— 即Runtime的sentinel_成员变量（由GetClearedJniWeakGlobal函数返回）。Runtime sentinel_就是一个Java Object对象，它在ClassLinker InitFromBootImage 函数中创建。该对象本身没有什么特别之处，只不过它有特殊用途而已。*/ new_obj = runtime-\u0026gt;GetClearedJniWeakGlobal(); } //修改WeakGloabl型对象的内容  *entry = GcRoot\u0026lt;mirror::Object\u0026gt;(new_obj); } } } Sweep void MarkSweep::Sweep(bool swap_bitmaps) {//注意，调用时swap_bitmaps为false  ...... { /*GetLiveStack返回Heap的live_stack_。14.4.4节中介绍过Heap live_stack_的内容。它 保存了mutator线程所创建的对象。从严格意义上来说是从下面的Reset调用后到PausePhase调用 Heap SwapStacks之前这段时间内mutator创建的对象。为什么这么说呢？原因是在于它们的使用 步骤： (1) mutator只会将创建的对象存储于Heap allocation_stack_中。 (2) Heap SwapStacks将交换Heap live_stack_和allocation_stack_的内容。此后， allocation_stack_容器为空容器（原因在步骤3）。 (3) Heap MarkAllocStackAsLive后，live_stack_会被Reset，也就是容器会被清空。 而live_stack_在第2步中会和allocation_stack_交换，所以交换后， allocation_stack_就是空容器了。 简单来说，live_stack_中的对象属于集合Live。但是，请读者注意，live_stack_只是集合 Live的一部分。因为它只保存了两次GC间创建的对象。*/ accounting::ObjectStack* live_stack = heap_-\u0026gt;GetLiveStack(); /*调用Heap MarkAllocStackAsLive对live_stack中的元素进行处理。 (1) 这些元素就是一个个mirror Object对象，它们属于集合Live。 (2) MarkAllocStackAsLive将找到这些对象所在的空间，然后对这些空间对象的 live_bitmap_位图进行设置。也就是说，集合Live由空间对象的live_bitmap_表示。*/ heap_-\u0026gt;MarkAllocStackAsLive(live_stack); live_stack-\u0026gt;Reset();//清空Heap live_stack_的内容  } //遍历HeapContinuous_spaces_的成员，读者可回顾14.4.1节中的图14-6。  for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { /*结合图14-6以及13.1节的内容可知，只有 \u0026#34;main rosalloc space\u0026#34;和\u0026#34;zygote / non moving space\u0026#34;这两个空间为 ContinuousMemMapAllocSpace。而\u0026#34;.../boot.art\u0026#34;对应的ImageSpace属于 ContinuousSpace。 */ if (space-\u0026gt;IsContinuousMemMapAllocSpace()) { space::ContinuousMemMapAllocSpace* alloc_space = space-\u0026gt;AsContinuousMemMapAllocSpace(); ...... //调用ContinuousMemMapAllocSpace的Sweep函数，swap_bitmaps值为false  RecordFree(alloc_space-\u0026gt;Sweep(swap_bitmaps)); } } //回收DiscontinuousSpace对象中的垃圾，请读者自行阅读这部分代码  SweepLargeObjects(swap_bitmaps) } ContinuousMemMapAllocSpace::Sweep collector::ObjectBytePair ContinuousMemMapAllocSpace::Sweep(bool swap_bitmaps) { /*Sweep的返回值类型为ObjectBytePair，它类似std的pair类，包含两个信息，第一个信息 是回收的垃圾对象的个数，第二个信息是回收的内存的字节数。*/ //获取空间的live_bitmap_和mark_bitmap_成员，它们分别代表集合Live和集合Mark  accounting::ContinuousSpaceBitmap* live_bitmap = GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = GetMarkBitmap(); //如果live_bitmap和mark_bitmap是同一个对象，则不需要清除  if (live_bitmap == mark_bitmap) { return collector::ObjectBytePair(0, 0); } SweepCallbackContext scc(swap_bitmaps, this); //交换live_bitmap和mark_bitmap的值。本次调用if的条件不满足  if (swap_bitmaps) { std::swap(live_bitmap, mark_bitmap); } /*调用ContinuousSpaceBitmap的SweepWalk函数，它将扫描从Begin()开始，到End() 结束的这段内存空间。请读者注意SweepWalk的参数： live_bitmap：代表集合Live。 mark_bitmap：代表集合Mark。 SweepWalk判断一个对象是否为垃圾对象的条件很简单。假设某个对象在两个位图中的索引是i， 那么，该对象是垃圾的条件是\u0026#34;live_bitmap[i] \u0026amp; ~mark_bitmap[i]\u0026#34;为true，即： (1) 如果live_bitmap[i]为1，说明它属于集合Live。 (2) 如果mark_bitmap[i]为0，说明这个对象不属于集合Mark。 当条件1和2满足时，这个对象就是垃圾对象。 GetSweepCallback由子类实现，返回一个处理垃圾对象回调函数。SweepWalk每找到一个垃圾对象 都会调用这个回调函数进行处理。*/ accounting::ContinuousSpaceBitmap::SweepWalk( *live_bitmap, *mark_bitmap, reinterpret_cast\u0026lt;uintptr_t\u0026gt;(Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(End()), GetSweepCallback(), reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;scc)); return scc.freed; } MallocSpace::SweepCallback void MallocSpace::SweepCallback(size_t num_ptrs, mirror::Object** ptrs, void* arg) { /*ContinuousSpaceBitmap SweepWalk找到垃圾对象后就会回调SweepCallback。 参数中的num_ptrs代表垃圾对象的个数，而**ptrs代表一个垃圾对象数组的起始地址。*/ SweepCallbackContext* context = static_cast\u0026lt;SweepCallbackContext*\u0026gt;(arg); space::MallocSpace* space = context-\u0026gt;space-\u0026gt;AsMallocSpace(); Thread* self = context-\u0026gt;self; //回调时传入的信息，swap_bitmaps为false  if (!context-\u0026gt;swap_bitmaps) { accounting::ContinuousSpaceBitmap* bitmap = space-\u0026gt;GetLiveBitmap(); //既然是垃圾对象，则需要将其从live_bitmap_中去除  for (size_t i = 0; i \u0026lt; num_ptrs; ++i) { bitmap-\u0026gt;Clear(ptrs[i]); } } context-\u0026gt;freed.objects += num_ptrs; //RosAlloc和DlMallocSpace均实现了FreeList函数，用于释放一组对象的内存  context-\u0026gt;freed.bytes += space-\u0026gt;FreeList(self, num_ptrs, ptrs); } SwapBitmaps /*SwapBitmaps的作用其实很简单，就是交换集合Live和集合Mark在相关数据结构中对应的成员变量。我们以集合Live和集合Mark为目标来看待交换后的结果。 集合Live包含了此次GC中搜索到的对象。显然，它们构成了集合Live第二部分的内容——即上一次GC后剩下的对象。注意，本次GC的剩余对象将作为下一次GC中集合Live的内容。 集合Mark包含的信息是原集合Live去掉本次GC中的垃圾对象后的结果。*/ void GarbageCollector::SwapBitmaps() { ...... const GcType gc_type = GetGcType(); for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { /*回顾13.7.1节的内容可知，ZygoteSpace的gc_retention_policy_取值为kGcRetention- PolicyFullCollect，而BumpPointerSpace、RegionSpace、DlMallocSpace、 RosAllocSpace的gc_retention_policy_取值为kGcRetentionPolicyAlwaysCollect， ImageSpace的gc_retention_policy_取值为kGcRetentionPolicyNeverCollect。 下面这个if条件中包含两个判断，其中的第二个判断说明只在MarkSweep的时候才处理ZygoteSpace 空间。而PartialMarkSweep以及StickMarkSweep均不需要处理它。 这也符合kGcTypeFull等回收策略的要求。 */ if( space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyAlwaysCollect || (gc_type == kGcTypeFull \u0026amp;\u0026amp; space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyFullCollect)) { accounting::ContinuousSpaceBitmap* live_bitmap = space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = space-\u0026gt;GetMarkBitmap(); if (live_bitmap != nullptr \u0026amp;\u0026amp; live_bitmap != mark_bitmap) { /*更新Heap live_bitmap_和mark_bitmap_数组中的元素，ReplaceBitmap第一个 参数为旧值，第二个参数为新值。其内部将先找到旧值所在的数组索引，然后将新值存储 到该索引位置上。下面这两行代码就是交换Heap live_bitmap_和mark_bitmap_ 对应元素的信息。 */ heap_-\u0026gt;GetLiveBitmap()-\u0026gt;ReplaceBitmap(live_bitmap, mark_bitmap); heap_-\u0026gt;GetMarkBitmap()-\u0026gt;ReplaceBitmap(mark_bitmap, live_bitmap); //交换space中live_bitmap_和mark_bitmap_。  space-\u0026gt;AsContinuousMemMapAllocSpace()-\u0026gt;SwapBitmaps(); } } } ......//对大内存对象的处理，和上面类似 } Heap::UnBindBitmaps void Heap::UnBindBitmaps() { ...... for (const auto\u0026amp; space : GetContinuousSpaces()) { if (space-\u0026gt;IsContinuousMemMapAllocSpace()) { space::ContinuousMemMapAllocSpace* alloc_space = space-\u0026gt;AsContinuousMemMapAllocSpace(); //temp_bitmap_不为空，说明之前曾经调用过BindLiveToMarkBitmap  if (alloc_space-\u0026gt;HasBoundBitmaps()) alloc_space-\u0026gt;UnBindBitmaps(); } } } space.cc\nvoid ContinuousMemMapAllocSpace::UnBindBitmaps() { //temp_bitmap_保存了原mark_bitmap_的内容，而mark_bitmap_保存了原live_bitmap_的内容  accounting::ContinuousSpaceBitmap* new_bitmap = temp_bitmap_.release(); //恢复Heap mark_bitmap_对应索引的内容  Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetMarkBitmap()-\u0026gt;ReplaceBitmap( mark_bitmap_.get(), new_bitmap); //恢复mark_bitmap_的内容  mark_bitmap_.reset(new_bitmap); } FinishPhase void MarkSweep::FinishPhase() { ...... mark_stack_-\u0026gt;Reset();//清空MarkSweep mark_stack_的内容  Thread* const self = Thread::Current(); ReaderMutexLock mu(self, *Locks::mutator_lock_); WriterMutexLock mu2(self, *Locks::heap_bitmap_lock_); //清空空间对象mark_bitmap_，也就是GC结束后，集合Mark将被清空  heap_-\u0026gt;ClearMarkedObjects(); } partial_mark_sweep\nPartialMarkSweep class PartialMarkSweep : public MarkSweep { public: virtual GcType GetGcType() const OVERRIDE { return kGcTypePartial; //回收策略  } ...... protected: virtual void BindBitmaps() OVERRIDE; ...... }; BindBitmaps void PartialMarkSweep::BindBitmaps() { //调用父类的BindBitmaps，根据14.4.3.1节的介绍可知，ImageSpace将  //加入immune_spaces_  MarkSweep::BindBitmaps(); WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { //根据13.1节的内容可知，只有ZygoteSpace空间的回收策略是  //kGcRetentionPolicyFullCollect。所以，下面这几行代码就是将ZygoteSpace加入  //immune_spaces_  if (space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyFullCollect) { immune_spaces_.AddSpace(space); } } } sticky_mark_sweep\nStickyMarkSweep class StickyMarkSweep FINAL : public PartialMarkSweep { //StickyMarkSweep派生自PartialMarkSweep  public: GcType GetGcType() const OVERRIDE { return kGcTypeSticky; } .... protected: void BindBitmaps() OVERRIDE; void MarkReachableObjects() OVERRIDE ; void Sweep(bool swap_bitmaps) OVERRIDE; ...... }; BindBitmaps void StickyMarkSweep::BindBitmaps() { //StickyMarkSweep不处理ImageSpace和ZygoteSpace  PartialMarkSweep::BindBitmaps(); WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); for (const auto\u0026amp; space : GetHeap()-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;IsContinuousMemMapAllocSpace() \u0026amp;\u0026amp; space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyAlwaysCollect) { //调用ContinuousMemMapAllocSpace的BindLiveToMarkBitmap函数，见下文解释  space-\u0026gt;AsContinuousMemMapAllocSpace()-\u0026gt;BindLiveToMarkBitmap(); } } //处理DiscontinuousSpace的情况，请读者自行阅读  ...... } ContinuousMemMapAllocSpace::BindLiveToMarkBitmap void ContinuousMemMapAllocSpace::BindLiveToMarkBitmap() { accounting::ContinuousSpaceBitmap* live_bitmap = GetLiveBitmap(); if (live_bitmap != mark_bitmap_.get()) { accounting::ContinuousSpaceBitmap* mark_bitmap = mark_bitmap_.release(); /*下面这行代码的意思是更新Heap mark_bitmap_中原mark_bitmap所在的元素。 更新前,该元素的旧值为mark_bitmap，更新后该元素的新增为live_bitmap。 要理解这行代码的含义，需要读者明白两点： (1) 根据上文对MarkSweep GC代码逻辑的介绍可知，空间对象的live_bitmap_就是本次 GC的集合Live。 (2) Heap mark_bitmap_为集合Mark。调用BindBitmaps的时候，标记工作还未开展， 所以集合Mark为空（集合Mark在上次GC的FinishPhase中被清空）。 结合1和2，对StickyMarkSweep来说，标记还没有开始做（BindBitmaps函数为GC的 准备工作），我们就已经把上次GC的幸存对象“标记”好了。所以，上次GC的幸存对象在本 次GC中将被保留。*/ Runtime::Current()-\u0026gt;GetHeap()-\u0026gt;GetMarkBitmap()-\u0026gt;ReplaceBitmap(mark_bitmap, live_bitmap); //mark_bitmap的值保存到temp_bitmap_中  temp_bitmap_.reset(mark_bitmap); //原live_bitmap的信息保存到mark_bitmap_中  mark_bitmap_.reset(live_bitmap); } } MarkReachableObjects void StickyMarkSweep::MarkReachableObjects() { //mark_stack_被清空，这表示在MarkRoots中做过标记的对象不再需要。但集合Mark的  //信息却留了下来  mark_stack_-\u0026gt;Reset(); //注意下面这个函数最后一个参数的取值为kCardDirty – 1  RecursiveMarkDirtyObjects(false, accounting::CardTable::kCardDirty - 1); } Sweep void StickyMarkSweep::Sweep(bool swap_bitmaps ATTRIBUTE_UNUSED) { /*SweepArray的第一个参数为Heap live_stack_。live_stack_包含了两次GC间所创建的 对象。它就是StickyMarkSweep中的集合Live。 */ SweepArray(GetHeap()-\u0026gt;GetLiveStack(), false); } SweepArray void MarkSweep::SweepArray(accounting::ObjectStack* allocations, bool swap_bitmaps) { Thread* self = Thread::Current(); /*sweep_array_free_buffer_mem_map_是MarkSweep的成员变量，在构造函数中创建 读者将它看作一块内存即可。下面这行代码将这块内存转成数组变量以方便后续代码的使用。 数据变量名为chunk_free_buffer，数组元素的类型为Object*。 */ mirror::Object** chunk_free_buffer = reinterpret_cast\u0026lt;mirror::Object**\u0026gt;( sweep_array_free_buffer_mem_map_-\u0026gt;BaseBegin()); size_t chunk_free_pos = 0; ...... /*allocations为输入参数，指向Heap live_stack_，读者将live_stack_看成一个数组 容器即可。下面的变量中，objects为这个数组的起始元素，count为数组的元素个数。 */ StackReference\u0026lt;mirror::Object\u0026gt;* objects = allocations-\u0026gt;Begin(); size_t count = allocations-\u0026gt;Size(); /*sweep_spaces是一个数组，用于保存此次GC所要扫描的空间对象。请读者注意，这段 代码中包含一个优化处理。根据注释可知，Heapnon_moving_space_中不太可能出现很多垃 圾对象，所以代码将把non_moving_space_放到sweep_spaces数组的最后。*/ std::vector\u0026lt;space::ContinuousSpace*\u0026gt;sweep_spaces; space::ContinuousSpace* non_moving_space = nullptr; for (space::ContinuousSpace* space : heap_-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;IsAllocSpace() \u0026amp;\u0026amp;!immune_spaces_.ContainsSpace(space)\u0026amp;\u0026amp; space-\u0026gt;GetLiveBitmap() != nullptr) { if (space == heap_-\u0026gt;GetNonMovingSpace()) { //如果是Heap non_moving_space_，则先不加到sweep_spaces数组中  non_moving_space = space; } else { sweep_spaces.push_back(space);//将space保存到数组中  } } } //如果存在non_moving_space，则将其加到数组的最后  if (non_moving_space != nullptr) { sweep_spaces.push_back(non_moving_space); } //接下来开始处理垃圾对象，逐个空间处理  for (space::ContinuousSpace* space : sweep_spaces) { //space和alloc_space指向的是同一个空间对象。只不过后续需要调用AllocSpace的  //FreeList函数释放内存，所以这里会先定义一个alloc_space变量  space::AllocSpace* alloc_space = space-\u0026gt;AsAllocSpace(); accounting::ContinuousSpaceBitmap* live_bitmap = space-\u0026gt;GetLiveBitmap(); accounting::ContinuousSpaceBitmap* mark_bitmap = space-\u0026gt;GetMarkBitmap(); ...... //objects为Heap live_stack_容器的起始元素，count为容器的元素个数,main  StackReference\u0026lt;mirror::Object\u0026gt;* out = objects; for (size_t i = 0; i \u0026lt;count; ++i) { mirror::Object* const obj = objects[i].AsMirrorPtr(); //kUseThreadLocalAllocationStack为编译常量，默认为true  if (kUseThreadLocalAllocationStack\u0026amp;\u0026amp; obj == nullptr) { continue; } //先判断space是否包含obj  if (space-\u0026gt;HasAddress(obj)) { //空间对象的mark_bitmap没有设置obj，所以obj是垃圾对象,main  if (!mark_bitmap-\u0026gt;Test(obj)) { /*kSweepArrayChunkFreeSize的值为0。我们找到一个垃圾对象后并不是马上就 清理它，而是先存起来，等攒到一定数量后再一起清理。所以，下面这段代 码的含义就很好理解了。kSweepArrayChunkFreeSize值为1024。 */ if (chunk_free_pos \u0026gt;= kSweepArrayChunkFreeSize) { freed.objects += chunk_free_pos; //释放一组垃圾对象的内存,main  freed.bytes += alloc_space-\u0026gt;FreeList(self, chunk_free_pos, chunk_free_buffer); chunk_free_pos = 0; } //如果个数还未超过1024，先存起来  chunk_free_buffer[chunk_free_pos++] = obj; } } else {//对应!mark_bitmap-\u0026gt;Test(obj)为false的时候，即obj不是垃圾对象  /*obj不是垃圾对象的话，则把obj存到Heap live_stack_新的位置上。随着垃圾对象 被清除，非垃圾对象将向前移动以填补垃圾对象所占据的位置，这样可减少后续其他空间 对象处理的工作量。当然，live_stack_的元素个数也需要相应调整。main*/ (out++)-\u0026gt;Assign(obj); } } ...... count = out - objects;//调整live_stack_的元素个数  } ......//对Discontinuousspaces的处理  { ...... allocations-\u0026gt;Reset();//清空Heap live_stack_的内容  } sweep_array_free_buffer_mem_map_-\u0026gt;MadviseDontNeedAndZero(); } 其他 mark_sweep.h/cc GetCollectorType //PartialMarkSweep和StickyMarkSweep均未重载下面这个函数  virtual CollectorType GetCollectorType() const OVERRIDE { //is_concurrent_为MarkSweep的成员变量，如果为true，则返回kCollectorTypeCMS  return is_concurrent_ ? kCollectorTypeCMS : kCollectorTypeMS; } GetGcType virtual GcType GetGcType() const OVERRIDE { return kGcTypeFull;//MarkSweep支持最强力度的GC策略 } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/gc2_concurrentcopying/",
	"title": "GC2_ConcurrentCopying",
	"tags": [],
	"description": "",
	"content": "ConcurrentCopying virtual GcType GetGcType() const OVERRIDE { //ConcurrentCopying仅支持kGcTypePartial，也就是不扫描ImageSpace和  //ZygoteSpace（除了那些有dirty card的对象）  return kGcTypePartial; } virtual CollectorType GetCollectorType() const OVERRIDE { return kCollectorTypeCC;//返回回收器类型 } void SetRegionSpace(space::RegionSpace* region_space) { //region_space_是ConcurrentCopying的成员变量  //ConcurrentCopying要回收的垃圾对象就在这个region_space_中  region_space_ = region_space; } RunPhases void ConcurrentCopying::RunPhases() { is_active_ = true; Thread* self = Thread::Current(); thread_running_gc_ = self; { ReaderMutexLock mu(self, *Locks::mutator_lock_); InitializePhase();//①初始化阶段  } FlipThreadRoots();//②完成半空间Flip工作  { ReaderMutexLock mu(self, *Locks::mutator_lock_); MarkingPhase();//③标记  } ...... { ReaderMutexLock mu(self, *Locks::mutator_lock_); ReclaimPhase();//④回收  } FinishPhase();//收尾工作，非常简单，请读者自行阅读  is_active_ = false; thread_running_gc_ = nullptr; } InitializePhase void ConcurrentCopying::InitializePhase() { ...... CheckEmptyMarkStack();//详情见下文代码分析  //immune_spaces_类型为ImmuneSpace，保存了不需要GC的空间对象  immune_spaces_.Reset(); ..... /*下面的代码逻辑将设置force_evacuate_all_成员变量，它和RegionSpace有关，我们 后续用到该变量时再介绍其含义。*/ if (GetCurrentIteration()-\u0026gt;GetGcCause() == kGcCauseExplicit || GetCurrentIteration()-\u0026gt;GetGcCause() == kGcCauseForNativeAlloc || GetCurrentIteration()-\u0026gt;GetClearSoftReferences()) { force_evacuate_all_ = true; } else { force_evacuate_all_ = false; } BindBitmaps();//详解见下文代码分析  ...... } CheckEmptyMarkStack void ConcurrentCopying::CheckEmptyMarkStack() { Thread* self = Thread::Current(); /*Thread tlsPtr_中有一个名为thread_local_mark_stack的成员变量，其定义如下： AtomicStack\u0026lt;:Object\u0026gt;* thread_local_mark_stack; thread_local_mark_stack是专门配合ConcurrentCopying而使用的，其数据类型就是 AtomicStack（和上文提到的Heap allocation_stack_、mark_stack_一样） tlsPtr_ thread_local_mark_stack的具体用法我们后文碰到时再介绍。 MarkStackMode是枚举变量，其中定义了4个枚举值（它们的含义们下文碰到时再介绍）： enum MarkStackMode { kMarkStackModeOff = 0, kMarkStackModeThreadLocal, kMarkStackModeShared, kMarkStackModeGcExclusive }; mark_stack_mode_是ConcurrentCopying成员变量，初始值为kMarkStackModeOff。 GC过程中将修改它。*/ MarkStackMode mark_stack_mode = mark_stack_mode_.LoadRelaxed(); //mark_stack_mode取值为kMarkStackModeThreadLocal的处理逻辑  if (mark_stack_mode == kMarkStackModeThreadLocal) { /*RevokeThreadLocalMarkStack将要求各个Java Thread执行一个CheckPoint任务， 该任务有三个关键处理，笔者列举如下： (1) 获取线程对象的tlsPtr_ thread_local_mark_stack对象（通过Thread GetThreadLocalMarkStack）。该对象初值为空，ConcurrentCopying GC过程中 会设置它（详情见后文分析）。 (2) 如果线程的thread_local_mark_stack不为空，则将它保存到ConcurrentCopying revoked_mark_stacks_（类型为vector\u0026lt;ObjectStack*\u0026gt;）成员变量中。 (3) 调用Thread SetThreadLocalMarkStack，将thread_local_mark_stack设置为空。 RevokeThreadLocalMarkStacks的调用结果就是将线程对象中不为空的 thread_local_mark_stack放到revoked_mark_stacks_数组中。 */ RevokeThreadLocalMarkStacks(false); MutexLock mu(Thread::Current(), mark_stack_lock_); //如果revoked_mark_stacks_不为空，则需要逐个清除其中所包含的Object对象  if (!revoked_mark_stacks_.empty()) { for (accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;* mark_stack : revoked_mark_stacks_) { while (!mark_stack-\u0026gt;IsEmpty()) { mirror::Object* obj = mark_stack-\u0026gt;PopBack(); ......//打印信息  } } } } else {//如果mark_stack_mode取值为其他值  MutexLock mu(Thread::Current(), mark_stack_lock_); //gc_mark_stack_指向一个ObjectStack对象  CHECK(gc_mark_stack_-\u0026gt;IsEmpty()); CHECK(revoked_mark_stacks_.empty()); } } BindBitmaps void ConcurrentCopying::BindBitmaps() { Thread* self = Thread::Current(); WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); for (const auto\u0026amp; space : heap_-\u0026gt;GetContinuousSpaces()) { //ConcurrentCopying只支持kGcTypePartial，所以ImageSpace、ZygoteSpace  //同样会被加到immune_spaces_中  if (space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyNeverCollect || space-\u0026gt;GetGcRetentionPolicy() == space::kGcRetentionPolicyFullCollect) { CHECK(space-\u0026gt;IsZygoteSpace() || space-\u0026gt;IsImageSpace()); immune_spaces_.AddSpace(space); /*cc_heap_bitmap_类型为HeapBitmap，cc_bitamps_类型为 vector\u0026lt; SpaceBitmap\u0026lt;kObjectAlignment\u0026gt;*\u0026gt;。这两个成员变量由 ConcurrentCopying内部使用。*/ const char* bitmap_name = space-\u0026gt;IsImageSpace() ? \u0026#34;cc image space bitmap\u0026#34; : \u0026#34;cc zygote space bitmap\u0026#34;; accounting::ContinuousSpaceBitmap* bitmap = accounting::ContinuousSpaceBitmap::Create(bitmap_name,space-\u0026gt;Begin(), space-\u0026gt;Capacity()); cc_heap_bitmap_-\u0026gt;AddContinuousSpaceBitmap(bitmap); cc_bitmaps_.push_back(bitmap); } else if (space == region_space_) { accounting::ContinuousSpaceBitmap* bitmap = accounting::ContinuousSpaceBitmap::Create( \u0026#34;cc region space bitmap\u0026#34;, space-\u0026gt;Begin(), space-\u0026gt;Capacity()); cc_heap_bitmap_-\u0026gt;AddContinuousSpaceBitmap(bitmap); cc_bitmaps_.push_back(bitmap); region_space_bitmap_ = bitmap; } } } FlipThreadRoots 图解 graph LR subgraph RootObject GC线程--\u0026gt;交换From和To空间 Mutator线程--\u0026gt;VisitRoots(\u0026quot;thread-\u0026gt;VisitRoots\u0026quot;) end VisitRoots--\u0026gt;|callback root ref|Mark(\u0026quot;mirror::Object* to_ref = Mark(ref);\u0026quot;) Mark--\u0026gt;|forwarding address|GetFwdPtr Mark--\u0026gt;Copy Mark--\u0026gt;PushOntoMarkStack subgraph ObjectReferencedByRoot ProcessMarkStack--\u0026gt;|遍历mark_stack中的根对象得到to_ref|VisitReferences(\u0026quot;to_ref-\u0026gt;VisitReferences\u0026quot;) end VisitReferences--\u0026gt;|得到field ref|Mark(\u0026quot;mirror::Object* to_ref = Mark(ref)得到ref的to_ref,标记，拷贝\u0026quot;)--\u0026gt;updateRef void ConcurrentCopying::FlipThreadRoots() { ...... Thread* self = Thread::Current(); Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); gc_barrier_-\u0026gt;Init(self, 0); ThreadFlipVisitor thread_flip_visitor(this, heap_-\u0026gt;use_tlab_); FlipCallback flip_callback(this); heap_-\u0026gt;ThreadFlipBegin(self); /*Runtime FlipThreadRoots将先暂停线程对象，然后设置它们的flip_function， 接着再恢复它们的运行。FlipThreadRoots前两个参数分别是两个闭包对象，其中： (1) GC线程（也就是当前调用FlipThreadRoots的线程）先执行flip_callback。 (2) 其他所有Java线程对象再执行thread_flip_visitor。 根据ThreadList的注释，FlipThreadRoots只由ConcurrentCopying使用。 */ size_t barrier_count = Runtime::Current()-\u0026gt;FlipThreadRoots(\u0026amp;thread_flip_visitor, \u0026amp;flip_callback, this); heap_-\u0026gt;ThreadFlipEnd(self); ...... is_asserting_to_space_invariant_ = true; ...... } FlipCallback class FlipCallback : public Closure { public: ...... virtual void Run(Thread* thread) OVERRIDE { ConcurrentCopying* cc = concurrent_copying_; ...... Thread* self = Thread::Current(); ...... /*调用RegionSpace的SetFromSpace。rb_table_为ReadBarrierTable，来自Heap的成员 变量rb_table_。ReadBarrieTable的启用需要设置前台回收器类型为 kCollectorTypeCC，并且定义编译宏kUseTableLookupReadBarrier。*/ cc-\u0026gt;region_space_-\u0026gt;SetFromSpace(cc-\u0026gt;rb_table_,cc-\u0026gt;force_evacuate_all_); //内部调用HeapSwapStacks。交换Heap allocation_stack_和live_stack_  cc-\u0026gt;SwapStacks(); ...... cc-\u0026gt;is_marking_ = true; //设置mark_stack_mode_的值为kMarkStackModeThreadLocal  cc-\u0026gt;mark_stack_mode_.StoreRelaxed(ConcurrentCopying::kMarkStackModeThreadLocal); ....... } ...... }; region_space.cc\nRegionSpace::SetFromSpace void RegionSpace::SetFromSpace(accounting::ReadBarrierTable* rb_table, bool force_evacuate_all) { /*回顾13.3.2节的内容可知，RegionSpace把内存资源划分成数个块，每一个块由一个Region对象 描述。num_regions_是Region的个数，而region_数组保存了各个内存块对应的Region信息。*/ ...... for (size_t i = 0; i \u0026lt;num_regions_; ++i) { Region* r = \u0026amp;regions_[i]; /*RegionState枚举变量描述了一个Region的状态，我们重点看前两个枚举值的含义： (1) kRegionStateFree：表示Region为空闲待使用状态 (2) kRegionStateAllocated：表示Region已经有一部分内存被分配了。 RegionType枚举变量描述了一个Region的类型，它有如下五种取值： (1) kRegionTypeAll：代码中没有明确使用它的地方，读者可不考虑 (2) kRegionTypeFromSpace：Region位于From Space中，需要被清除（evacuate） (3) kRegionTypeUnevacFromSpace：该Region位于From Space，但是不需要被清除 (4) kRegionTypeToSpace：Region位于To Space中。 (5) kRegionTypeNone：Region的默认类型。 如果一个Region首先被使用，其类型将从kRegionTypeNone转换为 kRegionTypeToSpace。相关代码见Region Unfree函数。 */ RegionState state = r-\u0026gt;State(); RegionType type = r-\u0026gt;Type(); if (!r-\u0026gt;IsFree()) {//IsFree返回false，说明该Region已经被使用  if (LIKELY(num_expected_large_tails == 0U)) { /*ShouldBeEvacuated用于判断一个Region是否需要被清除。Region中有两个成员变量 与之相关： (1) is_newly_allocated_：bool型。一个Region从kRegionStateFree到kRegion- StateAllocated时，该成员变量被设置为true（通过调用Region SetNewlyAllocated 函数来完成）。如果is_newly_allocated_为true，ShouldBeEvacuated返回也为true。 (2) live_bytes_：非垃圾对象所占内存的字节数。如果它和该Region中所分配的总内存字节数 之比小于75%（kEvaculateLivePercentThreshold），则ShouldBeEvacuated也返 回true。*/ bool should_evacuate = force_evacuate_all || r-\u0026gt;ShouldBeEvacuated(); if (should_evacuate) { r-\u0026gt;SetAsFromSpace();//设置Region的类型为kRegionTypeFromSpace  } else { //设置Region的类型为kRegionTypeUnevacFromSpace  r-\u0026gt;SetAsUnevacFromSpace(); } ........ }....... } else { ...... } } current_region_ = \u0026amp;full_region_; evac_region_ = \u0026amp;full_region_; } ThreadFlipVisitor class ThreadFlipVisitor : public Closure { public: ...... virtual void Run(Thread* thread) OVERRIDE { Thread* self = Thread::Current(); //设置线程对象tls32_is_gc_marking为true  thread-\u0026gt;SetIsGcMarking(true); if (use_tlab_ \u0026amp;\u0026amp; thread-\u0026gt;HasTlab()) { if (ConcurrentCopying::kEnableFromSpaceAccountingCheck) { ...... } else { //撤销RegionSpace为线程thread分配的TLAB  concurrent_copying_-\u0026gt;region_space_-\u0026gt;RevokeThreadLocalBuffers(thread); } } if (kUseThreadLocalAllocationStack) { //撤销线程本地Allocation Stack  thread-\u0026gt;RevokeThreadLocalAllocationStack(); } ReaderMutexLock mu(self, *Locks::heap_bitmap_lock_); //访问线程根对象。ConcurrentCopying的VisitRoots函数将被调用，其内部调用  //MarkRoot。我们下文将重点分析MarkRoot函数  thread-\u0026gt;VisitRoots(concurrent_copying_); concurrent_copying_-\u0026gt;GetBarrier().Pass(self); } ...... }; // Process some roots. inline void ConcurrentCopying::VisitRoots( mirror::Object*** roots, size_t count, const RootInfo\u0026amp; info ATTRIBUTE_UNUSED) { for (size_t i = 0; i \u0026lt; count; ++i) { mirror::Object** root = roots[i]; mirror::Object* ref = *root; mirror::Object* to_ref = Mark(ref); ...... } } inline void ConcurrentCopying::VisitRoots( mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;** roots, size_t count, const RootInfo\u0026amp; info ATTRIBUTE_UNUSED) { for (size_t i = 0; i \u0026lt; count; ++i) { mirror::CompressedReference\u0026lt;mirror::Object\u0026gt;* const root = roots[i]; if (!root-\u0026gt;IsNull()) { // kGrayImmuneObject is true because this is used for the thread flip.  MarkRoot\u0026lt;/*kGrayImmuneObject*/true\u0026gt;(root); } } } inline void ConcurrentCopying::MarkRoot(CompressedReference\u0026lt;Object\u0026gt;* root) { //ref是当前正在被访问的某个线程根对象  mirror::Object* const ref = root-\u0026gt;AsMirrorPtr(); /*调用ConcurrentCopying Mark，返回一个to_ref对象。to_ref的内容和ref一样， 但它可能位于其他空间中（这就是拷贝的含义，详情见下文对Mark的分析）。 如果to_ref和ref不相同，则需要修改存储ref的内存，使得它指向新的to_ref。 具体的修改方式是先将root转换为一个Atomic\u0026lt;CompressedReference\u0026lt;Object\u0026gt;\u0026gt;*对象， 然后进行原子操作。总之，在Mark函数后，原线程根对象可能被更新为位于另外一个空间中的对象。*/ mirror::Object* to_ref = Mark(ref); if (to_ref != ref) { auto* addr = reinterpret_cast\u0026lt;Atomic\u0026lt;CompressedReference\u0026lt;Object\u0026gt;\u0026gt;*\u0026gt; (root); auto expected_ref = CompressedReference\u0026lt;Object\u0026gt;::FromMirrorPtr(ref); auto new_ref = CompressedReference\u0026lt;Object\u0026gt;::FromMirrorPtr(to_ref); do { if (ref != addr-\u0026gt;LoadRelaxed().AsMirrorPtr()) { break; } } while (!addr-\u0026gt;CompareExchangeWeakRelaxed(expected_ref, new_ref)); } } ConcurrentCopying::Mark inline mirror::Object* ConcurrentCopying::Mark(mirror::Object* from_ref) { ...... //获取from_ref所在的Region的类型。注意，如果from_ref不是region_space_的对象，  //则GetRegionType返回kRegionTypeNone  space::RegionSpace::RegionType rtype = region_space_-\u0026gt;GetRegionType(from_ref); switch (rtype) { case space::RegionSpace::RegionType::kRegionTypeToSpace: //如果from_ref已经在To Space中，则直接返回它。不需要后续的拷贝  return from_ref; case space::RegionSpace::RegionType::kRegionTypeFromSpace: { /*如果from_ref位于From Space中（由Region ShouldEvacuate函数决定），则调用 GetFwdPtr找到from_ref的拷贝对象。下文将介绍GetFwdPtr函数。main*/ mirror::Object* to_ref = GetFwdPtr(from_ref); ...... if (to_ref == nullptr) { //如果from_ref不存在对应的拷贝对象，则调用Copy生成一个拷贝对象  to_ref = Copy(from_ref); } return to_ref; } case space::RegionSpace::RegionType::kRegionTypeUnevacFromSpace: { mirror::Object* to_ref = from_ref; //如果from_ref位于from space中不需要清理的Region的话，则对该对象进行标记  if (region_space_bitmap_-\u0026gt;AtomicTestAndSet(from_ref)) { } else { //如果from_ref是初次标记，则调用PushOntoMarkStack，下文将介绍该函数,main  PushOntoMarkStack(to_ref); } return to_ref; } case space::RegionSpace::RegionType::kRegionTypeNone: /*如果Region类型为kRegionTypeNone，说明from_ref不是region_space_中的 对象（有可能是ImageSpace或ZygoteSpace中的对象），则调用MarkNonMoving 函数。这种情况下无须拷贝from_ref。但它的引用型成员变量所指向的对象可能被拷贝 了，我们需要做对应的处理。读者不妨自行阅读MarkNonMoving函数。 */ return MarkNonMoving(from_ref); default: UNREACHABLE(); } } inline mirror::Object* ConcurrentCopying::GetFwdPtr( mirror::Object* from_ref) { //先拿到from_ref monitor_对应的LockWord对象  LockWord lw = from_ref-\u0026gt;GetLockWord(false); /*如果lw的状态为kForwardingAddress，说明lw包含了一个mirror Object对象的地址 信息。对Copying Collection而言，这个地址就是from_ref对应的拷贝对象的地址， GC理论称之为Forwarding Address。*/ if (lw.GetState() == LockWord::kForwardingAddress) { Object* fwd_ptr = reinterpret_cast\u0026lt;Object*\u0026gt;(lw.ForwardingAddress()); return fwd_ptr; //fwd_ptr就是from_ref的拷贝对象  } else { return nullptr; } } ConcurrentCopying::Copy //Copy函数拷贝from_ref对象的信息到一个新的对象to_ref中，然后将to_ref的地址存储到from_ref monitor_成员变量中。在GC理论中，这个地址叫Forwading Address。 mirror::Object* ConcurrentCopying::Copy(mirror::Object* from_ref) { //获取from_ref对象的内存大小  size_t obj_size = from_ref-\u0026gt;SizeOf\u0026lt;...\u0026gt;(); //按Region的要求进行对齐  size_t region_space_alloc_size = RoundUp(obj_size, space::RegionSpace::kAlignment); ...... //从region_space_中分配一块内存用来存储from_ref的内容。这块内存的起始地址为  //to_ref  mirror::Object* to_ref = region_space_-\u0026gt;AllocNonvirtual\u0026lt;true\u0026gt;(....); ......//region_space_分配失败的处理，这部分逻辑比较复杂，读者可先不关注它  while (true) { //拷贝：将from_ref的信息拷贝到to_ref  memcpy(to_ref, from_ref, obj_size); /*下面这段代码比较复杂，但功能很简单，设置from_ref的monitor_，就是把to_ref的地址 值设置到from_ref monitor_中。*/ LockWord old_lock_word = to_ref-\u0026gt;GetLockWord(false); ...... //构造新的LockWord对象  LockWord new_lock_word = LockWord::FromForwardingAddress( reinterpret_cast\u0026lt;size_t\u0026gt;(to_ref)); //原子操作，设置到from_ref里去。所以这段逻辑会比较复杂  bool success = from_ref-\u0026gt;CasLockWordWeakSequentiallyConsistent( old_lock_word, new_lock_word); if (LIKELY(success)) { ...... PushOntoMarkStack(to_ref);//保存to_ref  return to_ref; } ..... } } ConcurrentCopying::PushOntoMarkStack void ConcurrentCopying::PushOntoMarkStack(mirror::Object* to_ref) { Thread* self = Thread::Current(); MarkStackMode mark_stack_mode = mark_stack_mode_.LoadRelaxed(); //在FlipCallback中，mark_stack_mode_已经设置为kMarkStackModeThreadLocal了  if (LIKELY(mark_stack_mode == kMarkStackModeThreadLocal)) { if (LIKELY(self == thread_running_gc_)) { ...... //根据上文的介绍可知，PushOntoMarkStack可能由不同的Java线程调用。如果  //调用者是GC线程自己，则把to_ref加到ConcurrentCopying gc_mark_stack_中  gc_mark_stack_-\u0026gt;PushBack(to_ref); } else { /*如果是非GC线程调用PushOntoMarkStack，则需要使用线程对象tlsPtr_ thread_local_mark_stack。注意，如果线程对象还没有这个容器或者它已经存满的话，下 面的代码将从ConcurrentCopying pooled_mark_stacks_容器中取一个空闲的容器给线程。 pooled_mark_stacks_是一个数组，保存了256个ObjectStack对象，每一个ObjectStack只 能保存最多4096个Object指针。*/ accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;* tl_mark_stack = self-\u0026gt;GetThreadLocalMarkStack(); //tl_mark_stack不存在或者tl_mark_stack已满的情况  if (UNLIKELY(tl_mark_stack == nullptr || tl_mark_stack-\u0026gt;IsFull())) { MutexLock mu(self, mark_stack_lock_); accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;* new_tl_mark_stack; if (!pooled_mark_stacks_.empty()) { new_tl_mark_stack = pooled_mark_stacks_.back(); pooled_mark_stacks_.pop_back(); } else { //如果pooled_mark_stacks_被用完，则新建一个ObjectStack  new_tl_mark_stack = accounting::AtomicStack\u0026lt;mirror::Object\u0026gt;::Create( \u0026#34;thread local mark stack\u0026#34;, 4 * KB, 4 * KB); } new_tl_mark_stack-\u0026gt;PushBack(to_ref); self-\u0026gt;SetThreadLocalMarkStack(new_tl_mark_stack); if (tl_mark_stack != nullptr) { revoked_mark_stacks_.push_back(tl_mark_stack); } } else { tl_mark_stack-\u0026gt;PushBack(to_ref); } } } /*mark_stack_mode取值为非kMarkStackModeThreadLocal的处理，也是将对象 存储到ConcurrentCopying gc_mark_stack_中。*/ ...... } MarkingPhase void ConcurrentCopying::MarkingPhase() { /*MarkingPhase调用前，我们只对线程根对象进行了Mark（注意，此处使用Mark这个词一方 面代表它是ConcurrentCopying中的一个函数。另一方面，根据上文相关函数的代码分析可 知，ConcurrentCopying中的Mark除了做标记之外，还会根据需要生成拷贝对象）。*/ ...... { ...... /*扫描ImageSpace中的根对象。这里我们要多说几句。在MarkSweep中，对ImageSpace的扫描是 基于Write Barrier以及CardTable的。但Write Barrier这种技术却不能用于会移动对象的垃圾 回收算法。比如Copying collection。原因很简单，因为对象被移动后，它在card table中对 应card的位置也会发生变化。所以，对Copying Collection来说，Read Barrier就派上了用 场。Read Barrier有好几种比较经典的实现。ART中有三种，如TableLookup RB、Baker RB以 及Brooks RB。 笔者简单介绍下RB的大致作用：当mutator读取一个对象A的引用型成员变量a时，如果a所指向的对 象B携有forwarding address（B的拷贝对象B\u0026#39;），则转去读取B\u0026#39;。因为B有了拷贝对象B\u0026#39;，我们 自然希望凡是读取B的地方都改成读取B\u0026#39;。*/ for (space::ContinuousSpace* space : heap_-\u0026gt;GetContinuousSpaces()) { if (space-\u0026gt;IsImageSpace()) { gc::space::ImageSpace* image = space-\u0026gt;AsImageSpace(); if (image != nullptr) { mirror::ObjectArray\u0026lt;mirror::Object\u0026gt;* image_root = image-\u0026gt;GetImageHeader().GetImageRoots(); //ImageSpace中的根对象不会被拷贝，所以marked_image_root等于image_root，  //这段代码有些类似校验的作用  mirror::Object* marked_image_root = Mark(image_root); ......//一些校验相关的工作  } } } } {//访问其他类型的根对象  ...... Runtime::Current()-\u0026gt;VisitConcurrentRoots(this, kVisitRootFlagAllRoots); } {//访问其他类型的根对象  ...... Runtime::Current()-\u0026gt;VisitNonThreadRoots(this); } //访问immune_spaces_中的空间  for (auto\u0026amp; space : immune_spaces_.GetSpaces()) { accounting::ContinuousSpaceBitmap* live_bitmap = space-\u0026gt;GetLiveBitmap(); /*ConcurrentCopyingImmuneSpaceObjVisitor内部将在cc_heap_bitmap_中对扫描到 的对象进行标记，同时调用PushOntoMarkStack*/ ConcurrentCopyingImmuneSpaceObjVisitor visitor(this); live_bitmap-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space-\u0026gt;Limit()), visitor); } /*到此，所有根对象（包括immune_space_中的对象）都进行了标记。并且，根对象如果发生了 拷贝，则原始根对象将被替换为新的拷贝对象。接下来的工作就比较简单了，我们要遍历这些根 对象，将它们所引用的对象进行Mark（标记、拷贝）。同时，我们还要更新引用值。*/ Thread* self = Thread::Current(); {/*下面这段代码中包含三次ProcessMarkStack，这和ConcurrentCopying中的mark_stack_ mode_有关，它有四种取值。此次调用ProcessMarkStack时，mark_stack_mode_取值为 kMarkStackModeThreadLocal。*/ ProcessMarkStack(); //切换mark_stack_mode_为kMarkStackModeShared  SwitchToSharedMarkStackMode(); ProcessMarkStack(); //切换mark_stack_mode_为kMarkStackModeGcExclusive  SwitchToGcExclusiveMarkStackMode(); //对Java Reference对象的处理，各种回收器的处理都一样。我们后续统一介绍  ProcessReferences(self); ...... ProcessMarkStack(); ......; Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;CleanupClassLoaders(); DisableMarking(); ...... } ...... } //ProcessMarkStack内部将遍历通过PushOntoMarkStack保存下来的对象（这些对象都是拷贝后得到的对象，代码中用to_ref来表示）。其中最关键函数的是Scan。 inline void ConcurrentCopying::Scan(mirror::Object* to_ref) { //Scan很简单，就是遍历to_ref的引用型成员变量，内部调用ConcurrentCopying的Process函数进行处理。 */  ConcurrentCopyingRefFieldsVisitor visitor(this); to_ref-\u0026gt;VisitReferences\u0026lt;...\u0026gt;(visitor, visitor); } inline void ConcurrentCopying::Process(mirror::Object* obj, MemberOffset offset) { //obj是上面Scan中的to_ref，而offset是obj的某个引用型成员变量（由下面的ref表示）  mirror::Object* ref = obj-\u0026gt;GetFieldObject\u0026lt;....\u0026gt;(offset); //对ref进行Mark，得到ref的to_ref，如果两个一样，则不需要更新obj offset的内容  mirror::Object* to_ref = Mark(ref); if (to_ref == ref) { return; } /*到此，更新obj offset的内容，使得它指向to_ref。由于使用的是原子操作，所以下面的 代码逻辑中会使用循环。*/ mirror::Object* expected_ref = ref; mirror::Object* new_ref = to_ref; do { if (expected_ref != obj-\u0026gt;GetFieldObject\u0026lt;......\u0026gt;(offset)) { break; } } while (!obj-\u0026gt;CasFieldWeakRelaxedObjectWithoutWriteBarrier\u0026lt;...\u0026gt;( offset, expected_ref, new_ref)); } ReclaimPhase 图解 graph LR Clear(\u0026quot;region_space_-\u0026gt;ClearFromSpace()\u0026quot;) Sweep过程和MarkSweepl类似 void ConcurrentCopying::ReclaimPhase() { ...... { ..... ComputeUnevacFromSpaceLiveRatio();//详情见下文代码分析  } { ..... region_space_-\u0026gt;ClearFromSpace();//详情见下文代码分析  } { WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); ...... /*清空除immune_spaces_、region_space_外的空间中其他的垃圾对象。代码逻辑和 MarkSweep Sweep的类似。内部调用ContinuousMemMapAllocSpace的Sweep函数进 行处理。*/ Sweep(false); //调用GarbageCollector的SwapBitmaps函数，和MarkSweep的处理一样  SwapBitmaps(); heap_-\u0026gt;UnBindBitmaps(); ...... } void ConcurrentCopying::ComputeUnevacFromSpaceLiveRatio() { ...... //对RegionSpace中的标记对象进行统计  ConcurrentCopyingComputeUnevacFromSpaceLiveRatioVisitor visitor(this); region_space_bitmap_-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(region_space_-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(region_space_-\u0026gt;Limit()), visitor); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/gc3_markcompact/",
	"title": "GC3_MarkCompact",
	"tags": [],
	"description": "",
	"content": "mark_compact.h/cc virtual GcType GetGcType() const OVERRIDE { return kGcTypePartial;//MarkCompact不处理ImageSpace和ZygoteSpace } virtual CollectorType GetCollectorType() const OVERRIDE { return kCollectorTypeMC; } void MarkCompact::SetSpace(space::BumpPointerSpace* space) { space_ = space;//space_是MarkCompact成员变量 } RunPhases void MarkCompact::RunPhases() { Thread* self = Thread::Current(); /* InitializePhase非常简单，其中需要注意的是MarkCompact下面两个成员变量的设置： (1) mark_stack_ = heap_-\u0026gt;GetMarkStack(); (2) mark_bitmap_ = heap_-\u0026gt;GetMarkBitmap(); */ InitializePhase(); { ScopedPause pause(this);//MarkCompact是stop-the-world类型的回收器  ...... MarkingPhase();//①标记阶段，详情见下文分析  ReclaimPhase();//②回收阶段，详情见下文分析  } ...... FinishPhase();//收尾工作，非常简单，读者可自行阅读 } MarkingPhase void MarkCompact::MarkingPhase() { Thread* self = Thread::Current(); /*MarkCompact基于Mark-Compact回收原理，所以它也需要标记能搜索到的对象。不过，由于 BumpPointerSpace空间对象不包含位图对象，所以下面将为space_（指向一个 BumpPointerSpace空间）创建一个位图对象objects_before_forwarding。它用于记录 搜索到的对象。*/ objects_before_forwarding_.reset(accounting::ContinuousSpaceBitmap::Create( \u0026#34;objects before forwarding\u0026#34;, space_-\u0026gt;Begin(), space_-\u0026gt;Size())); //此外还创建了一个位图对象objects_with_lockword_，它和GC没有什么关系，只是用于  //保存一些信息。下文将见到objects_with_lockword_的作用  objects_with_lockword_.reset(accounting::ContinuousSpaceBitmap::Create( \u0026#34;objects with lock words\u0026#34;, space_-\u0026gt;Begin(), space_-\u0026gt;Size())); //将ImageSpace或ZygoteSpace加到MarkCompact immune_space_容器中  BindBitmaps(); /*ProcessCards和ClearCardTable用于处理CardTable中对应的card。此处请读者注意， 虽然MarkCompact也是通过移动对象来实现内存回收，但MarkCompact移动对象的过程是在 最后的回收阶段。此时，所有的非垃圾对象都已经标记。所以，MarkCompact中可以使用Write Barrier来记录跨空间的对象引用。作为对比，ConcurrentCopying在标记阶段可能就会移动 对象，这时就不方便使用Write Barrier了，而只能使用Read Barrier。 */ heap_-\u0026gt;ProcessCards(GetTimings(), false, false, true); heap_-\u0026gt;GetCardTable()-\u0026gt;ClearCardTable(); //下面几个函数我们都介绍过  if (kUseThreadLocalAllocationStack) { ...... heap_-\u0026gt;RevokeAllThreadLocalAllocationStacks(self); } ...... heap_-\u0026gt;SwapStacks(); { WriterMutexLock mu(self, *Locks::heap_bitmap_lock_); MarkRoots();//搜索并标记根对象，详情见下文  //借助CardTable来处理ImageSpace或ZygoteSpace中存在跨空间引用的对象，每找到  //这样一个对象就对其做标记并压入mark_stack_中。读者可先了解上面的MarkRoots函数  UpdateAndMarkModUnion(); MarkReachableObjects();//从根对象出发，扫描它们所引用的对象  } ......//Java Reference对象的处理等 } ReclaimPhase void MarkCompact::ReclaimPhase() { ...... WriterMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); /*Sweep将回收除space_、immune_spaces_外其他空间对象中的垃圾。内部代码逻辑非常简单， 就是调用ContinuousMemMapAllocSpace的Sweep函数进行回收。这些空间的垃圾回收使用 的是Mark-Sweep方法，不是Mark-Compact。*/ Sweep(false); //调用GarbageCollector SwapBitmaps函数，该函数在MarkSweep类中已经介绍过了  SwapBitmaps(); GetHeap()-\u0026gt;UnBindBitmaps();//该函数在MarkSweep中已经介绍过了  //压缩，这才是MarkCompact的精髓  Compact(); } Compact 图解 graph LR CalculateObjectForwardingAddresses--\u0026gt;UpdateReferences--\u0026gt;MoveObjectsToForwardingAddress void MarkCompact::Compact() { ..... /*Compact中有三个关键函数，此处先简单介绍它们的作用： 1: CalculateObjectForwardingAddresses：计算每个存活对象的forwarding address。 这个地址也就是这些对象的新的内存地址。 2: UpdateReferences：更新对象的引用关系，将所引用的对象修改为对应的forwarding address。这个函数没有什么特殊的知识，读者可自行阅读。 3: MoveObjects：将对象移动到它的forwarding address处。 */ CalculateObjectForwardingAddresses(); UpdateReferences(); MoveObjects(); ...... /*更新space_的末尾位置。经过上面压缩处理后，space_中的垃圾对象被清除，而非垃圾对象们 又被移动到了一起。这些非垃圾对象在space_中的末尾位置由bump_pointer_标示。 */ space_-\u0026gt;SetEnd(bump_pointer_); //清零[bump_Pointer_,bump_pointer_+bytes_freed)这段空间。这段空间就是垃圾对象所  //占据的内存大小  memset(bump_pointer_, 0, bytes_freed); } CalculateObjectForwardingAddresses //CalculateObjectForwardingAddress展示了MarkCompact中Compact的方法，就是将非垃圾对象一个一个排列起来。显然，要支持这种操作的话非BumpPointerSpace不可。 void MarkCompact::CalculateObjectForwardingAddresses() { ...... //bump_pointer_初值为space_的起始位置  bump_pointer_ = reinterpret_cast\u0026lt;uint8_t*\u0026gt;(space_-\u0026gt;Begin()); /*objects_before_forwarding_记录了space_中非垃圾对象的位图信息。下面的代码 将遍历space_中的非垃圾对象，然后调用函数对象进行处理。 CalculateObjectForwardingAddressVisitor内部调用MarkCompact ForwardObject 对每一个非垃圾对象进行处理。我们直接来看ForwardObject。*/ CalculateObjectForwardingAddressVisitor visitor(this); objects_before_forwarding_-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;End()), visitor); } void MarkCompact::ForwardObject(mirror::Object* obj) { //获取这个对象的所占内存的大小  const size_t alloc_size = RoundUp(obj-\u0026gt;SizeOf(), space::BumpPointerSpace::kAlignment); LockWord lock_word = obj-\u0026gt;GetLockWord(false); /*如果这个obj之前有设置LockWord（可能代表一个用于线程同步的Monitor），下面的if代码将 把LockWord旧值保存起来。等后续对象移动完毕后，我们需要恢复Obj的LockWord的旧值。 */ if (!LockWord::IsDefault(lock_word)) { //objects_with_lockword_记录哪个对象存在LockWord的旧值  objects_with_lockword_-\u0026gt;Set(obj); //lock_words_to_restore_是一个stddqueue（双端队列），用于保存obj的  //LockWord旧值  lock_words_to_restore_.push_back(lock_word); } //设置obj的forwarding address，为bump_pointer_  obj-\u0026gt;SetLockWord(LockWord::FromForwardingAddress(reinterpret_cast\u0026lt;size_t\u0026gt;(bump_pointer_)),false); //移动bump_poionter_，使得它指向下一个对象的forwarding address  bump_pointer_ += alloc_size; ++live_objects_in_space_; } UpdateReferences \u0026hellip;\u0026hellip;\nMoveObjects void MarkCompact::MoveObjects() { ...... /*遍历存活对象，MoveObjectVisitor内部调用MoveObject函数进行处理，下面将直接介绍 MoveObject的内容。*/ MoveObjectVisitor visitor(this);//内部调用MoveObject  objects_before_forwarding_-\u0026gt;VisitMarkedRange( reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;Begin()), reinterpret_cast\u0026lt;uintptr_t\u0026gt;(space_-\u0026gt;End()), visitor); ...... } void MarkCompact::MoveObject(mirror::Object* obj, size_t len) { //从LockWord中获取obj的目标地址  uintptr_t dest_addr = obj-\u0026gt;GetLockWord(false).ForwardingAddress(); mirror::Object* dest_obj = reinterpret_cast\u0026lt;mirror::Object*\u0026gt;(dest_addr); //使用memmove将obj移动到dest_addr处。  memmove(reinterpret_cast\u0026lt;void*\u0026gt;(dest_addr), reinterpret_cast\u0026lt;const void*\u0026gt;(obj), len); LockWord lock_word = LockWord::Default(); //如果obj之前有LockWord旧值，则需要从lock_words_to_restore_中拿到旧值  if (UNLIKELY(objects_with_lockword_-\u0026gt;Test(obj))) { lock_word = lock_words_to_restore_.front(); lock_words_to_restore_.pop_front(); } //设置dest_obj的LockWord。  dest_obj-\u0026gt;SetLockWord(lock_word, false); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/gc4_semi_space/",
	"title": "GC4_Semi_Space",
	"tags": [],
	"description": "",
	"content": "collector_type.h文件中关于枚举值kCollectorTypeSS有这样一句注释来介绍它：\u0026ldquo;Semi-space/mark-sweep hybrid，enables compaction.\u0026quot;。其含义是SemiSpace综合了Semi-space（即Copying Collector）和Mark-Sweep方法，同时还支持压缩。而kCollectorTypeGSS则是支持分代回收的SS方法。\n纵观SemiSpace，它的GC逻辑无非就是如下两点。\n 对GSS而言，from_space_中能搜索到的对象将被“提升”到promo_dest_space_空间中。对SS而言，from_space_中能搜索到的对象拷贝到to_space_中。GC之后，from_space_的空间被回收。 其他空间的处理和MarkSweep的类似，按照集合Live和集合Mark来找到和释放垃圾对象即可。SemiSpace在ART中的作用很重要，我们下文介绍应用程序退到后台后，虚拟机为减少内存碎片而做的内存压缩时就会用到它。  semi_space.cc\nRunPhases void SemiSpace::RunPhases() { Thread* self = Thread::Current(); InitializePhase();//①回收器初始化  //if为true，说明mutator线程已被暂停。这种情况的出现和SemiSpace的用法有关，  //我们暂且不用考虑这些  if (Locks::mutator_lock_-\u0026gt;IsExclusiveHeld(self)) { MarkingPhase();//②标记工作  ReclaimPhase();//回收工作，非常简单，留给读者自行研究  } else { //如果mutator未暂停，则SemiSpace只有标记阶段需要暂停mutator  { ScopedPause pause(this);//暂停mutator  MarkingPhase();//标记工作  } {//mutator恢复运行，可同时开展回收工作  ReaderMutexLock mu(self, *Locks::mutator_lock_); ReclaimPhase(); } } FinishPhase(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/gradledebug/",
	"title": "GradleDebug",
	"tags": [],
	"description": "",
	"content": "Gradle构建源码断点调试配置 (本方式也支持build.gradle中设置的断点调试)\n1 buildSrc配置 项目根目录下添加文件夹buildSrc,内部添加文件build.gradle:\nrepositories { mavenLocal() jcenter() google() } dependencies { //配置任意插件地址  implementation \u0026#39;com.android.tools.build:gradle:3.2.1\u0026#39; implementation \u0026#34;com.tencent.matrix:matrix-gradle-plugin:0.6.5.1\u0026#34; } 这样配置之后，在android studio的project视图下就能够在External Liberaries中看到Android Build Tool的源码，之后可以通过搜索需要调试的类和方法进行断点调试，目的是让IDE链接到gradle build tool 或各种自定义插件的源代码。(有时无法debug是因为该次build没有走断点处流程，先clean确保会走流程)\n2 gradlew command gradlew :app:compileDebugAidl -Dorg.gradle.daemon=false -Dorg.gradle.debug=true 也就是在需要debug的gradle语句后添加-Dorg.gradle.daemon=false -Dorg.gradle.debug=true。\n之后可以看到Terminal中执行被阻塞，并输出如下：\nTo honour the JVM settings for this build a new JVM will be forked. Please consider using the daemon: https://docs.gradle.org/4.6/userguide/gradle_daemon.html. \\\u0026gt; Starting Daemon 这里如果想每次执行命令，即使不设置后面的-Dorg.gradle.daemon=false -Dorg.gradle.debug=true信息，也默认执行断点调试，可以配置环境变量，方法如下:\n在系统环境变量里面添加：\nGRADLE_OPTS 值为:\n-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005\n3 配置remote debug Android Studio中按照如下步骤操作：\nMenu → Run → Edit Configurations\u0026hellip; → Add New Configuration → Remote → 自定义配置name → host: localhost → port: 5005 → OK(注意配置Use module classpatch：First search for sources of the debugged classes in the selected module classpath,也就是配置断点时源码查找路径)\n4 执行remote debug 然后点击右箭头执行remote debug，当然前提是先在源码中设置好断点\n断点停下时如果看不到变量信息，可以切换到如下Variables|Console查看详细变量值：\n如果还是有变量看不到值，需要确保将步骤1:中的buildSrc中的build.gradle配置好(配置的gradle版本要一致)，配置成功后，鼠标悬浮即可查看变量值\n调试gradle插件源码 基本方式和上述类似:\n1:添加buildSrc;\n2:在插件内部打断点(自定义plugin的apply方法内部);\n3:gradlew :app:assembleDebug -Dorg.gradle.daemon=false -Dorg.gradle.debug=true\n4:配置remote并debug\n参考 https://www.colabug.com/3241705.html\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/",
	"title": "gradlejenkins",
	"tags": [],
	"description": "",
	"content": "gradlejenkins 探索总结gradlejenkins知识\n AndroidPlugin     android打包    Android打包      GradleDebug     GradlePlugin     Gradle打包过程     Transform     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/gradleplugin/",
	"title": "GradlePlugin",
	"tags": [],
	"description": "",
	"content": "gradle plugin的两种方式  脚本插件模式：apply from: \u0026lsquo;xx.gradle\u0026rsquo; 标准插件模式：apply plugin: \u0026lsquo;xxx\u0026rsquo;  脚本插件模式转换为标准插件模式 直接在apply(Project project)回调时将之前的脚本插件代码copy过来即可，这里的上下文会缺少project，因此需要用project.with{}包裹原本的脚本代码\ngradle plugin执行流程 两种gradle plugin的都是相当于动态替换插件代码在apply的地地方，也就apply plugin时直接调用到apply(Project project)\n针对build.gradle从上到下执行的过程就是evaluate过程\n使用标准插件时拓展参数的执行流程\n 接入的gradle，apply plugin时，在插件内部回调方法apply(Project project)中进行拓展的定义：  mProject.extensions.create(\u0026#39;tinkerPatch\u0026#39;, TinkerPatchExtension) 接入的gradle文件，配置拓展参数信息 插件代码中before/afterEvaluate在闭包中获取用户配置信息  mProject.afterEvaluate { def configuration = mProject.tinkerPatch } /** * 由于一般方式配置拓展的方式，应用端配置的参数只能在afterEvaluate方法中获取配置的参数值，而此时已经无法在进行buildConfig配置tinkerEnable * 因此使用ext的拓展方式替代本拓展方式:*/ ext { tinkerPatchEnable = true appKey = \u0026#39;xxx\u0026#39; } apply plugin: \u0026#39;com.xh.xhcore.plugin\u0026#39; apply plugin方式插件编写流程  项目new android library module 只留下src/main和build.gradle，其他的文件全部删除 注册插件信息，在src/main/resources/META-INF/gradle-plugins/${pluginName}.properties moudule 进行 apply plugin: \u0026ldquo;${pluginName}\u0026rdquo;  插件内部包裹嵌套其他插件 root project的blueScript中配置的classPath的被嵌套的插件仅仅参与本项目的编译，并不会打包在发布的插件里，因此需要在插件build.gradle中添加implementation被嵌套的插件，来确保可以屏蔽被嵌套插件的依赖信息，使得接入方仅仅依赖我们自己的插件就行，无需知道我们内部依赖了哪些插件\n参考 https://docs.gradle.org/current/userguide/custom_plugins.html#header\nhttps://guides.gradle.org/testing-gradle-plugins/\nhttps://docs.gradle.org/4.10.3/userguide/test_kit.html\nhttps://docs.gradle.org/4.10.3/userguide/test_kit.html#sec:functional_testing_with_the_gradle_runner\nhttps://github.com/gradle-guides/testing-gradle-plugins/tree/master/samples/code/url-verifier-plugin\nAndroid 黑科技 ｜Gradle Plugin的一些使用场景\npackaging a plugin\nThere are several places where you can put the source for the plugin.\n Build script  You can include the source for the plugin directly in the build script. This has the benefit that the plugin is automatically compiled and included in the classpath of the build script without you having to do anything. However, the plugin is not visible outside the build script, and so you cannot reuse the plugin outside the build script it is defined in.\n buildSrc project  You can put the source for the plugin in the *rootProjectDir*/buildSrc/src/main/groovy directory (or *rootProjectDir*/buildSrc/src/main/java or *rootProjectDir*/buildSrc/src/main/kotlin depending on which language you prefer). Gradle will take care of compiling and testing the plugin and making it available on the classpath of the build script. The plugin is visible to every build script used by the build. However, it is not visible outside the build, and so you cannot reuse the plugin outside the build it is defined in.\nSee Organizing Gradle Projects for more details about the buildSrc project.\n Standalone project  You can create a separate project for your plugin. This project produces and publishes a JAR which you can then use in multiple builds and share with others. Generally, this JAR might include some plugins, or bundle several related task classes into a single library. Or some combination of the two.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/gradle%E6%89%93%E5%8C%85%E8%BF%87%E7%A8%8B/",
	"title": "Gradle打包过程",
	"tags": [],
	"description": "",
	"content": "gradle时序 graph LR init --\u0026gt;configure--\u0026gt;executeTasks executeTasks graph LR transform --\u0026gt; packageDebug(packageDebug: 将intermediates中的产物打包成apk) --\u0026gt; assembleDebug 自定义task http://blog.csdn.net/liuhongwei123888/article/details/50542104\nassets的注入 packageApplication之后assemble之前可以进行assets的注入\nremoveUnusedResourcesTask.dependsOn variant.packageApplication variant.assemble.dependsOn removeUnusedResourcesTask assets位于build下的如下目录:\nbuild\\intermediates\\merged_assets\\debug\\mergeDebugAssets\\out\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/graphics/",
	"title": "Graphics",
	"tags": [],
	"description": "",
	"content": "Graphics https://source.android.com/devices/graphics/index.html\nAndroid graphics components No matter what rendering API developers use, everything is rendered onto a \u0026ldquo;surface.\u0026rdquo; The surface represents the producer side of a buffer queue that is often consumed by SurfaceFlinger. Every window that is created on the Android platform is backed by a surface. All of the visible surfaces rendered are composited onto the display by SurfaceFlinger.\nThe following diagram shows how the key components work together:\nFigure 1. How surfaces are rendered\nThe main components are described below:\nImage Stream Producers An image stream producer can be anything that produces graphic buffers for consumption. Examples include OpenGL ES, Canvas 2D, and mediaserver video decoders.\nFigure 2. Graphic data flow through Android\nOpenGL ES OpenGL for Embedded Systems (OpenGL ES or GLES) is a subset[2] of the OpenGL computer graphics rendering application programming interface (API) for rendering 2D and 3D computer graphics such as those used by video games, typically hardware-accelerated using a graphics processing unit (GPU). It is designed for embedded systems like smartphones, tablet computers, video game consoles and PDAs. OpenGL ES is the \u0026ldquo;most widely deployed 3D graphics API in history\u0026rdquo;.[3]\nThe API is cross-language and multi-platform. The libraries GLUT and GLU are not available for OpenGL ES. OpenGL ES is managed by the non-profit technology consortium Khronos Group. Vulkan, a next-generation API from Khronos, is made for simpler high performance drivers for mobile and desktop devices.[4]\nVulkan Application developers use Vulkan to create apps that execute commands on the GPU with significantly reduced overhead. Vulkan also provides a more direct mapping to the capabilities found in current graphics hardware compared to EGL and GLES, minimizing opportunities for driver bugs and reducing developer testing time.\nLayers-Displays https://source.android.com/devices/graphics/layers-displays\nLayers A Layer is the most important unit of composition. A layer is a combination of a surface and an instance of SurfaceControl. Each layer has a set of properties that define how it interacts with other layers. Layer properties are described in the table below.\n   Property Description     Positional Defines where the layer appears on its display. Includes information such as the positions of a layer\u0026rsquo;s edges and its Z order relative to other layers (whether it should be in front of or behind other layers).   Content Defines how content displayed on the layer should be presented within the bounds defined by the positional properties. Includes information such as crop (to expand a portion of the content to fill the bounds of the layer) and transform (to show rotated or flipped content).   Composition Defines how the layer should be composited with other layers. Includes information such as blending mode and a layer-wide alpha value for alpha compositing.   Optimization Provides information not strictly necessary to correctly composite the layer, but that can be used by the Hardware Composer (HWC) device to optimize how it performs composition. Includes information such as the visible region of the layer and which portion of the layer has been updated since the previous frame.    Displays graph LR SurfaceFlinger--\u0026gt;internalDisplay SurfaceFlinger--\u0026gt;externalDisplays SurfaceFlinger--\u0026gt;virtualDisplays A display is another important unit of composition. A system can have multiple displays and displays can be added or removed during normal system operations. Displays are added/removed at the request of the HWC or at the request of the framework. The HWC device requests displays be added or removed when an external display is connected or disconnected from the device, which is called hotplugging. Clients request virtual displays, whose contents are rendered into an off-screen buffer instead of to a physical display.\nVirtual displays surfaceflinger supports an internal display (built into the phone or tablet), external displays (such as a television connected through hdmi), and one or more virtual displays that make composited output available within the system. virtual displays can be used to record the screen or send the screen over a network. frames generated for a virtual display are written to a bufferqueue.\nVirtual displays may share the same set of layers as the main display (the layer stack) or have their own set. There\u0026rsquo;s no VSYNC for a virtual display, so the VSYNC for the internal display triggers composition for all displays.\nOn HWC implementations that support them, virtual displays can be composited with OpenGL ES (GLES), HWC, or both GLES and HWC. On nonsupporting implementations, virtual displays are always composited using GLES.\nThe WindowManager can ask SurfaceFlinger to create a visible layer for which SurfaceFlinger acts as the BufferQueue consumer. It\u0026rsquo;s also possible to ask SurfaceFlinger to create a virtual display, for which SurfaceFlinger acts as the BufferQueue producer.\nVsync https://source.android.com/devices/graphics/implement-vsync\nThe VSYNC signal synchronizes the display pipeline. The display pipeline consists of app rendering, SurfaceFlinger composition, and the Hardware Composer (HWC) presenting images on the display. VSYNC synchronizes the time apps wake up to start rendering, the time SurfaceFlinger wakes up to composite the screen, and the display refresh cycle. This synchronization eliminates stutter and improves the visual performance of graphics.\nThe HWC generates VSYNC events and sends the events to SurfaceFlinger through the callback:\ntypedef void (*HWC2_PFN_VSYNC)(hwc2_callback_data_t callbackData, hwc2_display_t display, int64_t timestamp); SurfaceFlinger controls whether or not the HWC generates VSYNC events by calling to setVsyncEnabled. SurfaceFlinger enables setVsyncEnabled to generate VSYNC events so it can synchronize with the refresh cycle of the display. When SurfaceFlinger is synchronized to the display refresh cycle, SurfaceFlinger disables setVsyncEnabled to stop the HWC from generating VSYNC events. If SurfaceFlinger detects a difference between the actual VSYNC and the VSYNC it previously established SurfaceFlinger re-enables VSYNC event generation.\nVSYNC offset The sync app and SurfaceFlinger render loops to the hardware VSYNC. On a VSYNC event, the display begins showing frame N while SurfaceFlinger begins compositing windows for frame N+1. The app handles pending input and generates frame N+2.\nSynchronizing with VSYNC delivers consistent latency. It reduces errors in apps and SurfaceFlinger and minimizes displays drifting in and out of phase with each other. This, assumes app and SurfaceFlinger per-frame times don’t vary widely. The latency is at least two frames.\nTo remedy this, you can employ VSYNC offsets to reduce the input-to-display latency by making app and composition signal relative to hardware VSYNC. This is possible because app plus composition usually takes less than 33 ms.\nThe result of VSYNC offset is three signals with same period and offset phase:\n HW_VSYNC_0 — Display begins showing next frame. VSYNC — App reads input and generates next frame. SF_VSYNC — SurfaceFlinger begins compositing for next frame.  With VSYNC offset, SurfaceFlinger receives the buffer and composites the frame while the app simultaneously processes the input and renders the frame.\nNote: VSYNC offsets reduce the time available for app and composition, providing a greater chance for error.\nDispSync DispSync maintains a model of the periodic hardware-based VSYNC events of a display and uses that model to execute callbacks at specific phase offsets from the hardware VSYNC events.\nDispSync is a software phase-lock loop (PLL) that generates the VSYNC and SF_VSYNC signals used by Choreographer and SurfaceFlinger, even if not offset from hardware VSYNC.\nFigure 1. DispSync flow\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/handler/",
	"title": "handler",
	"tags": [],
	"description": "",
	"content": "handler 探索总结handler知识\n Epoll     Looper     ThreadLocal     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/di/hiltsource/",
	"title": "HiltSource",
	"tags": [],
	"description": "",
	"content": "Hilt Usage  Annotate the Application class with @HiltAndroidApp Annotate the Activity class with @AndroidEntryPoint Annotate the ViewModel class with @HiltViewModel and @Inject constructor Annotate the Repository class with @Singleton and @Inject constructor  ViewModel注入过程 以LoginActivity为例\n@HiltViewModel class LoginViewModel @Inject constructor( application: Application, private val savedStateHandle: SavedStateHandle, private val userRepository: UserRepository ) : LoginViewModel by viewModels() @MainThread inline fun \u0026lt;reified VM : ViewModel\u0026gt; ComponentActivity.viewModels( noinline factoryProducer: (() -\u0026gt; Factory)? = null ): Lazy\u0026lt;VM\u0026gt; { val factoryPromise = factoryProducer ?: { defaultViewModelProviderFactory//main  } return ViewModelLazy(VM::class, { viewModelStore }, factoryPromise) } class ViewModelLazy\u0026lt;VM : ViewModel\u0026gt; ( private val viewModelClass: KClass\u0026lt;VM\u0026gt;, private val storeProducer: () -\u0026gt; ViewModelStore, private val factoryProducer: () -\u0026gt; ViewModelProvider.Factory ) : Lazy\u0026lt;VM\u0026gt; { private var cached: VM? = null override val value: VM get() { val viewModel = cached return if (viewModel == null) { val factory = factoryProducer() val store = storeProducer() //main  ViewModelProvider(store, factory).get(viewModelClass.java).also { cached = it } } else { viewModel } } factoryProducer() Hilt_LoginActivity插入继承结构作为原本LoginActivity的父类 build/generated/source/kapt/debug/com/xh/demo/androidx/arch/login/Hilt_LoginActivity.java\npublic abstract class Hilt_LoginActivity\u0026lt;T extends ViewDataBinding\u0026gt; extends DataBindingActivity\u0026lt;T\u0026gt; implements GeneratedComponentManagerHolder { @Override public ViewModelProvider.Factory getDefaultViewModelProviderFactory() { return DefaultViewModelFactories.getActivityFactory(this); } } DefaultViewModelFactories.getActivityFactory public final class DefaultViewModelFactories { public static ViewModelProvider.Factory getActivityFactory(ComponentActivity activity) { return EntryPoints.get(activity, ActivityEntryPoint.class) .getHiltInternalFactoryFactory() .fromActivity(activity); } ViewModelProvider.Factory fromActivity(ComponentActivity activity) { return getHiltViewModelFactory(activity, activity.getIntent() != null ? activity.getIntent().getExtras() : null, defaultActivityFactory); } private ViewModelProvider.Factory getHiltViewModelFactory( SavedStateRegistryOwner owner, @Nullable Bundle defaultArgs, @Nullable ViewModelProvider.Factory extensionDelegate) { ViewModelProvider.Factory delegate = extensionDelegate == null ? new SavedStateViewModelFactory(application, owner, defaultArgs) : extensionDelegate; return new HiltViewModelFactory(//main  owner, defaultArgs, keySet, delegate, viewModelComponentBuilder); } } ViewModelProvider.get @NonNull @MainThread public \u0026lt;T extends ViewModel\u0026gt; T get(@NonNull String key, @NonNull Class\u0026lt;T\u0026gt; modelClass) { viewModel = mFactory.create(modelClass); } HiltViewModelFactory public HiltViewModelFactory( @NonNull SavedStateRegistryOwner owner, @Nullable Bundle defaultArgs, @NonNull Set\u0026lt;String\u0026gt; hiltViewModelKeys, @NonNull ViewModelProvider.Factory delegateFactory, @NonNull ViewModelComponentBuilder viewModelComponentBuilder) { this.hiltViewModelKeys = hiltViewModelKeys; this.delegateFactory = delegateFactory; this.hiltViewModelFactory = new AbstractSavedStateViewModelFactory(owner, defaultArgs) { @NonNull @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) protected \u0026lt;T extends ViewModel\u0026gt; T create( @NonNull String key, @NonNull Class\u0026lt;T\u0026gt; modelClass, @NonNull SavedStateHandle handle) {//main  ViewModelComponent component = viewModelComponentBuilder.savedStateHandle(handle).build(); Provider\u0026lt;? extends ViewModel\u0026gt; provider = EntryPoints.get(component, ViewModelFactoriesEntryPoint.class) .getHiltViewModelMap() .get(modelClass.getName()); if (provider == null) { throw new IllegalStateException( \u0026#34;Expected the @HiltViewModel-annotated class \u0026#39;\u0026#34; + modelClass.getName() + \u0026#34;\u0026#39; to be available in the multi-binding of \u0026#34; + \u0026#34;@HiltViewModelMap but none was found.\u0026#34;); } return (T) provider.get(); } }; } /** * View Model Provider Factory for the Hilt Extension. * * \u0026lt;p\u0026gt;A provider for this factory will be installed in the {@link * dagger.hilt.android.components.ActivityComponent} and {@link * dagger.hilt.android.components.FragmentComponent}. An instance of this factory will also be the * default factory by activities and fragments annotated with {@link * dagger.hilt.android.AndroidEntryPoint}. */ public final class HiltViewModelFactory implements ViewModelProvider.Factory { @NonNull @Override public \u0026lt;T extends ViewModel\u0026gt; T create(@NonNull Class\u0026lt;T\u0026gt; modelClass) { if (hiltViewModelKeys.contains(modelClass.getName())) { return hiltViewModelFactory.create(modelClass);//main  } else { return delegateFactory.create(modelClass); } } ViewModelCImpl 上述provider.get()实例为:ViewModelCImpl\nbuild/generated/source/kapt/debug/com/xh/demo/androidx/DaggerArchApplication_HiltComponents_SingletonC.java\nprivate final class ViewModelCImpl extends ArchApplication_HiltComponents.ViewModelC { private LoginViewModel loginViewModel() { return new LoginViewModel(ApplicationContextModule_ProvideApplicationFactory.provideApplication(DaggerArchApplication_HiltComponents_SingletonC.this.applicationContextModule), savedStateHandle, DaggerArchApplication_HiltComponents_SingletonC.this.userRepository()); } } DaggerArchApplication_HiltComponents_SingletonC build/generated/source/kapt/debug/com/xh/demo/androidx/DaggerArchApplication_HiltComponents_SingletonC.java\npublic final class DaggerArchApplication_HiltComponents_SingletonC extends ArchApplication_HiltComponents.SingletonC { private UserRepository userRepository() { Object local = userRepository; if (local instanceof MemoizedSentinel) { synchronized (local) { local = userRepository; if (local instanceof MemoizedSentinel) { local = new UserRepository(); userRepository = DoubleCheck.reentrantCheck(userRepository, local); } } } return (UserRepository) local; } Hilt_ArchApplication build/generated/source/kapt/debug/com/xh/demo/androidx/Hilt_ArchApplication.java\n/** * A generated base class to be extended by the @dagger.hilt.android.HiltAndroidApp annotated class. If using the Gradle plugin, this is swapped as the base class via bytecode transformation. */ public abstract class Hilt_ArchApplication extends Application implements GeneratedComponentManagerHolder { private final ApplicationComponentManager componentManager = new ApplicationComponentManager(new ComponentSupplier() { @Override public Object get() { return DaggerArchApplication_HiltComponents_SingletonC.builder() .applicationContextModule(new ApplicationContextModule(Hilt_ArchApplication.this)) .build(); } }); @Override public final ApplicationComponentManager componentManager() { return componentManager; } @Override public final Object generatedComponent() { return this.componentManager().generatedComponent(); } @CallSuper @Override public void onCreate() { // This is a known unsafe cast, but is safe in the only correct use case:  // ArchApplication extends Hilt_ArchApplication  ((ArchApplication_GeneratedInjector) generatedComponent()).injectArchApplication(UnsafeCasts.\u0026lt;ArchApplication\u0026gt;unsafeCast(this)); super.onCreate(); } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/hook/",
	"title": "Hook",
	"tags": [],
	"description": "",
	"content": "Hook机制之动态代理 动态代理 传统的静态代理模式需要为每一个需要代理的类写一个代理类，如果需要代理的类有几百个那不是要累死？为了更优雅地实现代理模式，JDK提供了动态代理方式，可以简单理解为JVM可以在运行时帮我们动态生成一系列的代理类，这样我们就不需要手写每一个静态的代理类了。依然以购物为例，用动态代理实现如下：\npublic static void main(String[] args) { Shopping women = new ShoppingImpl(); // 正常购物  System.out.println(Arrays.toString(women.doShopping(100))); // 招代理  women = (Shopping) Proxy.newProxyInstance(Shopping.class.getClassLoader(), women.getClass().getInterfaces(), new ShoppingHandler(women)); System.out.println(Arrays.toString(women.doShopping(100))); } 动态代理主要处理InvocationHandler和Proxy类；完整代码可以见github\n代理Hook 我们知道代理有比原始对象更强大的能力，比如飞到国外买东西，比如坑钱坑货；那么很自然，如果我们自己创建代理对象，然后把原始对象替换为我们的代理对象，那么就可以在这个代理对象为所欲为了；修改参数，替换返回值，我们称之为Hook。\n下面我们Hook掉startActivity这个方法，使得每次调用这个方法之前输出一条日志；（当然，这个输入日志有点点弱，只是为了展示原理；只要你想，你想可以替换参数，拦截这个startActivity过程，使得调用它导致启动某个别的Activity，指鹿为马！）\n首先我们得找到被Hook的对象，我称之为Hook点；什么样的对象比较好Hook呢？自然是容易找到的对象。什么样的对象容易找到？静态变量和单例；在一个进程之内，静态变量和单例变量是相对不容易发生变化的，因此非常容易定位，而普通的对象则要么无法标志，要么容易改变。我们根据这个原则找到所谓的Hook点。\n然后我们分析一下startActivity的调用链，找出合适的Hook点。我们知道对于Context.startActivity（Activity.startActivity的调用链与之不同），由于Context的实现实际上是ContextImpl;我们看ConetxtImpl类的startActivity方法：\n@Override public void startActivity(Intent intent, Bundle options) { warnIfCallingFromSystemProcess(); if ((intent.getFlags()\u0026amp;Intent.FLAG_ACTIVITY_NEW_TASK) == 0) { throw new AndroidRuntimeException( \u0026#34;Calling startActivity() from outside of an Activity \u0026#34; \\+ \u0026#34; context requires the FLAG_ACTIVITY_NEW_TASK flag.\u0026#34; \\+ \u0026#34; Is this really what you want?\u0026#34;); } mMainThread.getInstrumentation().execStartActivity( getOuterContext(), mMainThread.getApplicationThread(), null, (Activity)null, intent, -1, options); } 这里，实际上使用了ActivityThread类的mInstrumentation成员的execStartActivity方法；注意到，ActivityThread 实际上是主线程，而主线程一个进程只有一个，因此这里是一个良好的Hook点。\n接下来就是想要Hook掉我们的主线程对象，也就是把这个主线程对象里面的mInstrumentation给替换成我们修改过的代理对象；要替换主线程对象里面的字段，首先我们得拿到主线程对象的引用，如何获取呢？ActivityThread类里面有一个静态方法currentActivityThread可以帮助我们拿到这个对象类；但是ActivityThread是一个隐藏类，我们需要用反射去获取，代码如下：\n// 先获取到当前的ActivityThread对象 Class\u0026lt;?\u0026gt; activityThreadClass = Class.forName(\u0026#34;android.app.ActivityThread\u0026#34;); Method currentActivityThreadMethod = activityThreadClass.getDeclaredMethod(\u0026#34;currentActivityThread\u0026#34;); currentActivityThreadMethod.setAccessible(true); Object currentActivityThread = currentActivityThreadMethod.invoke(null); 拿到这个currentActivityThread之后，我们需要修改它的mInstrumentation这个字段为我们的代理对象，我们先实现这个代理对象，由于JDK动态代理只支持接口，而这个Instrumentation是一个类，没办法，我们只有手动写静态代理类，覆盖掉原始的方法即可。（cglib可以做到基于类的动态代理，这里先不介绍）\npublic static void attachContext() throws Exception{ // 先获取到当前的ActivityThread对象  Class\u0026lt;?\u0026gt; activityThreadClass = Class.forName(\u0026#34;android.app.ActivityThread\u0026#34;); Method currentActivityThreadMethod = activityThreadClass.getDeclaredMethod(\u0026#34;currentActivityThread\u0026#34;); currentActivityThreadMethod.setAccessible(true); Object currentActivityThread = currentActivityThreadMethod.invoke(null); // 拿到原始的 mInstrumentation字段  Field mInstrumentationField = activityThreadClass.getDeclaredField(\u0026#34;mInstrumentation\u0026#34;); mInstrumentationField.setAccessible(true); Instrumentation mInstrumentation = (Instrumentation) mInstrumentationField.get(currentActivityThread); // 创建代理对象  Instrumentation evilInstrumentation = new EvilInstrumentation(mInstrumentation); // 偷梁换柱  mInstrumentationField.set(currentActivityThread, evilInstrumentation); } 步骤 这就是使用代理进行Hook的原理——偷梁换柱。整个Hook过程简要总结如下：\n  寻找Hook点，原则是静态变量或者单例对象，尽量Hook pulic的对象和方法，非public不保证每个版本都一样，需要适配。\n  选择合适的代理方式，如果是接口可以用动态代理；如果是类可以手动写代理也可以使用cglib。\n  偷梁换柱——用代理对象替换原始对象\n  Hook机制之Binder Hook 因此，通过分析我们得知，系统Service的使用其实就分为两步：\nIBinder b = ServiceManager.getService(\u0026#34;service_name\u0026#34;); // 获取原始的IBinder对象 IXXInterface in = IXXInterface.Stub.asInterface(b); // 转换为Service接口 寻找Hook点 在插件框架原理解析——Hook机制之动态代理里面我们说过，Hook分为三步，最关键的一步就是寻找Hook点。我们现在已经搞清楚了系统服务的使用过程，那么就需要找出在这个过程中，在哪个环节是最合适hook的。\n由于系统服务的使用者都是对第二步获取到的IXXInterface进行操作，因此如果我们要hook掉某个系统服务，只需要把第二步的asInterface方法返回的对象修改为为我们Hook过的对象就可以了。\nasInterface过程 接下来我们分析asInterface方法，然后想办法把这个方法的返回值修改为我们Hook过的系统服务对象。这里我们以系统剪切版服务为例，源码位置为android.content.IClipboard,IClipboard.Stub.asInterface方法代码如下：\npublic static android.content.IClipboard asInterface(android.os.IBinder obj) { if ((obj == null)) { return null; } android.os.IInterface iin = obj.queryLocalInterface(DESCRIPTOR); // Hook点  if (((iin != null) \u0026amp;\u0026amp; (iin instanceof android.content.IClipboard))) { return ((android.content.IClipboard) iin); } return new android.content.IClipboard.Stub.Proxy(obj); } 这个方法的意思就是：先查看本进程是否存在这个Binder对象，如果有那么直接就是本进程调用了；如果不存在那么创建一个代理对象，让代理对象委托驱动完成跨进程调用。\n观察这个方法，前面的那个if语句判空返回肯定动不了手脚；最后一句调用构造函数然后直接返回我们也是无从下手，要修改asInterface方法的返回值，我们唯一能做的就是从这一句下手：\nandroid.os.IInterface iin = obj.queryLocalInterface(DESCRIPTOR); // Hook点\n我们可以尝试修改这个obj对象的queryLocalInterface方法的返回值，并保证这个返回值符合接下来的if条件检测，那么就达到了修改asInterface方法返回值的目的。\n而这个obj对象刚好是我们第一步返回的IBinder对象，接下来我们尝试对这个IBinder对象的queryLocalInterface方法进行hook。\ngetService过程 上文分析得知，我们想要修改IBinder对象的queryLocalInterface方法；获取IBinder对象的过程如下：\nIBinder b = ServiceManager.getService(\u0026ldquo;service_name\u0026rdquo;);\n因此，我们希望能修改这个getService方法的返回值，让这个方法返回一个我们伪造过的IBinder对象；这样，我们可以在自己伪造的IBinder对象的queryLocalInterface方法作处理，进而使得asInterface方法返回在queryLocalInterface方法里面处理过的值，最终实现hook系统服务的目的。\n在跟踪这个getService方法之前我们思考一下，由于系统服务是一系列的远程Service，它们的本体，也就是Binder本地对象一般都存在于某个单独的进程，在这个进程之外的其他进程存在的都是这些Binder本地对象的代理。因此在我们的进程里面，存在的也只是这个Binder代理对象，我们也只能对这些Binder代理对象下手。(如果这一段看不懂，建议不要往下看了，先看Binder学习指南)\n然后，这个getService是一个静态方法，如果此方法什么都不做，拿到Binder代理对象之后直接返回；那么我们就无能为力了：我们没有办法拦截一个静态方法，也没有办法获取到这个静态方法里面的局部变量(即我们希望修改的那个Binder代理对象)。\n接下来就可以看这个getService的代码了：\npublic static IBinder getService(String name) { try { IBinder service = sCache.get(name); if (service != null) { return service; } else { return getIServiceManager().getService(name); } } catch (RemoteException e) { Log.e(TAG, \u0026#34;error in getService\u0026#34;, e); } return null; } 天无绝人之路！ServiceManager为了避免每次都进行跨进程通信，把这些Binder代理对象缓存在一张map里面。\n我们可以替换这个map里面的内容为Hook过的IBinder对象，由于系统在getService的时候每次都会优先查找缓存，因此返回给使用者的都是被我们修改过的对象，从而达到瞒天过海的目的。\n步骤 总结一下，要达到修改系统服务的目的，我们需要如下两步：\n1: 首先肯定需要伪造一个系统服务对象，接下来就要想办法让asInterface能够返回我们的这个伪造对象而不是原始的系统服务对象。\n2: 通过上文分析我们知道，只要让getService返回IBinder对象的queryLocalInterface方法直接返回我们伪造过的系统服务对象就能达到目的。所以，我们需要伪造一个IBinder对象，主要是修改它的queryLocalInterface方法，让它返回我们伪造的系统服务对象；然后把这个伪造对象放置在ServiceManager的缓存map里面即可。\n通过Binder机制的优先查找本地Binder对象的这个特性达到了Hook掉系统服务对象的目的。因此queryLocalInterface也失去了它原本的意义(只查找本地Binder对象，没有本地对象返回null)，这个方法只是一个傀儡，是我们实现hook系统对象的桥梁：我们通过这个“漏洞”让asInterface永远都返回我们伪造过的对象。由于我们接管了asInterface这个方法的全部，我们伪造过的这个系统服务对象不能是只拥有本地Binder对象(原始queryLocalInterface方法返回的对象)的能力，还要有Binder代理对象操纵驱动的能力。\n接下来我们就以Hook系统的剪切版服务为例，用实际代码来说明，如何Hook掉系统服务。\nHook系统剪切版服务 伪造剪切版服务对象 final String CLIPBOARD_SERVICE = \u0026#34;clipboard\u0026#34;; // 下面这一段的意思实际就是: ServiceManager.getService(\u0026#34;clipboard\u0026#34;); // 只不过 ServiceManager这个类是@hide的  Class\u0026lt;?\u0026gt; serviceManager = Class.forName(\u0026#34;android.os.ServiceManager\u0026#34;); Method getService = serviceManager.getDeclaredMethod(\u0026#34;getService\u0026#34;, String.class); // ServiceManager里面管理的原始的Clipboard Binder对象 // 一般来说这是一个Binder代理对象  IBinder rawBinder = (IBinder) getService.invoke(null, CLIPBOARD_SERVICE); // Hook 掉这个Binder代理对象的 queryLocalInterface 方法 // 然后在 queryLocalInterface 返回一个IInterface对象, hook掉我们感兴趣的方法即可.  IBinder hookedBinder = (IBinder) Proxy.newProxyInstance(serviceManager.getClassLoader(), new Class\u0026lt;?\u0026gt;[] { IBinder.class }, new BinderProxyHookHandler(rawBinder)); // 把这个hook过的Binder代理对象放进ServiceManager的cache里面 // 以后查询的时候 会优先查询缓存里面的Binder, 这样就会使用被我们修改过的Binder了 Field cacheField = serviceManager.getDeclaredField(\u0026#34;sCache\u0026#34;); cacheField.setAccessible(true); Map\u0026lt;String, IBinder\u0026gt; cache = (Map) cacheField.get(null); cache.put(CLIPBOARD_SERVICE, hookedBinder); Hook机制之AMS\u0026amp;PMS 参考 http://weishu.me/2016/01/28/understand-plugin-framework-proxy-hook/\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/input/",
	"title": "input",
	"tags": [],
	"description": "",
	"content": "input 探索总结input知识\n touchEventNative     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%80%9D%E6%83%B3/ioc/",
	"title": "IOC",
	"tags": [],
	"description": "",
	"content": "graph TB 依赖者--\u0026gt;|依赖|被依赖者 变为\ngraph TB 被依赖者--\u0026gt;|提前注入接口实现|接口注入管理模块 依赖者--\u0026gt;|使用已经注入好了的接口实现|接口注入管理模块 参考 控制反转（IoC）与依赖注入（DI）\n对象A获得依赖对象B的过程,由主动行为变为了被动行为，控制权颠倒过来了，这就是“控制反转”这个名称的由来。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/java/",
	"title": "java",
	"tags": [],
	"description": "",
	"content": "java 探索总结java知识\n BlockingQueue     java并发     ThreadPoolExecutor     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/jni/java_jni%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E5%8E%9F%E7%90%86/",
	"title": "java_jni方法调用原理",
	"tags": [],
	"description": "",
	"content": "Method Execute Flow graph TB PerformCall(PerformCall)--\u0026gt;|Interpreter|ArtInterpreterToInterpreterBridge(interpreter::ArtInterpreterToInterpreterBridge) ArtInterpreterToInterpreterBridge--\u0026gt;ExecuteSwitchImplCpp(interpreter::ExecuteSwitchImplCpp) ExecuteSwitchImplCpp--\u0026gt;DoInvoke(case Instruction::xxx: interpreter::DoInvoke, find called ArtMethod) DoInvoke--\u0026gt;DoCallCommon(interpreter::DoCallCommon, prepare shadow frame) DoCallCommon--\u0026gt;PerformCall ArtMethod::Invoke--\u0026gt;art_quick_invoke_stub(art_quick_invoke_stub: function in quick_entry_point.S) artQuickToInterpreterBridge(artQuickToInterpreterBridge, prepare shadow frame)--\u0026gt;EnterInterpreterFromEntryPoint(interpreter::EnterInterpreterFromEntryPoint) EnterInterpreterFromEntryPoint--\u0026gt;ExecuteSwitchImplCpp PerformCall--\u0026gt;|CompiledCode|ArtInterpreterToCompiledCodeBridge(interpreter::ArtInterpreterToCompiledCodeBridge) ArtInterpreterToCompiledCodeBridge--\u0026gt;ArtMethod::Invoke compiledCode--\u0026gt;|Interpreter|artQuickToInterpreterBridge art_quick_invoke_stub--\u0026gt;|ART_METHOD_QUICK_CODE_OFFSET_32|IsJniMethod{Is JNI method?} IsJniMethod--\u0026gt;|no|entry_point_from_quick_compiled_code_(entry_point_from_quick_compiled_code_ linkCode时设置) IsJniMethod--\u0026gt;|yes|art_quick_generic_jni_trampoline_汇编 art_quick_generic_jni_trampoline_汇编--\u0026gt;artQuickGenericJniTrampoline artQuickGenericJniTrampoline--\u0026gt;data_(data_RegisterNative时设置) data_--\u0026gt;IsJniDlsymLookupStub{IsJniDlsymLookupStub?} IsJniDlsymLookupStub--\u0026gt;|no|nativeCode IsJniDlsymLookupStub--\u0026gt;|yes|artFindNativeMethod entry_point_from_quick_compiled_code_--\u0026gt;IsCompiled{Is Compiled?} IsCompiled--\u0026gt;|yes|compiledCode IsCompiled--\u0026gt;|no|art_quick_to_interpreter_bridge汇编 art_quick_to_interpreter_bridge汇编--\u0026gt;artQuickToInterpreterBridge Trampoline code 所有Trampoline code都是一段汇编代码编写的函数，这段汇编代码函数内部一般会跳转到一个由更高级的编程语言（C++）实现的函数。\nclass Thread{ ...... struct PACKED(sizeof(void*)) tls_ptr_sized_values { ...... //针对jni方法的Trampoline code，只包含一个pDlsymLookup函数指针,对应的Trampoline code在jni_entrypoints_x86.S里实现。  //结构体，和JNI调用有关。里边只有一个函数指针成员变量，名为pDlsymLookup。当JNI函数未注册时，这个成员变量将被调用以找到目标JNI函数  JniEntryPoints jni_entrypoints; //针对非jni方法的Trampoline code，一共包含132个函数指针,对应的Trampoline code在quick_entrypoints_x86.S里实现。  //结构体，其成员变量全是个函数指针类型，其定义可参考quick_entrypoints_list.h。它包含了一些由ART虚拟机提供的某些功能，而我们编译得到的机器码可能会用到它们。生成机器码时，我们需要生成对应的调用指令以跳转到这些函数  QuickEntryPoints quick_entrypoints; ...... } tlsPtr_; } art/runtime/interpreter/interpreter.cc\nArtInterpreterToInterpreterBridge void ArtInterpreterToInterpreterBridge(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame* shadow_frame, JValue* result) { self-\u0026gt;PushShadowFrame(shadow_frame); ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); if (LIKELY(!shadow_frame-\u0026gt;GetMethod()-\u0026gt;IsNative())) { result-\u0026gt;SetJ(Execute(self, accessor, *shadow_frame, JValue()).GetJ());//main  } else { // We don\u0026#39;t expect to be asked to interpret native code (which is entered via a JNI compiler  // generated stub) except during testing and image writing.  CHECK(!Runtime::Current()-\u0026gt;IsStarted()); ObjPtr\u0026lt;mirror::Object\u0026gt; receiver = is_static ? nullptr : shadow_frame-\u0026gt;GetVRegReference(0); uint32_t* args = shadow_frame-\u0026gt;GetVRegArgs(is_static ? 0 : 1); UnstartedRuntime::Jni(self, shadow_frame-\u0026gt;GetMethod(), receiver.Ptr(), args, result); } self-\u0026gt;PopShadowFrame(); Execute static inline JValue Execute( Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame\u0026amp; shadow_frame, JValue result_register, bool stay_in_interpreter = false) REQUIRES_SHARED(Locks::mutator_lock_) { if (LIKELY(shadow_frame.GetDexPC() == 0)) { // Entering the method, but not via deoptimization.  if (!stay_in_interpreter) { jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;MethodEntered(self, shadow_frame.GetMethod()); if (jit-\u0026gt;CanInvokeCompiledCode(method)) { JValue result; // Pop the shadow frame before calling into compiled code.  self-\u0026gt;PopShadowFrame(); //Calculate the offset of the first input reg. The input registers are in the high regs.  //It\u0026#39;s ok to access the code item here since JIT code will have been touched by the  // interpreter and compiler already.  uint16_t arg_offset = accessor.RegistersSize() - accessor.InsSize(); ArtInterpreterToCompiledCodeBridge(self, nullptr, \u0026amp;shadow_frame, arg_offset, \u0026amp;result); // Push the shadow frame back as the caller will expect it.  self-\u0026gt;PushShadowFrame(\u0026amp;shadow_frame); return result; } } } } ArtMethod* method = shadow_frame.GetMethod();//method为当前帧的方法  return ExecuteSwitchImpl\u0026lt;false, false\u0026gt;(self, accessor, shadow_frame, result_register, false); art/runtime/interpreter/interpreter_switch_impl.h/cc\nExecuteSwitchImpl // Wrapper around the switch interpreter which ensures we can unwind through it. template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; ALWAYS_INLINE JValue ExecuteSwitchImpl(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame\u0026amp; shadow_frame, JValue result_register, bool interpret_one_instruction) REQUIRES_SHARED(Locks::mutator_lock_) { SwitchImplContext ctx { .self = self, .accessor = accessor, .shadow_frame = shadow_frame, .result_register = result_register, .interpret_one_instruction = interpret_one_instruction, .result = JValue(), }; void* impl = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;ExecuteSwitchImplCpp\u0026lt;do_access_check, transaction_active\u0026gt;);//main  const uint16_t* dex_pc = ctx.accessor.Insns(); ExecuteSwitchImplAsm(\u0026amp;ctx, impl, dex_pc); return ctx.result; } template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; void ExecuteSwitchImplCpp(SwitchImplContext* ctx) { Thread* self = ctx-\u0026gt;self; const CodeItemDataAccessor\u0026amp; accessor = ctx-\u0026gt;accessor; ShadowFrame\u0026amp; shadow_frame = ctx-\u0026gt;shadow_frame; JValue result_register = ctx-\u0026gt;result_register; bool interpret_one_instruction = ctx-\u0026gt;interpret_one_instruction; constexpr bool do_assignability_check = do_access_check; self-\u0026gt;VerifyStack(); uint32_t dex_pc = shadow_frame.GetDexPC(); const auto* const instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); const uint16_t* const insns = accessor.Insns(); const Instruction* inst = Instruction::At(insns + dex_pc); uint16_t inst_data; jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); do { dex_pc = inst-\u0026gt;GetDexPc(insns); shadow_frame.SetDexPC(dex_pc); TraceExecution(shadow_frame, inst, dex_pc); inst_data = inst-\u0026gt;Fetch16(0); switch (inst-\u0026gt;Opcode(inst_data)) { case Instruction::INVOKE_DIRECT: { PREAMBLE(); bool success = DoInvoke\u0026lt;kDirect, false, do_access_check\u0026gt;( self, shadow_frame, inst, inst_data, \u0026amp;result_register); POSSIBLY_HANDLE_PENDING_EXCEPTION(!success, Next_3xx); break; } case Instruction::INVOKE_STATIC: { PREAMBLE(); bool success = DoInvoke\u0026lt;kStatic, false, do_access_check\u0026gt;( self, shadow_frame, inst, inst_data, \u0026amp;result_register); POSSIBLY_HANDLE_PENDING_EXCEPTION(!success, Next_3xx); break; } } } while (!interpret_one_instruction); // Record where we stopped.  shadow_frame.SetDexPC(inst-\u0026gt;GetDexPc(insns)); ctx-\u0026gt;result = result_register; return; art/runtime/interpreter/interpreter_common.h\nDoInvoke // Handles all invoke-XXX/range instructions except for invoke-polymorphic[/range]. // Returns true on success, otherwise throws an exception and returns false. template\u0026lt;InvokeType type, bool is_range, bool do_access_check\u0026gt; static inline bool DoInvoke(Thread* self, ShadowFrame\u0026amp; shadow_frame, const Instruction* inst, uint16_t inst_data, JValue* result) { // Make sure to check for async exceptions before anything else.  if (UNLIKELY(self-\u0026gt;ObserveAsyncException())) { return false; } const uint32_t method_idx = (is_range) ? inst-\u0026gt;VRegB_3rc() : inst-\u0026gt;VRegB_35c(); const uint32_t vregC = (is_range) ? inst-\u0026gt;VRegC_3rc() : inst-\u0026gt;VRegC_35c(); ObjPtr\u0026lt;mirror::Object\u0026gt; receiver = (type == kStatic) ? nullptr : shadow_frame.GetVRegReference(vregC); ArtMethod* sf_method = shadow_frame.GetMethod();//发起调用的方法  ArtMethod* const called_method = FindMethodFromCode\u0026lt;type, do_access_check\u0026gt;( method_idx, \u0026amp;receiver, sf_method, self);//被调用方法  // The shadow frame should already be pushed, so we don\u0026#39;t need to update it.  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr \u0026amp;\u0026amp; (type == kVirtual || type == kInterface)) { jit-\u0026gt;InvokeVirtualOrInterface(receiver, sf_method, shadow_frame.GetDexPC(), called_method); } // TODO: Remove the InvokeVirtualOrInterface instrumentation, as it was only used by the JIT.  if (type == kVirtual || type == kInterface) { instrumentation::Instrumentation* instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); if (UNLIKELY(instrumentation-\u0026gt;HasInvokeVirtualOrInterfaceListeners())) { instrumentation-\u0026gt;InvokeVirtualOrInterface( self, receiver.Ptr(), sf_method, shadow_frame.GetDexPC(), called_method); } } return DoCall\u0026lt;is_range, do_access_check\u0026gt;(called_method, self, shadow_frame, inst, inst_data, result); art/runtime/interpreter/interpreter_common.cc\nDoCall template\u0026lt;bool is_range, bool do_assignability_check\u0026gt; bool DoCall(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame, const Instruction* inst, uint16_t inst_data, JValue* result) { // Argument word count.  const uint16_t number_of_inputs = (is_range) ? inst-\u0026gt;VRegA_3rc(inst_data) : inst-\u0026gt;VRegA_35c(inst_data); // TODO: find a cleaner way to separate non-range and range information without duplicating  // code.  uint32_t arg[Instruction::kMaxVarArgRegs] = {}; // only used in invoke-XXX.  uint32_t vregC = 0; if (is_range) { vregC = inst-\u0026gt;VRegC_3rc(); } else { vregC = inst-\u0026gt;VRegC_35c(); inst-\u0026gt;GetVarArgs(arg, inst_data); } return DoCallCommon\u0026lt;is_range, do_assignability_check\u0026gt;( called_method, self, shadow_frame, result, number_of_inputs, arg, vregC); } art/runtime/interpreter/interpreter_common.cc\nDoCallCommon template \u0026lt;bool is_range, bool do_assignability_check\u0026gt; static inline bool DoCallCommon(ArtMethod* called_method, Thread* self, ShadowFrame\u0026amp; shadow_frame, JValue* result, uint16_t number_of_inputs, uint32_t (\u0026amp;arg)[Instruction::kMaxVarArgRegs], uint32_t vregC) { // Compute method information.  CodeItemDataAccessor accessor(called_method-\u0026gt;DexInstructionData()); // Number of registers for the callee\u0026#39;s call frame.  uint16_t num_regs; // Test whether to use the interpreter or compiler entrypoint, and save that result to pass to  // PerformCall. A deoptimization could occur at any time, and we shouldn\u0026#39;t change which  // entrypoint to use once we start building the shadow frame.  // For unstarted runtimes, always use the interpreter entrypoint. This fixes the case where we are  // doing cross compilation. Note that GetEntryPointFromQuickCompiledCode doesn\u0026#39;t use the image  // pointer size here and this may case an overflow if it is called from the compiler. b/62402160  const bool use_interpreter_entrypoint = !Runtime::Current()-\u0026gt;IsStarted() || ClassLinker::ShouldUseInterpreterEntrypoint( called_method, called_method-\u0026gt;GetEntryPointFromQuickCompiledCode()); ...... // Allocate shadow frame on the stack.  //called_method是被调用的方法  const char* old_cause = self-\u0026gt;StartAssertNoThreadSuspension(\u0026#34;DoCallCommon\u0026#34;); ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, \u0026amp;shadow_frame, called_method, /* dex pc */ 0); ShadowFrame* new_shadow_frame = shadow_frame_unique_ptr.get(); ...... PerformCall(self, accessor, shadow_frame.GetMethod(), first_dest_reg, new_shadow_frame, result, use_interpreter_entrypoint); art/runtime/common_dex_operations.h\nPerformCall inline void PerformCall(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ArtMethod* caller_method, const size_t first_dest_reg, ShadowFrame* callee_frame, JValue* result, bool use_interpreter_entrypoint) REQUIRES_SHARED(Locks::mutator_lock_) { if (LIKELY(Runtime::Current()-\u0026gt;IsStarted())) { if (use_interpreter_entrypoint) { interpreter::ArtInterpreterToInterpreterBridge(self, accessor, callee_frame, result); } else { interpreter::ArtInterpreterToCompiledCodeBridge( self, caller_method, callee_frame, first_dest_reg, result); } } else { interpreter::UnstartedRuntime::Invoke(self, accessor, callee_frame, result, first_dest_reg); } } ArtInterpreterToCompiledCodeBridge void ArtInterpreterToCompiledCodeBridge(Thread* self, ArtMethod* caller, ShadowFrame* shadow_frame, uint16_t arg_offset, JValue* result) REQUIRES_SHARED(Locks::mutator_lock_) { ArtMethod* method = shadow_frame-\u0026gt;GetMethod(); ...... jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr \u0026amp;\u0026amp; caller != nullptr) { jit-\u0026gt;NotifyInterpreterToCompiledCodeTransition(self, caller); } method-\u0026gt;Invoke(self, shadow_frame-\u0026gt;GetVRegArgs(arg_offset), (shadow_frame-\u0026gt;NumberOfVRegs() - arg_offset) * sizeof(uint32_t), result, method-\u0026gt;GetInterfaceMethodIfProxy(kRuntimePointerSize)-\u0026gt;GetShorty()); art/runtime/art_method.cc\nArtMethod::Invoke void ArtMethod::Invoke(Thread* self, uint32_t* args, uint32_t args_size, JValue* result, const char* shorty) { if (!IsStatic()) { (*art_quick_invoke_stub)(this, args, args_size, self, result, shorty); } else { (*art_quick_invoke_static_stub)(this, args, args_size, self, result, shorty);//in art/runtime/arch/x86/quick_entrypoints_x86.S  } art_quick_invoke_stub namespace art { extern \u0026#34;C\u0026#34; void art_quick_invoke_stub(ArtMethod*, uint32_t*, uint32_t, Thread*, JValue*, const char*); extern \u0026#34;C\u0026#34; void art_quick_invoke_static_stub(ArtMethod*, uint32_t*, uint32_t, Thread*, JValue*, const char*);  art/runtime/arch/x86/quick_entrypoints_x86.S\nDEFINE_FUNCTION art_quick_invoke_stub mov 20(%ebp), %eax // move method pointer into eax  call *ART_METHOD_QUICK_CODE_OFFSET_32(%eax) // call the method. java method转到art_quick_to_interpreter_bridge，jni method转到art_quick_generic_jni_trampoline art_quick_to_interpreter_bridge DEFINE_FUNCTION art_quick_to_interpreter_bridge PUSH eax // pass method  call SYMBOL(artQuickToInterpreterBridge) // (method, Thread*, SP) art/runtime/entrypoints/quick/quick_trampoline_entrypoints.cc\nartQuickToInterpreterBridge extern \u0026#34;C\u0026#34; uint64_t artQuickToInterpreterBridge(ArtMethod* method, Thread* self, ArtMethod** sp) REQUIRES_SHARED(Locks::mutator_lock_) { ...... JValue result; if (UNLIKELY(deopt_frame != nullptr)) { HandleDeoptimization(\u0026amp;result, method, deopt_frame, \u0026amp;fragment); } else { const char* old_cause = self-\u0026gt;StartAssertNoThreadSuspension( \u0026#34;Building interpreter shadow frame\u0026#34;); uint16_t num_regs = accessor.RegistersSize(); // No last shadow coming from quick.  ShadowFrameAllocaUniquePtr shadow_frame_unique_ptr = CREATE_SHADOW_FRAME(num_regs, /* link */ nullptr, method, /* dex pc */ 0); ShadowFrame* shadow_frame = shadow_frame_unique_ptr.get(); size_t first_arg_reg = accessor.RegistersSize() - accessor.InsSize(); BuildQuickShadowFrameVisitor shadow_frame_builder(sp, method-\u0026gt;IsStatic(), shorty, shorty_len, shadow_frame, first_arg_reg); shadow_frame_builder.VisitArguments(); const bool needs_initialization = method-\u0026gt;IsStatic() \u0026amp;\u0026amp; !method-\u0026gt;GetDeclaringClass()-\u0026gt;IsInitialized(); // Push a transition back into managed code onto the linked list in thread.  self-\u0026gt;PushManagedStackFragment(\u0026amp;fragment); self-\u0026gt;PushShadowFrame(shadow_frame); self-\u0026gt;EndAssertNoThreadSuspension(old_cause); if (needs_initialization) { // Ensure static method\u0026#39;s class is initialized.  StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::Class\u0026gt; h_class(hs.NewHandle(shadow_frame-\u0026gt;GetMethod()-\u0026gt;GetDeclaringClass())); if (!Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;EnsureInitialized(self, h_class, true, true)) { DCHECK(Thread::Current()-\u0026gt;IsExceptionPending()) \u0026lt;\u0026lt; shadow_frame-\u0026gt;GetMethod()-\u0026gt;PrettyMethod(); self-\u0026gt;PopManagedStackFragment(fragment); return 0; } } result = interpreter::EnterInterpreterFromEntryPoint(self, accessor, shadow_frame); } EnterInterpreterFromEntryPoint JValue EnterInterpreterFromEntryPoint(Thread* self, const CodeItemDataAccessor\u0026amp; accessor, ShadowFrame* shadow_frame) { DCHECK_EQ(self, Thread::Current()); bool implicit_check = !Runtime::Current()-\u0026gt;ExplicitStackOverflowChecks(); if (UNLIKELY(__builtin_frame_address(0) \u0026lt; self-\u0026gt;GetStackEndForInterpreter(implicit_check))) { ThrowStackOverflowError(self); return JValue(); } jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); if (jit != nullptr) { jit-\u0026gt;NotifyCompiledCodeToInterpreterTransition(self, shadow_frame-\u0026gt;GetMethod()); } return Execute(self, accessor, *shadow_frame, JValue()); } art_quick_generic_jni_trampoline DEFINE_FUNCTION art_quick_generic_jni_trampoline call SYMBOL(artQuickGenericJniTrampoline) // (Thread*, sp)  // On x86 there are no registers passed, so nothing to pop here.  // Native call.  call *%eax //调用native层的具体方法实现 artQuickGenericJniTrampoline extern \u0026#34;C\u0026#34; TwoWordReturn artQuickGenericJniTrampoline(Thread* self, ArtMethod** sp) REQUIRES_SHARED(Locks::mutator_lock_) { // Retrieve the stored native code.  void const* nativeCode = called-\u0026gt;GetEntryPointFromJni(); // There are two cases for the content of nativeCode:  // 1) Pointer to the native function.  // 2) Pointer to the trampoline for native code binding.  // In the second case, we need to execute the binding and continue with the actual native function  // pointer.  // after find the native method pointer, set it to nativeCode variable to avoid find native method again  DCHECK(nativeCode != nullptr); if (nativeCode == GetJniDlsymLookupStub()) { #if defined(__arm__) || defined(__aarch64__)  nativeCode = artFindNativeMethod(); #else  nativeCode = artFindNativeMethod(self); #endif art/runtime/entrypoints/jni/jni_entrypoints.cc\nartFindNativeMethod extern \u0026#34;C\u0026#34; const void* artFindNativeMethod(Thread* self) { DCHECK_EQ(self, Thread::Current()); #endif  Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); // We come here as Native.  ScopedObjectAccess soa(self); ArtMethod* method = self-\u0026gt;GetCurrentMethod(nullptr);//获取当前线程栈顶方法  DCHECK(method != nullptr); // Lookup symbol address for method, on failure we\u0026#39;ll return null with an exception set,  // otherwise we return the address of the method we found.  void* native_code = soa.Vm()-\u0026gt;FindCodeForNativeMethod(method); if (native_code == nullptr) { self-\u0026gt;AssertPendingException(); return nullptr; } // Register so that future calls don\u0026#39;t come here  return method-\u0026gt;RegisterNative(native_code); } art/runtime/java_vm_ext.cc\nJavaVMExt::FindCodeForNativeMethod void* JavaVMExt::FindCodeForNativeMethod(ArtMethod* m) { CHECK(m-\u0026gt;IsNative()); mirror::Class* c = m-\u0026gt;GetDeclaringClass(); // If this is a static method, it could be called before the class has been initialized.  CHECK(c-\u0026gt;IsInitializing()) \u0026lt;\u0026lt; c-\u0026gt;GetStatus() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; m-\u0026gt;PrettyMethod(); std::string detail; Thread* const self = Thread::Current(); void* native_method = libraries_-\u0026gt;FindNativeMethod(self, m, detail); if (native_method == nullptr) { // Lookup JNI native methods from native TI Agent libraries. See runtime/ti/agent.h for more  // information. Agent libraries are searched for native methods after all jni libraries.  native_method = FindCodeForNativeMethodInAgents(m); } // Throwing can cause libraries_lock to be reacquired.  if (native_method == nullptr) { LOG(ERROR) \u0026lt;\u0026lt; detail; self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/UnsatisfiedLinkError;\u0026#34;, detail.c_str()); } return native_method; } FindNativeMethod // See section 11.3 \u0026#34;Linking Native Methods\u0026#34; of the JNI spec. void* FindNativeMethod(Thread* self, ArtMethod* m, std::string\u0026amp; detail) REQUIRES(!Locks::jni_libraries_lock_) REQUIRES_SHARED(Locks::mutator_lock_) { std::string jni_short_name(m-\u0026gt;JniShortName());//\u0026#34;Java_com_example_myapplication_loadLibrary_jni_XHCoreJni_getSignatureKey\u0026#34;  std::string jni_long_name(m-\u0026gt;JniLongName());//\u0026#34;Java_com_example_myapplication_loadLibrary_jni_XHCoreJni_getSignatureKey__\u0026#34;  const char* shorty = m-\u0026gt;GetShorty(); { // Go to suspended since dlsym may block for a long time if other threads are using dlopen.  ScopedThreadSuspension sts(self, kNative); void* native_code = FindNativeMethodInternal(self, declaring_class_loader_allocator, shorty, jni_short_name, jni_long_name); if (native_code != nullptr) { return native_code; } } return nullptr; } FindNativeMethodInternal void* FindNativeMethodInternal(Thread* self, void* declaring_class_loader_allocator, const char* shorty, const std::string\u0026amp; jni_short_name, const std::string\u0026amp; jni_long_name) REQUIRES(!Locks::jni_libraries_lock_) REQUIRES(!Locks::mutator_lock_) { MutexLock mu(self, *Locks::jni_libraries_lock_); for (const auto\u0026amp; lib : libraries_) { SharedLibrary* const library = lib.second; // Use the allocator address for class loader equality to avoid unnecessary weak root decode.  if (library-\u0026gt;GetClassLoaderAllocator() != declaring_class_loader_allocator) { // We only search libraries loaded by the appropriate ClassLoader.  continue; } // Try the short name then the long name...  const char* arg_shorty = library-\u0026gt;NeedsNativeBridge() ? shorty : nullptr; void* fn = library-\u0026gt;FindSymbol(jni_short_name, arg_shorty); if (fn == nullptr) { fn = library-\u0026gt;FindSymbol(jni_long_name, arg_shorty); } if (fn != nullptr) { VLOG(jni) \u0026lt;\u0026lt; \u0026#34;[Found native code for \u0026#34; \u0026lt;\u0026lt; jni_long_name \u0026lt;\u0026lt; \u0026#34; in \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; library-\u0026gt;GetPath() \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;]\u0026#34;; return fn; } } return nullptr; } art/runtime/entrypoints/entrypoint_utils-inl.h\nFindMethodFromCode template\u0026lt;InvokeType type, bool access_check\u0026gt; inline ArtMethod* FindMethodFromCode(uint32_t method_idx, ObjPtr\u0026lt;mirror::Object\u0026gt;* this_object, ArtMethod* referrer, Thread* self) { ClassLinker* const class_linker = Runtime::Current()-\u0026gt;GetClassLinker(); constexpr ClassLinker::ResolveMode resolve_mode = access_check ? ClassLinker::ResolveMode::kCheckICCEAndIAE : ClassLinker::ResolveMode::kNoChecks; ArtMethod* resolved_method; if (type == kStatic) { resolved_method = class_linker-\u0026gt;ResolveMethod\u0026lt;resolve_mode\u0026gt;(self, method_idx, referrer, type); } else { StackHandleScope\u0026lt;1\u0026gt; hs(self); HandleWrapperObjPtr\u0026lt;mirror::Object\u0026gt; h_this(hs.NewHandleWrapper(this_object)); resolved_method = class_linker-\u0026gt;ResolveMethod\u0026lt;resolve_mode\u0026gt;(self, method_idx, referrer, type); } art/runtime/class_linker-inl.h\nClassLinker::ResolveMethod template \u0026lt;ClassLinker::ResolveMode kResolveMode\u0026gt; inline ArtMethod* ClassLinker::ResolveMethod(Thread* self, uint32_t method_idx, ArtMethod* referrer, InvokeType type) { // We do not need the read barrier for getting the DexCache for the initial resolved method  // lookup as both from-space and to-space copies point to the same native resolved methods array.  ArtMethod* resolved_method = referrer-\u0026gt;GetDexCache\u0026lt;kWithoutReadBarrier\u0026gt;()-\u0026gt;GetResolvedMethod( method_idx, image_pointer_size_); if (UNLIKELY(resolved_method == nullptr)) { referrer = referrer-\u0026gt;GetInterfaceMethodIfProxy(image_pointer_size_); ObjPtr\u0026lt;mirror::Class\u0026gt; declaring_class = referrer-\u0026gt;GetDeclaringClass(); StackHandleScope\u0026lt;2\u0026gt; hs(self); Handle\u0026lt;mirror::DexCache\u0026gt; h_dex_cache(hs.NewHandle(referrer-\u0026gt;GetDexCache())); Handle\u0026lt;mirror::ClassLoader\u0026gt; h_class_loader(hs.NewHandle(declaring_class-\u0026gt;GetClassLoader())); resolved_method = ResolveMethod\u0026lt;kResolveMode\u0026gt;(method_idx, h_dex_cache, h_class_loader, referrer, type); } art/runtime/mirror/dex_cache-inl.h\nDexCache::GetResolvedMethod inline ArtMethod* DexCache::GetResolvedMethod(uint32_t method_idx, PointerSize ptr_size) { DCHECK_EQ(Runtime::Current()-\u0026gt;GetClassLinker()-\u0026gt;GetImagePointerSize(), ptr_size); auto pair = GetNativePairPtrSize(GetResolvedMethods(), MethodSlotIndex(method_idx), ptr_size); return pair.GetObjectForIndex(method_idx); } art/runtime/class_linker.cc\nClassLinker::ResolveMethod template \u0026lt;ClassLinker::ResolveMode kResolveMode\u0026gt; ArtMethod* ClassLinker::ResolveMethod(uint32_t method_idx, Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, ArtMethod* referrer, InvokeType type) { .... // The method was not in the DexCache, resolve the declaring class.  klass = ResolveType(method_id.class_idx_, dex_cache, class_loader); resolved = FindResolvedMethod(klass, dex_cache.Get(), class_loader.Get(), method_idx); // If we found a method, check for incompatible class changes.  if (LIKELY(resolved != nullptr) \u0026amp;\u0026amp; LIKELY(kResolveMode == ResolveMode::kNoChecks || !resolved-\u0026gt;CheckIncompatibleClassChange(type))) { return resolved; } else { // If we had a method, or if we can find one with another lookup type,  // it\u0026#39;s an incompatible-class-change error.  if (resolved == nullptr) { resolved = FindIncompatibleMethod(klass, dex_cache.Get(), class_loader.Get(), method_idx); } if (resolved != nullptr) { ThrowIncompatibleClassChangeError(type, resolved-\u0026gt;GetInvokeType(), resolved, referrer); } else { // We failed to find the method (using all lookup types), so throw a NoSuchMethodError.  const char* name = dex_file.StringDataByIdx(method_id.name_idx_); const Signature signature = dex_file.GetMethodSignature(method_id); ThrowNoSuchMethodError(type, klass, name, signature); } Thread::Current()-\u0026gt;AssertPendingException(); return nullptr; ClassLinker::ResolveType ClassLinker::FindResolvedMethod ArtMethod* ClassLinker::FindResolvedMethod(ObjPtr\u0026lt;mirror::Class\u0026gt; klass, ObjPtr\u0026lt;mirror::DexCache\u0026gt; dex_cache, ObjPtr\u0026lt;mirror::ClassLoader\u0026gt; class_loader, uint32_t method_idx) { // Search for the method using dex_cache and method_idx. The Class::Find*Method()  // functions can optimize the search if the dex_cache is the same as the DexCache  // of the class, with fall-back to name and signature search otherwise  ArtMethod* resolved = nullptr; if (klass-\u0026gt;IsInterface()) { resolved = klass-\u0026gt;FindInterfaceMethod(dex_cache, method_idx, image_pointer_size_); } else { resolved = klass-\u0026gt;FindClassMethod(dex_cache, method_idx, image_pointer_size_); } if (resolved != nullptr \u0026amp;\u0026amp; hiddenapi::GetMemberAction( resolved, class_loader, dex_cache, hiddenapi::kLinking) == hiddenapi::kDeny) { resolved = nullptr; } if (resolved != nullptr) { // In case of jmvti, the dex file gets verified before being registered, so first  // check if it\u0026#39;s registered before checking class tables.  const DexFile\u0026amp; dex_file = *dex_cache-\u0026gt;GetDexFile(); DCHECK(!IsDexFileRegistered(Thread::Current(), dex_file) || FindClassTable(Thread::Current(), dex_cache) == ClassTableForClassLoader(class_loader)) \u0026lt;\u0026lt; \u0026#34;DexFile referrer: \u0026#34; \u0026lt;\u0026lt; dex_file.GetLocation() \u0026lt;\u0026lt; \u0026#34; ClassLoader: \u0026#34; \u0026lt;\u0026lt; DescribeLoaders(class_loader, \u0026#34;\u0026#34;); // Be a good citizen and update the dex cache to speed subsequent calls.  dex_cache-\u0026gt;SetResolvedMethod(method_idx, resolved, image_pointer_size_); // Disable the following invariant check as the verifier breaks it. b/73760543  // const DexFile::MethodId\u0026amp; method_id = dex_file.GetMethodId(method_idx);  // DCHECK(LookupResolvedType(method_id.class_idx_, dex_cache, class_loader) != nullptr)  // \u0026lt;\u0026lt; \u0026#34;Method: \u0026#34; \u0026lt;\u0026lt; resolved-\u0026gt;PrettyMethod() \u0026lt;\u0026lt; \u0026#34;, \u0026#34;  // \u0026lt;\u0026lt; \u0026#34;Class: \u0026#34; \u0026lt;\u0026lt; klass-\u0026gt;PrettyClass() \u0026lt;\u0026lt; \u0026#34; (\u0026#34; \u0026lt;\u0026lt; klass-\u0026gt;GetStatus() \u0026lt;\u0026lt; \u0026#34;), \u0026#34;  // \u0026lt;\u0026lt; \u0026#34;DexFile referrer: \u0026#34; \u0026lt;\u0026lt; dex_file.GetLocation();  } return resolved; art/runtime/native/java_lang_reflect_Method.cc\njava_lang_reflect_Method.cc::Method_invoke static JNINativeMethod gMethods[] = { FAST_NATIVE_METHOD(Method, invoke, \u0026#34;(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;\u0026#34;), }; static jobject Method_invoke(JNIEnv* env, jobject javaMethod, jobject javaReceiver, jobjectArray javaArgs) { ScopedFastNativeObjectAccess soa(env); return InvokeMethod(soa, javaMethod, javaReceiver, javaArgs); } art/runtime/reflection.cc\nreflection.cc::InvokeMethod jobject InvokeMethod(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject javaMethod, jobject javaReceiver, jobject javaArgs, size_t num_frames) { ObjPtr\u0026lt;mirror::Executable\u0026gt; executable = soa.Decode\u0026lt;mirror::Executable\u0026gt;(javaMethod); const bool accessible = executable-\u0026gt;IsAccessible(); ArtMethod* m = executable-\u0026gt;GetArtMethod(); ObjPtr\u0026lt;mirror::Class\u0026gt; declaring_class = m-\u0026gt;GetDeclaringClass(); // Check that the receiver is non-null and an instance of the field\u0026#39;s declaring class.  receiver = soa.Decode\u0026lt;mirror::Object\u0026gt;(javaReceiver); if (!VerifyObjectIsClass(receiver, declaring_class)) { return nullptr; } // Find the actual implementation of the virtual method.  m = receiver-\u0026gt;GetClass()-\u0026gt;FindVirtualMethodForVirtualOrInterface(m, kRuntimePointerSize); InvokeWithArgArray(soa, m, \u0026amp;arg_array, \u0026amp;result, shorty); } art/runtime/mirror/class-inl.h\ninline ArtMethod* Class::FindVirtualMethodForVirtualOrInterface(ArtMethod* method, PointerSize pointer_size) { if (method-\u0026gt;IsDirect()) { return method; } if (method-\u0026gt;GetDeclaringClass()-\u0026gt;IsInterface() \u0026amp;\u0026amp; !method-\u0026gt;IsCopied()) { return FindVirtualMethodForInterface(method, pointer_size); } return FindVirtualMethodForVirtual(method, pointer_size); } reflection.cc::InvokeWithArgArray void InvokeWithArgArray(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, ArtMethod* method, ArgArray* arg_array, JValue* result, const char* shorty) REQUIRES_SHARED(Locks::mutator_lock_) { uint32_t* args = arg_array-\u0026gt;GetArray(); if (UNLIKELY(soa.Env()-\u0026gt;IsCheckJniEnabled())) { CheckMethodArguments(soa.Vm(), method-\u0026gt;GetInterfaceMethodIfProxy(kRuntimePointerSize), args); } method-\u0026gt;Invoke(soa.Self(), args, arg_array-\u0026gt;GetNumBytes(), result, shorty); } 其他 ClassLinker::ShouldUseInterpreterEntrypoint bool ClassLinker::ShouldUseInterpreterEntrypoint(ArtMethod* method, const void* quick_code) //method-\u0026gt;IsNative() 判断是否是jni方法(在java中标记native关键字的方法)  if (UNLIKELY(method-\u0026gt;IsNative() || method-\u0026gt;IsProxyMethod())) { return false; } if (quick_code == nullptr) { return true; } Runtime* runtime = Runtime::Current(); instrumentation::Instrumentation* instr = runtime-\u0026gt;GetInstrumentation(); if (instr-\u0026gt;InterpretOnly()) { return true; } if (runtime-\u0026gt;GetClassLinker()-\u0026gt;IsQuickToInterpreterBridge(quick_code)) { // Doing this check avoids doing compiled/interpreter transitions.  return true; } if (Dbg::IsForcedInterpreterNeededForCalling(Thread::Current(), method)) { // Force the use of interpreter when it is required by the debugger.  return true; } if (Thread::Current()-\u0026gt;IsAsyncExceptionPending()) { // Force use of interpreter to handle async-exceptions  return true; } if (runtime-\u0026gt;IsJavaDebuggable()) { // For simplicity, we ignore precompiled code and go to the interpreter  // assuming we don\u0026#39;t already have jitted code.  // We could look at the oat file where `quick_code` is being defined,  // and check whether it\u0026#39;s been compiled debuggable, but we decided to  // only rely on the JIT for debuggable apps.  jit::Jit* jit = Runtime::Current()-\u0026gt;GetJit(); return (jit == nullptr) || !jit-\u0026gt;GetCodeCache()-\u0026gt;ContainsPc(quick_code); } if (runtime-\u0026gt;IsNativeDebuggable()) { DCHECK(runtime-\u0026gt;UseJitCompilation() \u0026amp;\u0026amp; runtime-\u0026gt;GetJit()-\u0026gt;JitAtFirstUse()); // If we are doing native debugging, ignore application\u0026#39;s AOT code,  // since we want to JIT it (at first use) with extra stackmaps for native  // debugging. We keep however all AOT code from the boot image,  // since the JIT-at-first-use is blocking and would result in non-negligible  // startup performance impact.  return !runtime-\u0026gt;GetHeap()-\u0026gt;IsInBootImageOatFile(quick_code); } return false; } art/runtime/jit/jit.cc\nJit::CanInvokeCompiledCode bool Jit::CanInvokeCompiledCode(ArtMethod* method) { return code_cache_-\u0026gt;ContainsPc(method-\u0026gt;GetEntryPointFromQuickCompiledCode()); } art::ShadowFrame art::shadowFrame * link_ //nextFrame below current frame, eg, caller reflection.cc::InvokeVirtualOrInterfaceWithJValues JValue InvokeVirtualOrInterfaceWithJValues(const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject obj, jmethodID mid, jvalue* args) { ObjPtr\u0026lt;mirror::Object\u0026gt; receiver = soa.Decode\u0026lt;mirror::Object\u0026gt;(obj); ArtMethod* method = FindVirtualMethod(receiver, jni::DecodeArtMethod(mid)); arg_array.BuildArgArrayFromJValues(soa, receiver, args); InvokeWithArgArray(soa, method, \u0026amp;arg_array, \u0026amp;result, shorty); return result; art_method.cc DexInstructionData inline CodeItemDataAccessor ArtMethod::DexInstructionData() { return CodeItemDataAccessor(*GetDexFile(), GetCodeItem()); } GetCodeItem inline const DexFile::CodeItem* ArtMethod::GetCodeItem() { return GetDexFile()-\u0026gt;GetCodeItem(GetCodeItemOffset()); } GetDexFile inline const DexFile* ArtMethod::GetDexFile() { // It is safe to avoid the read barrier here since the dex file is constant, so if we read the  // from-space dex file pointer it will be equal to the to-space copy.  return GetDexCache\u0026lt;kWithoutReadBarrier\u0026gt;()-\u0026gt;GetDexFile(); } GetDexCache template \u0026lt;ReadBarrierOption kReadBarrierOption\u0026gt; inline mirror::DexCache* ArtMethod::GetDexCache() { if (LIKELY(!IsObsolete\u0026lt;kReadBarrierOption\u0026gt;())) { mirror::Class* klass = GetDeclaringClass\u0026lt;kReadBarrierOption\u0026gt;(); return klass-\u0026gt;GetDexCache\u0026lt;kDefaultVerifyFlags, kReadBarrierOption\u0026gt;(); } else { DCHECK(!IsProxyMethod()); return GetObsoleteDexCache(); } } GetEntryPointFromQuickCompiledCode const void* GetEntryPointFromQuickCompiledCode() { return GetEntryPointFromQuickCompiledCodePtrSize(kRuntimePointerSize); } ALWAYS_INLINE const void* GetEntryPointFromQuickCompiledCodePtrSize(PointerSize pointer_size) { return GetNativePointer\u0026lt;const void*\u0026gt;( EntryPointFromQuickCompiledCodeOffset(pointer_size), pointer_size); } static MemberOffset EntryPointFromQuickCompiledCodeOffset(PointerSize pointer_size) { return MemberOffset(PtrSizedFieldsOffset(pointer_size) + OFFSETOF_MEMBER( PtrSizedFields, entry_point_from_quick_compiled_code_) / sizeof(void*) * static_cast\u0026lt;size_t\u0026gt;(pointer_size)); } 参考 ART执行类方法解析流程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/1javacrash/javacrashsystemhandle/",
	"title": "JavaCrashSystemHandle",
	"tags": [],
	"description": "",
	"content": "原理流程 当Binder服务端ApplicationThread所在进程(即Crash进程)挂掉后，则Binder客户端能收到相应的死亡通知，从而进入binderDied流程。\nAMP.handleApplicationCrash AMS.handleApplicationCrash AMS.findAppProcess AMS.handleApplicationCrashInner AMS.addErrorToDropBox AMS.crashApplication AMS.makeAppCrashingLocked AMS.startAppProblemLocked ProcessRecord.stopFreezingAllLocked ActivityRecord.stopFreezingScreenLocked WMS.stopFreezingScreenLocked WMS.stopFreezingDisplayLocked AMS.handleAppCrashLocked mUiHandler.sendMessage(SHOW_ERROR_MSG) Process.killProcess(Process.myPid()); System.exit(10); 其中addErrorToDropBox是将crash的信息输出到目录/data/system/dropbox。例如system_server的dropbox文件名为system_server_crash@xxx.txt (xxx代表的是时间戳)\nAMS.handleAppCrashLocked ASS.handleAppCrashLocked AS.handleAppCrashLocked AS.finishCurrentActivityLocked AMS.removeProcessLocked ProcessRecord.kill AMS.handleAppDiedLocked ASS.handleAppDiedLocked AMS.cleanUpApplicationRecordLocked AS.handleAppDiedLocked AS.removeHistoryRecordsForAppLocked ASS.resumeTopActivitiesLocked AS.resumeTopActivityLocked AS.resumeTopActivityInnerLocked ASS.finishTopRunningActivityLocked AS.finishTopRunningActivityLocked AS.finishActivityLocked 参考 http://gityuan.com/2016/06/24/app-crash/\n吹爆系列：深入探索android稳定性优化\n"
},
{
	"uri": "https://huanle19891345.github.io/en/java/java%E5%B9%B6%E5%8F%91/",
	"title": "java并发",
	"tags": [],
	"description": "",
	"content": "Java主流锁 悲观锁和乐观锁 乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。\n先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。\n而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。\n乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。\n根据从上面的概念描述我们可以发现：\n 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。  光说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例：\n通过调用方式示例，我们可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。那么，为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？我们通过介绍乐观锁的主要实现方式 “CAS” 的技术原理来为大家解惑。\nCAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。\nCAS算法涉及到三个操作数：\n 需要读写的内存值 V。 进行比较的值 A。 要写入的新值 B。  当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个不断重试的操作。\n之前提到java.util.concurrent包中的原子类，就是通过CAS来实现了乐观锁，那么我们进入原子类AtomicInteger的源码，看一下AtomicInteger的定义：\n根据定义我们可以看出各属性的作用：\n unsafe： 获取并操作内存的数据。 valueOffset： 存储value在AtomicInteger中的偏移量。 value： 存储AtomicInteger的int值，该属性需要借助volatile关键字保证其在线程间是可见的。  接下来，我们查看AtomicInteger的自增函数incrementAndGet()的源码时，发现自增函数底层调用的是unsafe.getAndAddInt()。但是由于JDK本身只有Unsafe.class，只通过class文件中的参数名，并不能很好的了解方法的作用，所以我们通过OpenJDK 8 来查看Unsafe的源码：\n根据OpenJDK 8的源码我们可以看出，getAndAddInt()循环获取给定对象o中的偏移量处的值v，然后判断内存值是否等于v。如果相等则将内存值设置为 v + delta，否则返回false，继续循环进行重试，直到设置成功才能退出循环，并且将旧值返回。整个“比较+更新”操作封装在compareAndSwapInt()中，在JNI里是借助于一个CPU指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值。\n后续JDK通过CPU的cmpxchg指令，去比较寄存器中的 A 和 内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A。然后通过Java代码中的while循环再次调用cmpxchg指令进行重试，直到设置成功为止。\nCAS虽然很高效，但是它也存在三大问题，这里也简单说一下：\n ABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。  JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。\n 循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。\n  只能保证一个共享变量的原子操作。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。\n  Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。\n自旋锁 VS 适应性自旋锁 在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。\n阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。\n在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。\n而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。\n自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。\n自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。\n自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。\n自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。\n在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock，本文中仅做名词介绍，不做深入讲解，感兴趣的同学可以自行查阅相关资料。\n无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁 这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。\n首先为什么Synchronized能实现线程同步？\n在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。\nJava对象头 synchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？\n我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。\nMark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。\nKlass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。\nMonitor Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。\nMonitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。==每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。==\nsynchronized解析——如果你愿意一层一层剥开我的心\nmonitorenter monitorenter指令介绍\n Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:\n If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.\nIf the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.\nIf another thread already owns the monitor associated with objectref, the thread blocks until the monitor\u0026rsquo;s entry count is zero, then tries again to gain ownership.\n  monitorexit monitorexit指令介绍\n The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.\nThe thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so.\n ACC_SYNCHRONIZED ACC_SYNCHRONIZED介绍\n Method-level synchronization is performed implicitly, as part of method invocation and return. A synchronized method is distinguished in the run-time constant pool’s methodinfo structure by the ACCSYNCHRONIZED flag, which is checked by the method invocation instructions. When invoking a method for which ACC_SYNCHRONIZED is set, the executing thread enters a monitor, invokes the method itself, and exits the monitor whether the method invocation completes normally or abruptly. During the time the executing thread owns the monitor, no other thread may enter it. If an exception is thrown during invocation of the synchronized method and the synchronized method does not handle the exception, the monitor for the method is automatically exited before the exception is rethrown out of the synchronized method.\n ObjectMonitor ObjectMonitor数据结构 在Java虚拟机（HotSpot）中，Monitor（管程）是由ObjectMonitor实现的\nObjectMonitor关键字 ObjectMonitor中几个关键字段的含义如图所示：\n工作机理 Java Monitor 的工作机理如图所示：\n 想要获取monitor的线程,首先会进入_EntryList队列。 当某个线程获取到对象的monitor后,进入Owner区域，设置为当前线程,同时计数器count加1。 如果线程调用了wait()方法，则会进入WaitSet队列。它会释放monitor锁，即将owner赋值为null,count自减1,进入WaitSet队列阻塞等待。 如果其他线程调用 notify() / notifyAll() ，会唤醒WaitSet中的某个线程，该线程再次尝试获取monitor锁，成功即进入Owner区域。 同步方法执行完毕了，线程退出临界区，会将monitor的owner设为null，并释放监视锁。  对象与monitor关联 对象是如何跟monitor关联的呢？直接先看图：\n锁优化 事实上，只有在JDK1.6之前，synchronized的实现才会直接调用ObjectMonitor的enter和exit，这种锁被称之为重量级锁。\n总结 现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。\n如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。\n所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。\n通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点：\n无锁\n无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。\n无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。\n偏向锁\n偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。\n在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。\n当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。\n偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。\n偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。\n轻量级锁\n是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。\n在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。\n拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。\n如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。\n如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。\n若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。\n重量级锁\n升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。\n整体的锁状态升级流程如下：\n综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞\n公平锁 VS 非公平锁 公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。\n非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。\n直接用语言描述可能有点抽象，这里作者用从别处看到的一个例子来讲述一下公平锁和非公平锁。\n如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。\n但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示：\n接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。\n根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。\n下面我们来看一下公平锁与非公平锁的加锁方法的源码:\n综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。\n可重入锁 VS 非可重入锁 可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁\n而为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？我们通过图示和源码来分别解析一下。\n还是打水的例子，有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。\n之前我们说过ReentrantLock和synchronized都是重入锁，那么我们通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。\n首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。\n当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。\n释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。\n独享锁 VS 共享锁 独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。\n独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。\n共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。\n独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。\n下图为ReentrantReadWriteLock的部分源码：\n我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。\n在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。\n那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。\n在最开始提及AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。\n在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示：\n了解了概念之后我们再来看代码，先看写锁的加锁源码：\ntryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。\n因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。\n接着是读锁的代码：\n可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1\u0026laquo;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。\n此时，我们再回头看一下互斥锁ReentrantLock中公平锁和非公平锁的加锁源码：\n我们发现在ReentrantLock虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。根据源码所示，当某一个线程调用lock方法获取锁时，如果同步资源没有被其他线程锁住，那么当前线程在使用CAS更新state成功后就会成功抢占该资源。而如果公共资源被占用且不是被当前线程占用，那么就会加锁失败。所以可以确定ReentrantLock无论读操作还是写操作，添加的锁都是都是独享锁。\n AQS  上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。  下面我们会从整体到细节，从流程到方法逐一剖析AQS框架，主要分析过程如下：\n2.1 原理概览 AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。\nCLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。\n主要原理图如下：\nAQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。\n2.1.1 AQS数据结构 先来看下AQS中最基本的数据结构——Node，Node即为上面CLH变体队列中的节点。\n解释一下几个方法和属性值的含义：\n   方法和属性值 含义     waitStatus 当前节点在队列中的状态   thread 表示处于该节点的线程   prev 前驱指针   predecessor 返回前驱节点，没有的话抛出npe   nextWaiter 指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍）   next 后继指针    线程两种锁的模式：\n   模式 含义     SHARED 表示线程以共享的模式等待锁   EXCLUSIVE 表示线程正在以独占的方式等待锁    waitStatus有下面几个枚举值：\n   枚举 含义     0 当一个Node被初始化的时候的默认值   CANCELLED 为1，表示线程获取锁的请求已经取消了   CONDITION 为-2，表示节点在等待队列中，节点线程等待唤醒   PROPAGATE 为-3，当前线程处在SHARED情况下，该字段才会使用   SIGNAL 为-1，表示线程已经准备好了，就等资源释放了    2.1.2 同步状态State 在了解数据结构后，接下来了解一下AQS的同步状态——State。AQS中维护了一个名为state的字段，意为同步状态，是由Volatile修饰的，用于展示当前临界资源的获锁情况。\n// java.util.concurrent.locks.AbstractQueuedSynchronizer  private volatile int state; 下面提供了几个访问这个字段的方法：\n   方法名 描述     protected final int getState() 获取State的值   protected final void setState(int newState) 设置State的值   protected final boolean compareAndSetState(int expect, int update) 使用CAS方式更新State    这几个方法都是Final修饰的，说明子类中无法重写它们。我们可以通过修改State字段表示的同步状态来实现多线程的独占模式和共享模式（加锁过程）。\n\u0026hellip;\u0026hellip;\n2.2 AQS重要方法与ReentrantLock的关联 从架构图中可以得知，AQS提供了大量用于自定义同步器实现的Protected方法。自定义同步器实现的相关方法也只是为了通过修改State字段来实现多线程的独占模式或者共享模式。自定义同步器需要实现以下方法（ReentrantLock需要实现的方法如下，并不是全部）：\n   方法名 描述     protected boolean isHeldExclusively() 该线程是否正在独占资源。只有用到Condition才需要去实现它。   protected boolean tryAcquire(int arg) 独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。   protected boolean tryRelease(int arg) 独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。   protected int tryAcquireShared(int arg) 共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。   protected boolean tryReleaseShared(int arg) 共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。    一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。\n以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。\n2.3 通过ReentrantLock理解AQS 2.3.1 线程加入等待队列 2.3.1.1 加入队列的时机 当执行Acquire(1)时，会通过tryAcquire获取锁。在这种情况下，如果获取锁失败，就会调用addWaiter加入到等待队列中去。\n\u0026hellip;\u0026hellip;剩下的直接看文章吧\nsynchronized synchronized能不能保证有序性？？\nsynchronized能够保证原子性和可见性，无法保证有序性，线程1在执行instance=new Singleton();内部的四步指令被重排序，导致先发生赋值后发生对象初始化，从而此时线程2直接在第一个空判断就因为非空而推出，进而得到了一个没有初始化的对象，进行对象访问会有问题\nclass Singleton{ private static volatile Singleton instance; private Singleton(){} public static Singleton getInstance(){ if(instance==null){ synchronized (Singleton.class){ if(instance==null){ instance=new Singleton(); } } } return instance; } } volatile 深度解析volatile—底层实现\n加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令。我们发现，volatile变量在字节码级别没有任何区别，在汇编级别使用了lock指令前缀。\nlock是一个指令前缀，Intel的手册上对其的解释是：\nCauses the processor\u0026rsquo;s LOCK# signal to be asserted during execution of the accompanying instruction (turns the instruction into an atomic instruction). In a multiprocessor environment, the LOCK# signal insures that the processor has exclusive use of any shared memory while the signal is asserted.\n对于可见性，Java提供了volatile关键字来保证可见性、有序性。但不保证原子性。普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。\n volatile关键字对于基本类型的修改可以在随后对多个线程的读保持一致，但是对于引用类型如数组，实体bean，仅仅保证引用的可见性，但并不保证引用内容的可见性。。 禁止进行指令重排序。  背景：为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。\n 如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。 在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，当某个CPU在写数据时，如果发现操作的变量是共享变量，则会通知其他CPU告知该变量的缓存行是无效的，因此其他CPU在读取该变量时，发现其无效会重新从主存中加载数据。  总结下来：\n 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量的缓存行无效，所以线程1再次读取变量的值时会去主存读取。  Lock ReentrantLock concurrent.atomic 包下的类大多是使用CAS操作来实现的\nCAS Android 并发之CAS（原子操作）简单介绍（五）\n那些地方使用CAS？\n比如JDK中的Atomic以及Lock的底层实现也是用CAS机制。\nCAS的缺点：\n CPU开销较大 在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。 不能保证代码块的原子性 CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3个变量共同进行原子性的更新，就不得不使用Synchronized了。  AQS AQS(AbstractQueuedSynchronizer)，AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁和相关的同步器的一个同步框架\nList并发访问 阻塞(锁)  Collections.synchronizedList + Iterator synchronized  显然这不是一个好的并发队列，这会导致吞吐量急剧下降。\n非阻塞(CAS)   Lock 一种好的实现方式是使用ReentrantReadWriteLock来代替ReentrantLock提高读取的吞吐量\n  ConcurrentLinkedQueue\n  它采用了参考资料1（http://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf） 中的算法。\n要使用非阻塞算法来完成队列操作，那么就需要一种“循环尝试”的动作，就是循环操作队列，直到成功为止，失败就会再次尝试\nConcurrentModificationException 参考 java中synchronized和volatile有什么区别？\n不使用synchronized和lock，如何实现一个线程安全的单例？\nJava Semaphore信号量\nJAVA并发编程: CAS和AQS\nJava并发之AQS详解\n\u0026laquo;/Users/qianpianpian/work/书籍/深入浅出Java多线程.pdf\u0026raquo;\n\u0026laquo;/Users/qianpianpian/work/书籍/Geektime/geektime_Java并发编程实战\u0026raquo;\n从ReentrantLock的实现看AQS的原理及应用\n【基本功】不可不说的java“锁”事\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/aop/jdk%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/",
	"title": "JDK动态代理",
	"tags": [],
	"description": "",
	"content": "Proxy /** parameter types of a proxy class constructor */ private static final Class\u0026lt;?\u0026gt;[] constructorParams = { InvocationHandler.class }; /** \\* a cache of proxy classes */ private static final WeakCache\u0026lt;ClassLoader, Class\u0026lt;?\u0026gt;[], Class\u0026lt;?\u0026gt;\u0026gt; proxyClassCache = new WeakCache\u0026lt;\u0026gt;(new KeyFactory(), new ProxyClassFactory()); newProxyInstance public static Object newProxyInstance(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException { final Class\u0026lt;?\u0026gt;[] intfs = interfaces.clone(); /* \\* Look up or generate the designated proxy class. */ Class\u0026lt;?\u0026gt; cl = getProxyClass0(loader, intfs);//main  final Constructor\u0026lt;?\u0026gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; return cons.newInstance(new Object[]{h}); /** \\* Generate a proxy class. Must call the checkProxyAccess method \\* to perform permission checks before calling this. */ private static Class\u0026lt;?\u0026gt; getProxyClass0(ClassLoader loader, Class\u0026lt;?\u0026gt;... interfaces) { if (interfaces.length \u0026gt; 65535) { throw new IllegalArgumentException(\u0026#34;interface limit exceeded\u0026#34;); } // If the proxy class defined by the given loader implementing  // the given interfaces exists, this will simply return the cached copy;  // otherwise, it will create the proxy class via the ProxyClassFactory  return proxyClassCache.get(loader, interfaces); } /** \\* A factory function that generates, defines and returns the proxy class given \\* the ClassLoader and array of interfaces. */ private static final class ProxyClassFactory implements BiFunction\u0026lt;ClassLoader, Class\u0026lt;?\u0026gt;[], Class\u0026lt;?\u0026gt;\u0026gt; { @Override public Class\u0026lt;?\u0026gt; apply(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces) { return generateProxy(proxyName, interfaces, loader, methodsArray, exceptionsArray); private static native Class\u0026lt;?\u0026gt; generateProxy(String name, Class\u0026lt;?\u0026gt;[] interfaces, ClassLoader loader, Method[] methods, Class\u0026lt;?\u0026gt;[][] exceptions); // END Android-changed: How proxies are generated. Proxy_generateProxy art/runtime/native/java_lang_reflect_Proxy.cc\nstatic JNINativeMethod gMethods[] = { FAST_NATIVE_METHOD(Proxy, generateProxy, \u0026#34;(Ljava/lang/String;[Ljava/lang/Class;Ljava/lang/ClassLoader;[Ljava/lang/reflect/Method;[[Ljava/lang/Class;)Ljava/lang/Class;\u0026#34;), }; static jclass Proxy_generateProxy(JNIEnv* env, jclass, jstring name, jobjectArray interfaces, jobject loader, jobjectArray methods, jobjectArray throws) { ScopedFastNativeObjectAccess soa(env); ClassLinker* class_linker = Runtime::Current()-\u0026gt;GetClassLinker(); return soa.AddLocalReference\u0026lt;jclass\u0026gt;(class_linker-\u0026gt;CreateProxyClass( soa, name, interfaces, loader, methods, throws)); } ClassLinker::CreateProxyClass创建并触发类加载流程 art/runtime/class_linker.cc\nmirror::Class* ClassLinker::CreateProxyClass(ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jstring name, jobjectArray interfaces, jobject loader, jobjectArray methods, jobjectArray throws) { "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/",
	"title": "jetpack",
	"tags": [],
	"description": "",
	"content": "jetpack 探索总结jetpack知识\n arch    1lifecycle    Lifecycle     LifecycleCoroutine      2livedata    1MediatorLiveData     LiveData     LiveDataCoroutine     Transformations      3viewmodel    SaveAndRestoreInstanceState     SavedStateHandle     SavingStates     ViewModel     ViewModelScope_Delegate      Coroutines     databinding    Databinding     TwoWayDataBinding      di    DI     HiltSource      架构实现    KaptGenerateViewModel     架构思考和实现     架构思考和实现Inner       compose    Compose     ComposeSource     LayoutNode     ReComposition      SupportToAndroidx     workmanager    WorkManager      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/ndk/jni/",
	"title": "JNI",
	"tags": [],
	"description": "",
	"content": "https://docs.oracle.com/javase/7/docs/technotes/guides/jni/spec/types.html\nhttps://developer.android.com/training/articles/perf-jni\nJavaVM and JNIEnv 图解 graph LR JavaVM--\u0026gt;singlePerProcess JNIEnv--\u0026gt;singlePerThread JNI defines two key data structures, \u0026ldquo;JavaVM\u0026rdquo; and \u0026ldquo;JNIEnv\u0026rdquo;. Both of these are essentially pointers to pointers to function tables. (In the C++ version, they\u0026rsquo;re classes with a pointer to a function table and a member function for each JNI function that indirects through the table.) The JavaVM provides the \u0026ldquo;invocation interface\u0026rdquo; functions, which allow you to create and destroy a JavaVM. In theory you can have multiple JavaVMs per process, but Android only allows one.\nThe JNIEnv provides most of the JNI functions. Your native functions all receive a JNIEnv as the first argument.\nThe JNIEnv is used for thread-local storage. For this reason, you cannot share a JNIEnv between threads. If a piece of code has no other way to get its JNIEnv, you should share the JavaVM, and use GetEnv to discover the thread\u0026rsquo;s JNIEnv. (Assuming it has one; see AttachCurrentThread below.)\nNative libraries You can load native code from shared libraries with the standard System.loadLibrary.\nIn practice, older versions of Android had bugs in PackageManager that caused installation and update of native libraries to be unreliable. The ReLinker project offers workarounds for this and other native library loading problems.\nTo use RegisterNatives:\n Provide a JNIEXPORT jint JNI_OnLoad(JavaVM* vm, void* reserved) function. In your JNI_OnLoad, register all of your native methods using RegisterNatives. Build with -fvisibility=hidden so that only your JNI_OnLoad is exported from your library. This produces faster and smaller code, and avoids potential collisions with other libraries loaded into your app (but it creates less useful stack traces if you app crashes in native code).   https://android-developers.googleblog.com/2011/07/debugging-android-jni-with-checkjni.html\nhttps://developer.android.com/training/articles/perf-jni#native-libraries\nhttps://docs.oracle.com/javase/7/docs/technotes/guides/jni/spec/jniTOC.html\nhttps://docs.oracle.com/javase/6/docs/technotes/guides/jni/spec/design.html#wp615\nThe programmer can also call the JNI function RegisterNatives() to register the native methods associated with a class. The RegisterNatives() function is particularly useful with statically linked functions.\nResolving Native Method Names Dynamic linkers resolve entries based on their names. A native method name is concatenated from the following components:\n the prefix Java_ a mangled fully-qualified class name an underscore (“_”) separator a mangled method name for overloaded native methods, two underscores (“__”) followed by the mangled argument signature  The VM checks for a method name match for methods that reside in the native library. The VM looks first for the short name; that is, the name without the argument signature. It then looks for the long name, which is the name with the argument signature. Programmers need to use the long name only when a native method is overloaded with another native method. However, this is not a problem if the native method has the same name as a nonnative method. A nonnative method (a Java method) does not reside in the native library.\nIn the following example, the native method g does not have to be linked using the long name because the other method g is not a native method, and thus is not in the native library.\nclass Cls1 { int g(int i); native int g(double d); } Native Method Arguments The JNI interface pointer is the first argument to native methods. The JNI interface pointer is of type JNIEnv. The second argument differs depending on whether the native method is static or nonstatic. The second argument to a nonstatic native method is a reference to the object. The second argument to a static native method is a reference to its Java class.\nThe remaining arguments correspond to regular Java method arguments. The native method call passes its result back to the calling routine via the return value. Chapter 3 describes the mapping between Java and C types.\npackage pkg; class Cls { native double f(int i, String s); ... } //The C function with the long mangled name Java_pkg_Cls_f_ILjava_lang_String_2 implements native method f: //Code Example 2-1 Implementing a Native Method Using C  jdouble Java_pkg_Cls_f__ILjava_lang_String_2 ( JNIEnv *env, /* interface pointer */ jobject obj, /* \u0026#34;this\u0026#34; pointer */ jint i, /* argument #1 */ jstring s) /* argument #2 */ { /* Obtain a C-copy of the Java string */ const char *str = (*env)-\u0026gt;GetStringUTFChars(env, s, 0); /* process the string */ ... /* Now we are done with str */ (*env)-\u0026gt;ReleaseStringUTFChars(env, s, str); return ... } Referencing Java Objects   Primitive types, such as integers, characters, and so on, are copied between Java and native code.\n  Arbitrary Java objects, on the other hand, are passed by reference.\n  The VM must keep track of all objects that have been passed to the native code, so that these objects are not freed by the garbage collector. The native code, in turn, must have a way to inform the VM that it no longer needs the objects. In addition, the garbage collector must be able to move an object referred to by the native code.\nGlobal and Local References The JNI divides object references used by the native code into two categories: local and global references.\n Local references are valid for the duration of a native method call, and are automatically freed after the native method returns. Global references remain valid until they are explicitly freed.  Implementing Local References To implement local references, the Java VM creates a registry for each transition of control from Java to a native method. A registry maps nonmovable local references to Java objects, and keeps the objects from being garbage collected. All Java objects passed to the native method (including those that are returned as the results of JNI function calls) are automatically added to the registry. The registry is deleted after the native method returns, allowing all of its entries to be garbage collected.\n注册方式JNI_OnLoad extern \u0026#34;C\u0026#34; JNIEXPORT JNICALL jint JNI_OnLoad(JavaVM *vm, void *reserved) { JNIEnv *env; if (vm-\u0026gt;GetEnv(reinterpret_cast\u0026lt;void **\u0026gt;(\u0026amp;env), JNI_VERSION_1_6) != JNI_OK) { return -1; } } C调用java方法 static jmethodID g_callbackOnContentChange = nullptr; g_cls = reinterpret_cast\u0026lt;jclass\u0026gt;(env-\u0026gt;NewGlobalRef(instance)); if (!g_cls) { MMKVError(\u0026#34;fail to create global reference for %s\u0026#34;, clsName); return -3; } g_callbackOnContentChange = env-\u0026gt;GetStaticMethodID(g_cls, \u0026#34;onContentChangedByOuterProcess\u0026#34;, \u0026#34;(Ljava/lang/String;)V\u0026#34;); if (!g_callbackOnContentChange) { MMKVError(\u0026#34;fail to get method id for onContentChangedByOuterProcess()\u0026#34;); currentEnv-\u0026gt;CallStaticVoidMethod(g_cls, g_callbackOnContentChange, str); https://source.android.com/devices/tech/debug/native-memory\njava调用C，异常捕获 Within the JNI literature, the word exception appears to be used exclusively to refer to Java exceptions. Unexpected events in native code are referred to as programming errors. JNI explicitly does not require JVMs to check for programming errors. If a programming error occurs, behavior is undefined. Different JVMs may behave differently.\nIt\u0026rsquo;s the native code\u0026rsquo;s responsibility to translate all programming errors into either return codes or Java exceptions. Java exceptions don\u0026rsquo;t get thrown immediately from native code. They can be pending, only thrown once the native code returns to the Java caller. The native code can check for pending exceptions with ExceptionOccurred and clear them with ExceptionClear.\n//libnativehelper/include/nativehelper/JNIHelp.h inline int jniThrowRuntimeException(JNIEnv* env, const char* msg) { return jniThrowRuntimeException(\u0026amp;env-\u0026gt;functions, msg); } //libnativehelper/JNIHelp.c int jniThrowRuntimeException(JNIEnv* env, const char* msg) { return jniThrowException(env, \u0026#34;java/lang/RuntimeException\u0026#34;, msg); } int jniThrowException(JNIEnv* env, const char* className, const char* message) { DiscardPendingException(env, className); jclass exceptionClass = (*env)-\u0026gt;FindClass(env, className); if (exceptionClass == NULL) { ALOGE(\u0026#34;Unable to find exception class %s\u0026#34;, className); /* ClassNotFoundException now pending */ return -1; } int status = 0; if ((*env)-\u0026gt;ThrowNew(env, exceptionClass, message) != JNI_OK) { ALOGE(\u0026#34;Failed throwing \u0026#39;%s\u0026#39; \u0026#39;%s\u0026#39;\u0026#34;, className, message); /* an exception, most likely OOM, will now be pending */ status = -1; } (*env)-\u0026gt;DeleteLocalRef(env, exceptionClass); return status; } //art/runtime/jni/jni_internal.cc  static jint ThrowNew(JNIEnv* env, jclass c, const char* msg) { return ThrowNewException(env, c, msg, nullptr); } int ThrowNewException(JNIEnv* env, jclass exception_class, const char* msg, jobject cause) REQUIRES(!Locks::mutator_lock_) { jmethodID mid = env-\u0026gt;GetMethodID(exception_class, \u0026#34;\u0026lt;init\u0026gt;\u0026#34;, signature); ScopedLocalRef\u0026lt;jthrowable\u0026gt; exception( env, reinterpret_cast\u0026lt;jthrowable\u0026gt;(env-\u0026gt;NewObjectA(exception_class, mid, args))); ScopedObjectAccess soa(env); soa.Self()-\u0026gt;SetException(soa.Decodemirror::Throwable(exception.get())); } //art/runtime/thread.cc void Thread::SetException(ObjPtrmirror::Throwable new_exception) { CHECK(new_exception != nullptr); // TODO: DCHECK(!IsExceptionPending());  tlsPtr_.exception = new_exception.Ptr(); } 参考\u0026laquo;OKHttp读取Socket流程.vsdx\u0026raquo;中系统对recvFrom jni调用的异常向java层抛出\nC调用java，异常捕获 if you invoke a Java method from JNI, calling ExceptionCheck afterwards will return JNI_TRUE if an exception was thrown by the Java.\nif you\u0026rsquo;re just invoking a JNI function (such as FindClass), ExceptionCheck will tell you if that failed in a way that leaves a pending exception (as FindClass will do on error).\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/jni/",
	"title": "jni",
	"tags": [],
	"description": "",
	"content": "jni 探索总结jni知识\n _解释执行7_0     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/jni/jni%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2/",
	"title": "Jni数据转换",
	"tags": [],
	"description": "",
	"content": "数据转换总结 graph TB jstring--\u0026gt;|soa.decode|mirror::String* mirror::String*--\u0026gt;|encode/AddLocalReference|jstring mirror::String*--\u0026gt;char* char*--\u0026gt;|mirror::String::AllocFromModifiedUtf8|mirror::String* jmethodid--\u0026gt;|decode|ArtMethod* ArtMethod*--\u0026gt;|encode|jmethodid jobject(\u0026quot;jobject/IndirectRef\u0026quot;)--\u0026gt;|decode|mirrorObject(\u0026quot;art::mirror::Object*\u0026quot;) mirrorObject--\u0026gt;|Assign/Compress|StackReference(\u0026quot;art::StackReference\u0026lt;mirror::Object\u0026gt;*\u0026quot;) StackReference--\u0026gt;|AsMirrorPtr/UnCompress|mirrorObject StackReference--\u0026gt;|OwnedBy|Handle(\u0026quot;art::Handle~T~\u0026quot;) StackHandleScope--\u0026gt;|Provided|Handle StackHandleScope--\u0026gt;|OwnsMulti|StackReference ThreadTlsPtr--\u0026gt;|OwnsLinkedList|StackHandleScope mirrorObject--\u0026gt;|encode|jobject HandleScope的作用 类设计 //8.2.2 ScopedObjectAccess等辅助类\nScopedObjectAccessAlreadyRunnable DecodeMethod ArtMethod* DecodeMethod(jmethodID mid) const SHARED_REQUIRES(Locks::mutator_lock_) { Locks::mutator_lock_-\u0026gt;AssertSharedHeld(Self()); return reinterpret_cast\u0026lt;ArtMethod*\u0026gt;(mid);//main  } EncodeMethod jmethodID EncodeMethod(ArtMethod* method) const SHARED_REQUIRES(Locks::mutator_lock_) { Locks::mutator_lock_-\u0026gt;AssertSharedHeld(Self()); return reinterpret_cast\u0026lt;jmethodID\u0026gt;(method);//main  } T AddLocalReference(mirror::Object* obj) /* * Add a local reference for an object to the indirect reference table associated with the * current stack frame. When the native function returns, the reference will be discarded. * * We need to allow the same reference to be added multiple times, and cope with nullptr. * * This will be called on otherwise unreferenced objects. We cannot do GC allocations here, and * it\u0026#39;s best if we don\u0026#39;t grab a mutex. */ template\u0026lt;typename T\u0026gt; T AddLocalReference(mirror::Object* obj) const SHARED_REQUIRES(Locks::mutator_lock_) { return obj == nullptr ? nullptr : Env()-\u0026gt;AddLocalReference\u0026lt;T\u0026gt;(obj); } T Decode(jobject obj) template\u0026lt;typename T\u0026gt; T Decode(jobject obj) const SHARED_REQUIRES(Locks::mutator_lock_) { Locks::mutator_lock_-\u0026gt;AssertSharedHeld(Self()); return down_cast\u0026lt;T\u0026gt;(Self()-\u0026gt;DecodeJObject(obj));//main  } jni_env_ext(-inl.h).h AddLocalReference // JNI local references. IndirectReferenceTable locals GUARDED_BY(Locks::mutator_lock_); template\u0026lt;typename T\u0026gt; inline T JNIEnvExt::AddLocalReference(mirror::Object* obj) { IndirectRef ref = locals.Add(local_ref_cookie, obj); return reinterpret_cast\u0026lt;T\u0026gt;(ref); } libnativehelper/include_jni/jni.h\njni.h 类型定义 /* Primitive types that match up with Java equivalents. */ typedef uint8_t jboolean; /* unsigned 8 bits */ typedef int8_t jbyte; /* signed 8 bits */ typedef uint16_t jchar; /* unsigned 16 bits */ typedef int16_t jshort; /* signed 16 bits */ typedef int32_t jint; /* signed 32 bits */ typedef int64_t jlong; /* signed 64 bits */ typedef float jfloat; /* 32-bit IEEE 754 */ typedef double jdouble; /* 64-bit IEEE 754 */ /* \u0026#34;cardinal indices and sizes\u0026#34; */ typedef jint jsize; class _jobject {}; class _jclass : public _jobject {}; class _jstring : public _jobject {}; class _jarray : public _jobject {}; class _jobjectArray : public _jarray {}; class _jbooleanArray : public _jarray {}; class _jbyteArray : public _jarray {}; class _jcharArray : public _jarray {}; class _jshortArray : public _jarray {}; class _jintArray : public _jarray {}; class _jlongArray : public _jarray {}; class _jfloatArray : public _jarray {}; class _jdoubleArray : public _jarray {}; class _jthrowable : public _jobject {}; typedef _jobject* jobject; typedef _jclass* jclass; typedef _jstring* jstring; typedef _jarray* jarray; typedef _jobjectArray* jobjectArray; typedef _jbooleanArray* jbooleanArray; typedef _jbyteArray* jbyteArray; typedef _jcharArray* jcharArray; typedef _jshortArray* jshortArray; typedef _jintArray* jintArray; typedef _jlongArray* jlongArray; typedef _jfloatArray* jfloatArray; typedef _jdoubleArray* jdoubleArray; typedef _jthrowable* jthrowable; typedef _jobject* jweak; struct _jfieldID; /* opaque structure */ typedef struct _jfieldID* jfieldID; /* field IDs */ struct _jmethodID; /* opaque structure */ typedef struct _jmethodID* jmethodID; /* method IDs */ JNINativeMethod typedef struct { const char* name; const char* signature; void* fnPtr; } JNINativeMethod; NewObject jobject NewObject(jclass clazz, jmethodID methodID, ...) { va_list args; va_start(args, methodID); jobject result = functions-\u0026gt;NewObjectV(this, clazz, methodID, args); va_end(args); return result; } libnativehelper/platform_include/nativehelper/jni_macros.h\nNATIVE_METHOD #define NATIVE_METHOD(className, functionName, signature) \\ MAKE_JNI_NATIVE_METHOD(#functionName, signature, className ## _ ## functionName) //java方法对应的native实现函数方法名规范 art/runtime/jni_internal.cc\njni_internal.cc GetStringUTFChars static const char* GetStringUTFChars(JNIEnv* env, jstring java_string, jboolean* is_copy) { if (is_copy != nullptr) { *is_copy = JNI_TRUE; } ScopedObjectAccess soa(env); ObjPtr\u0026lt;mirror::String\u0026gt; s = soa.Decode\u0026lt;mirror::String\u0026gt;(java_string); size_t byte_count = s-\u0026gt;GetUtfLength(); char* bytes = new char[byte_count + 1]; CHECK(bytes != nullptr); // bionic aborts anyway.  if (s-\u0026gt;IsCompressed()) { for (size_t i = 0; i \u0026lt; byte_count; ++i) { bytes[i] = s-\u0026gt;CharAt(i); } } else { const uint16_t* chars = s-\u0026gt;GetValue(); ConvertUtf16ToModifiedUtf8(bytes, byte_count, chars, s-\u0026gt;GetLength()); } bytes[byte_count] = \u0026#39;\\0\u0026#39;; return bytes; } ReleaseStringUTFChars static void ReleaseStringUTFChars(JNIEnv*, jstring, const char* chars) { delete[] chars; } NewStringUTF static jstring NewStringUTF(JNIEnv* env, const char* utf) { if (utf == nullptr) { return nullptr; } ScopedObjectAccess soa(env); mirror::String* result = mirror::String::AllocFromModifiedUtf8(soa.Self(), utf); return soa.AddLocalReference\u0026lt;jstring\u0026gt;(result); } NewObjectV static jobject NewObjectV(JNIEnv* env, jclass java_class, jmethodID mid, va_list args) { CHECK_NON_NULL_ARGUMENT(java_class); CHECK_NON_NULL_ARGUMENT(mid); ScopedObjectAccess soa(env); mirror::Class* c = EnsureInitialized(soa.Self(), soa.Decode\u0026lt;mirror::Class*\u0026gt;(java_class)); if (c == nullptr) { return nullptr; } if (c-\u0026gt;IsStringClass()) { // Replace calls to String.\u0026lt;init\u0026gt; with equivalent StringFactory call.  jmethodID sf_mid = WellKnownClasses::StringInitToStringFactoryMethodID(mid); return CallStaticObjectMethodV(env, WellKnownClasses::java_lang_StringFactory, sf_mid, args); } mirror::Object* result = c-\u0026gt;AllocObject(soa.Self()); if (result == nullptr) { return nullptr; } jobject local_result = soa.AddLocalReference\u0026lt;jobject\u0026gt;(result); CallNonvirtualVoidMethodV(env, local_result, java_class, mid, args); if (soa.Self()-\u0026gt;IsExceptionPending()) { return nullptr; } return local_result; art/runtime/thread.cc\nthread.cc GetTopHandleScope HandleScope* GetTopHandleScope() { return tlsPtr_.top_handle_scope; } PushHandleScope void PushHandleScope(HandleScope* handle_scope) { DCHECK_EQ(handle_scope-\u0026gt;GetLink(), tlsPtr_.top_handle_scope); tlsPtr_.top_handle_scope = handle_scope; } DecodeJObject ObjPtr\u0026lt;mirror::Object\u0026gt; Thread::DecodeJObject(jobject obj) const { if (obj == nullptr) { return nullptr; } //将jobject转换为IndirectRef  IndirectRef ref = reinterpret_cast\u0026lt;IndirectRef\u0026gt;(obj); IndirectRefKind kind = IndirectReferenceTable::GetIndirectRefKind(ref); ObjPtr\u0026lt;mirror::Object\u0026gt; result; bool expect_null = false; // The \u0026#34;kinds\u0026#34; below are sorted by the frequency we expect to encounter them.  if (kind == kLocal) {//如果是local型引用，则从local的IRTable中找到对应的对象  IndirectReferenceTable\u0026amp; locals = tlsPtr_.jni_env-\u0026gt;locals_; // Local references do not need a read barrier.  result = locals.Get\u0026lt;kWithoutReadBarrier\u0026gt;(ref); } else if (kind == kHandleScopeOrInvalid) { // TODO: make stack indirect reference table lookup more efficient.  // Check if this is a local reference in the handle scope.  if (LIKELY(HandleScopeContains(obj))) { //如果是栈上传递过来的对象(如方法参数)，则可以直接转换成mirror Object对象  // Read from handle scope.  result = reinterpret_cast\u0026lt;StackReference\u0026lt;mirror::Object\u0026gt;*\u0026gt;(obj)-\u0026gt;AsMirrorPtr(); VerifyObject(result); } else { tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;JniAbortF(nullptr, \u0026#34;use of invalid jobject %p\u0026#34;, obj); expect_null = true; result = nullptr; } } else if (kind == kGlobal) { //对Global型对象的处理，想必是要交给JavaVMExt globals_来处理  result = tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;DecodeGlobal(ref); } else {//对WeakGlobal型对象的处理，如果该对象已经回收，则返回nullptr  DCHECK_EQ(kind, kWeakGlobal); result = tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;DecodeWeakGlobal(const_cast\u0026lt;Thread*\u0026gt;(this), ref); if (Runtime::Current()-\u0026gt;IsClearedJniWeakGlobal(result)) { //对象被回收了，所以返回nullptr  // This is a special case where it\u0026#39;s okay to return null.  expect_null = true; result = nullptr; } } if (UNLIKELY(!expect_null \u0026amp;\u0026amp; result == nullptr)) { tlsPtr_.jni_env-\u0026gt;vm_-\u0026gt;JniAbortF(nullptr, \u0026#34;use of deleted %s %p\u0026#34;, ToStr\u0026lt;IndirectRefKind\u0026gt;(kind).c_str(), obj); } return result; } indirect_reference_table(-inl).h IrtEntry* const table_; size_t i_; const size_t capacity_; Get template\u0026lt;ReadBarrierOption kReadBarrierOption\u0026gt; inline mirror::Object* IndirectReferenceTable::Get(IndirectRef iref) const { if (!GetChecked(iref)) { return nullptr; } uint32_t idx = ExtractIndex(iref); mirror::Object* obj = table_[idx].GetReference()-\u0026gt;Read\u0026lt;kReadBarrierOption\u0026gt;(); VerifyObject(obj); return obj; } Add IndirectRef IndirectReferenceTable::Add(uint32_t cookie, mirror::Object* obj) { // We know there\u0026#39;s enough room in the table. Now we just need to find  // the right spot. If there\u0026#39;s a hole, find it and fill it; otherwise,  // add to the end of the list.  IndirectRef result; ...... table_[index].Add(obj); result = ToIndirectRef(index); return result; ToIndirectRef /* * The object pointer itself is subject to relocation in some GC * implementations, so we shouldn\u0026#39;t really be using it here. */ IndirectRef ToIndirectRef(uint32_t tableIndex) const { DCHECK_LT(tableIndex, 65536U); uint32_t serialChunk = table_[tableIndex].GetSerial(); uintptr_t uref = (serialChunk \u0026lt;\u0026lt; 20) | (tableIndex \u0026lt;\u0026lt; 2) | kind_; return reinterpret_cast\u0026lt;IndirectRef\u0026gt;(uref); } class IrtEntry class IrtEntry { void Add(mirror::Object* obj) SHARED_REQUIRES(Locks::mutator_lock_) { ++serial_; if (serial_ == kIRTPrevCount) { serial_ = 0; } references_[serial_] = GcRoot\u0026lt;mirror::Object\u0026gt;(obj); } GcRoot\u0026lt;mirror::Object\u0026gt;* GetReference() { DCHECK_LT(serial_, kIRTPrevCount); return \u0026amp;references_[serial_]; } void SetReference(mirror::Object* obj) { DCHECK_LT(serial_, kIRTPrevCount); references_[serial_] = GcRoot\u0026lt;mirror::Object\u0026gt;(obj); } private: uint32_t serial_; GcRoot\u0026lt;mirror::Object\u0026gt; references_[kIRTPrevCount]; } Gc_root.h template\u0026lt;class MirrorType\u0026gt; class GcRoot { public: template\u0026lt;ReadBarrierOption kReadBarrierOption = kWithReadBarrier\u0026gt; ALWAYS_INLINE MirrorType* Read(GcRootSource* gc_root_source = nullptr) const SHARED_REQUIRES(Locks::mutator_lock_); art/rumtime/mirror/String.h\nmirror/String.h GetValue uint16_t value_[0]; uint16_t* GetValue() SHARED_REQUIRES(Locks::mutator_lock_) { return \u0026amp;value_[0]; } art/runtime/native/java_lang_reflect_Method.cc\nava_lang_reflect_Method.cc Method_invoke static jobject Method_invoke(JNIEnv* env, jobject javaMethod, jobject javaReceiver, jobjectArray javaArgs) { ScopedFastNativeObjectAccess soa(env); return InvokeMethod(soa, javaMethod, javaReceiver, javaArgs); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/jvm_jit/",
	"title": "JVM_JIT",
	"tags": [],
	"description": "",
	"content": "JVM解释器和编译器 JVM：JVM有自己完善的硬件架构，如处理器、堆栈（Stack）、寄存器等，还具有相应的指令系统（字节码就是一种指令格式）。JVM屏蔽了与具体操作系统平台相关的信息，使得Java程序只需要生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。JVM是Java平台无关的基础。JVM负责运行字节码：JVM把每一条要执行的字节码交给解释器，翻译成对应的机器码，然后由解释器执行。JVM解释执行字节码文件就是JVM操作Java解释器进行解释执行字节码文件的过程。\nJava编译器：将Java源文件（.java文件）编译成字节码文件（.class文件，是特殊的二进制文件，二进制字节码文件），这种字节码就是JVM的“机器语言”。javac.exe可以简单看成是Java编译器。\nJava解释器：是JVM的一部分。Java解释器用来解释执行Java编译器编译后的程序。java.exe可以简单看成是Java解释器。\n注意：通常情况下，一个平台上的二进制可执行文件不能在其他平台上工作，因为此可执行文件包含了对目标处理器的机器语言。而Class文件这种特殊的二进制文件，是可以运行在任何支持Java虚拟机的硬件平台和操作系统上的！\n维基百科定义：\nJVM：一种能够运行Java字节码（Java bytecode）的虚拟机。\n字节码：字节码是已经经过编译，但与特定机器码无关，需要解释器转译后才能成为机器码的中间代码。\nJava字节码：是Java虚拟机执行的一种指令格式。\n解释器：是一种电脑程序，能够把高级编程语言一行一行直接翻译运行。解释器不会一次把整个程序翻译出来，只像一位“中间人”，每次运行程序时都要先转成另一种语言再作运行，因此解释器的程序运行速度比较缓慢。它每翻译一行程序叙述就立刻运行，然后再翻译下一行，再运行，如此不停地进行下去。它会先将源码翻译成另一种语言，以供多次运行而无需再经编译。其制成品无需依赖编译器而运行，程序运行速度比较快。\n即时编译(Just-in-time compilation: JIT)：又叫实时编译、及时编译。是指一种在运行时期把字节码编译成原生机器码的技术，一句一句翻译源代码，但是会将翻译过的代码缓存起来以降低性能耗损。这项技术是被用来改善虚拟机的性能的。\nJIT编译器是JRE的一部分。原本的Java程序都是要经过解释执行的，其执行速度肯定比可执行的二进制字节码程序慢。为了提高执行速度，引入了JIT。在运行时，JIT会把翻译过来的机器码保存起来，以备下次使用。而如果JIT对每条字节码都进行编译，则会负担过重，所以，JIT只会对经常执行的字节码进行编译，如循环，高频度使用的方法等。它会以整个方法为单位，一次性将整个方法的字节码编译为本地机器码，然后直接运行编译后的机器码。\n 深入理解java虚拟机（程序编译与代码优化）\n编译对象与触发条件 编译对象 程序在运行过程中会被即时编译器编译的「热点代码」有两类：\n 被多次调用的方法； 被多次执行的循环体。 这两种被多次重复执行的代码，称之为「热点代码」。  对于被多次调用的方法，方法体内的代码自然会被执行多次，理所当然的就是热点代码。\n而对于多次执行的循环体则是为了解决一个方法只被调用一次或者少量几次，但是方法体内部存在循环次数较多的循环体问题，这样循环体的代码也被重复执行多次，因此这些代码也是热点代码。\n对于第一种情况，由于是方法调用触发的编译，因此编译器理所当然地会以整个方法作为编译对象，这种编译也是虚拟机中标准的 JIT 编译方式。而对于后一种情况，尽管编译动作是由循环体所触发的，但是编译器依然会以整个方法（而不是单独的循环体）作为编译对象。这种编译方式因为发生在方法执行过程中，因此形象地称之为栈上替换（On Stack Replacement，简称 OSR 编译，即方法栈帧还在栈上，方法就被替换了）。\n即时编译器的触发条件 判断一段代码是不是热点代码，是不是需要触发即时编译，这样的行为称为「热点探测」。其实进行热点探测并不一定需要知道方法具体被调用了多少次，目前主要的热点探测判定方式有两种。\n  基于采样的热点探测：采用这种方法的虚拟机会周期性地检查各个线程栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是「热点方法」。基于采样的热点探测的好处是实现简单、高效，还可以很容易地获取方法调用关系（将调用栈展开即可），缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因数的影响而扰乱热点探测。\n  基于计数器的热点探测：采用这种方法的虚拟机会为每个方法（甚至代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是「热点方法」。这种统计方法实现起来麻烦一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是统计结果相对来说更加精确和严谨。\n  HotSpot 虚拟机采用的是第二种：基于计数器的热点探测。因此它为每个方法准备了两类计数器：方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）。在确定虚拟机运行参数的情况下，这两个计数器都有一个确定的阈值，当计数器超过阈值就会触发 JIT 编译。\n方法调用计数器 顾名思义，这个计数器用于统计方法被调用的次数。当一个方法被调用时，会首先检查该方法是否存在被 JIT 编译过的版本，如果存在，则优先使用编译后的本地代码来执行。如果不存在，则将此方法的调用计数器加 1，==然后判断方法调用计数器与回边计数器之和是否超过方法调用计数器的阈值==。如果超过阈值，将会向即时编译器提交一个该方法的代码编译请求。\n如果不做任何设置，执行引擎不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成。当编译完成后，这个方法的调用入口地址就会被系统自动改写成新的，下一次调用该方法时就会使用已编译的版本。\n热度衰减 如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间内方法调用的次数。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的调用计数器值就会被减少一半，这个过程称为方法调用计数器热度的衰减，而这段时间就称为此方法统计的==半衰期==。\n进行热度衰减的动作是在虚拟机进行 GC 时顺便进行的，可以设置虚拟机参数来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。此外还可以设置虚拟机参数调整半衰期的时间。\n回边计数器 回边计数器的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为「回边」（Back Edge）。建立回边计数器统计的目的是为了触发 OSR 编译。\n当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否已经有编译好的版本，如果有，它将优先执行已编译的代码，否则就把回边计数器值加 1，然后判断方法调用计数器和回边计数器值之和是否超过计数器的阈值。当超过阈值时，将会提交一个 OSR 编译请求，并且把回边计数器的值降低一些，以便继续在解释器中执行循环，等待编译器输出编译结果。\n与方法计数器不同，回边计数器没有计算热度衰减的过程，因此这个计数器统计的就是该方法循环执行的绝对次数。当计数器溢出时，它还会把方法计数器的值也调整到溢出状态，这样下次再进入该方法的时候就会执行标准编译过程。\n编译优化技术 我们都知道，以编译方式执行本地代码比解释执行方式更快，一方面是因为节约了虚拟机解释执行字节码额外消耗的时间；另一方面是因为虚拟机设计团队几乎把所有对代码的优化措施都集中到了即时编译器中。这一小节我们来介绍下 HotSpot 虚拟机的即时编译器在编译代码时采用的优化技术。\n方法内联 第一步是进行方法内联（Method Inlining），方法内联的重要性要高于其它优化措施。方法内联的目的主要有两个，一是去除方法调用的成本（比如建立栈帧），二是为其它优化建立良好的基础，方法内联膨胀之后可以便于更大范围上采取后续的优化手段，从而获得更好的优化效果。因此，各种编译器一般都会把内联优化放在优化序列的最前面\n冗余消除 第二步进行冗余消除\n复写传播 第三步进行复写传播\n无用代码消除 第四步进行无用代码消除\n 公共子表达式消除； 数组边界检查消除； 方法内联； 逃逸分析。  JIT Code Cache https://docs.oracle.com/javase/8/embedded/develop-apps-platforms/codecache.htm\n15 Codecache Tuning This chapter describes techniques for reducing the just-in-time (JIT) compiler\u0026rsquo;s consumption of memory in the codecache, where it stores compiled methods.\nThis chapter contains the following topics:\nIntroduction\njava Launcher Codecache Option Summary\nMeasuring Codecache Usage\nConstraining the Codecache Size\nReducing Compilations\nReducing Compiled Method Sizes\nIntroduction The Java Virtual Machine (JVM) generates native code and ==stores it in a memory area called the codecache==. The JVM generates native code for a variety of reasons, including for the dynamically generated interpreter loop, Java Native Interface (JNI) stubs, and for Java methods that are compiled into native code by the just-in-time (JIT) compiler. The JIT is by far the biggest user of the codecache. This appendix describes techniques for reducing the JIT compiler\u0026rsquo;s codecache usage while still maintaining good performance.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/kaptgenerateviewmodel/",
	"title": "KaptGenerateViewModel",
	"tags": [],
	"description": "",
	"content": "Kapt编译时生成Viewmodel Android架构组件拥有生命周期的自动管理和数据解耦等优秀的功能，能够将传统MVP架构进行替换。在使用架构组件的过程中，我采用的方式是首先完成基础类\nT 表示对应的retrofit service类型\nabstract class BaseViewModel\u0026lt;T\u0026gt;(application: Application) : AndroidViewModel(application) { 之后针对Retrofit中的不同Service interface，继承并实现具体的viewmodel类，并针对每个service接口，需要编写一个liveData字段和对应的get或post方法提供给app层调用，同时对应的方法可能会存在三种类型:\n1:直接调用service进行网络获取 package com.xxx.xxx.architecture.xxx import android.app.Application import android.arch.lifecycle.MediatorLiveData import com.baseproject.architecture.BaseViewModel import com.xxx.xxx.appbase.BaseAppLiveDataObserver /** * This file is generated by kapt, please do not edit this file */ open class BaseAnchorServiceViewModel(application: Application) : BaseViewModel\u0026lt;AnchorService\u0026gt;(application) { val getHotAnchorListLiveData: MediatorLiveData\u0026lt;kotlin.collections.List\u0026lt;SearchHotAnchorModel\u0026gt;\u0026gt; by lazy { MediatorLiveData\u0026lt;kotlin.collections.List\u0026lt;SearchHotAnchorModel\u0026gt;\u0026gt;() } fun getHotAnchorList() { mService.getHotAnchorList().subscribe(BaseAppLiveDataObserver(getHotAnchorListLiveData)) } } 2：使用本地缓存展示之后进行网络获取更新 val getUserAssetsLiveData: MediatorLiveData\u0026lt;UserAssetsModel\u0026gt; by lazy { MediatorLiveData\u0026lt;UserAssetsModel\u0026gt;() } fun getUserAssets() { object : BaseAppNetworkBoundResource\u0026lt;UserAssetsModel\u0026gt;(getUserAssetsLiveData) { override fun doApiCall(): Observable\u0026lt;UserAssetsModel\u0026gt; { return mService.getUserAssets()}} } 3:使用json类型的数据post，也会造成所需方法写法上的差异 val postRewardReceiveLiveData: MediatorLiveData\u0026lt;PostRewardReceiveModel\u0026gt; by lazy { MediatorLiveData\u0026lt;PostRewardReceiveModel\u0026gt;() } fun postRewardReceive(reward_ids: List\u0026lt;Int\u0026gt;, anchor_id: String) { val params = BaseJSONObject().put(\u0026#34;reward_ids\u0026#34;,reward_ids).put(\u0026#34;anchor_id\u0026#34;,anchor_id) mService.postRewardReceive(RequestBody.create(MediaType.parse(\u0026#34;application/json\u0026#34;), params.toString())).subscribe(BaseAppLiveDataObserver(postRewardReceiveLiveData)) } 不同的方式有很多共同之处，因此我采用kapt注解的方式一键生成相关代码，大大优化了开发效率，项目地址:\nhttps://github.com/huanle19891345/kapt_viewmodel\n欢迎指教\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/kernel/",
	"title": "kernel",
	"tags": [],
	"description": "",
	"content": "kernel 探索总结kernel知识\n kernel     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/kernel/kernel/",
	"title": "kernel",
	"tags": [],
	"description": "",
	"content": "下载和编译内核步骤 Android 9.0内核编译\n下载内核 cd kernel git clone https://android.googlesource.com/kernel/goldfish 执行完这两条命令后就可以看到kernel目录下有一个goldfish目录了,goldfish内核专门是提供给emulator用的.\ncd goldfish git branch -r git checkout origin/android-goldfish-4.4-dev -b android-goldfish-4.4-dev 这里涉及到要下载哪个版本的内核,emulator命令默认用的是qemu内核, 一般跟这个版本的内核一样就可以了,可以直接启用emulator然后进入到Settings-\u0026gt;System-\u0026gt;About phone-\u0026gt;点击Android version,里面就有内核版本号.\n编译内核 一定要和Android编译时lunch选的一样, 可以进入到out/target/product目录下查看自己编的是什么版本, 如果是generic_x86_64,那lunch的就是aosp_x86_64_eng的,其他版本依此类推. 接下来就可以编译了,下面我提供了几个编译的脚本大家可以进行对比和参照,lunch不同的版本对应的脚本是不一样的,即使编译通过了,也不能运行,我因为这个浪费了很长的时间 使用方法:\n 在goldfish目录下创建一个build.sh文件 将脚本里面的内容复制到build.sh中,或者根据脚本自己写, 注意lunch的版本 执行chmod a+rx build.sh并且执行./build.sh.  aosp_x86-eng #指定编译的内核类型 export ARCH=x86 #指定的gcc编译器的前缀, 就是下面PATH中的x86_64-linux-android-4.9的前缀 export CROSS_COMPILE=x86_64-linux-android- export REAL_CROSS_COMPILE=x86_64-linux-android- #这里android_root要写是android根目录的绝对地址例如: ~/google/android-9.0 PATH=$PATH:/home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gcc/linux-x86/x86/x86_64-linux-android-4.9/bin #编译的配置,在arch/x86/configs目录下, make x86_64_ranchu_defconfig #编译内核命令 make -j16 编译内核大概10来分钟就可以完成了,之后会生成一个arch/x86_64/boot/bzImage的东西,不同kernel生成的是不一样的,要看清楚. 最后回到android根目录执行emulator -kernel kernel/goldfish/arch/x86/boot/bzImage启动虚拟机\n启动虚拟机 ~/Android/Source/android-9.0.0_r3$ emulator -show-kernel -kernel /home/zhenghuan/Android/Source/kernel/goldfish/arch/x86/boot/bzImage -qemu -s  -kernel use specific emulated kernel 指定模拟器的内核，这里指定我们自己编译的内核arch/x86/boot/bzImage -qemu args... pass arguments to qemu 传递qemu参数，emulator就是基于qemu开发的 -s 是qemu参数，等同于-gdb tcp::1234，意思就是通过tcp的1234端口，gdb可以连接到内核中的kgdb。一般连接kgdb都要通过串口来连接，但是qemu通过指定-gdb tcp::1234就可以了，不知到原理是什么。  调试android内核 使用Android模拟器调试linux内核\n如何在Android上调试内核 在Android上调试内核，一般都要借助于内核中的kgdb。kgdb是内核对gdb的支持，通过编译配置kgdb和其他相关配置，可以通过gdb远程连接到内核中的kgdb。kgdb只能远程调试，也就是说，要有一台被调试的机器(target machine)和一台开发机器(develop machine)。如果真机调试，target就是手机，develop就是ubuntu主机。如果是模拟器调试，target就是模拟器，develop是ubuntu主机。\n步骤 goldfish/.config编译选项 CONFIG_DEBUG_KERNEL=y 打开这个选项后，vmlinux 才有符号 CONFIG_DEBUG_INFO=y CONFIG_FRAME_POINTER=y //开启kgdb CONFIG_KGDB=y CONFIG_DEBUG_RODATA=n CONFIG_RANDOMIZE_BASE=n CONFIG_DEBUG_RODATA这个选项我们虽然手动设置为n，但是执行make后会被覆盖，所以我们要改以下两个文件，确保CONFIG_DEBUG_RODATA不开启:\nzhangjg@zjg:~/deve/open_source/android-kernel/goldfish$ git diff diff --git a/arch/arm/mm/Kconfig b/arch/arm/mm/Kconfig index 41218867a9a6..e67810313d97 100644 --- a/arch/arm/mm/Kconfig +++ b/arch/arm/mm/Kconfig @@ -1052,7 +1052,7 @@ config ARM_KERNMEM_PERMS config DEBUG_RODATA bool \u0026#34;Make kernel text and rodata read-only\u0026#34; depends on ARM_KERNMEM_PERMS - default y + default n help If this is set, kernel text and rodata will be made read-only. This is to help catch accidental or malicious attempts to change the diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig index ad1f3bfafe75..50fa4dc68eff 100644 --- a/arch/x86/Kconfig +++ b/arch/x86/Kconfig @@ -307,7 +307,7 @@ config FIX_EARLYCON_MEM def_bool y config DEBUG_RODATA - def_bool y + def_bool n config PGTABLE_LEVELS int 注意，一定确保CONFIG_DEBUG_RODATA和CONFIG_RANDOMIZE_BASE不开启，如果开启这两个选项，通过gdb不能设置断点，报如下错误:\n(gdb) b vfs_write Breakpoint 1 at 0xffffffff803474d8: file fs/read_write.c, line 524. (gdb) c Continuing. Warning: Cannot insert breakpoint 1. Cannot access memory at address 0xffffffff803474d8 make -j16 Serial console over KGDB NMI debugger port (SERIAL_KGDB_NMI) [N/y/?] (NEW) N KGDB: kernel debugger (KGDB) [Y/n/?] y KGDB: use kgdb over the serial console (KGDB_SERIAL_CONSOLE) [Y/n/m/?] (NEW) n KGDB: internal test suite (KGDB_TESTS) [N/y/?] (NEW) N KGDB: Allow debugging with traps in notifiers (KGDB_LOW_LEVEL_TRAP) [N/y/?] (NEW) N KGDB_KDB: include kdb frontend for kgdb (KGDB_KDB) [N/y/?] (NEW) y KDB: Select kdb command functions to be enabled by default (KDB_DEFAULT_ENABLE) [0x1] (NEW) 0x1 KGDB_KDB: keyboard as input device (KDB_KEYBOARD) [N/y/?] (NEW) y KDB: continue after catastrophic errors (KDB_CONTINUE_CATASTROPHIC) [0] (NEW) 0 Kernel: arch/x86/boot/bzImage is ready (#2) ton在内核源码根目录生成vmlinux文件 启动虚拟机 gdb /path/to/vmlinux 最好使用aosp/prebuilts/gdb/linux-x86里的gdb，这个版本的gdb是兼容所有体系结构的。 gdb命令在aosp/prebuilts/gdb/linux-x86/bin目录中\n~/Android/Source/kernel/goldfish$ export PATH=/home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gdb/linux-x86/bin:$PATH ~/Android/Source/kernel/goldfish$ which gdb /home/zhenghuan/Android/Source/android-9.0.0_r3/prebuilts/gdb/linux-x86/bin/gdb ~/Android/Source/kernel/goldfish$ gdb ./vmlinux GNU gdb (GDB) 7.11 Copyright (C) 2016 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-linux-gnu\u0026#34;. Type \u0026#34;show configuration\u0026#34; for configuration details. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;. Find the GDB manual and other documentation resources online at: \u0026lt;http://www.gnu.org/software/gdb/documentation/\u0026gt;. For help, type \u0026#34;help\u0026#34;. Type \u0026#34;apropos word\u0026#34; to search for commands related to \u0026#34;word\u0026#34;... Reading symbols from ./vmlinux...done. (gdb) target remote :1234 Remote debugging using :1234 0xffffffff834345e8 in ?? () (gdb) bt #0 0xffffffff834345e8 in ?? () #1 0xffffffff84003ec8 in ?? () #2 0xffffffff8340c0d9 in ?? () #3 0x0000000000000000 in ?? () 调试效果 可以设置断点并进入断点停下，但无法next和step(step有概率能成功)单步跳转,总是跳转到apic模块，考虑使用走读+断点调试的方式研究\n其他 全局修改编译优化，位于goldfish/Makefile:\n#ifdef CONFIG_CC_OPTIMIZE_FOR_SIZE #KBUILD_CFLAGS\t+= $(call cc-option,-Oz,-Os) #else #ifdef CONFIG_PROFILE_ALL_BRANCHES #KBUILD_CFLAGS\t+= -O2 #else #KBUILD_CFLAGS += -O2 #endif #endif KBUILD_CFLAGS += -Og  https://github.com/torvalds/linux\nhttps://source.android.com/setup/build/building-kernels\nhttps://source.android.com/devices/architecture/kernel\nhttps://android.googlesource.com/kernel/common/\n下载时Repo Branches选择common-android-4.14\nBuilding Kernels This page details the process of building custom kernels for Android devices. The following instructions guide you through the process of selecting the right sources, building the kernel, and embedding the results into a system image built from the Android Open Source Project (AOSP).\n android版本与linux内核版本对应关系\nhttps://blog.csdn.net/ly890700/article/details/75040704/\n6.0 Marshmallow |23 |3.18.10\nAndroid安卓版本 | API级别 | Linux内核版本 ——————————————————————- 1.5 Cupcake | 3 | 2.6.27 1.6 Donut | 4 | 2.6.29 2.0/1 Eclair | 5-7 | 2.6.29 2.2.x Froyo | 8 | 2.6.32 2.3.x Gingerbread | 9, 10 | 2.6.35 3.x.x Honeycomb | 11-13 | 2.6.36 4.0.x Ice Cream San | 14, 15 | 3.0.1 4.1.x Jelly Bean | 16 | 3.0.31 4.2.x Jelly Bean | 17 | 3.4.0 4.3 Jelly Bean | 18 | 3.4.39 4.4 Kit Kat | 19, 20 | 3.10 5.x Lollipop | 21, 22 | 3.16.1 6.0 Marshmallow | 23 | 3.18.10 7.0 Nougat | 24 | 4.4.1 7.1 Nougat | 25 | 4.4.1 8.0 Oreo | 26 | 4.10 8.1 Oreo | 27 | 4.10 9.0 Pie | 28 | 4.4, 4.9 and 4.14\n"
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/",
	"title": "kotlin",
	"tags": [],
	"description": "",
	"content": "kotlin 探索总结kotlin知识\n coroutine    kotlin协程     kotlin协程Source     kotlin协程取消     kotlin协程异常     使用挂起函数来封装回调      "
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/coroutine/kotlin%E5%8D%8F%E7%A8%8B/",
	"title": "kotlin协程",
	"tags": [],
	"description": "",
	"content": "协程是通过编译技术实现(不需要虚拟机VM/操作系统OS的支持),通过插入相关代码来生效！ 与之相反,线程/进程是需要虚拟机VM/操作系统OS的支持,通过调度CPU执行生效!\n优秀文章 Kotlin Coroutines(协程) 完全解析（一），协程简介\nKotlin Coroutines(协程) 完全解析（二），深入理解协程的挂起、恢复与调度\nKotlin Coroutines(协程) 完全解析（三），封装异步回调、协程间关系及协程的取消\nKotlin Coroutines(协程) 完全解析（四），协程的异常处理\nKotlin Coroutines(协程) 完全解析（五），协程的并发\nStructured concurrency\n谷歌开发者 在 android 开发中使用协程 | 背景介绍\n协程中的取消和异常 | 异常处理详解\n官网doc 英文:\nhttps://kotlinlang.org/docs/reference/coroutines/basics.html\nhttps://github.com/Kotlin/kotlinx.coroutines/blob/master/docs/coroutines-guide.md\nhttps://github.com/Kotlin/KEEP/blob/master/proposals/coroutines.md\n中文:\nhttps://www.kotlincn.net/docs/reference/coroutines/coroutines-guide.html\n和Android Jetpack结合 https://developer.android.com/topic/libraries/architecture/coroutines#lifecyclescope\nhttps://developer.android.google.cn/kotlin/coroutines\n异步编程模型 异步的含义是被调用的方法执行完之后，无法直接拿到返回值(切换了线程)，需要通过回调接收返回值\n协程相当于提前切换到子线程，然后同步走逻辑，进而改变每一层的异步调用为同步，\n协程将同步方法和线程切换两者相隔离，所有方法都是同步方法，单独控制执行线程，避免异步方法去接收回调参数\n区别：\n 回调调用时机: 回调接口可以有多个method，并在不同时机调用(对应的也可以在return对象中区分处理) 回调方法参数: 可以封装成method的return参数， 调用方上下文: 需要利用调用方的上下文(提供变量等)  异步回调 fun requestTokenAsync(cb: (Token) -\u0026gt; Unit) { ... } fun createPostAsync(token: Token, item: Item, cb: (Post) -\u0026gt; Unit) { ... } fun processPost(post: Post) { ... } fun postItem(item: Item) { requestTokenAsync { token -\u0026gt; createPostAsync(token, item) { post -\u0026gt; processPost(post) } } } CompletableFuture and Rx fun requestTokenAsync(): CompletableFuture\u0026lt;Token\u0026gt; { ... } fun createPostAsync(token: Token, item: Item): CompletableFuture\u0026lt;Post\u0026gt; { ... } fun processPost(post: Post) { ... } fun postItem(item: Item) { requestTokenAsync() .thenCompose { token -\u0026gt; createPostAsync(token, item) } .thenAccept { post -\u0026gt; processPost(post) } .exceptionally { e -\u0026gt; e.printStackTrace() null } } fun requestToken(): Token { ... } fun createPost(token: Token, item: Item): Post { ... } fun processPost(post: Post) { ... } fun postItem(item: Item) { Single.fromCallable { requestToken() } .map { token -\u0026gt; createPost(token, item) } .subscribe( { post -\u0026gt; processPost(post) }, // onSuccess  { e -\u0026gt; e.printStackTrace() } // onError  ) } 协程-同步函数返回 suspend fun requestToken(): Token { ... } // 挂起函数 suspend fun createPost(token: Token, item: Item): Post { ... } // 挂起函数 fun processPost(post: Post) { ... } fun postItem(item: Item) { GlobalScope.launch { val token = requestToken() val post = createPost(token, item) processPost(post) // 需要异常处理，直接加上 try/catch 语句即可  } } 协程恢复resume 协程的挂起通过suspend挂起函数实现，协程的恢复通过Continuation.resumeWith实现。\nsuspend fun requestToken(): Token { ... } 实际上在 JVM 中更像下面这样：\nObject requestToken(Continuation\u0026lt;Token\u0026gt; cont) { ... } Continuation的定义如下，类似于一个通用的回调接口：\n/** * Interface representing a continuation after a suspension point that returns value of type `T`. */ public interface Continuation\u0026lt;in T\u0026gt; { /** * Context of the coroutine that corresponds to this continuation. */ public val context: CoroutineContext /** * Resumes the execution of the corresponding coroutine passing successful or failed [result] as the * return value of the last suspension point. */ public fun resumeWith(result: Result\u0026lt;T\u0026gt;) } 现在再看之前postItem函数：\nsuspend fun requestToken(): Token { ... } // 挂起函数 suspend fun createPost(token: Token, item: Item): Post { ... } // 挂起函数 fun processPost(post: Post) { ... } fun postItem(item: Item) { GlobalScope.launch { val token = requestToken() val post = createPost(token, item) processPost(post) } } 然而，协程内部实现不是使用普通回调的形式，而是使用状态机来处理不同的挂起点，大致的 CPS(Continuation Passing Style) 代码为：\n// 编译后生成的内部类大致如下 final class postItem$1 extends SuspendLambda ... { public final Object invokeSuspend(Object result) { ... switch (this.label) { case 0: this.label = 1; token = requestToken(this) break; case 1: this.label = 2; Token token = result; post = createPost(token, this.item, this) break; case 2: Post post = result; processPost(post) break; } } } 上面代码中每一个挂起点和初始挂起点对应的 Continuation 都会转化为一种状态，协程恢复只是跳转到下一种状态中。挂起函数将执行过程分为多个 Continuation 片段，并且利用状态机的方式保证各个片段是顺序执行的。\n协程之间的关系 父协程手动调用cancel()或者异常结束，会立即取消它的所有子协程 父协程必须等待所有子协程完成（处于完成或者取消状态）才能完成 子协程抛出未捕获的异常时，默认情况下会取消其父协程。 Executor.asCoroutineDispatcher() https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/java.util.concurrent.-executor/as-coroutine-dispatcher.html\n"
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/coroutine/kotlin%E5%8D%8F%E7%A8%8Bsource/",
	"title": "kotlin协程Source",
	"tags": [],
	"description": "",
	"content": "总结 类设计 协程的三层包装  常用的launch和async返回的Job、Deferred，里面封装了协程状态，提供了取消协程接口，而它们的实例都是继承自AbstractCoroutine，它是协程的第一层包装。 第二层包装是编译器生成的SuspendLambda的子类，封装了协程的真正运算逻辑，继承自BaseContinuationImpl，其中completion属性就是协程的第一层包装。 第三层包装是前面分析协程的线程调度时提到的DispatchedContinuation，封装了线程调度逻辑，包含了协程的第二层包装。三层包装都实现了Continuation接口，通过代理模式将协程的各层包装组合在一起，每层负责不同的功能。  resumeWith CoroutineContext graph LR coroutineContext--\u0026gt;Element1[\u0026quot;Element1: a singleton context by itself.\u0026quot;] coroutineContext--\u0026gt;Element2[\u0026quot;Element2: a singleton context by itself.\u0026quot;] coroutineContext--\u0026gt;ContinuationInterceptor[\u0026quot;ContinuationInterceptor: DefaultDispatcher.\u0026quot;] coroutineContext--\u0026gt;CoroutineExceptionHandler[\u0026quot;CoroutineExceptionHandler: CoroutineExceptionHandlerImpl.\u0026quot;] coroutineContext--\u0026gt;ElementXxx[\u0026quot;ElementXxx: a singleton context by itself.\u0026quot;] 挂起和恢复设计 sequenceDiagram CurrentThreadType-\u0026gt;\u0026gt;DispatchedThreadType: dispatch activate DispatchedThreadType CurrentThreadType-\u0026gt;\u0026gt;CurrentThreadType: suspend coroutine and release thread DispatchedThreadType--\u0026gt;\u0026gt;CurrentThreadType: resume deactivate DispatchedThreadType graph LR subgraph 基础层 suspendCoroutine--\u0026gt;suspendCoroutineUninterceptedOrReturn suspendCancellableCoroutine--\u0026gt;suspendCoroutineUninterceptedOrReturn end subgraph 上层功能 delay--\u0026gt;suspendCancellableCoroutine withContext--\u0026gt;suspendCoroutineUninterceptedOrReturn awaitSuspend--\u0026gt;suspendCoroutineUninterceptedOrReturn yield--\u0026gt;suspendCoroutineUninterceptedOrReturn coroutineScope--\u0026gt;suspendCoroutineUninterceptedOrReturn end Coroutine构造和启动 CoroutineScope.launch public val coroutineContext: CoroutineContext launch本质上也是将用户配置的协程闭包作为一个suspend函数(()-\u0026gt;Unit),并将该函数在指定的dispatcher上执行，和withContext类似\npublic fun CoroutineScope.launch( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; Unit ): Job { val newContext = newCoroutineContext(context) val coroutine = if (start.isLazy) LazyStandaloneCoroutine(newContext, block) else StandaloneCoroutine(newContext, active = true) coroutine.start(start, coroutine, block)//main  return coroutine } CoroutineScope.newCoroutineContext intercepted过程会用到(context[ContinuationInterceptor]: DefaultScheduler实例DefaultDispatcher作为后续resume时的线程调度器\npublic actual fun CoroutineScope.newCoroutineContext(context: CoroutineContext): CoroutineContext { val combined = coroutineContext + context val debug = if (DEBUG) combined + CoroutineId(COROUTINE_ID.incrementAndGet()) else combined return if (combined !== Dispatchers.Default \u0026amp;\u0026amp; combined[ContinuationInterceptor] == null) debug + Dispatchers.Default else debug } coroutine.start CoroutineStart.start\u0026ndash;\u0026gt;invoke\npublic fun \u0026lt;R\u0026gt; start(start: CoroutineStart, receiver: R, block: suspend R.() -\u0026gt; T) { initParentJob() start(block, receiver, this) } public operator fun \u0026lt;R, T\u0026gt; invoke(block: suspend R.() -\u0026gt; T, receiver: R, completion: Continuation\u0026lt;T\u0026gt;) = when (this) { //receiver and completion both are StandaloneCoroutine instance,same one  CoroutineStart.DEFAULT -\u0026gt; block.startCoroutineCancellable(receiver, completion)//main  CoroutineStart.ATOMIC -\u0026gt; block.startCoroutine(receiver, completion) CoroutineStart.UNDISPATCHED -\u0026gt; block.startCoroutineUndispatched(receiver, completion) CoroutineStart.LAZY -\u0026gt; Unit // will start lazily  } commonMain\\intrinsics\\Cancellable.kt\n/** * Use this function to start coroutine in a cancellable way, so that it can be cancelled * while waiting to be dispatched. */ internal fun \u0026lt;R, T\u0026gt; (suspend (R) -\u0026gt; T).startCoroutineCancellable(receiver: R, completion: Continuation\u0026lt;T\u0026gt;) = runSafely(completion) { createCoroutineUnintercepted(receiver, completion).intercepted().resumeCancellable(Unit) } private inline fun runSafely(completion: Continuation\u0026lt;*\u0026gt;, block: () -\u0026gt; Unit) { try { block() } catch (e: Throwable) { completion.resumeWith(Result.failure(e)) } } kotlin/coroutines/intrinsics/IntrinsicsJvm.kt\n(suspend R.() -\u0026gt; T).createCoroutineUnintercepted public actual fun \u0026lt;R, T\u0026gt; (suspend R.() -\u0026gt; T).createCoroutineUnintercepted( receiver: R, completion: Continuation\u0026lt;T\u0026gt; ): Continuation\u0026lt;Unit\u0026gt; { val probeCompletion = probeCoroutineCreated(completion) return if (this is BaseContinuationImpl) //new编译产物SuspendLambda的子类对象，并将第一层对象StandaloneCoroutine作为参数传递给构造方法  create(receiver, probeCompletion)//main,receiver和probeCompletion都是StandaloneCoroutine{Active}@7e4d11a  else { createCoroutineFromSuspendFunction(probeCompletion) { (this as Function2\u0026lt;R, Continuation\u0026lt;T\u0026gt;, Any?\u0026gt;).invoke(receiver, it) } } } // Suspension lambdas inherit from this class internal abstract class SuspendLambda( public override val arity: Int, completion: Continuation\u0026lt;Any?\u0026gt;? ) : ContinuationImpl(completion), FunctionBase\u0026lt;Any?\u0026gt;, SuspendFunction { CoroutineCompileOutput build/tmp/kotlin-classes/debug/com/xxx/CoroutineTest.class\n使用jd-gui打开,对比\nobject CoroutineTest { fun test() { GlobalScope.launch(Dispatchers.Main.immediate) { println(\u0026#34;I\u0026#39;m sleeping ... thread name = ${Thread.currentThread().name}\u0026#34;) delay(500L)//release current thread while suspend current coroutine  println(\u0026#34;I\u0026#39;m sleeping over ... thread name = ${Thread.currentThread().name}\u0026#34;) } println(\u0026#34;finished thread name = ${Thread.currentThread().name}\u0026#34;) } } 对应\npublic final class CoroutineTest { public final void test() { BuildersKt.launch$default((CoroutineScope)GlobalScope.INSTANCE, (CoroutineContext)Dispatchers.getMain().getImmediate(), null, new CoroutineTest$test$1(null), 2, null); Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); String str = \u0026#34;finished thread name = \u0026#34; + Thread.currentThread().getName(); boolean bool = false; System.out.println(str); } static final class CoroutineTest$test$1 extends SuspendLambda implements Function2\u0026lt;CoroutineScope, Continuation\u0026lt;? super Unit\u0026gt;, Object\u0026gt; { private CoroutineScope p$; Object L$0; int label; @Nullable public final Object invokeSuspend(@NotNull Object $result) { CoroutineScope $this$launch; String str; boolean bool; Object object = IntrinsicsKt.getCOROUTINE_SUSPENDED(); switch (this.label) { case 0: ResultKt.throwOnFailure($result); $this$launch = this.p$; Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); str = \u0026#34;I\u0026#39;m sleeping ... thread name = \u0026#34; + Thread.currentThread().getName(); bool = false; System.out.println(str); this.L$0 = $this$launch; this.label = 1; if (DelayKt.delay(500L, (Continuation)this) == object) return object; DelayKt.delay(500L, (Continuation)this); Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); str = \u0026#34;I\u0026#39;m sleeping over ... thread name = \u0026#34; + Thread.currentThread().getName(); bool = false; System.out.println(str); return Unit.INSTANCE; case 1: $this$launch = (CoroutineScope)this.L$0; ResultKt.throwOnFailure($result); Intrinsics.checkExpressionValueIsNotNull(Thread.currentThread(), \u0026#34;Thread.currentThread()\u0026#34;); str = \u0026#34;I\u0026#39;m sleeping over ... thread name = \u0026#34; + Thread.currentThread().getName(); bool = false; System.out.println(str); return Unit.INSTANCE; } throw new IllegalStateException(\u0026#34;call to \u0026#39;resume\u0026#39; before \u0026#39;invoke\u0026#39; with coroutine\u0026#34;); } } internal fun Result\u0026lt;*\u0026gt;.throwOnFailure() { if (value is Result.Failure) throw value.exception } ContinuationImpl.intercepted() public actual fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.intercepted(): Continuation\u0026lt;T\u0026gt; = (this as? ContinuationImpl)?.intercepted() ?: this // State machines for named suspend functions extend from this class internal abstract class ContinuationImpl( completion: Continuation\u0026lt;Any?\u0026gt;?, private val _context: CoroutineContext? ) : BaseContinuationImpl(completion) { constructor(completion: Continuation\u0026lt;Any?\u0026gt;?) : this(completion, completion?.context) public override val context: CoroutineContext get() = _context!! @Transient private var intercepted: Continuation\u0026lt;Any?\u0026gt;? = null public fun intercepted(): Continuation\u0026lt;Any?\u0026gt; = //context是combineContext：[StandaloneCoroutine{Active}@7e4d11a, DefaultDispatcher]  //(context[ContinuationInterceptor]返回DefaultScheduler实例DefaultDispatcher  intercepted ?: (context[ContinuationInterceptor]?.interceptContinuation(this) ?: this) .also { intercepted = it } CoroutineDispatcher.interceptContinuation\npublic final override fun \u0026lt;T\u0026gt; interceptContinuation(continuation: Continuation\u0026lt;T\u0026gt;): Continuation\u0026lt;T\u0026gt; = DispatchedContinuation(this, continuation) DispatchedContinuation.resumeCancellable internal fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeCancellable(value: T) = when (this) { is DispatchedContinuation -\u0026gt; resumeCancellable(value) else -\u0026gt; resume(value) } inline fun resumeCancellable(value: T) { if (dispatcher.isDispatchNeeded(context)) { _state = value resumeMode = MODE_CANCELLABLE dispatcher.dispatch(context, this) } else { executeUnconfined(value, MODE_CANCELLABLE) { if (!resumeCancelled()) { resumeUndispatched(value) } } } } override fun dispatch(context: CoroutineContext, block: Runnable): Unit = try { coroutineScheduler.dispatch(block) } catch (e: RejectedExecutionException) { DefaultExecutor.dispatch(context, block) } fun dispatch(block: Runnable, taskContext: TaskContext = NonBlockingContext, fair: Boolean = false) { trackTask() // this is needed for virtual time support  val task = createTask(block, taskContext) // try to submit the task to the local queue and act depending on the result  when (submitToLocalQueue(task, fair)) { ADDED -\u0026gt; return NOT_ADDED -\u0026gt; { // try to offload task to global queue  if (!globalQueue.addLast(task)) {//main  // Global queue is closed in the last step of close/shutdown -- no more tasks should be accepted  throw RejectedExecutionException(\u0026#34;$schedulerNamewas terminated\u0026#34;) } requestCpuWorker() } else -\u0026gt; requestCpuWorker() // ask for help  } } fun addLast(element: E): Boolean { _cur.loop { cur -\u0026gt; when (cur.addLast(element)) { Core.ADD_SUCCESS -\u0026gt; return true Core.ADD_CLOSED -\u0026gt; return false Core.ADD_FROZEN -\u0026gt; _cur.compareAndSet(cur, cur.next()) // move to next  } } } 线程调度 jvmMain\\scheduling\\CoroutineScheduler.kt\ninternal inner class Worker private constructor() : Thread() { override fun run() { var wasIdle = false // local variable to avoid extra idleReset invocations when tasks repeatedly arrive  while (!isTerminated \u0026amp;\u0026amp; state != WorkerState.TERMINATED) { val task = findTask()//类似java ThreadPoolExecutor,循环读取WorkQueue中的Task,并执行task  if (task == null) { // Wait for a job with potential park  if (state == WorkerState.CPU_ACQUIRED) { cpuWorkerIdle() } else { blockingWorkerIdle() } wasIdle = true } else { // Note: read task.mode before running the task, because Task object will be reused after run  val taskMode = task.mode if (wasIdle) { idleReset(taskMode) wasIdle = false } beforeTask(taskMode, task.submissionTime) runSafely(task)//main  afterTask(taskMode) } } tryReleaseCpu(WorkerState.TERMINATED) } } internal fun findTask(): Task? { if (tryAcquireCpuPermit()) return findTaskWithCpuPermit() /* * If the local queue is empty, try to extract blocking task from global queue. * It\u0026#39;s helpful for two reasons: * 1) We won\u0026#39;t call excess park/unpark here and someone\u0026#39;s else CPU token won\u0026#39;t be transferred, * which is a performance win * 2) It helps with rare race when external submitter sends depending blocking tasks * one by one and one of the requested workers may miss CPU token */ return localQueue.poll() ?: globalQueue.removeFirstWithModeOrNull(TaskMode.PROBABLY_BLOCKING) } CoroutineScheduler.runSafely\nprivate fun runSafely(task: Task) { try { task.run() } catch (e: Throwable) { val thread = Thread.currentThread() thread.uncaughtExceptionHandler.uncaughtException(thread, e) } finally { unTrackTask() } } runTask resume过程参考visio类图\nresumewith\nDispatchedTask\u0026lt;in T\u0026gt;\npublic final override fun run() { val taskContext = this.taskContext try { val delegate = delegate as DispatchedContinuation\u0026lt;T\u0026gt; //continuation为BaseContinuationImpl子类，实现对第二层的代理  val continuation = delegate.continuation val context = continuation.context val job = if (resumeMode.isCancellableMode) context[Job] else null val state = takeState() // NOTE: Must take state in any case, even if cancelled  withCoroutineContext(context, delegate.countOrElement) { if (job != null \u0026amp;\u0026amp; !job.isActive) continuation.resumeWithException(job.getCancellationException()) else { val exception = getExceptionalResult(state) if (exception != null) continuation.resumeWithStackTrace(exception)//cancel和其他异常时进入  else //调用resumeWith(Result.success(value))  continuation.resume(getSuccessfulResult(state))//main  } } } catch (e: Throwable) { throw DispatchException(\u0026#34;Unexpected exception running $this\u0026#34;, e) } finally { taskContext.afterTask() } @Suppress(\u0026#34;NOTHING_TO_INLINE\u0026#34;) internal inline fun Continuation\u0026lt;*\u0026gt;.resumeWithStackTrace(exception: Throwable) { resumeWith(Result.failure(recoverStackTrace(exception, this))) } SuspendLambda_resumeWith //BaseContinuationImpl //封装了协程的运算逻辑，用以协程的启动和恢复 public final override fun resumeWith(result: Result\u0026lt;Any?\u0026gt;) { // This loop unrolls recursion in current.resumeWith(param) to make saner and shorter stack traces on resume  var current = this var param = result while (true) { // Invoke \u0026#34;resume\u0026#34; debug probe on every resumed continuation, so that a debugging library infrastructure  // can precisely track what part of suspended callstack was already resumed  probeCoroutineResumed(current) with(current) { val completion = completion!! // fail fast when trying to resume continuation without completion  val outcome: Result\u0026lt;Any?\u0026gt; = try { val outcome = invokeSuspend(param)//main  if (outcome === COROUTINE_SUSPENDED) return Result.success(outcome) } catch (exception: Throwable) {//catch了所有异常，封装到outcome里  Result.failure(exception) } releaseIntercepted() // this state machine instance is terminating  if (completion is BaseContinuationImpl) { // unrolling recursion via loop  current = completion param = outcome } else {//是AbstractCoroutine实例时  // top-level completion reached -- invoke and return  //completion为AbstractCoroutine实例，实现对第一层的代理  completion.resumeWith(outcome) return } } } } coroutinecompileoutput\nAbstractCoroutine.resumeWith /** commonMain/AbstractCoroutine.kt * Completes execution of this with coroutine with the specified result. */ public final override fun resumeWith(result: Result\u0026lt;T\u0026gt;) { makeCompletingOnce(result.toState(), defaultResumeMode) } //commonMain/JobSupport.kt  internal fun makeCompletingOnce(proposedUpdate: Any?, mode: Int): Boolean = loopOnState { state -\u0026gt; when (tryMakeCompleting(state, proposedUpdate, mode)) { COMPLETING_ALREADY_COMPLETING -\u0026gt; throw IllegalStateException(\u0026#34;Job $thisis already complete or completing, \u0026#34; + \u0026#34;but is being completed with $proposedUpdate\u0026#34;, proposedUpdate.exceptionOrNull) COMPLETING_COMPLETED -\u0026gt; return true COMPLETING_WAITING_CHILDREN -\u0026gt; return false COMPLETING_RETRY -\u0026gt; return@loopOnState else -\u0026gt; error(\u0026#34;unexpected result\u0026#34;) } } withContext(基于suspendCoroutineUninterceptedOrReturn) public suspend fun \u0026lt;T\u0026gt; withContext( context: CoroutineContext, block: suspend CoroutineScope.() -\u0026gt; T ): T = suspendCoroutineUninterceptedOrReturn sc@ { uCont -\u0026gt; // compute new context  val oldContext = uCont.context val newContext = oldContext + context // always check for cancellation of new context  newContext.checkCompletion() // FAST PATH #1 -- new context is the same as the old one  if (newContext === oldContext) { val coroutine = ScopeCoroutine(newContext, uCont) // MODE_DIRECT  return@sc coroutine.startUndispatchedOrReturn(coroutine, block) } // FAST PATH #2 -- the new dispatcher is the same as the old one (something else changed)  // `equals` is used by design (see equals implementation is wrapper context like ExecutorCoroutineDispatcher)  if (newContext[ContinuationInterceptor] == oldContext[ContinuationInterceptor]) { val coroutine = UndispatchedCoroutine(newContext, uCont) // MODE_UNDISPATCHED  // There are changes in the context, so this thread needs to be updated  withCoroutineContext(newContext, null) { return@sc coroutine.startUndispatchedOrReturn(coroutine, block) } } // SLOW PATH -- use new dispatcher  val coroutine = DispatchedCoroutine(newContext, uCont) // MODE_CANCELLABLE,传递uCont用于在old dispatcher上resume  coroutine.initParentJob() block.startCoroutineCancellable(coroutine, coroutine)//该方法和launch时的主流程类似，恢复流程由DispatchedCoroutine指定  coroutine.getResult() } dispatched // Used by withContext when context dispatcher changes private class DispatchedCoroutine\u0026lt;in T\u0026gt;( context: CoroutineContext, uCont: Continuation\u0026lt;T\u0026gt; ) : ScopeCoroutine\u0026lt;T\u0026gt;(context, uCont) { 监听completion通知，执行resume internal open class ScopeCoroutine\u0026lt;in T\u0026gt;( context: CoroutineContext, @JvmField val uCont: Continuation\u0026lt;T\u0026gt; // unintercepted continuation ) : AbstractCoroutine\u0026lt;T\u0026gt;(context, true), CoroutineStackFrame { override fun afterCompletionInternal(state: Any?, mode: Int) { if (state is CompletedExceptionally) { val exception = if (mode == MODE_IGNORE) state.cause else recoverStackTrace(state.cause, uCont) uCont.resumeUninterceptedWithExceptionMode(exception, mode) } else { uCont.resumeUninterceptedMode(state as T, mode)//uCont是old，eg:Continuation at com.example.myapplication.coroutine.CoroutineTest$postItem$1.invokeSuspend(CoroutineTest.kt:55)  } } } internal fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeUninterceptedMode(value: T, mode: Int) { when (mode) { MODE_ATOMIC_DEFAULT -\u0026gt; intercepted().resume(value) MODE_CANCELLABLE -\u0026gt; intercepted().resumeCancellable(value) MODE_DIRECT -\u0026gt; resume(value) MODE_UNDISPATCHED -\u0026gt; withCoroutineContext(context, null) { resume(value) } MODE_IGNORE -\u0026gt; {} else -\u0026gt; error(\u0026#34;Invalid mode $mode\u0026#34;) } } resume\nundispatched internal fun \u0026lt;T, R\u0026gt; AbstractCoroutine\u0026lt;T\u0026gt;.startUndispatchedOrReturn(receiver: R, block: suspend R.() -\u0026gt; T): Any? { initParentJob() return undispatchedResult({ true }) { block.startCoroutineUninterceptedOrReturn(receiver, this) } } kotlin/coroutines/intrinsics/IntrinsicsJvm.kt\npublic actual inline fun \u0026lt;T\u0026gt; (suspend () -\u0026gt; T).startCoroutineUninterceptedOrReturn( completion: Continuation\u0026lt;T\u0026gt; ): Any? = (this as Function1\u0026lt;Continuation\u0026lt;T\u0026gt;, Any?\u0026gt;).invoke(completion) delay(基于suspendCancellableCoroutine) /** * Delays coroutine for a given time without blocking a thread and resumes it after a specified time. * This suspending function is cancellable. * If the [Job] of the current coroutine is cancelled or completed while this suspending function is waiting, this function * immediately resumes with [CancellationException]. */ public suspend fun delay(timeMillis: Long) { if (timeMillis \u0026lt;= 0) return // don\u0026#39;t delay  return suspendCancellableCoroutine sc@ { cont: CancellableContinuation\u0026lt;Unit\u0026gt; -\u0026gt; cont.context.delay.scheduleResumeAfterDelay(timeMillis, cont) } } /** Returns [Delay] implementation of the given context */ internal val CoroutineContext.delay: Delay get() = get(ContinuationInterceptor) as? Delay ?: DefaultDelay suspendCancellableCoroutine /** * Suspends coroutine similar to [suspendCoroutine], but provide an implementation of [CancellableContinuation] to * the [block]. This function throws [CancellationException] if the coroutine is cancelled or completed while suspended. */ public suspend inline fun \u0026lt;T\u0026gt; suspendCancellableCoroutine( crossinline block: (CancellableContinuation\u0026lt;T\u0026gt;) -\u0026gt; Unit ): T = suspendCoroutineUninterceptedOrReturn { uCont -\u0026gt;//uCont是生成的SuspendLambda子类，也就是第二层  val cancellable = CancellableContinuationImpl(uCont.intercepted(), resumeMode = MODE_CANCELLABLE) // NOTE: Before version 1.1.0 the following invocation was inlined here, so invocation of this  // method indicates that the code was compiled by kotlinx.coroutines \u0026lt; 1.1.0  // cancellable.initCancellability()  block(cancellable) cancellable.getResult() } suspendCoroutineUninterceptedOrReturn //Obtains the current continuation instance inside suspend functions and either suspends currently running coroutine or returns result immediately without suspension. suspend inline fun \u0026lt;T\u0026gt; suspendCoroutineUninterceptedOrReturn( crossinline block: (Continuation\u0026lt;T\u0026gt;) -\u0026gt; Any? ): T main线程delay，执行block /** * Implements [CoroutineDispatcher] on top of an arbitrary Android [Handler]. */ internal class HandlerContext override fun scheduleResumeAfterDelay(timeMillis: Long, continuation: CancellableContinuation\u0026lt;Unit\u0026gt;) { val block = Runnable { with(continuation) { resumeUndispatched(Unit) } } handler.postDelayed(block, timeMillis.coerceAtMost(MAX_DELAY)) continuation.invokeOnCancellation { handler.removeCallbacks(block) } } 非main线程delay，执行block public override fun scheduleResumeAfterDelay(timeMillis: Long, continuation: CancellableContinuation\u0026lt;Unit\u0026gt;) { val timeNanos = delayToNanos(timeMillis) if (timeNanos \u0026lt; MAX_DELAY_NS) { val now = nanoTime() DelayedResumeTask(now + timeNanos, continuation).also { task -\u0026gt; continuation.disposeOnCancellation(task) schedule(now, task) } } } CancellableContinuation\u0026lt;*\u0026gt;.disposeOnCancellation(handle: DisposableHandle) public fun CancellableContinuation\u0026lt;*\u0026gt;.disposeOnCancellation(handle: DisposableHandle) = invokeOnCancellation(handler = DisposeOnCancel(handle).asHandler) private class DisposeOnCancel(private val handle: DisposableHandle) : CancelHandler() { override fun invoke(cause: Throwable?) = handle.dispose() } private inner class DelayedResumeTask( nanoTime: Long, private val cont: CancellableContinuation\u0026lt;Unit\u0026gt; ) : DelayedTask(nanoTime) { override fun run() { with(cont) { resumeUndispatched(Unit) } } override fun toString(): String = super.toString() + cont.toString() } internal abstract class DelayedTask( /** * This field can be only modified in [scheduleTask] before putting this DelayedTask * into heap to avoid overflow and corruption of heap data structure. */ @JvmField var nanoTime: Long ) : Runnable, Comparable\u0026lt;DelayedTask\u0026gt;, DisposableHandle, ThreadSafeHeapNode { @Synchronized final override fun dispose() { val heap = _heap if (heap === DISPOSED_TASK) return // already disposed  @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) (heap as? DelayedTaskQueue)?.remove(this) // remove if it is in heap (first)  _heap = DISPOSED_TASK // never add again to any heap  } } DefaultExecutor.schedule public fun schedule(now: Long, delayedTask: DelayedTask) { when (scheduleImpl(now, delayedTask)) { SCHEDULE_OK -\u0026gt; if (shouldUnpark(delayedTask)) unpark() SCHEDULE_COMPLETED -\u0026gt; reschedule(now, delayedTask) SCHEDULE_DISPOSED -\u0026gt; {} // do nothing -- task was already disposed  else -\u0026gt; error(\u0026#34;unexpected result\u0026#34;) } } getResult @PublishedApi internal fun getResult(): Any? { installParentCancellationHandler() if (trySuspend()) return COROUTINE_SUSPENDED // otherwise, onCompletionInternal was already invoked \u0026amp; invoked tryResume, and the result is in the state  val state = this.state if (state is CompletedExceptionally) throw recoverStackTrace(state.cause, this) // if the parent job was already cancelled, then throw the corresponding cancellation exception  // otherwise, there is a race is suspendCancellableCoroutine { cont -\u0026gt; ... } does cont.resume(...)  // before the block returns. This getResult would return a result as opposed to cancellation  // exception that should have happened if the continuation is dispatched for execution later.  if (resumeMode == MODE_CANCELLABLE) { val job = context[Job] if (job != null \u0026amp;\u0026amp; !job.isActive) { val cause = job.getCancellationException() cancelResult(state, cause) throw recoverStackTrace(cause, this) } } return getSuccessfulResult(state) } trySuspend释放线程 private const val UNDECIDED = 0 private const val SUSPENDED = 1 private const val RESUMED = 2 private fun trySuspend(): Boolean { _decision.loop { decision -\u0026gt; when (decision) { UNDECIDED -\u0026gt; if (this._decision.compareAndSet(UNDECIDED, SUSPENDED)) return true RESUMED -\u0026gt; return false else -\u0026gt; error(\u0026#34;Already suspended\u0026#34;) } } } main线程delay,恢复协程的后续执行 with(continuation) { resumeUndispatched(Unit) } /** * Calls the specified function [block] with the given [receiver] as its receiver and returns its result. */ @kotlin.internal.InlineOnly public inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R { return receiver.block() } commonMain/CancellableContinuationImpl.kt\noverride fun CoroutineDispatcher.resumeUndispatched(value: T) { val dc = delegate as? DispatchedContinuation resumeImpl(value, if (dc?.dispatcher === this) MODE_UNDISPATCHED else resumeMode) } // returns null when successfully dispatched resumed, CancelledContinuation if too late (was already cancelled) private fun resumeImpl(proposedUpdate: Any?, resumeMode: Int): CancelledContinuation? { _state.loop { state -\u0026gt; when (state) { is NotCompleted -\u0026gt; { if (!_state.compareAndSet(state, proposedUpdate)) return@loop // retry on cas failure  disposeParentHandle() dispatchResume(resumeMode)//main  return null } } } private fun dispatchResume(mode: Int) { if (tryResume()) return // completed before getResult invocation -- bail out  // otherwise, getResult has already commenced, i.e. completed later or in other thread  dispatch(mode) } tryResume private fun tryResume(): Boolean { _decision.loop { decision -\u0026gt; when (decision) { UNDECIDED -\u0026gt; if (this._decision.compareAndSet(UNDECIDED, RESUMED)) return true SUSPENDED -\u0026gt; return false else -\u0026gt; error(\u0026#34;Already resumed\u0026#34;) } } } DispatchedTask.dispatch internal fun \u0026lt;T\u0026gt; DispatchedTask\u0026lt;T\u0026gt;.dispatch(mode: Int = MODE_CANCELLABLE) { val delegate = this.delegate if (mode.isDispatchedMode \u0026amp;\u0026amp; delegate is DispatchedContinuation\u0026lt;*\u0026gt; \u0026amp;\u0026amp; mode.isCancellableMode == resumeMode.isCancellableMode) { // dispatch directly using this instance\u0026#39;s Runnable implementation  val dispatcher = delegate.dispatcher val context = delegate.context if (dispatcher.isDispatchNeeded(context)) { dispatcher.dispatch(context, this) } else { resumeUnconfined() } } else { resume(delegate, mode)//main  } } internal fun \u0026lt;T\u0026gt; DispatchedTask\u0026lt;T\u0026gt;.resume(delegate: Continuation\u0026lt;T\u0026gt;, useMode: Int) { // slow-path - use delegate  val state = takeState() val exception = getExceptionalResult(state) if (exception != null) { /* * Recover stacktrace for non-dispatched tasks. * We usually do not recover stacktrace in a `resume` as all resumes go through `DispatchedTask.run` * and we recover stacktraces there, but this is not the case for a `suspend fun main()` that knows nothing about * kotlinx.coroutines and DispatchedTask */ val recovered = if (delegate is DispatchedTask\u0026lt;*\u0026gt;) exception else recoverStackTrace(exception, delegate) delegate.resumeWithExceptionMode(recovered, useMode) } else { delegate.resumeMode(getSuccessfulResult(state), useMode)//main  } } internal fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeMode(value: T, mode: Int) { when (mode) { MODE_ATOMIC_DEFAULT -\u0026gt; resume(value) MODE_CANCELLABLE -\u0026gt; resumeCancellable(value) MODE_DIRECT -\u0026gt; resumeDirect(value) MODE_UNDISPATCHED -\u0026gt; (this as DispatchedContinuation).resumeUndispatched(value) MODE_IGNORE -\u0026gt; {} else -\u0026gt; error(\u0026#34;Invalid mode $mode\u0026#34;) } } inline fun resumeUndispatched(value: T) { //this: DispatchedContinuation[Main [immediate]...]  withCoroutineContext(context, countOrElement) { continuation.resume(value)//走后续的resume流程  } } public inline fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resume(value: T): Unit = resumeWith(Result.success(value)) //协程的恢复 override fun resumeWith(result: Result\u0026lt;T\u0026gt;) { val context = continuation.context val state = result.toState() if (dispatcher.isDispatchNeeded(context)) { _state = state resumeMode = MODE_ATOMIC_DEFAULT dispatcher.dispatch(context, this) } else { executeUnconfined(state, MODE_ATOMIC_DEFAULT) { withCoroutineContext(this.context, countOrElement) { continuation.resumeWith(result) } } } } 继续中间层的resume流程\ncoroutineScope(基于suspendCoroutineUninterceptedOrReturn) commonMain/CoroutineScope.kt\npublic suspend fun \u0026lt;R\u0026gt; coroutineScope(block: suspend CoroutineScope.() -\u0026gt; R): R { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } return suspendCoroutineUninterceptedOrReturn { uCont -\u0026gt; val coroutine = ScopeCoroutine(uCont.context, uCont) coroutine.startUndispatchedOrReturn(coroutine, block) } } Job * A job has the following states: * * | **State** | [isActive] | [isCompleted] | [isCancelled] | * | -------------------------------- | ---------- | ------------- | ------------- | * | _New_ (optional initial state) | `false` | `false` | `false` | * | _Active_ (default initial state) | `true` | `false` | `false` | * | _Completing_ (transient state) | `true` | `false` | `false` | * | _Cancelling_ (transient state) | `false` | `false` | `true` | * | _Cancelled_ (final state) | `false` | `true` | `true` | * | _Completed_ (final state) | `false` | `true` | `false` | * ``` * wait children * +-----+ start +--------+ complete +-------------+ finish +-----------+ * | New | -----\u0026gt; | Active | ---------\u0026gt; | Completing | -------\u0026gt; | Completed | * +-----+ +--------+ +-------------+ +-----------+ * | cancel / fail | * | +----------------+ * | | * V V * +------------+ finish +-----------+ * | Cancelling | --------------------------------\u0026gt; | Cancelled | * +------------+ +-----------+ * ``` async async时释放线程，但不挂起协程\nawait被调用时不释放线程，但挂起协程\npublic fun \u0026lt;T\u0026gt; CoroutineScope.async( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; T ): Deferred\u0026lt;T\u0026gt; { val newContext = newCoroutineContext(context) val coroutine = if (start.isLazy) LazyDeferredCoroutine(newContext, block) else DeferredCoroutine\u0026lt;T\u0026gt;(newContext, active = true) coroutine.start(start, coroutine, block) return coroutine } public interface Deferred\u0026lt;out T\u0026gt; : Job { public suspend fun await(): T ...... } private open class DeferredCoroutine\u0026lt;T\u0026gt;( parentContext: CoroutineContext, active: Boolean ) : AbstractCoroutine\u0026lt;T\u0026gt;(parentContext, active), Deferred\u0026lt;T\u0026gt;, SelectClause1\u0026lt;T\u0026gt; { override fun getCompleted(): T = getCompletedInternal() as T override suspend fun await(): T = awaitInternal() as T override val onAwait: SelectClause1\u0026lt;T\u0026gt; get() = this override fun \u0026lt;R\u0026gt; registerSelectClause1(select: SelectInstance\u0026lt;R\u0026gt;, block: suspend (T) -\u0026gt; R) = registerSelectClause1Internal(select, block) } awaitInternal internal suspend fun awaitInternal(): Any? { // fast-path -- check state (avoid extra object creation)  while (true) { // lock-free loop on state  val state = this.state if (state !is Incomplete) { // already complete -- just return result  if (state is CompletedExceptionally) { // Slow path to recover stacktrace  recoverAndThrow(state.cause) } return state.unboxState() } if (startInternal(state) \u0026gt;= 0) break // break unless needs to retry  } return awaitSuspend() // slow-path } private suspend fun awaitSuspend(): Any? = suspendCoroutineUninterceptedOrReturn { uCont -\u0026gt; val cont = AwaitContinuation(uCont.intercepted(), this) cont.disposeOnCancellation(invokeOnCompletion(ResumeAwaitOnCompletion(this, cont).asHandler)) cont.getResult() } invokeOnCompletion public final override fun invokeOnCompletion(handler: CompletionHandler): DisposableHandle = invokeOnCompletion(onCancelling = false, invokeImmediately = true, handler = handler) ResumeAwaitOnCompletion private class ResumeAwaitOnCompletion\u0026lt;T\u0026gt;( job: JobSupport, private val continuation: CancellableContinuationImpl\u0026lt;T\u0026gt; ) : JobNode\u0026lt;JobSupport\u0026gt;(job) { override fun invoke(cause: Throwable?) { val state = job.state assert { state !is Incomplete } if (state is CompletedExceptionally) { // Resume with exception in atomic way to preserve exception  continuation.resumeWithExceptionMode(state.cause, MODE_ATOMIC_DEFAULT) } else { // Resuming with value in a cancellable way (AwaitContinuation is configured for this mode).  @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) continuation.resume(state.unboxState() as T) } } override fun toString() = \u0026#34;ResumeAwaitOnCompletion[$continuation]\u0026#34; } Dispatchers.Main.immediate @JvmStatic //这里的dispatcher就是下面的HandlerContext实例 public actual val Main: MainCoroutineDispatcher get() = MainDispatcherLoader.dispatcher MainDispatcherLoader val dispatcher: MainCoroutineDispatcher = loadMainDispatcher() public abstract class MainCoroutineDispatcher : CoroutineDispatcher() { public abstract val immediate: MainCoroutineDispatcher } public sealed class HandlerDispatcher : MainCoroutineDispatcher(), Delay { public abstract override val immediate: HandlerDispatcher } internal class HandlerContext private constructor( private val handler: Handler, private val name: String?, private val invokeImmediately: Boolean ) : HandlerDispatcher(), Delay { @Volatile private var _immediate: HandlerContext? = if (invokeImmediately) this else null override val immediate: HandlerContext = _immediate ?: HandlerContext(handler, name, true).also { _immediate = it } override fun isDispatchNeeded(context: CoroutineContext): Boolean { return !invokeImmediately || Looper.myLooper() != handler.looper } 协程resume时根据dispatcher.isDispatchNeeded判断是否需要dispatch\nDispatchedContinuation inline fun resumeCancellable(value: T) { if (dispatcher.isDispatchNeeded(context)) {//main  _state = value resumeMode = MODE_CANCELLABLE dispatcher.dispatch(context, this) } else { executeUnconfined(value, MODE_CANCELLABLE) { if (!resumeCancelled()) { resumeUndispatched(value) } } } } CoroutineStackFrame 发生异常时用于恢复协程堆栈\ninternal actual typealias CoroutineStackFrame = kotlin.coroutines.jvm.internal.CoroutineStackFrame /** * Represents one frame in the coroutine call stack for debugger. * This interface is implemented by compiler-generated implementations of * [Continuation] interface. */ @SinceKotlin(\u0026#34;1.3\u0026#34;) public interface CoroutineStackFrame { /** * Returns a reference to the stack frame of the caller of this frame, * that is a frame before this frame in coroutine call stack. * The result is `null` for the first frame of coroutine. */ public val callerFrame: CoroutineStackFrame? /** * Returns stack trace element that correspond to this stack frame. * The result is `null` if the stack trace element is not available for this frame. * In this case, the debugger represents this stack frame using the * result of [toString] function. */ public fun getStackTraceElement(): StackTraceElement? } DispatchedTask.run\npublic final override fun run() { val taskContext = this.taskContext var fatalException: Throwable? = null withCoroutineContext(context, delegate.countOrElement) { val exception = getExceptionalResult(state) val job = if (resumeMode.isCancellableMode) context[Job] else null /* * Check whether continuation was originally resumed with an exception. * If so, it dominates cancellation, otherwise the original exception * will be silently lost. */ if (exception == null \u0026amp;\u0026amp; job != null \u0026amp;\u0026amp; !job.isActive) { val cause = job.getCancellationException() cancelResult(state, cause) continuation.resumeWithStackTrace(cause) } else { if (exception != null) continuation.resumeWithStackTrace(exception)//main  else continuation.resume(getSuccessfulResult(state)) } } } internal inline fun Continuation\u0026lt;*\u0026gt;.resumeWithStackTrace(exception: Throwable) { resumeWith(Result.failure(recoverStackTrace(exception, this))) } internal actual fun \u0026lt;E : Throwable\u0026gt; recoverStackTrace(exception: E, continuation: Continuation\u0026lt;*\u0026gt;): E { if (!RECOVER_STACK_TRACES || continuation !is CoroutineStackFrame) return exception return recoverFromStackFrame(exception, continuation) } private fun \u0026lt;E : Throwable\u0026gt; recoverFromStackFrame(exception: E, continuation: CoroutineStackFrame): E { /* * Here we are checking whether exception has already recovered stacktrace. * If so, we extract initial and merge recovered stacktrace and current one */ val (cause, recoveredStacktrace) = exception.causeAndStacktrace() // Try to create an exception of the same type and get stacktrace from continuation  val newException = tryCopyException(cause) ?: return exception val stacktrace = createStackTrace(continuation) private fun createStackTrace(continuation: CoroutineStackFrame): ArrayDeque\u0026lt;StackTraceElement\u0026gt; { val stack = ArrayDeque\u0026lt;StackTraceElement\u0026gt;() continuation.getStackTraceElement()?.let { stack.add(it) } var last = continuation while (true) { last = (last as? CoroutineStackFrame)?.callerFrame ?: break last.getStackTraceElement()?.let { stack.add(it) } } return stack } "
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/coroutine/kotlin%E5%8D%8F%E7%A8%8B%E5%8F%96%E6%B6%88/",
	"title": "kotlin协程取消",
	"tags": [],
	"description": "",
	"content": "协程的取消 graph subgraph 协程 subgraph 挂起函数1 开始挂起函数1--\u0026gt;|执行|函数1执行中--\u0026gt;|3:需要函数1内协作判断isAlive,退出计算|函数1执行完成 end subgraph 挂起函数2 开始挂起函数2--\u0026gt;|执行|函数2执行中--\u0026gt;函数2执行完成 end 函数1执行完成--\u0026gt;resume--\u0026gt;开始挂起函数2 cancel--\u0026gt;|1:cpu密集计算类型:在该协程线程中修改协程job状态为canceling|函数1执行中 resume--\u0026gt;|2:DispatchedTask.run判断job状态|异常resume 开始挂起函数1--\u0026gt;|IO类型:cont.invokeOnCancellation|设置cancel时的处理方法 end runtask时对CancellationException的判断\n协程的取消只是在协程的第一层包装中 AbstractCoroutine 中修改协程的状态，并没有影响到第二层包装中 BaseContinuationImpl 中协程的实际运算逻辑。所以协程的取消只是状态的变化，并不会取消协程的实际运算逻辑，看下面的代码示例：\nfun main(args: Array\u0026lt;String\u0026gt;) = runBlocking { val job1 = launch(Dispatchers.Default) { repeat(5) { println(\u0026#34;job1 sleep ${it + 1}times\u0026#34;) delay(500) } } delay(700) job1.cancel() val job2 = launch(Dispatchers.Default) { var nextPrintTime = 0L var i = 1 while (i \u0026lt;= 3) { val currentTime = System.currentTimeMillis() if (currentTime \u0026gt;= nextPrintTime) { println(\u0026#34;job2 sleep ${i++}...\u0026#34;) nextPrintTime = currentTime + 500L } } } delay(700) job2.cancel() } 输出结果如下：\njob1 sleep 1 times job1 sleep 2 times job2 sleep 1 ... job2 sleep 2 ... job2 sleep 3 ... 上面代码中 job1 取消后，delay()会检测协程是否已取消，所以 job1 之后的运算就结束了；而 job2 取消后，没有检测协程状态的逻辑，都是计算逻辑，所以 job2 的运算逻辑还是会继续运行。\n所以为了可以及时取消协程的运算逻辑，可以检测协程的状态，使用isActive来判断，上面示例中可以将while(i \u0026lt;= 3)替换为while(isActive)。\ncommonMain/JobSupport.kt\nJobSupport.cancel // external cancel with cause, never invoked implicitly from internal machinery public override fun cancel(cause: CancellationException?) { cancelInternal(cause) // must delegate here, because some classes override cancelInternal(x) } public open fun cancelInternal(cause: Throwable?): Boolean = cancelImpl(cause) \u0026amp;\u0026amp; handlesException // cause is Throwable or ParentJob when cancelChild was invoked  // returns true is exception was handled, false otherwise  internal fun cancelImpl(cause: Any?): Boolean { if (onCancelComplete) { // make sure it is completing, if cancelMakeCompleting returns true it means it had make it  // completing and had recorded exception  if (cancelMakeCompleting(cause)) return true // otherwise just record exception via makeCancelling below  } return makeCancelling(cause)//main  } makeCancelling // transitions to Cancelling state  // cause is Throwable or ParentJob when cancelChild was invoked  private fun makeCancelling(cause: Any?): Boolean { var causeExceptionCache: Throwable? = null // lazily init result of createCauseException(cause)  loopOnState { state -\u0026gt; when (state) { is Finishing -\u0026gt; { // already finishing -- collect exceptions  ..... return true } is Incomplete -\u0026gt; { // Not yet finishing -- try to make it cancelling  val causeException = causeExceptionCache ?: createCauseException(cause).also { causeExceptionCache = it } if (state.isActive) { // active state becomes cancelling  if (tryMakeCancelling(state, causeException)) return true//main  } else { // non active state starts completing  when (tryMakeCompleting(state, CompletedExceptionally(causeException), mode = MODE_ATOMIC_DEFAULT)) { COMPLETING_ALREADY_COMPLETING -\u0026gt; error(\u0026#34;Cannot happen in $state\u0026#34;) COMPLETING_COMPLETED, COMPLETING_WAITING_CHILDREN -\u0026gt; return true // ok  COMPLETING_RETRY -\u0026gt; return@loopOnState else -\u0026gt; error(\u0026#34;unexpected result\u0026#34;) } } } else -\u0026gt; return false // already complete  } } } // try make new Cancelling state on the condition that we\u0026#39;re still in the expected state  private fun tryMakeCancelling(state: Incomplete, rootCause: Throwable): Boolean { assert { state !is Finishing } // only for non-finishing states  assert { state.isActive } // only for active states  // get state\u0026#39;s list or else promote to list to correctly operate on child lists  val list = getOrPromoteCancellingList(state) ?: return false//main  // Create cancelling state (with rootCause!)  val cancelling = Finishing(list, false, rootCause) if (!_state.compareAndSet(state, cancelling)) return false // Notify listeners  notifyCancelling(list, rootCause)//main  return true } getOrPromoteCancellingList // Performs promotion of incomplete coroutine state to NodeList for the purpose of  // converting coroutine state to Cancelling, returns null when need to retry  private fun getOrPromoteCancellingList(state: Incomplete): NodeList? = state.list notifyCancelling private fun notifyCancelling(list: NodeList, cause: Throwable) { // first cancel our own children  onCancelling(cause) notifyHandlers\u0026lt;JobCancellingNode\u0026lt;*\u0026gt;\u0026gt;(list, cause)//main  // then cancel parent  cancelParent(cause) // tentative cancellation -- does not matter if there is no parent  } private inline fun \u0026lt;reified T: JobNode\u0026lt;*\u0026gt;\u0026gt; notifyHandlers(list: NodeList, cause: Throwable?) { var exception: Throwable? = null list.forEach\u0026lt;T\u0026gt; { node -\u0026gt; try { node.invoke(cause)//main  } catch (ex: Throwable) { exception?.apply { addSuppressedThrowable(ex) } ?: run { exception = CompletionHandlerException(\u0026#34;Exception in completion handler $nodefor $this\u0026#34;, ex) } } } exception?.let { handleOnCompletionException(it) } } delay时 ChildContinuation as JobNode // Same as ChildHandleNode, but for cancellable continuation internal class ChildContinuation( parent: Job, @JvmField val child: CancellableContinuationImpl\u0026lt;*\u0026gt; ) : JobCancellingNode\u0026lt;Job\u0026gt;(parent) { override fun invoke(cause: Throwable?) { child.cancel(child.getContinuationCancellationCause(job))//main  } override fun toString(): String = \u0026#34;ChildContinuation[$child]\u0026#34; } /** * It is used when parent is cancelled to get the cancellation cause for this continuation. */ open fun getContinuationCancellationCause(parent: Job): Throwable = parent.getCancellationException() CancellableContinuationImpl.cancel //commonMain/CancellableContinuationImpl.kt public override fun cancel(cause: Throwable?): Boolean { _state.loop { state -\u0026gt; if (state !is NotCompleted) return false // false if already complete or cancelling  // Active -- update to final state  val update = CancelledContinuation(this, cause, handled = state is CancelHandler) if (!_state.compareAndSet(state, update)) return@loop // retry on cas failure  // Invoke cancel handler if it was present  if (state is CancelHandler) invokeHandlerSafely { state.invoke(cause) } // Complete state update  disposeParentHandle() dispatchResume(mode = MODE_ATOMIC_DEFAULT)//main  return true } } dispatchResume private fun dispatchResume(mode: Int) { if (tryResume()) return // completed before getResult invocation -- bail out  // otherwise, getResult has already commenced, i.e. completed later or in other thread  dispatch(mode) } internal fun \u0026lt;T\u0026gt; DispatchedTask\u0026lt;T\u0026gt;.dispatch(mode: Int = MODE_CANCELLABLE) { val delegate = this.delegate if (mode.isDispatchedMode \u0026amp;\u0026amp; delegate is DispatchedContinuation\u0026lt;*\u0026gt; \u0026amp;\u0026amp; mode.isCancellableMode == resumeMode.isCancellableMode) { // dispatch directly using this instance\u0026#39;s Runnable implementation  val dispatcher = delegate.dispatcher val context = delegate.context if (dispatcher.isDispatchNeeded(context)) { dispatcher.dispatch(context, this) } else { resumeUnconfined() } } else { resume(delegate, mode)//main  } } internal fun \u0026lt;T\u0026gt; DispatchedTask\u0026lt;T\u0026gt;.resume(delegate: Continuation\u0026lt;T\u0026gt;, useMode: Int) { // slow-path - use delegate  val state = takeState() val exception = getExceptionalResult(state) if (exception != null) { /* * Recover stacktrace for non-dispatched tasks. * We usually do not recover stacktrace in a `resume` as all resumes go through `DispatchedTask.run` * and we recover stacktraces there, but this is not the case for a `suspend fun main()` that knows nothing about * kotlinx.coroutines and DispatchedTask */ val recovered = if (delegate is DispatchedTask\u0026lt;*\u0026gt;) exception else recoverStackTrace(exception, delegate) delegate.resumeWithExceptionMode(recovered, useMode)//main  } else { delegate.resumeMode(getSuccessfulResult(state), useMode) } } delegate.resumeWithExceptionMode internal fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeWithExceptionMode(exception: Throwable, mode: Int) { when (mode) { MODE_ATOMIC_DEFAULT -\u0026gt; resumeWithException(exception)//main  MODE_CANCELLABLE -\u0026gt; resumeCancellableWithException(exception) MODE_DIRECT -\u0026gt; resumeDirectWithException(exception) MODE_UNDISPATCHED -\u0026gt; (this as DispatchedContinuation).resumeUndispatchedWithException(exception) MODE_IGNORE -\u0026gt; {} else -\u0026gt; error(\u0026#34;Invalid mode $mode\u0026#34;) } } public inline fun \u0026lt;T\u0026gt; Continuation\u0026lt;T\u0026gt;.resumeWithException(exception: Throwable): Unit = resumeWith(Result.failure(exception)) override fun resumeWith(result: Result\u0026lt;T\u0026gt;) { val context = continuation.context val state = result.toState() if (dispatcher.isDispatchNeeded(context)) { _state = state resumeMode = MODE_ATOMIC_DEFAULT dispatcher.dispatch(context, this)//main  } else { executeUnconfined(state, MODE_ATOMIC_DEFAULT) { withCoroutineContext(this.context, countOrElement) { continuation.resumeWith(result)//main  } } } } 后续在dispatchedtask.run走异常resume流程\n之后:\nnternal abstract class BaseContinuationImpl( // This is `public val` so that it is private on JVM and cannot be modified by untrusted code, yet  // it has a public getter (since even untrusted code is allowed to inspect its call stack).  public val completion: Continuation\u0026lt;Any?\u0026gt;? ) : Continuation\u0026lt;Any?\u0026gt;, CoroutineStackFrame, Serializable { // This implementation is final. This fact is used to unroll resumeWith recursion.  public final override fun resumeWith(result: Result\u0026lt;Any?\u0026gt;) { // This loop unrolls recursion in current.resumeWith(param) to make saner and shorter stack traces on resume  var current = this var param = result//cancel时为Failure(kotlinx.coroutines.JobCancellationException  while (true) { // Invoke \u0026#34;resume\u0026#34; debug probe on every resumed continuation, so that a debugging library infrastructure  // can precisely track what part of suspended callstack was already resumed  probeCoroutineResumed(current) with(current) { val completion = completion!! // fail fast when trying to resume continuation without completion  val outcome: Result\u0026lt;Any?\u0026gt; = try { val outcome = invokeSuspend(param)//Failure类型的param会导致ResultKt.throwOnFailure($result)抛异常  if (outcome === COROUTINE_SUSPENDED) return Result.success(outcome) } catch (exception: Throwable) { //cancel时为kotlinx.coroutines.JobCancellationException  Result.failure(exception) } releaseIntercepted() // this state machine instance is terminating  if (completion is BaseContinuationImpl) { // unrolling recursion via loop  current = completion param = outcome } else { // top-level completion reached -- invoke and return  completion.resumeWith(outcome)//后续流程和非cancel异常处理类似，  //主要区别1:仅cancel时会notifyCancelling  //2.cancelParent(finalException) || handleJobException(finalException)时由于cancelParent为true,  //不会走handleJobException的异常处理流程  return } } } 参考 https://www.kotlincn.net/docs/reference/coroutines/cancellation-and-timeouts.html\nCancellation in coroutines\n"
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/coroutine/kotlin%E5%8D%8F%E7%A8%8B%E5%BC%82%E5%B8%B8/",
	"title": "kotlin协程异常",
	"tags": [],
	"description": "",
	"content": "协程内部异常分类 graph LR 协程内部trycatch--\u0026gt;|非suspend方法|作为invokeSuspend内部状态机中的一个分支,分支内和非协程类似catch,协程无感知 协程内部trycatch--\u0026gt;|suspend方法|抛出异常(\u0026quot;resume流程invokeSuspend时ResultKt.throwOnFailure($result);抛出异常\u0026quot;) CancellationException--\u0026gt;参考协程取消 协程UncaughtException /** kotlin/util/Result.kt * Throws exception if the result is failure. This internal function minimizes * inlined bytecode for [getOrThrow] and makes sure that in the future we can * add some exception-augmenting logic here (if needed). */ @PublishedApi @SinceKotlin(\u0026#34;1.3\u0026#34;) internal fun Result\u0026lt;*\u0026gt;.throwOnFailure() { if (value is Result.Failure) throw value.exception } 协程UncaughtException 标记异常 internal abstract class BaseContinuationImpl( // This is `public val` so that it is private on JVM and cannot be modified by untrusted code, yet  // it has a public getter (since even untrusted code is allowed to inspect its call stack).  public val completion: Continuation\u0026lt;Any?\u0026gt;? ) : Continuation\u0026lt;Any?\u0026gt;, CoroutineStackFrame, Serializable { // This implementation is final. This fact is used to unroll resumeWith recursion.  public final override fun resumeWith(result: Result\u0026lt;Any?\u0026gt;) { // This loop unrolls recursion in current.resumeWith(param) to make saner and shorter stack traces on resume  var current = this var param = result while (true) { // Invoke \u0026#34;resume\u0026#34; debug probe on every resumed continuation, so that a debugging library infrastructure  // can precisely track what part of suspended callstack was already resumed  probeCoroutineResumed(current) with(current) { val completion = completion!! // fail fast when trying to resume continuation without completion  val outcome: Result\u0026lt;Any?\u0026gt; = try { val outcome = invokeSuspend(param) if (outcome === COROUTINE_SUSPENDED) return Result.success(outcome) } catch (exception: Throwable) { Result.failure(exception)//main  } releaseIntercepted() // this state machine instance is terminating  if (completion is BaseContinuationImpl) { // unrolling recursion via loop  current = completion param = outcome } else { // top-level completion reached -- invoke and return  completion.resumeWith(outcome)//main  return } } } } AbstractCoroutine.resumeWith public abstract class AbstractCoroutine\u0026lt;in T\u0026gt; /** * Completes execution of this with coroutine with the specified result. */ public final override fun resumeWith(result: Result\u0026lt;T\u0026gt;) { makeCompletingOnce(result.toState(), defaultResumeMode) } JobSupport.makeCompletingOnce public open class JobSupport constructor(active: Boolean) : Job, ChildJob, ParentJob, SelectClause0 { internal fun makeCompletingOnce(proposedUpdate: Any?, mode: Int): Boolean = loopOnState { state -\u0026gt; when (tryMakeCompleting(state, proposedUpdate, mode)) { COMPLETING_ALREADY_COMPLETING -\u0026gt; throw IllegalStateException(\u0026#34;Job $thisis already complete or completing, \u0026#34; + \u0026#34;but is being completed with $proposedUpdate\u0026#34;, proposedUpdate.exceptionOrNull) COMPLETING_COMPLETED -\u0026gt; return true COMPLETING_WAITING_CHILDREN -\u0026gt; return false COMPLETING_RETRY -\u0026gt; return@loopOnState else -\u0026gt; error(\u0026#34;unexpected result\u0026#34;) } } private fun tryMakeCompleting(state: Any?, proposedUpdate: Any?, mode: Int): Int { if (state !is Incomplete) return COMPLETING_ALREADY_COMPLETING /* * FAST PATH -- no children to wait for \u0026amp;\u0026amp; simple state (no list) \u0026amp;\u0026amp; not cancelling =\u0026gt; can complete immediately * Cancellation (failures) always have to go through Finishing state to serialize exception handling. * Otherwise, there can be a race between (completed state -\u0026gt; handled exception and newly attached child/join) * which may miss unhandled exception. */ if ((state is Empty || state is JobNode\u0026lt;*\u0026gt;) \u0026amp;\u0026amp; state !is ChildHandleNode \u0026amp;\u0026amp; proposedUpdate !is CompletedExceptionally) { if (!tryFinalizeSimpleState(state, proposedUpdate, mode)) return COMPLETING_RETRY return COMPLETING_COMPLETED } // The separate slow-path function to simplify profiling  return tryMakeCompletingSlowPath(state, proposedUpdate, mode)//main } private fun tryMakeCompletingSlowPath(state: Incomplete, proposedUpdate: Any?, mode: Int): Int { // get state\u0026#39;s list or else promote to list to correctly operate on child lists  val list = getOrPromoteCancellingList(state) ?: return COMPLETING_RETRY // promote to Finishing state if we are not in it yet  // This promotion has to be atomic w.r.t to state change, so that a coroutine that is not active yet  // atomically transition to finishing \u0026amp; completing state  val finishing = state as? Finishing ?: Finishing(list, false, null) // must synchronize updates to finishing state  var notifyRootCause: Throwable? = null synchronized(finishing) { // check if this state is already completing  if (finishing.isCompleting) return COMPLETING_ALREADY_COMPLETING // mark as completing  finishing.isCompleting = true // if we need to promote to finishing then atomically do it here.  // We do it as early is possible while still holding the lock. This ensures that we cancelImpl asap  // (if somebody else is faster) and we synchronize all the threads on this finishing lock asap.  if (finishing !== state) { if (!_state.compareAndSet(state, finishing)) return COMPLETING_RETRY } // ## IMPORTANT INVARIANT: Only one thread (that had set isCompleting) can go past this point  require(!finishing.isSealed) // cannot be sealed  // add new proposed exception to the finishing state  val wasCancelling = finishing.isCancelling (proposedUpdate as? CompletedExceptionally)?.let { finishing.addExceptionLocked(it.cause) } // If it just becomes cancelling --\u0026gt; must process cancelling notifications  notifyRootCause = finishing.rootCause.takeIf { !wasCancelling }//cancel异常时notifyRootCause为null,不会notifyCancelling  } // process cancelling notification here -- it cancels all the children _before_ we start to to wait them (sic!!!)  notifyRootCause?.let { notifyCancelling(list, it) } // now wait for children  val child = firstChild(state) if (child != null \u0026amp;\u0026amp; tryWaitForChild(finishing, child, proposedUpdate)) return COMPLETING_WAITING_CHILDREN // otherwise -- we have not children left (all were already cancelled?)  if (tryFinalizeFinishingState(finishing, proposedUpdate, mode)) return COMPLETING_COMPLETED // otherwise retry  return COMPLETING_RETRY } tryFinalizeFinishingState // Finalizes Finishing -\u0026gt; Completed (terminal state) transition. // ## IMPORTANT INVARIANT: Only one thread can be concurrently invoking this method. private fun tryFinalizeFinishingState(state: Finishing, proposedUpdate: Any?, mode: Int): Boolean { /* * Note: proposed state can be Incomplete, e.g. * async { * something.invokeOnCompletion {} // \u0026lt;- returns handle which implements Incomplete under the hood * } */ require(this.state === state) // consistency check -- it cannot change  require(!state.isSealed) // consistency check -- cannot be sealed yet  require(state.isCompleting) // consistency check -- must be marked as completing  val proposedException = (proposedUpdate as? CompletedExceptionally)?.cause // Create the final exception and seal the state so that no more exceptions can be added  var wasCancelling = false // KLUDGE: we cannot have contract for our own expect fun synchronized  val finalException = synchronized(state) { wasCancelling = state.isCancelling val exceptions = state.sealLocked(proposedException) val finalCause = getFinalRootCause(state, exceptions) if (finalCause != null) addSuppressedExceptions(finalCause, exceptions) finalCause } // Create the final state object  val finalState = when { // was not cancelled (no exception) -\u0026gt; use proposed update value  finalException == null -\u0026gt; proposedUpdate // small optimization when we can used proposeUpdate object as is on cancellation  finalException === proposedException -\u0026gt; proposedUpdate // cancelled job final state  else -\u0026gt; CompletedExceptionally(finalException) } // Now handle the final exception  if (finalException != null) { val handled = cancelParent(finalException) || handleJobException(finalException)//main,handleJobException  if (handled) (finalState as CompletedExceptionally).makeHandled() } // Process state updates for the final state before the state of the Job is actually set to the final state  // to avoid races where outside observer may see the job in the final state, yet exception is not handled yet.  if (!wasCancelling) onCancelling(finalException) onCompletionInternal(finalState) // Then CAS to completed state -\u0026gt; it must succeed  require(_state.compareAndSet(state, finalState.boxIncomplete())) { \u0026#34;Unexpected state: ${_state.value}, expected: $state, update: $finalState\u0026#34; } // And process all post-completion actions  completeStateFinalization(state, finalState, mode) return true } /** * The method that is invoked when the job is cancelled to possibly propagate cancellation to the parent. * Returns `true` if the parent is responsible for handling the exception, `false` otherwise. * * Invariant: never returns `false` for instances of [CancellationException], otherwise such exception * may leak to the [CoroutineExceptionHandler]. */ private fun cancelParent(cause: Throwable): Boolean { // Is scoped coroutine -- don\u0026#39;t propagate, will be rethrown  if (isScopedCoroutine) return true /* CancellationException is considered \u0026#34;normal\u0026#34; and parent usually is not cancelled when child produces it. * This allow parent to cancel its children (normally) without being cancelled itself, unless * child crashes and produce some other exception during its completion. */ val isCancellation = cause is CancellationException val parent = parentHandle // No parent -- ignore CE, report other exceptions.  if (parent === null || parent === NonDisposableHandle) { return isCancellation//仅cancel时parent === NonDisposableHandle,return true  } // Notify parent but don\u0026#39;t forget to check cancellation  return parent.childCancelled(cause) || isCancellation } 处理异常 StandaloneCoroutine.handleJobException private open class StandaloneCoroutine( parentContext: CoroutineContext, active: Boolean ) : AbstractCoroutine\u0026lt;Unit\u0026gt;(parentContext, active) { override fun handleJobException(exception: Throwable): Boolean { handleCoroutineException(context, exception) return true } } context[CoroutineExceptionHandler].handleException commonMain/CoroutineExceptionHandler.kt\n/** * Helper function for coroutine builder implementations to handle uncaught and unexpected exceptions in coroutines, * that could not be otherwise handled in a normal way through structured concurrency, saving them to a future, and * cannot be rethrown. This is a last resort handler to prevent lost exceptions. * * If there is [CoroutineExceptionHandler] in the context, then it is used. If it throws an exception during handling * or is absent, all instances of [CoroutineExceptionHandler] found via [ServiceLoader] and * [Thread.uncaughtExceptionHandler] are invoked. */ @InternalCoroutinesApi public fun handleCoroutineException(context: CoroutineContext, exception: Throwable) { // Invoke an exception handler from the context if present  try { context[CoroutineExceptionHandler]?.let { it.handleException(context, exception) return } } catch (t: Throwable) { handleCoroutineExceptionImpl(context, handlerException(exception, t)) return } // If a handler is not present in the context or an exception was thrown, fallback to the global handler  handleCoroutineExceptionImpl(context, exception) } handleCoroutineExceptionImpl jvmMain/CoroutineExceptionHandlerImpl.kt\ninternal actual fun handleCoroutineExceptionImpl(context: CoroutineContext, exception: Throwable) { // use additional extension handlers  for (handler in handlers) { try { handler.handleException(context, exception) } catch (t: Throwable) { // Use thread\u0026#39;s handler if custom handler failed to handle exception  val currentThread = Thread.currentThread() currentThread.uncaughtExceptionHandler.uncaughtException(currentThread, handlerException(exception, t)) } } // use thread\u0026#39;s handler  val currentThread = Thread.currentThread() currentThread.uncaughtExceptionHandler.uncaughtException(currentThread, exception) } /** * A list of globally installed [CoroutineExceptionHandler] instances. * * Note that Android may have dummy [Thread.contextClassLoader] which is used by one-argument [ServiceLoader.load] function, * see (https://stackoverflow.com/questions/13407006/android-class-loader-may-fail-for-processes-that-host-multiple-applications). * So here we explicitly use two-argument `load` with a class-loader of [CoroutineExceptionHandler] class. * * We are explicitly using the `ServiceLoader.load(MyClass::class.java, MyClass::class.java.classLoader).iterator()` * form of the ServiceLoader call to enable R8 optimization when compiled on Android. */ private val handlers: List\u0026lt;CoroutineExceptionHandler\u0026gt; = ServiceLoader.load( CoroutineExceptionHandler::class.java, CoroutineExceptionHandler::class.java.classLoader ).iterator().asSequence().toList() AndroidExceptionPreHandler.handleException @Keep internal class AndroidExceptionPreHandler : AbstractCoroutineContextElement(CoroutineExceptionHandler), CoroutineExceptionHandler, Function0\u0026lt;Method?\u0026gt; { override fun handleException(context: CoroutineContext, exception: Throwable) { /* * If we are on old SDK, then use Android\u0026#39;s `Thread.getUncaughtExceptionPreHandler()` that ensures that * an exception is logged before crashing the application. * * Since Android Pie default uncaught exception handler always ensures that exception is logged without interfering with * pre-handler, so reflection hack is no longer needed. * * See https://android-review.googlesource.com/c/platform/frameworks/base/+/654578/ */ val thread = Thread.currentThread() if (Build.VERSION.SDK_INT \u0026gt;= 28) { thread.uncaughtExceptionHandler.uncaughtException(thread, exception)//main  } else { (preHandler?.invoke(null) as? Thread.UncaughtExceptionHandler) ?.uncaughtException(thread, exception) } } Thread\npublic UncaughtExceptionHandler getUncaughtExceptionHandler() { return uncaughtExceptionHandler != null ? uncaughtExceptionHandler : group; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/layoutinflater/layoutinflater/",
	"title": "LayoutInflater",
	"tags": [],
	"description": "",
	"content": "原理图 视图层级 AppCompatActivity.setContentView @Override public void setContentView(@LayoutRes int layoutResID) { getDelegate().setContentView(layoutResID); } AppCompatDelegateImpl.java\n@Override public void setContentView(int resId) { ensureSubDecor(); ViewGroup contentParent = mSubDecor.findViewById(android.R.id.content); contentParent.removeAllViews(); LayoutInflater.from(mContext).inflate(resId, contentParent); } installDecor,createSubDecor private void ensureSubDecor() { if (!mSubDecorInstalled) { mSubDecor = createSubDecor(); } } private ViewGroup createSubDecor() { // Now let\u0026#39;s make sure that the Window has installed its decor by retrieving it  //确保优先初始化 DecorView  mWindow.getDecorView();//PhoneWindow  ViewGroup subDecor = null; //根据不同的设置来对 subDecor 进行初始化  if (!mWindowNoTitle) { subDecor = title相关的view } else { if (mOverlayActionMode) { subDecor = (ViewGroup) inflater.inflate( R.layout.abc_screen_simple_overlay_action_mode, null); } else { subDecor = (ViewGroup) inflater.inflate(R.layout.abc_screen_simple, null); } } // Now set the Window\u0026#39;s content view with the decor  // 将 subDecor 添加到 DecorView 中  mWindow.setContentView(subDecor); return subDecor; } PhoneWindow.java\n@Override public final View getDecorView() { if (mDecor == null || mForceDecorInstall) { installDecor(); } return mDecor; } private void installDecor() { if (mDecor == null) { mDecor = generateDecor(-1); } else { mDecor.setWindow(this); } if (mContentParent == null) { mContentParent = generateLayout(mDecor); } } protected DecorView generateDecor(int featureId) { return new DecorView(context, featureId, this, getAttributes()); } protected ViewGroup generateLayout(DecorView decor) { ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT); return contentParent; } findViewById Window.java @Nullable public \u0026lt;T extends View\u0026gt; T findViewById(@IdRes int id) { return getDecorView().findViewById(id); } View.java @Nullable public final \u0026lt;T extends View\u0026gt; T findViewById(@IdRes int id) { if (id == NO_ID) { return null; } return findViewTraversal(id); } ViewGroup.java @Override protected \u0026lt;T extends View\u0026gt; T findViewTraversal(@IdRes int id) { if (id == mID) { return (T) this; } final View[] where = mChildren; final int len = mChildrenCount; for (int i = 0; i \u0026lt; len; i++) { View v = where[i]; if ((v.mPrivateFlags \u0026amp; PFLAG_IS_ROOT_NAMESPACE) == 0) { v = v.findViewById(id); if (v != null) { return (T) v; } } } return null; } LayoutInflater.from /** * Obtains the LayoutInflater from the given context. */ public static LayoutInflater from(Context context) { //对应的BinderServer是PhoneLayoutInflater,位于当前进程，不走ServiceManager获取  LayoutInflater LayoutInflater = (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE); return LayoutInflater; } Activity.java\n@Override public Object getSystemService(@ServiceName @NonNull String name) { if (WINDOW_SERVICE.equals(name)) { return mWindowManager; } else if (SEARCH_SERVICE.equals(name)) { ensureSearchManager(); return mSearchManager; } return super.getSystemService(name); } ContextThemeWrapper.java\n@Override public Object getSystemService(String name) { if (LAYOUT_INFLATER_SERVICE.equals(name)) { if (mInflater == null) { mInflater = LayoutInflater.from(getBaseContext()).cloneInContext(this); } return mInflater; } return getBaseContext().getSystemService(name); } ContextImpl.java\n@Override public Object getSystemService(String name) { return SystemServiceRegistry.getSystemService(this, name); } SystemServiceRegistry.java\nregisterService(Context.LAYOUT_INFLATER_SERVICE, LayoutInflater.class, new CachedServiceFetcher\u0026lt;LayoutInflater\u0026gt;() { @Override public LayoutInflater createService(ContextImpl ctx) { return new PhoneLayoutInflater(ctx.getOuterContext()); }}); PhoneLayoutInflater.inflate public class PhoneLayoutInflater extends LayoutInflater { public View inflate(@LayoutRes int resource, @Nullable ViewGroup root) { return inflate(resource, root, root != null); } public View inflate(@LayoutRes int resource, @Nullable ViewGroup root, boolean attachToRoot) { final Resources res = getContext().getResources(); final XmlResourceParser parser = res.getLayout(resource); return inflate(parser, root, attachToRoot); } public View inflate(XmlPullParser parser, @Nullable ViewGroup root, boolean attachToRoot) { // Temp is the root view that was found in the xml  final View temp = createViewFromTag(root, name, inflaterContext, attrs); // Inflate all children under temp against its context.  rInflateChildren(parser, temp, attrs, true); // We are supposed to attach all the views we found (int temp)  // to root. Do that now.  if (root != null \u0026amp;\u0026amp; attachToRoot) { root.addView(temp, params); } } createRootViewInXml rInflateChildren final void rInflateChildren(XmlPullParser parser, View parent, AttributeSet attrs, boolean finishInflate) throws XmlPullParserException, IOException { rInflate(parser, parent, parent.getContext(), attrs, finishInflate); } void rInflate(XmlPullParser parser, View parent, Context context, AttributeSet attrs, boolean finishInflate) throws XmlPullParserException, IOException { while (((type = parser.next()) != XmlPullParser.END_TAG || parser.getDepth() \u0026gt; depth) \u0026amp;\u0026amp; type != XmlPullParser.END_DOCUMENT) { final View view = createViewFromTag(parent, name, context, attrs); final ViewGroup viewGroup = (ViewGroup) parent; final ViewGroup.LayoutParams params = viewGroup.generateLayoutParams(attrs); rInflateChildren(parser, view, attrs, true); viewGroup.addView(view, params); } } createViewFromTag private View createViewFromTag(View parent, String name, Context context, AttributeSet attrs) { return createViewFromTag(parent, name, context, attrs, false); } View createViewFromTag(View parent, String name, Context context, AttributeSet attrs, boolean ignoreThemeAttr) { View view; if (mFactory2 != null) { view = mFactory2.onCreateView(parent, name, context, attrs); } else if (mFactory != null) { view = mFactory.onCreateView(name, context, attrs); } else { view = null; } if (view == null \u0026amp;\u0026amp; mPrivateFactory != null) { view = mPrivateFactory.onCreateView(parent, name, context, attrs); } if (view == null) { final Object lastContext = mConstructorArgs[0]; mConstructorArgs[0] = context; try { if (-1 == name.indexOf(\u0026#39;.\u0026#39;)) { view = onCreateView(parent, name, attrs); } else { view = createView(name, null, attrs); } } finally { mConstructorArgs[0] = lastContext; } } return view; } default Factory2\u0026ndash;\u0026gt;AppCompatDelegateImpl.java public final View onCreateView(View parent, String name, Context context, AttributeSet attrs) { return createView(parent, name, context, attrs); } @Override public View createView(View parent, final String name, @NonNull Context context, @NonNull AttributeSet attrs) { return mAppCompatViewInflater.createView(parent, name, context, attrs, inheritContext, IS_PRE_LOLLIPOP, /* Only read android:theme pre-L (L+ handles this anyway) */ true, /* Read read app:theme as a fallback at all times for legacy reasons */ VectorEnabledTintResources.shouldBeUsed() /* Only tint wrap the context if enabled */ ); final View createView(View parent, final String name, @NonNull Context context, @NonNull AttributeSet attrs, boolean inheritContext, boolean readAndroidTheme, boolean readAppTheme, boolean wrapContext) { // We need to \u0026#39;inject\u0026#39; our tint aware Views in place of the standard framework versions  switch (name) { case \u0026#34;TextView\u0026#34;: view = createTextView(context, attrs); verifyNotNull(view, name); break; case \u0026#34;ImageView\u0026#34;: view = createImageView(context, attrs); verifyNotNull(view, name); break; case \u0026#34;Button\u0026#34;: view = createButton(context, attrs); verifyNotNull(view, name); break; ...... } if (view == null \u0026amp;\u0026amp; originalContext != context) { // If the original context does not equal our themed context, then we need to manually  // inflate it using the name so that android:theme takes effect.  view = createViewFromTag(context, name, attrs); } } @NonNull protected AppCompatButton createButton(Context context, AttributeSet attrs) { return new AppCompatButton(context, attrs); } private View createViewFromTag(Context context, String name, AttributeSet attrs) { createViewByPrefix(context, name, null) } private View createViewByPrefix(Context context, String name, String prefix) throws ClassNotFoundException, InflateException { Constructor\u0026lt;? extends View\u0026gt; constructor = sConstructorMap.get(name); if (constructor == null) { // Class not found in the cache, see if it\u0026#39;s real, and try to add it  Class\u0026lt;? extends View\u0026gt; clazz = Class.forName( prefix != null ? (prefix + name) : name, false, context.getClassLoader()).asSubclass(View.class); constructor = clazz.getConstructor(sConstructorSignature); sConstructorMap.put(name, constructor); } constructor.setAccessible(true); return constructor.newInstance(mConstructorArgs); } public void setFactory2(Factory2 factory) { if (mFactorySet) { throw new IllegalStateException(\u0026#34;A factory has already been set on this LayoutInflater\u0026#34;); } mFactorySet = true; if (mFactory == null) { mFactory = mFactory2 = factory; } else { mFactory = mFactory2 = new FactoryMerger(factory, factory, mFactory, mFactory2); } } root.addView 参考 Android DecorView 与 Activity 绑定原理分析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/layoutinflater/",
	"title": "layoutinflater",
	"tags": [],
	"description": "",
	"content": "layoutinflater 探索总结layoutinflater知识\n LayoutInflater     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/compose/layoutnode/",
	"title": "LayoutNode",
	"tags": [],
	"description": "",
	"content": "Measure原理图 graph TB XxModifier--\u0026gt;MeasureScope.measure(\u0026quot;MeasureScope.measure\u0026quot;)--\u0026gt;|1|measurable(\u0026quot;measurable.measure(constraints)\u0026quot;) measurable--\u0026gt;|1|performMeasure performMeasure--\u0026gt;|1|MeasureScope.measure MeasureScope.measure--\u0026gt;|2|MeasureScope.layout Draw原理图 graph TB InnerPlaceable.performDraw--\u0026gt;|forEach|drawChild(\u0026quot;child.draw(canvas)\u0026quot;)--\u0026gt;ViewLayer.drawLayer --\u0026gt;ViewLayer.dispatchDraw--\u0026gt;|drawBlock|LayoutNodeWrapper.invoke--\u0026gt;performDraw(\u0026quot;performDraw(canvas)\u0026quot;) --\u0026gt;|leafNode?|DrawModifier.ContentDrawScope.draw performDraw--\u0026gt;|parentNode?|InnerPlaceable.performDraw LayoutNode类设计图 classDiagram class IntrinsicMeasurable{ \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +parentData: Any? } class Measurable { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +measure(constraints: Constraints): Placeable } IntrinsicMeasurable\u0026lt;|--Measurable Measurable\u0026lt;|--LayoutNode Measurable\u0026lt;|--OuterMeasurablePlaceable Measurable\u0026lt;|--LayoutNodeWrapper class Measured { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +measuredWidth: Int +measuredHeight: Int } class Placeable { +place(x: Int, y: Int, zIndex: Float = 0f) } class LayoutNodeWrapper{ +layoutNode: LayoutNode +layer: OwnedLayer +performMeasure(constraints: Constraints)Placeable +draw(canvas: Canvas) } class OuterMeasurablePlaceable { +layoutNode: LayoutNode +outerWrapper: LayoutNodeWrapper } class LayoutNode { +innerLayoutNodeWrapper: LayoutNodeWrapper = InnerPlaceable(this) +outerMeasurablePlaceable = OuterMeasurablePlaceable(this, innerLayoutNodeWrapper) +outerLayoutNodeWrapper: LayoutNodeWrapper +mDrawScope: LayoutNodeDrawScope = sharedDrawScope } class ModifiedDrawNode{ +modifier: DrawModifier } class DelegatingLayoutNodeWrapper~T : Modifier.Element~ { +wrapped: LayoutNodeWrapper +modifier: T } Measured\u0026lt;|--Placeable Placeable\u0026lt;|--OuterMeasurablePlaceable Placeable\u0026lt;|--LayoutNodeWrapper LayoutNodeWrapper\u0026lt;|--InnerPlaceable LayoutNodeWrapper\u0026lt;|--DelegatingLayoutNodeWrapper DelegatingLayoutNodeWrapper\u0026lt;|--ModifiedLayoutNode DelegatingLayoutNodeWrapper\u0026lt;|--ModifiedDrawNode Modifier类设计图 classDiagram Modifier\u0026lt;|--Element class LayoutModifier { +MeasureScope.measure( measurable: Measurable, constraints: Constraints ): MeasureResult } class PaddingModifier { +MeasureScope.measure( measurable: Measurable, constraints: Constraints ): MeasureResult } class OffsetModifier { +MeasureScope.measure( measurable: Measurable, constraints: Constraints ): MeasureResult } Element\u0026lt;|--LayoutModifier LayoutModifier\u0026lt;|--PaddingModifier LayoutModifier\u0026lt;|--OffsetModifier class IntrinsicMeasureScope { +layoutDirection: LayoutDirection } Density\u0026lt;|--IntrinsicMeasureScope class MeasureScope { +layout() MeasureResult } IntrinsicMeasureScope\u0026lt;|--MeasureScope class DrawModifier { +ContentDrawScope.draw() } class Background { +ContentDrawScope.draw() } class PainterModifier { +ContentDrawScope.draw() } Element\u0026lt;|--DrawModifier LayoutModifier\u0026lt;|--PainterModifier DrawModifier\u0026lt;|--PainterModifier DrawModifier\u0026lt;|--Background class DrawScope { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; +drawContext: DrawContext +layoutDirection: LayoutDirection } class ContentDrawScope { +drawContent() } class LayoutNodeDrawScope { +canvasDrawScope: CanvasDrawScope = CanvasDrawScope() } class CanvasDrawScope { +draw(...) } Density\u0026lt;|--DrawScope DrawScope\u0026lt;|--ContentDrawScope ContentDrawScope\u0026lt;|--LayoutNodeDrawScope DrawScope\u0026lt;|--CanvasDrawScope Layout_Usage Using the layout modifier fun Modifier.firstBaselineToTop( firstBaselineToTop: Dp ) = Modifier.layout { measurable, constraints -\u0026gt; // Measure the composable  val placeable = measurable.measure(constraints) // Check the composable has a first baseline  check(placeable[FirstBaseline] != AlignmentLine.Unspecified) val firstBaseline = placeable[FirstBaseline] // Height of the composable with padding - first baseline  val placeableY = firstBaselineToTop.toIntPx() - firstBaseline val height = placeable.height + placeableY layout(placeable.width, height) { // Where the composable gets placed  placeable.place(0, placeableY) } } Creating custom layouts @Composable fun MyBasicColumn( modifier: Modifier = Modifier, content: @Composable() () -\u0026gt; Unit ) { Layout( modifier = modifier, content = content ) { measurables, constraints -\u0026gt; // Don\u0026#39;t constrain child views further, measure them with given constraints  // List of measured children  val placeables = measurables.map { measurable -\u0026gt; // Measure each children  measurable.measure(constraints.copy(minHeight = 0)) } // Set the size of the layout as big as it can  layout(constraints.maxWidth, constraints.maxHeight) { // Track the y co-ord we have placed children up to  var yPosition = 0 // Place children in the parent layout  placeables.forEach { placeable -\u0026gt; // Position item on the screen  placeable.place(x = 0, y = yPosition) // Record the y co-ord placed up to  yPosition += placeable.height } } } } Measure_Layout AndroidComposeView.onMeasure override fun onMeasure(widthMeasureSpec: Int, heightMeasureSpec: Int) { trace(\u0026#34;AndroidOwner:onMeasure\u0026#34;) { if (!isAttachedToWindow) { invalidateLayoutNodeMeasurement(root) } val (minWidth, maxWidth) = convertMeasureSpec(widthMeasureSpec) val (minHeight, maxHeight) = convertMeasureSpec(heightMeasureSpec) val constraints = Constraints(minWidth, maxWidth, minHeight, maxHeight) if (onMeasureConstraints == null) { // first onMeasure after last onLayout  onMeasureConstraints = constraints wasMeasuredWithMultipleConstraints = false } else if (onMeasureConstraints != constraints) { // we were remeasured twice with different constraints after last onLayout  wasMeasuredWithMultipleConstraints = true } measureAndLayoutDelegate.updateRootConstraints(constraints) measureAndLayoutDelegate.measureAndLayout()//main  setMeasuredDimension(root.width, root.height)//main  } } convertMeasureSpec private fun convertMeasureSpec(measureSpec: Int): Pair\u0026lt;Int, Int\u0026gt; { val mode = MeasureSpec.getMode(measureSpec) val size = MeasureSpec.getSize(measureSpec) return when (mode) { MeasureSpec.EXACTLY -\u0026gt; size to size MeasureSpec.UNSPECIFIED -\u0026gt; 0 to Constraints.Infinity MeasureSpec.AT_MOST -\u0026gt; 0 to size else -\u0026gt; throw IllegalStateException() } } /** * @param constraints The constraints to measure the root [LayoutNode] with */ fun updateRootConstraints(constraints: Constraints) { if (rootConstraints != constraints) { rootConstraints = constraints root.layoutState = NeedsRemeasure relayoutNodes.add(root) } } override val root = LayoutNode().also { it.measurePolicy = RootMeasurePolicy it.modifier = Modifier .then(semanticsModifier) .then(_focusManager.modifier) .then(keyInputModifier) } measureAndLayout /** * Iterates through all LayoutNodes that have requested layout and measures and lays them out */ fun measureAndLayout(): Boolean { .... if (relayoutNodes.isNotEmpty()) { relayoutNodes.popEach { layoutNode -\u0026gt; if (layoutNode.layoutState == NeedsRemeasure) { if (doRemeasure(layoutNode, rootConstraints)) { rootNodeResized = true } } if (layoutNode.layoutState == NeedsRelayout \u0026amp;\u0026amp; layoutNode.isPlaced) { if (layoutNode === root) { layoutNode.place(0, 0) } else { layoutNode.replace() } onPositionedDispatcher.onNodePositioned(layoutNode) } measureIteration++ // execute postponed `onRequestMeasure`  if (postponedMeasureRequests.isNotEmpty()) { postponedMeasureRequests.fastForEach { if (it.isAttached) { requestRemeasure(it) } } postponedMeasureRequests.clear() } } MeasureAndLayoutDelegate.requestRemeasure /** MeasureAndLayoutDelegate.kt * Requests remeasure for this [layoutNode] and nodes affected by its measure result. * * @return returns true if the [measureAndLayout] execution should be scheduled as a result * of the request. */ fun requestRemeasure(layoutNode: LayoutNode): Boolean = when (layoutNode.layoutState) { Measuring, NeedsRemeasure -\u0026gt; { // requestMeasure has already been called for this node or  // we\u0026#39;re currently measuring it, let\u0026#39;s swallow. example when it happens: we compose  // DataNode inside BoxWithConstraints, this calls onRequestMeasure on DataNode\u0026#39;s  // parent, but this parent is BoxWithConstraints which is currently measuring.  false } LayingOut -\u0026gt; { // requestMeasure is currently laying out and it is incorrect to request remeasure  // now, let\u0026#39;s postpone it.  postponedMeasureRequests.add(layoutNode) consistencyChecker?.assertConsistent() false } NeedsRelayout, Ready -\u0026gt; { if (duringMeasureLayout \u0026amp;\u0026amp; layoutNode.wasMeasuredDuringThisIteration) { postponedMeasureRequests.add(layoutNode) } else { layoutNode.layoutState = NeedsRemeasure if (layoutNode.isPlaced || layoutNode.canAffectParent) { val parentLayoutState = layoutNode.parent?.layoutState if (parentLayoutState != NeedsRemeasure) { relayoutNodes.add(layoutNode) } } } !duringMeasureLayout } } MeasureAndLayoutDelegate.doRemeasure private fun doRemeasure(layoutNode: LayoutNode, rootConstraints: Constraints): Boolean { val sizeChanged = if (layoutNode === root) { layoutNode.remeasure(rootConstraints) } else { layoutNode.remeasure() } val parent = layoutNode.parent if (sizeChanged) { if (parent == null) { return true } else if (layoutNode.measuredByParent == InMeasureBlock) { requestRemeasure(parent) } else { require(layoutNode.measuredByParent == InLayoutBlock) requestRelayout(parent) } } return false } LayoutNode.remeasure /** * Return true if the measured size has been changed */ internal fun remeasure( constraints: Constraints = outerMeasurablePlaceable.lastConstraints!! ) = outerMeasurablePlaceable.remeasure(constraints) /** OuterMeasurablePlaceable.kt * Return true if the measured size has been changed */ fun remeasure(constraints: Constraints): Boolean { val outerWrapperPreviousMeasuredSize = outerWrapper.size owner.snapshotObserver.observeMeasureSnapshotReads(layoutNode) { outerWrapper.measure(constraints)//main  } } LayoutNodeWrapper.measure /** LayoutNodeWrapper.kt * Measures the modified child. */ final override fun measure(constraints: Constraints): Placeable { measurementConstraints = constraints val result = performMeasure(constraints) layer?.resize(measuredSize) return result } ModifiedLayoutNode.performMeasure internal class ModifiedLayoutNode( wrapped: LayoutNodeWrapper, modifier: LayoutModifier ) : DelegatingLayoutNodeWrapper\u0026lt;LayoutModifier\u0026gt;(wrapped, modifier) { override fun performMeasure(constraints: Constraints): Placeable = with(modifier) { measureResult = measureScope.measure(wrapped, constraints) this@ModifiedLayoutNode } Modifier.paddin //Padding.kt @Stable fun Modifier.padding(all: Dp) = this.then( PaddingModifier( start = all, top = all, end = all, bottom = all, rtlAware = true, inspectorInfo = debugInspectorInfo { name = \u0026#34;padding\u0026#34; value = all } ) ) PaddingModifier.MeasureScope.measure private class PaddingModifier( val start: Dp = 0.dp, val top: Dp = 0.dp, val end: Dp = 0.dp, val bottom: Dp = 0.dp, val rtlAware: Boolean, inspectorInfo: InspectorInfo.() -\u0026gt; Unit ) : LayoutModifier, InspectorValueInfo(inspectorInfo) { override fun MeasureScope.measure( measurable: Measurable, constraints: Constraints ): MeasureResult { val horizontal = start.roundToPx() + end.roundToPx() val vertical = top.roundToPx() + bottom.roundToPx() val placeable = measurable.measure(constraints.offset(-horizontal, -vertical)) val width = constraints.constrainWidth(placeable.width + horizontal) val height = constraints.constrainHeight(placeable.height + vertical) return layout(width, height) { if (rtlAware) { placeable.placeRelative(start.roundToPx(), top.roundToPx()) } else { placeable.place(start.roundToPx(), top.roundToPx()) } } } @Composable fun Spacer(modifier: Modifier) { Layout({}, modifier) { _, constraints -\u0026gt; with(constraints) { val width = if (hasFixedWidth) maxWidth else 0 val height = if (hasFixedHeight) maxHeight else 0 layout(width, height) {} } } } LayerNodeWrapper.placeAt override fun placeAt( position: IntOffset, zIndex: Float, layerBlock: (GraphicsLayerScope.() -\u0026gt; Unit)? ) { onLayerBlockUpdated(layerBlock) if (this.position != position) { this.position = position val layer = layer if (layer != null) { layer.move(position) } else { wrappedBy?.invalidateLayer() } layoutNode.owner?.onLayoutChange(layoutNode) } this.zIndex = zIndex } fun onLayerBlockUpdated(layerBlock: (GraphicsLayerScope.() -\u0026gt; Unit)?) { val blockHasBeenChanged = this.layerBlock !== layerBlock this.layerBlock = layerBlock if (isAttached \u0026amp;\u0026amp; layerBlock != null) { if (layer == null) { layer = layoutNode.requireOwner().createLayer( this, invalidateParentLayer AndroidComposeView.createLayer override fun createLayer( drawBlock: (Canvas) -\u0026gt; Unit, invalidateParentLayer: () -\u0026gt; Unit ): OwnedLayer { // RenderNode is supported on Q+ for certain, but may also be supported on M-O.  // We can\u0026#39;t be confident that RenderNode is supported, so we try and fail over to  // the ViewLayer implementation. We\u0026#39;ll try even on on P devices, but it will fail  // until ART allows things on the unsupported list on P.  if (Build.VERSION.SDK_INT \u0026gt;= Build.VERSION_CODES.M \u0026amp;\u0026amp; isRenderNodeCompatible) { try { return RenderNodeLayer( this, drawBlock, invalidateParentLayer ) } catch (_: Throwable) { isRenderNodeCompatible = false } } return ViewLayer( this, viewLayersContainer, drawBlock, invalidateParentLayer ) } internal class ViewLayer( val ownerView: AndroidComposeView, val container: ViewLayerContainer, val drawBlock: (Canvas) -\u0026gt; Unit, val invalidateParentLayer: () -\u0026gt; Unit ) : View(ownerView.context), OwnedLayer { init { setWillNotDraw(false) // we WILL draw  id = generateViewId() container.addView(this) } } Draw AndroidComposeView.dispatchDraw override fun dispatchDraw(canvas: android.graphics.Canvas) { if (!isAttachedToWindow) { invalidateLayers(root) } measureAndLayout() // we don\u0026#39;t have to observe here because the root has a layer modifier  // that will observe all children. The AndroidComposeView has only the  // root, so it doesn\u0026#39;t have to invalidate itself based on model changes.  canvasHolder.drawInto(canvas) { root.draw(this) }//main  if (dirtyLayers.isNotEmpty()) { for (i in 0 until dirtyLayers.size) { val layer = dirtyLayers[i] layer.updateDisplayList() } dirtyLayers.clear() } } LayoutNode.draw internal fun draw(canvas: Canvas) = outerLayoutNodeWrapper.draw(canvas) LayoutNodeWapper.draw /** * Draws the content of the LayoutNode */ fun draw(canvas: Canvas) { val layer = layer if (layer != null) { layer.drawLayer(canvas)//main  } else { val x = position.x.toFloat() val y = position.y.toFloat() canvas.translate(x, y) performDraw(canvas)//main  canvas.translate(-x, -y) } } DelegateLayoutWrapper.performDraw override fun performDraw(canvas: Canvas) { wrapped.draw(canvas) } ViewLayer.drawLayer override fun drawLayer(canvas: Canvas) { drawnWithZ = elevation \u0026gt; 0f if (drawnWithZ) { canvas.enableZ() } container.drawChild(canvas, this, drawingTime)//main  if (drawnWithZ) { canvas.disableZ() } } ViewLayerContainer.drawChild // we change visibility for this method so ViewLayer can use it for drawing internal fun drawChild(canvas: Canvas, view: View, drawingTime: Long) { super.drawChild(canvas.nativeCanvas, view, drawingTime)//call ViewGroup\u0026#39;s drawChild } ViewLayer.dispatchDraw override fun dispatchDraw(canvas: android.graphics.Canvas) { canvasHolder.drawInto(canvas) { val clipPath = manualClipPath if (clipPath != null) { save() clipPath(clipPath) } drawBlock(this)//main  if (clipPath != null) { restore() } isInvalidated = false } } CanvasHolder.drawInto /** * Holder class that is used to issue scoped calls to a [Canvas] from the framework * equivalent canvas without having to allocate an object on each draw call */ class CanvasHolder { @PublishedApi internal val androidCanvas = AndroidCanvas() inline fun drawInto(targetCanvas: android.graphics.Canvas, block: Canvas.() -\u0026gt; Unit) { val previousCanvas = androidCanvas.internalCanvas androidCanvas.internalCanvas = targetCanvas androidCanvas.block() androidCanvas.internalCanvas = previousCanvas } } drawBlock: LayerNodeWrapper.invoke // implementation of draw block passed to the OwnedLayer override fun invoke(canvas: Canvas) { if (layoutNode.isPlaced) { require(layoutNode.layoutState == LayoutNode.LayoutState.Ready) { \u0026#34;Layer is redrawn for LayoutNode in state ${layoutNode.layoutState}[$layoutNode]\u0026#34; } snapshotObserver.observeReads(this, onCommitAffectingLayer) { performDraw(canvas)//main  } lastLayerDrawingWasSkipped = false } else { // The invalidation is requested even for nodes which are not placed. As we are not  // going to display them we skip the drawing. It is safe to just draw nothing as the  // layer will be invalidated again when the node will be finally placed.  lastLayerDrawingWasSkipped = true } } InnerPlaceable.performDraw override fun performDraw(canvas: Canvas) { val owner = layoutNode.requireOwner()//AndroidComposeView  layoutNode.zSortedChildren.forEach { child -\u0026gt; if (child.isPlaced) { require(child.layoutState == LayoutNode.LayoutState.Ready) { \u0026#34;$childis not ready. layoutState is ${child.layoutState}\u0026#34; } child.draw(canvas)//main  } } if (owner.showLayoutBounds) { drawBorder(canvas, innerBoundsPaint) } } LayoutNode.Draw internal fun draw(canvas: Canvas) = outerLayoutNodeWrapper.draw(canvas) internal val outerLayoutNodeWrapper: LayoutNodeWrapper get() = outerMeasurablePlaceable.outerWrapper ModifiedDrawNode.performDraw override fun performDraw(canvas: Canvas) { val size = measuredSize.toSize() if (cacheDrawModifier != null \u0026amp;\u0026amp; invalidateCache) { layoutNode.requireOwner().snapshotObserver.observeReads( this, onCommitAffectingModifiedDrawNode, updateCache ) } val drawScope = layoutNode.mDrawScope drawScope.draw(canvas, size, wrapped) { with(drawScope) { with(modifier) { draw() } } } } LayoutNodeDrawScope.draw internal inline fun draw( canvas: Canvas, size: Size, LayoutNodeWrapper: LayoutNodeWrapper, block: DrawScope.() -\u0026gt; Unit ) { val previousWrapper = wrapped wrapped = LayoutNodeWrapper canvasDrawScope.draw( LayoutNodeWrapper.measureScope, LayoutNodeWrapper.measureScope.layoutDirection, canvas, size, block ) wrapped = previousWrapper } CanvasDrawScope.draw /** * Draws into the provided [Canvas] with the commands specified in the lambda with this * [DrawScope] as a receiver * * @param canvas target canvas to render into * @param size bounds relative to the current canvas translation in which the [DrawScope] * should draw within * @param block lambda that is called to issue drawing commands on this [DrawScope] */ inline fun draw( density: Density, layoutDirection: LayoutDirection, canvas: Canvas, size: Size, block: DrawScope.() -\u0026gt; Unit ) { // Remember the previous drawing parameters in case we are temporarily re-directing our  // drawing to a separate Layer/RenderNode only to draw that content back into the original  // Canvas. If there is no previous canvas that was being drawing into, this ends up  // resetting these parameters back to defaults defensively  val (prevDensity, prevLayoutDirection, prevCanvas, prevSize) = drawParams drawParams.apply { this.density = density this.layoutDirection = layoutDirection this.canvas = canvas this.size = size } canvas.save() this.block()//main  canvas.restore() drawParams.apply { this.density = prevDensity this.layoutDirection = prevLayoutDirection this.canvas = prevCanvas this.size = prevSize } } block() with(drawScope) { with(modifier) { draw() } } Background.ContentDrawScope.draw private class Background constructor( private val color: Color? = null, private val brush: Brush? = null, private val alpha: Float = 1.0f, private val shape: Shape, inspectorInfo: InspectorInfo.() -\u0026gt; Unit ) : DrawModifier, InspectorValueInfo(inspectorInfo) { override fun ContentDrawScope.draw() { if (shape === RectangleShape) { // shortcut to avoid Outline calculation and allocation  drawRect() } else { drawOutline() } drawContent() } CanvasDrawScope.drawRect override fun drawRect( color: Color, topLeft: Offset, size: Size, /*FloatRange(from = 0.0, to = 1.0)*/ alpha: Float, style: DrawStyle, colorFilter: ColorFilter?, blendMode: BlendMode ) = drawParams.canvas.drawRect( left = topLeft.x, top = topLeft.y, right = topLeft.x + size.width, bottom = topLeft.y + size.height, paint = configurePaint(color, style, alpha, colorFilter, blendMode) ) AndroidCanvas.drawRect LayoutNodeDrawScope.drawContent override fun drawContent() { drawIntoCanvas { canvas -\u0026gt; wrapped?.draw(canvas) } } inline fun DrawScope.drawIntoCanvas(block: (Canvas) -\u0026gt; Unit) = block(drawContext.canvas) PainterModifier.ContentDrawScope.draw override fun ContentDrawScope.draw() { translate(dx, dy) { with(painter) { draw(size = scaledSize, alpha = alpha, colorFilter = colorFilter) } } } } Painter.DrawScope.draw fun DrawScope.draw( size: Size, alpha: Float = DefaultAlpha, colorFilter: ColorFilter? = null ) { inset( left = 0.0f, top = 0.0f, right = this.size.width - size.width, bottom = this.size.height - size.height ) { if (alpha \u0026gt; 0.0f \u0026amp;\u0026amp; size.width \u0026gt; 0 \u0026amp;\u0026amp; size.height \u0026gt; 0) { if (useLayer) { val layerRect = Rect(Offset.Zero, Size(size.width, size.height)) // TODO (b/154550724) njawad replace with RenderNode/Layer API usage  drawIntoCanvas { canvas -\u0026gt; canvas.withSaveLayer(layerRect, obtainPaint()) { onDraw() } } } else { onDraw() } } } } VectorPainter. DrawScope.onDraw override fun DrawScope.onDraw() { with(vector) { draw(currentAlpha, currentColorFilter ?: intrinsicColorFilter) } // This conditional is necessary to obtain invalidation callbacks as the state is  // being read here which adds this callback to the snapshot observation  if (isDirty) { isDirty = false } } VectorComponent.DrawScope.draw fun DrawScope.draw(alpha: Float, colorFilter: ColorFilter?) { val targetColorFilter = if (colorFilter != null) { colorFilter } else { intrinsicColorFilter } // If the content of the vector has changed, or we are drawing a different size  // update the cached image to ensure we are scaling the vector appropriately  if (isDirty || previousDrawSize != size) { root.scaleX = size.width / viewportWidth root.scaleY = size.height / viewportHeight cacheDrawScope.drawCachedImage( IntSize(ceil(size.width).toInt(), ceil(size.height).toInt()), this@draw, layoutDirection, drawVectorBlock ) isDirty = false previousDrawSize = size } cacheDrawScope.drawInto(this, alpha, targetColorFilter) } CanvasDrawScope.drawPath override fun drawPath( path: Path, brush: Brush, /*FloatRange(from = 0.0, to = 1.0)*/ alpha: Float, style: DrawStyle, colorFilter: ColorFilter?, blendMode: BlendMode ) = drawParams.canvas.drawPath( path, configurePaint(brush, style, alpha, colorFilter, blendMode) ) AndroidCanvas.drawPath override fun drawPath(path: Path, paint: Paint) { internalCanvas.drawPath(path.asAndroidPath(), paint.asFrameworkPaint()) } 其他 LayoutState /** * Describes the current state the [LayoutNode] is in. */ internal enum class LayoutState { /** * Request remeasure was called on the node. */ NeedsRemeasure, /** * Node is currently being measured. */ Measuring, /** * Request relayout was called on the node or the node was just measured and is going to * layout soon (measure stage is always being followed by the layout stage). */ NeedsRelayout, /** * Node is currently being laid out. */ LayingOut, /** * Node is measured and laid out or not yet attached to the [Owner] (see [LayoutNode.owner]). */ Ready } Measurable /** * A part of the composition that can be measured. This represents a layout. * The instance should never be stored. */ interface Measurable : IntrinsicMeasurable { /** * Measures the layout with [constraints], returning a [Placeable] layout that has its new * size. A [Measurable] can only be measured once inside a layout pass. */ fun measure(constraints: Constraints): Placeable } IntrinsicMeasurable /** * A part of the composition that can be measured. This represents a layout. * The instance should never be stored. */ interface IntrinsicMeasurable { /** * Data provided by the `ParentData` */ val parentData: Any? /** * Calculates the minimum width that the layout can be such that * the content of the layout will be painted correctly. */ fun minIntrinsicWidth(height: Int): Int /** * Calculates the smallest width beyond which increasing the width never * decreases the height. */ fun maxIntrinsicWidth(height: Int): Int /** * Calculates the minimum height that the layout can be such that * the content of the layout will be painted correctly. */ fun minIntrinsicHeight(width: Int): Int /** * Calculates the smallest height beyond which increasing the height never * decreases the width. */ fun maxIntrinsicHeight(width: Int): Int } Placeable /** * A [Placeable] corresponds to a child layout that can be positioned by its * parent layout. Most [Placeable]s are the result of a [Measurable.measure] call. * * A `Placeable` should never be stored between measure calls. */ abstract class Placeable : Measured { Measured /** * A [Measured] corresponds to a layout that has been measured by its parent layout. */ interface Measured { /** * The measured width of the layout. This might not respect the measurement constraints. */ val measuredWidth: Int /** * The measured height of the layout. This might not respect the measurement constraints. */ val measuredHeight: Int LayoutNodeWrapper /** * Measurable and Placeable type that has a position. */ internal abstract class LayoutNodeWrapper( internal val layoutNode: LayoutNode ) : Placeable(), Measurable, LayoutCoordinates, OwnerScope, (Canvas) -\u0026gt; Unit { /** * Measures the modified child. */ abstract fun performMeasure(constraints: Constraints): Placeable 参考 https://developer.android.google.cn/jetpack/compose/layout#custom-layouts\nhttps://developer.android.google.cn/jetpack/compose/graphics#drawscope\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/1lifecycle/lifecycle/",
	"title": "Lifecycle",
	"tags": [],
	"description": "",
	"content": "设计图 https://developer.android.com/topic/libraries/architecture/lifecycle\n生命周期感知型组件的最佳做法  使界面控制器（Activity 和 Fragment）尽可能保持精简。它们不应试图获取自己的数据，而应使用 ViewModel 执行此操作，并观察 LiveData 对象以将更改体现到视图中。 设法编写数据驱动型界面，对于此类界面，界面控制器的责任是随着数据更改而更新视图，或者将用户操作通知给 ViewModel。 将数据逻辑放在 ViewModel 类中。ViewModel 应充当界面控制器与应用其余部分之间的连接器。不过要注意，ViewModel 不负责获取数据（例如，从网络获取）。但是，ViewModel 应调用相应的组件来获取数据，然后将结果提供给界面控制器。 使用数据绑定在视图与界面控制器之间维持干净的接口。这样一来，您可以使视图更具声明性，并尽量减少需要在 Activity 和 Fragment 中编写的更新代码。如果您更愿意使用 Java 编程语言执行此操作，请使用诸如 Butter Knife 之类的库，以避免样板代码并实现更好的抽象化。 如果界面很复杂，不妨考虑创建 presenter 类来处理界面的修改。这可能是一项艰巨的任务，但这样做可使界面组件更易于测试。 避免在 ViewModel 中引用 View 或 Activity 上下文。如果 ViewModel 存在的时间比 Activity 更长（在配置更改的情况下），Activity 将泄漏并且不会获得垃圾回收器的妥善处置。 使用 Kotlin 协程管理长时间运行的任务和其他可以异步运行的操作。  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/1lifecycle/lifecyclecoroutine/",
	"title": "LifecycleCoroutine",
	"tags": [],
	"description": "",
	"content": "LifecycleCoroutine 图解 sequenceDiagram LifecycleCoroutineScopeImpl-\u0026gt;\u0026gt;LifecycleCoroutineScopeImpl: Lifecycle.coroutineScope.get(),register activate LifecycleCoroutineScopeImpl Note right of LifecycleCoroutineScopeImpl: lunch启动协程并lifecycle.addObserver deactivate LifecycleCoroutineScopeImpl LifecycleCoroutineScopeImpl-\u0026gt;\u0026gt;LifecycleCoroutineScopeImpl: onStateChanged回调时State.DESTROYED自动取消协程 LifecycleCoroutineScopeImpl-\u0026gt;\u0026gt;LifecycleCoroutineScopeImpl: launchWhenXxx activate LifecycleCoroutineScopeImpl LifecycleCoroutineScopeImpl-\u0026gt;\u0026gt;LifecycleController: new LifecycleController LifecycleController-\u0026gt;\u0026gt;LifecycleController: lifecycle.addObserver LifecycleController-\u0026gt;\u0026gt;DispatchQueue: dispatch lifecycle to LifecycleCoroutineScopeImpl-\u0026gt;\u0026gt;PausingDispatcher: withContext(PausingDispatcher, block) deactivate LifecycleCoroutineScopeImpl PausingDispatcher-\u0026gt;\u0026gt;PausingDispatcher: dispatchQueue.runOrEnqueue(block) activate PausingDispatcher PausingDispatcher-\u0026gt;\u0026gt;DispatchQueue: dispatch block to deactivate PausingDispatcher LifecycleCoroutineScopeImpl /** * [CoroutineScope] tied to this [LifecycleOwner]\u0026#39;s [Lifecycle]. * * This scope will be cancelled when the [Lifecycle] is destroyed. * * This scope is bound to * [Dispatchers.Main.immediate][kotlinx.coroutines.MainCoroutineDispatcher.immediate]. */ val LifecycleOwner.lifecycleScope: LifecycleCoroutineScope get() = lifecycle.coroutineScope val Lifecycle.coroutineScope: LifecycleCoroutineScope get() { while (true) { val existing = mInternalScopeRef.get() as LifecycleCoroutineScopeImpl? if (existing != null) { return existing } val newScope = LifecycleCoroutineScopeImpl( this, SupervisorJob() + Dispatchers.Main.immediate ) if (mInternalScopeRef.compareAndSet(null, newScope)) { newScope.register() return newScope } } } internal class LifecycleCoroutineScopeImpl( override val lifecycle: Lifecycle, override val coroutineContext: CoroutineContext ) : LifecycleCoroutineScope(), LifecycleEventObserver { init { // in case we are initialized on a non-main thread, make a best effort check before  // we return the scope. This is not sync but if developer is launching on a non-main  // dispatcher, they cannot be 100% sure anyways.  if (lifecycle.currentState == Lifecycle.State.DESTROYED) { coroutineContext.cancel() } } fun register() { launch(Dispatchers.Main.immediate) { if (lifecycle.currentState \u0026gt;= Lifecycle.State.INITIALIZED) { lifecycle.addObserver(this@LifecycleCoroutineScopeImpl) } else { coroutineContext.cancel() } } } override fun onStateChanged(source: LifecycleOwner, event: Lifecycle.Event) { if (lifecycle.currentState \u0026lt;= Lifecycle.State.DESTROYED) { lifecycle.removeObserver(this) coroutineContext.cancel() } } } LifecycleCoroutineScope abstract class LifecycleCoroutineScope internal constructor() : CoroutineScope { internal abstract val lifecycle: Lifecycle fun launchWhenCreated(block: suspend CoroutineScope.() -\u0026gt; Unit): Job = launch { lifecycle.whenCreated(block) } fun launchWhenStarted(block: suspend CoroutineScope.() -\u0026gt; Unit): Job = launch { lifecycle.whenStarted(block) } fun launchWhenResumed(block: suspend CoroutineScope.() -\u0026gt; Unit): Job = launch { lifecycle.whenResumed(block) } } suspend fun \u0026lt;T\u0026gt; Lifecycle.whenCreated(block: suspend CoroutineScope.() -\u0026gt; T): T { return whenStateAtLeast(Lifecycle.State.CREATED, block) } /** * Runs the given [block] on a [CoroutineDispatcher] that executes the [block] on the main thread * and suspends the execution unless the [Lifecycle]\u0026#39;s state is at least [minState]. * * If the [Lifecycle] moves to a lesser state while the [block] is running, the [block] will * be suspended until the [Lifecycle] reaches to a state greater or equal to [minState]. * * Note that this won\u0026#39;t effect any sub coroutine if they use a different [CoroutineDispatcher]. * However, the [block] will not resume execution when the sub coroutine finishes unless the * [Lifecycle] is at least in [minState]. * * If the [Lifecycle] is destroyed while the [block] is suspended, the [block] will be cancelled * which will also cancel any child coroutine launched inside the [block]. * * If you have a `try finally` block in your code, the `finally` might run after the [Lifecycle] * moves outside the desired state. It is recommended to check the [Lifecycle.getCurrentState] * before accessing the UI. Similarly, if you have a `catch` statement that might catch * `CancellationException`, you should check the [Lifecycle.getCurrentState] before accessing the * UI. See the sample below for more details. ...... */ suspend fun \u0026lt;T\u0026gt; Lifecycle.whenStateAtLeast( minState: Lifecycle.State, block: suspend CoroutineScope.() -\u0026gt; T ) = withContext(Dispatchers.Main.immediate) { val job = coroutineContext[Job] ?: error(\u0026#34;when[State] methods should have a parent job\u0026#34;) val dispatcher = PausingDispatcher() val controller = LifecycleController(this@whenStateAtLeast, minState, dispatcher.dispatchQueue, job) try { withContext(dispatcher, block) } finally { controller.finish() } } PausingDispatcher dispatch block to dispatchQueue /** * A [CoroutineDispatcher] implementation that maintains a dispatch queue to be able to pause * execution of coroutines. * * @see [DispatchQueue] and [Lifecycle.whenStateAtLeast] for details. */ internal class PausingDispatcher : CoroutineDispatcher() { /** * helper class to maintain state and enqueued continuations. */ @JvmField internal val dispatchQueue = DispatchQueue() @ExperimentalCoroutinesApi override fun dispatch(context: CoroutineContext, block: Runnable) { dispatchQueue.runOrEnqueue(block) } } LifecycleController dispatch lifecycle to dispatchQueue internal class LifecycleController( private val lifecycle: Lifecycle, private val minState: Lifecycle.State, private val dispatchQueue: DispatchQueue, parentJob: Job ) { private val observer = LifecycleEventObserver { source, _ -\u0026gt; if (source.lifecycle.currentState == Lifecycle.State.DESTROYED) { // cancel job before resuming remaining coroutines so that they run in cancelled  // state  handleDestroy(parentJob) } else if (source.lifecycle.currentState \u0026lt; minState) { dispatchQueue.pause() } else { dispatchQueue.resume() } } init { // If Lifecycle is already destroyed (e.g. developer leaked the lifecycle), we won\u0026#39;t get  // an event callback so we need to check for it before registering  // see: b/128749497 for details.  if (lifecycle.currentState == Lifecycle.State.DESTROYED) { handleDestroy(parentJob) } else { lifecycle.addObserver(observer) } } @Suppress(\u0026#34;NOTHING_TO_INLINE\u0026#34;) // avoid unnecessary method  private inline fun handleDestroy(parentJob: Job) { parentJob.cancel() finish() } /** * Removes the observer and also marks the [DispatchQueue] as finished so that any remaining * runnables can be executed. */ @MainThread fun finish() { lifecycle.removeObserver(observer) dispatchQueue.finish() } } "
},
{
	"uri": "https://huanle19891345.github.io/en/linux/",
	"title": "linux",
	"tags": [],
	"description": "",
	"content": "linux 探索总结linux知识\n linux_io     "
},
{
	"uri": "https://huanle19891345.github.io/en/linux/linux_io/",
	"title": "linux_io",
	"tags": [],
	"description": "",
	"content": "linux基础——linux下五种IO模型小结（阻塞IO、非阻塞IO、IO复用、信号驱动式IO、异步IO）\nJava IO：阻塞/非阻塞式IO、同步/异步IO\nLinux IO模式及 select、poll、epoll详解\nIO操作两个阶段 再说一下IO发生时涉及的对象和步骤。以read函数举例，对于一个networkIO会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：\n（1）等待数据准备(Waitingfor the data to be ready)\n（2）将数据从内核拷贝到进程中(Copyingthe data from the kernel to the process)\n记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。是否阻塞说的是第一个阶段，即等待数据准备阶段是否会阻塞，而是否同步说的是第二阶段，即将数据从内核拷贝到进程这个真实的IO Operation操作阶段是否阻塞。\nFileObserver基于inotify\nLooper基于epoll\nhttps://stackoverflow.com/questions/17207809/difference-between-inotify-and-epoll\ninotify  inotify_init(void) creates inotify instance to read events from inotify_add_watch(int fd, const char * path, int mask) returns a watch fd around the file node behind the path inotify_rm_watch(int fd, int wd) stops watching for events on fd  epoll  epoll_create(void) creates epoll object epoll_ctl(int epfd, int op, int fd, struct epoll_event * event) sets up events to watch epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); blocks until event happens  The biggest difference is that epoll can be used for ANY fd. This means it\u0026rsquo;s good for watching all types of ways to communicate data. Sockets, IPC, files, printers.. anything. inotify is for filesystems only.\nHowever, because inotify is specific to filesystems, you can receive notifications on a wide array of filesystem-specific attributes, such as file attributes and the file being read. These things are not possible via epoll.\nIn fact, inotify returns a file descriptor - which means you can use epoll to determine which inotify FD\u0026rsquo;s you should call read on. So the two go hand in hand to some extent.\nhttp://en.wikipedia.org/wiki/Inotify\n https://jvns.ca/blog/2017/06/03/async-io-on-linux--select--poll--and-epoll/\nselect、poll、epoll之间的区别(搜狗面试)\nselect，poll，epoll select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。\nepoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现\ngraph LR 水平触发--\u0026gt;报告了fd后,没有被处理,那么下次poll时会再次报告该fd 边沿触发--\u0026gt;只会通知你一次,直到该文件描述符上出现第二次可读写事件才会通知你 Select select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：\nselect的几大缺点：\n（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大，当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll做的。\n（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大，需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大\n**（3）**单个进程可监视的fd数量被限制，即能监听端口的大小有限。一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.\nPoll poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。\n它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：\n1、大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义，它的开销随着文件描述符数量的增加而线性增大。\n2、poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。\nselect \u0026amp; poll区别1 poll支持的事件类型更多更详细:\nThey both call a lot of the same functions. One thing that the book mentioned in particular is that poll returns a larger set of possible results for file descriptors like POLLRDNORM | POLLRDBAND | POLLIN | POLLHUP | POLLERR while select just tells you “there’s input / there’s output / there’s an error”.\nselect translates from poll’s more detailed results (like POLLWRBAND) into a general “you can write”. You can see the code where it does this in Linux 4.10 here.\nselect \u0026amp; poll区别2 Select 单个进程可监视的fd数量被限制,32位机默认是1024个,64位机默认是2048.\nselect \u0026amp; poll区别3 描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构\nandroid新版本源码中runSelectLoop方法内部实现从select改为poll\nEpoll Here are the steps to using epoll:\n Call epoll_create to tell the kernel you’re gong to be epolling! It gives you an id back Call epoll_ctl to tell the kernel file descriptors you’re interested in updates about. Interestingly, you can give it lots of different kinds of file descriptors (pipes, FIFOs, sockets, POSIX message queues, inotify instances, devices, \u0026amp; more), but not regular files. I think this makes sense – pipes \u0026amp; sockets have a pretty simple API (one process writes to the pipe, and another process reads!), so it makes sense to say “this pipe has new data for reading”. But files are weird! You can write to the middle of a file! So it doesn’t really make sense to say “there’s new data available for reading in this file”. Call epoll_wait to wait for updates about the list of files you’re interested in.  epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。\n　对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。\n　对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。\n　对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/xcrash/linuxapi/",
	"title": "linuxApi",
	"tags": [],
	"description": "",
	"content": "dlsym https://linux.die.net/man/3/dlsym\nvoid *dlsym(void *handle, const char *symbol); The function dlsym() takes a \u0026ldquo;handle\u0026rdquo; of a dynamic library returned by dlopen() and the null-terminated symbol name, returning the address where that symbol is loaded into memory.\npthread_create http://man7.org/linux/man-pages/man3/pthread_create.3.html\nint pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg);  The pthread_create() function starts a new thread in the calling process. The new thread starts execution by invoking start_routine(); arg is passed as the sole argument of start_routine().  ​ ​\nsigaction https://linux.die.net/man/2/sigaction\nint sigaction(int signum, const struct sigaction *act, struct sigaction *oldact); The sigaction() system call is used to change the action taken by a process on receipt of a specific signal. (See signal(7) for an overview of signals.)\nsignum specifies the signal and can be any valid signal except SIGKILL and SIGSTOP.\nIf act is non-NULL, the new action for signal signum is installed from act. If oldact is non-NULL, the previous action is saved in oldact.\nsigaltstack http://man7.org/linux/man-pages/man2/sigaltstack.2.html\nint sigaltstack(const stack_t *ss, stack_t *old_ss); sigaltstack() allows a process to define a new alternate signal stack and/or retrieve the state of an existing alternate signal stack. An alternate signal stack is used during the execution of a signal handler if the establishment of that handler (see sigaction(2)) requested it. The normal sequence of events for using an alternate signal stack is the following: 1. Allocate an area of memory to be used for the alternate signal stack. 2. Use sigaltstack() to inform the system of the existence and location of the alternate signal stack. 3. When establishing a signal handler using sigaction(2), inform the system that the signal handler should be executed on the alternate signal stack by specifying the SA_ONSTACK flag. The ss argument is used to specify a new alternate signal stack, while the old_ss argument is used to retrieve information about the currently established signal stack. If we are interested in performing just one of these tasks, then the other argument can be specified as NULL. memcpy http://man7.org/linux/man-pages/man3/memcpy.3.html\nvoid *memcpy(void *dest, const void *src, size_t n); The memcpy() function copies n bytes from memory area src to memory area dest. The memory areas must not overlap. Use memmove(3) if the memory areas do overlap. The memcpy() function returns a pointer to dest. prctl http://man7.org/linux/man-pages/man2/prctl.2.html\nint prctl(int option, unsigned long arg2, unsigned long arg3, unsigned long arg4, unsigned long arg5); prctl() is called with a first argument describing what to do (with values defined in \u0026lt;linux/prctl.h\u0026gt;), and further arguments with a significance depending on the first one. The first argument can be: PR_SET_PTRACER (since Linux 3.4)...... fork http://man7.org/linux/man-pages/man2/fork.2.html\n pid_t fork(void); fork() creates a new process by duplicating the calling process. The new process is referred to as the child process. The calling process is referred to as the parent process. The child process and the parent process run in separate memory spaces. At the time of fork() both memory spaces have the same content. Memory writes, file mappings (mmap(2)), and unmappings (munmap(2)) performed by one of the processes do not affect the other. RETURN VALUE top On success, the PID of the child process is returned in the parent, and 0 is returned in the child. On failure, -1 is returned in the parent, no child process is created, and errno is set appropriately. waitpid https://linux.die.net/man/3/waitpid\nwait, waitpid - wait for a child process to stop or terminate\npid_t waitpid(pid_t pid, int *stat_loc, int options); execl https://linux.die.net/man/3/execl\nexecl, execlp, execle, execv, execvp, execvpe - execute a file\nint execl(const char *path, const char *arg, ...); alarm http://man7.org/linux/man-pages/man2/alarm.2.html\nunsigned int alarm(unsigned int seconds); alarm() arranges for a SIGALRM signal to be delivered to the calling process in seconds seconds. read http://man7.org/linux/man-pages/man2/read.2.html\nssize_t read(int fd, void *buf, size_t count); read() attempts to read up to count bytes from file descriptor fd into the buffer starting at buf. write http://man7.org/linux/man-pages/man2/write.2.html\nwrite - write to a file descriptor\nssize_t write(int fd, const void *buf, size_t count); write() writes up to count bytes from the buffer starting at buf to the file referred to by the file descriptor fd. open http://man7.org/linux/man-pages/man2/open.2.html\nint open(const char *pathname, int flags); The open() system call opens the file specified by pathname. If the specified file does not exist, it may optionally (if O_CREAT is specified in flags) be created by open(). ptrace http://man7.org/linux/man-pages/man2/ptrace.2.html\nNAME top ptrace - process trace SYNOPSIS top #include \u0026lt;sys/ptrace.h\u0026gt; long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data); PTRACE_ATTACH Attach to the process specified in pid, making it a tracee of the calling process. The tracee is sent a SIGSTOP, but will not necessarily have stopped by the completion of this call; use waitpid(2) to wait for the tracee to stop. See the \u0026quot;Attaching and detaching\u0026quot; subsection for additional informa‐ tion. (addr and data are ignored.) Permission to perform a PTRACE_ATTACH is governed by a ptrace access mode PTRACE_MODE_ATTACH_REALCREDS check; see below. Attaching and detaching A thread can be attached to the tracer using the call ptrace(PTRACE_ATTACH, tid, 0, 0); or ptrace(PTRACE_SEIZE, tid, 0, PTRACE_O_flags); PTRACE_ATTACH sends SIGSTOP to this thread. If the tracer wants this SIGSTOP to have no effect, it needs to suppress it. PTRACE_GETREGSET (since Linux 2.6.34) Read the tracee's registers. addr specifies, in an architecture-dependent way, the type of registers to be read. NT_PRSTATUS (with numerical value 1) usually results in reading of general-purpose registers. If the CPU has, for example, floating-point and/or vector registers, they can be retrieved by setting addr to the corresponding NT_foo constant. data points to a struct iovec, which describes the destination buffer's location and length. On return, the kernel modifies iov.len to indicate the actual number of bytes returned. PTRACE_PEEKTEXT, PTRACE_PEEKDATA Read a word at the address addr in the tracee's memory, returning the word as the result of the ptrace() call. Linux does not have separate text and data address spaces, so these two requests are currently equivalent. (data is ignored; but see NOTES.) RETURN VALUE top On success, the PTRACE_PEEK* requests return the requested data (but see NOTES), the PTRACE_SECCOMP_GET_FILTER request returns the number of instructions in the BPF program, and other requests return zero. On error, all requests return -1, and errno is set appropriately. Since the value returned by a successful PTRACE_PEEK* request may be -1, the caller must clear errno before the call, and then check it afterward to determine whether or not an error occurred. SIGSTOP 作用是suspend，可以通过SIGCONT恢复\neventfd http://man7.org/linux/man-pages/man2/eventfd.2.html\neventfd - create a file descriptor for event notification\n#include \u0026lt;sys/eventfd.h\u0026gt; int eventfd(unsigned int initval, int flags); eventfd() creates an \u0026quot;eventfd object\u0026quot; that can be used as an event wait/notify mechanism by user-space applications, and by the kernel to notify user-space applications of events. As its return value, eventfd() returns a new file descriptor that can be used to refer to the eventfd object. EFD_CLOEXEC (since Linux 2.6.27) Set the close-on-exec (FD_CLOEXEC) flag on the new file descriptor. See the description of the O_CLOEXEC flag in open(2) for reasons why this may be useful. dup2 http://man7.org/linux/man-pages/man2/dup.2.html\ndup, dup2, dup3 - duplicate a file descriptor\nint dup(int oldfd); int dup2(int oldfd, int newfd); int dup3(int oldfd, int newfd, int flags); The dup() system call creates a copy of the file descriptor oldfd, using the lowest-numbered unused file descriptor for the new descriptor. The dup2() system call performs the same task as dup(), but instead of using the lowest-numbered unused file descriptor, it uses the file descriptor number specified in newfd. If the file descriptor newfd was previously open, it is silently closed before being reused. syscall http://man7.org/linux/man-pages/man2/syscall.2.html\nsyscall - indirect system call\nlong syscall(long number, ...); mmap http://man7.org/linux/man-pages/man2/mmap.2.html\nmmap, munmap - map or unmap files or devices into memory void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); int munmap(void *addr, size_t length); mmap() creates a new mapping in the virtual address space of the calling process. The starting address for the new mapping is specified in addr. The length argument specifies the length of the mapping (which must be greater than 0). If addr is NULL, then the kernel chooses the (page-aligned) address at which to create the mapping; this is the most portable method of creating a new mapping. If addr is not NULL, then the kernel takes it as a hint about where to place the mapping; on Linux, the kernel will pick a nearby page boundary (but always above or equal to the value specified by /proc/sys/vm/mmap_min_addr) and attempt to create the mapping there. If another mapping already exists there, the kernel picks a new address that may or may not depend on the hint. The address of the new mapping is returned as the result of the call. MAP_PRIVATE Create a private copy-on-write mapping. Updates to the mapping are not visible to other processes mapping the same file, and are not carried through to the underlying file. It is unspecified whether changes made to the file after the mmap() call are visible in the mapped region. RETURN VALUE top On success, mmap() returns a pointer to the mapped area. On error, the value MAP_FAILED (that is, (void *) -1) is returned, and errno is set to indicate the cause of the error. On success, munmap() returns 0. On failure, it returns -1, and errno is set to indicate the cause of the error (probably to EINVAL). ElfW https://code.woboq.org/userspace/glibc/elf/link.h.html\n/* We use this macro to refer to ELF types independent of the native wordsize. `ElfW(TYPE)' is used in place of `Elf32_TYPE' or `Elf64_TYPE'. */ #define ElfW(type) _ElfW (Elf, __ELF_NATIVE_CLASS, type) #define _ElfW(e,w,t) _ElfW_1 (e, w, _##t) #define _ElfW_1(e,w,t) e##w##t Ehdr和Phdr http://man7.org/linux/man-pages/man5/elf.5.html\nEhdr ELF header (Ehdr) The ELF header is described by the type Elf32_Ehdr or Elf64_Ehdr: The ELF header is described by the type Elf32_Ehdr or Elf64_Ehdr: #define EI_NIDENT 16 typedef struct { unsigned char e_ident[EI_NIDENT]; uint16_t e_type; uint16_t e_machine; uint32_t e_version; ElfN_Addr e_entry; ElfN_Off e_phoff; ElfN_Off e_shoff; uint32_t e_flags; uint16_t e_ehsize; uint16_t e_phentsize; uint16_t e_phnum; uint16_t e_shentsize; uint16_t e_shnum; uint16_t e_shstrndx; } ElfN_Ehdr; Phdr Program header (Phdr) Program header (Phdr) An executable or shared object file's program header table is an array of structures, each describing a segment or other information the system needs to prepare the program for execution. An object file segment contains one or more sections. Program headers are meaningful only for executable and shared object files. A file spec‐ ifies its own program header size with the ELF header's e_phentsize and e_phnum members. The ELF program header is described by the type Elf32_Phdr or Elf64_Phdr depending on the architecture: typedef struct { uint32_t p_type; Elf32_Off p_offset; Elf32_Addr p_vaddr; Elf32_Addr p_paddr; uint32_t p_filesz; uint32_t p_memsz; uint32_t p_flags; uint32_t p_align; } Elf32_Phdr; typedef struct { uint32_t p_type; uint32_t p_flags; Elf64_Off p_offset; Elf64_Addr p_vaddr; Elf64_Addr p_paddr; uint64_t p_filesz; uint64_t p_memsz; uint64_t p_align; } The main difference between the 32-bit and the 64-bit program header lies in the location of the p_flags member in the total struct. "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/2livedata/livedata/",
	"title": "LiveData",
	"tags": [],
	"description": "",
	"content": "类设计 androidx.lifecycle:lifecycle-livedata:2.0.0\nandroidx.lifecycle:lifecycle-livedata-core:2.0.0\nobserve private SafeIterableMap\u0026lt;Observer\u0026lt;? super T\u0026gt;, ObserverWrapper\u0026gt; mObservers = new SafeIterableMap\u0026lt;\u0026gt;(); observe @MainThread public void observe(@NonNull LifecycleOwner owner, @NonNull Observer\u0026lt;? super T\u0026gt; observer) { assertMainThread(\u0026#34;observe\u0026#34;); if (owner.getLifecycle().getCurrentState() == DESTROYED) { // ignore  return; } LifecycleBoundObserver wrapper = new LifecycleBoundObserver(owner, observer); ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing != null \u0026amp;\u0026amp; !existing.isAttachedTo(owner)) { throw new IllegalArgumentException(\u0026#34;Cannot add the same observer\u0026#34; + \u0026#34; with different lifecycles\u0026#34;); } if (existing != null) { return; } owner.getLifecycle().addObserver(wrapper); } LifecycleBoundObserver class LifecycleBoundObserver extends ObserverWrapper implements LifecycleEventObserver { final LifecycleOwner mOwner; @Override boolean shouldBeActive() { return mOwner.getLifecycle().getCurrentState().isAtLeast(STARTED); } @Override public void onStateChanged(@NonNull LifecycleOwner source, @NonNull Lifecycle.Event event) { if (mOwner.getLifecycle().getCurrentState() == DESTROYED) { removeObserver(mObserver); return; } activeStateChanged(shouldBeActive()); } observeForever @MainThread public void observeForever(@NonNull Observer\u0026lt;? super T\u0026gt; observer) { assertMainThread(\u0026#34;observeForever\u0026#34;); AlwaysActiveObserver wrapper = new AlwaysActiveObserver(observer); ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing instanceof LiveData.LifecycleBoundObserver) { throw new IllegalArgumentException(\u0026#34;Cannot add the same observer\u0026#34; + \u0026#34; with different lifecycles\u0026#34;); } if (existing != null) { return; } wrapper.activeStateChanged(true); } AlwaysActiveObserver private class AlwaysActiveObserver extends ObserverWrapper { @Override boolean shouldBeActive() { return true; } } updateValue postValue protected void postValue(T value) { boolean postTask; synchronized (mDataLock) { postTask = mPendingData == NOT_SET; mPendingData = value; } if (!postTask) { return; } ArchTaskExecutor.getInstance().postToMainThread(mPostValueRunnable); } private final Runnable mPostValueRunnable = new Runnable() { @Override public void run() { Object newValue; synchronized (mDataLock) { newValue = mPendingData; mPendingData = NOT_SET; } //noinspection unchecked  setValue((T) newValue); } }; setValue @MainThread protected void setValue(T value) { assertMainThread(\u0026#34;setValue\u0026#34;); mVersion++; mData = value; dispatchingValue(null);//null标识通知mObservers中的所有Observer } LifecycleBoundObserver.onStateChanged @Override public void onStateChanged(LifecycleOwner source, Lifecycle.Event event) { if (mOwner.getLifecycle().getCurrentState() == DESTROYED) { removeObserver(mObserver); return; } activeStateChanged(shouldBeActive()); } ObserverWrapper.activeStateChanged void activeStateChanged(boolean newActive) { if (newActive == mActive) { return; } //仅在active状态发生变化时才继续流程  // immediately set active state, so we\u0026#39;d never dispatch anything to inactive owner  mActive = newActive; boolean wasInactive = LiveData.this.mActiveCount == 0; LiveData.this.mActiveCount += mActive ? 1 : -1; if (wasInactive \u0026amp;\u0026amp; mActive) { onActive(); } if (LiveData.this.mActiveCount == 0 \u0026amp;\u0026amp; !mActive) { onInactive(); } if (mActive) {//仅仅在active时才dispatchValue  dispatchingValue(this);//通知当前observer  } } dispatchingValue //如果传递了参数ObserverWrapper，则对其considerNotify，否则对mObservers中的item进行considerNotify void dispatchingValue(@Nullable ObserverWrapper initiator) { if (mDispatchingValue) { mDispatchInvalidated = true; return; } mDispatchingValue = true; do { mDispatchInvalidated = false; if (initiator != null) { considerNotify(initiator); initiator = null; } else { for (Iterator\u0026lt;Map.Entry\u0026lt;Observer\u0026lt;? super T\u0026gt;, ObserverWrapper\u0026gt;\u0026gt; iterator = mObservers.iteratorWithAdditions(); iterator.hasNext(); ) { considerNotify(iterator.next().getValue()); if (mDispatchInvalidated) { break; } } } } while (mDispatchInvalidated); mDispatchingValue = false; } considerNotify private void considerNotify(ObserverWrapper observer) { if (!observer.mActive) { return; } // Check latest state b4 dispatch. Maybe it changed state but we didn\u0026#39;t get the event yet.  //  // we still first check observer.active to keep it as the entrance for events. So even if  // the observer moved to an active state, if we\u0026#39;ve not received that event, we better not  // notify for a more predictable notification order.  if (!observer.shouldBeActive()) { observer.activeStateChanged(false); return; } if (observer.mLastVersion \u0026gt;= mVersion) { return; } //only when mVersion \u0026gt; observer.mLastVersion  observer.mLastVersion = mVersion; //noinspection unchecked  observer.mObserver.onChanged((T) mData); } LifecycleBoundObserver.shouldBeActive @Override boolean shouldBeActive() { return mOwner.getLifecycle().getCurrentState().isAtLeast(STARTED); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/2livedata/livedatacoroutine/",
	"title": "LiveDataCoroutine",
	"tags": [],
	"description": "",
	"content": "@UseExperimental(ExperimentalTypeInference::class) fun \u0026lt;T\u0026gt; liveData( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, @BuilderInference block: suspend LiveDataScope\u0026lt;T\u0026gt;.() -\u0026gt; Unit ): LiveData\u0026lt;T\u0026gt; = CoroutineLiveData(context, timeoutInMs, block) CoroutineLiveData 图解 sequenceDiagram CoroutineLiveData-\u0026gt;\u0026gt;CoroutineLiveData: init activate CoroutineLiveData CoroutineLiveData-\u0026gt;\u0026gt;BlockRunner: new BlockRunner BlockRunner-\u0026gt;\u0026gt;CoroutineScope: new CoroutineScope deactivate CoroutineLiveData CoroutineLiveData-\u0026gt;\u0026gt;CoroutineLiveData: onActive activate CoroutineLiveData CoroutineLiveData-\u0026gt;\u0026gt;BlockRunner: blockRunner?.maybeRun() BlockRunner-\u0026gt;\u0026gt;CoroutineScope: runningJob = scope.launch CoroutineScope-\u0026gt;\u0026gt;CoroutineScope: block(liveDataScopeImpl) deactivate CoroutineLiveData CoroutineLiveData-\u0026gt;\u0026gt;CoroutineLiveData: onInactive activate CoroutineLiveData CoroutineLiveData-\u0026gt;\u0026gt;BlockRunner: blockRunner?.cancel() BlockRunner-\u0026gt;\u0026gt;CoroutineScope: cancellationJob = scope.launch deactivate CoroutineLiveData internal typealias Block\u0026lt;T\u0026gt; = suspend LiveDataScope\u0026lt;T\u0026gt;.() -\u0026gt; Unit internal class CoroutineLiveData\u0026lt;T\u0026gt;( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, block: Block\u0026lt;T\u0026gt; ) : MediatorLiveData\u0026lt;T\u0026gt;() { private var blockRunner: BlockRunner\u0026lt;T\u0026gt;? init { // use an intermediate supervisor job so that if we cancel individual block runs due to losing  // observers, it won\u0026#39;t cancel the given context as we only cancel w/ the intention of possibly  // relaunching using the same parent context.  val supervisorJob = SupervisorJob(context[Job]) // The scope for this LiveData where we launch every block Job.  // We default to Main dispatcher but developer can override it.  // The supervisor job is added last to isolate block runs.  val scope = CoroutineScope(Dispatchers.Main.immediate + context + supervisorJob) blockRunner = BlockRunner( liveData = this, block = block, timeoutInMs = timeoutInMs, scope = scope ) { blockRunner = null } } } onActive override fun onActive() { super.onActive() blockRunner?.maybeRun() } BlockRunner.maybeRun @MainThread fun maybeRun() { cancellationJob?.cancel() cancellationJob = null if (runningJob != null) { return } runningJob = scope.launch { val liveDataScope = LiveDataScopeImpl(liveData, coroutineContext) block(liveDataScope)//block是suspend function，通过这种方式完成CoroutineScope到liveDataScope的闭包参数转换  onDone() } } onInactive override fun onInactive() { super.onInactive() blockRunner?.cancel() } BlockRunner.cancel @MainThread fun cancel() { if (cancellationJob != null) { error(\u0026#34;Cancel call cannot happen without a maybeRun\u0026#34;) } cancellationJob = scope.launch(Dispatchers.Main.immediate) { delay(timeoutInMs) if (!liveData.hasActiveObservers()) { // one last check on active observers to avoid any race condition between starting  // a running coroutine and cancelation  runningJob?.cancel() runningJob = null } } } LiveDataScope interface LiveDataScope\u0026lt;T\u0026gt; { suspend fun emit(value: T) suspend fun emitSource(source: LiveData\u0026lt;T\u0026gt;): DisposableHandle val latestValue: T? } internal class LiveDataScopeImpl\u0026lt;T\u0026gt;( internal var target: CoroutineLiveData\u0026lt;T\u0026gt;, context: CoroutineContext ) : LiveDataScope\u0026lt;T\u0026gt; { override val latestValue: T? get() = target.value // use `liveData` provided context + main dispatcher to communicate with the target  // LiveData. This gives us main thread safety as well as cancellation cooperation  private val coroutineContext = context + Dispatchers.Main.immediate } emit(value: T) override suspend fun emit(value: T) = withContext(coroutineContext) { target.clearSource() target.value = value//CoroutineLiveData\u0026lt;T\u0026gt;.setValue } emitSource(source: LiveData) 图解 graph LR CoroutineLiveData--\u0026gt;|1: addSource|SourceLiveData CoroutineLiveData--\u0026gt;|2: onActive|SourceLiveData SourceLiveData--\u0026gt;|3: observe when coroutineLiveData onActive|observer--\u0026gt;|5:update when sourceLiveData onChanged|CoroutineLiveData observer--\u0026gt;|4:I have observer,call my onAcitive|SourceLiveData override suspend fun emitSource(source: LiveData\u0026lt;T\u0026gt;): DisposableHandle = withContext(coroutineContext) { return@withContext target.emitSource(source) } CoroutineLiveData.emitSource private var emittedSource: EmittedSource? = null internal suspend fun emitSource(source: LiveData\u0026lt;T\u0026gt;): DisposableHandle { clearSource() val newSource = addDisposableSource(source) emittedSource = newSource return newSource } internal suspend fun clearSource() { emittedSource?.disposeNow() emittedSource = null } internal suspend fun \u0026lt;T\u0026gt; MediatorLiveData\u0026lt;T\u0026gt;.addDisposableSource( source: LiveData\u0026lt;T\u0026gt; ): EmittedSource = withContext(Dispatchers.Main.immediate) { addSource(source) {//call mediatorLiveData.addSource  value = it //call liveData.setValue  } EmittedSource( source = source, mediator = this@addDisposableSource ) } 参考 https://developer.android.com/kotlin/ktx#livedata\nhttps://github.com/android/architecture-components-samples/tree/main/LiveDataSample\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/handler/looper/",
	"title": "Looper",
	"tags": [],
	"description": "",
	"content": "原理总结 Looper就是对epoll系统调用的封装层，屏蔽外部对epoll的直接使用\nLooper 图解 sequenceDiagram rect rgb(199, 237, 204) Looper-\u0026gt;\u0026gt;Looper: Looper() activate Looper Looper-\u0026gt;\u0026gt;Looper: mWakeEventFd = eventfd Looper-\u0026gt;\u0026gt;Looper: rebuildEpollLocked activate Looper Looper-\u0026gt;\u0026gt;Looper: mEpollFd = epoll_create(EPOLL_SIZE_HINT) Note right of Looper: eventItem.events = EPOLLIN,eventItem.data.fd = mWakeEventFd Looper-\u0026gt;\u0026gt;Looper: epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeEventFd, \u0026amp; eventItem) Note right of Looper: 编译mRequests对每个子项进行下面的ctl,mRequests通过addFd添加元素 Looper-\u0026gt;\u0026gt;Looper: epoll_ctl(mEpollFd, EPOLL_CTL_ADD, request.fd, \u0026amp; eventItem) deactivate Looper deactivate Looper end rect rgb(199, 237, 204) Looper-\u0026gt;\u0026gt;Looper: addFd Note right of Looper: 将fd封装成request,epoll_ctl(mEpollFd, EPOLL_CTL_ADD, fd, \u0026amp;eventItem),use SimpleLooperCallback as adapter from handleEvent to callback function end rect rgb(199, 237, 204) Looper-\u0026gt;\u0026gt;Looper: pollOnce,开启for循环 activate Looper Note right of Looper: timeoutMillis由MessageQueue的next()方法提供，队列中有message时，时间为msg.when-now,否则无消息，为-1表示一直在epoll中等待消息 Looper-\u0026gt;\u0026gt;Looper: 处理mResponses并尝试return Looper-\u0026gt;\u0026gt;Looper: pollInner activate Looper Looper-\u0026gt;\u0026gt;Looper: int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_EVENTS, timeoutMillis) Looper-\u0026gt;\u0026gt;Looper: 针对eventCount中每个event,if(fd == mWakeEventFd \u0026amp;\u0026amp; epollEvents \u0026amp; EPOLLIN)awoken(),否则对应到mRequests中并pushResponse Looper-\u0026gt;\u0026gt;Looper: 1:处理mMessageEnvelopes中的C层消息 Looper-\u0026gt;\u0026gt;Looper: 2:处理mResponses中元素,回调通过addFd添加进来的监听 Looper-\u0026gt;\u0026gt;Looper: 3:返回之后回到java层的循环处处理java层消息 deactivate Looper deactivate Looper end system/core/libutils/Looper.cpp\nLooper Looper::Looper(bool allowNonCallbacks) : mAllowNonCallbacks(allowNonCallbacks), mSendingMessage(false), mPolling(false), mEpollFd(-1), mEpollRebuildRequired(false), mNextRequestSeq(0), mResponseIndex(0), mNextMessageUptime(LLONG_MAX) { mWakeEventFd = eventfd(0, EFD_NONBLOCK | EFD_CLOEXEC);//main  LOG_ALWAYS_FATAL_IF(mWakeEventFd \u0026lt; 0, \u0026#34;Could not make wake event fd: %s\u0026#34;, strerror(errno)); AutoMutex _l(mLock); rebuildEpollLocked();//main } void Looper::rebuildEpollLocked() { // Allocate the new epoll instance and register the wake pipe.  mEpollFd = epoll_create(EPOLL_SIZE_HINT);//main  LOG_ALWAYS_FATAL_IF(mEpollFd \u0026lt; 0, \u0026#34;Could not create epoll instance: %s\u0026#34;, strerror(errno)); struct epoll_event eventItem; memset(\u0026amp; eventItem, 0, sizeof(epoll_event)); // zero out unused members of data field union  eventItem.events = EPOLLIN; eventItem.data.fd = mWakeEventFd; int result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeEventFd, \u0026amp; eventItem);//main  LOG_ALWAYS_FATAL_IF(result != 0, \u0026#34;Could not add wake event fd to epoll instance: %s\u0026#34;, strerror(errno)); for (size_t i = 0; i \u0026lt; mRequests.size(); i++) { const Request\u0026amp; request = mRequests.valueAt(i); struct epoll_event eventItem; request.initEventItem(\u0026amp;eventItem); int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, request.fd, \u0026amp; eventItem); if (epollResult \u0026lt; 0) { ALOGE(\u0026#34;Error adding epoll events for fd %d while rebuilding epoll set: %s\u0026#34;, request.fd, strerror(errno)); } } } eventfd 是 Linux 系统中一个用来通知事件的文件描述符，基于内核向用户空间应用发送通知的机制，可以有效地被用来实现用户空间事件驱动的应用程序。\n简而言之：eventfd 就是用来触发事件通知，它只有一个系统调用接口：\nint eventfd(unsigned int initval, int flags); 表示打开一个 eventfd 文件并返回文件描述符，支持 epoll/poll/select 操作。\n在 Android 6.0 后，Handler 底层替换为 eventfd/epoll 实现。而 6.0 之前是由 pipe/epoll 实现的\naddFd int Looper::addFd(int fd, int ident, int events, Looper_callbackFunc callback, void* data) { // use SimpleLooperCallback as adapter from handleEvent to callback function  return addFd(fd, ident, events, callback ? new SimpleLooperCallback(callback) : NULL, data); } int Looper::addFd(int fd, int ident, int events, const sp\u0026lt;LooperCallback\u0026gt;\u0026amp; callback, void* data) { if (!callback.get()) { if (! mAllowNonCallbacks) { ALOGE(\u0026#34;Invalid attempt to set NULL callback but not allowed for this looper.\u0026#34;); return -1; } if (ident \u0026lt; 0) { ALOGE(\u0026#34;Invalid attempt to set NULL callback with ident \u0026lt; 0.\u0026#34;); return -1; } } else { ident = POLL_CALLBACK; } Request request; request.fd = fd; request.ident = ident; request.events = events; request.seq = mNextRequestSeq++; request.callback = callback; request.data = data; struct epoll_event eventItem; request.initEventItem(\u0026amp;eventItem); ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex \u0026lt; 0) { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, fd, \u0026amp; eventItem); mRequests.add(fd, request); } else { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_MOD, fd, \u0026amp; eventItem); } } Request::initEventItem void Looper::Request::initEventItem(struct epoll_event* eventItem) const { int epollEvents = 0; if (events \u0026amp; EVENT_INPUT) epollEvents |= EPOLLIN; if (events \u0026amp; EVENT_OUTPUT) epollEvents |= EPOLLOUT; memset(eventItem, 0, sizeof(epoll_event)); // zero out unused members of data field union  eventItem-\u0026gt;events = epollEvents; eventItem-\u0026gt;data.fd = fd; } pollOnce //timeoutMillis由MessageQueue的next()方法中计算并提供，队列中有message时，时间为msg.when-now,否则无消息，为-1表示一直在epoll中等待消息 int Looper::pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) { int result = 0; for (;;) { while (mResponseIndex \u0026lt; mResponses.size()) { const Response\u0026amp; response = mResponses.itemAt(mResponseIndex++); int ident = response.request.ident; if (ident \u0026gt;= 0) { int fd = response.request.fd; int events = response.events; void* data = response.request.data; if (outFd != NULL) *outFd = fd; if (outEvents != NULL) *outEvents = events; if (outData != NULL) *outData = data; return ident; } } if (result != 0) { if (outFd != NULL) *outFd = 0; if (outEvents != NULL) *outEvents = 0; if (outData != NULL) *outData = NULL; return result; } result = pollInner(timeoutMillis); } } pollInner // Maximum number of file descriptors for which to retrieve poll events each iteration. static const int EPOLL_MAX_EVENTS = 16; int Looper::pollInner(int timeoutMillis) { // Poll.  int result = POLL_WAKE; mResponses.clear(); mResponseIndex = 0; struct epoll_event eventItems[EPOLL_MAX_EVENTS]; int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_EVENTS, timeoutMillis); for (int i = 0; i \u0026lt; eventCount; i++) { int fd = eventItems[i].data.fd; uint32_t epollEvents = eventItems[i].events; if (fd == mWakeEventFd) { if (epollEvents \u0026amp; EPOLLIN) { awoken(); } } else { ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex \u0026gt;= 0) { int events = 0; if (epollEvents \u0026amp; EPOLLIN) events |= EVENT_INPUT; if (epollEvents \u0026amp; EPOLLOUT) events |= EVENT_OUTPUT; if (epollEvents \u0026amp; EPOLLERR) events |= EVENT_ERROR; if (epollEvents \u0026amp; EPOLLHUP) events |= EVENT_HANGUP; pushResponse(events, mRequests.valueAt(requestIndex)); } } } //1：处理C层发送的消息  // Invoke pending message callbacks.  mNextMessageUptime = LLONG_MAX; while (mMessageEnvelopes.size() != 0) { nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); const MessageEnvelope\u0026amp; messageEnvelope = mMessageEnvelopes.itemAt(0); if (messageEnvelope.uptime \u0026lt;= now) { // Remove the envelope from the list.  // We keep a strong reference to the handler until the call to handleMessage  // finishes. Then we drop it so that the handler can be deleted *before*  // we reacquire our lock.  { // obtain handler  sp\u0026lt;MessageHandler\u0026gt; handler = messageEnvelope.handler; Message message = messageEnvelope.message; mMessageEnvelopes.removeAt(0); mSendingMessage = true; mLock.unlock(); handler-\u0026gt;handleMessage(message); } // release handler  mLock.lock(); mSendingMessage = false; result = POLL_CALLBACK; } else { // The last message left at the head of the queue determines the next wakeup time.  mNextMessageUptime = messageEnvelope.uptime; break; } } //2：回调通过addFd添加进来的监听  // Invoke all response callbacks.  for (size_t i = 0; i \u0026lt; mResponses.size(); i++) { Response\u0026amp; response = mResponses.editItemAt(i); if (response.request.ident == POLL_CALLBACK) { int fd = response.request.fd; int events = response.events; void* data = response.request.data; // Invoke the callback. Note that the file descriptor may be closed by  // the callback (and potentially even reused) before the function returns so  // we need to be a little careful when removing the file descriptor afterwards.  int callbackResult = response.request.callback-\u0026gt;handleEvent(fd, events, data);//回调flutter在MessageLoopAndroid构造方法中设置的callback监听  if (callbackResult == 0) {//callback方法返回0时表示需要移除该fd监听  removeFd(fd, response.request.seq); } // Clear the callback reference in the response structure promptly because we  // will not clear the response vector itself until the next poll.  response.request.callback.clear(); result = POLL_CALLBACK; } } return result;//3：:返回之后回到java层的死循环处处理java层消息 } pushResponse void Looper::pushResponse(int events, const Request\u0026amp; request) { Response response; response.events = events; response.request = request; mResponses.push(response); } 参考 Android Handler 中的 epoll 机制？\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/apm/matrixgradleplugin/",
	"title": "MatrixGradlePlugin",
	"tags": [],
	"description": "",
	"content": "主流程 graph LR 注册plugin--\u0026gt;CollectDirectoryInputTask--\u0026gt;MethodCollector 注册plugin--\u0026gt;CollectJarInputTask--\u0026gt;MethodCollector--\u0026gt;MethodTracer 解决了很多Matrix自身的问题，参考同目录下\u0026laquo;Matrix接入后遇到的问题.md\u0026raquo;\nMatrixPlugin.apply @Override void apply(Project project) { project.extensions.create(\u0026#34;matrix\u0026#34;, MatrixExtension) project.matrix.extensions.create(\u0026#34;trace\u0026#34;, MatrixTraceExtension) project.matrix.extensions.create(\u0026#34;removeUnusedResources\u0026#34;, MatrixDelUnusedResConfiguration) if (!project.plugins.hasPlugin(\u0026#39;com.android.application\u0026#39;)) { throw new GradleException(\u0026#39;Matrix Plugin, Android Application plugin required\u0026#39;) } project.afterEvaluate { def android = project.extensions.android def configuration = project.matrix android.applicationVariants.all { variant -\u0026gt; if (configuration.trace.enable) { com.tencent.matrix.trace.transform.MatrixTraceTransform.inject(project, configuration.trace, variant.getVariantData().getScope())//main  } if (configuration.removeUnusedResources.enable) { if (Util.isNullOrNil(configuration.removeUnusedResources.variant) || variant.name.equalsIgnoreCase(configuration.removeUnusedResources.variant)) { Log.i(TAG, \u0026#34;removeUnusedResources %s\u0026#34;, configuration.removeUnusedResources) RemoveUnusedResourcesTask removeUnusedResourcesTask = project.tasks.create(\u0026#34;remove\u0026#34; + variant.name.capitalize() + \u0026#34;UnusedResources\u0026#34;, RemoveUnusedResourcesTask) removeUnusedResourcesTask.inputs.property(RemoveUnusedResourcesTask.BUILD_VARIANT, variant.name) project.tasks.add(removeUnusedResourcesTask) removeUnusedResourcesTask.dependsOn variant.packageApplication variant.assemble.dependsOn removeUnusedResourcesTask } } } } } MatrixTraceTransform.inject public static void inject(Project project, MatrixTraceExtension extension, VariantScope variantScope) { GlobalScope globalScope = variantScope.getGlobalScope(); BaseVariantData variant = variantScope.getVariantData(); String mappingOut = Joiner.on(File.separatorChar).join( String.valueOf(globalScope.getBuildDir()), FD_OUTPUTS, \u0026#34;mapping\u0026#34;, variantScope.getVariantConfiguration().getDirName()); String traceClassOut = Joiner.on(File.separatorChar).join( String.valueOf(globalScope.getBuildDir()), FD_OUTPUTS, \u0026#34;traceClassOut\u0026#34;, variantScope.getVariantConfiguration().getDirName()); Configuration config = new Configuration.Builder() .setPackageName(variant.getApplicationId()) .setBaseMethodMap(extension.getBaseMethodMapFile()) .setBlackListFile(extension.getBlackListFile()) .setMethodMapFilePath(mappingOut + \u0026#34;/methodMapping.txt\u0026#34;)//main  .setIgnoreMethodMapFilePath(mappingOut + \u0026#34;/ignoreMethodMapping.txt\u0026#34;) .setMappingPath(mappingOut) .setTraceClassOut(traceClassOut) .build(); try { String[] hardTask = getTransformTaskName(extension.getCustomDexTransformName(), variant.getName()); for (Task task : project.getTasks()) { for (String str : hardTask) { if (task.getName().equalsIgnoreCase(str) \u0026amp;\u0026amp; task instanceof TransformTask) { TransformTask transformTask = (TransformTask) task; Log.i(TAG, \u0026#34;successfully inject task:\u0026#34; + transformTask.getName()); Field field = TransformTask.class.getDeclaredField(\u0026#34;transform\u0026#34;); field.setAccessible(true); field.set(task, new MatrixTraceTransform(config, transformTask.getTransform())); break; } } private static String[] getTransformTaskName(String customDexTransformName, String buildTypeSuffix) { if (!Util.isNullOrNil(customDexTransformName)) { return new String[]{customDexTransformName + \u0026#34;For\u0026#34; + buildTypeSuffix}; } else { String[] names = new String[]{ \u0026#34;transformClassesWithDexBuilderFor\u0026#34; + buildTypeSuffix, \u0026#34;transformClassesWithDexFor\u0026#34; + buildTypeSuffix, }; return names; } } MatrixTraceTransform.transform\n@Override public void transform(TransformInvocation transformInvocation) throws TransformException, InterruptedException, IOException { super.transform(transformInvocation); long start = System.currentTimeMillis(); try { doTransform(transformInvocation); // hack,main  } catch (ExecutionException e) { e.printStackTrace(); } long cost = System.currentTimeMillis() - start; long begin = System.currentTimeMillis(); origTransform.transform(transformInvocation); long origTransformCost = System.currentTimeMillis() - begin; Log.i(\u0026#34;Matrix.\u0026#34; + getName(), \u0026#34;[transform] cost time: %dms %s:%sms MatrixTraceTransform:%sms\u0026#34;, System.currentTimeMillis() - start, origTransform.getClass().getSimpleName(), origTransformCost, cost); } private void doTransform(TransformInvocation transformInvocation) throws ExecutionException, InterruptedException { final boolean isIncremental = transformInvocation.isIncremental() \u0026amp;\u0026amp; this.isIncremental(); /** \\* step 1 */ long start = System.currentTimeMillis(); List\u0026lt;Future\u0026gt; futures = new LinkedList\u0026lt;\u0026gt;(); final MappingCollector mappingCollector = new MappingCollector(); final AtomicInteger methodId = new AtomicInteger(0); final ConcurrentHashMap\u0026lt;String, TraceMethod\u0026gt; collectedMethodMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); futures.add(executor.submit(new ParseMappingTask(mappingCollector, collectedMethodMap, methodId)));//main  Map\u0026lt;File, File\u0026gt; dirInputOutMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); Map\u0026lt;File, File\u0026gt; jarInputOutMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); Collection\u0026lt;TransformInput\u0026gt; inputs = transformInvocation.getInputs(); for (TransformInput input : inputs) { for (DirectoryInput directoryInput : input.getDirectoryInputs()) { futures.add(executor.submit(new CollectDirectoryInputTask(dirInputOutMap, directoryInput, isIncremental))); } for (JarInput inputJar : input.getJarInputs()) { futures.add(executor.submit(new CollectJarInputTask(inputJar, isIncremental, jarInputOutMap, dirInputOutMap))); } } for (Future future : futures) { future.get(); } futures.clear(); Log.i(TAG, \u0026#34;[doTransform] Step(1)[Parse]... cost:%sms\u0026#34;, System.currentTimeMillis() - start); /** \\* step 2 */ start = System.currentTimeMillis(); //main  MethodCollector methodCollector = new MethodCollector(executor, mappingCollector, methodId, config, collectedMethodMap); methodCollector.collect(dirInputOutMap.keySet(), jarInputOutMap.keySet()); Log.i(TAG, \u0026#34;[doTransform] Step(2)[Collection]... cost:%sms\u0026#34;, System.currentTimeMillis() - start); /** \\* step 3 */ start = System.currentTimeMillis(); MethodTracer methodTracer = new MethodTracer(executor, mappingCollector, config, methodCollector.getCollectedMethodMap(), methodCollector.getCollectedClassExtendMap()); methodTracer.trace(dirInputOutMap, jarInputOutMap); Log.i(TAG, \u0026#34;[doTransform] Step(3)[Trace]... cost:%sms\u0026#34;, System.currentTimeMillis() - start); } ParseMappingTask private class ParseMappingTask implements Runnable { @Override public void run() { try { long start = System.currentTimeMillis(); File mappingFile = new File(config.mappingDir, \u0026#34;mapping.txt\u0026#34;); if (mappingFile.exists() \u0026amp;\u0026amp; mappingFile.isFile()) { MappingReader mappingReader = new MappingReader(mappingFile); mappingReader.read(mappingCollector); } int size = config.parseBlackFile(mappingCollector); File baseMethodMapFile = new File(config.baseMethodMapPath); getMethodFromBaseMethod(baseMethodMapFile, collectedMethodMap); retraceMethodMap(mappingCollector, collectedMethodMap); Log.i(TAG, \u0026#34;[ParseMappingTask#run] cost:%sms, black size:%s, collect %s method from %s\u0026#34;, System.currentTimeMillis() - start, size, collectedMethodMap.size(), config.baseMethodMapPath); } catch (IOException e) { e.printStackTrace(); } } MethodCollector.collect public void collect(Set\u0026lt;File\u0026gt; srcFolderList, Set\u0026lt;File\u0026gt; dependencyJarList) throws ExecutionException, InterruptedException { List\u0026lt;Future\u0026gt; futures = new LinkedList\u0026lt;\u0026gt;(); for (File srcFile : srcFolderList) { ArrayList\u0026lt;File\u0026gt; classFileList = new ArrayList\u0026lt;\u0026gt;(); if (srcFile.isDirectory()) { listClassFiles(classFileList, srcFile); } else { classFileList.add(srcFile); } for (File classFile : classFileList) { futures.add(executor.submit(new CollectSrcTask(classFile))); } } for (File jarFile : dependencyJarList) { futures.add(executor.submit(new CollectJarTask(jarFile))); } for (Future future : futures) { future.get(); } futures.clear(); futures.add(executor.submit(new Runnable() { @Override public void run() { saveIgnoreCollectedMethod(mappingCollector); } })); futures.add(executor.submit(new Runnable() { @Override public void run() { saveCollectedMethod(mappingCollector); } })); for (Future future : futures) { future.get(); } futures.clear(); CollectJarTask class CollectJarTask implements Runnable { @Override public void run() { ZipFile zipFile = null; try { zipFile = new ZipFile(fromJar); Enumeration\u0026lt;? extends ZipEntry\u0026gt; enumeration = zipFile.entries(); while (enumeration.hasMoreElements()) { ZipEntry zipEntry = enumeration.nextElement(); String zipEntryName = zipEntry.getName(); if (isNeedTraceFile(zipEntryName)) { InputStream inputStream = zipFile.getInputStream(zipEntry); ClassReader classReader = new ClassReader(inputStream); ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_MAXS); ClassVisitor visitor = new TraceClassAdapter(Opcodes.ASM5, classWriter);//main  classReader.accept(visitor, 0); TraceClassAdapter private class TraceClassAdapter extends ClassVisitor { @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) { if (isABSClass) { return super.visitMethod(access, name, desc, signature, exceptions); } else { if (!hasWindowFocusMethod) { hasWindowFocusMethod = isWindowFocusChangeMethod(name, desc); } return new CollectMethodNode(className, access, name, desc, signature, exceptions); } } private class CollectMethodNode extends MethodNode { @Override public void visitEnd() { super.visitEnd(); if (isNeedTrace \u0026amp;\u0026amp; !collectedMethodMap.containsKey(traceMethod.getMethodName())) { traceMethod.id = methodId.incrementAndGet(); collectedMethodMap.put(traceMethod.getMethodName(), traceMethod); incrementCount.incrementAndGet(); saveCollectedMethod private void saveCollectedMethod(MappingCollector mappingCollector) { File methodMapFile = new File(configuration.methodMapFilePath); List\u0026lt;TraceMethod\u0026gt; methodList = new ArrayList\u0026lt;\u0026gt;(); TraceMethod extra = TraceMethod.create(TraceBuildConstants.METHOD_ID_DISPATCH, Opcodes.ACC_PUBLIC, \u0026#34;android.os.Handler\u0026#34;, \u0026#34;dispatchMessage\u0026#34;, \u0026#34;(Landroid.os.Message;)V\u0026#34;); collectedMethodMap.put(extra.getMethodName(), extra);//main  methodList.addAll(collectedMethodMap.values()); Log.i(TAG, \u0026#34;[saveCollectedMethod] size:%s incrementCount:%s path:%s\u0026#34;, collectedMethodMap.size(), incrementCount.get(), methodMapFile.getAbsolutePath()); Collections.sort(methodList, new Comparator\u0026lt;TraceMethod\u0026gt;() { @Override public int compare(TraceMethod o1, TraceMethod o2) { return o1.id - o2.id; } }); ... FileOutputStream fileOutputStream = new FileOutputStream(methodMapFile, false); Writer w = new OutputStreamWriter(fileOutputStream, \u0026#34;UTF-8\u0026#34;); pw = new PrintWriter(w); for (TraceMethod traceMethod : methodList) { traceMethod.revert(mappingCollector); pw.println(traceMethod.toString()); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/apm/resource/matrixresourceplugin/",
	"title": "MatrixResourcePlugin",
	"tags": [],
	"description": "",
	"content": "Summary:\n 参考了leakcanary并进行优化，如哨兵，hprof裁剪等 dump hprof文件仍然在主进程，无法在线上使用 先dump hprof文件，后使用HprofVisitor进行裁剪压缩，而不是在dump的同时通过native hook直接裁剪 hprof文件的生成和分析相分离，分析过程在server端命令行执行分析任务  ResourcePlugin.init private final ResourceConfig mConfig; private ActivityRefWatcher mWatcher = null; @Override public void init(Application app, PluginListener listener) { super.init(app, listener); if (Build.VERSION.SDK_INT \u0026lt; Build.VERSION_CODES.ICE_CREAM_SANDWICH) { MatrixLog.e(TAG, \u0026#34;API is low Build.VERSION_CODES.ICE_CREAM_SANDWICH(14), ResourcePlugin is not supported\u0026#34;); unSupportPlugin(); return; } mWatcher = new ActivityRefWatcher(app, this); } ResourcePlugin.start @Override public void start() { super.start(); mWatcher.start(); } @Override public void stop() { super.stop(); mWatcher.stop(); } @Override public void destroy() { super.destroy(); mWatcher.destroy(); } ActivityRefWatcher public ActivityRefWatcher(Application app, final ResourcePlugin resourcePlugin) { this(app, resourcePlugin, new ComponentFactory()); } private ActivityRefWatcher(Application app, ResourcePlugin resourcePlugin, ComponentFactory componentFactory) { super(app, FILE_CONFIG_EXPIRED_TIME, resourcePlugin.getTag(), resourcePlugin); this.mResourcePlugin = resourcePlugin; final ResourceConfig config = resourcePlugin.getConfig(); final Context context = app; HandlerThread handlerThread = MatrixHandlerThread.getDefaultHandlerThread(); mDumpHprofMode = config.getDumpHprofMode(); mBgScanTimes = config.getBgScanIntervalMillis(); mFgScanTimes = config.getScanIntervalMillis(); mContentIntent = config.getNotificationContentIntent(); mDetectExecutor = componentFactory.createDetectExecutor(config, handlerThread); mMaxRedetectTimes = config.getMaxRedetectTimes(); mDumpStorageManager = componentFactory.createDumpStorageManager(context); mHeapDumper = componentFactory.createHeapDumper(context, mDumpStorageManager); mHeapDumpHandler = componentFactory.createHeapDumpHandler(context, config); mDestroyedActivityInfos = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); } start @Override public void start() { stopDetect();//main  final Application app = mResourcePlugin.getApplication(); if (app != null) { app.registerActivityLifecycleCallbacks(mRemovedActivityMonitor);//main  AppActiveMatrixDelegate.INSTANCE.addListener(this);//main--\u0026gt;onForeground  scheduleDetectProcedure();//main  MatrixLog.i(TAG, \u0026#34;watcher is started.\u0026#34;); } } @Override public void onForeground(boolean isForeground) { if (isForeground) { MatrixLog.i(TAG, \u0026#34;we are in foreground, modify scan time[%sms].\u0026#34;, mFgScanTimes); mDetectExecutor.clearTasks(); mDetectExecutor.setDelayMillis(mFgScanTimes); mDetectExecutor.executeInBackground(mScanDestroyedActivitiesTask);//main  } else { MatrixLog.i(TAG, \u0026#34;we are in background, modify scan time[%sms].\u0026#34;, mBgScanTimes); mDetectExecutor.setDelayMillis(mBgScanTimes); } } private void scheduleDetectProcedure() { mDetectExecutor.executeInBackground(mScanDestroyedActivitiesTask); } @Override public void stop() { stopDetect();//main  MatrixLog.i(TAG, \u0026#34;watcher is stopped.\u0026#34;); } private void stopDetect() { final Application app = mResourcePlugin.getApplication(); if (app != null) { app.unregisterActivityLifecycleCallbacks(mRemovedActivityMonitor); AppActiveMatrixDelegate.INSTANCE.removeListener(this); unscheduleDetectProcedure(); } } Application.ActivityLifecycleCallbacks.onActivityDestroyed private final Application.ActivityLifecycleCallbacks mRemovedActivityMonitor = new ActivityLifeCycleCallbacksAdapter() { @Override public void onActivityDestroyed(Activity activity) { pushDestroyedActivityInfo(activity); } } ActivityRefWatcher.mScanDestroyedActivitiesTask private final RetryableTask mScanDestroyedActivitiesTask = new RetryableTask() { @Override public Status execute() { // If destroyed activity list is empty, just wait to save power.  if (mDestroyedActivityInfos.isEmpty()) { MatrixLog.i(TAG, \u0026#34;DestroyedActivityInfo isEmpty!\u0026#34;); return Status.RETRY; } final WeakReference\u0026lt;Object\u0026gt; sentinelRef = new WeakReference\u0026lt;\u0026gt;(new Object()); triggerGc(); if (sentinelRef.get() != null) { // System ignored our gc request, we will retry later.  MatrixLog.d(TAG, \u0026#34;system ignore our gc request, wait for next detection.\u0026#34;); return Status.RETRY; } final Iterator\u0026lt;DestroyedActivityInfo\u0026gt; infoIt = mDestroyedActivityInfos.iterator(); while (infoIt.hasNext()) { final DestroyedActivityInfo destroyedActivityInfo = infoIt.next(); if (destroyedActivityInfo.mActivityRef.get() == null) { // The activity was recycled by a gc triggered outside.  MatrixLog.v(TAG, \u0026#34;activity with key [%s] was already recycled.\u0026#34;, destroyedActivityInfo.mKey); infoIt.remove(); continue; } ++destroyedActivityInfo.mDetectedCount; if (destroyedActivityInfo.mDetectedCount \u0026lt; mMaxRedetectTimes || !mResourcePlugin.getConfig().getDetectDebugger()) { // Although the sentinel tell us the activity should have been recycled,  // system may still ignore it, so try again until we reach max retry times.  MatrixLog.i(TAG, \u0026#34;activity with key [%s] should be recycled but actually still \\n\u0026#34; \\+ \u0026#34;exists in %s times, wait for next detection to confirm.\u0026#34;, destroyedActivityInfo.mKey, destroyedActivityInfo.mDetectedCount); continue; } MatrixLog.i(TAG, \u0026#34;activity with key [%s] was suspected to be a leaked instance. mode[%s]\u0026#34;, destroyedActivityInfo.mKey, mDumpHprofMode); if (mDumpHprofMode == ResourceConfig.DumpMode.SILENCE_DUMP) { .... mResourcePlugin.onDetectIssue(new Issue(resultJson)); } else if (mDumpHprofMode == ResourceConfig.DumpMode.AUTO_DUMP) { final File hprofFile = mHeapDumper.dumpHeap();//main  if (hprofFile != null) { markPublished(destroyedActivityInfo.mActivityName); final HeapDump heapDump = new HeapDump(hprofFile, destroyedActivityInfo.mKey, destroyedActivityInfo.mActivityName); mHeapDumpHandler.process(heapDump);//main  infoIt.remove(); } else { MatrixLog.i(TAG, \u0026#34;heap dump for further analyzing activity with key [%s] was failed, just ignore.\u0026#34;, destroyedActivityInfo.mKey); infoIt.remove(); } } else if (mDumpHprofMode == ResourceConfig.DumpMode.MANUAL_DUMP) { ...... MatrixLog.i(TAG, \u0026#34;show notification for notify activity leak. %s\u0026#34;, destroyedActivityInfo.mActivityName); } AndroidHeapDumper.dumpHeap//ported from LeakCanary This class is ported from LeakCanary.\npublic File dumpHeap() { final File hprofFile = mDumpStorageManager.newHprofFile(); try { Debug.dumpHprofData(hprofFile.getAbsolutePath()); return hprofFile; } catch (Exception e) { MatrixLog.printErrStackTrace(TAG, e, \u0026#34;failed to dump heap into file: %s.\u0026#34;, hprofFile.getAbsolutePath()); return null; } } CanaryWorkerService.shrinkHprofAndReport public static void shrinkHprofAndReport(Context context, HeapDump heapDump) { final Intent intent = new Intent(context, CanaryWorkerService.class); intent.setAction(ACTION_SHRINK_HPROF); intent.putExtra(EXTRA_PARAM_HEAPDUMP, heapDump); enqueueWork(context, CanaryWorkerService.class, JOB_ID, intent); } @Override protected void onHandleWork(Intent intent) { if (intent != null) { final String action = intent.getAction(); if (ACTION_SHRINK_HPROF.equals(action)) { try { intent.setExtrasClassLoader(this.getClassLoader()); final HeapDump heapDump = (HeapDump) intent.getSerializableExtra(EXTRA_PARAM_HEAPDUMP); if (heapDump != null) { doShrinkHprofAndReport(heapDump);//main  } else { MatrixLog.e(TAG, \u0026#34;failed to deserialize heap dump, give up shrinking and reporting.\u0026#34;); } } catch (Throwable thr) { MatrixLog.printErrStackTrace(TAG, thr, \u0026#34;failed to deserialize heap dump, give up shrinking and reporting.\u0026#34;); } } } } private void doShrinkHprofAndReport(HeapDump heapDump) { final File hprofDir = heapDump.getHprofFile().getParentFile(); final File shrinkedHProfFile = new File(hprofDir, getShrinkHprofName(heapDump.getHprofFile())); final File zipResFile = new File(hprofDir, getResultZipName(\u0026#34;dump_result_\u0026#34; + android.os.Process.myPid())); final File hprofFile = heapDump.getHprofFile(); ZipOutputStream zos = null; try { long startTime = System.currentTimeMillis(); new HprofBufferShrinker().shrink(hprofFile, shrinkedHProfFile);//main  MatrixLog.i(TAG, \u0026#34;shrink hprof file %s, size: %dk to %s, size: %dk, use time:%d\u0026#34;, hprofFile.getPath(), hprofFile.length() / 1024, shrinkedHProfFile.getPath(), shrinkedHProfFile.length() / 1024, (System.currentTimeMillis() - startTime)); zos = new ZipOutputStream(new BufferedOutputStream(new FileOutputStream(zipResFile))); final ZipEntry resultInfoEntry = new ZipEntry(\u0026#34;result.info\u0026#34;); final ZipEntry shrinkedHProfEntry = new ZipEntry(shrinkedHProfFile.getName()); zos.putNextEntry(resultInfoEntry); final PrintWriter pw = new PrintWriter(new OutputStreamWriter(zos, Charset.forName(\u0026#34;UTF-8\u0026#34;))); pw.println(\u0026#34;# Resource Canary Result Infomation. THIS FILE IS IMPORTANT FOR THE ANALYZER !!\u0026#34;); pw.println(\u0026#34;sdkVersion=\u0026#34; + Build.VERSION.SDK_INT); pw.println(\u0026#34;manufacturer=\u0026#34; + Build.MANUFACTURER); pw.println(\u0026#34;hprofEntry=\u0026#34; + shrinkedHProfEntry.getName()); pw.println(\u0026#34;leakedActivityKey=\u0026#34; + heapDump.getReferenceKey()); pw.flush(); zos.closeEntry(); zos.putNextEntry(shrinkedHProfEntry); copyFileToStream(shrinkedHProfFile, zos); zos.closeEntry(); shrinkedHProfFile.delete(); hprofFile.delete(); MatrixLog.i(TAG, \u0026#34;process hprof file use total time:%d\u0026#34;, (System.currentTimeMillis() - startTime)); //回调通知shrinkedHProfile文件路径等信息  CanaryResultService.reportHprofResult(this, zipResFile.getAbsolutePath(), heapDump.getActivityName()); }} HprofBufferShrinker.shrink public void shrink(File hprofIn, File hprofOut) throws IOException { FileInputStream is = null; OutputStream os = null; try { is = new FileInputStream(hprofIn); os = new BufferedOutputStream(new FileOutputStream(hprofOut)); final HprofReader reader = new HprofReader(new BufferedInputStream(is)); reader.accept(new HprofInfoCollectVisitor());//main  // Reset.  is.getChannel().position(0); reader.accept(new HprofKeptBufferCollectVisitor());//main  // Reset.  is.getChannel().position(0); reader.accept(new HprofBufferShrinkVisitor(new HprofWriter(os)));//main  } HprofReader.accept public HprofReader(InputStream in) { mStreamIn = in; } public void accept(HprofVisitor hv) throws IOException { acceptHeader(hv); acceptRecord(hv); hv.visitEnd(); } private void acceptHeader(HprofVisitor hv) throws IOException { final String text = IOUtil.readNullTerminatedString(mStreamIn); final int idSize = IOUtil.readBEInt(mStreamIn); if (idSize \u0026lt;= 0 || idSize \u0026gt;= (Integer.MAX_VALUE \u0026gt;\u0026gt; 1)) { throw new IOException(\u0026#34;bad idSize: \u0026#34; + idSize); } final long timestamp = IOUtil.readBELong(mStreamIn); mIdSize = idSize; hv.visitHeader(text, idSize, timestamp); } HprofInfoCollectVisitor.visitHeader class HprofInfoCollectVisitor extends HprofVisitor { @Override public void visitHeader(String text, int idSize, long timestamp) { mIdSize = idSize; mNullBufferId = ID.createNullID(idSize); } } 分析Hprof 对hprof文件的生成和分析相分离，分析位于matrix-resource-canary/matrix-resource-canary-analyzer模块中的com.tencent.matrix.resource.analyzer.CLIMain.main方法\n//CLIMain public static void main(String[] args) { if (args.length == 0) { printUsage(System.out); System.exit(ERROR_NEED_ARGUMENTS); } try { final CommandLine cmdline = new DefaultParser().parse(sOptions, args); if (cmdline.hasOption(OPTION_HELP.mOption.getLongOpt())) { printUsage(System.out); System.exit(ERROR_SUCCESS); } parseArguments(cmdline); doAnalyze();//main  } } private static void doAnalyze() throws IOException { // Then do analyzing works and output into directory or zip according to the option. Besides,  // store extra info into the result json by the way.  analyzeAndStoreResult(tempHprofFile, sdkVersion, manufacturer, leakedActivityKey, extraInfo); } private static void analyzeAndStoreResult(File hprofFile, int sdkVersion, String manufacturer, String leakedActivityKey, JSONObject extraInfo) throws IOException { final HeapSnapshot heapSnapshot = new HeapSnapshot(hprofFile); final ExcludedRefs excludedRefs = AndroidExcludedRefs.createAppDefaults(sdkVersion, manufacturer).build(); final ActivityLeakResult activityLeakResult = new ActivityLeakAnalyzer(leakedActivityKey, excludedRefs).analyze(heapSnapshot);//main  DuplicatedBitmapResult duplicatedBmpResult = DuplicatedBitmapResult.noDuplicatedBitmap(0); if (sdkVersion \u0026lt; 26) {//main  final ExcludedBmps excludedBmps = AndroidExcludedBmpRefs.createDefaults().build(); duplicatedBmpResult = new DuplicatedBitmapAnalyzer(mMinBmpLeakSize, excludedBmps).analyze(heapSnapshot);//main  } else { System.err.println(\u0026#34;\\n ! SDK version of target device is larger or equal to 26, \u0026#34; \\+ \u0026#34;which is not supported by DuplicatedBitmapAnalyzer.\u0026#34;); } 其他 ComponentFactory public static class ComponentFactory { protected RetryableTaskExecutor createDetectExecutor(ResourceConfig config, HandlerThread handlerThread) { return new RetryableTaskExecutor(config.getScanIntervalMillis(), handlerThread); } protected DumpStorageManager createDumpStorageManager(Context context) { return new DumpStorageManager(context); } protected AndroidHeapDumper createHeapDumper(Context context, DumpStorageManager dumpStorageManager) { return new AndroidHeapDumper(context, dumpStorageManager); } protected AndroidHeapDumper.HeapDumpHandler createHeapDumpHandler(final Context context, ResourceConfig resourceConfig) { return new AndroidHeapDumper.HeapDumpHandler() { @Override public void process(HeapDump result) {//main  CanaryWorkerService.shrinkHprofAndReport(context, result);//main  } }; } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/apm/matrixsource/",
	"title": "MatrixSource",
	"tags": [],
	"description": "",
	"content": "MatrixPlugins设计 TracePlugin设计 main_title_sbuffer_array\nmain_title_structureddatatostack\n其他main_title为UIThreadMonitor和LooperMonitor\nStartupTracer /** * \u0026lt;p\u0026gt; * firstMethod.i LAUNCH_ACTIVITY onWindowFocusChange LAUNCH_ACTIVITY onWindowFocusChange * ^ ^ ^ ^ ^ * | | | | | * |---------app---------|---|---firstActivity---|---------...---------|---careActivity---| * |\u0026lt;--applicationCost--\u0026gt;| * |\u0026lt;--------------firstScreenCost--------------\u0026gt;| * |\u0026lt;---------------------------------------coldCost-------------------------------------\u0026gt;| * . |\u0026lt;-----warmCost----\u0026gt;| * * \u0026lt;/p\u0026gt; */ MatrixApplication.onCreate @Override public void onCreate() { super.onCreate(); Matrix.Builder builder = new Matrix.Builder(this); builder.patchListener(new TestPluginListener(this)); //trace  TraceConfig traceConfig = new TraceConfig.Builder() .dynamicConfig(dynamicConfig) .enableFPS(fpsEnable) .enableEvilMethodTrace(traceEnable) .enableAnrTrace(traceEnable) .enableStartup(traceEnable) .splashActivities(\u0026#34;sample.tencent.matrix.SplashActivity;\u0026#34;) .isDebug(true) .isDevEnv(false) .build(); TracePlugin tracePlugin = (new TracePlugin(traceConfig)); builder.plugin(tracePlugin); //resource  builder.plugin(new ResourcePlugin(new ResourceConfig.Builder() .dynamicConfig(dynamicConfig) .setDumpHprof(false) .setDetectDebuger(true) //only set true when in sample, not in your app  .build())); ResourcePlugin.activityLeakFixer(this); //io  IOCanaryPlugin ioCanaryPlugin = new IOCanaryPlugin(new IOConfig.Builder() .dynamicConfig(dynamicConfig) .build()); builder.plugin(ioCanaryPlugin); // prevent api 19 UnsatisfiedLinkError  //sqlite  SQLiteLintConfig config = initSQLiteLintConfig(); SQLiteLintPlugin sqLiteLintPlugin = new SQLiteLintPlugin(config); builder.plugin(sqLiteLintPlugin); ThreadWatcher threadWatcher = new ThreadWatcher(new ThreadConfig.Builder().dynamicConfig(dynamicConfig).build()); builder.plugin(threadWatcher); Matrix.init(builder.build());//main  //start only startup tracer, close other tracer.  tracePlugin.start();//main  Matrix.with().getPluginByClass(ThreadWatcher.class).start();//main  } Plugin配置，构造Matrix单例对象 //Matrix public static class Builder { private final Application application; private PluginListener pluginListener; private HashSet\u0026lt;Plugin\u0026gt; plugins = new HashSet\u0026lt;\u0026gt;();//main  public Builder(Application app) { this.application = app; } public Builder patchListener(PluginListener pluginListener) { this.pluginListener = pluginListener; return this; } public Builder plugin(Plugin plugin) { String tag = plugin.getTag(); for (Plugin exist : plugins) { if (tag.equals(exist.getTag())) { throw new RuntimeException(String.format(\u0026#34;plugin with tag %s is already exist\u0026#34;, tag)); } } plugins.add(plugin); return this; } public Matrix build() { if (pluginListener == null) { pluginListener = new DefaultPluginListener(application); } return new Matrix(application, pluginListener, plugins); } plugin.init private Matrix(Application app, PluginListener listener, HashSet\u0026lt;Plugin\u0026gt; plugins) { this.application = app; this.pluginListener = listener; this.plugins = plugins; AppActiveMatrixDelegate.INSTANCE.init(application); for (Plugin plugin : plugins) { plugin.init(application, pluginListener); pluginListener.onInit(plugin); } } public static Matrix init(Matrix matrix) { synchronized (Matrix.class) { if (sInstance == null) { sInstance = matrix; } else { MatrixLog.e(TAG, \u0026#34;Matrix instance is already set. this invoking will be ignored\u0026#34;); } } return sInstance; } public static Matrix with() { if (sInstance == null) { throw new RuntimeException(\u0026#34;you must init Matrix sdk first\u0026#34;); } return sInstance; } tracePlugin.init @Override public void init(Application app, PluginListener listener) { super.init(app, listener); MatrixLog.i(TAG, \u0026#34;trace plugin init, trace config: %s\u0026#34;, traceConfig.toString()); if (Build.VERSION.SDK_INT \u0026lt; Build.VERSION_CODES.JELLY_BEAN) { MatrixLog.e(TAG, \u0026#34;[FrameBeat] API is low Build.VERSION_CODES.JELLY_BEAN(16), TracePlugin is not supported\u0026#34;); unSupportPlugin(); return; } anrTracer = new AnrTracer(traceConfig); frameTracer = new FrameTracer(traceConfig); evilMethodTracer = new EvilMethodTracer(traceConfig); startupTracer = new StartupTracer(traceConfig); } tracePlugin.start @Override public void start() { super.start(); Runnable runnable = new Runnable() { @Override public void run() { if (!UIThreadMonitor.getMonitor().isInit()) { try { UIThreadMonitor.getMonitor().init(traceConfig); } catch (java.lang.RuntimeException e) { MatrixLog.e(TAG, \u0026#34;[start] RuntimeException:%s\u0026#34;, e); return; } } AppMethodBeat.getInstance().onStart(); UIThreadMonitor.getMonitor().onStart(); anrTracer.onStartTrace(); frameTracer.onStartTrace(); evilMethodTracer.onStartTrace(); startupTracer.onStartTrace(); } }; if (Thread.currentThread() == Looper.getMainLooper().getThread()) { runnable.run(); } else { MatrixLog.w(TAG, \u0026#34;start TracePlugin in Thread[%s] but not in mainThread!\u0026#34;, Thread.currentThread().getId()); MatrixHandlerThread.getDefaultMainHandler().post(runnable); } } UIThreadMonitor(Choreographer中的vsync监听) init public void init(TraceConfig config) { if (Thread.currentThread() != Looper.getMainLooper().getThread()) { throw new AssertionError(\u0026#34;must be init in main thread!\u0026#34;); } this.config = config; choreographer = Choreographer.getInstance(); callbackQueueLock = reflectObject(choreographer, \u0026#34;mLock\u0026#34;); callbackQueues = reflectObject(choreographer, \u0026#34;mCallbackQueues\u0026#34;); addInputQueue = reflectChoreographerMethod(callbackQueues[CALLBACK_INPUT], ADD_CALLBACK, long.class, Object.class, Object.class); addAnimationQueue = reflectChoreographerMethod(callbackQueues[CALLBACK_ANIMATION], ADD_CALLBACK, long.class, Object.class, Object.class); addTraversalQueue = reflectChoreographerMethod(callbackQueues[CALLBACK_TRAVERSAL], ADD_CALLBACK, long.class, Object.class, Object.class); frameIntervalNanos = reflectObject(choreographer, \u0026#34;mFrameIntervalNanos\u0026#34;); LooperMonitor.register(new LooperMonitor.LooperDispatchListener() { @Override public boolean isValid() { return isAlive; } @Override public void dispatchStart() { super.dispatchStart(); UIThreadMonitor.this.dispatchBegin(); } @Override public void dispatchEnd() { super.dispatchEnd(); UIThreadMonitor.this.dispatchEnd(); } }); if (config.isDevEnv()) { addObserver(new LooperObserver() { @Override public void doFrame(String focusedActivityName, long start, long end, long frameCostMs, long inputCost, long animationCost, long traversalCost) { MatrixLog.i(TAG, \u0026#34;activityName[%s] frame cost:%sms [%s|%s|%s]ns\u0026#34;, focusedActivityName, frameCostMs, inputCost, animationCost, traversalCost); } }); } MatrixLog.i(TAG, \u0026#34;[UIThreadMonitor] %s %s %s %s %s frameIntervalNanos:%s\u0026#34;, callbackQueueLock == null, callbackQueues == null, addInputQueue == null, addTraversalQueue == null, addAnimationQueue == null, frameIntervalNanos); this.isInit = true; } onStart @Override public synchronized void onStart() { if (!isInit) { throw new RuntimeException(\u0026#34;never init!\u0026#34;); } if (!isAlive) { this.isAlive = true; synchronized (this) { MatrixLog.i(TAG, \u0026#34;[onStart] callbackExist:%s %s\u0026#34;, Arrays.toString(callbackExist), Utils.getStack()); callbackExist = new boolean[CALLBACK_LAST + 1]; } queueStatus = new int[CALLBACK_LAST + 1]; queueCost = new long[CALLBACK_LAST + 1]; addFrameCallback(CALLBACK_INPUT, this, true);//main,反射添加callbackQueues的指定类型监听  } } @Override public void run() { //记录input, animation, traversal的耗时情况  final long start = System.nanoTime(); try { doFrameBegin(token);//main  doQueueBegin(CALLBACK_INPUT); addFrameCallback(CALLBACK_ANIMATION, new Runnable() { @Override public void run() { doQueueEnd(CALLBACK_INPUT); doQueueBegin(CALLBACK_ANIMATION); } }, true); addFrameCallback(CALLBACK_TRAVERSAL, new Runnable() { @Override public void run() { doQueueEnd(CALLBACK_ANIMATION); doQueueBegin(CALLBACK_TRAVERSAL); } }, true); } private void doQueueBegin(int type) { queueStatus[type] = DO_QUEUE_BEGIN; queueCost[type] = System.nanoTime(); } private void doQueueEnd(int type) { queueStatus[type] = DO_QUEUE_END; queueCost[type] = System.nanoTime() - queueCost[type]; synchronized (this) { callbackExist[type] = false; } } dispatchBegin private void dispatchBegin() { token = dispatchTimeMs[0] = SystemClock.uptimeMillis(); dispatchTimeMs[2] = SystemClock.currentThreadTimeMillis(); AppMethodBeat.i(AppMethodBeat.METHOD_ID_DISPATCH); synchronized (observers) { for (LooperObserver observer : observers) { if (!observer.isDispatchBegin()) { observer.dispatchBegin(dispatchTimeMs[0], dispatchTimeMs[2], token); } } } } dispatchEnd private void dispatchEnd() { if (isBelongFrame) { //doFrame作为一次dispatchMessage的内容，如果在dispatchEnd时isBelongFrame为true，表示这次dispatchMessage是一次doFrame绘制任务  doFrameEnd(token); } dispatchTimeMs[3] = SystemClock.currentThreadTimeMillis();//cpuEnd  dispatchTimeMs[1] = SystemClock.uptimeMillis();//end  AppMethodBeat.o(AppMethodBeat.METHOD_ID_DISPATCH); synchronized (observers) { for (LooperObserver observer : observers) { if (observer.isDispatchBegin()) { observer.dispatchEnd(dispatchTimeMs[0], dispatchTimeMs[2], dispatchTimeMs[1], dispatchTimeMs[3], token, isBelongFrame); } } } doFrameEnd private void doFrameEnd(long token) { doQueueEnd(CALLBACK_TRAVERSAL); for (int i : queueStatus) { if (i != DO_QUEUE_END) { queueCost[i] = DO_QUEUE_END_ERROR; if (config.isDevEnv) { throw new RuntimeException(String.format(\u0026#34;UIThreadMonitor happens type[%s] != DO_QUEUE_END\u0026#34;, i)); } } } queueStatus = new int[CALLBACK_LAST + 1]; long start = token; long end = SystemClock.uptimeMillis(); synchronized (observers) { for (LooperObserver observer : observers) { if (observer.isDispatchBegin()) { observer.doFrame(AppMethodBeat.getVisibleScene(), start, end, end - start, queueCost[CALLBACK_INPUT], queueCost[CALLBACK_ANIMATION], queueCost[CALLBACK_TRAVERSAL]);//main  } } } addFrameCallback(CALLBACK_INPUT, this, true);//监听下一帧,main  this.isBelongFrame = false; } private void doFrameBegin(long token) { this.isBelongFrame = true; } LooperMonitor(main looper中的dispatchMessage监听) //main looper中的dispatchMessage监听 LooperMonitor implements MessageQueue.IdleHandler { private static final HashSet\u0026lt;LooperDispatchListener\u0026gt; listeners = new HashSet\u0026lt;\u0026gt;(); public static void register(LooperDispatchListener listener) { synchronized (listeners) { listeners.add(listener); } } private static final LooperMonitor monitor = new LooperMonitor(); private LooperMonitor() { resetPrinter();//main  if (Build.VERSION.SDK_INT \u0026gt;= Build.VERSION_CODES.M) { Looper.getMainLooper().getQueue().addIdleHandler(this);//main  } else { MessageQueue queue = reflectObject(Looper.getMainLooper(), \u0026#34;mQueue\u0026#34;); queue.addIdleHandler(this); } } } resetPrinter private static void resetPrinter() { final Printer originPrinter = reflectObject(Looper.getMainLooper(), \u0026#34;mLogging\u0026#34;); if (originPrinter == printer \u0026amp;\u0026amp; null != printer) { return; } if (null != printer) { MatrixLog.w(TAG, \u0026#34;[resetPrinter] maybe looper printer was replace other!\u0026#34;); } Looper.getMainLooper().setMessageLogging(printer = new Printer() { boolean isHasChecked = false; boolean isValid = false; @Override public void println(String x) { if (null != originPrinter) { originPrinter.println(x); } if (!isHasChecked) {//Looper中queue.next获取到消息之后在//msg.target.dispatchMessage(msg);前后会调用logging打印\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;和\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;的log  isValid = x.charAt(0) == \u0026#39;\u0026gt;\u0026#39; || x.charAt(0) == \u0026#39;\u0026lt;\u0026#39;; isHasChecked = true; if (!isValid) { MatrixLog.e(TAG, \u0026#34;[println] Printer is inValid! x:%s\u0026#34;, x); } } if (isValid) { dispatch(x.charAt(0) == \u0026#39;\u0026gt;\u0026#39;); if (null != testPrinter) { testPrinter.println(x); } } } }); queueIdle @Override public boolean queueIdle() { resetPrinter(); return true; } dispatchToListeners private static void dispatch(boolean isBegin) { for (LooperDispatchListener listener : listeners) { if (listener.isValid()) { if (isBegin) { if (!listener.isHasDispatchStart) { listener.dispatchStart(); } } else { if (listener.isHasDispatchStart) { listener.dispatchEnd(); } } } else if (!isBegin \u0026amp;\u0026amp; listener.isHasDispatchStart) { listener.dispatchEnd(); } } } AppMethodBeat 字节码插桩的类，每个app方法执行开始处调用AppMethodBeat.i,结束之前调用AppMethodBeat.o\nprivate static AppMethodBeat sInstance = new AppMethodBeat(); private static HandlerThread sTimerUpdateThread = MatrixHandlerThread.getNewHandlerThread(\u0026#34;matrix_time_update_thread\u0026#34;); private static Handler sHandler = new Handler(sTimerUpdateThread.getLooper()); private static LooperMonitor.LooperDispatchListener looperMonitorListener = new LooperMonitor.LooperDispatchListener() { @Override public boolean isValid() { return status \u0026gt;= STATUS_READY; } @Override public void dispatchStart() { super.dispatchStart(); AppMethodBeat.dispatchBegin(); } @Override public void dispatchEnd() { super.dispatchEnd(); AppMethodBeat.dispatchEnd(); } }; i(methodId) /** \\* hook method when it\u0026#39;s called in. */ public static void i(int methodId) { if (status \u0026lt;= STATUS_STOPPED) { return; } if (methodId \u0026gt;= METHOD_ID_MAX) { return; } if (status == STATUS_DEFAULT) { synchronized (statusLock) { if (status == STATUS_DEFAULT) { realExecute(); status = STATUS_READY; } }} if (Thread.currentThread().getId() == sMainThread.getId()) { if (assertIn) { android.util.Log.e(TAG, \u0026#34;ERROR!!! AppMethodBeat.i Recursive calls!!!\u0026#34;); return; } assertIn = true; if (sIndex \u0026lt; Constants.BUFFER_SIZE) { mergeData(methodId, sIndex, true);//main  } else { sIndex = -1; } ++sIndex; assertIn = false; }} o(methodId) /** \\* hook method when it\u0026#39;s called out. */ public static void o(int methodId) { if (status \u0026lt;= STATUS_STOPPED) { return; } if (methodId \u0026gt;= METHOD_ID_MAX) { return; } if (Thread.currentThread().getId() == sMainThread.getId()) { if (sIndex \u0026lt; Constants.BUFFER_SIZE) { mergeData(methodId, sIndex, false);//main  } else { sIndex = -1; } ++sIndex; } } mergeData /** \\* merge trace info as a long data * \\* @param methodId \\* @param index \\* @param isIn */ private static void mergeData(int methodId, int index, boolean isIn) { if (methodId == AppMethodBeat.METHOD_ID_DISPATCH) { sCurrentDiffTime = SystemClock.uptimeMillis() - sDiffTime; } long trueId = 0L; if (isIn) { trueId |= 1L \u0026lt;\u0026lt; 63; } trueId |= (long) methodId \u0026lt;\u0026lt; 43; trueId |= sCurrentDiffTime \u0026amp; 0x7FFFFFFFFFFL;//43位1  sBuffer[index] = trueId;//main  checkPileup(index); sLastIndex = index; } private static IndexRecord sIndexRecordHead = null;//链表，每个item的index由小到大排列 private static long[] sBuffer = new long[Constants.BUFFER_SIZE]; private static int sIndex = 0;//未到阈值时只增 private static int sLastIndex = -1; sBuffer_array sBuffer数组的item含义如下:\nsIndexRecordHead链表 graph LR sIndexRecordHead--\u0026gt;|next,index递增|IndexRecord1--\u0026gt;|next,index递增|IndexRecord2--\u0026gt;|next,index递增|IndexRecord3 maskIndex //将当前调用的方法new IndexRecord(sIndex - 1)按照index升序排列插入到链表sIndexRecordHead当中 //返回new的record信息，相当于当前时刻的开始方法记录信息 public IndexRecord maskIndex(String source) {} copyData //从sBuffer中复制开始方法调用记录点到当前调用方法记录点中的堆栈信息,利用index信息 public long[] copyData(IndexRecord startRecord) { return copyData(startRecord, new IndexRecord(sIndex - 1));} public long[] copyData(IndexRecord startRecord, IndexRecord endRecord) {} IndexRecord.release public static final class IndexRecord { public IndexRecord(int index) { this.index = index; } public int index; private IndexRecord next; public boolean isValid = true; public String source; public void release() {//在sIndexRecordHead 整个链表中，删除this对应的节点record} at(插桩后 在Activity的onWindowFocusChanged中调用) /** \\* when the special method calls,it\u0026#39;s will be called. * \\* @param activity now at which activity \\* @param isFocus this window if has focus */ public static void at(Activity activity, boolean isFocus) { String activityName = activity.getClass().getName(); if (isFocus) { if (sFocusActivitySet.add(activityName)) { synchronized (listeners) { for (IAppMethodBeatListener listener : listeners) { listener.onActivityFocused(activityName);//main  } structuredDataToStack TraceDataUtils\n示意图 public static void structuredDataToStack(long[] buffer, LinkedList\u0026lt;MethodItem\u0026gt; result, boolean isStrict, long endTime) { ...... //addMethodItem构造linkedlist stask结构,在方法out时向前找到对应的in,记录一条methodItem在linkedlist头部[...id4,id7,id6,id5] addMethodItem(result, methodItem); TreeNode root = new TreeNode(null, null); stackToTree(result, root);//根据depth转成tree结构，执行完之后可以根据depth为0的节点查看其children也就是depth为1的节点的耗时情况，如果出现depth为0耗时远大于所有children节点耗时之和，说明有系统方法作为depth为1的节点且耗时比较久，统计进depth为0的时间却没有统计进app内部方法depth为1的节点  result.clear(); treeToStack(root, result);//深度优先tree转换为list } //逆序删除list中靠后的且耗时小于5ms的元素，保留最后30个 public static void trimStack(List\u0026lt;MethodItem\u0026gt; stack, int targetCount, IStructuredDataFilter filter) {} //key综合了大于总耗时0.3的methodItem得到 public static String getTreeKey(List\u0026lt;MethodItem\u0026gt; stack, long stackCost) { public static final class TreeNode { MethodItem item; TreeNode father; LinkedList\u0026lt;TreeNode\u0026gt; children = new LinkedList\u0026lt;\u0026gt;(); TreeNode(MethodItem item, TreeNode father) { this.item = item; this.father = father; } 其他 PluginListener classDiagram class PluginListener { +onInit(Plugin plugin) void +onStart(Plugin plugin) void +onStop(Plugin plugin) void +onDestroy(Plugin plugin) void +onReportIssue(Issue issue) void } PluginListener\u0026lt;|--DefaultPluginListener DefaultPluginListener\u0026lt;|--TestPluginListener //TestPluginListener @Override public void onReportIssue(Issue issue) { super.onReportIssue(issue); MatrixLog.e(TAG, issue.toString()); IssuesMap.put(IssueFilter.getCurrentFilter(), issue); jumpToIssueActivity(); } Issue private Integer type; private String tag; private String key; private JSONObject content; private Plugin plugin; IDynamicConfig enum ExptEnum { // trace  clicfg_matrix_trace_fps_enable, clicfg_matrix_trace_care_scene_set, clicfg_matrix_trace_fps_time_slice, clicfg_matrix_trace_evil_method_threshold, } String get(String key, String defStr); int get(String key, int defInt); long get(String key, long defLong); boolean get(String key, boolean defBool); float get(String key, float defFloat); TraceConfig public IDynamicConfig dynamicConfig; public boolean defaultFpsEnable; public boolean defaultMethodTraceEnable; public boolean defaultStartupEnable; public boolean defaultAnrEnable; public boolean isDebug; public boolean isDevEnv; public String splashActivities; public Set\u0026lt;String\u0026gt; splashActivitiesSet; public static class Builder { private TraceConfig config = new TraceConfig(); public Builder dynamicConfig(IDynamicConfig dynamicConfig) { config.dynamicConfig = dynamicConfig; return this; } public TraceConfig build() { return config; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/apm/matrix%E6%8E%A5%E5%85%A5%E5%90%8E%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/",
	"title": "Matrix接入后遇到的问题",
	"tags": [],
	"description": "",
	"content": "1：methodId差异 描述:\n和热修复同时使用的问题，methodId差异导致dexdiff差异多大且main dex上每次都有diff\n解决方案: 通过配置baseMethodMap给matrix，将基准包的methodMapping信息提供给在构建差分包的前期构建new apk时使用，是的new apk的方法映射和old apk一致\n2: methodid映射为具体的方法签名 debug环境下需要自动将methodid映射为具体的方法签名，增强堆栈可读性\n解决方案: 在debug环境下将methodMapping文件在packageDebug task执行前放入assets目录进而打包进apk，展示前将assets信息读取并用来解析methodId\n3：上报过滤 统计堆栈信息有时除了Handler.dispatchMessage(Message message)占据大量时间(700ms以上)但其他methodItem占用时间都很少(700多项方法调用，每项占据的时间都不大，但总时间较长)，这种场景可以理解为在一次dispatchMessage中进行了过多任务的处理，每个任务都耗时不明显大，也是需要处理的。但还是要看清时间占用是在app中的方法还是系统方法里\n比如dispatchMessage-\u0026gt;分发onCreate时间处理逻辑方法任务数量过多\n4: androidPlugin版本过低2.1.0\u0026ndash;\u0026gt;3.2.1 matrix-gradle-plugin中android plugin版本过低2.1.0\u0026ndash;\u0026gt;3.2.1\n普通java仓库先在构建过程确定依赖仓库的最新版本，但gradle plugin的构建过程在未确定依赖仓库的最新版本之前，只能使用自身配置的版本进行构建\n2.1.0的android plugin版本再构建初期限制了构建者的android plugin版本也是2.1.0，因此需要升级\n5: androidPlugin版本过低3.2.1\u0026ndash;\u0026gt;3.6.1 matrix-gradle-plugin中android plugin版本过低3.2.1\u0026ndash;\u0026gt;3.6.1\n5.1 反射transformClassesWithDexBuilderForDebug/Release新版不存在 compile \u0026#39;com.android.tools.build:gradle:3.2.1\u0026#39; 此时如果exclude，会导致在新的gradle插件版本如3.6.1上，matrix plugin完全失效但没有报错信息\nimplementation(Libs.lib_matrxi_gradle_plugin) { exclude group: \u0026#39;com.android.tools.build\u0026#39; } 原因1:\n从gradle3.2.1\u0026ndash;\u0026gt;3.6.1期间project.getTasks()发生了变化，原本\ntransformClassesWithDexBuilderFordebug和transformClassesWithDexFordebug两个任务不存在，\n实际生效log:\n[INFO][MatrixTraceTransform]successfully inject task:transformClassesWithDexBuilderForDebug [INFO][MatrixTraceTransform]successfully inject task:transformClassesWithDexBuilderForRelease\n导致matrix插件反射修改的逻辑没有机会进入\u0026quot;successfully inject task\u0026quot;:\ntry { String[] hardTask = getTransformTaskName(extension.getCustomDexTransformName(), variant.getName()); for (Task task : project.getTasks()) { for (String str : hardTask) { if (task.getName().equalsIgnoreCase(str) \u0026amp;\u0026amp; task instanceof TransformTask) { TransformTask transformTask = (TransformTask) task; Log.i(TAG, \u0026#34;successfully inject task:\u0026#34; + transformTask.getName()); Field field = TransformTask.class.getDeclaredField(\u0026#34;transform\u0026#34;); field.setAccessible(true); field.set(task, new MatrixTraceTransform(config, transformTask.getTransform())); break; } } } 5.2: 反射修改output导致 原因2:\nmatrix插件使用反射修改output，并不是标准的方式利用outputProvider进行，这从3.2.1提升到3.6.1之后已经不行，生成不了dex文件\n//反射修改了输出路径 replaceFile(directoryInput, dirOutput); replaceChangedFile(directoryInput, outChangedFiles); 原本的反射思路:\nCollection\u0026lt;TransformInput\u0026gt; inputs = transformInvocation.getInputs(); for (TransformInput input : inputs) { for (DirectoryInput directoryInput : input.getDirectoryInputs()) { ImmutableDirectoryInput @NonNull private final Map\u0026lt;File, Status\u0026gt; changedFiles; 解决方案:\n通过outputProvider提供的路径替代matrix固定的traceClass输出路径并删除原本的反射替换\nfinal File dirOutput = outputProvider.getContentLocation(directoryInput.getName(), directoryInput.getContentTypes(), directoryInput.getScopes(), Format.DIRECTORY); outputProvider.getContentLocation(inputJar.getName(), inputJar.getContentTypes() , inputJar.getScopes(), Format.JAR) 5.3 assets拷贝问题 从3.2.1-\u0026gt;3.6.1之后methodMap没有正确copy到指定目录：apk中的assets\n6: androidPlugin版本过低3.6.1\u0026ndash;\u0026gt;4.0.1 private class TraceClassAdapter extends ClassVisitor { @Override public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) { super.visit(version, access, name, signature, superName, interfaces); this.className = name; if ((access \u0026amp; Opcodes.ACC_ABSTRACT) \u0026gt; 0 || (access \u0026amp; Opcodes.ACC_INTERFACE) \u0026gt; 0) { this.isABSClass = true; } collectedClassExtendMap.put(className, superName);//这里gradle debug发现META-INF/versions/9/module-info.class时superName为null，分析得知需要修改isNeedTraceFile判断条件,UN_TRACE_CLASS新增\u0026#34;META-INF\u0026#34;  } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/apm/matrix%E7%A0%94%E7%A9%B6/",
	"title": "Matrix研究",
	"tags": [],
	"description": "",
	"content": "线上:\nhttps://github.com/Tencent/matrix/wiki/Matrix-Android-TraceCanary\nhttps://github.com/Tencent/matrix/wiki/Matrix-Android-IOCanary\n线下:\nhttps://github.com/Tencent/matrix/wiki/Matrix-Android-ResourceCanary\nhttps://github.com/Tencent/matrix/wiki/Matrix-Android-SQLiteLint\nhttps://github.com/Tencent/matrix/wiki/Matrix-Android-\n https://developer.android.com/topic/performance/vitals/launch-time\n极客时间-Android开发高手课\n07 | 启动优化（上）：从启动过程看启动速度优化\nmethodMapping.txt文件走向 transform中内存计算出methodMapping,\n写入\u0026quot;${buildDir}/outputs/mapping/${currentVariantName}/methodMapping.txt\u0026quot;，之后拷贝到getAssembleOutputBakFile里,用于tinker，构建new apk时的baseMethodMapping\ndebug时写入buildDirPath + \u0026ldquo;/intermediates/merged_assets/debug/methodMapping.txt\u0026rdquo;,用于开发模式下自动转换堆栈信息\n启动优化 https://developer.android.google.cn/topic/performance/vitals/launch-time\n我以微信为例，用户从桌面点击图标开始，会经过 4 个关键阶段。\n  T1 预览窗口显示。系统在拉起微信进程之前，会先根据微信的 Theme 属性创建预览窗口。当然如果我们禁用预览窗口或者将预览窗口指定为透明，用户在这段时间依然看到的是桌面。\n  T2 闪屏显示。在微信进程和闪屏窗口页面创建完毕，并且完成一系列 inflate view、onmeasure、onlayout 等准备工作后，用户终于可以看到熟悉的“小地球”。\n  T3 主页显示。在完成主窗口创建和页面显示的准备工作后，用户可以看到微信的主界面。\n  T4 界面可操作。在启动完成后，微信会有比较多的工作需要继续执行，例如聊天和朋友圈界面的预加载、小程序框架和进程的准备等。在这些工作完成后，用户才可以真正开始愉快地聊天。\n  问题 1：点击图标很久都不响应\n如果我们禁用了预览窗口或者指定了透明的皮肤，那用户点击了图标之后，需要 T2 时间才能真正看到应用闪屏。对于用户体验来说，点击了图标，过了几秒还是停留在桌面，看起来就像没有点击成功，这在中低端机中更加明显。\n问题 2：首页显示太慢\n现在应用启动流程越来越复杂，闪屏广告、热修复框架、插件化框架、大前端框架，所有准备工作都需要集中在启动阶段完成。上面说的 T3 首页显示时间对于中低端机来说简直就是噩梦，经常会达到十几秒的时间。\n问题 3：首页显示后无法操作。\n既然首页显示那么慢，那我能不能把尽量多的工作都通过异步化延后执行呢？很多应用的确就是这么做的，但这会造成两种后果：要么首页会出现白屏，要么首页出来后用户根本无法操作。\n启动优化方法  闪屏优化 业务梳理 业务优化 线程优化 从具体的做法来看，线程的优化一方面是控制线程数量，线程数量太多会相互竞争 CPU 资源，因此要有统一的线程池，并且根据机器性能来控制数量。 GC 优化 系统调用优化  启动进阶方法  I/O 优化 数据重排 2.1类重排 通过 ReDex 的Interdex调整类在 Dex 中的排列顺序 2.2资源文件重排 类的加载  启动性能指标 那我们一般使用什么指标来衡量启动速度的快慢呢？\n很多应用采用平均启动时间，不过这个指标其实并不太好，一些体验很差的用户很有可能是被平均了。我更建议使用类似下面的指标：\n  快开慢开比。例如 2 秒快开比、5 秒慢开比，我们可以看到有多少比例的用户体验非常好，多少比例的用户比较槽糕。\n  90% 用户的启动时间。如果 90% 的用户启动时间都小于 5 秒，那么我们 90% 区间启动耗时就是 5 秒。\n  区分启动的类型\nAlpha\nIO优化 检测场景 3.1 检测主线程 I/O 耗时的 IO 操作不能占据主线程太久。检测条件：\n 操作线程为主线程 连续读写耗时超过一定阈值或单次 write\\read 耗时超过一定阈值  3.2 读写Buffer过小，I/O次数增多 Buffer 过小，会导致 read/write 的次数增多，从而影响了性能。检测条件：\n buffer 小于一定阈值 read/write 的次数超过一定的阈值  3.3 重复读 如果频繁地读某个文件，证明这个文件的内容很常被用到，可以通过缓存来提高效率。检测条件如下：\n 同一线程读某个文件的次数超过一定阈值  3.4 Closeable Leak 监控 Closeable Leak 指的是打开资源包括文件、Cursor 等，没有及時 close，引起泄露。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/measurelayoutdraw/measure/",
	"title": "measure",
	"tags": [],
	"description": "",
	"content": "原理总结 MeasureSpec MeasureSpec是View的内部类，内部封装了View的规格尺寸，以及View的宽高信息。在Measure的流程中，系统会将View的LayoutParams根据父容器是施加的规则转换为MeasureSpec，然后在onMeasure()方法中具体确定控件的宽高信息。源码及分析如下所示：\npublic static class MeasureSpec { //int类型占4个字节，其中高2位表示尺寸测量模式，低30位表示具体的宽高信息  private static final int MODE_SHIFT = 30; private static final int MODE_MASK = 0x3 \u0026lt;\u0026lt; MODE_SHIFT; /** @hide */ @IntDef({UNSPECIFIED, EXACTLY, AT_MOST}) @Retention(RetentionPolicy.SOURCE) public @interface MeasureSpecMode {} //如下所示是MeasureSpec中的三种模式：UNSPECIFIED、EXACTLY、AT_MOST  /** * Measure specification mode: The parent has not imposed any constraint * on the child. It can be whatever size it wants. */ public static final int UNSPECIFIED = 0 \u0026lt;\u0026lt; MODE_SHIFT; /** * Measure specification mode: The parent has determined an exact size * for the child. The child is going to be given those bounds regardless * of how big it wants to be. */ public static final int EXACTLY = 1 \u0026lt;\u0026lt; MODE_SHIFT; /** * Measure specification mode: The child can be as large as it wants up * to the specified size. */ public static final int AT_MOST = 2 \u0026lt;\u0026lt; MODE_SHIFT; } UNSPECIFIED = 0 EXACTLY = 1073741824 AT_MOST = -2147483648 MATCH_PARENT = -1 WRAP_CONTENT = -2 MeasureSpec的常量中指定了两种内容，一种为尺寸模式，一种为具体的宽高信息。其中高2位表示尺寸测量模式，低30位表示具体的宽高信息。\n尺寸测量模式有如下三种：\n①UNSPECIFIED：未指定模式，父容器不限制View的大小，一般用于系统内部的测量\n②AT_MOST：最大模式，对应于在xml文件中指定控件大小为wrap_content属性，子View的最终大小是父View指定的大小值，并且子View的大小不能大于这个值\n③EXACTLY ：精确模式，对应于在xml文件中指定控件为match_parent属性或者是具体的数值，父容器测量出View所需的具体大小\n 对于每一个View，都持有一个MeasureSpec，MeasureSpec保存了该View的尺寸测量模式以及具体的宽高信息，MeasureSpec受自身的LayoutParams和父容器的MeasureSpec共同影响。\n 每个ViewGroup或View的onMeasure方法中的两个参数MeasureSpec，都保存了该view自身LayoutParams和父容器MeasureSpec共同影响之后提供的Measure mode和size信息\nMeasure过程中会传递MeasureSpec对象，包含mode和size信息，之后计算完毕后通过setMeasuredDimension设置到mMeasuredWidth和mMeasuredHeight(此时就只有具体的size信息了)，之后在layout过程中可以拿到Measure好的宽高size进行摆放\nViewRootImpl Measure private boolean measureHierarchy(final View host, final WindowManager.LayoutParams lp, final Resources res, final int desiredWindowWidth, final int desiredWindowHeight) { int childWidthMeasureSpec; int childHeightMeasureSpec; ... childWidthMeasureSpec = getRootMeasureSpec(desiredWindowWidth, lp.width); childHeightMeasureSpec = getRootMeasureSpec(desiredWindowHeight, lp.height); performMeasure(childWidthMeasureSpec, childHeightMeasureSpec); } /** \\* Figures out the measure spec for the root view in a window based on it\u0026#39;s layout params. * \\* @param windowSize The available width or height of the window \\* @param rootDimension The layout params for one dimension (width or height) of the window. \\* @return The measure spec to use to measure the root view. */ private static int getRootMeasureSpec(int windowSize, int rootDimension) { int measureSpec; switch (rootDimension) { case ViewGroup.LayoutParams.MATCH_PARENT: // Window can\u0026#39;t resize. Force root view to be windowSize.  measureSpec = MeasureSpec.makeMeasureSpec(windowSize, MeasureSpec.EXACTLY); break; case ViewGroup.LayoutParams.WRAP_CONTENT: // Window can resize. Set max size for root view.  measureSpec = MeasureSpec.makeMeasureSpec(windowSize, MeasureSpec.AT_MOST); break; default: // Window wants to be an exact size. Force root view to be that size.  measureSpec = MeasureSpec.makeMeasureSpec(rootDimension, MeasureSpec.EXACTLY); break; } return measureSpec; } ViewGroup Measure ViewGroup::getChildMeasureSpec\nView:setMeasuredDimension\nprotected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { // 1.通过遍历，对每个child进行测量  for(int i = 0 ; i \u0026lt; getChildCount() ; i++){ View child = getChildAt(i); // 2.计算新的布局要求，并对子控件进行测量  measureChild(child, widthMeasureSpec, heightMeasureSpec); } // 3.完成子控件的测量,对高度进行累加  int height = 0; for(int i = 0 ; i \u0026lt; getChildCount() ; i++){ height += child.getMeasuredHeight(); } // 4.完成LinearLayout的测量  setMeasuredDimension(width, height); } protected void measureChild(View child, int parentWidthMeasureSpec, int parentHeightMeasureSpec) { // 获取子元素的布局参数  final LayoutParams lp = child.getLayoutParams(); // 通过padding值，计算出子控件的布局要求  final int childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec, mPaddingLeft + mPaddingRight, lp.width); final int childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec, mPaddingTop + mPaddingBottom, lp.height); // 将新的布局要求传入measure方法，完成子控件的测量  child.measure(childWidthMeasureSpec, childHeightMeasureSpec); } /** \\* Does the hard part of measureChildren: figuring out the MeasureSpec to \\* pass to a particular child. This method figures out the right MeasureSpec \\* for one dimension (height or width) of one child view. * \\* The goal is to combine information from our MeasureSpec with the \\* LayoutParams of the child to get the best possible results. For example, \\* if the this view knows its size (because its MeasureSpec has a mode of \\* EXACTLY), and the child has indicated in its LayoutParams that it wants \\* to be the same size as the parent, the parent should ask the child to \\* layout given an exact size. * \\* @param spec The requirements for this view \\* @param padding The padding of this view for the current dimension and \\* margins, if applicable \\* @param childDimension How big the child wants to be in the current \\* dimension \\* @return a MeasureSpec integer for the child */ public static int getChildMeasureSpec(int spec, int padding, int childDimension) { //获取父View的测量模式  int specMode = MeasureSpec.getMode(spec); //获取父View的测量大小  int specSize = MeasureSpec.getSize(spec); //父View计算出的子View的大小，子View不一定用这个值  int size = Math.max(0, specSize - padding); //声明变量用来保存实际计算的到的子View的size和mode即大小和模式  int resultSize = 0; int resultMode = 0; switch (specMode) { // Parent has imposed an exact size on us  //如果父容器的模式是Exactly即确定的大小  case MeasureSpec.EXACTLY: //子View的高度或宽度\u0026gt;0说明其实一个确切的值，因为match_parent和wrap_content的值是\u0026lt;0的  if (childDimension \u0026gt;= 0) { resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; //子View的高度或宽度为match_parent  } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size. So be it.  resultSize = size;//将size即父View的大小减去边距值所得到的值赋值给resultSize  resultMode = MeasureSpec.EXACTLY;//指定子View的测量模式为EXACTLY  //子View的高度或宽度为wrap_content  } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can\u0026#39;t be bigger than us.  resultSize = size;//将size赋值给result  resultMode = MeasureSpec.AT_MOST;//指定子View的测量模式为AT_MOST  } break; // Parent has imposed a maximum size on us  //如果父容器的测量模式是AT_MOST  case MeasureSpec.AT_MOST: if (childDimension \u0026gt;= 0) { // Child wants a specific size... so be it  resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size, but our size is not fixed.  // Constrain child to not be bigger than us.  resultSize = size; // 因为父View的大小是受到限制值的限制,所以子View的大小也应该受到父容器的限制并且不能超过父View  resultMode = MeasureSpec.AT_MOST; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can\u0026#39;t be bigger than us.  resultSize = size; resultMode = MeasureSpec.AT_MOST; } break; // Parent asked to see how big we want to be  //如果父容器的测量模式是UNSPECIFIED即父容器的大小未受限制  case MeasureSpec.UNSPECIFIED: //如果自View的宽和高是一个精确的值  if (childDimension \u0026gt;= 0) { // Child wants a specific size... let him have it  //子View的大小为精确值  resultSize = childDimension; //测量的模式为EXACTLY  resultMode = MeasureSpec.EXACTLY; //子View的宽或高为match_parent  } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size... find out how big it should be  //因为父View的大小是未定的，所以子View的大小也是未定的  resultSize = 0; resultMode = MeasureSpec.UNSPECIFIED; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size.... find out how big it should be  resultSize = 0; resultMode = MeasureSpec.UNSPECIFIED; } break; } //根据resultSize和resultMode调用makeMeasureSpec方法得到测量要求，并将其作为返回值  return MeasureSpec.makeMeasureSpec(resultSize, resultMode); } View Measure public final void measure(int widthMeasureSpec, int heightMeasureSpec) { // ... 公共逻辑  // 开发者需要自己重写onMeasure函数，以自定义测量逻辑  onMeasure(widthMeasureSpec, heightMeasureSpec); } protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { // 普遍意义上，setMeasuredDimension()标志着测量结束  setMeasuredDimension(getDefaultSize(getSuggestedMinimumWidth(), widthMeasureSpec), getDefaultSize(getSuggestedMinimumHeight(), heightMeasureSpec)); } protected int getSuggestedMinimumWidth() { return (mBackground == null) ? mMinWidth : max(mMinWidth, mBackground.getMinimumWidth()); } public static int getDefaultSize(int size, int measureSpec) { // 宽度的默认值  int result = size; int specMode = MeasureSpec.getMode(measureSpec); int specSize = MeasureSpec.getSize(measureSpec); // 根据不同的测量模式，返回的测量结果不同  switch (specMode) { // 任意模式，宽度为默认值  case MeasureSpec.UNSPECIFIED: result = size; break; // match_parent、wrap_content则返回布局要求中的size值  case MeasureSpec.AT_MOST: case MeasureSpec.EXACTLY: result = specSize; break; } return result; } protected final void setMeasuredDimension(int measuredWidth, int measuredHeight) { // measuredWidth 测量结果，View的宽度  // measuredHeight 测量结果，View的高度  // 省略其它代码...  // 该方法的本质就是将测量结果存起来，以便后续的layout和draw流程中获取控件的宽高  mMeasuredWidth = measuredWidth; mMeasuredHeight = measuredHeight; } 参考 看 Google 是如何设计的 View 机制？\n自定义View心法—View工作流程\nAndroid 一个困惑很久的问题：onMeasure() 为什么会执行多次？\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/measurelayoutdraw/",
	"title": "measurelayoutdraw",
	"tags": [],
	"description": "",
	"content": "measurelayoutdraw 探索总结measurelayoutdraw知识\n measure     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/messageloop/",
	"title": "MessageLoop",
	"tags": [],
	"description": "",
	"content": "TaskRunners::TaskRunners(std::string label, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; platform, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; gpu, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; ui, fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; io) : label_(std::move(label)), platform_(std::move(platform)), gpu_(std::move(gpu)), ui_(std::move(ui)), io_(std::move(io)) {} ThreadHost::ThreadHost /// The collection of all the threads used by the engine. ThreadHost enum Type { Platform = 1 \u0026lt;\u0026lt; 0, UI = 1 \u0026lt;\u0026lt; 1, GPU = 1 \u0026lt;\u0026lt; 2, IO = 1 \u0026lt;\u0026lt; 3, }; std::unique_ptr\u0026lt;fml::Thread\u0026gt; platform_thread; std::unique_ptr\u0026lt;fml::Thread\u0026gt; ui_thread; std::unique_ptr\u0026lt;fml::Thread\u0026gt; gpu_thread; std::unique_ptr\u0026lt;fml::Thread\u0026gt; io_thread; ThreadHost(std::string name_prefix, uint64_t type_mask); ThreadHost::ThreadHost(std::string name_prefix, uint64_t mask) { if (mask \u0026amp; ThreadHost::Type::Platform) { platform_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.platform\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::UI) { ui_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.ui\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::GPU) { gpu_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.gpu\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::IO) { io_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.io\u0026#34;); } } Thread::Thread Thread std::unique_ptr\u0026lt;std::thread\u0026gt; thread_; fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; task_runner_; Thread::Thread(const std::string\u0026amp; name) : joined_(false) { fml::AutoResetWaitableEvent latch; fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; runner; thread_ = std::make_unique\u0026lt;std::thread\u0026gt;([\u0026amp;latch, \u0026amp;runner, name]() -\u0026gt; void { SetCurrentThreadName(name); fml::MessageLoop::EnsureInitializedForCurrentThread(); auto\u0026amp; loop = MessageLoop::GetCurrent(); runner = loop.GetTaskRunner(); latch.Signal(); loop.Run(); }); latch.Wait(); task_runner_ = runner; } tls_message_loop.reset(new MessageLoop()); MessageLoop fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop_; fml::RefPtr\u0026lt;fml::TaskRunner\u0026gt; task_runner_; FML_THREAD_LOCAL ThreadLocalUniquePtr\u0026lt;MessageLoop\u0026gt; tls_message_loop; void MessageLoop::EnsureInitializedForCurrentThread() { if (tls_message_loop.get() != nullptr) { // Already initialized.  return; } tls_message_loop.reset(new MessageLoop()); } MessageLoop::MessageLoop() : loop_(MessageLoopImpl::Create()), task_runner_(fml::MakeRefCounted\u0026lt;fml::TaskRunner\u0026gt;(loop_)) { } MessageLoop\u0026amp; MessageLoop::GetCurrent() { auto* loop = tls_message_loop.get(); return *loop; } void MessageLoop::Run() { loop_-\u0026gt;DoRun(); } TaskRunner::TaskRunner //TaskRunner  fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop_; TaskRunner::TaskRunner(fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop) : loop_(std::move(loop)) {} MessageLoopImpl::Create MessageLoopImpl // Exposed for the embedder shell which allows clients to poll for events  // instead of dedicating a thread to the message loop.  friend class MessageLoop; fml::RefPtr\u0026lt;MessageLoopTaskQueues\u0026gt; task_queue_; TaskQueueId queue_id_; fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; MessageLoopImpl::Create() { #if OS_MACOSX  return fml::MakeRefCounted\u0026lt;MessageLoopDarwin\u0026gt;(); #elif OS_ANDROID  return fml::MakeRefCounted\u0026lt;MessageLoopAndroid\u0026gt;(); #elif OS_FUCHSIA  return fml::MakeRefCounted\u0026lt;MessageLoopFuchsia\u0026gt;(); #elif OS_LINUX  return fml::MakeRefCounted\u0026lt;MessageLoopLinux\u0026gt;(); #elif OS_WIN  return fml::MakeRefCounted\u0026lt;MessageLoopWin\u0026gt;(); #else  return nullptr; #endif } void MessageLoopImpl::DoRun() { if (terminated_) { // Message loops may be run only once.  return; } // Allow the implementation to do its thing.  Run();//main  // The loop may have been implicitly terminated. This can happen if the  // implementation supports termination via platform specific APIs or just  // error conditions. Set the terminated flag manually.  terminated_ = true; // The message loop is shutting down. Check if there are expired tasks. This  // is the last chance for expired tasks to be serviced. Make sure the  // terminated flag is already set so we don\u0026#39;t accrue additional tasks now.  RunExpiredTasksNow(); // When the message loop is in the process of shutting down, pending tasks  // should be destructed on the message loop\u0026#39;s thread. We have just returned  // from the implementations |Run| method which we know is on the correct  // thread. Drop all pending tasks on the floor.  task_queue_-\u0026gt;DisposeTasks(queue_id_); } MessageLoopAndroid::Run MessageLoopAndroid fml::UniqueObject\u0026lt;ALooper*, UniqueLooperTraits\u0026gt; looper_; fml::UniqueFD timer_fd_; MessageLoopAndroid::MessageLoopAndroid() : looper_(AcquireLooperForThread()), timer_fd_(::timerfd_create(kClockType, TFD_NONBLOCK | TFD_CLOEXEC)), running_(false) { static const int kWakeEvents = ALOOPER_EVENT_INPUT; ALooper_callbackFunc read_event_fd = [](int, int events, void* data) -\u0026gt; int {//在epoll_wait被唤醒之后会回调本callback  if (events \u0026amp; kWakeEvents) { reinterpret_cast\u0026lt;MessageLoopAndroid*\u0026gt;(data)-\u0026gt;OnEventFired(); } return 1; // continue receiving callbacks  }; int add_result = ::ALooper_addFd(looper_.get(), // looper  timer_fd_.get(), // fd  ALOOPER_POLL_CALLBACK, // ident  kWakeEvents, // events  read_event_fd, // callback  this // baton  ); /*此处是通过android中的ndk工具实现loop消息机制，对于1.ui, 1.gpu, 1.io线程会创建native的loop，对于main线程会复用Android原生的native loop。 ALooper_forThread：获取当前线程的loop，对应Looper::getForThread()，通过该线程key向TLS来查询是否存在已创建的c++层的loop ALooper_prepare：创建新的loop，对应Looper::prepare()，在TLS中记录着该线程为key，loop为value的数据。 ALooper_acquire: 获取loop的引用，对应looper-\u0026gt;incStrong()，也就是将引用计数加1；*/ static ALooper* AcquireLooperForThread() { ALooper* looper = ALooper_forThread(); if (looper == nullptr) { // No looper has been configured for the current thread. Create one and  // return the same.  looper = ALooper_prepare(0); } // The thread already has a looper. Acquire a reference to the same and return  // it.  ALooper_acquire(looper); return looper; } //frameworks/base/native/android/looper.cpp struct ALooper;//存在的价值是不希望调用者直接调用Looper的方法，只能调用Alooper开头的指定方法,提供封装性 /** * ALooper * * A looper is the state tracking an event loop for a thread. * Loopers do not define event structures or other such things; rather * they are a lower-level facility to attach one or more discrete objects * listening for an event. An \u0026#34;event\u0026#34; here is simply data available on * a file descriptor: each attached object has an associated file descriptor, * and waiting for \u0026#34;events\u0026#34; means (internally) polling on all of these file * descriptors until one or more of them have data available. * * A thread can have only one ALooper associated with it. */ typedef struct ALooper ALooper; 32static inline ALooper* Looper_to_ALooper(Looper* looper) { 33 return reinterpret_cast\u0026lt;ALooper*\u0026gt;(looper); 34} ALooper* ALooper_forThread() { return Looper_to_ALooper(Looper::getForThread().get()); } ALooper* ALooper_prepare(int opts) { return Looper_to_ALooper(Looper::prepare(opts).get()); } void ALooper_acquire(ALooper* looper) { ALooper_to_Looper(looper)-\u0026gt;incStrong((void*)ALooper_acquire); } void ALooper_release(ALooper* looper) { ALooper_to_Looper(looper)-\u0026gt;decStrong((void*)ALooper_acquire); } 78int ALooper_addFd(ALooper* looper, int fd, int ident, int events, 79 ALooper_callbackFunc callback, void* data) { 80 return ALooper_to_Looper(looper)-\u0026gt;addFd(fd, ident, events, callback, data); 81} 82 83int ALooper_removeFd(ALooper* looper, int fd) { 84 return ALooper_to_Looper(looper)-\u0026gt;removeFd(fd); 85} void MessageLoopAndroid::Run() { FML_DCHECK(looper_.get() == ALooper_forThread()); running_ = true; while (running_) { int result = ::ALooper_pollOnce(-1, // infinite timeout  nullptr, // out fd,  nullptr, // out events,  nullptr // out data  ); if (result == ALOOPER_POLL_TIMEOUT || result == ALOOPER_POLL_ERROR) { // This handles the case where the loop is terminated using ALooper APIs.  running_ = false; } } } 52int ALooper_pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) { 53 sp\u0026lt;Looper\u0026gt; looper = Looper::getForThread(); 54 if (looper == NULL) { 55 ALOGE(\u0026#34;ALooper_pollOnce: No looper for this thread!\u0026#34;); 56 return ALOOPER_POLL_ERROR; 57 } 58 59 IPCThreadState::self()-\u0026gt;flushCommands(); 60 return looper-\u0026gt;pollOnce(timeoutMillis, outFd, outEvents, outData); 61} TaskRunner::PostTask void TaskRunner::PostTask(const fml::closure\u0026amp; task) { loop_-\u0026gt;PostTask(task, fml::TimePoint::Now()); } void TaskRunner::PostTaskForTime(const fml::closure\u0026amp; task, fml::TimePoint target_time) { loop_-\u0026gt;PostTask(task, target_time); } void TaskRunner::PostDelayedTask(const fml::closure\u0026amp; task, fml::TimeDelta delay) { loop_-\u0026gt;PostTask(task, fml::TimePoint::Now() + delay); } MessageLoopImpl::PostTask void MessageLoopImpl::PostTask(const fml::closure\u0026amp; task, fml::TimePoint target_time) { task_queue_-\u0026gt;RegisterTask(queue_id_, task, target_time); } MessageLoopTaskQueues::RegisterTask //MessageLoopTaskQueues void MessageLoopTaskQueues::RegisterTask(TaskQueueId queue_id, const fml::closure\u0026amp; task, fml::TimePoint target_time) { std::scoped_lock queue_lock(GetMutex(queue_id)); size_t order = order_++; const auto\u0026amp; queue_entry = queue_entries_[queue_id]; queue_entry-\u0026gt;delayed_tasks.push({order, task, target_time}); TaskQueueId loop_to_wake = queue_id; if (queue_entry-\u0026gt;subsumed_by != _kUnmerged) { loop_to_wake = queue_entry-\u0026gt;subsumed_by; } WakeUpUnlocked(loop_to_wake, queue_entry-\u0026gt;delayed_tasks.top().GetTargetTime()); } void MessageLoopTaskQueues::WakeUpUnlocked(TaskQueueId queue_id, fml::TimePoint time) const { if (queue_entries_.at(queue_id)-\u0026gt;wakeable) { queue_entries_.at(queue_id)-\u0026gt;wakeable-\u0026gt;WakeUp(time); } } void MessageLoopAndroid::WakeUp(fml::TimePoint time_point) { bool result = TimerRearm(timer_fd_.get(), time_point); FML_DCHECK(result); } //TimerRearm bool TimerRearm(int fd, fml::TimePoint time_point) { uint64_t nano_secs = time_point.ToEpochDelta().ToNanoseconds(); // \u0026#34;0\u0026#34; will disarm the timer, desired behavior is to immediately  // trigger the timer.  if (nano_secs \u0026lt; 1) { nano_secs = 1; } struct itimerspec spec = {}; spec.it_value.tv_sec = (time_t)(nano_secs / NSEC_PER_SEC); spec.it_value.tv_nsec = nano_secs % NSEC_PER_SEC; spec.it_interval = spec.it_value; // single expiry.  int result = ::timerfd_settime(fd, TFD_TIMER_ABSTIME, \u0026amp;spec, nullptr); return result == 0; } int timerfd_settime(int ufc, int flags, const struct itimerspec* utmr, struct itimerspec* otmr) { return syscall(__NR_timerfd_settime, ufc, flags, utmr, otmr);//通过系统调用__NR_timerfd_settime来设置定时唤醒。 } looper唤醒之后的回调处理 void MessageLoopAndroid::OnEventFired() { if (TimerDrain(timer_fd_.get())) { RunExpiredTasksNow(); }} void MessageLoopImpl::RunExpiredTasksNow() { FlushTasks(FlushType::kAll); } void MessageLoopImpl::FlushTasks(FlushType type) { TRACE_EVENT0(\u0026#34;fml\u0026#34;, \u0026#34;MessageLoop::FlushTasks\u0026#34;); std::vector\u0026lt;fml::closure\u0026gt; invocations; //遍历整个延迟任务队列，将时间已到期的任务加入invocations  task_queue_-\u0026gt;GetTasksToRunNow(queue_id_, type, invocations); for (const auto\u0026amp; invocation : invocations) { invocation();//执行postTask时设置的回调闭包,main  std::vector\u0026lt;fml::closure\u0026gt; observers = task_queue_-\u0026gt;GetObserversToNotify(queue_id_); for (const auto\u0026amp; observer : observers) {//queue的observers被逐个调用  observer(); } } } 其他 ThreadHost初始化\n[-\u0026gt; flutter/shell/common/thread_host.cc] ThreadHost::ThreadHost(std::string name_prefix, uint64_t mask) { if (mask \u0026amp; ThreadHost::Type::Platform) { platform_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.platform\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::UI) { //创建线程 [见小节2.2]  ui_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.ui\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::GPU) { gpu_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.gpu\u0026#34;); } if (mask \u0026amp; ThreadHost::Type::IO) { io_thread = std::make_unique\u0026lt;fml::Thread\u0026gt;(name_prefix + \u0026#34;.io\u0026#34;); } } TaskRunner初始化\n[-\u0026gt; flutter/fml/task_runner.cc] TaskRunner::TaskRunner(fml::RefPtr\u0026lt;MessageLoopImpl\u0026gt; loop) : loop_(std::move(loop)) {} Flutter引擎启动过程，会创建UI/GPU/IO这3个线程，并且会为每个线程依次创建MessageLoop对象，启动后处于epoll_wait等待状态。对于Flutter的消息机制跟Android原生的消息机制有很多相似之处，都有消息(或者任务)、消息队列以及Looper，有一点不同的是Android有一个Handler类，用于发送消息以及执行回调方法，相对应Flutter中有着相近功能的便是TaskRunner。\n上图是从源码中提炼而来的任务处理流程，比官方流程图更容易理解一些复杂流程的时序问题，后续会专门讲解个中原由。Flutter的任务队列处理机制跟Android的消息队列处理相通，只不过Flutter分为Task和MicroTask两种类型，引擎和Dart虚拟机的事件以及Future都属于Task，Dart层执行scheduleMicrotask()所产生的属于Microtask。\n每次Flutter引擎在消费任务时调用FlushTasks()方法，遍历整个延迟任务队列delayed_tasks_，将已到期的任务加入task队列，然后开始处理任务。\n Step 1: 检查task，当task队列不为空，先执行一个task； Step 2: 检查microTask，当microTask不为空，则执行microTask；不断循环Step 2 直到microTask队列为空，再回到执行Step 1；  可简单理解为先处理完所有的Microtask，然后再处理Task。因为scheduleMicrotask()方法的调用自身就处于一个Task，执行完当前的task，也就意味着马上执行该Microtask。\n了解了其工作机制，再来看看这4个Task Runner的具体工作内容。\n Platform Task Runner：运行在Android或者iOS的主线程，尽管阻塞该线程并不会影响Flutter渲染管道，平台线程建议不要执行耗时操作；否则可能触发watchdog来结束该应用。比如Android、iOS都是使用平台线程来传递用户输入事件，一旦平台线程被阻塞则会引起手势事件丢失。 UI Task Runner: 运行在ui线程，比如1.ui，用于引擎执行root isolate中的所有Dart代码，执行渲染与处理Vsync信号，将widget转换生成Layer Tree。除了渲染之外，还有处理Native Plugins消息、Timers、Microtasks等工作； GPU Task Runner：运行在gpu线程，比如1.gpu，用于将Layer Tree转换为具体GPU指令，执行设备GPU相关的skia调用，转换相应平台的绘制方式，比如OpenGL, vulkan, metal等。每一帧的绘制需要UI Runner和GPU Runner配合完成，任何一个环节延迟都可能导致掉帧； IO Task Runner：运行在io线程，比如1.io，前3个Task Runner都不允许执行耗时操作，该Runner用于将图片从磁盘读取出来，解压转换为GPU可识别的格式后，再上传给GPU线程。为了能访问GPU，IO Runner跟GPU Runner的Context在同一个ShareGroup。比如ui.image通过异步调用让IO Runner来异步加载图片，该线程不能执行其他耗时操作，否则可能会影响图片加载的性能。  深入理解Flutter消息机制\n深入理解Flutter异步Future机制\n深入理解Flutter的Isolate创建过程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/methodchannel/",
	"title": "MethodChannel",
	"tags": [],
	"description": "",
	"content": "整体设计 graph LR subgraph DartVM Dart(DartFramework)--\u0026gt;|await|Engine(EngineC++) end subgraph Platform Engine--\u0026gt;|GetPlatformTaskRunner-\u0026gt;PostTask|PlatformC++--\u0026gt;PlatformJava PlatformJava--\u0026gt;PlatformC++ PlatformC++--\u0026gt;|ui_task_runner_-\u0026gt;PostTask|Engine--\u0026gt;Dart end 传递数据编解码设计 数据反向也是类似的编解码\ngraph LR subgraph Dart MethodCallDart(\u0026quot;MethodCall:StringMethodName,ObjectArguments\u0026quot;)--\u0026gt;|encode|ByteBufferDart(\u0026quot;ByteDataDart\u0026quot;) end ByteBufferDart--\u0026gt;Transport--\u0026gt;|decode|MethodCallNative subgraph native MethodCallNative end EngineUi线程接收消息模块设计 graph TB subgraph DartUiThreadNative ALooper_pollOnce--\u0026gt;MessageLoopAndroid::OnEventFired --\u0026gt;Engine::DispatchPlatformMessage--\u0026gt;RuntimeController::DispatchPlatformMessage --\u0026gt;PlatformConfiguration::DispatchPlatformMessage--\u0026gt;tonic::DartInvoke end subgraph DartUiThreadDart tonic::DartInvoke--\u0026gt;binding.dart--\u0026gt;platform_channel.dart--\u0026gt;callHandler end 类结构设计 MethodChannel classDiagram class MethodChannel { String name MethodCodec codec BinaryMessenger binaryMessenger } class MethodCodec { encodeMethodCall(MethodCall methodCall)ByteData decodeMethodCall(ByteData? methodCall)MethodCall decodeEnvelope(ByteData envelope)dynamic encodeSuccessEnvelope(dynamic result)ByteData encodeErrorEnvelope(String code, String? message, dynamic details)ByteData } class BinaryMessenger{ handlePlatformMessage(String channel, ByteData? data, ui.PlatformMessageResponseCallback? callback)Future~void~ send(String channel, ByteData? message)Future~ByteData~ setMessageHandler(String channel, MessageHandler? handler)void } MethodCodec\u0026lt;|--StandardMethodCodec MethodCodec\u0026lt;|--JSONMethodCodec BinaryMessenger\u0026lt;|--_DefaultBinaryMessenger MessageChannel classDiagram class BasicMessageChannel~T~{ String name MessageCodec\u0026lt;T\u0026gt; codec BinaryMessenger binaryMessenger } class MessageCodec~T~ { encodeMessage(T message)ByteData decodeMessage(ByteData? message) T } MethodChannel和MessageChannel的区别: codec结构不同，Message不涉及MethodCall结构，并且request参数和response都是类型T。\n注册监听MethodChannel().setMethodCallHandler((call, result) -\u0026gt; {}) class MainActivity() : FlutterActivity() { private val CHANNEL = \u0026#34;samples.flutter.dev/battery\u0026#34; override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) GeneratedPluginRegistrant.registerWith(this) MethodChannel(flutterView, CHANNEL).setMethodCallHandler { call, result -\u0026gt; // Note: this method is invoked on the main thread.  if (call.method == \u0026#34;getBatteryLevel\u0026#34;) { val batteryLevel = getBatteryLevel()//android平台api调用获取  if (batteryLevel != -1) { result.success(batteryLevel) } else { result.error(\u0026#34;UNAVAILABLE\u0026#34;, \u0026#34;Battery level not available.\u0026#34;, null) } } else { result.notImplemented() } } MethodChannel.java\nWrap handler with IncomingMethodCallHandler private final BinaryMessenger messenger; public MethodChannel(BinaryMessenger messenger, String name) { this(messenger, name, StandardMethodCodec.INSTANCE); } public MethodChannel(BinaryMessenger messenger, String name, MethodCodec codec) { this.messenger = messenger; this.name = name; this.codec = codec; } @UiThread public void setMethodCallHandler(@Nullable MethodChannel.MethodCallHandler handler) { this.messenger.setMessageHandler(this.name, handler == null ? null : new MethodChannel.IncomingMethodCallHandler(handler)); } interface BinaryMessenger @UiThread void setMessageHandler(@NonNull String var1, @Nullable BinaryMessenger.BinaryMessageHandler var2); FlutterView extends SurfaceView implements BinaryMessenger, TextureRegistry { @UiThread public void setMessageHandler(String channel, BinaryMessageHandler handler) { this.mNativeView.setMessageHandler(channel, handler); } } FlutterNativeView implements BinaryMessenger @UiThread public void setMessageHandler(String channel, BinaryMessageHandler handler) { this.dartExecutor.setMessageHandler(channel, handler); } DartExecutor implements BinaryMessenger @NonNull private final DartMessenger messenger; @UiThread public void setMessageHandler(@NonNull String channel, @Nullable BinaryMessageHandler handler) { this.messenger.setMessageHandler(channel, handler); } DartMessenger.setMessageHandler DartMessenger //platform注册监听 public void setMessageHandler(@NonNull String channel, @Nullable BinaryMessageHandler handler) { if (handler == null) { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Removing handler for channel \u0026#39;\u0026#34; + channel + \u0026#34;\u0026#39;\u0026#34;); this.messageHandlers.remove(channel); } else { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Setting handler for channel \u0026#39;\u0026#34; + channel + \u0026#34;\u0026#39;\u0026#34;); this.messageHandlers.put(channel, handler); } } IncomingMethodCallHandler.onMessage private final class IncomingMethodCallHandler implements BinaryMessageHandler { private final MethodChannel.MethodCallHandler handler; IncomingMethodCallHandler(MethodChannel.MethodCallHandler handler) { this.handler = handler; } @UiThread public void onMessage(ByteBuffer message, final BinaryReply reply) { MethodCall call = MethodChannel.this.codec.decodeMethodCall(message);//ByteBuffer to Object  try { this.handler.onMethodCall(call, new MethodChannel.Result() { public void success(Object result) { reply.reply(MethodChannel.this.codec.encodeSuccessEnvelope(result));//object to ByteBuffer  } public void error(String errorCode, String errorMessage, Object errorDetails) { reply.reply(MethodChannel.this.codec.encodeErrorEnvelope(errorCode, errorMessage, errorDetails)); } public void notImplemented() { reply.reply((ByteBuffer)null); } }); } catch (RuntimeException var5) { Log.e(\u0026#34;MethodChannel#\u0026#34; + MethodChannel.this.name, \u0026#34;Failed to handle method call\u0026#34;, var5); reply.reply(MethodChannel.this.codec.encodeErrorEnvelope(\u0026#34;error\u0026#34;, var5.getMessage(), (Object)null)); } 发起调用methodChannel.invokeMethod static const platform = const MethodChannel(\u0026#39;samples.flutter.dev/battery\u0026#39;); try { final int result = await platform.invokeMethod(\u0026#39;getBatteryLevel\u0026#39;); batteryLevel = \u0026#39;Battery level at $result% .\u0026#39;; } on PlatformException catch (e) { batteryLevel = \u0026#34;Failed to get battery level: \u0026#39;${e.message}\u0026#39;.\u0026#34;; } const MethodChannel(this.name, [this.codec = const StandardMethodCodec(), this.binaryMessenger = defaultBinaryMessenger ]) /// The logical channel on which communication happens, not null.  final String name; /// The message codec used by this channel, not null.  final MethodCodec codec; /// The messenger used by this channel to send platform messages.  ///  /// The messenger may not be null.  final BinaryMessenger binaryMessenger; /// The default instance of [BinaryMessenger].  ///  /// This is used to send messages from the application to the platform, and  /// keeps track of which handlers have been registered on each channel so  /// it may dispatch incoming messages to the registered handler.  const BinaryMessenger defaultBinaryMessenger = _DefaultBinaryMessenger._(); @optionalTypeArgs Future\u0026lt;T\u0026gt; invokeMethod\u0026lt;T\u0026gt;(String method, [ dynamic arguments ]) async { final ByteData result = await binaryMessenger.send( name, codec.encodeMethodCall(MethodCall(method, arguments)), ); final T typedResult = codec.decodeEnvelope(result); return typedResult; codec.encodeMethodCall ByteData result = await binaryMessenger.send /// A messenger which sends binary data across the Flutter platform barrier.  ///  /// This class also registers handlers for incoming messages.*  BinaryMessenger /// Send a binary message to the platform plugins on the given channel.  /// Returns a [Future] which completes to the received response, undecoded,  /// in binary form.  Future\u0026lt;ByteData\u0026gt; send(String channel, ByteData message); _DefaultBinaryMessenger /// A function which takes a platform message and asynchronously returns an encoded response. typedef MessageHandler = Future\u0026lt;ByteData\u0026gt; Function(ByteData message); // Mock handlers that intercept and respond to outgoing messages.  // This is static so that this class can have a const constructor. static final Map\u0026lt;String, MessageHandler\u0026gt; _mockHandlers = \u0026lt;String, MessageHandler\u0026gt;{}; @override Future\u0026lt;ByteData\u0026gt; send(String channel, ByteData message) { final MessageHandler handler = _mockHandlers[channel]; if (handler != null) return handler(message); return _sendPlatformMessage(channel, message); } Future\u0026lt;ByteData\u0026gt; _sendPlatformMessage(String channel, ByteData message) { final Completer\u0026lt;ByteData\u0026gt; completer = Completer\u0026lt;ByteData\u0026gt;(); ui.window.sendPlatformMessage(channel, message, (ByteData reply) { try { completer.complete(reply); } return completer.future; ui.window.SendPlatformMessage Window /// Sends a message to a platform-specific plugin.  ///  /// The `name` parameter determines which plugin receives the message. The  /// `data` parameter contains the message payload and is typically UTF-8  /// encoded JSON but can be arbitrary data. If the plugin replies to the  /// message, `callback` will be called with the response.  void sendPlatformMessage(String name, ByteData data, PlatformMessageResponseCallback callback) { final String error = _sendPlatformMessage(name, _zonedPlatformMessageResponseCallback(callback), data); if (error != null) throw Exception(error); String _sendPlatformMessage(String name, PlatformMessageResponseCallback callback, ByteData data) native \u0026#39;Window_sendPlatformMessage\u0026#39;; Window.cc\nvoid Window::RegisterNatives(tonic::DartLibraryNatives* natives) { natives-\u0026gt;Register({ {\u0026#34;Window_sendPlatformMessage\u0026#34;, _SendPlatformMessage, 4, true}, void _SendPlatformMessage(Dart_NativeArguments args) { tonic::DartCallStatic(\u0026amp;SendPlatformMessage, args); } Dart_Handle SendPlatformMessage(Dart_Handle window, const std::string\u0026amp; name, Dart_Handle callback, Dart_Handle data_handle) { dart_state-\u0026gt;window()-\u0026gt;client()-\u0026gt;HandlePlatformMessage return Dart_Null(); Engine\nvoid Engine::HandlePlatformMessage(fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { if (message-\u0026gt;channel() == kAssetChannel) { HandleAssetPlatformMessage(std::move(message)); } else { delegate_.OnEngineHandlePlatformMessage(std::move(message)); } } class Delegate { //--------------------------------------------------------------------------  /// @brief When the Flutter application has a message to send to the  /// underlying platform, the message needs to be forwarded to  /// the platform on the the appropriate thread (via the platform  /// task runner). The engine delegates this task to the shell  /// via this method.  ///  /// @see `PlatformView::HandlePlatformMessage`  ///  /// @param[in] message The message from the Flutter application to send to  /// the underlying platform.  ///  virtual void OnEngineHandlePlatformMessage( fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) = 0; Shell\nconst TaskRunners task_runners_; const TaskRunners\u0026amp; Shell::GetTaskRunners() const {return task_runners_;} Shell::Shell(DartVMRef vm, TaskRunners task_runners, Settings settings) : task_runners_(std::move(task_runners)), Shell::OnEngineHandlePlatformMessage // |Engine::Delegate| void Shell::OnEngineHandlePlatformMessage( fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { FML_DCHECK(is_setup_); FML_DCHECK(task_runners_.GetUITaskRunner()-\u0026gt;RunsTasksOnCurrentThread()); if (message-\u0026gt;channel() == kSkiaChannel) { HandleEngineSkiaMessage(std::move(message)); return; } task_runners_.GetPlatformTaskRunner()-\u0026gt;PostTask( [view = platform_view_-\u0026gt;GetWeakPtr(), message = std::move(message)]() { if (view) { view-\u0026gt;HandlePlatformMessage(std::move(message)); } }); } void PlatformView::HandlePlatformMessage(fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { if (auto response = message-\u0026gt;response()) response-\u0026gt;CompleteEmpty(); } PlatformViewAndroid::HandlePlatformMessage // |PlatformView| void PlatformViewAndroid::HandlePlatformMessage( FlutterViewHandlePlatformMessage(env, view.obj(), java_channel.obj(), message_array.obj(), response_id); shell\\platform\\android\\platform_view_android_jni.cc\nbool PlatformViewAndroid::Register(JNIEnv* env) { g_flutter_jni_class = new fml::jni::ScopedJavaGlobalRef\u0026lt;jclass\u0026gt;( env, env-\u0026gt;FindClass(\u0026#34;io/flutter/embedding/engine/FlutterJNI\u0026#34;)); if (g_flutter_jni_class-\u0026gt;is_null()) { FML_LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Failed to find FlutterJNI Class.\u0026#34;; return false; } g_handle_platform_message_method = env-\u0026gt;GetMethodID(g_flutter_jni_class-\u0026gt;obj(), \u0026#34;handlePlatformMessage\u0026#34;, \u0026#34;(Ljava/lang/String;[BI)V\u0026#34;); static jmethodID g_handle_platform_message_method = nullptr; void FlutterViewHandlePlatformMessage(JNIEnv* env, jobject obj, jstring channel, jobject message, jint responseId) { env-\u0026gt;CallVoidMethod(obj, g_handle_platform_message_method, channel, message, responseId); FML_CHECK(CheckException(env)); } FlutterJNI\n// Called by native. private void handlePlatformMessage(@NonNull String channel, byte[] message, int replyId) { if (this.platformMessageHandler != null) { this.platformMessageHandler.handleMessageFromDart(channel, message, replyId); } } PlatformMessageHandler\nvoid handleMessageFromDart(@NonNull String var1, @Nullable byte[] var2, int var3); void handlePlatformMessageResponse(int var1, @Nullable byte[] var2); DartMessenger.handleMessageFromDart @NonNull private final Map\u0026lt;String, BinaryMessageHandler\u0026gt; messageHandlers; //由dart发起调用 public void handleMessageFromDart(@NonNull String channel, @Nullable byte[] message, int replyId) { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Received message from Dart over channel \u0026#39;\u0026#34; + channel + \u0026#34;\u0026#39;\u0026#34;); BinaryMessageHandler handler = (BinaryMessageHandler)this.messageHandlers.get(channel); if (handler != null) { try { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Deferring to registered handler to process message.\u0026#34;); ByteBuffer buffer = message == null ? null : ByteBuffer.wrap(message); handler.onMessage(buffer, new DartMessenger.Reply(this.flutterJNI, replyId)); } catch (Exception var6) { Log.e(\u0026#34;DartMessenger\u0026#34;, \u0026#34;Uncaught exception in binary message listener\u0026#34;, var6); this.flutterJNI.invokePlatformMessageEmptyResponseCallback(replyId); } } else { Log.v(\u0026#34;DartMessenger\u0026#34;, \u0026#34;No registered handler for message. Responding to Dart with empty reply message.\u0026#34;); this.flutterJNI.invokePlatformMessageEmptyResponseCallback(replyId); } } BinaryMessageHandler.onMessage 消息回复 Reply.reply DartMessenger private static class Reply implements BinaryReply { @NonNull private final FlutterJNI flutterJNI; private final int replyId; private final AtomicBoolean done = new AtomicBoolean(false); Reply(@NonNull FlutterJNI flutterJNI, int replyId) { this.flutterJNI = flutterJNI; this.replyId = replyId; } public void reply(@Nullable ByteBuffer reply) { if (this.done.getAndSet(true)) { throw new IllegalStateException(\u0026#34;Reply already submitted\u0026#34;); } else { if (reply == null) { this.flutterJNI.invokePlatformMessageEmptyResponseCallback(this.replyId); } else { this.flutterJNI.invokePlatformMessageResponseCallback(this.replyId, reply, reply.position()); } FlutterJNI\n@UiThread public void invokePlatformMessageResponseCallback(int responseId, @Nullable ByteBuffer message, int position) { this.ensureRunningOnMainThread(); if (this.isAttached()) { this.nativeInvokePlatformMessageResponseCallback(this.nativePlatformViewId, responseId, message, position); } else { Log.w(\u0026#34;FlutterJNI\u0026#34;, \u0026#34;Tried to send a platform message response, but FlutterJNI was detached from native C++. Could not send. Response ID: \u0026#34; + responseId); } private native void nativeInvokePlatformMessageResponseCallback(long var1, int var3, @Nullable ByteBuffer var4, int var5); shell\\platform\\android\\platform_view_android_jni.cc\nbool RegisterApi(JNIEnv* env) { static const JNINativeMethod flutter_jni_methods[] = { // Start of methods from FlutterJNI  { .name = \u0026#34;nativeInvokePlatformMessageResponseCallback\u0026#34;, .signature = \u0026#34;(JILjava/nio/ByteBuffer;I)V\u0026#34;, .fnPtr = reinterpret_cast\u0026lt;void*\u0026gt;(\u0026amp;InvokePlatformMessageResponseCallback), }, static void InvokePlatformMessageResponseCallback(JNIEnv* env, jobject jcaller, jlong shell_holder, jint responseId, jobject message, jint position) { ANDROID_SHELL_HOLDER-\u0026gt;GetPlatformView() -\u0026gt;InvokePlatformMessageResponseCallback(env, //  responseId, //  message, //  position //  ); } PlatformViewAndroid::InvokePlatformMessageResponseCallback void PlatformViewAndroid::InvokePlatformMessageResponseCallback( JNIEnv* env, jint response_id, jobject java_response_data, jint java_response_position) { if (!response_id) return; auto it = pending_responses_.find(response_id); if (it == pending_responses_.end()) return; uint8_t* response_data = static_cast\u0026lt;uint8_t*\u0026gt;(env-\u0026gt;GetDirectBufferAddress(java_response_data)); std::vector\u0026lt;uint8_t\u0026gt; response = std::vector\u0026lt;uint8_t\u0026gt;( response_data, response_data + java_response_position); auto message_response = std::move(it-\u0026gt;second); pending_responses_.erase(it); message_response-\u0026gt;Complete( std::make_unique\u0026lt;fml::DataMapping\u0026gt;(std::move(response))); } PlatformMessageResponseDart::Complete void PlatformMessageResponseDart::Complete(std::unique_ptr\u0026lt;fml::Mapping\u0026gt; data) { if (callback_.is_empty()) return; FML_DCHECK(!is_complete_); is_complete_ = true; ui_task_runner_-\u0026gt;PostTask(fml::MakeCopyable( [callback = std::move(callback_), data = std::move(data)]() mutable { std::shared_ptr\u0026lt;tonic::DartState\u0026gt; dart_state = callback.dart_state().lock(); if (!dart_state) return; tonic::DartState::Scope scope(dart_state); Dart_Handle byte_buffer = WrapByteData(std::move(data)); tonic::DartInvoke(callback.Release(), {byte_buffer});//调用SendPlatformMessage的第三个参数闭包  })); } sendplatformmessage\nMethodCodec ByteBuffer encodeMethodCall(MethodCall methodCall); MethodCall decodeMethodCall(ByteBuffer methodCall); ByteBuffer encodeSuccessEnvelope(Object result); Object decodeEnvelope(ByteBuffer envelope); StandardMethodCodec\n@Override public MethodCall decodeMethodCall(ByteBuffer methodCall) { methodCall.order(ByteOrder.nativeOrder()); final Object method = messageCodec.readValue(methodCall); final Object arguments = messageCodec.readValue(methodCall); if (method instanceof String \u0026amp;\u0026amp; !methodCall.hasRemaining()) { return new MethodCall((String) method, arguments); } throw new IllegalArgumentException(\u0026#34;Method call corrupted\u0026#34;); } @Override public ByteBuffer encodeSuccessEnvelope(Object result) { final ExposedByteArrayOutputStream stream = new ExposedByteArrayOutputStream(); stream.write(0); messageCodec.writeValue(stream, result); final ByteBuffer buffer = ByteBuffer.allocateDirect(stream.size()); buffer.put(stream.buffer(), 0, stream.size()); return buffer; } 反向(Native调用Dart)原理 Native侧platformThread DispatchPlatformMessage shell/platform/android/platform_view_android_jni_impl.cc\nstatic void DispatchPlatformMessage(JNIEnv* env, jobject jcaller, jlong shell_holder, jstring channel, jobject message, jint position, jint responseId) { ANDROID_SHELL_HOLDER-\u0026gt;GetPlatformView()-\u0026gt;DispatchPlatformMessage( env, //  fml::jni::JavaStringToString(env, channel), //  message, //  position, //  responseId //  ); } shell/platform/android/platform_view_android.cc\nvoid PlatformViewAndroid::DispatchPlatformMessage(JNIEnv* env, std::string name, jobject java_message_data, jint java_message_position, jint response_id) { uint8_t* message_data = static_cast\u0026lt;uint8_t*\u0026gt;(env-\u0026gt;GetDirectBufferAddress(java_message_data)); fml::MallocMapping message = fml::MallocMapping::Copy(message_data, java_message_position); fml::RefPtr\u0026lt;flutter::PlatformMessageResponse\u0026gt; response; if (response_id) { response = fml::MakeRefCounted\u0026lt;PlatformMessageResponseAndroid\u0026gt;( response_id, jni_facade_, task_runners_.GetPlatformTaskRunner()); } PlatformView::DispatchPlatformMessage( std::make_unique\u0026lt;flutter::PlatformMessage\u0026gt;( std::move(name), std::move(message), std::move(response))); } runtime/runtime_controller.cc\n// |PlatformConfigurationClient| void RuntimeController::HandlePlatformMessage( std::unique_ptr\u0026lt;PlatformMessage\u0026gt; message) { client_.HandlePlatformMessage(std::move(message)); } GetUITaskRunner()-\u0026gt;PostTask shell/common/shell.cc\n// |PlatformView::Delegate| void Shell::OnPlatformViewDispatchPlatformMessage( std::unique_ptr\u0026lt;PlatformMessage\u0026gt; message) { FML_DCHECK(is_setup_); FML_DCHECK(task_runners_.GetPlatformTaskRunner()-\u0026gt;RunsTasksOnCurrentThread()); task_runners_.GetUITaskRunner()-\u0026gt;PostTask(fml::MakeCopyable( [engine = engine_-\u0026gt;GetWeakPtr(), message = std::move(message)]() mutable { if (engine) { engine-\u0026gt;DispatchPlatformMessage(std::move(message)); } })); } Dart侧(UI Thread) if (engine) { engine-\u0026gt;DispatchPlatformMessage(std::move(message)); } shell/common/engine.cc\nvoid Engine::DispatchPlatformMessage(std::unique_ptr\u0026lt;PlatformMessage\u0026gt; message) { std::string channel = message-\u0026gt;channel(); if (channel == kLifecycleChannel) { if (HandleLifecyclePlatformMessage(message.get())) { return; } } else if (channel == kLocalizationChannel) { if (HandleLocalizationPlatformMessage(message.get())) { return; } } else if (channel == kSettingsChannel) { HandleSettingsPlatformMessage(message.get()); return; } else if (!runtime_controller_-\u0026gt;IsRootIsolateRunning() \u0026amp;\u0026amp; channel == kNavigationChannel) { // If there\u0026#39;s no runtime_, we may still need to set the initial route.  HandleNavigationPlatformMessage(std::move(message)); return; } if (runtime_controller_-\u0026gt;IsRootIsolateRunning() \u0026amp;\u0026amp; runtime_controller_-\u0026gt;DispatchPlatformMessage(std::move(message))) { return; } FML_DLOG(WARNING) \u0026lt;\u0026lt; \u0026#34;Dropping platform message on channel: \u0026#34; \u0026lt;\u0026lt; channel; } runtime/runtime_controller.cc\nbool RuntimeController::DispatchPlatformMessage( std::unique_ptr\u0026lt;PlatformMessage\u0026gt; message) { if (auto* platform_configuration = GetPlatformConfigurationIfAvailable()) { TRACE_EVENT1(\u0026#34;flutter\u0026#34;, \u0026#34;RuntimeController::DispatchPlatformMessage\u0026#34;, \u0026#34;mode\u0026#34;, \u0026#34;basic\u0026#34;); platform_configuration-\u0026gt;DispatchPlatformMessage(std::move(message)); return true; } return false; } lib/ui/window/platform_configuration.cc\nvoid PlatformConfiguration::DispatchPlatformMessage( std::unique_ptr\u0026lt;PlatformMessage\u0026gt; message) { std::shared_ptr\u0026lt;tonic::DartState\u0026gt; dart_state = dispatch_platform_message_.dart_state().lock(); if (!dart_state) { FML_DLOG(WARNING) \u0026lt;\u0026lt; \u0026#34;Dropping platform message for lack of DartState on channel: \u0026#34; \u0026lt;\u0026lt; message-\u0026gt;channel(); return; } tonic::DartState::Scope scope(dart_state); Dart_Handle data_handle = (message-\u0026gt;hasData()) ? ToByteData(message-\u0026gt;data()) : Dart_Null(); if (Dart_IsError(data_handle)) { FML_DLOG(WARNING) \u0026lt;\u0026lt; \u0026#34;Dropping platform message because of a Dart error on channel: \u0026#34; \u0026lt;\u0026lt; message-\u0026gt;channel(); return; } int response_id = 0; if (auto response = message-\u0026gt;response()) { response_id = next_response_id_++; pending_responses_[response_id] = response; } tonic::LogIfError( tonic::DartInvoke(dispatch_platform_message_.Get(), {tonic::ToDart(message-\u0026gt;channel()), data_handle, tonic::ToDart(response_id)})); } binding.dart\n@override Future\u0026lt;void\u0026gt; handlePlatformMessage( String channel, ByteData? data, ui.PlatformMessageResponseCallback? callback, ) async { ByteData? response; try { final MessageHandler? handler = _handlers[channel]; if (handler != null) { response = await handler(data); platform_channel.dart\nvoid setMessageHandler(Future\u0026lt;T\u0026gt; Function(T message)? handler) { if (handler == null) { binaryMessenger.setMessageHandler(name, null); } else { binaryMessenger.setMessageHandler(name, (ByteData? message) async { return codec.encodeMessage(await handler(codec.decodeMessage(message)));//进入之前设置的回调闭包  }); } } lib/messages.dart\nstatic void setup(FlutterRouterApi api) { { const BasicMessageChannel\u0026lt;Object\u0026gt; channel = BasicMessageChannel\u0026lt;Object\u0026gt;(\u0026#39;dev.flutter.pigeon.FlutterRouterApi.popRoute\u0026#39;, StandardMessageCodec()); if (api == null) { channel.setMessageHandler(null); } else { channel.setMessageHandler((Object message) async { //进入之前设置的Handler回调闭包  assert(message != null, \u0026#39;Argument for dev.flutter.pigeon.FlutterRouterApi.popRoute was null. Expected CommonParams.\u0026#39;); final CommonParams input = CommonParams.decode(message); api.popRoute(input); return; }); } 其他 MethodChannel支持双向通信，反向原理类似，参考demo: multiple flutters\nFlutter和原生之间的平台通道实践与原理\n深入理解Flutter的Platform Channel机制\nMethodChannel的执行流程涉及到主线程和UI线程的交互，代码从Dart到C++再到Java层，执行完相应逻辑后原路返回，从Java层到C++层再到Dart层。\n[小节3.5] Shell::OnEngineHandlePlatformMessage 将任务发送给主线程\n[-\u0026gt; flutter/shell/common/shell.cc] constexpr char kSkiaChannel[] = \u0026#34;flutter/skia\u0026#34;; void Shell::OnEngineHandlePlatformMessage( fml::RefPtr\u0026lt;PlatformMessage\u0026gt; message) { if (message-\u0026gt;channel() == kSkiaChannel) { HandleEngineSkiaMessage(std::move(message)); return; } //[见小节3.6]  task_runners_.GetPlatformTaskRunner()-\u0026gt;PostTask( [view = platform_view_-\u0026gt;GetWeakPtr(), message = std::move(message)]() { if (view) { view-\u0026gt;HandlePlatformMessage(std::move(message)); } }); } //将HandlePlatformMessage的工作交给主线程的PlatformTaskRunner来处理，对于PlatformView在Android平台的实例为PlatformViewAndroid。 [小节6.5] PlatformMessageResponseDart::Complete 将任务发送给UI线程\n[-\u0026gt; flutter/lib/ui/window/platform_message_response_dart.cc] void PlatformMessageResponseDart::Complete(std::unique_ptr\u0026lt;fml::Mapping\u0026gt; data) { is_complete_ = true; //post到UI线程来执行  ui_task_runner_-\u0026gt;PostTask(fml::MakeCopyable( [callback = std::move(callback_), data = std::move(data)]() mutable { std::shared_ptr\u0026lt;tonic::DartState\u0026gt; dart_state = callback.dart_state().lock(); tonic::DartState::Scope scope(dart_state); Dart_Handle byte_buffer = WrapByteData(std::move(data)); //[见小节6.6]  tonic::DartInvoke(callback.Release(), {byte_buffer}); })); } //到此就发生了线程切换操作，将任务post到UI线程的UITaskRunner来执行。 "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/mmkv/mmkv/",
	"title": "MMKV",
	"tags": [],
	"description": "",
	"content": "参考 https://github.com/Tencent/MMKV/wiki/android_ipc\nhttps://github.com/Tencent/MMKV/wiki/design\n原理总结 MMKV 本质上是将文件 mmap 到内存块中，将新增的 key-value 统统 append 到内存中；到达边界后，进行重整回写以腾出空间，空间还是不够的话，就 double 内存空间；对于内存文件中可能存在的重复键值，MMKV 只选用最后写入的作为有效键值。\n状态同步 写指针的同步 我们可以在每个进程内部缓存自己的写指针，然后在写入键值的同时，还要把最新的写指针位置也写到 mmap 内存中；这样每个进程只需要对比一下缓存的指针与 mmap 内存的写指针，如果不一样，就说明其他进程进行了写操作。事实上 MMKV 原本就在文件头部保存了有效内存的大小，这个数值刚好就是写指针的内存偏移量，我们可以重用这个数值来校对写指针。\n内存重整的感知 考虑使用一个单调递增的序列号，每次发生内存重整，就将序列号递增。将这个序列号也放到 mmap 内存中，每个进程内部也缓存一份，只需要对比序列号是否一致，就能够知道其他进程是否触发了内存重整。\n内存增长的感知 事实上 MMKV 在内存增长之前，会先尝试通过内存重整来腾出空间，重整后还不够空间才申请新的内存。所以内存增长可以跟内存重整一样处理。至于新的内存大小，可以通过查询文件大小来获得，无需在 mmap 内存另外存放。\n挑选进程锁  文件锁，优点是天然 robust，缺点是不支持递归加锁，也不支持读写锁升级/降级，需要自行实现。 pthread_mutex，优点是 pthread 库支持递归加锁，也支持读写锁升级/降级，缺点是不 robust，需要自行清理。  文件锁 到这里我们已经完成了数据的多进程同步工作，是时候回头处理锁事了，亦即前面提到的递归锁和锁升级/降级。\n递归锁 意思是如果一个进程/线程已经拥有了锁，那么后续的加锁操作不会导致卡死，并且解锁也不会导致外层的锁被解掉。对于文件锁来说，前者是满足的，后者则不然。因为文件锁是状态锁，没有计数器，无论加了多少次锁，一个解锁操作就全解掉。只要用到子函数，就非常需要递归锁。\n锁升级/降级 锁升级是指将已经持有的共享锁，升级为互斥锁，亦即将读锁升级为写锁；锁降级则是反过来。文件锁支持锁升级，但是容易死锁：假如 A、B 进程都持有了读锁，现在都想升级到写锁，就会陷入相互等待的困境，发生死锁。另外，由于文件锁不支持递归锁，也导致了锁降级无法进行，一降就降到没有锁。\n为了解决递归锁和锁升级/降级这两个难题，需要对文件锁(系统调用flock)进行封装，增加读锁、写锁计数器。处理逻辑如下表：\n   读锁计数器 写锁计数器 加读锁 加写锁 解读锁 解写锁     0 0 加读锁 加写锁 - -   0 1 +1 +1 - 解写锁   0 N +1 +1 - -1   1 0 +1 解读锁再加写锁 解读锁 -   1 1 +1 +1 -1 加读锁   1 N +1 +1 -1 -1   N 0 +1 解读锁再加写锁 -1 -   N 1 +1 +1 -1 加读锁   N N +1 +1 -1 -1    需要注意的地方有两点：\n 加写锁时，如果当前已经持有读锁，那么先尝试加写锁，try_lock 失败说明其他进程持有了读锁，我们需要先将自己的读锁释放掉，再进行加写锁操作，以避免死锁的发生。(这里的死锁指的是：本进程先加了读锁，之后又尝试加写锁，而这个写锁要等到前面那个读锁释放之后才能加上，而这是不可能的，因此造成死锁)。 解写锁时，假如之前曾经持有读锁，那么我们不能直接释放掉写锁，这样会导致读锁也解了。我们应该加一个读锁，将锁降级。  graph LR 加读锁--\u0026gt;直接加 加写锁--\u0026gt;首次加写锁,如果有读锁,需要先unlock,防止死锁 加写锁--\u0026gt;非首次加写锁,直接+1 解读锁--\u0026gt;直接解 解写锁--\u0026gt;写锁数量大于1直接-1 解写锁--\u0026gt;写锁数量为1,如果有读锁,加读锁锁降级,避免解写锁时读锁也解了,锁失效 MMKV initialize public static String initialize(String rootDir, LibLoader loader, MMKVLogLevel logLevel) { if (loader != null) { if (BuildConfig.FLAVOR.equals(\u0026#34;SharedCpp\u0026#34;)) { loader.loadLibrary(\u0026#34;c++_shared\u0026#34;); } loader.loadLibrary(\u0026#34;mmkv\u0026#34;); } else { if (BuildConfig.FLAVOR.equals(\u0026#34;SharedCpp\u0026#34;)) { System.loadLibrary(\u0026#34;c++_shared\u0026#34;); } System.loadLibrary(\u0026#34;mmkv\u0026#34;); } jniInitialize(rootDir, logLevel2Int(logLevel)); MMKV.rootDir = rootDir; return MMKV.rootDir; } loadLibrary\njniinitialize\nregisterContentChangeNotify // content change notification of other process // trigger by getXXX() or setXXX() or checkContentChangedByOuterProcess() private static MMKVContentChangeNotification gContentChangeNotify; public static void registerContentChangeNotify(MMKVContentChangeNotification notify) { gContentChangeNotify = notify; setWantsContentChangeNotify(gContentChangeNotify != null); } setwantscontentchangenotify\nonContentChangedByOuterProcess private static void onContentChangedByOuterProcess(String mmapID) { if (gContentChangeNotify != null) { gContentChangeNotify.onContentChangedByOuterProcess(mmapID); } } defaultMMKV public static MMKV defaultMMKV() { long handle = getDefaultMMKV(SINGLE_PROCESS_MODE, null); return checkProcessMode(handle, \u0026#34;DefaultMMKV\u0026#34;, SINGLE_PROCESS_MODE); } native-bridge.cpp JNI_OnLoad extern \u0026#34;C\u0026#34; JNIEXPORT JNICALL jint JNI_OnLoad(JavaVM *vm, void *reserved) { g_currentJVM = vm; JNIEnv *env; if (vm-\u0026gt;GetEnv(reinterpret_cast\u0026lt;void **\u0026gt;(\u0026amp;env), JNI_VERSION_1_6) != JNI_OK) { return -1; } static const char *clsName = \u0026#34;com/tencent/mmkv/MMKV\u0026#34;; jclass instance = env-\u0026gt;FindClass(clsName); g_cls = reinterpret_cast\u0026lt;jclass\u0026gt;(env-\u0026gt;NewGlobalRef(instance)); int ret = registerNativeMethods(env, g_cls); return JNI_VERSION_1_6; } registerNativeMethods static int registerNativeMethods(JNIEnv *env, jclass cls) { return env-\u0026gt;RegisterNatives(cls, g_methods, sizeof(g_methods) / sizeof(g_methods[0])); } jniInitialize MMKV_JNI void jniInitialize(JNIEnv *env, jobject obj, jstring rootDir, jint logLevel) { const char *kstr = env-\u0026gt;GetStringUTFChars(rootDir, nullptr); if (kstr) { MMKV::initializeMMKV(kstr, (MMKVLogLevel) logLevel); env-\u0026gt;ReleaseStringUTFChars(rootDir, kstr); } } setWantsContentChangeNotify MMKV_JNI void setWantsContentChangeNotify(JNIEnv *env, jclass type, jboolean notify) { if (notify == JNI_TRUE) { MMKV::registerContentChangeHandler(onContentChangedByOuterProcess); } else { MMKV::unRegisterContentChangeHandler(); } } registercontentchangehandler\nonContentChangedByOuterProcess_n static void onContentChangedByOuterProcess(const std::string \u0026amp;mmapID) { auto currentEnv = getCurrentEnv(); if (currentEnv \u0026amp;\u0026amp; g_callbackOnContentChange) { jstring str = string2jstring(currentEnv, mmapID); currentEnv-\u0026gt;CallStaticVoidMethod(g_cls, g_callbackOnContentChange, str); } } g_callbackOnContentChange\ngetDefaultMMKV MMKV_JNI jlong getDefaultMMKV(JNIEnv *env, jobject obj, jint mode, jstring cryptKey) { MMKV *kv = nullptr; if (cryptKey) { string crypt = jstring2string(env, cryptKey); if (crypt.length() \u0026gt; 0) { kv = MMKV::defaultMMKV((MMKVMode) mode, \u0026amp;crypt); } } if (!kv) { kv = MMKV::defaultMMKV((MMKVMode) mode, nullptr); } return (jlong) kv; } getMMKVWithID MMKV_JNI jlong getMMKVWithID(JNIEnv *env, jobject, jstring mmapID, jint mode, jstring cryptKey, jstring rootPath) { string str = jstring2string(env, mmapID); kv = MMKV::mmkvWithID(str, DEFAULT_MMAP_SIZE, (MMKVMode) mode, \u0026amp;crypt, \u0026amp;path); return (jlong) kv; } mmkvwithid\nMMKV.cpp initializeMMKV void MMKV::initializeMMKV(const MMKVPath_t \u0026amp;rootDir, MMKVLogLevel logLevel) { g_currentLogLevel = logLevel; ThreadLock::ThreadOnce(\u0026amp;once_control, initialize); g_rootDir = rootDir; mkPath(g_rootDir); } initialize void initialize() { g_instanceDic = new unordered_map\u0026lt;string, MMKV *\u0026gt;; g_instanceLock = new ThreadLock(); g_instanceLock-\u0026gt;initialize(); mmkv::DEFAULT_MMAP_SIZE = mmkv::getPageSize(); } registerContentChangeHandler void MMKV::registerContentChangeHandler(mmkv::ContentChangeHandler handler) { g_contentChangeHandler = handler; } defaultMMKV MMKV *MMKV::defaultMMKV(MMKVMode mode, string *cryptKey) { #ifndef MMKV_ANDROID  return mmkvWithID(DEFAULT_MMAP_ID, mode, cryptKey); #else  return mmkvWithID(DEFAULT_MMAP_ID, DEFAULT_MMAP_SIZE, mode, cryptKey); #endif } mmkvWithID MMKV *MMKV::mmkvWithID(const string \u0026amp;mmapID, int size, MMKVMode mode, string *cryptKey, string *rootPath) { SCOPED_LOCK(g_instanceLock); auto mmapKey = mmapedKVKey(mmapID, rootPath); auto itr = g_instanceDic-\u0026gt;find(mmapKey); if (itr != g_instanceDic-\u0026gt;end()) { MMKV *kv = itr-\u0026gt;second; return kv; } auto kv = new MMKV(mmapID, size, mode, cryptKey, rootPath); (*g_instanceDic)[mmapKey] = kv; return kv; } MMKV() MMKV::MMKV(const string \u0026amp;mmapID, int size, MMKVMode mode, string *cryptKey, string *rootPath) : m_mmapID(mmapedKVKey(mmapID, rootPath)) // historically Android mistakenly use mmapKey as mmapID  , m_path(mappedKVPathWithID(m_mmapID, mode, rootPath)) , m_crcPath(crcPathWithID(m_mmapID, mode, rootPath)) , m_dic(nullptr) , m_dicCrypt(nullptr) , m_file(new MemoryFile(m_path, size, (mode \u0026amp; MMKV_ASHMEM) ? MMFILE_TYPE_ASHMEM : MMFILE_TYPE_FILE)) , m_metaFile(new MemoryFile(m_crcPath, DEFAULT_MMAP_SIZE, m_file-\u0026gt;m_fileType)) , m_metaInfo(new MMKVMetaInfo()) , m_crypter(nullptr) , m_lock(new ThreadLock()) , m_fileLock(new FileLock(m_metaFile-\u0026gt;getFd(), (mode \u0026amp; MMKV_ASHMEM))) , m_sharedProcessLock(new InterProcessLock(m_fileLock, SharedLockType)) , m_exclusiveProcessLock(new InterProcessLock(m_fileLock, ExclusiveLockType)) , m_isInterProcess((mode \u0026amp; MMKV_MULTI_PROCESS) != 0 || (mode \u0026amp; CONTEXT_MODE_MULTI_PROCESS) != 0) { m_actualSize = 0; m_output = nullptr; // force use fcntl(), otherwise will conflict with MemoryFile::reloadFromFile()  m_fileModeLock = new FileLock(m_file-\u0026gt;getFd(), true); m_sharedProcessModeLock = new InterProcessLock(m_fileModeLock, SharedLockType); m_exclusiveProcessModeLock = nullptr; # ifndef MMKV_DISABLE_CRYPT  if (cryptKey \u0026amp;\u0026amp; cryptKey-\u0026gt;length() \u0026gt; 0) { m_dicCrypt = new MMKVMapCrypt(); m_crypter = new AESCrypt(cryptKey-\u0026gt;data(), cryptKey-\u0026gt;length()); } else # endif  { m_dic = new MMKVMap(); } m_needLoadFromFile = true; m_hasFullWriteback = false; m_crcDigest = 0; m_sharedProcessLock-\u0026gt;m_enable = m_isInterProcess; m_exclusiveProcessLock-\u0026gt;m_enable = m_isInterProcess; // sensitive zone  { SCOPED_LOCK(m_sharedProcessLock); loadFromFile(); } } loadFromFile void MMKV::loadFromFile() { if (!m_file-\u0026gt;isFileValid()) { m_file-\u0026gt;reloadFromFile(); } auto ptr = (uint8_t *) m_file-\u0026gt;getMemory(); if (loadFromFile \u0026amp;\u0026amp; m_actualSize \u0026gt; 0) { MMBuffer inputBuffer(ptr + Fixed32Size, m_actualSize, MMBufferNoCopy); } MemoryFile reloadFromFile void MemoryFile::reloadFromFile() { m_fd = open(m_name.c_str(), O_RDWR | O_CREAT | O_CLOEXEC, S_IRWXU); FileLock fileLock(m_fd); InterProcessLock lock(\u0026amp;fileLock, ExclusiveLockType); SCOPED_LOCK(\u0026amp;lock); mmkv::getFileSize(m_fd, m_size); // round up to (n * pagesize)  if (m_size \u0026lt; DEFAULT_MMAP_SIZE || (m_size % DEFAULT_MMAP_SIZE != 0)) { size_t roundSize = ((m_size / DEFAULT_MMAP_SIZE) + 1) * DEFAULT_MMAP_SIZE; truncate(roundSize); } else { auto ret = mmap(); if (!ret) { doCleanMemoryCache(true); } } } mmap bool MemoryFile::mmap() { m_ptr = (char *) ::mmap(m_ptr, m_size, PROT_READ | PROT_WRITE, MAP_SHARED, m_fd, 0); if (m_ptr == MAP_FAILED) { MMKVError(\u0026#34;fail to mmap [%s], %s\u0026#34;, m_name.c_str(), strerror(errno)); m_ptr = nullptr; return false; } return true; } getMemory void *getMemory() { return m_ptr; } FileLock FileLock::FileLock(MMKVFileHandle_t fd, bool isAshmem) : m_fd(fd), m_sharedLockCount(0), m_exclusiveLockCount(0), m_isAshmem(isAshmem) { m_lockInfo.l_type = F_WRLCK; m_lockInfo.l_start = 0; m_lockInfo.l_whence = SEEK_SET; m_lockInfo.l_len = 0; m_lockInfo.l_pid = 0; } lock bool FileLock::lock(LockType lockType) { return doLock(lockType, true); } doLock bool FileLock::doLock(LockType lockType, bool wait, bool *tryAgain) { if (lockType == SharedLockType) { // don\u0026#39;t want shared-lock to break any existing locks  if (m_sharedLockCount \u0026gt; 0 || m_exclusiveLockCount \u0026gt; 0) { m_sharedLockCount++; return true; } } else { // don\u0026#39;t want exclusive-lock to break existing exclusive-locks  if (m_exclusiveLockCount \u0026gt; 0) { m_exclusiveLockCount++; return true; } // prevent deadlock  if (m_sharedLockCount \u0026gt; 0) { unLockFirstIfNeeded = true; } } auto ret = platformLock(lockType, wait, unLockFirstIfNeeded, tryAgain); if (ret) { if (lockType == SharedLockType) { m_sharedLockCount++; } else { m_exclusiveLockCount++; } } return ret; } unlock bool FileLock::unlock(LockType lockType) { if (lockType == SharedLockType) { if (m_sharedLockCount == 0) { return false; } // don\u0026#39;t want shared-lock to break any existing locks  if (m_sharedLockCount \u0026gt; 1 || m_exclusiveLockCount \u0026gt; 0) { m_sharedLockCount--; return true; } } else { if (m_exclusiveLockCount == 0) { return false; } if (m_exclusiveLockCount \u0026gt; 1) { m_exclusiveLockCount--; return true; } // restore shared-lock when all exclusive-locks are done  if (m_sharedLockCount \u0026gt; 0) { unlockToSharedLock = true; } } auto ret = platformUnLock(unlockToSharedLock); if (ret) { if (lockType == SharedLockType) { m_sharedLockCount--; } else { m_exclusiveLockCount--; } } return ret; } platformLock bool FileLock::platformLock(LockType lockType, bool wait, bool unLockFirstIfNeeded, bool *tryAgain) { if (m_isAshmem) { return ashmemLock(lockType, wait, unLockFirstIfNeeded, tryAgain); } auto realLockType = LockType2FlockType(lockType); auto cmd = wait ? realLockType : (realLockType | LOCK_NB); if (unLockFirstIfNeeded) { // try lock  auto ret = flock(m_fd, realLockType | LOCK_NB); if (ret == 0) { return true; } // let\u0026#39;s be gentleman: unlock my shared-lock to prevent deadlock  ret = flock(m_fd, LOCK_UN); if (ret != 0) { MMKVError(\u0026#34;fail to try unlock first fd=%d, ret=%d, error:%s\u0026#34;, m_fd, ret, strerror(errno)); } } auto ret = flock(m_fd, cmd); ...... } platformUnLock bool FileLock::platformUnLock(bool unlockToSharedLock) { if (m_isAshmem) { return ashmemUnLock(unlockToSharedLock); } int cmd = unlockToSharedLock ? LOCK_SH : LOCK_UN; auto ret = flock(m_fd, cmd); } InterProcessLock InterProcessLock(FileLock *fileLock, LockType lockType) : m_fileLock(fileLock), m_lockType(lockType), m_enable(true) { MMKV_ASSERT(m_fileLock); } lock void lock() { if (m_enable) { m_fileLock-\u0026gt;lock(m_lockType); } } unlock void unlock() { if (m_enable) { m_fileLock-\u0026gt;unlock(m_lockType); } } ScopedLock explicit ScopedLock(T *oLock) : m_lock(oLock) { MMKV_ASSERT(m_lock); lock(); } ~ScopedLock() { unlock(); m_lock = nullptr; } lock unLock template \u0026lt;typename T\u0026gt; class ScopedLock { T *m_lock; void lock() { if (m_lock) { m_lock-\u0026gt;lock(); } } void unlock() { if (m_lock) { m_lock-\u0026gt;unlock(); } } } ThreadLock.cpp ThreadOnce pthread_once用来确保在C++下多线程并发时，callback只调用一次，可用于C++中的单例模式\npthread_once实现简析\nvoid ThreadLock::ThreadOnce(ThreadOnceToken_t *onceToken, void (*callback)()) { pthread_once(onceToken, callback); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/mmkv/",
	"title": "mmkv",
	"tags": [],
	"description": "",
	"content": "mmkv 探索总结mmkv知识\n MMKV     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/multidex/",
	"title": "MultiDex",
	"tags": [],
	"description": "",
	"content": "原理 Android5.0以下MultiDex下启动丝般柔滑 Android5.0及以上的设备在安装apk的时候就优化好了Multidex,所以在首次打开的时候执行,Multidex.install(this);并不会占用多少时间\n当Android系统安装一个应用的时候，有一步是对Dex进行优化，这个过程有一个专门的工具来处理，叫DexOpt。DexOpt的执行过程是在第一次加载Dex文件的时候执行的。这个过程会生成一个ODEX文件，即Optimised Dex。执行ODex的效率会比直接执行Dex文件的效率要高很多。 但是在早期的Android系统中，DexOpt有一个问题，DexOpt会把每一个类的方法id检索起来，存在一个链表结构里面。但是这个链表的长度是用一个short类型来保存的，导致了方法id的数目不能够超过65536个。当一个项目足够大的时候，显然这个方法数的上限是不够的。尽管在新版本的Android系统中，DexOpt修复了这个问题，但是我们仍然需要对低版本的Android系统做兼容。 比如:微信app经过分包后,我们解压其apk文件:\n从中我们可以看到微信经过分包处理之后有3个dex文件\n使用 (1)在App所属的build.gradle里面\nandroid { ...... defaultConfig { multiDexEnabled true ...... } } (2)在你自定义的Application(这个一般项目里面都有) MultiDex.install(this);//初始化\n 参考 美团Android DEX自动拆包及动态加载简介\nhttp://allenfeng.com/2016/11/17/principle-analysis-on-multidex/\nhttps://blog.csdn.net/dbs1215/article/details/79214565\nhttps://developer.android.com/studio/build/multidex#multidexkeepfile-property\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/ndk/native_hook/",
	"title": "native_hook",
	"tags": [],
	"description": "",
	"content": "对于 Native Hook 技术，我们比较熟悉的有 GOT/PLT Hook、Trap Hook 以及 Inline Hook，下面我来逐个讲解这些 Hook 技术的实现原理和优劣比较。\nGOT/PLT Hook xHook https://github.com/iqiyi/xHook\nhttps://github.com/iqiyi/xHook/blob/master/docs/overview/android_plt_hook_overview.zh-CN.md\n  hook libc.so android_getaddrinfofornet ，貌似没hook成功 https://github.com/iqiyi/xHook/issues/16\n  如何获取到被hook的方法的地址 https://github.com/iqiyi/xHook/issues/15\n  PLT/GOT hook局限性 xhook只支持PLT/GOT方式的hook，就是hook“调用方so中的对外调用点”。android_getaddrinfofornet函数的实现在libc.so中，需要hook android_getaddrinfofornet的调用方，可以： xhook_register(\u0026#34;.*/libwebviewchromium\\\\.so$\u0026#34;, \u0026#34;android_getaddrinfofornet\u0026#34;, new_android_getaddrinfofornet, NULL); 不能做 ELF 内部函数之间调用的 hook。 inline hook 可以做到 demo执行步骤 1：下载Android NDK r16b，配置环境变量(每次重启PC都要配置一次) 2：./build_libs.sh通过cmd中单个执行编译完成 3：./install_libs.sh通过在cmd中执行: C:\\Users\\zhenghuan\\git\\demo\\xHook\u0026gt;install_libs.sh 完成 如何引用系统so https://developer.android.com/ndk/guides/stable_apis.html?hl=zh-CN\nhttps://stackoverflow.com/questions/13115827/how-to-link-to-the-libmedia-so-system-library-in-an-android-ndk-app-using-androi\nInlineHook Android inline hook 浅析\n什么是 inline hook  Inline hooking is a method of intercepting calls to target functions. The general idea is to redirect a function to our own, so that we can perform processing before and/or after the function does its; this could include: checking parameters, shimming, logging, spoofing returned data, and filtering calls.\nThe hooks are placed by directly modifying code within the target function (inline modification), usually by overwriting the first few bytes with a jump; this allows execution to be redirected before the function does any processing\n Inline hook 的原理 inline hook 由3部分组成：\n Hook - 为了 hook 目标函数(旧函数)，会向其代码中写入一个5个字节的跳转指令(实际跳转指令以及指令大小跟平台相关) Proxy - 用于指定被 hook 的目标函数将要跳转到的函数(新函数) Trampoline - 用于调用旧函数  参考 Android Native Hook技术路线概述\nandroid native hook技术你知道多少?\nfrida https://www.frida.re/\nhttps://github.com/frida/frida\n旧项目 https://github.com/crmulliner/adbi\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/nativecrash/",
	"title": "nativecrash",
	"tags": [],
	"description": "",
	"content": "nativecrash 探索总结nativecrash知识\n 1nativeCrash选型和整体流程     nativeCrash1SystemHandle     nativeCrash2Monitor_CollectStack     nativeCrash3SymbolRecovery     nativeCrash4AnalysisRootCause     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/nativecrash/nativecrash1systemhandle/",
	"title": "nativeCrash1SystemHandle",
	"tags": [],
	"description": "",
	"content": "从安卓 APP 开发的角度，Java 崩溃捕获相对比较容易，JVM 给 Java 字节码提供了一个受控的运行环境，同时也提供了完善的 Java 崩溃捕获机制。Native 崩溃的捕获和处理相对比较困难，安卓系统的==debuggerd 守护进程会为 native 崩溃自动生成详细的崩溃描述文件（tombstone）。==\n在==开发调试阶段，可以通过系统提供的 bugreport 工具获取 tombstone 文件==（或者将设备 root 后也可以拿到）。但是对于发布到线上的安卓 APP，如何获取 tombstone 文件，安卓操作系统本身并没有提供这样的功能。这个问题一直是安卓 native 崩溃分析和移动端 APM 系统的痛点之一。\nTombstones https://source.android.com/devices/tech/debug/native-crash\nhttps://source.android.com/devices/tech/debug/index.html#debuggerd\nBefore Android 8.0, crashes were handled by the debuggerd and debuggerd64 daemons. In Android 8.0 and higher, crash_dump32 and crash_dump64 are spawned as needed.\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/nativecrash/nativecrash2monitor_collectstack/",
	"title": "nativeCrash2Monitor_CollectStack",
	"tags": [],
	"description": "",
	"content": "参考xcrashnativecrash源码分析\n1 捕捉native crash的发生 信号 所有的信号量都定义在\u0026lt;signal.h\u0026gt;文件中:\n#define SIGHUP 1 // 终端连接结束时发出(不管正常或非正常) #define SIGINT 2 // 程序终止(例如Ctrl-C) #define SIGQUIT 3 // 程序退出(Ctrl-\\) #define SIGILL 4 // 执行了非法指令，或者试图执行数据段，堆栈溢出 #define SIGTRAP 5 // 断点时产生，由debugger使用 #define SIGABRT 6 // 调用abort函数生成的信号，表示程序异常 #define SIGIOT 6 // 同上，更全，IO异常也会发出 #define SIGBUS 7 // 非法地址，包括内存地址对齐出错，比如访问一个4字节的整数, 但其地址不是4的倍数 #define SIGFPE 8 // 计算错误，比如除0、溢出 #define SIGKILL 9 // 强制结束程序，具有最高优先级，本信号不能被阻塞、处理和忽略 #define SIGUSR1 10 // 未使用，保留 #define SIGSEGV 11 // 非法内存操作，与SIGBUS不同，他是对合法地址的非法访问，比如访问没有读权限的内存，向没有写权限的地址写数据 #define SIGUSR2 12 // 未使用，保留 #define SIGPIPE 13 // 管道破裂，通常在进程间通信产生 #define SIGALRM 14 // 定时信号, #define SIGTERM 15 // 结束程序，类似温和的SIGKILL，可被阻塞和处理。通常程序如果终止不了，才会尝试SIGKILL #define SIGSTKFLT 16 // 协处理器堆栈错误 #define SIGCHLD 17 // 子进程结束时, 父进程会收到这个信号。 #define SIGCONT 18 // 让一个停止的进程继续执行 #define SIGSTOP 19 // 停止进程,本信号不能被阻塞,处理或忽略 #define SIGTSTP 20 // 停止进程,但该信号可以被处理和忽略 #define SIGTTIN 21 // 当后台作业要从用户终端读数据时, 该作业中的所有进程会收到SIGTTIN信号 #define SIGTTOU 22 // 类似于SIGTTIN, 但在写终端时收到 #define SIGURG 23 // 有紧急数据或out-of-band数据到达socket时产生 #define SIGXCPU 24 // 超过CPU时间资源限制时发出 #define SIGXFSZ 25 // 当进程企图扩大文件以至于超过文件大小资源限制 #define SIGVTALRM 26 // 虚拟时钟信号. 类似于SIGALRM, 但是计算的是该进程占用的CPU时间. #define SIGPROF 27 // 类似于SIGALRM/SIGVTALRM, 但包括该进程用的CPU时间以及系统调用的时间 #define SIGWINCH 28 // 窗口大小改变时发出 #define SIGIO 29 // 文件描述符准备就绪, 可以开始进行输入/输出操作 #define SIGPOLL SIGIO // 同上，别称 #define SIGPWR 30 // 电源异常 #define SIGSYS 31 // 非法的系统调用 致命的信号分为 2 类：\n1、kernel 发出的：\nSIGFPE: 除数为零。\nSIGILL: 无法识别的 CPU 指令。\nSIGSYS: 无法识别的系统调用（system call）。\nSIGSEGV: 错误的虚拟内存地址访问。\nSIGBUS: 错误的物理设备地址访问。\n2、用户态进程发出的：\nSIGABRT: 调用 abort() / kill() / tkill() / tgkill() 自杀，或被其他进程通过 kill() / tkill() / tgkill() 他杀。\nNaive 崩溃捕获需要注册这些信号的处理函数（signal handler），然后在信号处理函数中收集数据。\n因为信号是以“中断”的方式出现的，可能中断任何 CPU 指令序列的执行，所以在信号处理函数中，只能调用“异步信号安全（async-signal-safe）”的函数。例如malloc()、calloc()、free()、snprintf()、gettimeofday() 等等都是不能使用的，C++ STL / boost 也是不能使用的。\n所以，在信号处理函数中我们只能不分配堆内存，需要使用堆内存只能在初始化时预分配。如果要使用不在异步信号安全白名单中的 libc / bionic 函数，只能直接调用 system call 或者自己实现\n进程崩溃前的极端情况 当崩溃捕获逻辑开始运行时，会面对很多糟糕的情况，比如：栈溢出、堆内存不可用、虚拟内存地址耗尽、FD 耗尽、Flash 空间耗尽等。有时，这些极端情况的出现，本身就是导致进程崩溃的间接原因。\n1、栈溢出 我们需要预先用 sigaltstack() 为 signal handler 分配专门的栈内存空间，否则当遇到栈溢出时，signal handler 将无法正常运行。\n2、虚拟内存地址耗尽 内存泄露很容易导致虚拟内存地址耗尽，特别是在 32 位环境中。这意味着在 signal handler 中也不能使用类似 mmap() 的调用。\n3、FD 耗尽 FD 泄露是常见的导致进程崩溃的间接原因。这意味着在 signal handler 中无法正常的使用依赖于 FD 的操作，比如无法 open() + read() 读取/proc 中的各种信息。为了不干扰 APP 的正常运行，我们仅仅预留了一个 FD，用于在崩溃时可靠的创建出“崩溃信息记录文件”。\n4、Flash 空间耗尽 在 16G / 32G 存储空间的安卓设备中，这种情况经常发生。这意味着 signal handler 无法把崩溃信息记录到本地文件中。我们只能尝试在初始化时预先创建一些“占坑”文件，然后一直循环使用这些“占坑”文件来记录崩溃信息。如果“占坑”文件也创建失败，我们需要把最重要的一些崩溃信息（比如 backtrace）保存在内存中，然后立刻回调和发送这些信息。\n信号处理函数与子进程 在信号处理函数（signal handler）代码执行的==开始阶段==，我们只能“忍辱偷生”：\n1、遵守它的各种限制。\n2、不使用堆内存。\n3、自己实现需要的调用的“异步信号安全版本”，比如：snprintf()、gettimeofday()。\n4、必要时直接调用 system call。\n但这并非长久之计，我们要尽快在信号处理函数中执行“逃逸”，即使用clone() + execl() 创建新的子进程，然后在==子进程中继续收集崩溃信息==。这样做的目的是：\n1、避开 async-signal-safe 的限制。\n2、避开虚拟内存地址耗尽的问题。\n3、避开 FD 耗尽的问题。\n4、使用 ptrace() suspend 崩溃进程中所有的线程。与 iOS 不同，Linux / Android 不支持 suspend 本进程内的线程。（如果不做 suspend，则其他未崩溃的线程还在继续执行，还在继续写 logcat，当我们收集 logcat 时，崩溃时间点附近的 logcat 可能早已被淹没。类似的，其他的业务 log buffers 也存在被淹没的问题。）\n5、除了崩溃线程本身的 registers、backtrace 等，还能用 ptrace()收集到进程中其他所有线程的 registers、backtrace 等信息，这对于某些崩溃问题的分析是有意义的。\n6、更安全的读取内存数据。（ptrace 读数据失败会返回错误码，但是在崩溃线程内直接读内存数据，如果内存地址非法，会导致段错误）\n由此可以看出“逃逸”是必然的选择，整个过程如下图所示：\nCapture Native Crash 1. 注册信号处理函数 #include \u0026lt;signal.h\u0026gt; int sigaction(int signum,const struct sigaction *act,struct sigaction *oldact)); //signum：代表信号编码，可以是除SIGKILL及SIGSTOP外的任何一个特定有效的信号，如果为这两个信号定义自己的处理函数，将导致信号安装错误。 //act：指向结构体sigaction的一个实例的指针，该实例指定了对特定信号的处理，如果设置为空，进程会执行默认处理。 //oldact：和参数act类似，只不过保存的是原来对相应信号的处理，也可设置为NULL。  struct sigaction sa_old; memset(\u0026amp;sa, 0, sizeof(sa)); sigemptyset(\u0026amp;sa.sa_mask); sa.sa_sigaction = my_handler; sa.sa_flags = SA_SIGINFO; if (sigaction(sig, \u0026amp;sa, \u0026amp;sa_old) == 0) { ... } 2. 设置额外栈空间 #include \u0026lt;signal.h\u0026gt;int sigaltstack(const stack_t *ss, stack_t *oss);   SIGSEGV很有可能是栈溢出引起的，如果在默认的栈上运行很有可能会破坏程序运行的现场，无法获取到正确的上下文。而且当栈满了（太多次递归，栈上太多对象），系统会在同一个已经满了的栈上调用SIGSEGV的信号处理函数，又再一次引起同样的信号。\n  我们应该开辟一块新的空间作为运行信号处理函数的栈。可以使用sigaltstack在任意线程注册一个可选的栈，保留一下在紧急情况下使用的空间。（系统会在危险情况下把栈指针指向这个地方，使得可以在一个新的栈上运行信号处理函数）\n  stack_t stack; memset(\u0026amp;stack, 0, sizeof(stack)); /* Reserver the system default stack size. We don\u0026#39;t need that much by the way. */ stack.ss_size = SIGSTKSZ; stack.ss_sp = malloc(stack.ss_size); stack.ss_flags = 0; /* Install alternate stack size. Be sure the memory region is valid until you revert it. */ if (stack.ss_sp != NULL \u0026amp;\u0026amp; sigaltstack(\u0026amp;stack, NULL) == 0) { ... } 3.兼容其他signal处理 static void my_handler(const int code, siginfo_t *const si, void *const sc) { ... /* Call previous handler. */ old_handler.sa_sigaction(code, si, sc); }   某些信号可能在之前已经被安装过信号处理函数，而sigaction一个信号量只能注册一个处理函数，这意味着我们的处理函数会覆盖其他人的处理信号\n  保存旧的处理函数，在处理完我们的信号处理函数后，在重新运行老的处理函数就能完成兼容。\n  2 收集crash原因和so中的相对地址 信号处理函数的入参中有丰富的错误信息，下面我们来一一分析。\n/*信号处理函数*/ void (*sa_sigaction)(const int code, siginfo_t *const si, void * const sc) siginfo_t { int si_signo; /* Signal number 信号量 */ int si_errno; /* An errno value */ int si_code; /* Signal code 错误码 */ } 1. code 发生native crash之后，logcat中会打出如下一句信息：\nsignal 11 (SIGSEGV), code 0 (SI_USER), fault addr 0x0\n根据code去查表，其实就可以知道发生native crash的大致原因：\n2. pc值 信号处理函数中的第三个入参sc是uc_mcontext的结构体，是cpu相关的上下文，包括当前线程的寄存器信息和奔溃时的pc值。能够知道崩溃时的pc，就能知道崩溃时执行的是那条指令。\n不过这个结构体的定义是平台相关，不同平台、不同cpu架构中的定义都不一样：\n  x86-64架构：uc_mcontext.gregs[REG_RIP]\n  arm架构：uc_mcontext.arm_pc\n  3. 共享库名字和相对偏移地址 (1) dladdr() pc值是程序加载到内存中的绝对地址，我们需要拿到奔溃代码相对于共享库的相对偏移地址，才能使用addr2line分析出是哪一行代码。通过dladdr()可以获得共享库加载到内存的起始地址，用pc值减去它就可以获得相对偏移地址，并且可以获得共享库的名字。\nDl_info info; if (dladdr(addr, \u0026amp;info) != 0 \u0026amp;\u0026amp; info.dli_fname != NULL) { void * const nearest = info.dli_saddr; //相对偏移地址  const uintptr_t addr_relative = ((uintptr_t) addr - (uintptr_t) info.dli_fbase); ... } (2) Linux下进程的地址空间布局 ==任何一个程序通常都包括代码段和数据段，这些代码和数据本身都是静态的。程序要想运行，首先要由操作系统负责为其创建进程，并在进程的虚拟地址空间中为其代码段和数据段建立映射。光有代码段和数据段是不够的，进程在运行过程中还要有其动态环境，其中最重要的就是堆栈==。\n栈(stack)，作为进程的临时数据区,增长方向是从高地址到低地址。\n(3) /proc/self/maps：检查各个模块加载在内存的地址范围 在Linux系统中，/proc/self/maps保存了各个程序段在内存中的加载地址范围，grep出共享库的名字，就可以知道共享库的加载基值是多少。\n得到相对偏移地址之后，使用readelf查看共享库的符号表，就可以知道是哪个函数crash了。\n3 获取Crash发生时的函数调用栈 获取 backtrace xCrash 的 backtrace 实现 xCrash 参考了一部分 AOSP 和 BreakPad 的实现思路，在不需要 root 权限和兼容 Android 4.0 - 9.0 的前提下，自己实现了 unwind 逻辑。这样做的好处是 unwind 过程不再是一个黑盒，细节完全可控，遇到问题完全可调试。\nBacktrace unwind 依赖于三部分数据：寄存器、栈内存、各 ELF 中的 unwind table。xCrash 目前能处理 Android 4.0 - 9.0 中可能出现的所有格式的 unwind table，它们来自于 ELF 中的以下 section：\n（1）.ARM.exidx（只存在于 32 位 ARM 架构）\n（2）.eh_frame 和 .eh_frame_hdr\n（3）.debug_frame\n（4）.gnu_debugdata（LZMA 压缩的 mini debug info，其中可能包含其他的 unwind table，比如：.debug_frame）\n1. 原理 在前一步，我们获取了奔溃时的pc值和各个寄存器的内容，通过SP(stack pointer)和FP(frame pointer)所限定的stack frame，就可以得到母函数的SP和FP，从而得到母函数的stack frame（PC，LR，SP，FP会在函数调用的第一时间压栈），以此追溯，即可得到所有函数的调用顺序。\n2. 实现 获取函数调用栈是最麻烦的，至今没有一个好用的，全都要做一些大改动。常见的做法有四种：\n  第一种：直接使用系统的\u0026lt;unwind.h\u0026gt;库，可以获取到出错文件与函数名。只不过需要自己解析函数符号，同时经常会捕获到系统错误，需要手动过滤。\n  第二种：在4.1.1以上，5.0以下，使用系统自带的libcorkscrew.so，5.0开始，系统中没有了libcorkscrew.so，可以自己编译系统源码中的libunwind。libunwind是一个开源库，事实上高版本的安卓源码中就使用了优化版libunwind作为解堆栈的工具来替代libcorkscrew。\n  第三种：使用开源库coffeecatch，但是这种方案也不能百分之百兼容所有机型。\n  第四种：使用 Google 的breakpad，这是所有 C/C++堆栈获取的权威方案，基本上业界都是基于这个库来做的。只不过这个库是全平台的 android、iOS、Windows、Linux、MacOS 全都有，所以非常大，在使用的时候得把无关的平台剥离掉减小体积。\n  第五种: libbacktrace，其实也是用 libunwind 实现的，源码在 system/core 下面.使用 libbacktrace 一共就 3 步：\n   使用 Backtrace::Create 创建一个 Backtrace 实例 调用 Unwind 函数 unwind 一下 stack FormatFrameData 输出每个栈帧的文本信息（也可以自己根据 frame 自己打印）  获取函数符号 (1) libcorkscrew/libunwind 可以通过libcorkscrew中的get_backtrace_symbols函数获得函数符号。\n(2) dladdr 更通用的方法是通过dladdr获得函数名字。\nint dladdr(void *addr, Dl_info *info); typedef struct { const char *dli_fname; /* Pathname of shared object that contains address */ void *dli_fbase; /* Base address at which shared object is loaded */ const char *dli_sname; /* Name of symbol whose definition overlaps addr */ void *dli_saddr; /* Exact address of symbol named in dli_sname */ } Dl_info; 传入每一层堆栈的相对偏移地址，就可以从dli_fname中获得函数名字。\n获得java堆栈 如何获得native crash所对应的java层堆栈，这个问题曾经困扰了我一段时间。这里有一个前提：我们认为crash线程就是捕获到信号的线程，虽然这在SIGABRT下不一定可靠。有了这个认知，接下来就好办了。在信号处理函数中获得当前线程的名字，然后把crash线程的名字传给java层，在java里dump出这个线程的堆栈，就是crash所对应的java层堆栈了。\n  在c中获得线程名字：\n  然后传给java层：\n  结果展示 经过诸多探索，终于得到了完美的堆栈：\njava.lang.Error: signal 11 (Address not mapped to object) at address 0x0 at dalvik.system.NativeStart.run(Native Method) Caused by: java.lang.Error: signal 11 (Address not mapped to object) at address 0x0 at /data/app-lib/com.tencent.moai.crashcatcher.demo-1/libQMCrashGenerator.so.0xd8e(dangerousFunction:0x5:0) at /data/app-lib/com.tencent.moai.crashcatcher.demo-1/libQMCrashGenerator.so.0xd95(wrapDangerousFunction:0x2:0) at /data/app-lib/com.tencent.moai.crashcatcher.demo-1/libQMCrashGenerator.so.0xd9d(nativeInvalidAddressCrash:0x2:0) at /system/lib/libdvm.so.0x1ee8c(dvmPlatformInvoke:0x70:0) at /system/lib/libdvm.so.0x503b7(dvmCallJNIMethod(unsigned int const*, JValue*, Method const*, Thread*):0x1ee:0) at /system/lib/libdvm.so.0x28268(Native Method) at /system/lib/libdvm.so.0x2f738(dvmMterpStd(Thread*):0x44:0) at /system/lib/libdvm.so.0x2cda8(dvmInterpret(Thread*, Method const*, JValue*):0xb8:0) at /system/lib/libdvm.so.0x648e3(dvmInvokeMethod(Object*, Method const*, ArrayObject*, ArrayObject*, ClassObject*, bool):0x1aa:0) at /system/lib/libdvm.so.0x6cff9(Native Method) at /system/lib/libdvm.so.0x28268(Native Method) at /system/lib/libdvm.so.0x2f738(dvmMterpStd(Thread*):0x44:0) at /system/lib/libdvm.so.0x2cda8(dvmInterpret(Thread*, Method const*, JValue*):0xb8:0) at /system/lib/libdvm.so.0x643d9(dvmCallMethodV(Thread*, Method const*, Object*, bool, JValue*, std::__va_list):0x14c:0) at /system/lib/libdvm.so.0x4bca1(Native Method) at /system/lib/libandroid_runtime.so.0x50ac3(Native Method) at /system/lib/libandroid_runtime.so.0x518e7(android::AndroidRuntime::start(char const*, char const*):0x206:0) at /system/bin/app_process.0xf33(Native Method) at /system/lib/libc.so.0xf584(__libc_init:0x64:0) at /system/bin/app_process.0x107c(Native Method) Caused by: java.lang.Error: java stack at com.tencent.crashcatcher.CrashCatcher.nativeInvalidAddressCrash(Native Method) at com.tencent.crashcatcher.CrashCatcher.invalidAddressCrash(CrashCatcher.java:33) at com.tencent.moai.crashcatcher.demo.MainActivity$4.onClick(MainActivity.java:56) at android.view.View.performClick(View.java:4488) at android.view.View$PerformClick.run(View.java:18860) at android.os.Handler.handleCallback(Handler.java:808) at android.os.Handler.dispatchMessage(Handler.java:103) at android.os.Looper.loop(Looper.java:222) at android.app.ActivityThread.main(ActivityThread.java:5484) at java.lang.reflect.Method.invokeNative(Native Method) at java.lang.reflect.Method.invoke(Method.java:515) at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:860) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:676) at dalvik.system.NativeStart.main(Native Method) 在native层构造了一个Error传给java，所以在java层可以很轻松地根据堆栈进行业务上的处理。\npublic interface CrashHandleListener { @Keep void onCrash(int id, Error e); } 参考 Linux虚拟地址空间布局\nAndroid 平台 Native 代码的崩溃捕获机制及实现\nAndroid Native Crash 收集\nAndroid native 崩溃信息捕获实践\nAndroid APP native 崩溃分析之令人困惑的 backtrace\nhttps://linux.die.net/man/1/addr2line\n汇编基础知识  伪处理程序中的堆栈从高地址增长到低地址。因此，push会导致堆栈指针的递减。pop会导致堆栈指针的增量。 寄存器 sp(stack pointer) 用于指向堆栈。 寄存器 fp(frame pointer) 用作帧指针。帧指针充当被调用函数和调用函数之间的锚。 当调用一个函数时，该函数首先将 fp 的当前值保存在堆栈上。然后，它将 sp 寄存器的值保存在 fp 寄存器中。然后递减 sp 寄存器来为本地变量分配空间。 fp 寄存器用于访问本地变量和参数，局部变量位于帧指针的负偏移量处，传递给函数的参数位于帧指针的正偏移量。 当函数返回时， fp 寄存器被复制到 sp 寄存器中，这将释放用于局部变量的堆栈，函数调用者的 fp 寄存器的值由pop从堆栈中恢复。   pc and lr are related code registers. One is \u0026ldquo;Where you are\u0026rdquo;, the other is \u0026ldquo;Where you were\u0026rdquo;. sp and fp are related local data registers. One is \u0026ldquo;Where local data is\u0026rdquo;, the other is \u0026ldquo;Where the last local data is\u0026rdquo;.  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/nativecrash/nativecrash3symbolrecovery/",
	"title": "nativeCrash3SymbolRecovery",
	"tags": [],
	"description": "",
	"content": "1. 获取crash日志信息  adb logcat 的堆栈轨迹 /data/tombstones/ 中的 tombstone  2. 使用addr2line或ndk-stack工具查看crash文件和行号 addr2line https://stackoverflow.com/questions/5314036/how-to-use-addr2line-in-android\nNative crash异常，能定位到代码哪个地方报错吗 #18\narm-linux-androideabi-addr2line –e obj/local/armeabi/libhello-jni.so 00004de8 000056c8 00004fb4 00004f58 #这一步就该addr2line出场了。我们从backstrace中拿到了出错时的指令地址，它对应我们程序中某个函数的某行操作。我们需要addr2line将对应文件和对应行数打出来。这个命令的格式是 addr2line -e exefile addr #在NDK中找到对应的addr2line命令，testapp程序文件取出来，执行命令 [root@localhost]# /opt/android_tools/android-ndk-r20/toolchains/llvm/prebuilt/linux-x86_64/bin/arm-linux-androideabi-addr2line -f -e testapp 000a3f10 testGetEntryById /home/***/***/***/test.c:220 real command: $ Sdk/ndk-bundle/toolchains/llvm/prebuilt/windows-x86_64/bin/x86_64-linux-android-addr2line.exe -f -e ~/git/demo/xCrash/src/native/libxcrash/obj/local/x86_64/libxcrash.so 000000000000c2df xc_test_call_4 git/demo/xCrash/src/native/libxcrash/jni/xc_test.c:64 ndk-stack工具 https://developer.android.com/ndk/guides/ndk-stack?hl=zh-cn\nhttps://help.aliyun.com/knowledge_detail/70180.html\nadb shell logcat | ndk-stack -sym $PROJECT_PATH/obj/local/armeabi //需要-sym指定的目录中存在包含符号的so，系统system/lib下的so默认被strip导致没有符号 ndk-stack -sym ./workspace2/testNdkStack/obj/local/armeabi-v7a/ -dump ./logcat.log \u0026gt; result.log 在result.log中可以分析定位到出现该crash的对应代码文件和具体行数 real command: git\\demo\\xCrash\\src\\native\\libxcrash\\obj\\local\u0026gt;ndk-stack -sym ./x86_64 -dump Desktop\\nativeCrash\\generate\\tombstone_00001584779373143460_1.2.3-beta456-patch789__xcrash.sample.native.xcrash \u0026gt; result.txt 3. 使用objdump获取函数汇编信息 为了进一步定位问题，我们需要将出错函数的汇编取到，这就用到了objdump工具。我们使用objdump将testapp反汇编重定向到文件中。然后查看对应函数的汇编代码。\nhttps://github.com/iqiyi/xHook/blob/master/docs/overview/android_plt_hook_overview.zh-CN.md\nhttps://helpmanual.io/help/objdump/\ncaikelun@debian:~$ arm-linux-androideabi-objdump -D ./libtest.so ............... ............... 00000f60 \u0026lt;say_hello@@Base\u0026gt;: f60: b5b0 push {r4, r5, r7, lr} f62: af02 add r7, sp, #8 f64: f44f 6080 mov.w r0, #1024 ; 0x400 f68: f7ff ef34 blx dd4 \u0026lt;malloc@plt\u0026gt; f6c: 4604 mov r4, r0 f6e: b16c cbz r4, f8c \u0026lt;say_hello@@Base+0x2c\u0026gt; f70: a507 add r5, pc, #28 ; (adr r5, f90 \u0026lt;say_hello@@Base+0x30\u0026gt;) f72: a308 add r3, pc, #32 ; (adr r3, f94 \u0026lt;say_hello@@Base+0x34\u0026gt;) f74: 4620 mov r0, r4 f76: f44f 6180 mov.w r1, #1024 ; 0x400 f7a: 462a mov r2, r5 f7c: f7ff ef30 blx de0 \u0026lt;snprintf@plt\u0026gt; f80: 4628 mov r0, r5 f82: 4621 mov r1, r4 f84: e8bd 40b0 ldmia.w sp!, {r4, r5, r7, lr} f88: f001 ba96 b.w 24b8 \u0026lt;_Unwind_GetTextRelBase@@Base+0x8\u0026gt; f8c: bdb0 pop {r4, r5, r7, pc} f8e: bf00 nop f90: 7325 strb r5, [r4, #12] f92: 0000 movs r0, r0 f94: 6568 str r0, [r5, #84] ; 0x54 f96: 6c6c ldr r4, [r5, #68] ; 0x44 f98: 0a6f lsrs r7, r5, #9 f9a: 0000 movs r0, r0 ............... real command(windows): $ Sdk/ndk-bundle/toolchains/llvm/prebuilt/windows-x86_64/bin/x86_64-linux-android-objdump.exe -D ~/git/demo/xCrash/src/native/libxcrash/obj/local/x86_64/libxcrash.so \u0026gt; libxcrash_objdump.log real command(mac): /Users/qianpianpian/Library/Android/sdk/ndk/21.1.6352462/toolchains/llvm/prebuilt/darwin-x86_64/bin (objdump文件位置也可以通过本命令查找:find ~/Library/Android/sdk -name \u0026#34;*objdump*\u0026#34;) bin % ./x86_64-linux-android-objdump -m i386 -D ~/backup/20200818/libart.so \u0026gt; ~/backup/20200818/libart_objdump.log ObjectDump问题处理 can\u0026rsquo;t disassemble for architecture UNKNOWN! so来源于三星生产设备，直接adb pull system/lib/libart.so下来进行分析\n首先-h查看file format为elf32-little\n然后-i查看支持的cpu架构信息找到如下\nelf32-little (header little endian, data little endian) i386 l1om k1om iamcu plugin\n最后增加-m i386 在-D前面ok\n参考 Android Native crash日志分析\n[android]程序crash分析方法\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/nativecrash/nativecrash4analysisrootcause/",
	"title": "nativeCrash4AnalysisRootCause",
	"tags": [],
	"description": "",
	"content": "汇编 ARM汇编指令集汇总\n基本语法 汇编语言的主体是汇编指令。汇编指令和机器指令的差别在于指令的表示方法上。汇编指令是机器指令便于记忆的书写格式。\n#操作：寄存器BX的内容送到AX中 1000100111011000 #机器指令 mov ax,bx #汇编指令 汇编语言语句的语法 汇编语言语句输入每行一个语句。每个语句如下的格式如下：\n[label] mnemonic [operands] [;comment] 方括号中的字段是可选的。基本指令有两部分组成，第一个是要执行的指令（助记符）的名称和所述第二命令的操作数或参数的。\n以下是一些典型的汇编语言语句的例子：\nINC COUNT ; Increment the memory variable COUNT MOV TOTAL, 48 ; Transfer the value 48 in the  ; memory variable TOTAL ADD AH, BH ; Add the content of the  ; BH register into the AH register AND MASK1, 128 ; Perform AND operation on the  ; variable MASK1 and 128 ADD MARKS, 10 ; Add 10 to the variable MARKS MOV AL, 10 ; Transfer the value 10 to the AL register disassembler tool IDAPro is best disassembler tool for many processors and file types. HexRays ARM - plugin for IDAPro (doesn\u0026rsquo;t work separately), which trying to decompile assembler to C-like source code\nboth not free\nhttps://www.hex-rays.com/index.shtml\nnativeCrash objdump分析流程: 分析步骤 首先查看如下关键信息进行方向确定\n\u0026ldquo;signal\u0026rdquo;: \u0026ldquo;11 (SIGSEGV)\u0026rdquo;,\n\u0026ldquo;code\u0026rdquo;: \u0026ldquo;2 (SEGV_ACCERR)\u0026rdquo;,\n\u0026ldquo;fault addr\u0026rdquo;: \u0026ldquo;0x15049024\u0026rdquo;,\n\u0026ldquo;backtrace\u0026rdquo;: \u0026ldquo;#00 pc 0017c126 /system/lib/libart.so (_ZN3art2gc9allocator8RosAlloc8BulkFreeEPNS_6ThreadEPPvj+149)\\n\u0026rdquo;,\n\u0026ldquo;java stacktrace\u0026rdquo;: [ \u0026ldquo;at dalvik.system.VMRuntime.runHeapTasks(Native method)\u0026rdquo;,\n 根据tombstone找到对应的出错方法名，在objdump之后的反汇编文件中找到该方法(根据pc值或方法签名(例如_ZN3art2gc9allocator8RosAlloc8BulkFreeEPNS_6ThreadEPPvj)找到方法定义) 根据tombstone中backtrace的pc信息找到对应的指令执行位置 结合源码和反编译objdump指令以及上一步得到的出错位置， 向上寻找造成问题的原因  分析例子1  xc_test_call_4 c2df  rax 0000000000000000 rbx 0000743b3f05f200 rcx 0b8b8de9d74c4547 rdx 0000743b50a00000 r8 ffffffffffffffe0 r9 0000000000000000 r10 0000000000000022 r11 0000000000000206 r12 0000743b3ff4c410 r13 0000743b5c2451d0 r14 0000743b3ff4c630 r15 0000743b3ff4c630 rdi 0000000000000003 rsi 0000743b50b6f940 rbp 0000743b3ff4c110 rsp 0000743b3ff4c100 rip 0000743b569942df backtrace: #00 pc 000000000000c2df /data/app/xcrash.sample-1/lib/x86_64/libxcrash.so (xc_test_call_4+31)  #01 pc 000000000000c315 /data/app/xcrash.sample-1/lib/x86_64/libxcrash.so (xc_test_call_3+21)  #02 pc 000000000000c345 /data/app/xcrash.sample-1/lib/x86_64/libxcrash.so (xc_test_call_2+21)  #03 pc 000000000000c371 /data/app/xcrash.sample-1/lib/x86_64/libxcrash.so (xc_test_call_1+17)  #04 pc 000000000000c412 /data/app/xcrash.sample-1/lib/x86_64/libxcrash.so (xc_test_crash+130)  #05 pc 0000000000267f23 /data/app/xcrash.sample-1/oat/x86_64/base.odex  int xc_test_call_4(int v) { int *a = NULL;  xc_test_set_abort_msg();  *a = v; // crash!  (*a)++;  v = *a;  return v; } 000000000000c2c0 \u0026lt;xc_test_call_4\u0026gt;: c2c0:\t55 push %rbp c2c1:\t48 89 e5 mov %rsp,%rbp c2c4:\t48 83 ec 10 sub $0x10,%rsp c2c8:\t89 7d fc mov %edi,-0x4(%rbp) c2cb:\t48 c7 45 f0 00 00 00 movq $0x0,-0x10(%rbp) c2d2:\t00 c2d3:\te8 38 02 00 00 callq c510 \u0026lt;xc_test_set_abort_msg\u0026gt; c2d8:\t8b 7d fc mov -0x4(%rbp),%edi c2db:\t48 8b 45 f0 mov -0x10(%rbp),%rax c2df:\t89 38 mov %edi,(%rax) //尝试从rax中提取数据时，由于地址为0报错 c2e1:\t48 8b 45 f0 mov -0x10(%rbp),%rax c2e5:\t8b 38 mov (%rax),%edi c2e7:\t83 c7 01 add $0x1,%edi 分析例子2 tombstone-\u0026gt; signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x4798 r0 00004780 r1 00000780 r2 00000060 r3 e0cbc018 r4 e71f01d0 r5 db53b4b0 r6 db53b4a8 r7 00000000 r8 e71f01d4 r9 e71efa10 r10 e7cd94ec r11 e16ff848 ip b9839850 sp e16ff830 lr b951a62c pc b9519f10 backtrace: #00 pc 000a3f10 /data/data/com.test/files/testapp  stack: e16ff7f0 00000000 e16ff7f4 00000000 e16ff7f8 00000002 e16ff7fc ffffffff e16ff800 e0c8f1c0 [anon:libc_malloc] e16ff804 e16ff8a8 \u0026lt;anonymous:e1603000\u0026gt; e16ff808 e0c83640 [anon:libc_malloc] e16ff80c 0000c50b e16ff810 e71e6900 [anon:libc_malloc] e16ff814 00000000 e16ff818 e71efa17 [anon:libc_malloc] e16ff81c e71efa18 [anon:libc_malloc] e16ff820 dfea3014 [anon:libc_malloc] e16ff824 00000000 e16ff828 acb0ac7c e16ff82c 00000000 #00 e16ff830 00000000  e16ff834 b98c1694 \u0026lt;anonymous:b983a000\u0026gt; e16ff838 00400014 e16ff83c 00004000 e16ff840 00004780 e16ff844 80140000 //fp-4，所以fp-2是0x8014(注意这里是小端字节序) e16ff848 e16ff8b8 \u0026lt;anonymous:e1603000\u0026gt; //fp地址 e16ff84c b951a62c /data/data/com.test/files/testapp #代码示例，做了简化，方便理解 struct entry *testGetEntryById(unsigned short Id) { ... blockId = Id \u0026gt;\u0026gt; 9;  blockOffset = Id \u0026amp; (1 \u0026lt;\u0026lt; 9 - 1);  block = g_Table.EntryBlock[blockId];//问题出在这一行  if (block == NULL) { return NULL； } entry = \u0026amp;block-\u0026gt;Entry[blockOffset];  if (!entry-\u0026gt;Valid)\t{ return NULL;  } ... } objdump--\u0026gt; 000a3e54 \u0026lt;testGetEntryById\u0026gt;: a3e54: e92d4800 push {fp, lr} a3e58: e1a0b00d mov fp, sp a3e5c: e24dd018 sub sp, sp, #24  a3e60: e59f10d0 ldr r1, [pc, #208] ; a3f38 \u0026lt;testGetEntryById+0xe4\u0026gt;  a3e64: e08f1001 add r1, pc, r1 a3e68: e2811004 add r1, r1, #4  a3e6c: e14b00b2 strh r0, [fp, #-2] //fp-2位置存放了入参Id ...//省略 a3f08: e50b0008 str r0, [fp, #-8]  a3f0c: e51b0008 ldr r0, [fp, #-8]  a3f10: e5900018 ldr r0, [r0, #24]\t//问题发生位置  #第一列对应tombstone文件中的pc值，也就是so文件的相对地址 #在tombstone中可以找到fp(即r11)为e16ff848 #在stack中可以找到fp-2的值为0x8014。  #Id = 32788(对应16进制数0x8014)， 右移9bit后是64,即blockId是64。但是g_Table.EntryBlock[]数组大小为64， index范围 0~63。64超出数组范围，造成访问溢出，取到了错误的block地址。从而导致的最终的问题发生。  其他 SIGSEGV Code定义 https://elixir.bootlin.com/linux/latest/source/include/uapi/asm-generic/siginfo.h#L223\n/* * SIGSEGV si_codes */ #define SEGV_MAPERR\t1\t/* address not mapped to object */ #define SEGV_ACCERR\t2\t/* invalid permissions for mapped object */ #define SEGV_BNDERR\t3\t/* failed address bound checks */ #ifdef __ia64__ # define __SEGV_PSTKOVF\t4\t/* paragraph stack overflow */ #else # define SEGV_PKUERR\t4\t/* failed protection key checks */ #endif #define SEGV_ACCADI\t5\t/* ADI not enabled for mapped object */ #define SEGV_ADIDERR\t6\t/* Disrupting MCD error */ #define SEGV_ADIPERR\t7\t/* Precise MCD exception */ #define SEGV_MTEAERR\t8\t/* Asynchronous ARM MTE error */ #define SEGV_MTESERR\t9\t/* Synchronous ARM MTE exception */ #define NSIGSEGV\t9 ###\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/ndk/",
	"title": "ndk",
	"tags": [],
	"description": "",
	"content": "ndk 探索总结ndk知识\n ELF文件结构     JNI     native_hook     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/pigeon/",
	"title": "Pigeon",
	"tags": [],
	"description": "",
	"content": "https://github.com/flutter/packages/tree/master/packages/pigeon\nPigeon介绍 Pigeon是Flutter官方推荐的，用于自动生成PlatformChannel通信层模板代码(channel定义，编解码，异常处理等)的package，可以减少通信层开发时间。生成的代码通过MessageChannel进行通信。pigeon则使用MessageChannel并针对每个api方法设置唯一的channelName来进行区分，BasicMessageChannel中的T,也就是request参数和response类型都是Object，并在传输过程中对model进行编解码成Map传输。\nPigeon功能 graph LR subgraph Pigeon/message.dart HostApi(\u0026quot;@HostApi\u0026quot;) FlutterApi(\u0026quot;@FlutterApi\u0026quot;) Class(\u0026quot;Define Class\u0026quot;) configurePigeon end subgraph server GenerateFlutterApi GenereateHostApi end subgraph client GenerateCallHostApi GenerateCallFullterApi end FlutterApi--\u0026gt;|handle in Flutter|GenerateFlutterApi(\u0026quot;abstract class FlutterApi:channel.setMessageHandler and delegate to FlutterApi\u0026quot;) GenerateCallHostApi(\u0026quot;class HostApi: wrap channel.send\u0026quot;)--\u0026gt;|Flutter to host|HostApi GenerateCallFullterApi(\u0026quot;classFlutterApi: wrap channel.send\u0026quot;)--\u0026gt;|host to Flutter|FlutterApi HostApi--\u0026gt;|handle in host|GenereateHostApi(\u0026quot;interface HostApi: channel.setMessageHandler and delegate to HostApi\u0026quot;) Pigeon 生成代码 Client端 class NativeNetworkApi { Future\u0026lt;Resource\u0026gt; request(RequestParams arg) async { final Object encoded = arg.encode(); const BasicMessageChannel\u0026lt;Object\u0026gt; channel = BasicMessageChannel\u0026lt;Object\u0026gt;(\u0026#39;dev.flutter.pigeon.NativeNetworkApi.request\u0026#39;, StandardMessageCodec()); final Map\u0026lt;Object, Object\u0026gt; replyMap = await channel.send(encoded) as Map\u0026lt;Object, Object\u0026gt;; if (replyMap == null) { throw PlatformException( code: \u0026#39;channel-error\u0026#39;, message: \u0026#39;Unable to establish connection on channel.\u0026#39;, details: null, ); } else if (replyMap[\u0026#39;error\u0026#39;] != null) { final Map\u0026lt;Object, Object\u0026gt; error = (replyMap[\u0026#39;error\u0026#39;] as Map\u0026lt;Object, Object\u0026gt;); throw PlatformException( code: (error[\u0026#39;code\u0026#39;] as String), message: error[\u0026#39;message\u0026#39;] as String, details: error[\u0026#39;details\u0026#39;], ); } else { return Resource.decode(replyMap[\u0026#39;result\u0026#39;]); } } 调用方式\nNativeNetworkApi().request(requestParams) Server端 /** Generated interface from Pigeon that represents a handler of messages from Flutter.*/ public interface NativeNetworkApi { void request(RequestParams arg, Result\u0026lt;Resource\u0026gt; result); /** Sets up an instance of `NativeNetworkApi` to handle messages through the `binaryMessenger`. */ static void setup(BinaryMessenger binaryMessenger, NativeNetworkApi api) { { BasicMessageChannel\u0026lt;Object\u0026gt; channel = new BasicMessageChannel\u0026lt;\u0026gt;(binaryMessenger, \u0026#34;dev.flutter.pigeon.NativeNetworkApi.request\u0026#34;, new StandardMessageCodec()); if (api != null) { channel.setMessageHandler((message, reply) -\u0026gt; { Map\u0026lt;String, Object\u0026gt; wrapped = new HashMap\u0026lt;\u0026gt;(); try { @SuppressWarnings(\u0026#34;ConstantConditions\u0026#34;) RequestParams input = RequestParams.fromMap((Map\u0026lt;String, Object\u0026gt;)message); api.request(input, result -\u0026gt; { wrapped.put(\u0026#34;result\u0026#34;, result.toMap()); reply.reply(wrapped); }); } catch (Error | RuntimeException exception) { wrapped.put(\u0026#34;error\u0026#34;, wrapError(exception)); reply.reply(wrapped); } }); } else { channel.setMessageHandler(null); } } { 配置处理方式\nclass NetworkPlugin : FlutterPlugin, Messages.NativeNetworkApi { /// The MethodChannel that will the communication between Flutter and native Android  ///  /// This local reference serves to register the plugin with the Flutter Engine and unregister it  /// when the Flutter Engine is detached from the Activity  override fun onAttachedToEngine(@NonNull flutterPluginBinding: FlutterPlugin.FlutterPluginBinding) { Messages.NativeNetworkApi.setup(flutterPluginBinding.binaryMessenger, this) } override fun onDetachedFromEngine(@NonNull flutterPluginBinding: FlutterPlugin.FlutterPluginBinding) { Messages.NativeNetworkApi.setup(flutterPluginBinding.binaryMessenger, null) } override fun request(requestParams: Messages.RequestParams, result: Messages.Result\u0026lt;Messages.Resource\u0026gt;) { result.success(resource) } @async关键字 Client端 Future\u0026lt;Resource\u0026gt; request(RequestParams arg) async { Server端 sync时生成的server端handler直接代理到接口实现进行方法调用，无法异步，必须阻塞platform thread\nRequestParams input = RequestParams.fromMap((Map\u0026lt;String, Object\u0026gt;)message); Resource output = api.request(input); wrapped.put(\u0026#34;result\u0026#34;, output.toMap()); reply.reply(wrapped); async时server端handler方法签名多一个参数Result，利用回调实现异步\npublic interface Result\u0026lt;T\u0026gt; { void success(T result); } RequestParams input = RequestParams.fromMap((Map\u0026lt;String, Object\u0026gt;)message); api.request(input, result -\u0026gt; { wrapped.put(\u0026#34;result\u0026#34;, result.toMap()); reply.reply(wrapped); }); Pigeon原理 https://github.com/flutter/packages/blob/master/packages/pigeon/doc\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/qigsaw/qigsaw/",
	"title": "Qigsaw",
	"tags": [],
	"description": "",
	"content": "爱奇艺重磅开源基于Android-App-Bundle动态化方案Qigsaw\nSplit APKs 加载\n应用进程所使用到的 ClassLoader 和 Resources 均在LoadedAPK中创建。\n通过 Android 9.0 LoadedAPK源码片段，我们一起了解下 Split APKs 加载过程。\nClassLoader 创建 通过createOrUpdateClassLoaderLocked方法名，可以知道该方法是用于创建和更新 ClassLoader。该方法有两个核心步骤。\n1：如果mClassLoader为空，则创建 PathClassLoader 实例。\n2：如果addedPaths不为空，则更新 PathClassLoader 实例。\n该方法指明，应用进程是可以动态加载 Split APKs 代码。\nResources 创建 通过getResources方法代码片段，可知 Split APKs 的资源路径作为mResources创建参数。\n关于更多 Split APKs 加载原理细节，请阅读相关 Android 源码。\n第三方应用利用 PackageInstaller 安装 split APKs 体验极其不友好，且某些国产手机对 split APKs 功能支持不完善，所以我们最终还是按照一般插件化方式安装加载 split APKs。\n依据上图，如果需要动态加载 split APKs，需要解决代码、资源以及四大组件的加载。\nSplit APKs 代码加载 针对 splits 代码加载，Qigsaw 采用单类加载器方式，即 base APK 和 split APKs 采用同一 ClassLoader 加载。\n在 DexPathList 中，为每个 split 创建对应的Element和NativeLibraryElement实例即可。关于单类加载器更多细节，本文不再赘述，相关原理已非常成熟。\nSplit APKs 资源加载。 Splits 资源加载相较于代码加载会复杂，因为不同系统版本或不同手机厂商都会存在一些兼容性问题。\nAndroid Gradle Plugin 在资源打包时，会对res目录下资源文件分配一个唯一 Id。\nId 前两位PP为 Package Id，代表应用类型。是系统应用、第三方应用、Instant App 或 Dynamic Feature 等。\nId 中间两位TT为 Type，代表资源类型。是 drawable、layout 或 string 等。\nId 后四位EE为 Entry，代表该资源顺序。\n所有第三方应用 base APK 资源 Package Id 均为 7F，Android App Bundle 对 splits 资源打包时会基于 7F 依次递减分配 Package Id。因此，即使我们将 split APKs 资源添加到当前应用 Resources 实例中，也不会出现资源冲突问题，splits 访问 base 资源也更加方便。\nQigsaw 提供loadResources方法加载 split APKs 资源。为避免开发者写大量模板代码，Qigsaw 打包插件采用字节码操作方式自动写入该方法。\nSplit APKs 四大组件加载 Android App Bundle 在 Manifest 文件合并过程中，会将 split APKs manifest 文件内容合并至 base APK 中。因此，所有 split APKs 四大组件信息都是已经声明在 base APK 中。\nAndroid App Bundle 这种处理方式不支持 Manifest 更新，例如新增四大组件，所以 Qigsaw 也不支持新增四大组件。在正常开发迭代过程中，动态新增 splits 四大组件需求极少，所以 Qigsaw 与 Android App Bundle 特性保持一致。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/qigsaw/",
	"title": "qigsaw",
	"tags": [],
	"description": "",
	"content": "qigsaw 探索总结qigsaw知识\n Qigsaw     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/compose/recomposition/",
	"title": "ReComposition",
	"tags": [],
	"description": "",
	"content": "类设计 GeneratedClass JetnewsApp传递ComposableLambdaImpl:AppContent{}给JetnewsTheme @Composable fun JetnewsApp( appContainer: AppContainer, navigationViewModel: NavigationViewModel ) { //调用方法JetnewsTheme,并将AppContent闭包作为composableLambda传递给JetnewsTheme  JetnewsTheme { //每个调用位置都有一个特殊的key，这里是-819895379  AppContent( navigationViewModel = navigationViewModel, interestsRepository = appContainer.interestsRepository, postsRepository = appContainer.postsRepository ) } } @Composable fun JetnewsTheme( darkTheme: Boolean = isSystemInDarkTheme(), content: @Composable () -\u0026gt; Unit ) {......} public final class JetnewsAppKt { public static final void JetnewsApp(AppContainer appContainer, NavigationViewModel navigationViewModel, Composer $composer, int $changed) { int i;...... Composer $composer2 = $composer.startRestartGroup(1936574869, \u0026#34;C(JetnewsApp)35@1302L232:JetnewsApp.kt#x6nqmx\u0026#34;); if (($changed \u0026amp; 14) == 0) { i = ($composer2.changed(appContainer) ? 4 : 2) | $changed; } else { i = $changed; } if (($changed \u0026amp; 112) == 0) { i |= $composer2.changed(navigationViewModel) ? 32 : 16; } if (((i \u0026amp; 91) ^ 18) != 0 || !$composer2.getSkipping()) { ThemeKt.JetnewsTheme(false, ComposableLambdaKt.composableLambda($composer2, -819895379, true, \u0026#34;C36@1325L203:JetnewsApp.kt#x6nqmx\u0026#34;, new JetnewsAppKt$JetnewsApp$1(appContainer, navigationViewModel, i)), $composer2, 48, 1); } else { $composer2.skipToGroupEnd(); } ScopeUpdateScope endRestartGroup = $composer2.endRestartGroup(); if (endRestartGroup != null) { endRestartGroup.updateScope(new JetnewsAppKt$JetnewsApp$2(appContainer, navigationViewModel, $changed)); } } final class JetnewsAppKt$JetnewsApp$1 extends Lambda implements Function2\u0026lt;Composer, Integer, Unit\u0026gt; { public final void invoke(Composer $composer, int $changed) { if ((($changed \u0026amp; 11) ^ 2) != 0 || !$composer.getSkipping()) { InterestsRepository interestsRepository = this.$appContainer.getInterestsRepository(); JetnewsAppKt.access$AppContent(this.$navigationViewModel, this.$appContainer.getPostsRepository(), interestsRepository, $composer, (this.$$dirty \u0026gt;\u0026gt; 3) \u0026amp; 14); return; } $composer.skipToGroupEnd(); } } public final class JetnewsAppKt$JetnewsApp$2 extends Lambda implements Function2\u0026lt;Composer, Integer, Unit\u0026gt; { public final void invoke(Composer composer, int i) { JetnewsAppKt.JetnewsApp(this.$appContainer, this.$navigationViewModel, composer, this.$$changed | 1); } } composableLambda执行闭包 content: @Composable () -\u0026gt; Unit content()//执行ComposableLambdaImpl //ComposableLambdaImpl override operator fun invoke(c: Composer, changed: Int): Any? { val c = c.startRestartGroup(key, sourceInformation) trackRead(c) val dirty = changed or if (c.changed(this)) differentBits(0) else sameBits(0) val result = (_block as (c: Composer, changed: Int) -\u0026gt; Any?)(c, dirty)//main  c.endRestartGroup()?.updateScope(this as (Composer, Int) -\u0026gt; Unit) return result } 闭包执行流程进入了对应的方法调用 本例是AppContent方法\nAppContent( navigationViewModel = navigationViewModel, interestsRepository = appContainer.interestsRepository, postsRepository = appContainer.postsRepository ) @Composable private fun AppContent( navigationViewModel: NavigationViewModel, postsRepository: PostsRepository, interestsRepository: InterestsRepository ) { Crossfade(navigationViewModel.currentScreen) { screen -\u0026gt; //key = -819896238  Surface(color = MaterialTheme.colors.background) { when (screen) { is Screen.Home -\u0026gt; HomeScreen( navigateTo = navigationViewModel::navigateTo, postsRepository = postsRepository ) is Screen.Interests -\u0026gt; InterestsScreen( navigateTo = navigationViewModel::navigateTo, interestsRepository = interestsRepository ) is Screen.Article -\u0026gt; ArticleScreen( postId = screen.postId, postsRepository = postsRepository, onBack = { navigationViewModel.onBack() } ) } } } //$composer是 composerImpl实例,  //$changed运行时为4，也就是0x100,也就是说仅有第一个参数navigationViewModel是可变参数，需要进行数据变化跟踪  public static final void AppContent(NavigationViewModel navigationViewModel, PostsRepository postsRepository, InterestsRepository interestsRepository, Composer $composer, int $changed) { int i; //AppContent的调用处和这里的AppContent方法定义处，都有自己的groupId，并都会进行start和end调用  Composer $composer2 = $composer.startRestartGroup(-194496041, \u0026#34;C(AppContent)P(1,2)50@1711L790:JetnewsApp.kt#x6nqmx\u0026#34;); if (($changed \u0026amp; 14) == 0) { i = ($composer2.changed(navigationViewModel) ? 4 : 2) | $changed; } else { i = $changed; } if (($changed \u0026amp; 112) == 0) { i |= $composer2.changed(postsRepository) ? 32 : 16; } if (($changed \u0026amp; 896) == 0) { i |= $composer2.changed(interestsRepository) ? 256 : 128; } if (((i \u0026amp; 731) ^ 146) != 0 || !$composer2.getSkipping()) { CrossfadeKt.Crossfade(navigationViewModel.getCurrentScreen(), null, null, ComposableLambdaKt.composableLambda($composer2, -819896238, true, \u0026#34;C51@1806L6,51@1776L719:JetnewsApp.kt#x6nqmx\u0026#34;, new JetnewsAppKt$AppContent$1(navigationViewModel, postsRepository, i, interestsRepository)), $composer2, 3584, 6); } else { $composer2.skipToGroupEnd(); } ScopeUpdateScope endRestartGroup = $composer2.endRestartGroup(); if (endRestartGroup != null) { endRestartGroup.updateScope(new JetnewsAppKt$AppContent$2(navigationViewModel, postsRepository, interestsRepository, $changed)); } } @Composable方法体 startRestartGroup /** * A Compose compiler plugin API. DO NOT call directly. * * Called to record a group for a [Composable] function and starts a group that can be * recomposed on demand based on the lambda passed to * [updateScope][ScopeUpdateScope.updateScope] when [endRestartGroup] is called * * @param key An compiler generated key based on the source location of the call. * @param sourceInformation An optional string value to that provides the compose tools enough * information to calculate the source location calls made in the group. * @return the instance of the composer to use for the rest of the function. */ @ComposeCompilerApi override fun startRestartGroup(key: Int, sourceInformation: String?): Composer { start(key, null, false, sourceInformation) addRecomposeScope() return this } start private fun start(key: Int, objectKey: Any?, isNode: Boolean, data: Any?) { // Check for the insert fast path. If we are already inserting (creating nodes) then // there is no need to track insert, deletes and moves with a pending changes object. if (inserting) { reader.beginEmpty() val startIndex = writer.currentGroup when { isNode -\u0026gt; writer.startNode(Composer.Empty) data != null -\u0026gt; writer.startData(key, objectKey ?: Composer.Empty, data) else -\u0026gt; writer.startGroup(key, objectKey ?: Composer.Empty) } enterGroup(isNode, null) return } private fun enterGroup(isNode: Boolean, newPending: Pending?) { // When entering a group all the information about the parent should be saved, to be  // restored when end() is called, and all the tracking counters set to initial state for the  // group.  pendingStack.push(pending) this.pending = newPending this.nodeIndexStack.push(nodeIndex) if (isNode) nodeIndex = 0 this.groupNodeCountStack.push(groupNodeCount) groupNodeCount = 0 } addRecomposeScope private fun addRecomposeScope() { if (inserting) { val scope = RecomposeScopeImpl(this) invalidateStack.push(scope) updateValue(scope) } else { val invalidation = invalidations.removeLocation(reader.parent) val scope = reader.next() as RecomposeScopeImpl scope.requiresRecompose = invalidation != null invalidateStack.push(scope) } } ComposerImpl.changed /** * Determine if the current slot table value is equal to the given value, if true, the value * is scheduled to be skipped during [applyChanges] and [changes] return false; otherwise * [applyChanges] will update the slot table to [value]. In either case the composer\u0026#39;s slot * table is advanced. * * @param value the value to be compared. */ @ComposeCompilerApi override fun changed(value: Any?): Boolean { return if (nextSlot() != value) { updateValue(value) true } else { false } } getSkipping /** * A Compose compiler plugin API. DO NOT call directly. * * Reflects whether the [Composable] function can skip. Even if a [Composable] function is * called with the same parameters it might still need to run because, for example, a new * value was provided for a [CompositionLocal] created by [staticCompositionLocalOf]. */ @ComposeCompilerApi val skipping: Boolean 深度优先Stack结构 graph TB subgraph 深度优先Stack methodA(\u0026quot;methodA-groupA\u0026quot;)--\u0026gt;methodB(\u0026quot;methodB-groupB\u0026quot;) methodA--\u0026gt;methodC(\u0026quot;methodC-groupC\u0026quot;) methodB--\u0026gt;methodD(\u0026quot;methodD-groupD\u0026quot;) methodB--\u0026gt;methodE(\u0026quot;methodE-groupE\u0026quot;) methodB--\u0026gt;methodF(\u0026quot;methodF-groupF\u0026quot;) end subgraph 对应关系 composable--对应---lambdaSubClass--对应---method--对应---group--对应---flutter的widget end endRestartGroup /** * End a restart group. If the recompose scope was marked used during composition then a * [ScopeUpdateScope] is returned that allows attaching a lambda that will produce the same * composition as was produced by this group (including calling [startRestartGroup] and * [endRestartGroup]). */ @ComposeCompilerApi override fun endRestartGroup(): ScopeUpdateScope? { // This allows for the invalidate stack to be out of sync since this might be called during exception stack  // unwinding that might have not called the doneJoin/endRestartGroup in the wrong order.  val scope = if (invalidateStack.isNotEmpty()) invalidateStack.pop() else null scope?.requiresRecompose = false val result = if (scope != null \u0026amp;\u0026amp; (scope.used || collectParameterInformation)) { if (scope.anchor == null) { scope.anchor = if (inserting) { writer.anchor(writer.parent) } else { reader.anchor(reader.parent) } } scope.defaultsInvalid = false scope } else { null } end(isNode = false) return result } updateScope /** RecomposeScopeImpl.kt * Update [block]. The scope is returned by [Composer.endRestartGroup] when [used] is true * and implements [ScopeUpdateScope]. */ override fun updateScope(block: (Composer, Int) -\u0026gt; Unit) { this.block = block } //Composer /** * A Compose internal property. DO NOT call directly. Use [currentRecomposeScope] instead. * * The invalidation current invalidation scope. An new invalidation scope is created whenever * [startRestartGroup] is called. when this scope\u0026#39;s [RecomposeScope.invalidate] is called * then lambda supplied to [endRestartGroup]\u0026#39;s [ScopeUpdateScope] will be scheduled to be * run. */ @InternalComposeApi val recomposeScope: RecomposeScope? composableLambda ComposableLambda.kt\n@Suppress(\u0026#34;unused\u0026#34;) @ComposeCompilerApi fun composableLambda( composer: Composer, key: Int, tracked: Boolean, sourceInformation: String?, block: Any ): ComposableLambda { composer.startReplaceableGroup(key) val slot = composer.rememberedValue() val result = if (slot === Composer.Empty) { val value = ComposableLambdaImpl(key, tracked, sourceInformation) composer.updateRememberedValue(value) value } else { slot as ComposableLambdaImpl } result.update(block) composer.endReplaceableGroup() return result } ReCompose 图解 runRecomposeAndApplyChanges过程\nsequenceDiagram RecomposeScopeImpl-\u0026gt;\u0026gt;RecomposeScopeImpl: invalidate AndroidUiFrameClock-\u0026gt;\u0026gt;AndroidUiFrameClock:withFrameNanos Note right of AndroidUiFrameClock: suspendCancellableCoroutine AndroidUiFrameClock-\u0026gt;\u0026gt;AndroidUiDispatcher:postFrameCallback(callback) Note right of AndroidUiDispatcher: 通过Choreographer注册Vsync AndroidUiDispatcher-\u0026gt;\u0026gt;AndroidUiDispatcher: dispatchCallback.doFrame AndroidUiDispatcher-\u0026gt;\u0026gt;AndroidUiFrameClock: toRun[i].doFrame(frameTimeNanos) Note right of AndroidUiFrameClock: 恢复suspendCancellableCoroutine挂起的协程 AndroidUiFrameClock-\u0026gt;\u0026gt;AndroidUiFrameClock: performRecompose AndroidUiFrameClock-\u0026gt;\u0026gt;RecomposeScopeImpl:compose RecomposeScopeImpl-\u0026gt;\u0026gt;RecomposeScopeImpl: block?.invoke(composer, 1) Note right of RecomposeScopeImpl: 该block为上次composition时通过updateScope设置进来的block也就是lambdaSubClass AndroidUiFrameClock-\u0026gt;\u0026gt;ComposerImpl: applyChanges ComposerImpl-\u0026gt;\u0026gt;ComposerImpl:slotTable.write runRecomposeAndApplyChanges\u0026hellip;recompositionRunner suspend fun runRecomposeAndApplyChanges() = recompositionRunner { parentFrameClock -\u0026gt; ...... private val knownCompositions = mutableListOf\u0026lt;ControlledComposition\u0026gt;() private suspend fun recompositionRunner( block: suspend CoroutineScope.(parentFrameClock: MonotonicFrameClock) -\u0026gt; Unit ) { try { // Invalidate all registered composers when we start since we weren\u0026#39;t observing  // snapshot changes on their behalf. Assume anything could have changed.  synchronized(stateLock) { knownCompositions.fastForEach { it.invalidateAll() } // Don\u0026#39;t need to deriveStateLocked here; invalidate will do it if needed.  } coroutineScope { block(parentFrameClock) } CompositonImpl.invalidateAll override fun invalidateAll() { synchronized(lock) { composer.invalidateAll() } } ComposerImpl.invalidateAll /** * Invalidate all known RecomposeScopes. Used by [Recomposer] to bring known composers * back into a known good state after a period of time when snapshot changes were not * being observed. */ internal fun invalidateAll() { slotTable.slots.forEach { (it as? RecomposeScopeImpl)?.invalidate() } } RecomposeScopeImpl.invalidate override fun invalidate() { invalidateForResult() } fun invalidateForResult(): InvalidationResult = (composer as? ComposerImpl)?.invalidate(this) ?: InvalidationResult.IGNORED ComposerImpl.invalidate internal fun invalidate(scope: RecomposeScopeImpl): InvalidationResult { if (scope.defaultsInScope) { scope.defaultsInvalid = true } val anchor = scope.anchor ...... parentContext.invalidate(composition) return if (isComposing) InvalidationResult.DEFERRED else InvalidationResult.SCHEDULED } CompositionContextImpl.invalidate private inner class CompositionContextImpl( override val compoundHashKey: Int, override val collectingParameterInformation: Boolean ) : CompositionContext() { override fun invalidate(composition: ControlledComposition) { parentContext.invalidate(this@ComposerImpl.composition) parentContext.invalidate(composition) } ReComposer.invalidate internal override fun invalidate(composition: ControlledComposition) { synchronized(stateLock) { if (composition !in compositionInvalidations) { compositionInvalidations += composition deriveStateLocked() } else null }?.resume(Unit) } Choreographer private static final class CallbackRecord { public CallbackRecord next; public long dueTime; public Object action; // Runnable or FrameCallback  public Object token; public void run(long frameTimeNanos) { if (token == FRAME_CALLBACK_TOKEN) { ((FrameCallback)action).doFrame(frameTimeNanos);//main  } else { ((Runnable)action).run(); } } } AndroidUiDispatcher.dispatchCallback.doFrame class AndroidUiDispatcher private constructor( val choreographer: Choreographer, private val handler: android.os.Handler ) : CoroutineDispatcher() { private var toRunOnFrame = mutableListOf\u0026lt;Choreographer.FrameCallback\u0026gt;() private val dispatchCallback = object : Choreographer.FrameCallback, Runnable { override fun doFrame(frameTimeNanos: Long) { handler.removeCallbacks(this) performTrampolineDispatch() performFrameDispatch(frameTimeNanos)//main  } } } private fun performFrameDispatch(frameTimeNanos: Long) { val toRun = synchronized(lock) { if (!scheduledFrameDispatch) return scheduledFrameDispatch = false val result = toRunOnFrame toRunOnFrame = spareToRunOnFrame spareToRunOnFrame = result result } for (i in 0 until toRun.size) { // This callback will not and must not throw, see AndroidUiFrameClock  toRun[i].doFrame(frameTimeNanos)//main  } toRun.clear() } AndroidUiFrameClock\u0026hellip;resumeWith class AndroidUiFrameClock( val choreographer: Choreographer ) : androidx.compose.runtime.MonotonicFrameClock { override suspend fun \u0026lt;R\u0026gt; withFrameNanos( onFrame: (Long) -\u0026gt; R ): R { val uiDispatcher = coroutineContext[ContinuationInterceptor] as? AndroidUiDispatcher return suspendCancellableCoroutine { co -\u0026gt; // Important: this callback won\u0026#39;t throw, and AndroidUiDispatcher counts on it.  val callback = Choreographer.FrameCallback { frameTimeNanos -\u0026gt; co.resumeWith(runCatching { onFrame(frameTimeNanos) }) } // If we\u0026#39;re on an AndroidUiDispatcher then we post callback to happen *after*  // the greedy trampoline dispatch is complete.  // This means that onFrame will run on the current choreographer frame if one is  // already in progress, but withFrameNanos will *not* resume until the frame  // is complete. This prevents multiple calls to withFrameNanos immediately dispatching  // on the same frame.  if (uiDispatcher != null \u0026amp;\u0026amp; uiDispatcher.choreographer == choreographer) { uiDispatcher.postFrameCallback(callback) co.invokeOnCancellation { uiDispatcher.removeFrameCallback(callback) } } else { choreographer.postFrameCallback(callback) co.invokeOnCancellation { choreographer.removeFrameCallback(callback) } } } } } runRecomposeAndApplyChanges\u0026hellip;performRecompose suspend fun runRecomposeAndApplyChanges() = recompositionRunner { parentFrameClock -\u0026gt; val toRecompose = mutableListOf\u0026lt;ControlledComposition\u0026gt;() val toApply = mutableListOf\u0026lt;ControlledComposition\u0026gt;() while (shouldKeepRecomposing) { awaitWorkAvailable() // Don\u0026#39;t await a new frame if we don\u0026#39;t have frame-scoped work  if ( synchronized(stateLock) { if (!hasFrameWorkLocked) { recordComposerModificationsLocked() !hasFrameWorkLocked } else false } ) continue parentFrameClock.withFrameNanos { frameTime -\u0026gt; trace(\u0026#34;recomposeFrame\u0026#34;) { ...... // Drain any composer invalidations from snapshot changes and record  // composers to work on  synchronized(stateLock) { recordComposerModificationsLocked() compositionInvalidations.fastForEach { toRecompose += it } compositionInvalidations.clear() } // Perform recomposition for any invalidated composers  val modifiedValues = IdentityArraySet\u0026lt;Any\u0026gt;() try { toRecompose.fastForEach { composer -\u0026gt; //main  performRecompose(composer, modifiedValues)?.let { toApply += it } } if (toApply.isNotEmpty()) changeCount++ } finally { toRecompose.clear() } // Perform apply changes  try { toApply.fastForEach { composition -\u0026gt; composition.applyChanges() } } finally { toApply.clear() } recomposer.performRecompose private fun performRecompose( composition: ControlledComposition, modifiedValues: IdentityArraySet\u0026lt;Any\u0026gt;? ): ControlledComposition? { if (composition.isComposing || composition.isDisposed) return null return if ( composing(composition, modifiedValues) { modifiedValues?.forEach { composition.recordWriteOf(it) } composition.recompose()//main  } ) composition else null } CompositionImpl.recompose override fun recompose(): Boolean = synchronized(lock) { drainPendingModificationsForCompositionLocked() //main  composer.recompose().also { shouldDrain -\u0026gt; // Apply would normally do this for us; do it now if apply shouldn\u0026#39;t happen.  if (!shouldDrain) drainPendingModificationsLocked() } } ComposerImpl.recompose internal fun recompose(): Boolean { check(changes.isEmpty()) { \u0026#34;Expected applyChanges() to have been called\u0026#34; } if (invalidations.isNotEmpty()) { trace(\u0026#34;Compose:recompose\u0026#34;) { nodeIndex = 0 var complete = false val wasComposing = isComposing isComposing = true try { startRoot() skipCurrentGroup()//main  endRoot() complete = true override fun skipCurrentGroup() { if (invalidations.isEmpty()) { skipGroup() } else { val reader = reader val key = reader.groupKey val dataKey = reader.groupObjectKey updateCompoundKeyWhenWeEnterGroup(key, dataKey) startReaderGroup(reader.isNode, null) recomposeToGroupEnd()//main  reader.endGroup() updateCompoundKeyWhenWeExitGroup(key, dataKey) } } /** * Recompose any invalidate child groups of the current parent group. This should be called * after the group is started but on or before the first child group. It is intended to be * called instead of [skipReaderToGroupEnd] if any child groups are invalid. If no children * are invalid it will call [skipReaderToGroupEnd]. */ private fun recomposeToGroupEnd() { var firstInRange = invalidations.firstInRange(reader.currentGroup, end) while (firstInRange != null) { ..... firstInRange.scope.compose(this)//main  RecomposeScopeImpl.compose fun compose(composer: Composer) { block?.invoke(composer, 1) ?: error(\u0026#34;Invalid restart scope\u0026#34;)//这里的block为前一次composition时通过updateScope设置进来的block也就是lambdaSubClass } CompositionImpl.applyChanges override fun applyChanges() { synchronized(lock) { composer.applyChanges() drainPendingModificationsLocked() } } ComposerImpl.applyChanges internal fun applyChanges() { trace(\u0026#34;Compose:applyChanges\u0026#34;) { val invalidationAnchors = slotTable.read { reader -\u0026gt; invalidations.map { reader.anchor(it.location) to it } } val manager = RememberEventDispatcher(abandonSet) try { applier.onBeginChanges() // Apply all changes  slotTable.write { slots -\u0026gt; val applier = applier changes.forEach { change -\u0026gt; change(applier, slots, manager)//main  } changes.clear() } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/apm/resource/",
	"title": "resource",
	"tags": [],
	"description": "",
	"content": "resource 探索总结resource知识\n MatrixResourcePlugin     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/tinker/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/resource.arsc%E7%94%9F%E6%88%90%E5%92%8C%E7%BB%93%E6%9E%84/",
	"title": "Resource.arsc生成和结构",
	"tags": [],
	"description": "",
	"content": "从资源ID获取字符串资源 String appName = getResources().getString(R.string.app_name); 从资源ID获取drawable资源的过程 Drawable drawable = getResources().getDrawable(R.drawable.background, getTheme()); 研究源码来源 tinker gradle plugin中的resourceParser ResDiffDecoder\u0026ndash;AbstractApkParser\u0026ndash;ResourceTableParser\nAbstractApkParser.parseResourceTable private DexClass[] dexClasses; private ResourceTable resourceTable; private String manifestXml; private ApkMeta apkMeta; private Set\u0026lt;Locale\u0026gt; locales; private List\u0026lt;CertificateMeta\u0026gt; certificateMetaList; private static final Locale DEFAULT_LOCALE; private Locale preferredLocale; public void parseResourceTable() throws IOException { byte[] data = this.getFileData(\u0026#34;resources.arsc\u0026#34;); if (data == null) { this.resourceTable = new ResourceTable(); this.locales = Collections.emptySet(); } else { this.resourceTable = new ResourceTable(); this.locales = Collections.emptySet(); ByteBuffer buffer = ByteBuffer.wrap(data); ResourceTableParser resourceTableParser = new ResourceTableParser(buffer); resourceTableParser.parse(); this.resourceTable = resourceTableParser.getResourceTable(); this.locales = resourceTableParser.getLocales(); } } AndroidParser.resourceTableLogicalChange public static boolean resourceTableLogicalChange(Configuration config) throws IOException { ApkParser parser = new ApkParser(config.mOldApkFile); ApkParser newParser = new ApkParser(config.mNewApkFile); parser.parseResourceTable(); newParser.parseResourceTable(); return parser.getResourceTable().equals(newParser.getResourceTable()); } ResourceTable设计 graph LR resourceTableParser--\u0026gt;resourceTable--\u0026gt;ResourcePackage1--\u0026gt;typeStringPool resourceTable--\u0026gt;ResourcePackage2 resourceTable--\u0026gt;ResourcePackage3 ResourcePackage1--\u0026gt;keyStringPool ResourcePackage1--\u0026gt;TypeSpec1 ResourcePackage1--\u0026gt;TypeSpec2 ResourcePackage1--\u0026gt;TypeSpec3 ResourcePackage1--\u0026gt;ListType1(\u0026quot;ListTypeConfig1\u0026quot;) ResourcePackage1--\u0026gt;ListType2(\u0026quot;ListTypeConfig2\u0026quot;) ResourcePackage1--\u0026gt;ListType3(\u0026quot;ListTypeConfig3\u0026quot;) ListType1--\u0026gt;Type1 Type1--\u0026gt;ResourceEntry1--\u0026gt;ResourceValue1 Type1--\u0026gt;ResourceEntry2--\u0026gt;ResourceValue2 Type1--\u0026gt;ResourceEntry3--\u0026gt;ResourceValue3 ListType1--\u0026gt;Type2 ListType1--\u0026gt;Type3 ChunkHeader设计 classDiagram class ChunkHeader { -int chunkType; -int headerSize; -long chunkSize; } class ResourceTableHeader { -long packageCount; } class StringPoolHeader { -long stringCount; -long styleCount; -long flags; -long stringsStart; -long stylesStart; } class PackageHeader { -long id; -String name; -long typeStrings; -long lastPublicType; -long keyStrings; -long lastPublicKey; } class TypeSpecHeader { -short id; -short res0; -int res1; -long entryCount; } class TypeHeader { -short id; -short res0; -int res1; -long entryCount; -long entriesStart; -ResTableConfig config; -long startPoint; } ChunkHeader\u0026lt;|--ResourceTableHeader ChunkHeader\u0026lt;|--StringPoolHeader ChunkHeader\u0026lt;|--PackageHeader ChunkHeader\u0026lt;|--TypeSpecHeader ChunkHeader\u0026lt;|--TypeHeader ResourceTableParser private ByteOrder byteOrder; private StringPool stringPool; private ByteBuffer buffer; private ResourceTable resourceTable; private List\u0026lt;ResourceTableParser.FlagsOffset\u0026gt; mFlagsOffsets; private Set\u0026lt;Locale\u0026gt; locales; public void parse() { ResourceTableHeader resourceTableHeader = (ResourceTableHeader)this.readChunkHeader();//1  this.stringPool = ParseUtils.readStringPool(this.buffer, (StringPoolHeader)this.readChunkHeader());//2  this.resourceTable = new ResourceTable(); this.resourceTable.setFileSize((long)this.buffer.array().length); this.resourceTable.setStringPool(this.stringPool); PackageHeader packageHeader = (PackageHeader)this.readChunkHeader();//3  for(int i = 0; (long)i \u0026lt; resourceTableHeader.getPackageCount(); ++i) { Pair\u0026lt;ResourcePackage, PackageHeader\u0026gt; pair = this.readPackage(packageHeader);//main  this.resourceTable.addPackage((ResourcePackage)pair.getLeft()); packageHeader = (PackageHeader)pair.getRight();//下一个package的Header  } this.resourceTable.setBuffers(this.buffer); } private ChunkHeader readChunkHeader() { long begin = (long)this.buffer.position(); int chunkType = Buffers.readUShort(this.buffer); int headerSize = Buffers.readUShort(this.buffer); long chunkSize = Buffers.readUInt(this.buffer); switch(chunkType) { case 0: default: throw new ParserException(\u0026#34;Unexpected chunk Type: 0x\u0026#34; + Integer.toHexString(chunkType)); case 1: StringPoolHeader stringPoolHeader = new StringPoolHeader(chunkType, headerSize, chunkSize); stringPoolHeader.setStringCount(Buffers.readUInt(this.buffer)); stringPoolHeader.setStyleCount(Buffers.readUInt(this.buffer)); stringPoolHeader.setFlags(Buffers.readUInt(this.buffer)); stringPoolHeader.setStringsStart(Buffers.readUInt(this.buffer)); stringPoolHeader.setStylesStart(Buffers.readUInt(this.buffer)); this.buffer.position((int)(begin + (long)headerSize));//main  return stringPoolHeader; case 2: ResourceTableHeader resourceTableHeader = new ResourceTableHeader(chunkType, headerSize, chunkSize); resourceTableHeader.setPackageCount(Buffers.readUInt(this.buffer)); this.buffer.position((int)(begin + (long)headerSize));//main  return resourceTableHeader; ............ ResourceTable private Map\u0026lt;Short, ResourcePackage\u0026gt; packageMap = new HashMap(); private Map\u0026lt;String, ResourcePackage\u0026gt; packageNameMap = new HashMap(); private ByteBuffer buffer; private StringPool stringPool; private long fileSize; public static Map\u0026lt;Integer, String\u0026gt; sysStyle = ResourceLoader.loadSystemStyles(); ResourcePackage private String name; private short id; private StringPool typeStringPool; private StringPool keyStringPool; private Map\u0026lt;Short, TypeSpec\u0026gt; typeSpecMap = new HashMap(); private Map\u0026lt;String, TypeSpec\u0026gt; typeSpecNameMap = new HashMap(); private Map\u0026lt;Short, List\u0026lt;Type\u0026gt;\u0026gt; typesMap = new HashMap(); private Map\u0026lt;String, List\u0026lt;Type\u0026gt;\u0026gt; typesNameMap = new HashMap(); TypeSpec private long[] entryFlags; private String name; private short id; Type private String name; private short id; private TypeHeader typeHeader; private Locale locale; private ResTableConfig config; private StringPool keyStringPool; private ByteBuffer buffer; private long[] offsets; private StringPool stringPool; private ResourceTable resourceTable; private HashMap\u0026lt;Integer, ResourceEntry\u0026gt; resourceEntryHashMap = new HashMap(); private HashMap\u0026lt;String, ResourceEntry\u0026gt; resourceEntryNameHashMap = new HashMap(); ResourceEntry private int size; private int flags; private String key; private ResourceValue value; private Type type; ResourceValue protected final int value; protected int size; protected short dataType; AAPT Source 源文件：android\\frameworks\\base\\tools\\aapt(2)\\main.cpp int main(int argc, char* const argv[]) 源文件：android\\frameworks\\base\\tools\\aapt(2)\\AaptAssets.cpp Parser http://androidxref.com/7.0.0_r1/xref/frameworks/base/tools/aapt2/unflatten/BinaryResourceParser.cpp\nhttp://androidxref.com/7.0.0_r1/xref/frameworks/base/tools/aapt2/unflatten/ResChunkPullParser.cpp#27\nAndroid 9.0上位于 appt2/format/binary/.cpp\nFile Format Chunk Header in every Chunk Resources.arsc文件格式是由一系列的chunk构成,每一个chunk均包含如下结构的ResChunk_header,用来描述这个chunk的基本信息\ntype：是当前这个chunk的类型\nheaderSize：是当前这个chunk的头部大\nsize：是当前这个chunk的大小\nRES_TABLE_TYPE Resources.arsc文件的第一个结构是资源索引表头部。其结构如下,描述了Resources.arsc文件的大小和资源包数量。\n**header：就是标准的Chunk头部信息格式****\n**packageCount：被编译的资源包的个数****\nAndroid中一个apk可能包含多个资源包，默认情况下都只有一个就是应用的包名所在的资源包\n图中蓝色高亮的部分就是资源索引表头部。通过解析,我们可以得到如下信息,这个chunk的类型为RES_TABLE_TYPE,头部大小为0XC,整个chunk的大小为1400252byte,有一个编译好的资源包。\nRES_STRING_POOL_TYPE 紧跟着资源索引表头部的是资源项的值字符串资源池,这个字符串资源池包含了所有的在资源包里面所定义的资源项的值字符串\n*header：标准的Chunk头部信息结构*\n*stringCount：字符串的个数*\n**styleCount：字符串样式的个数****\n**flags：字符串的属性,可取值包括0x000(UTF-16),0x001(字符串经过排序)、0X100(UTF-8)和他们的组合值****\n**stringStart：字符串内容块相对于其头部的距离****\n**stylesStart：字符串样式块相对于其头部的距离****\n*实例：*\n图中绿色高亮的部分就是字符串资源池头部,通过解析,我们可以得到如下信息,这个chunk的类型为RES_STRING_POOL_TYPE,即字符串资源池。头部大小为0X1C,整个chunk的大小为369524byte,有8073条字符串,72个字符串样式,为UTF-8编码,无排序,字符串内容块相对于此chunk头部的偏移为0X7F60,字符串样式块相对于此chunk头部的偏移为0X5A054。 紧接着头部的的是两个偏移数组，分别是字符串偏移数组和字符串样式偏移数组。这两个偏移数组的大小分别等于stringCount和styleCount的值，而每一个元素的类型都是无符号整型。整个字符中资源池结构如下。\n字符串资源池中的字符串前两个字节为字符串长度,长度计算方法如下。另外如果字符串编码格式为UTF-8则字符串以0X00作为结束符,UTF-16则以0X0000作为结束符。 len = (((hbyte \u0026amp; 0x7F) \u0026laquo; 8)) | lbyte; 字符串与字符串样式有一一对应的关系,也就是说如果第n个字符串有样式,则它的样式描述位于样式块的第n个元素。 字符串样式的结构包括如下两个结构体,ResStringPool_ref和ResStringPool_span。 一个字符串可以对应多个ResStringPool_span和一个ResStringPool_ref。ResStringPool_span在前描述字符串的样式,ResStringPool_ref在后固定值为0XFFFFFFFF作为占位符。样式块最后会以两个值为0XFFFFFFFF的ResStringPool_ref作为结束。\n*实例：*\n图中蓝色高亮的部分就是样式内容块,按照格式解析可以得出,第一个字符串和第二字符串无样式,第三个字符串第4个字符到第7个字符的位置样式为字符串资源池中0X1F88的字符,以此类推。\nRES_TABLE_PACKAGE_TYPE 接着资源项的值字符串资源池后面的部分就是Package数据块,这个数据块记录编译包的元数据\n**header：Chunk的头部信息数据结构****\n*id：包的ID,等于Package Id,一般用户包的值Package Id为0X7F,系统资源包的Package Id为0X01；这个值很重要的，在后面我们构建前面说到的那个public.xml中的id值的时候需要用到。*\n*name：包名*\n*typeString：类型字符串资源池相对头部的偏移*\n*lastPublicType：最后一个导出的Public类型字符串在类型字符串资源池中的索引，目前这个值设置为类型字符串资源池的元素个数。在解析的过程中没发现他的用途*\n*keyStrings：资源项名称字符串相对头部的偏移*\n*lastPublicKey：最后一个导出的Public资源项名称字符串在资源项名称字符串资源池中的索引，目前这个值设置为资源项名称字符串资源池的元素个数。在解析的过程中没发现他的用途*\n*实例：*\n图中紫色高亮的部分就是ResTable_package,按照上面的格式解析数据,我们可以得出,此Chunk的Type为RES_TABLE_PACKAGE_TYPE,头部大小为0X120,整个chunk的大小为1030716byte,Package Id为0X7F,包名称为co.runner.app,类型字符串资源池距离头部的偏移是0X120,有15条字符串,资源项名称字符串资源池0X1EC,有6249条字符串。 Packege数据块的整体结构,可以用以下的示意图表示：\n其中Type String Pool和Key String Pool是两个字符串资源池,结构和资源项的值字符串资源池结构相同,分别对应类型字符串资源池和资源项名称字符串资源池。 再接下来的结构体可能是类型规范数据块或者类型资源项数据块,我们可以通过他们的Type来识别,类型规范数据块的Type为RES_TABLE_TYPE_SPEC_TYPE,类型资源项数据块的Type为RES_TABLE_TYPE_TYPE。\nRES_TABLE_TYPE_SPEC_TYPE 类型规范数据块用来描述资源项的配置差异性。通过这个差异性描述，我们就可以知道每一个资源项的配置状况。知道了一个资源项的配置状况之后，Android资源管理框架在检测到设备的配置信息发生变化之后，就可以知道是否需要重新加载该资源项。类型规范数据块是按照类型来组织的，也就是说，每一种类型都对应有一个类型规范数据块\n**header：Chunk的头部信息结构****\n*id：标识资源的Type ID,Type ID是指资源的类型ID。资源的类型有animator、anim、color、drawable、layout、menu、raw、string和xml等等若干种，每一种都会被赋予一个ID。*\n*res0：保留,始终为0*\n*res1：保留,始终为0*\n**entryCount：等于本类型的资源项个数,指名称相同的资源项的个数。****\n实例：\n图中绿色高亮的部分就是ResTable_typeSpec,按照上面的格式解析数据,我们可以得出,此Chunk的Type为RES_TABLE_TYPE_SPEC_TYPE,头部大小为0X10,整个chunk的大小为564byte,资源ID为1,本类型资源项数量为137。 ResTable_typeSpec后面紧跟着的是一个大小为entryCount的uint32_t数组，每一个数组元素都用来描述一个资源项的配置差异性的。\nRES_TABLE_TYPE_TYPE 类型资源项数据块用来描述资源项的具体信息, 这样我们就可以知道每一个资源项的名称、值和配置等信息。 类型资源项数据同样是按照类型和配置来组织的,也就是说,一个具有n个配置的类型一共对应有n个类型资源项数据块。\n**header：Chunk的头部信息结构****\n*id：标识资源的Type ID*\n*res0：保留,始终为0*\n*res1：保留,始终为0*\n*entryCount：等于本类型的资源项个数,指名称相同的资源项的个数。*\n*entriesStart：等于资源项数据块相对头部的偏移值。*\n*resConfig：指向一个ResTable_config,用来描述配置信息,地区,语言,分辨率等*\n*实例：*\n图中红色高亮的部分就是ResTable_type,按照上面的格式解析数据,我们可以得出,RES_TABLE_TYPE_TYPE,头部大小为0X44,整个chunk的大小为4086byte,资源ID为1,本类型资源项数量为137,资源数据块相对于头部的偏移为0X268。 ResTable_type后接着是一个大小为entryCount的uint32_t数组，每一个数组元素都用来描述一个资源项数据块的偏移位置。 紧跟在这个偏移数组后面的是一个大小为entryCount的ResTable_entry数组,每一个数组元素都用来描述一个资源项的具体信息。\nstruct ResTable_entry ResTable_entry根据flags的不同,后面跟随的数据也不相同,如果flags此位为1,则ResTable_entry是ResTable_map_entry,ResTable_map_entry继承自ResTable_entry,其结构如下。\nstruct ResTable_map_entry ResTable_map_entry其后跟随则count个ResTable_map类型的数组,ResTable_map的结构如下：\nstruct ResTable_map *实例：*\n图中颜色由深到浅就是一个完整的flags为1的资源项,现在就一起来解读这段数据的含义,这个资源项头部的大小为0X10,flags为1所以后面跟随的是ResTable_map数组,名称没有在资源项引用池中,没有父map_entry,有一个ResTable_map。 如果flags此位为0,则ResTable_entry其后跟随的是一个Res_value,描述一个普通资源的值,Res_value结构如下。\nstruct Res_value *size：ResValue的头部大小*\n*res0：保留，始终为0*\n*dataType：数据的类型,可以从上面的枚举类型中获取*\n*data：数据对应的索引*\n这里我们看到了有一个转化的方法，这个我们在解析AndroidManifest文件的时候也用到了这个方法。\n*实例：*\n图中画红线的部分就是一个ResTable_entry其后跟随的是一个Res_value的例子,从中我们可以得出以下信息,这个头部大小为8,flags等于0,所以后面跟随的是Res_value,在资源项名称字符串资源池中的索引为150,对应的值是badge_continue_months,Res_value的大小为8,数据的类型是TYPE_STRING,在资源项的值字符串资源池的索引为1912,对应的值是res/drawable-nodpi-v4/badge_continue_months.png。\n参考 Android 应用资源表(resources.arsc)解析\u0026ndash;aapt\nResource.arsc文件解析\nAndroid逆向之旅\u0026mdash;解析编译之后的Resource.arsc文件格式\n通过ApkTool分析resources.arsc文件以及resources.arsc文件的格式\n一文读懂resource.arsc文件结构\nAndroid6.0之App中的资源查找过程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/alloc_gc/runtime_visitroots/",
	"title": "Runtime_VisitRoots",
	"tags": [],
	"description": "",
	"content": "art/runtime/runtime.cc\nRuntime::VisitRoots void Runtime::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) { VisitNonConcurrentRoots(visitor, flags); VisitConcurrentRoots(visitor, flags); } VisitNonConcurrentRoots void Runtime::VisitNonConcurrentRoots(RootVisitor* visitor, VisitRootFlags flags) { VisitThreadRoots(visitor, flags); VisitNonThreadRoots(visitor); } VisitThreadRoots void Runtime::VisitThreadRoots(RootVisitor* visitor, VisitRootFlags flags) { thread_list_-\u0026gt;VisitRoots(visitor, flags); } art/runtime/thread_list.cc\nThreadList::VisitRoots void ThreadList::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) const { MutexLock mu(Thread::Current(), *Locks::thread_list_lock_); for (const auto\u0026amp; thread : list_) { thread-\u0026gt;VisitRoots(visitor, flags); } } art/runtime/thread.cc\nThread::VisitRoots void Thread::VisitRoots(RootVisitor* visitor, VisitRootFlags flags) { if ((flags \u0026amp; VisitRootFlags::kVisitRootFlagPrecise) != 0) { VisitRoots\u0026lt;/* kPrecise */ true\u0026gt;(visitor); } else { VisitRoots\u0026lt;/* kPrecise */ false\u0026gt;(visitor); } } //define the meaning of enum RootType template \u0026lt;bool kPrecise\u0026gt; void Thread::VisitRoots(RootVisitor* visitor) { const pid_t thread_id = GetThreadId(); visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.opeer, RootInfo(kRootThreadObject, thread_id)); if (tlsPtr_.exception != nullptr \u0026amp;\u0026amp; tlsPtr_.exception != GetDeoptimizationException()) { visitor-\u0026gt;VisitRoot(reinterpret_cast\u0026lt;mirror::Object**\u0026gt;(\u0026amp;tlsPtr_.exception), RootInfo(kRootNativeStack, thread_id)); } if (tlsPtr_.async_exception != nullptr) { visitor-\u0026gt;VisitRoot(reinterpret_cast\u0026lt;mirror::Object**\u0026gt;(\u0026amp;tlsPtr_.async_exception), RootInfo(kRootNativeStack, thread_id)); } visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;tlsPtr_.monitor_enter_object, RootInfo(kRootNativeStack, thread_id)); tlsPtr_.jni_env-\u0026gt;VisitJniLocalRoots(visitor, RootInfo(kRootJNILocal, thread_id)); tlsPtr_.jni_env-\u0026gt;VisitMonitorRoots(visitor, RootInfo(kRootJNIMonitor, thread_id)); HandleScopeVisitRoots(visitor, thread_id); if (tlsPtr_.debug_invoke_req != nullptr) { tlsPtr_.debug_invoke_req-\u0026gt;VisitRoots(visitor, RootInfo(kRootDebugger, thread_id)); } ...... // Visit roots on this thread\u0026#39;s stack  RuntimeContextType context; RootCallbackVisitor visitor_to_callback(visitor, thread_id); ReferenceMapVisitor\u0026lt;RootCallbackVisitor, kPrecise\u0026gt; mapper(this, \u0026amp;context, visitor_to_callback); mapper.template WalkStack\u0026lt;StackVisitor::CountTransitions::kNo\u0026gt;(false); for (instrumentation::InstrumentationStackFrame\u0026amp; frame : *GetInstrumentationStack()) { visitor-\u0026gt;VisitRootIfNonNull(\u0026amp;frame.this_object_, RootInfo(kRootVMInternal, thread_id)); } } VisitNonThreadRoots void Runtime::VisitNonThreadRoots(RootVisitor* visitor) { java_vm_-\u0026gt;VisitRoots(visitor); sentinel_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); pre_allocated_OutOfMemoryError_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); pre_allocated_NoClassDefFoundError_.VisitRootIfNonNull(visitor, RootInfo(kRootVMInternal)); verifier::MethodVerifier::VisitStaticRoots(visitor); VisitTransactionRoots(visitor); } VisitConcurrentRoots void Runtime::VisitConcurrentRoots(RootVisitor* visitor, VisitRootFlags flags) { intern_table_-\u0026gt;VisitRoots(visitor, flags); class_linker_-\u0026gt;VisitRoots(visitor, flags); heap_-\u0026gt;VisitAllocationRecords(visitor); if ((flags \u0026amp; kVisitRootFlagNewRoots) == 0) { // Guaranteed to have no new roots in the constant roots.  VisitConstantRoots(visitor); } Dbg::VisitRoots(visitor); } art/runtime/gc_root.h\nRootType enum RootType { kRootUnknown = 0, kRootJNIGlobal, kRootJNILocal, kRootJavaFrame, kRootNativeStack, kRootStickyClass, //contains mirror class  kRootThreadBlock, kRootMonitorUsed, kRootThreadObject, kRootInternedString, kRootFinalizing, // used for HPROF\u0026#39;s conversion to HprofHeapTag  kRootDebugger, kRootReferenceCleanup, // used for HPROF\u0026#39;s conversion to HprofHeapTag  kRootVMInternal, kRootJNIMonitor, }; art/runtime/gc_root.h\nRootVisitor VisitRootIfNonNull // Single root version, not overridable. ALWAYS_INLINE void VisitRootIfNonNull(mirror::Object** root, const RootInfo\u0026amp; info) REQUIRES_SHARED(Locks::mutator_lock_) { if (*root != nullptr) { VisitRoot(root, info); } } // Single root version, not overridable. ALWAYS_INLINE void VisitRoot(mirror::Object** root, const RootInfo\u0026amp; info) REQUIRES_SHARED(Locks::mutator_lock_) { VisitRoots(\u0026amp;root, 1, info); } SingleRootVisitor // Only visits roots one at a time, doesn\u0026#39;t handle updating roots. Used when performance isn\u0026#39;t critical. class SingleRootVisitor : public RootVisitor { VisitRoots void VisitRoots(mirror::Object*** roots, size_t count, const RootInfo\u0026amp; info) OVERRIDE REQUIRES_SHARED(Locks::mutator_lock_) { for (size_t i = 0; i \u0026lt; count; ++i) { VisitRoot(*roots[i], info); } } art/runtime/jni_env_ext.h\njni_env_ext.h VisitJniLocalRoots void VisitJniLocalRoots(RootVisitor* visitor, const RootInfo\u0026amp; root_info) REQUIRES_SHARED(Locks::mutator_lock_) { locals_.VisitRoots(visitor, root_info); } art/runtime/java_vm_ext.cc\njava_vm_ext.cc VisitRoots void JavaVMExt::VisitRoots(RootVisitor* visitor) { Thread* self = Thread::Current(); ReaderMutexLock mu(self, *Locks::jni_globals_lock_); globals_.VisitRoots(visitor, RootInfo(kRootJNIGlobal)); // The weak_globals table is visited by the GC itself (because it mutates the table). } art/runtime/gc/heap-visit-objects-inl.h\nHeap VisitObjectsPaused template \u0026lt;typename Visitor\u0026gt; inline void Heap::VisitObjectsPaused(Visitor\u0026amp;\u0026amp; visitor) { Thread* self = Thread::Current(); Locks::mutator_lock_-\u0026gt;AssertExclusiveHeld(self); VisitObjectsInternalRegionSpace(visitor); VisitObjectsInternal(visitor); } VisitObjectsInternalRegionSpace // Visit objects in the region spaces. template \u0026lt;typename Visitor\u0026gt; inline void Heap::VisitObjectsInternalRegionSpace(Visitor\u0026amp;\u0026amp; visitor) { region_space_-\u0026gt;Walk(visitor); } VisitObjectsInternal // Visit objects in the other spaces. template \u0026lt;typename Visitor\u0026gt; inline void Heap::VisitObjectsInternal(Visitor\u0026amp;\u0026amp; visitor) { if (bump_pointer_space_ != nullptr) { // Visit objects in bump pointer space.  bump_pointer_space_-\u0026gt;Walk(visitor); } for (auto* it = allocation_stack_-\u0026gt;Begin(), *end = allocation_stack_-\u0026gt;End(); it \u0026lt; end; ++it) { mirror::Object* const obj = it-\u0026gt;AsMirrorPtr(); visitor(obj); } { ReaderMutexLock mu(Thread::Current(), *Locks::heap_bitmap_lock_); GetLiveBitmap()-\u0026gt;Visit\u0026lt;Visitor\u0026gt;(visitor); } art/runtime/gc/accounting/heap_bitmap-inl.h\nHeapBitmap Visit template \u0026lt;typename Visitor\u0026gt; inline void HeapBitmap::Visit(Visitor\u0026amp;\u0026amp; visitor) { for (const auto\u0026amp; bitmap : continuous_space_bitmaps_) { bitmap-\u0026gt;VisitMarkedRange(bitmap-\u0026gt;HeapBegin(), bitmap-\u0026gt;HeapLimit(), visitor); } for (const auto\u0026amp; bitmap : large_object_bitmaps_) { bitmap-\u0026gt;VisitMarkedRange(bitmap-\u0026gt;HeapBegin(), bitmap-\u0026gt;HeapLimit(), visitor); } } art/runtime/mirror/object-refvisitor-inl.h\nObject VisitReferences template \u0026lt;bool kVisitNativeRoots, VerifyObjectFlags kVerifyFlags, ReadBarrierOption kReadBarrierOption, typename Visitor, typename JavaLangRefVisitor\u0026gt; inline void Object::VisitReferences(const Visitor\u0026amp; visitor, const JavaLangRefVisitor\u0026amp; ref_visitor) { ObjPtr\u0026lt;Class\u0026gt; klass = GetClass\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;(); visitor(this, ClassOffset(), false); const uint32_t class_flags = klass-\u0026gt;GetClassFlags\u0026lt;kVerifyNone\u0026gt;(); if (LIKELY(class_flags == kClassFlagNormal)) { DCHECK((!klass-\u0026gt;IsVariableSize\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;())); VisitInstanceFieldsReferences\u0026lt;kVerifyFlags, kReadBarrierOption\u0026gt;(klass, visitor); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/3viewmodel/saveandrestoreinstancestate/",
	"title": "SaveAndRestoreInstanceState",
	"tags": [],
	"description": "",
	"content": "转屏场景 数据保存 android/app/servertransaction/ActivityRelaunchItem.java\n@Override public void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { client.handleRelaunchActivity(mActivityClientRecord, pendingActions); } ActivityThread.handleRelaunchActivity @Override public void handleRelaunchActivity(ActivityClientRecord tmp, PendingTransactionActions pendingActions) { handleRelaunchActivityInner(r, configChanges, tmp.pendingResults, tmp.pendingIntents, pendingActions, tmp.startsNotResumed, tmp.overrideConfig, \u0026#34;handleRelaunchActivity\u0026#34;); } private void handleRelaunchActivityInner(ActivityClientRecord r, int configChanges, List\u0026lt;ResultInfo\u0026gt; pendingResults, List\u0026lt;ReferrerIntent\u0026gt; pendingIntents, PendingTransactionActions pendingActions, boolean startsNotResumed, Configuration overrideConfig, String reason) { // Preserve last used intent, it may be set from Activity#setIntent().  final Intent customIntent = r.activity.mIntent; // Need to ensure state is saved.  if (!r.paused) { performPauseActivity(r, false, reason, null /* pendingActions */); } if (!r.stopped) { callActivityOnStop(r, true /* saveState */, reason); } handleDestroyActivity(r.token, false, configChanges, true, reason);//getNonConfigInstance传递true，非转屏正常启动Activity时传递false  r.activity = null; handleLaunchActivity(r, pendingActions, customIntent); } callActivityOnStop private void callActivityOnStop(ActivityClientRecord r, boolean saveState, String reason) { // Before P onSaveInstanceState was called before onStop, starting with P it\u0026#39;s  // called after. Before Honeycomb state was always saved before onPause.  final boolean shouldSaveState = saveState \u0026amp;\u0026amp; !r.activity.mFinished \u0026amp;\u0026amp; r.state == null \u0026amp;\u0026amp; !r.isPreHoneycomb(); final boolean isPreP = r.isPreP(); if (shouldSaveState \u0026amp;\u0026amp; isPreP) { callActivityOnSaveInstanceState(r); } r.activity.performStop(false /*preserveWindow*/, reason); callActivityOnSaveInstanceState private void callActivityOnSaveInstanceState(ActivityClientRecord r) { r.state = new Bundle(); r.state.setAllowFds(false); mInstrumentation.callActivityOnSaveInstanceState(r.activity, r.state);//r.state记录Bundle这个Parcelable数据 } public void callActivityOnSaveInstanceState(Activity activity, Bundle outState) { activity.performSaveInstanceState(outState); } final void performSaveInstanceState(Bundle outState) { onSaveInstanceState(outState); } 数据恢复 handleStartActivity @Override public void handleStartActivity(ActivityClientRecord r, PendingTransactionActions pendingActions) { activity.performStart(\u0026#34;handleStartActivity\u0026#34;); mInstrumentation.callActivityOnRestoreInstanceState(activity, r.state); } callActivityOnRestoreInstanceState public void callActivityOnRestoreInstanceState(Activity activity, Bundle savedInstanceState) { activity.performRestoreInstanceState(savedInstanceState); } final void performRestoreInstanceState(Bundle savedInstanceState) { onRestoreInstanceState(savedInstanceState); } 其他 ActivityClientRecord /** Activity client record, used for bookkeeping for the real {@link Activity} instance. */ public static final class ActivityClientRecord { public IBinder token; Activity activity; Window window; Activity.NonConfigurationInstances lastNonConfigurationInstances; Bundle state; ...... } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/3viewmodel/savedstatehandle/",
	"title": "SavedStateHandle",
	"tags": [],
	"description": "",
	"content": "原理图 sequenceDiagram ComponentActivity-\u0026gt;\u0026gt;ComponentActivity: onSaveInstanceState activate ComponentActivity ComponentActivity-\u0026gt;\u0026gt;SavedStateRegistryController: performSave activate SavedStateRegistryController SavedStateRegistryController-\u0026gt;\u0026gt;SavedStateRegistry: performSave deactivate SavedStateRegistryController deactivate ComponentActivity ComponentActivity-\u0026gt;\u0026gt;ComponentActivity: onCreate activate ComponentActivity ComponentActivity-\u0026gt;\u0026gt;SavedStateRegistryController: performRestore activate SavedStateRegistryController SavedStateRegistryController-\u0026gt;\u0026gt;SavedStateRegistry: performRestore deactivate SavedStateRegistryController deactivate ComponentActivity SavedStateViewModelFactory-\u0026gt;\u0026gt;SavedStateViewModelFactory: create activate SavedStateViewModelFactory SavedStateViewModelFactory-\u0026gt;\u0026gt;SavedStateHandleController: create SavedStateHandleController-\u0026gt;\u0026gt;SavedStateRegistry: consumeRestoredStateForKey SavedStateRegistry-\u0026gt;\u0026gt;SavedStateHandle: createHandle deactivate SavedStateViewModelFactory Demo // UserProfileViewModel class UserProfileViewModel( savedStateHandle: SavedStateHandle ) : ViewModel() { val userId : String = savedStateHandle[\u0026#34;uid\u0026#34;] ?: throw IllegalArgumentException(\u0026#34;missing user id\u0026#34;) val user : User = TODO() } // UserProfileFragment private val viewModel: UserProfileViewModel by viewModels( factoryProducer = { SavedStateViewModelFactory(this) } //新版这已经是by viewModels的默认factory  ... ) performSave ComponentActivity\n@CallSuper @Override protected void onSaveInstanceState(@NonNull Bundle outState) { Lifecycle lifecycle = getLifecycle(); if (lifecycle instanceof LifecycleRegistry) { ((LifecycleRegistry) lifecycle).setCurrentState(Lifecycle.State.CREATED); } super.onSaveInstanceState(outState); mSavedStateRegistryController.performSave(outState);//main } public void performSave(@NonNull Bundle outBundle) { mRegistry.performSave(outBundle); } void performSave(@NonNull Bundle outBundle) { Bundle components = new Bundle(); if (mRestoredState != null) { components.putAll(mRestoredState); } for (Iterator\u0026lt;Map.Entry\u0026lt;String, SavedStateProvider\u0026gt;\u0026gt; it = mComponents.iteratorWithAdditions(); it.hasNext(); ) { Map.Entry\u0026lt;String, SavedStateProvider\u0026gt; entry1 = it.next(); components.putBundle(entry1.getKey(), entry1.getValue().saveState()); } outBundle.putBundle(SAVED_COMPONENTS_KEY, components); } performRestore ComponentActivity.onSaveInstanceState\nprotected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); mSavedStateRegistryController.performRestore(savedInstanceState); ReportFragment.injectIfNeededIn(this); if (mContentLayoutId != 0) { setContentView(mContentLayoutId); } } public void performRestore(@Nullable Bundle savedState) { Lifecycle lifecycle = mOwner.getLifecycle(); if (lifecycle.getCurrentState() != Lifecycle.State.INITIALIZED) { throw new IllegalStateException(\u0026#34;Restarter must be created only during \u0026#34; + \u0026#34;owner\u0026#39;s initialization stage\u0026#34;); } lifecycle.addObserver(new Recreator(mOwner)); mRegistry.performRestore(lifecycle, savedState); } void performRestore(@NonNull Lifecycle lifecycle, @Nullable Bundle savedState) { if (mRestored) { throw new IllegalStateException(\u0026#34;SavedStateRegistry was already restored.\u0026#34;); } if (savedState != null) { mRestoredState = savedState.getBundle(SAVED_COMPONENTS_KEY); } lifecycle.addObserver(new GenericLifecycleObserver() { @Override public void onStateChanged(LifecycleOwner source, Lifecycle.Event event) { if (event == Lifecycle.Event.ON_START) { mAllowingSavingState = true; } else if (event == Lifecycle.Event.ON_STOP) { mAllowingSavingState = false; } } }); mRestored = true; } 参考 https://developer.android.com/topic/libraries/architecture/viewmodel-savedstate\nSavedStateViewModelFactory public final class SavedStateViewModelFactory extends ViewModelProvider.KeyedFactory { public SavedStateViewModelFactory(@NonNull Application application, @NonNull SavedStateRegistryOwner owner) { this(application, owner, null); } public SavedStateViewModelFactory(@NonNull Application application, @NonNull SavedStateRegistryOwner owner, @Nullable Bundle defaultArgs) { mSavedStateRegistry = owner.getSavedStateRegistry(); mLifecycle = owner.getLifecycle(); mDefaultArgs = defaultArgs; mApplication = application; mFactory = ViewModelProvider.AndroidViewModelFactory.getInstance(application); } } SavedStateRegistryOwner public interface SavedStateRegistryOwner extends LifecycleOwner { @NonNull SavedStateRegistry getSavedStateRegistry(); } ComponentActivity implement SavedStateRegistryOwner\nprivate final SavedStateRegistryController mSavedStateRegistryController = SavedStateRegistryController.create(this); @NonNull @Override public final SavedStateRegistry getSavedStateRegistry() { return mSavedStateRegistryController.getSavedStateRegistry(); } SavedStateRegistryController /** * An API for {@link SavedStateRegistryOwner} implementations to control {@link SavedStateRegistry}. * \u0026lt;p\u0026gt; * {@code SavedStateRegistryOwner} should call {@link #performRestore(Bundle)} to restore state of * {@link SavedStateRegistry} and {@link #performSave(Bundle)} to gather SavedState from it. */ public final class SavedStateRegistryController { private final SavedStateRegistryOwner mOwner; private final SavedStateRegistry mRegistry; private SavedStateRegistryController(SavedStateRegistryOwner owner) { mOwner = owner; mRegistry = new SavedStateRegistry(); } @NonNull public SavedStateRegistry getSavedStateRegistry() { return mRegistry; } SavedStateRegistry /** * An interface for plugging components that consumes and contributes to the saved state. * * \u0026lt;p\u0026gt;This objects lifetime is bound to the lifecycle of owning component: when activity or * fragment is recreated, new instance of the object is created as well. */ public final class SavedStateRegistry { @Nullable private Bundle mRestoredState; private SafeIterableMap\u0026lt;String, SavedStateProvider\u0026gt; mComponents = new SafeIterableMap\u0026lt;\u0026gt;(); public Bundle consumeRestoredStateForKey(@NonNull String key) { if (mRestoredState != null) { Bundle result = mRestoredState.getBundle(key); mRestoredState.remove(key); if (mRestoredState.isEmpty()) { mRestoredState = null; } return result; } return null; } public void registerSavedStateProvider(@NonNull String key, @NonNull SavedStateProvider provider) { SavedStateProvider previous = mComponents.putIfAbsent(key, provider); if (previous != null) { throw new IllegalArgumentException(\u0026#34;SavedStateProvider with the given key is\u0026#34; + \u0026#34; already registered\u0026#34;); } } /** * This interface marks a component that contributes to saved state. */ public interface SavedStateProvider { /** * Called to retrieve a state from a component before being killed * so later the state can be received from {@link #consumeRestoredStateForKey(String)} * * @return S with your saved state. */ @NonNull Bundle saveState(); } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/3viewmodel/savingstates/",
	"title": "SavingStates",
	"tags": [],
	"description": "",
	"content": "SavingStatesScope sequenceDiagram LocalPersistence-\u0026gt;\u0026gt;AMS: user open activity activate AMS AMS-\u0026gt;\u0026gt;ActivityViewModelScope: start activate AMS activate ActivityViewModelScope ActivityViewModelScope-\u0026gt;\u0026gt;Activity: start activate Activity AMS-\u0026gt;\u0026gt;ActivityViewModelScope: rotation/relaunch rect rgb(199, 237, 204) ActivityViewModelScope-\u0026gt;\u0026gt;Activity: rotation/relaunch Activity-\u0026gt;\u0026gt;Activity: destory,retainNonConfigurationInstance deactivate Activity Activity-\u0026gt;\u0026gt;Activity: launch,attach恢复lastNonConfigurationInstances activate Activity deactivate Activity end rect rgb(253, 245, 230) AMS-\u0026gt;\u0026gt;ActivityViewModelScope: killApplicatonOrActivity by system ActivityViewModelScope-\u0026gt;\u0026gt;AMS: onStop,saveInstanceState deactivate ActivityViewModelScope activate AMS deactivate AMS AMS-\u0026gt;\u0026gt;ActivityViewModelScope: restart activate ActivityViewModelScope AMS-\u0026gt;\u0026gt;ActivityViewModelScope: onstart,restoreInstanceState deactivate ActivityViewModelScope end deactivate AMS rect rgb(151,255,255) AMS-\u0026gt;\u0026gt;LocalPersistence: save data to local persistence LocalPersistence-\u0026gt;\u0026gt;AMS: user leave activity deactivate AMS LocalPersistence-\u0026gt;\u0026gt;AMS: next time user open activity activate AMS AMS-\u0026gt;\u0026gt;LocalPersistence: user restore data from local persistence deactivate AMS end options https://developer.android.com/topic/libraries/architecture/saving-states#options\n    ViewModel Saved instance state Persistent storage     Storage location in memory serialized to disk on disk or network   Survives configuration change Yes Yes Yes   Survives system-initiated process death No Yes Yes   Survives user complete activity dismissal/onFinish() No No Yes   Data limitations complex objects are fine, but space is limited by available memory only for primitive types and simple, small objects such as String only limited by disk space or cost / time of retrieval from the network resource   Read/write time quick (memory access only) slow (requires serialization/deserialization and disk access) slow (requires disk access or network transaction)    viewmodel-lifecycle "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/shadow/shadow/",
	"title": "Shadow",
	"tags": [],
	"description": "",
	"content": "Shadow设计 Activity的生命周期问题，大方向的选择 其实我们早就在用一款也是基于代理组件转调插件组件的插件框架了。只不过这款插件框架用到了大量反射使用私有API，眼看着是不可能再Android 9.0上继续使用了。我们也调研了外界口碑最好的RePlugin。所以大概就这两种方向，一是用代理Activity作为壳子注册在宿主中真正运行起来，然后让它持有插件Activity，想办法在收到系统的生命周期方法调用时转调插件Activity的对应生命周期方法。二是Hack修改宿主PathClassLoader，让它能在收到系统查询AndroidManifest中注册的Activity的类时返回插件的Activity类。\n方法二就是RePlugin的关键技术。它利用了JVM的特性。我也不太肯定这算不算是bug，总之ClassLoader的loadClass方法返回的实际类可以和它被要求加载的类名字不一样。举个例子，宿主的AndroidManifest.xml注册一个Activity名叫A，插件里有一个Activity名叫B。宿主代码或者apk中最终是没有A这个类的，只有在AndroidManifest中注册的一个名字而已。当想要加载插件Activity B时，就发出一个启动Activity A的Intent。系统收到这个Intent后会检查宿主安装的AndroidManifest信息，从中确定A是哪个apk安装的，就会找到宿主的PathClassLoader。然后系统就会试图从PathClassLoader中加载A这个类，然后作为Activity类型的对象使用（这很正常）。所以如果我们把宿主的PathClassLoader给Hack了，控制它的加载逻辑，让它收到这个加载调用时实际返回的是插件Activity B的类。由于B也真的是Activity的子类，所以系统拿回去当作Activity类型使用没有任何问题。这里再扩展一下，如果类C继承自类A，在加载C时也会去加载A，如果这时拿B当A返回的话，C收到B之后是会发现B的名字不是A而出错的。关于RePlugin这段关键技术的实现，当时调研时就发现实现的有些麻烦了。RePlugin选择复制一个PathClassLoader，然后替换系统持有的PathClassLoader。所以复制PathClassLoader需要反射使用PathClassLoader的私有API，拿出来它里面的数据，替换系统持有的PathClassLoader也要反射修改私有API。我们当时已经实现了“全动态插件框架”，其中代理壳子Activity的动态化使用的方法也能解决这个问题，我们的选择是在宿主PathClassLoader上给它加一个parent ClassLoader。因为PathClassLoader也是一个有正常“双亲委派”逻辑的ClassLoader，它加载什么类都会先问自己parent ClassLoader先加载。所以我们加上去的这个parent ClassLoader也能完成RePlugin想要做的事。不过我们用它的目的是不希望壳子Activity打包在宿主占用宿主很多方法数，还不能更新。这一点以后可能再单独讲。关于这个替换实现，最近给RePlugin提了一个PR：github.com/Qihoo360/Re… ，有兴趣的同学可以看一下。\nRePlugin的这种方案还有一点非常不适合我们的业务，就是宿主AndroidManifest中注册的“坑位”Activity，就是上面举例的Activity A，是不能同时供多个插件Activity使用的。就是我不能在宿主AndroidManifest中注册一个Activity A，然后让它同时支持插件Activity B和C。这是因为ClassLoader在loadClass的时候，收到的参数只有一个A的类名，我们没有办法传递更多信息，让ClassLoader能在这个loadClass的调用中区分出应该返回B还是应该返回C。所以这种方案需要在宿主中注册大量Activity，这对于我们的宿主来说是不可接受的。而方法一是用代理Activity持有插件Activity转调的方案，就可以在启动代理Activity时通过Intent传递很多参数，代理Activity通过Intent中的参数就能决定该构造一个B还是一个C。这就使得这种方案下壳子是可复用的。\n还有一点就是我们在旧框架上就已经设计了“全动态插件框架”，所以基于方法一的方向上开发新插件框架，我们可以不修改宿主的任何代码，不跟宿主版本就能更新插件框架。关于这一点，后续文章再解析。\n所以我们探索的方向就这样确定在方法一这个方向上了。\n所有的插件框架中，Activity的加载都是这样的，new一个DexClassLoader加载插件apk。然后从插件ClassLoader中load指定的插件Activity名字，newInstance之后强转为Activity类型使用。实际上Android系统自身在启动Activity时也是这样做的。所以这就是插件机制能动态更新Activity的基本原理。\n所以，所有的插件框架在解决的问题都不是如何动态加载类，而是动态加载的Activity没有在AndroidManifest中注册，该如何能正常运行。如果Android系统没有AndroidManifest的限制，那么所有插件框架都没有存在的必要了。因为Java语言本身就支持动态更新实现的能力。\nShadow动态化原理 Shadow的全动态设计原理解析\n打包在宿主中的只有core.common和dynamic.host。其余都是动态加载的，或者编译期的。\n源码中的dynamic-host module中的接口pluginManager，dynamic-loader module,都对自己的能力做了接口抽象，用于运行时加载动态实现\ndynamic-host module中的接口pluginManager在dynamic-manager内进行了实现，具体见\u0026quot;Shadow设计.vsdx\u0026quot;\nContainer动态化 PluginProcessService在void loadRuntime(String uuid)成功加载runtimeapk之后，判断如果加载了新的runtime，会将InstalledApk信息保存到sp。之后hackParentToRuntime时会new RuntimeClassLoader来设置为当前宿主PathClassLoader的parent，这样就可以实现宿主manifest文件中注册的代理容器Activity的动态加载:public class PluginDefaultProxyActivity extends PluginContainerActivity ,其中的@override方法可以不必一次全部实现，可以在业务需要时再添加\n动态化加载manager 参考代码分析\nloadParameters.dependsOn Shadow对插件包管理的设计\nLoadApkBloc:: /** * 加载插件到ClassLoader中. * * @param installedPlugin 已安装（PluginManager已经下载解包）的插件 * @return 加载了插件的ClassLoader */ @Throws(LoadApkException::class) fun loadPlugin(installedApk: InstalledApk, loadParameters: LoadParameters, pluginPartsMap: MutableMap\u0026lt;String, PluginParts\u0026gt;): PluginClassLoader { val apk = File(installedApk.apkFilePath) val odexDir = if (installedApk.oDexPath == null) null else File(installedApk.oDexPath) val dependsOn = loadParameters.dependsOn //Logger类一定打包在宿主中，所在的classLoader即为加载宿主的classLoader  val hostClassLoader: ClassLoader = Logger::class.java.classLoader!! val hostParentClassLoader = hostClassLoader.parent if (dependsOn == null || dependsOn.isEmpty()) { return PluginClassLoader( apk.absolutePath, odexDir, installedApk.libraryPath, hostClassLoader, hostParentClassLoader, loadParameters.hostWhiteList ) } else if (dependsOn.size == 1) { val partKey = dependsOn[0] val pluginParts = pluginPartsMap[partKey] if (pluginParts == null) { throw LoadApkException(\u0026#34;加载\u0026#34; + loadParameters.partKey + \u0026#34;时它的依赖\u0026#34; + partKey + \u0026#34;还没有加载\u0026#34;) } else { return PluginClassLoader( apk.absolutePath, odexDir, installedApk.libraryPath, pluginParts.classLoader, null, loadParameters.hostWhiteList ) } } else { val dependsOnClassLoaders = dependsOn.map { val pluginParts = pluginPartsMap[it] if (pluginParts == null) { throw LoadApkException(\u0026#34;加载\u0026#34; + loadParameters.partKey + \u0026#34;时它的依赖\u0026#34; + it + \u0026#34;还没有加载\u0026#34;) } else { pluginParts.classLoader } }.toTypedArray() val combineClassLoader = CombineClassLoader(dependsOnClassLoaders, hostParentClassLoader) return PluginClassLoader( apk.absolutePath, odexDir, installedApk.libraryPath, combineClassLoader, null, loadParameters.hostWhiteList ) } 参考 Tencent Shadow—零反射全动态Android插件框架正式开源\nhttps://github.com/Tencent/Shadow\nShadow的设计细节将在掘金持续分享\n重磅推荐腾讯自主研发的Android插件框架！\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/shadow/",
	"title": "shadow",
	"tags": [],
	"description": "",
	"content": "shadow 探索总结shadow知识\n Shadow     ShadowPlugin     ShadowSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/shadow/shadowplugin/",
	"title": "ShadowPlugin",
	"tags": [],
	"description": "",
	"content": "ShadowTransform类设计 gradle配置 //Sample-plugin-app中build.gradle中对应的配置，动态生成config.json的一些参数  packagePlugin { pluginTypes { debug { loaderApkConfig = new Tuple2(\u0026#39;sample-loader-debug.apk\u0026#39;, \u0026#39;:sample-loader:assembleDebug\u0026#39;) runtimeApkConfig = new Tuple2(\u0026#39;sample-runtime-debug.apk\u0026#39;, \u0026#39;:sample-runtime:assembleDebug\u0026#39;) pluginApks { pluginApk1 { businessName = \u0026#39;sample-plugin-app\u0026#39; partKey = \u0026#39;sample-plugin-app\u0026#39; buildTask = \u0026#39;:sample-plugin-app:assembleDebug\u0026#39; apkName = \u0026#39;sample-plugin-app-debug.apk\u0026#39; apkPath = \u0026#39;projects/sample/sample-plugin/sample-plugin-app/build/outputs/apk/debug/sample-plugin-app-debug.apk\u0026#39; } } } release { loaderApkConfig = new Tuple2(\u0026#39;sample-loader-release.apk\u0026#39;, \u0026#39;:sample-loader:assembleRelease\u0026#39;) runtimeApkConfig = new Tuple2(\u0026#39;sample-runtime-release.apk\u0026#39;, \u0026#39;:sample-runtime:assembleRelease\u0026#39;) pluginApks { pluginApk1 { businessName = \u0026#39;sample-plugin-app\u0026#39; partKey = \u0026#39;sample-plugin-app\u0026#39; buildTask = \u0026#39;:sample-plugin-app:assembleRelease\u0026#39; apkName = \u0026#39;sample-plugin-app-release.apk\u0026#39; apkPath = \u0026#39;projects/sample/sample-plugin/sample-plugin-app/build/outputs/apk/release/sample-plugin-app-release.apk\u0026#39; } } } } loaderApkProjectPath = \u0026#39;projects/sample/sample-plugin/sample-loader\u0026#39; runtimeApkProjectPath = \u0026#39;projects/sample/sample-plugin/sample-runtime\u0026#39; version = 4 compactVersion = [1, 2, 3] uuidNickName = \u0026#34;1.1.5\u0026#34; ShadowPlugin class ShadowPlugin : Plugin\u0026lt;Project\u0026gt; { override fun apply(project: Project) { val plugin = project.plugins.getPlugin(AppPlugin::class.java) val shadowExtension = project.extensions.create(\u0026#34;shadow\u0026#34;, ShadowExtension::class.java) if (!project.hasProperty(\u0026#34;disable_shadow_transform\u0026#34;)) { plugin.extension.registerTransform(ShadowTransform( project, classPoolBuilder, { shadowExtension.transformConfig.useHostContext } )) } project.extensions.create(\u0026#34;packagePlugin\u0026#34;, PackagePluginExtension::class.java, project) project.afterEvaluate { val packagePlugin = project.extensions.findByName(\u0026#34;packagePlugin\u0026#34;) val extension = packagePlugin as PackagePluginExtension val buildTypes = extension.buildTypes val tasks = mutableListOf\u0026lt;Task\u0026gt;() for (i in buildTypes) { println(\u0026#34;buildTypes = \u0026#34; + i.name) val task = createPackagePluginTask(project, i)//main  tasks.add(task) } if (tasks.isNotEmpty()) { project.tasks.create(\u0026#34;packageAllPlugin\u0026#34;) { it.group = \u0026#34;plugin\u0026#34; it.description = \u0026#34;打包所有插件\u0026#34; }.dependsOn(tasks) } } CreatePackagePluginTask\ninternal fun createPackagePluginTask(project: Project, buildType: PluginBuildType): Task { return project.tasks.create(\u0026#34;package${buildType.name.capitalize()}Plugin\u0026#34;, Zip::class.java) { it.from(pluginFiles, targetConfigFile) val suffix: String? = System.getenv(\u0026#34;PluginSuffix\u0026#34;) if (suffix == null) { it.archiveName = \u0026#34;plugin-${buildType.name}.zip\u0026#34; } else { it.archiveName = \u0026#34;plugin-${buildType.name}-$suffix.zip\u0026#34; } it.destinationDir = File(\u0026#34;${project.rootDir}/build\u0026#34;) } private fun createGenerateConfigTask(project: Project, buildType: PluginBuildType): Task { val task = project.tasks.create(\u0026#34;generate${buildType.name.capitalize()}Config\u0026#34;) { it.group = \u0026#34;plugin\u0026#34; it.description = \u0026#34;生成插件配置文件\u0026#34; it.outputs.file(targetConfigFile) it.outputs.upToDateWhen { false } } .dependsOn(pluginApkTasks) .doLast { println(\u0026#34;generateConfig task begin\u0026#34;) val json = extension.toJson(project, loaderApkName, runtimeApkName, buildType) val bizWriter = BufferedWriter(FileWriter(targetConfigFile)) bizWriter.write(json.toJSONString()) bizWriter.newLine() bizWriter.flush() bizWriter.close() println(\u0026#34;generateConfig task done\u0026#34;) } Extension PackagePluginExtension var loaderApkProjectPath = \u0026#34;\u0026#34; var runtimeApkProjectPath = \u0026#34;\u0026#34; var uuid = \u0026#34;\u0026#34; var version: Int = 0 var uuidNickName = \u0026#34;\u0026#34; var compactVersion: Array\u0026lt;Int\u0026gt; = emptyArray() var buildTypes: NamedDomainObjectContainer\u0026lt;PluginBuildType\u0026gt; constructor(project: Project) { buildTypes = project.container(PluginBuildType::class.java) buildTypes.all { it.pluginApks = project.container(PluginApkConfig::class.java) } } fun pluginTypes(closure: Closure\u0026lt;PluginBuildType\u0026gt;) { buildTypes.configure(closure) } PluginBuildType var name = \u0026#34;\u0026#34; var loaderApkConfig: Tuple2\u0026lt;String, String\u0026gt; = Tuple2(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;) var runtimeApkConfig: Tuple2\u0026lt;String, String\u0026gt; = Tuple2(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;) lateinit var pluginApks: NamedDomainObjectContainer\u0026lt;PluginApkConfig\u0026gt; constructor(name: String) { this.name = name } fun pluginApks(closure: Closure\u0026lt;PluginApkConfig\u0026gt;) { pluginApks.configure(closure) } PluginApkConfig\nvar name = \u0026#34;\u0026#34; var partKey = \u0026#34;\u0026#34; /** \\* 业务名（空字符串表示同宿主相同业务） */ var businessName = \u0026#34;\u0026#34; var apkName = \u0026#34;\u0026#34; var apkPath = \u0026#34;\u0026#34; var buildTask = \u0026#34;\u0026#34; var dependsOn: Array\u0026lt;String\u0026gt; = emptyArray() var hostWhiteList: Array\u0026lt;String\u0026gt; = emptyArray() ShadowExtension shadow { transform { // useHostContext = [\u0026#39;abc\u0026#39;]  } var transformConfig = TransformConfig() fun transform(action: Action\u0026lt;in TransformConfig\u0026gt;) { action.execute(transformConfig) } TransformConfig var useHostContext: Array\u0026lt;String\u0026gt; = emptyArray() "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/shadow/shadowsource/",
	"title": "ShadowSource",
	"tags": [],
	"description": "",
	"content": "Shadow类设计和原理 Shadow核心功能 core层 = manager + loader, dynamic层用来动态化\n打包在宿主中的只有core.common和dynamic.host。其余都是动态加载的，或者编译期的。\nsequenceDiagram Note over Manager: host(位于主进程) Note over Loader: PluginProcessPPS(plugin进程) Manager-\u0026gt;\u0026gt;Manager: Manager动态化:通过接口PluginManager实现 Manager-\u0026gt;\u0026gt;Manager: 下载插件、安装插件,得到LoadParameters Manager-\u0026gt;\u0026gt;Loader: bindService Loader-\u0026gt;\u0026gt;Loader: Loader动态化:通过双向接口HostActivityDelegate和HostActivityDelegator实现 Loader-\u0026gt;\u0026gt;Loader: 将插件免安装的运行起来,代理壳子ContainerActivity需要和PluginActivity通过Loader相互调用 Manager 1：解压zip包到data目录下的指定路径下\n2：解析config.json到PluginConfig\n3：根据插件配置信息插入一组数据到db，返回InstalledPlugin\n4：对runtime和loader两个apk做odex(更新odex信息到数据库，更新part.oDexDir)\n5：对每个插件apk做extractSo(更新信息到数据库，更新part.libraryDir)和odex(更新odex信息到数据库，更新part.oDexDir)\n6：bindPluginProgressService，加载runtime，加载loader，加载plugin，调用loader的convertActivityIntent转换intent为代理容器Activity\n7：正常启动代理容器Activity\nshadow的全动态设计原理解析\nManager的动态化 Shadow的Manager的功能就是管理插件，包括插件的下载逻辑、入口逻辑，预加载逻辑等。反正就是一切还没有进入到Loader之前的所有事情。\n由于Manager就是一个普通类，不是Android系统规定要在Manifest中注册才能使用的类，所以Manager的动态化就是一般性的动态加载实现。\n为了让宿主中的固定代码足够的少，我们给Manager定义的接口就是一个类似传统Main函数的接口。\nvoid enter(Context context, long formId, Bundle bundle, EnterCallback callback); 这就是Manager的唯一方法，宿主中只会调用这个方法。传入当前界面的Context以便打开下一个插件Activity。将所有插件中可能用到的参数通过Bundle传给插件。定义一些fromId，用来让Manager的实现逻辑分辨这一次enter是从哪里来的。实际上在宿主中的每一处enter调用都可以设置不同的fromId，就相当于让Manager知道调用来自宿主中的哪一行代码了。再传入一个EnterCallback供Manager可以返回一个动态加载的View作为插件的Loading View。\nLoader PpsBinder中Loader本身的Binder先通过PPS跨进程通信到Manager进程，从而使Loader的Binder成了跨进程的Binder\nLoader的动态化 Loader就是负责加载插件Activity，然后实现插件Activity的生命周期等功能的那部分核心逻辑了。很多插件框架就只有Loader这部分功能，或者说只开源了Loader这部分功能。一般来说，Loader是宿主到插件的桥梁。比如说我们要在宿主中执行Loader的代码，才能Hack一些系统类，让它们加载插件Activity。或者在宿主中的代理壳子Activity中，也要使用Loader去加载插件Activity完成转调功能。所以通常宿主代码就直接依赖了Loader的代码。这就是为什么其他插件框架都需要将插件框架本身的代码打包在宿主中。\n稍复杂一点的问题就是代理壳子ContainerActivity需要和PluginActivity通过Loader相互调用。所以Shadow应用前面提到的动态化原理时，做了双向的接口，可以看到代码中的HostActivityDelegate和HostActivityDelegator。通过定义出这两个接口，可以避免ContainerActivity和Loader相互加载对方时还需要加载对方所依赖的其他类。定义成接口，就只需要加载这个接口就行了。\n通过这个设计，插件框架的绝大部分需要修改或修复的代码就都可以动态发布了。并且也使得在同一个宿主中可以有多个不同实现的Loader，这样业务就可以针对业务自身的bug修改Loader的代码，不会影响其他业务了。紧急情况下Loader也可以耦合业务逻辑。\n宿主中的公共代码和资源的更新和修复可行性方案 graph LR subgraph 插件自带动态加载能力,可以更新功能,修复问题 宿主(\u0026quot;宿主(包含公共仓库资源)\u0026quot;)--\u0026gt;插件1,通过配置whiteList访问宿主公共资源 宿主--\u0026gt;插件2 宿主--\u0026gt;插件3 end 1：利用热修复方案如Tinker中的java修复部分替换宿主dex elements(atlas的host更新也使用的类似修复方案)，资源更新也采用相应的热修复方式进行\n2：将公共代码和资源从组件做成插件，动态加载：\n参考DynamicPluginLoader:\nval coreLoaderFactory = mDynamicLoaderClassLoader.getInterface( CoreLoaderFactory::class.java, CORE_LOADER_FACTORY_IMPL_NAME ) mPluginLoader = coreLoaderFactory.build(hostContext) DelegateProviderHolder.setDelegateProvider(mPluginLoader) 通过注入的方式将loader中的接口实现动态注入到runtime模块(loader依赖runtime)，用来动态的实现DelegateProvider接口\nHostUiLayerProvider 也是类似的注入依赖思想，依赖倒置，控制反转\n类似manager的加载方式？Or使用插件间dependOn的方式？\nManager方式适用于仅仅java代码的动态化，dependOn也可以拓展支持资源\n参考rePlugin的方式：\n//WebViewActivity  // 从WebView插件获取WebrViewPage的代理  WebPageProxy viewProxy = WebPageProxy.create(this); View contentView = viewProxy.getView(); 实际使用方式：基础插件启动后将自己注入给宿主，之后宿主和业务插件都能够使用这个接口的动态实现：\n本方案的问题：\n2.1：基础仓库的代码迁移成本，基础仓库需要抽象出对外暴露的接口\n2.2：基础组件间的相互依赖关系处理：\n将所有基础仓库统一到一个对外仓库，只用动态加载那个仓库\n2.3：对测试和发版流程影响很大，基础插件和业务插件之间的多对多关系复杂\n2.4：性能，基础插件的加载时提前于其他业务的，因此dex2oat过程的耗时很关键\n3：保底方案是宿主没有动态更新能力，一旦公共仓库有bug或有新功能，必须发版\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%AD%98%E5%82%A8/sharedpreferences/sharedpreferences/",
	"title": "SharedPreferences",
	"tags": [],
	"description": "",
	"content": "1、加载/初始化 维护spName\u0026ndash;\u0026gt;file,file\u0026ndash;\u0026gt;sharedPreferencesImpl两个ArrayMap内存缓存 ContextImpl.java\n@Override public SharedPreferences getSharedPreferences(String name, int mode) { File file; synchronized (ContextImpl.class) { if (mSharedPrefsPaths == null) { mSharedPrefsPaths = new ArrayMap\u0026lt;\u0026gt;(); } file = mSharedPrefsPaths.get(name); if (file == null) { file = getSharedPreferencesPath(name); mSharedPrefsPaths.put(name, file); } } return getSharedPreferences(file, mode); } @Override public SharedPreferences getSharedPreferences(File file, int mode) { SharedPreferencesImpl sp; synchronized (ContextImpl.class) { final ArrayMap\u0026lt;File, SharedPreferencesImpl\u0026gt; cache = getSharedPreferencesCacheLocked(); sp = cache.get(file); if (sp == null) { checkMode(mode); sp = new SharedPreferencesImpl(file, mode); cache.put(file, sp); return sp; } } return sp; } SharedPreferencesImpl构造方法切子线程loadFromDisk,得到Map\u0026lt;String, Object\u0026gt; mMap SharedPreferencesImpl.java\nSharedPreferencesImpl(File file, int mode) { mFile = file; mBackupFile = makeBackupFile(file); mMode = mode; mLoaded = false; mMap = null; mThrowable = null; startLoadFromDisk(); } private void startLoadFromDisk() { new Thread(\u0026#34;SharedPreferencesImpl-load\u0026#34;) { public void run() { loadFromDisk(); } }.start(); } private void loadFromDisk() { synchronized (mLock) { if (mLoaded) { return; } if (mBackupFile.exists()) { mFile.delete(); mBackupFile.renameTo(mFile); } } str = new BufferedInputStream(new FileInputStream(mFile), 16 * 1024); map = (Map\u0026lt;String, Object\u0026gt;) XmlUtils.readMapXml(str); synchronized (mLock) { mLoaded = true; mThrowable = thrown; // It\u0026#39;s important that we always signal waiters, even if we\u0026#39;ll make  // them fail with an exception. The try-finally is pretty wide, but  // better safe than sorry.  try { mMap = map; } catch (Throwable t) { mThrowable = t; } finally { mLock.notifyAll(); } } edit: wait util loaded @Override public Editor edit() { // TODO: remove the need to call awaitLoadedLocked() when  // requesting an editor. will require some work on the  // Editor, but then we should be able to do:  //  // context.getSharedPreferences(..).edit().putString(..).apply()  //  // ... all without blocking.  synchronized (mLock) { awaitLoadedLocked(); } return new EditorImpl(); } awaitLoadedLocked @GuardedBy(\u0026#34;mLock\u0026#34;) private void awaitLoadedLocked() { while (!mLoaded) { try { mLock.wait(); } catch (InterruptedException unused) { } } } putXxx: mModified.put(key, value) @Override public Editor putString(String key, @Nullable String value) { synchronized (mEditorLock) { mModified.put(key, value); return this; } } getXXX() 导致ANR public String getString(String key, @Nullable String defValue) { synchronized (mLock) { awaitLoadedLocked(); String v = (String)mMap.get(key); return v != null ? v : defValue; } } 2、编辑提交 2.1、 commit()流程 @Override public boolean commit() { MemoryCommitResult mcr = commitToMemory(); SharedPreferencesImpl.this.enqueueDiskWrite(mcr, null /* sync write on this thread okay */); try { mcr.writtenToDiskLatch.await(); } catch (InterruptedException e) { return false; } notifyListeners(mcr); return mcr.writeToDiskResult; } 2.1.1 commitToMemory // Returns true if any changes were made  private MemoryCommitResult commitToMemory() { long memoryStateGeneration; List\u0026lt;String\u0026gt; keysModified = null; Set\u0026lt;OnSharedPreferenceChangeListener\u0026gt; listeners = null; Map\u0026lt;String, Object\u0026gt; mapToWriteToDisk; synchronized (SharedPreferencesImpl.this.mLock) { mapToWriteToDisk = mMap; synchronized (mEditorLock) { for (Map.Entry\u0026lt;String, Object\u0026gt; e : mModified.entrySet()) { String k = e.getKey(); Object v = e.getValue(); // \u0026#34;this\u0026#34; is the magic value for a removal mutation. In addition,  // setting a value to \u0026#34;null\u0026#34; for a given key is specified to be  // equivalent to calling remove on that key.  if (v == this || v == null) { if (!mapToWriteToDisk.containsKey(k)) { continue; } mapToWriteToDisk.remove(k); } else { if (mapToWriteToDisk.containsKey(k)) { Object existingValue = mapToWriteToDisk.get(k); if (existingValue != null \u0026amp;\u0026amp; existingValue.equals(v)) { continue; } } mapToWriteToDisk.put(k, v); } changesMade = true; } return new MemoryCommitResult(memoryStateGeneration, keysModified, listeners, mapToWriteToDisk); } } 2.2.2 enqueueDiskWrite private void enqueueDiskWrite(final MemoryCommitResult mcr, final Runnable postWriteRunnable) { final boolean isFromSyncCommit = (postWriteRunnable == null); final Runnable writeToDiskRunnable = new Runnable() { @Override public void run() { synchronized (mWritingToDiskLock) { writeToFile(mcr, isFromSyncCommit); } synchronized (mLock) { mDiskWritesInFlight--; } if (postWriteRunnable != null) { postWriteRunnable.run(); } } }; // Typical #commit() path with fewer allocations, doing a write on  // the current thread.  if (isFromSyncCommit) { boolean wasEmpty = false; synchronized (mLock) { wasEmpty = mDiskWritesInFlight == 1; } if (wasEmpty) { writeToDiskRunnable.run(); return; } } QueuedWork.queue(writeToDiskRunnable, !isFromSyncCommit);//add to sWork  } QueuedWork.queue  当apply()方式提交的时候，默认消息会延迟发送100毫秒，避免频繁的磁盘写入操作。 当commit()方式，调用QueuedWork的queue()时，会立即向handler()发送Message。  /** Delay for delayed runnables, as big as possible but low enough to be barely perceivable */ private static final long DELAY = 100; public static void queue(Runnable work, boolean shouldDelay) { Handler handler = getHandler(); synchronized (sLock) { sWork.add(work); if (shouldDelay \u0026amp;\u0026amp; sCanDelay) { handler.sendEmptyMessageDelayed(QueuedWorkHandler.MSG_RUN, DELAY); } else { handler.sendEmptyMessage(QueuedWorkHandler.MSG_RUN); } } } getHandler /** * Lazily create a handler on a separate thread. */ private static Handler getHandler() { synchronized (sLock) { if (sHandler == null) { HandlerThread handlerThread = new HandlerThread(\u0026#34;queued-work-looper\u0026#34;, Process.THREAD_PRIORITY_FOREGROUND); handlerThread.start(); sHandler = new QueuedWorkHandler(handlerThread.getLooper()); } return sHandler; } } private static class QueuedWorkHandler extends Handler { static final int MSG_RUN = 1; QueuedWorkHandler(Looper looper) { super(looper); } public void handleMessage(Message msg) { if (msg.what == MSG_RUN) { processPendingWork(); } } } processPendingWork private static void processPendingWork() { long startTime = 0; synchronized (sProcessingWork) { LinkedList\u0026lt;Runnable\u0026gt; work; synchronized (sLock) { work = (LinkedList\u0026lt;Runnable\u0026gt;) sWork.clone(); sWork.clear(); // Remove all msg-s as all work will be processed now  getHandler().removeMessages(QueuedWorkHandler.MSG_RUN); } if (work.size() \u0026gt; 0) { for (Runnable w : work) { w.run(); } } } } writeToFile private void writeToFile(MemoryCommitResult mcr, boolean isFromSyncCommit) { boolean fileExists = mFile.exists(); // Rename the current file so it may be used as a backup during the next read  if (fileExists) { boolean backupFileExists = mBackupFile.exists(); if (!backupFileExists) { if (!mFile.renameTo(mBackupFile)) { Log.e(TAG, \u0026#34;Couldn\u0026#39;t rename file \u0026#34; + mFile + \u0026#34; to backup file \u0026#34; + mBackupFile); mcr.setDiskWriteResult(false, false); return; } } else { mFile.delete(); } } // Attempt to write the file, delete the backup and return true as atomically as  // possible. If any exception occurs, delete the new file; next time we will restore  // from the backup.  try { FileOutputStream str = createFileOutputStream(mFile); XmlUtils.writeMapXml(mcr.mapToWriteToDisk, str); FileUtils.sync(str); str.close(); // Writing was successful, delete the backup file if there is one.  mBackupFile.delete(); mcr.setDiskWriteResult(true, true); void setDiskWriteResult(boolean wasWritten, boolean result) { this.wasWritten = wasWritten; writeToDiskResult = result; writtenToDiskLatch.countDown(); } 2.2、 apply()流程 public void apply() { final MemoryCommitResult mcr = commitToMemory(); final Runnable awaitCommit = new Runnable() { @Override public void run() { try { mcr.writtenToDiskLatch.await(); } catch (InterruptedException ignored) { } } }; QueuedWork.addFinisher(awaitCommit); Runnable postWriteRunnable = new Runnable() { @Override public void run() { awaitCommit.run(); QueuedWork.removeFinisher(awaitCommit); } }; SharedPreferencesImpl.this.enqueueDiskWrite(mcr, postWriteRunnable); notifyListeners(mcr); } apply 接口整体的详细设计思路如下图（基于 Android8.0 及以下版本分析）：\n尽管 Google 官方在 Android 8.0 及以后版本对 sp 写入逻辑进行优化，期望是在上述步骤 6 中 UI 线程不是傻傻的等，而是帮助子线程一起写入，但是由于是保守协助，并没有很好的解决这个问题。\n2.3 主线程堵塞ANR 为了保证异步任务及时完成，当生命周期处于 handleStopService() 、handlePauseActivity() 、 handleStopActivity() 的时候会调用QueuedWork.waitToFinish() 会等待写入任务执行完毕。\nwaitToFinish，processPendingWork  You don\u0026rsquo;t need to worry about Android component lifecycles and their interaction with apply() writing to disk. The framework makes sure in-flight disk writes from apply() complete before switching states.\n //QueuedWork.java  /** * Trigger queued work to be processed immediately. The queued work is processed on a separate * thread asynchronous. While doing that run and process all finishers on this thread. The * finishers can be implemented in a way to check weather the queued work is finished. * * Is called from the Activity base class\u0026#39;s onPause(), after BroadcastReceiver\u0026#39;s onReceive, * after Service command handling, etc. (so async work is never lost) */ public static void waitToFinish() { processPendingWork();//write to disk and run postWriteRunnable, will block main thread  while (true) { Runnable finisher; synchronized (sLock) { finisher = sFinishers.poll(); } finisher.run(); } } waitToFinish()会将，储存在QueuedWork的操作一并处理掉。什么时候呢？在Activiy的 onPause()、BroadcastReceiver的onReceive()以及Service的onStartCommand()方法之前都会调用waitToFinish()。大家知道这些方法都是执行在主线程中，一旦waitToFinish()执行超时，就会抛出ANR。\n至于waitToFinish调用具体时机，查看ActivityThread.java类文件。这里只是说本质原理\n线程安全 多操作线程安全 为了保证SharedPreferences是线程安全的，Google的设计者一共使用了3把锁：\n对于简单的 读操作 而言，我们知道其原理是读取内存中mMap的值并返回，那么为了保证线程安全，只需要加一把锁保证mMap的线程安全即可：\nmMap相关的mLock锁 public String getString(String key, @Nullable String defValue) { synchronized (mLock) { String v = (String)mMap.get(key); return v != null ? v : defValue; } } 写操作线程安全 对于写操作而言，每次putXXX()并不能立即更新在mMap中，这是理所当然的，如果开发者没有调用apply()方法，那么这些数据的更新理所当然应该被抛弃掉，但是如果直接更新在mMap中，那么数据就难以恢复。\n因此，Editor本身也应该持有一个mEditorMap对象，用于存储数据的更新；只有当调用apply()时，才尝试将mEditorMap与mMap进行合并，以达到数据更新的目的。\n因此，这里我们还需要另外一把锁保证mEditorMap的线程安全，笔者认为，不和mMap公用同一把锁的原因是，在apply()被调用之前，getXXX和putXXX理应是没有冲突的。\n代码实现参考如下：\nEditorImpl相关的mEditorLock锁 public final class EditorImpl implements Editor { @Override public Editor putString(String key, String value) { synchronized (mEditorLock) { mEditorMap.put(key, value); return this; } } } 而当真正需要执行apply()进行写操作时，mEditorMap与mMap进行合并，这时必须通过2把锁保证mEditorMap与mMap的线程安全，保证mMap最终能够更新成功，最终向对应的xml文件中进行更新。\n文件的更新理所当然也需要加一把锁：\n写文件时的锁mWritingToDiskLock // SharedPreferencesImpl.EditorImpl.enqueueDiskWrite() synchronized (mWritingToDiskLock) { writeToFile(mcr, isFromSyncCommit); } 最终，我们一共通过使用了3把锁，对整个写操作的线程安全进行了保证。\n 篇幅限制，本文不对源码进行详细引申，有兴趣的读者可参考 SharedPreferencesImpl.EditorImpl 类的apply()源码。\n 3、跨进程操作的解决方案 //ContextImpl private void checkMode(int mode) { if (getApplicationInfo().targetSdkVersion \u0026gt;= Build.VERSION_CODES.N) { if ((mode \u0026amp; MODE_WORLD_READABLE) != 0) { throw new SecurityException(\u0026#34;MODE_WORLD_READABLE no longer supported\u0026#34;); } if ((mode \u0026amp; MODE_WORLD_WRITEABLE) != 0) { throw new SecurityException(\u0026#34;MODE_WORLD_WRITEABLE no longer supported\u0026#34;); } } } Andorid 7.0及以上会抛出异常，Sharepreferences不再支持多进程模式。多进程共享文件会出现问题的本质在于，因为不同进程，所以线程同步会失效。要解决这个问题，可尝试跨进程解决方案，如ContentProvider、AIDL、AIDL、Service。\n4、替代方案 MMKV Jetpack DataStore 5、 小结 通过本文我们了解了SharedPreferences的基本原理。再回头看看文章开头的那几个问题，是不是有答案了。\n commit()方法和apply()方法的区别：commit()方法是同步的有返回结果，同步保证使用Countdownlatch，即使同步但不保证往磁盘的写入是发生在当前线程的。apply()方法是异步的具体发生在QueuedWork中，里面维护了一个单线程去执行磁盘写入操作。 commit()和apply()方法其实都是Block主线程。commit()只要在主线程调用就会堵塞主线程;apply（）方法磁盘写入操作虽然是异步的，但是当组件(Activity Service BroadCastReceiver)这些系统组件特定状态转换的时候，会把QueuedWork中未完成的那些磁盘写入操作放在主线程执行，且如果比较耗时会产生ANR。 跨进程操作，需要借助Android平台常规的IPC手段（如，AIDL ContentProvider等来封装一层sp数据处理流程）来完成。 替代解决方案:看4。  6. 参考 SharedPreferences灵魂拷问之原理\n官方也无力回天？“SharedPreferences 存在什么问题？”\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%AD%98%E5%82%A8/sharedpreferences/",
	"title": "sharedpreferences",
	"tags": [],
	"description": "",
	"content": "sharedpreferences 探索总结sharedpreferences知识\n SharedPreferences     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/thread/stacktraceelement/",
	"title": "StackTraceElement",
	"tags": [],
	"description": "",
	"content": "9.0.0_r3\nThrowable.getStackTrace public StackTraceElement[] getStackTrace() { return getOurStackTrace().clone(); } private synchronized StackTraceElement[] getOurStackTrace() { // Initialize stack trace field with information from // backtrace if this is the first call to this method // // Android-changed: test explicitly for equality with // STACK_TRACE_ELEMENT if (stackTrace == libcore.util.EmptyArray.STACK_TRACE_ELEMENT || (stackTrace == null \u0026amp;\u0026amp; backtrace != null) /* Out of protocol state */) { stackTrace = nativeGetStackTrace(backtrace);//main  backtrace = null; } return stackTrace; } /art/runtime/native/java_lang_Throwable.cc\nnamespace art { static jobjectArray Throwable_nativeGetStackTrace(JNIEnv* env, jclass, jobject javaStackState) { ScopedFastNativeObjectAccess soa(env); return Thread::InternalStackTraceToStackTraceElementArray(soa, javaStackState); } Thread.getStackTrace public StackTraceElement[] getStackTrace() { StackTraceElement ste[] = VMStack.getThreadStackTrace(this); return ste != null ? ste : EmptyArray.STACK_TRACE_ELEMENT; } 61 /** 62 * Retrieves the stack trace from the specified thread. 63 * 64 * @param t 65 * thread of interest 66 * @return an array of stack trace elements, or null if the thread 67 * doesn′t have a stack trace (e.g. because it exited) 68 */ 69 @FastNative 70 native public static StackTraceElement[] getThreadStackTrace(Thread t); static jobjectArray VMStack_getThreadStackTrace(JNIEnv* env, jclass, jobject javaThread) { ScopedFastNativeObjectAccess soa(env); auto fn = [](Thread* thread, const ScopedFastNativeObjectAccess\u0026amp; soaa) REQUIRES_SHARED(Locks::mutator_lock_) -\u0026gt; jobject { return thread-\u0026gt;CreateInternalStackTrace\u0026lt;false\u0026gt;(soaa); }; jobject trace = GetThreadStack(soa, javaThread, fn); if (trace == nullptr) { return nullptr; } return Thread::InternalStackTraceToStackTraceElementArray(soa, trace); } /art/runtime/thread.cc\nThread::InternalStackTraceToStackTraceElementArray jobjectArray Thread::InternalStackTraceToStackTraceElementArray( const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, jobject internal, jobjectArray output_array, int* stack_depth) { // Decode the internal stack trace into the depth, method trace and PC trace.  // Subtract one for the methods and PC trace.  int32_t depth = soa.Decode\u0026lt;mirror::Array\u0026gt;(internal)-\u0026gt;GetLength() - 1; ClassLinker* const class_linker = Runtime::Current()-\u0026gt;GetClassLinker(); jobjectArray result; if (output_array != nullptr) { // Reuse the array we were given.  result = output_array; // ...adjusting the number of frames we\u0026#39;ll write to not exceed the array length.  const int32_t traces_length = soa.Decode\u0026lt;mirror::ObjectArray\u0026lt;mirror::StackTraceElement\u0026gt;\u0026gt;(result)-\u0026gt;GetLength(); depth = std::min(depth, traces_length); } else { // Create java_trace array and place in local reference table  mirror::ObjectArray\u0026lt;mirror::StackTraceElement\u0026gt;* java_traces = class_linker-\u0026gt;AllocStackTraceElementArray(soa.Self(), depth); if (java_traces == nullptr) { return nullptr; } result = soa.AddLocalReference\u0026lt;jobjectArray\u0026gt;(java_traces); } if (stack_depth != nullptr) { *stack_depth = depth; } for (int32_t i = 0; i \u0026lt; depth; ++i) { ObjPtr\u0026lt;mirror::ObjectArray\u0026lt;mirror::Object\u0026gt;\u0026gt; decoded_traces = soa.Decode\u0026lt;mirror::Object\u0026gt;(internal)-\u0026gt;AsObjectArray\u0026lt;mirror::Object\u0026gt;(); // Methods and dex PC trace is element 0.  DCHECK(decoded_traces-\u0026gt;Get(0)-\u0026gt;IsIntArray() || decoded_traces-\u0026gt;Get(0)-\u0026gt;IsLongArray()); ObjPtr\u0026lt;mirror::PointerArray\u0026gt; const method_trace = ObjPtr\u0026lt;mirror::PointerArray\u0026gt;::DownCast(MakeObjPtr(decoded_traces-\u0026gt;Get(0))); // Prepare parameters for StackTraceElement(String cls, String method, String file, int line)  ArtMethod* method = method_trace-\u0026gt;GetElementPtrSize\u0026lt;ArtMethod*\u0026gt;(i, kRuntimePointerSize); uint32_t dex_pc = method_trace-\u0026gt;GetElementPtrSize\u0026lt;uint32_t\u0026gt;( i + method_trace-\u0026gt;GetLength() / 2, kRuntimePointerSize); //main  ObjPtr\u0026lt;mirror::StackTraceElement\u0026gt; obj = CreateStackTraceElement(soa, method, dex_pc); if (obj == nullptr) { return nullptr; } // We are called from native: use non-transactional mode.  soa.Decode\u0026lt;mirror::ObjectArray\u0026lt;mirror::StackTraceElement\u0026gt;\u0026gt;(result)-\u0026gt;Set\u0026lt;false\u0026gt;(i, obj); } return result; } static ObjPtr\u0026lt;mirror::StackTraceElement\u0026gt; CreateStackTraceElement( const ScopedObjectAccessAlreadyRunnable\u0026amp; soa, ArtMethod* method, uint32_t dex_pc) REQUIRES_SHARED(Locks::mutator_lock_) { int32_t line_number; StackHandleScope\u0026lt;3\u0026gt; hs(soa.Self()); auto class_name_object(hs.NewHandle\u0026lt;mirror::String\u0026gt;(nullptr)); auto source_name_object(hs.NewHandle\u0026lt;mirror::String\u0026gt;(nullptr)); if (method-\u0026gt;IsProxyMethod()) { line_number = -1; class_name_object.Assign(method-\u0026gt;GetDeclaringClass()-\u0026gt;GetName()); // source_name_object intentionally left null for proxy methods  } else { line_number = method-\u0026gt;GetLineNumFromDexPC(dex_pc); // Allocate element, potentially triggering GC  // TODO: reuse class_name_object via Class::name_?  const char* descriptor = method-\u0026gt;GetDeclaringClassDescriptor(); CHECK(descriptor != nullptr); std::string class_name(PrettyDescriptor(descriptor)); class_name_object.Assign( mirror::String::AllocFromModifiedUtf8(soa.Self(), class_name.c_str())); if (class_name_object == nullptr) { soa.Self()-\u0026gt;AssertPendingOOMException(); return nullptr; } const char* source_file = method-\u0026gt;GetDeclaringClassSourceFile(); if (line_number == -1) { // Make the line_number field of StackTraceElement hold the dex pc.  // source_name_object is intentionally left null if we failed to map the dex pc to  // a line number (most probably because there is no debug info). See b/30183883.  line_number = dex_pc; } else { if (source_file != nullptr) { source_name_object.Assign(mirror::String::AllocFromModifiedUtf8(soa.Self(), source_file)); if (source_name_object == nullptr) { soa.Self()-\u0026gt;AssertPendingOOMException(); return nullptr; } } } } const char* method_name = method-\u0026gt;GetInterfaceMethodIfProxy(kRuntimePointerSize)-\u0026gt;GetName(); CHECK(method_name != nullptr); Handle\u0026lt;mirror::String\u0026gt; method_name_object( hs.NewHandle(mirror::String::AllocFromModifiedUtf8(soa.Self(), method_name))); if (method_name_object == nullptr) { return nullptr; } return mirror::StackTraceElement::Alloc(soa.Self(), class_name_object, method_name_object, source_name_object, line_number); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%93%8D%E5%BA%94%E5%BC%8F%E6%9E%B6%E6%9E%84/stream/stream/",
	"title": "Stream",
	"tags": [],
	"description": "",
	"content": "Stream/BLoC https://www.didierboelens.com/2018/08/reactive-programming-streams-bloc/\nFlutter中如何利用StreamBuilder和BLoC来控制Widget状态\nWhy use RxDart and how we can use with BLoC Pattern in Flutter?\nWhat is a Stream? Introduction In order to easily visualize the notion of Stream, simply consider a pipe with 2 ends, only one allowing to insert something into it. When you insert something into the pipe, it flows inside the pipe and goes out by the other end.\nIn Flutter,\n the pipe is called a Stream to control the Stream, we usually(*) use a StreamController to insert something into the Stream, the StreamController exposes the “entrance\u0026quot;, called a StreamSink, accessible via the sink property the way out of the Stream, is exposed by the StreamController via the stream property  How do I know that something is conveyed by a Stream? When you need to be notified that something is conveyed by a Stream, you simply need to listen to the stream property of the StreamController.\nWhen you define a listener, you receive a StreamSubscription object. This is via that StreamSubscription object that you will be notified that something happens at the level of the Stream.\nAs soon as there is at least one active listener, the Stream starts generating events to notify the active StreamSubscription object(s) each time:\n some data goes out from the stream, when some error has been sent to the stream, when the stream is closed.  The StreamSubscription object also allows you to:\n stop listening, pause, resume.  Is a Stream only a simple pipe? No, a Stream also allows to process the data that flows inside it before it goes out.\nTo control the processing of the data inside a Stream, we use a StreamTransformer, which is nothing but\n a function that “captures” the data that flows inside the Stream does something with the data the outcome of this transformation is also a Stream  You will directly understand from this statement that it is very possible to use several StreamTransformers in sequence.\nA StreamTransformer may be used to do any type of processing, such as, e.g.:\n filtering: to filter the data based on any type of condition, regrouping: to regroup data, modification: to apply any type of modification to the data, inject data to other streams, buffering, processing: do any kind of action/operation based on the data, …  Types of Streams There are 2 types of Streams.\nSingle-subscription Streams This type of Stream only allows a single listener during the whole lifetime of that Stream.\n It is not possible to listen twice on such Stream, even after the first subscription has been canceled.\n Broadcast Streams This second type of Stream allows any number of listeners.\n It is possible to add a listener to a Broadcast Stream at any moment. The new listener will receive the events, as of the moment it starts listening to the Stream.\n Important note about the Resources  It is a very good practice to always release the resources which are no longer necessary.\n This statement applies to:\n StreamSubscription - when you no longer need to listen to a stream, cancel the subscription; StreamController - when you no longer need a StreamController, close it; the same applies to RxDart Subjects, when you no longer need a BehaviourSubject, a PublishSubject…, close it.  Usage StreamController import \u0026#39;dart:async\u0026#39;; void main() { // 初始化一个单订阅的Stream controller  final StreamController ctrl = StreamController(); // 初始化一个监听  final StreamSubscription subscription = ctrl.stream.listen((data) =\u0026gt; print(\u0026#39;$data\u0026#39;)); // 往Stream中添加数据  ctrl.sink.add(\u0026#39;my name\u0026#39;); ctrl.sink.add(1234); ctrl.sink.add({\u0026#39;a\u0026#39;: \u0026#39;element A\u0026#39;, \u0026#39;b\u0026#39;: \u0026#39;element B\u0026#39;}); ctrl.sink.add(123.45); // StreamController用完后需要释放  ctrl.close(); } StreamBuilder StreamBuilder其实是一个StatefulWidget，它通过监听Stream，发现有数据输出时，自动重建，调用builder方法。\nStreamBuilder\u0026lt;T\u0026gt;( key: ...可选... stream: ...需要监听的stream... initialData: ...初始数据，否则为空... builder: (BuildContext context, AsyncSnapshot\u0026lt;T\u0026gt; snapshot){ if (snapshot.hasData){ return ...基于snapshot.hasData返回的控件 } return ...没有数据的时候返回的控件 }, ) 下面是一个模仿官方自带demo“计数器”的一个例子，使用了StreamBuilder，而不需要任何setState：\nimport \u0026#39;dart:async\u0026#39;; import \u0026#39;package:flutter/material.dart\u0026#39;; class CounterPage extends StatefulWidget { @override _CounterPageState createState() =\u0026gt; _CounterPageState(); } class _CounterPageState extends State\u0026lt;CounterPage\u0026gt; { int _counter = 0; final StreamController\u0026lt;int\u0026gt; _streamController = StreamController\u0026lt;int\u0026gt;(); @override void dispose(){ _streamController.close(); super.dispose(); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar(title: Text(\u0026#39;Stream version of the Counter App\u0026#39;)), body: Center( child: StreamBuilder\u0026lt;int\u0026gt;( // 监听Stream，每次值改变的时候，更新Text中的内容  stream: _streamController.stream, initialData: _counter, builder: (BuildContext context, AsyncSnapshot\u0026lt;int\u0026gt; snapshot){ return Text(\u0026#39;You hit me: ${snapshot.data}times\u0026#39;); } ), ), floatingActionButton: FloatingActionButton( child: const Icon(Icons.add), onPressed: (){ // 每次点击按钮，更加_counter的值，同时通过Sink将它发送给Stream；  // 每注入一个值，都会引起StreamBuilder的监听，StreamBuilder重建并刷新counter  _streamController.sink.add(++_counter); }, ), ); } } Source classDiagram类结构 classDiagram class EventSink~T~ { add(T event)void addError(Object error, [StackTrace? stackTrace])void close()void } class StreamConsumer~S~ { addStream(Stream\u0026lt;S\u0026gt; stream)Future close()Future } class StreamSink~T~ { close()Future Future done; } class StreamController~T~ { Stream\u0026lt;T\u0026gt; stream StreamSink\u0026lt;T\u0026gt; sink } class Stream~T~ { listen(void onData(T event)?, Function? onError, void onDone()?, bool? cancelOnError)StreamSubscription~T~ } class _StreamControllerBase~T~ { } class _BroadcastStreamController~T~ { Function onListen Function onCancel Stream\u0026lt;T\u0026gt; stream =\u0026gt; _BroadcastStream\u0026lt;T\u0026gt;(this); } class _AsyncBroadcastStreamController~T~ { _sendData(T data)void _sendError(Object error, StackTrace stackTrace)void _sendDone()void } class _StreamImpl~T~ { listen(void onData(T event)?, ...)StreamSubscription~T~ } class _ControllerStream~T~ { _StreamControllerLifecycle\u0026lt;T\u0026gt; _controller; _createSubscription(void onData(T event)?, ...)StreamSubscription~T~ } class _BroadcastStream~T~ { isBroadcast =\u0026gt; true; } StreamSink\u0026lt;|--StreamController EventSink\u0026lt;|--StreamSink StreamConsumer\u0026lt;|--StreamSink StreamController\u0026lt;|--_StreamControllerBase _StreamControllerBase\u0026lt;|--_BroadcastStreamController _BroadcastStreamController\u0026lt;|--_AsyncBroadcastStreamController Stream\u0026lt;|--_StreamImpl _StreamImpl\u0026lt;|--_ControllerStream _ControllerStream\u0026lt;|--_BroadcastStream class _ForwardingStream~S, T~ { Stream\u0026lt;S\u0026gt; _source listen(void onData(T event)?, ...)StreamSubscription~T~ _handleData(S data)void } class _MapStream~S, T~ { _Transformation\u0026lt;S, T\u0026gt; _transform _handleData(S inputEvent, _EventSink\u0026lt;T\u0026gt; sink)void } Stream\u0026lt;|--_ForwardingStream _ForwardingStream\u0026lt;|--_MapStream class StreamView~T~ { Stream\u0026lt;T\u0026gt; _stream; } Stream\u0026lt;|--StreamView class Subject~T~ { StreamController\u0026lt;T\u0026gt; _controller } StreamController\u0026lt;|--Subject StreamView\u0026lt;|--Subject classDiagram class StreamSubscription~T~ { onData(void handleData(T data)?)void onError(Function? handleError)void onDone(void handleDone()?)void resume()void pause([Future\u0026lt;void\u0026gt;? resumeSignal])void } class _EventDispatch~T~ { _sendData(T data)void _sendError(Object error, StackTrace stackTrace)void _sendDone()void } class _BufferingStreamSubscription~T~ { _DataHandler\u0026lt;T\u0026gt; _onData; Function _onError; _DoneHandler _onDone; } class _EventSink~T~ { _add(T data)void _addError(Object error, StackTrace stackTrace)void _close()void } class _ForwardingStreamSubscription~S, T~ { _ForwardingStream\u0026lt;S, T\u0026gt; _stream; StreamSubscription\u0026lt;S\u0026gt;? _subscription; _add(T data)void } StreamSubscription\u0026lt;|--_BufferingStreamSubscription _EventSink\u0026lt;|--_BufferingStreamSubscription _EventDispatch\u0026lt;|--_BufferingStreamSubscription _BufferingStreamSubscription\u0026lt;|--_ForwardingStreamSubscription graph LR Stream.listen--\u0026gt;|_subscribe, call|onListen_Callback StreamController.broadcast /// The [onListen] callback is called when the first listener is subscribed,  /// and the [onCancel] is called when there are no longer any active listeners.  /// If a listener is added again later, after the [onCancel] was called,  /// the [onListen] will be called again. factory StreamController.broadcast( {void onListen()?, void onCancel()?, bool sync = false}) { return sync ? _SyncBroadcastStreamController\u0026lt;T\u0026gt;(onListen, onCancel) : _AsyncBroadcastStreamController\u0026lt;T\u0026gt;(onListen, onCancel); } Stream.map Stream\u0026lt;S\u0026gt; map\u0026lt;S\u0026gt;(S convert(T event)) { return new _MapStream\u0026lt;T, S\u0026gt;(this, convert); } 原理总结 graph LR subgraph 事件订阅 subscribe(\u0026quot;类似RxJava设计,subscribe/listen时持有上游Stream对象进行订阅,并包裹observer/subcription\u0026quot;) end subscribe--\u0026gt;consume subgraph 事件消费 consume(\u0026quot;在消费事件时能够提前拦截并按照操作符的含义进行操作,之后转发给下游OnData\u0026quot;) end RxJava核心架构图如下：\n_MapStream\u0026lt;S, T\u0026gt; /// A stream pipe that converts data events before passing them on. class _MapStream\u0026lt;S, T\u0026gt; extends _ForwardingStream\u0026lt;S, T\u0026gt; { final _Transformation\u0026lt;S, T\u0026gt; _transform; _MapStream(Stream\u0026lt;S\u0026gt; source, T transform(S event)) : this._transform = transform, super(source); void _handleData(S inputEvent, _EventSink\u0026lt;T\u0026gt; sink) { T outputEvent; try { outputEvent = _transform(inputEvent); } catch (e, s) { _addErrorWithReplacement(sink, e, s); return; } sink._add(outputEvent); } } _ForwardingStream abstract class _ForwardingStream\u0026lt;S, T\u0026gt; extends Stream\u0026lt;T\u0026gt; { final Stream\u0026lt;S\u0026gt; _source; _ForwardingStream(this._source);//_source是上游Stream对象，用来进行订阅  bool get isBroadcast =\u0026gt; _source.isBroadcast; StreamSubscription\u0026lt;T\u0026gt; listen(void onData(T value)?, {Function? onError, void onDone()?, bool? cancelOnError}) {//开始事件订阅过程  return _createSubscription(onData, onError, onDone, cancelOnError ?? false); } StreamSubscription\u0026lt;T\u0026gt; _createSubscription(void onData(T data)?, Function? onError, void onDone()?, bool cancelOnError) { return new _ForwardingStreamSubscription\u0026lt;S, T\u0026gt;(//main  this, onData, onError, onDone, cancelOnError); } // Override the following methods in subclasses to change the behavior.  void _handleData(S data, _EventSink\u0026lt;T\u0026gt; sink); void _handleError(Object error, StackTrace stackTrace, _EventSink\u0026lt;T\u0026gt; sink) { sink._addError(error, stackTrace); } void _handleDone(_EventSink\u0026lt;T\u0026gt; sink) { sink._close(); } } _ForwardingStreamSubscription /// Abstract superclass for subscriptions that forward to other subscriptions. class _ForwardingStreamSubscription\u0026lt;S, T\u0026gt; extends _BufferingStreamSubscription\u0026lt;T\u0026gt; { final _ForwardingStream\u0026lt;S, T\u0026gt; _stream; StreamSubscription\u0026lt;S\u0026gt;? _subscription; _ForwardingStreamSubscription(this._stream, void onData(T data)?, Function? onError, void onDone()?, bool cancelOnError) : super(onData, onError, onDone, cancelOnError) {//传入父类的是onData，用于transform后进行_EventSink的_add听通知  _subscription = _stream._source//用上游Stream对象进行订阅  .listen(_handleData, onError: _handleError, onDone: _handleDone);//将_handleData方法作为onData传入，方便回调时拦截  } void _add(T data) {//开始消费事件过程  if (_isClosed) return; super._add(data); } // Methods used as listener on source subscription.  void _handleData(S data) { _stream._handleData(data, this);//转发到_MapStream._handleData,类似RxJava的设计，在subscribe/listen时配置observer/subcription,进而在消费事件时能够提前拦截并按照操作符的含义进行操作  } void _handleError(error, StackTrace stackTrace) { _stream._handleError(error, stackTrace, this); } void _handleDone() { _stream._handleDone(this); } } class _BufferingStreamSubscription\u0026lt;T\u0026gt; implements StreamSubscription\u0026lt;T\u0026gt;, _EventSink\u0026lt;T\u0026gt;, _EventDispatch\u0026lt;T\u0026gt; { _BufferingStreamSubscription(void onData(T data)?, Function? onError, void onDone()?, bool cancelOnError) : this.zoned(Zone.current, onData, onError, onDone, cancelOnError); _BufferingStreamSubscription.zoned(this._zone, void onData(T data)?, Function? onError, void onDone()?, bool cancelOnError) : _state = (cancelOnError ? _STATE_CANCEL_ON_ERROR : 0), _onData = _registerDataHandler\u0026lt;T\u0026gt;(_zone, onData), _onError = _registerErrorHandler(_zone, onError), _onDone = _registerDoneHandler(_zone, onDone); void _add(T data) { if (_canFire) { _sendData(data); } else { _addPending(new _DelayedData\u0026lt;T\u0026gt;(data)); } } void _sendData(T data) { _zone.runUnaryGuarded(_onData, data);//执行_onData配置的方法，也就是构造方法传入的onData  } static void Function(T) _registerDataHandler\u0026lt;T\u0026gt;( Zone zone, void Function(T)? handleData) { return zone.registerUnaryCallback\u0026lt;void, T\u0026gt;(handleData ?? _nullDataHandler); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%93%8D%E5%BA%94%E5%BC%8F%E6%9E%B6%E6%9E%84/stream/",
	"title": "stream",
	"tags": [],
	"description": "",
	"content": "stream 探索总结stream知识\n Stream     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/supporttoandroidx/",
	"title": "SupportToAndroidx",
	"tags": [],
	"description": "",
	"content": "升级背景 为了升级公司客户端架构，促进更高效的开发效率，减少模板代码并提升稳定性，需要基础仓库从support迁移到androidx，并提供相应的升级方案以及基于androidx的基础组件。\n模块拆分方式命名   不依赖support/androidx的模块称为pure模块\n  依赖support的称为support模块\n  依赖androidx的称为androidx模块\n  升级方案  module内部，将原本的基础仓库old base module拆分为base_support + base_pure两个模块，剥离support依赖。其中base_pure模块拆分到一个单独的project中，而base_support项目需要新增base_androidx branch，分开两个branch迭代，并通过cherrypick进行修改同步，同时分别发布独立的maven。 old base module所依赖的模块，也需要按照1的方式进行拆分。同时pure模块只能依赖pure模块,非pure模块可以依赖对应的非pure模块和pure模块 pure模块的单测test模块是support或者androidx都没关系，不影响发版仓库中的内容 androidx利用灰度版本去进行测试  包依赖关系 graph TB app_support--\u0026gt;base_support app_support--\u0026gt;base_pure app_androidx--\u0026gt;base_androidx app_androidx--\u0026gt;base_pure base_support--\u0026gt;xxx_pure base_pure--\u0026gt;xxx_pure base_support--\u0026gt;xxx_support base_androidx--\u0026gt;xxx_androidx base_androidx--\u0026gt;xxx_pure 升级步骤 https://developer.android.google.cn/jetpack/androidx/migrate?hl=zh-cn\nhttps://medium.com/androiddevelopers/migrating-to-androidx-tip-tricks-and-guidance-88d5de238876\n是时候迁移至 AndroidX 了！\ngraph LR olderSupport--\u0026gt;|APIchanges|28.0.0Support--\u0026gt;|namespaceChanges|androidx1.0  创建新分支准备迁移，停止同步进行的新功能开发和重构，防止冲突 在old base module中搜索support进行处理,去除不必要的support库依赖 support升级到28，这是因为，1.0.0 版本的 AndroidX 工件是与支持库 28.0.0 工件等效的二进制文件。 编译和测试用例通过 配置android.useAndroidX=true android.enableJetifier=true 更新依赖的仓库到支持androidx的版本 迁移到androidx: AS操作 Refactor \u0026gt; Migrate to AndroidX  基于androidx的后续基础架构封装 新架构单独封装一个独立的module(使用androidx)，提供基础能力\n 基础View组件(Activity,Fragment,View等)，支持DataBinding的能力选择 基础ViewModel组件 基础Repository组件 新架构组件的使用规范和样例 startup启动组件 后台任务调度执行组件 datastore组件替代现有的sharedPreference 其他jetpack组件，按需封装提供  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/surfaceview/",
	"title": "surfaceview",
	"tags": [],
	"description": "",
	"content": "surfaceview 探索总结surfaceview知识\n SurfaceViewSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/surfaceview/surfaceviewsource/",
	"title": "SurfaceViewSource",
	"tags": [],
	"description": "",
	"content": "源码位置: frameworks/base/core/java/android/view/SurfaceView.java\nsurfaceView support scale and translation to its parent or itself\nonAttachedToWindow @Override protected void onAttachedToWindow() { super.onAttachedToWindow(); getViewRootImpl().addWindowStoppedCallback(this); mWindowStopped = false; mViewVisibility = getVisibility() == VISIBLE; updateRequestedVisibility(); mAttachedToWindow = true; mParent.requestTransparentRegion(SurfaceView.this);//main  if (!mGlobalListenersAdded) { ViewTreeObserver observer = getViewTreeObserver(); observer.addOnScrollChangedListener(mScrollChangedListener); observer.addOnPreDrawListener(mDrawListener); mGlobalListenersAdded = true; } } requestTransparentRegion //ViewGroup  @Override public void requestTransparentRegion(View child) { if (child != null) { child.mPrivateFlags |= View.PFLAG_REQUEST_TRANSPARENT_REGIONS; if (mParent != null) { mParent.requestTransparentRegion(this); } } } @Override//ViewRootImpl  public void requestTransparentRegion(View child) { // the test below should not fail unless someone is messing with us  checkThread(); if (mView == child) { mView.mPrivateFlags |= View.PFLAG_REQUEST_TRANSPARENT_REGIONS; // Need to make sure we re-evaluate the window attributes next  // time around, to ensure the window has the correct format.  mWindowAttributesChanged = true; mWindowAttributesChangesFlag = 0; requestLayout(); } } SurfaceView如何挖洞 SurfaceView的窗口类型一般都是TYPE_APPLICATION_MEDIA或者TYPE_APPLICATION_MEDIA_OVERLAY，它的Z轴位置是小于其宿主窗口的Z位置。为了保证SurfaceView的UI是可见的，SurfaceView就需要在其宿主窗口的上面挖一个洞出来，实际上就是在其宿主窗口的绘图表面上设置一块透明区域，以便可以将自己显示出来。 SurfaceView在被附加到宿主窗口之上的时候，会请求在宿主窗口上设置透明区域，而每当其宿主窗口刷新自己的UI的时候，就会将所有嵌入在它里面的SurfaceView所设置的透明区域收集起来，然后再通知WindowManagerService服务为其设置一个总的透明区域。\nonWindowVisibilityChanged @Override protected void onWindowVisibilityChanged(int visibility) { super.onWindowVisibilityChanged(visibility); mWindowVisibility = visibility == VISIBLE; updateRequestedVisibility(); updateSurface(); } updateSurface protected void updateSurface() { ViewRootImpl viewRoot = getViewRootImpl(); //1 new SurfaceSession  mSurfaceSession = new SurfaceSession(viewRoot.mSurface); //2 new SurfaceControl  mSurfaceControl = new SurfaceControlWithBackground( name, (mSurfaceFlags \u0026amp; SurfaceControl.OPAQUE) != 0, new SurfaceControl.Builder(mSurfaceSession) .setSize(mSurfaceWidth, mSurfaceHeight) .setFormat(mFormat) .setFlags(mSurfaceFlags)); //3 mSurfaceControl.show()  mSurfaceControl.setLayer(mSubLayer); if (mViewVisibility) { mSurfaceControl.show(); } else { mSurfaceControl.hide(); } //4 mSurface.copyFrom(mSurfaceControl)  if (creating) { mSurface.copyFrom(mSurfaceControl); } //5 回调SurfaceHolder.Callback, surface的状态变化  if (visible \u0026amp;\u0026amp; mSurface.isValid()) { if (!mSurfaceCreated \u0026amp;\u0026amp; (surfaceChanged || visibleChanged)) { mSurfaceCreated = true; mIsCreating = true; if (callbacks == null) { callbacks = getSurfaceCallbacks(); } for (SurfaceHolder.Callback c : callbacks) { c.surfaceCreated(mSurfaceHolder); } } if (creating || formatChanged || sizeChanged || visibleChanged || realSizeChanged) { if (callbacks == null) { callbacks = getSurfaceCallbacks(); } for (SurfaceHolder.Callback c : callbacks) { c.surfaceChanged(mSurfaceHolder, mFormat, myWidth, myHeight); } } if (redrawNeeded) { if (callbacks == null) { callbacks = getSurfaceCallbacks(); } mPendingReportDraws++; viewRoot.drawPending(); SurfaceCallbackHelper sch = new SurfaceCallbackHelper(this::onDrawFinished); sch.dispatchSurfaceRedrawNeededAsync(mSurfaceHolder, callbacks); } } 旧版本android系统使用常规View绘制方式通过mSession和WMS通信，并在WMS进程内完成\n new SurfaceSesion (addToDisplay时) new SurfaceControl(relayout时)  新版本android9.0,在应用进程内部SurfaceView.UpdateSurface时独立完成了上述流程\n/** surfaceView.getHolder * Return the SurfaceHolder providing access and control over this * SurfaceView\u0026#39;s underlying surface. * * @return SurfaceHolder The holder of the surface. */ public SurfaceHolder getHolder() { return mSurfaceHolder; } SurfaceHolder.lockCanvas private final SurfaceHolder mSurfaceHolder = new SurfaceHolder() { @Override public void addCallback(Callback callback) { synchronized (mCallbacks) { // This is a linear search, but in practice we\u0026#39;ll  // have only a couple callbacks, so it doesn\u0026#39;t matter.  if (mCallbacks.contains(callback) == false) { mCallbacks.add(callback); } } } public Canvas lockCanvas() { return internalLockCanvas(null, false); } final ReentrantLock mSurfaceLock = new ReentrantLock(); final Surface mSurface = new Surface(); // Current surface in use  private Canvas internalLockCanvas(Rect dirty, boolean hardware) { mSurfaceLock.lock(); Canvas c = null; if (!mDrawingStopped \u0026amp;\u0026amp; mSurfaceControl != null) { if (hardware) { c = mSurface.lockHardwareCanvas(); } else { c = mSurface.lockCanvas(dirty); } return c; } lockHardwareCanvas public Canvas lockHardwareCanvas() { synchronized (mLock) { checkNotReleasedLocked(); if (mHwuiContext == null) { mHwuiContext = new HwuiContext(false); } return mHwuiContext.lockCanvas( nativeGetWidth(mNativeObject), nativeGetHeight(mNativeObject)); } } RenderNode.create HwuiContext(boolean isWideColorGamut) { mRenderNode = RenderNode.create(\u0026#34;HwuiCanvas\u0026#34;, null); mRenderNode.setClipToBounds(false); mHwuiRenderer = nHwuiCreate(mRenderNode.mNativeRenderNode, mNativeObject, isWideColorGamut);//mHwuiRenderer在native层就是一个RenderProxy指针  } new RenderProxy frameworks/base/core/jni/android_view_Surface.cpp\nstatic const JNINativeMethod gSurfaceMethods[] = { {\u0026#34;nHwuiCreate\u0026#34;, \u0026#34;(JJZ)J\u0026#34;, (void*) hwui::create }, } static jlong create(JNIEnv* env, jclass clazz, jlong rootNodePtr, jlong surfacePtr, jboolean isWideColorGamut) { RenderNode* rootNode = reinterpret_cast\u0026lt;RenderNode*\u0026gt;(rootNodePtr); sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface*\u0026gt;(surfacePtr)); ContextFactory factory; RenderProxy* proxy = new RenderProxy(false, rootNode, \u0026amp;factory); proxy-\u0026gt;loadSystemProperties(); if (isWideColorGamut) { proxy-\u0026gt;setWideGamut(true); } proxy-\u0026gt;setSwapBehavior(SwapBehavior::kSwap_discardBuffer); proxy-\u0026gt;initialize(surface); // Shadows can\u0026#39;t be used via this interface, so just set the light source  // to all 0s.  proxy-\u0026gt;setup(0, 0, 0); proxy-\u0026gt;setLightCenter((Vector3){0, 0, 0}); return (jlong) proxy; } mRenderNode.start Canvas lockCanvas(int width, int height) { if (mCanvas != null) { throw new IllegalStateException(\u0026#34;Surface was already locked!\u0026#34;); } mCanvas = mRenderNode.start(width, height); return mCanvas; } lockCanvas public Canvas lockCanvas(Rect inOutDirty) throws Surface.OutOfResourcesException, IllegalArgumentException { synchronized (mLock) { mLockedObject = nativeLockCanvas(mNativeObject, mCanvas, inOutDirty); return mCanvas; } } SurfaceHolder.unlockCanvasAndPost public void unlockCanvasAndPost(Canvas canvas) { mSurface.unlockCanvasAndPost(canvas); mSurfaceLock.unlock(); } public void unlockCanvasAndPost(Canvas canvas) { synchronized (mLock) { checkNotReleasedLocked(); if (mHwuiContext != null) { mHwuiContext.unlockAndPost(canvas); } else { unlockSwCanvasAndPost(canvas); } } } mHwuiContext.unlockAndPost mRenderNode.end(mCanvas); void unlockAndPost(Canvas canvas) { if (canvas != mCanvas) { throw new IllegalArgumentException(\u0026#34;canvas object must be the same instance that \u0026#34; + \u0026#34;was previously returned by lockCanvas\u0026#34;); } mRenderNode.end(mCanvas); mCanvas = null; nHwuiDraw(mHwuiRenderer); } renderproxy-\u0026gt;syncAndDrawFrame() frameworks/base/core/jni/android_view_Surface.cpp\nstatic const JNINativeMethod gSurfaceMethods[] = { {\u0026#34;nHwuiDraw\u0026#34;, \u0026#34;(J)V\u0026#34;, (void*) hwui::draw }, } static void draw(JNIEnv* env, jclass clazz, jlong rendererPtr) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(rendererPtr); nsecs_t vsync = systemTime(CLOCK_MONOTONIC); UiFrameInfoBuilder(proxy-\u0026gt;frameInfo()) .setVsync(vsync, vsync) .addFlag(FrameInfoFlags::SurfaceCanvas); proxy-\u0026gt;syncAndDrawFrame(); } unlockSwCanvasAndPost private void unlockSwCanvasAndPost(Canvas canvas) { nativeUnlockCanvasAndPost(mLockedObject, canvas); } 参考 Android中SurfaceView使用详解\nSurfaceView原理分析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E6%BA%90%E7%A0%81%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95/syscall%E6%9F%A5%E6%89%BE%E6%96%B9%E5%BC%8F/",
	"title": "Syscall查找方式",
	"tags": [],
	"description": "",
	"content": "Android9.0采用如下Tips3,4进行定位\nTips 1： 用户空间的方法xxx，对应系统调用层方法则是sys_xxx； Tips 2： unistd.h文件记录着系统调用中断号的信息。(搜索__SYSCALL找到unistd.d文件位置) /* kernel/signal.c */ __SYSCALL(__NR_kill, sys_kill) Tips 3： 宏定义SYSCALL_DEFINEx(xxx,…)，展开后对应的方法则是sys_xxx； Tips 4： 方法参数的个数x，对应于SYSCALL_DEFINEx。 kill(int pid, int sig)方法共两个参数，则对应方法于SYSCALL_DEFINE2(kill,...)，进入signal.c文件，再次搜索关键字，便能看到方法： include/linux/syscalls.h\nsyscalls.h #define SYSCALL_DEFINE1(name, ...) SYSCALL_DEFINEx(1, _##name, __VA_ARGS__) #define SYSCALL_DEFINE2(name, ...) SYSCALL_DEFINEx(2, _##name, __VA_ARGS__) #define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__) #define SYSCALL_DEFINE4(name, ...) SYSCALL_DEFINEx(4, _##name, __VA_ARGS__) #define SYSCALL_DEFINE5(name, ...) SYSCALL_DEFINEx(5, _##name, __VA_ARGS__) #define SYSCALL_DEFINE6(name, ...) SYSCALL_DEFINEx(6, _##name, __VA_ARGS__)  #define SYSCALL_DEFINEx(x, sname, ...)\t\\ SYSCALL_METADATA(sname, x, __VA_ARGS__)\t\\ __SYSCALL_DEFINEx(x, sname, __VA_ARGS__)  #define __SYSCALL_DEFINEx(x, name, ...)\t\\ asmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))\t\\ __attribute__((alias(__stringify(SyS##name))));\t\\ static inline long SYSC##name(__MAP(x,__SC_DECL,__VA_ARGS__));\t\\ asmlinkage long SyS##name(__MAP(x,__SC_LONG,__VA_ARGS__));\t\\ asmlinkage long SyS##name(__MAP(x,__SC_LONG,__VA_ARGS__))\t\\ {\t\\ long ret = SYSC##name(__MAP(x,__SC_CAST,__VA_ARGS__));\t\\ __MAP(x,__SC_TEST,__VA_ARGS__);\t\\ __PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__));\t\\ return ret;\t\\ }\t\\ static inline long SYSC##name(__MAP(x,__SC_DECL,__VA_ARGS__)) fs/ioctl.c\nioctl kgdb调试堆栈 #0 binder_ioctl (filp=0xffff8800618f6a00, cmd=3224396289, arg=3463711848) at drivers/android/binder.c:4738 #1 0xffffffff803873fe in C_SYSC_ioctl (arg32=\u0026lt;optimized out\u0026gt;, cmd=\u0026lt;optimized out\u0026gt;, fd=\u0026lt;optimized out\u0026gt;) at fs/compat_ioctl.c:1592 #2 compat_SyS_ioctl (fd=46, cmd=3224396289, arg32=3463711848) at fs/compat_ioctl.c:1544 #3 0xffffffff80201a69 in do_syscall_32_irqs_on (regs=\u0026lt;optimized out\u0026gt;) at arch/x86/entry/common.c:392 #4 do_fast_syscall_32 (regs=0xffff880052e33f58) at arch/x86/entry/common.c:459 #5 0xffffffff80941c75 in entry_SYSENTER_compat () at arch/x86/entry/entry_64_compat.S:126 #6 0x0000000000000000 in ?? () frame 2 compat_SyS_ioctl对应COMPAT_SYSCALL_DEFINE3(ioctl, \u0026hellip;),实现和下述SYSCALL_DEFINE3类似\nSYSCALL_DEFINE3(ioctl, unsigned int, fd, unsigned int, cmd, unsigned long, arg) { int error; struct fd f = fdget(fd); if (!f.file) return -EBADF; error = security_file_ioctl(f.file, cmd, arg); if (!error) error = do_vfs_ioctl(f.file, fd, cmd, arg); fdput(f); return error; } vfs_ioctl /** * vfs_ioctl - call filesystem specific ioctl methods * @filp:\topen file to invoke ioctl method on * @cmd:\tioctl command to execute * @arg:\tcommand-specific argument for ioctl * * Invokes filesystem specific -\u0026gt;unlocked_ioctl, if one exists; otherwise * returns -ENOTTY. * * Returns 0 on success, -errno on error. */ static long vfs_ioctl(struct file *filp, unsigned int cmd, unsigned long arg) { int error = -ENOTTY; if (!filp-\u0026gt;f_op-\u0026gt;unlocked_ioctl) goto out; error = filp-\u0026gt;f_op-\u0026gt;unlocked_ioctl(filp, cmd, arg); if (error == -ENOIOCTLCMD) error = -ENOTTY; out: return error; } drivers/android/binder.c\n.unlocked_ioctl = binder_ioctl static const struct file_operations binder_fops = { .owner = THIS_MODULE, .poll = binder_poll, .unlocked_ioctl = binder_ioctl, .compat_ioctl = binder_ioctl, .mmap = binder_mmap, .open = binder_open, .flush = binder_flush, .release = binder_release, }; drivers/staging/android/ashmem.c\nashmem ashmem_fops static const struct file_operations ashmem_fops = { .owner = THIS_MODULE, .open = ashmem_open, .release = ashmem_release, .read = ashmem_read, .llseek = ashmem_llseek, .mmap = ashmem_mmap, .unlocked_ioctl = ashmem_ioctl, #ifdef CONFIG_COMPAT \t.compat_ioctl = compat_ashmem_ioctl, #endif }; static struct miscdevice ashmem_misc = { .minor = MISC_DYNAMIC_MINOR, .name = \u0026#34;ashmem\u0026#34;, .fops = \u0026amp;ashmem_fops, }; static int __init ashmem_init(void) { int ret; ashmem_area_cachep = kmem_cache_create(\u0026#34;ashmem_area_cache\u0026#34;, sizeof(struct ashmem_area), 0, 0, NULL); ashmem_range_cachep = kmem_cache_create(\u0026#34;ashmem_range_cache\u0026#34;, sizeof(struct ashmem_range), 0, 0, NULL); ret = misc_register(\u0026amp;ashmem_misc); register_shrinker(\u0026amp;ashmem_shrinker); return 0; } device_initcall(ashmem_init); fs/eventpoll.c\nepoll_wait kgdb调试堆栈 #0 ep_poll (ep=0xffff88006ac71180, events=0xcab7adb8, maxevents=16, timeout=0) at fs/eventpoll.c:1599 #1 0xffffffff8037b095 in SYSC_epoll_wait (timeout=\u0026lt;optimized out\u0026gt;, maxevents=\u0026lt;optimized out\u0026gt;, events=\u0026lt;optimized out\u0026gt;, epfd=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:2009 #2 SyS_epoll_wait (epfd=\u0026lt;optimized out\u0026gt;, events=\u0026lt;optimized out\u0026gt;, maxevents=16, timeout=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:1974 #3 0xffffffff8037b148 in SYSC_epoll_pwait (sigsetsize=\u0026lt;optimized out\u0026gt;, sigmask=\u0026lt;optimized out\u0026gt;, timeout=\u0026lt;optimized out\u0026gt;, maxevents=\u0026lt;optimized out\u0026gt;, events=\u0026lt;optimized out\u0026gt;, epfd=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:2040 #4 SyS_epoll_pwait (epfd=38, events=3401035192, maxevents=16, timeout=0, sigmask=0, sigsetsize=\u0026lt;optimized out\u0026gt;) at fs/eventpoll.c:2020 #5 0xffffffff80201a69 in do_syscall_32_irqs_on (regs=\u0026lt;optimized out\u0026gt;) at arch/x86/entry/common.c:392 #6 do_fast_syscall_32 (regs=0xffff88006175bf58) at arch/x86/entry/common.c:459 #7 0xffffffff80941c75 in entry_SYSENTER_compat () at arch/x86/entry/entry_64_compat.S:126 #8 0x0000000000000000 in ?? () frame 2 SyS_epoll_wait对应下述方法:\n/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). */ SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { include/linux/fs.h\nstruct file struct file { union { struct llist_node\tfu_llist; struct rcu_head fu_rcuhead; } f_u; struct path\tf_path; struct inode\t*f_inode;\t/* cached value */ const struct file_operations\t*f_op; /* * Protects f_ep_links, f_flags. * Must not be taken from IRQ context. */ spinlock_t\tf_lock; atomic_long_t\tf_count; unsigned int f_flags; fmode_t\tf_mode; struct mutex\tf_pos_lock; loff_t\tf_pos; struct fown_struct\tf_owner; const struct cred\t*f_cred; struct file_ra_state\tf_ra; u64\tf_version; #ifdef CONFIG_SECURITY \tvoid\t*f_security; #endif \t/* needed for tty driver, and maybe others */ void\t*private_data; #ifdef CONFIG_EPOLL \t/* Used by fs/eventpoll.c to link all the hooks to this file */ struct list_head\tf_ep_links; struct list_head\tf_tfile_llink; #endif /* #ifdef CONFIG_EPOLL */\tstruct address_space\t*f_mapping; } __attribute__((aligned(4)));\t/* lest something weird decides that 2 is OK */ 参考 http://gityuan.com/2016/05/21/syscall/\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/",
	"title": "system",
	"tags": [],
	"description": "",
	"content": "system 探索总结system知识\n ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Epoll     Looper     ThreadLocal      input    touchEventNative      kernel    kernel      layoutinflater    LayoutInflater      surfaceview    SurfaceViewSource      textureview    TextureViewSource      thread    StackTraceElement     ThreadState      zygote    SystemServerSource     ZygoteSource     Zygote进程      后台任务    后台任务处理      多进程    binder    1BinderServiceManager     2BinderServer     3BinderClient     4BinderKernel     BinderDeath     Binder原理      mmkv    MMKV       应用启动退出    应用启动      源码研究方法    Syscall查找方式      系统绘制    Graphics     measurelayoutdraw    measure      Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/jni/systemloadlibrary/",
	"title": "SystemLoadLibrary",
	"tags": [],
	"description": "",
	"content": "图解 graph LR findLibrary--\u0026gt;mapLibraryName findLibrary--\u0026gt;NativeLibraryElement.findNativeLibrary nativeload--\u0026gt;JavaVMExt::LoadNativeLibrary--\u0026gt;checkCache(\u0026quot;library = libraries_-\u0026gt;Get(path);\u0026quot;) JavaVMExt::LoadNativeLibrary--\u0026gt;android_dlopen_ext JavaVMExt::LoadNativeLibrary--\u0026gt;dlsym--\u0026gt;JNI_OnLoad--\u0026gt;RegisterNatives--\u0026gt;ArtMethod::setEntryProintFromJni 动态链接器linker过程参考\nRuntime.getRuntime().load /** * Loads the native library specified by the filename argument. The filename * argument must be an absolute path name. * (for example * \u0026lt;code\u0026gt;Runtime.getRuntime().load(\u0026#34;/home/avh/lib/libX11.so\u0026#34;);\u0026lt;/code\u0026gt;). */ public void load(String filename) { load0(VMStack.getStackClass1(), filename); } synchronized void load0(Class\u0026lt;?\u0026gt; fromClass, String filename) { if (!(new File(filename).isAbsolute())) { throw new UnsatisfiedLinkError(\u0026#34;Expecting an absolute path of the library: \u0026#34; + filename); } String error = nativeLoad(filename, fromClass.getClassLoader()); if (error != null) { throw new UnsatisfiedLinkError(error); } } java/lang/System.java\nSystem.loadLibrary /** * Loads the native library specified by the \u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; * argument. The \u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; argument must not contain any platform * specific prefix, file extension or path. If a native library * called \u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; is statically linked with the VM, then the * JNI_OnLoad_\u0026lt;code\u0026gt;libname\u0026lt;/code\u0026gt; function exported by the library is invoked. * See the JNI Specification for more details. * * Otherwise, the libname argument is loaded from a system library * location and mapped to a native library image in an implementation- * dependent manner. **/ public static void loadLibrary(String libname) { Runtime.getRuntime().loadLibrary0(VMStack.getCallingClassLoader(), libname); } java/lang/Runtime.java\nsynchronized void loadLibrary0(ClassLoader loader, String libname) { String libraryName = libname; if (loader != null) { String filename = loader.findLibrary(libraryName); if (filename == null) { // It\u0026#39;s not necessarily true that the ClassLoader used  // System.mapLibraryName, but the default setup does, and it\u0026#39;s  // misleading to say we didn\u0026#39;t find \u0026#34;libMyLibrary.so\u0026#34; when we  // actually searched for \u0026#34;liblibMyLibrary.so.so\u0026#34;.  throw new UnsatisfiedLinkError(loader + \u0026#34; couldn\u0026#39;t find \\\u0026#34;\u0026#34; + System.mapLibraryName(libraryName) + \u0026#34;\\\u0026#34;\u0026#34;); } String error = nativeLoad(filename, loader); if (error != null) { throw new UnsatisfiedLinkError(error); } return; } String filename = System.mapLibraryName(libraryName); List\u0026lt;String\u0026gt; candidates = new ArrayList\u0026lt;String\u0026gt;(); String lastError = null; for (String directory : getLibPaths()) {//getLibPaths return /system/lib/  String candidate = directory + filename; candidates.add(candidate); if (IoUtils.canOpenReadOnly(candidate)) { String error = nativeLoad(candidate, loader); if (error == null) { return; // We successfully loaded the library. Job done.  } lastError = error; } } if (lastError != null) { throw new UnsatisfiedLinkError(lastError); } throw new UnsatisfiedLinkError(\u0026#34;Library \u0026#34; + libraryName + \u0026#34; not found; tried \u0026#34; + candidates); } BaseDexClassLoader.findLibrary @Override public String findLibrary(String name) { return pathList.findLibrary(name); } DexPathList.findLibrary /** * Finds the named native code library on any of the library * directories pointed at by this instance. This will find the * one in the earliest listed directory, ignoring any that are not * readable regular files. * * @return the complete path to the library or {@code null} if no * library was found */ public String findLibrary(String libraryName) { String fileName = System.mapLibraryName(libraryName);//xxx--\u0026gt;libxxx.so  //[0] --\u0026gt; directory \u0026#34;/data/app/com.example.myapplication-sj3RwTZhmeZrfbRZIori-w==/lib/x86\u0026#34;  //[1] --\u0026gt; zip file \u0026#34;/data/app/com.example.myapplication-sj3RwTZhmeZrfbRZIori-w==/base.apk\u0026#34;, dir \u0026#34;lib/x86\u0026#34;  //[2] --\u0026gt; directory \u0026#34;/system/lib\u0026#34;;  //[3] --\u0026gt; directory \u0026#34;/vendor/lib\u0026#34;  for (NativeLibraryElement element : nativeLibraryPathElements) { String path = element.findNativeLibrary(fileName); if (path != null) { return path; } } return null; } NativeLibraryElement.findNativeLibrary /** * Element of the native library path */ /*package*/ static class NativeLibraryElement { /** A file denoting a directory or zip file. */ private final File path; /** If path denotes a zip file, this denotes a base path inside the zip.*/ private final String zipDir; private ClassPathURLStreamHandler urlHandler; private boolean initialized; public String findNativeLibrary(String name) { maybeInit(); if (zipDir == null) { String entryPath = new File(path, name).getPath();// /data/app/com.example.myapplication-sj3RwTZhmeZrfbRZIori-w==/lib/x86/libxhcore.so  if (IoUtils.canOpenReadOnly(entryPath)) { return entryPath; } } else if (urlHandler != null) { // Having a urlHandler means the element has a zip file.  // In this case Android supports loading the library iff  // it is stored in the zip uncompressed.  String entryName = zipDir + \u0026#39;/\u0026#39; + name; if (urlHandler.isEntryStored(entryName)) { return path.getPath() + zipSeparator + entryName; } } return null; } } //IoUtils /** * Do not use. This is for System.loadLibrary use only. * * Checks whether {@code path} can be opened read-only. Similar to File.exists, but doesn\u0026#39;t * require read permission on the parent, so it\u0026#39;ll work in more cases, and allow you to * remove read permission from more directories. Everyone else should just open(2) and then * use the fd, but the loadLibrary API is broken by its need to ask ClassLoaders where to * find a .so rather than just calling dlopen(3). */ public static boolean canOpenReadOnly(String path) { try { // Use open(2) rather than stat(2) so we require fewer permissions. http://b/6485312.  FileDescriptor fd = Libcore.os.open(path, O_RDONLY, 0); Libcore.os.close(fd); return true; } catch (ErrnoException errnoException) { return false; } } nativeLoad private static native String nativeLoad(String filename, ClassLoader loader); libcore/ojluni/src/main/native/Runtime.c\nRuntime_nativeLoad JNIEXPORT jstring JNICALL Runtime_nativeLoad(JNIEnv* env, jclass ignored, jstring javaFilename, jobject javaLoader) { return JVM_NativeLoad(env, javaFilename, javaLoader); } art/openjdkjvm/OpenjdkJvm.cc\nJVM_NativeLoad JNIEXPORT jstring JVM_NativeLoad(JNIEnv* env, jstring javaFilename, jobject javaLoader) { ScopedUtfChars filename(env, javaFilename); if (filename.c_str() == NULL) { return NULL; } std::string error_msg; { art::JavaVMExt* vm = art::Runtime::Current()-\u0026gt;GetJavaVM(); bool success = vm-\u0026gt;LoadNativeLibrary(env, filename.c_str(), javaLoader, \u0026amp;error_msg); if (success) { return nullptr; } } // Don\u0026#39;t let a pending exception from JNI_OnLoad cause a CheckJNI issue with NewStringUTF.  env-\u0026gt;ExceptionClear(); return env-\u0026gt;NewStringUTF(error_msg.c_str()); } art/runtime/java_vm_ext.cc\nJavaVMExt::LoadNativeLibrary bool JavaVMExt::LoadNativeLibrary(JNIEnv* env, const std::string\u0026amp; path, jobject class_loader, std::string* error_msg) { // See if we\u0026#39;ve already loaded this library. If we have, and the class loader  // matches, return successfully without doing anything.  SharedLibrary* library; Thread* self = Thread::Current(); { MutexLock mu(self, *Locks::jni_libraries_lock_); library = libraries_-\u0026gt;Get(path);//libraries_ 中存储了所有已经加载了libraries的map，其中key是so全路径string，value是SharedLibrary*  } if (library != nullptr) { return xxx } // Retrieve the library path from the classloader, if necessary.  ScopedLocalRef\u0026lt;jstring\u0026gt; library_path(env, GetLibrarySearchPath(env, class_loader)); Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); const char* path_str = path.empty() ? nullptr : path.c_str(); bool needs_native_bridge = false; void* handle = android::OpenNativeLibrary(env, runtime_-\u0026gt;GetTargetSdkVersion(), path_str, class_loader, library_path.get(), \u0026amp;needs_native_bridge, error_msg); if (handle == nullptr) { VLOG(jni) \u0026lt;\u0026lt; \u0026#34;dlopen(\\\u0026#34;\u0026#34; \u0026lt;\u0026lt; path \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;, RTLD_NOW) failed: \u0026#34; \u0026lt;\u0026lt; *error_msg; return false; } bool created_library = false; { // Create SharedLibrary ahead of taking the libraries lock to maintain lock ordering.  std::unique_ptr\u0026lt;SharedLibrary\u0026gt; new_library( new SharedLibrary(env, self, path, handle, needs_native_bridge, class_loader, class_loader_allocator)); MutexLock mu(self, *Locks::jni_libraries_lock_); library = libraries_-\u0026gt;Get(path); if (library == nullptr) { // We won race to get libraries_lock.  library = new_library.release(); libraries_-\u0026gt;Put(path, library);//path为so的全路径名  created_library = true; } } bool was_successful = false; void* sym = library-\u0026gt;FindSymbol(\u0026#34;JNI_OnLoad\u0026#34;, nullptr); if (sym == nullptr) { VLOG(jni) \u0026lt;\u0026lt; \u0026#34;[No JNI_OnLoad found in \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; path \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;]\u0026#34;; was_successful = true; } else { ...... VLOG(jni) \u0026lt;\u0026lt; \u0026#34;[Calling JNI_OnLoad in \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; path \u0026lt;\u0026lt; \u0026#34;\\\u0026#34;]\u0026#34;; typedef int (*JNI_OnLoadFn)(JavaVM*, void*); JNI_OnLoadFn jni_on_load = reinterpret_cast\u0026lt;JNI_OnLoadFn\u0026gt;(sym); int version = (*jni_on_load)(this, nullptr);//调用自定义.cpp的JNI_OnLoad method  if (version == JNI_ERR) { StringAppendF(error_msg, \u0026#34;JNI_ERR returned from JNI_OnLoad in \\\u0026#34;%s\\\u0026#34;\u0026#34;, path.c_str()); } else if (JavaVMExt::IsBadJniVersion(version)) { StringAppendF(error_msg, \u0026#34;Bad JNI version returned from JNI_OnLoad in \\\u0026#34;%s\\\u0026#34;: %d\u0026#34;, path.c_str(), version); // It\u0026#39;s unwise to call dlclose() here, but we can mark it  // as bad and ensure that future load attempts will fail.  // We don\u0026#39;t know how far JNI_OnLoad got, so there could  // be some partially-initialized stuff accessible through  // newly-registered native method calls. We could try to  // unregister them, but that doesn\u0026#39;t seem worthwhile.  } else { was_successful = true; } library-\u0026gt;SetResult(was_successful); return was_successful; } system/core/libnativeloader/native_loader.cpp\nOpenNativeLibrary void* OpenNativeLibrary(JNIEnv* env, int32_t target_sdk_version, const char* path, jobject class_loader, jstring library_path, bool* needs_native_bridge, std::string* error_msg) { #if defined(__ANDROID__)  UNUSED(target_sdk_version); if (class_loader == nullptr) { *needs_native_bridge = false; return dlopen(path, RTLD_NOW); } std::lock_guard\u0026lt;std::mutex\u0026gt; guard(g_namespaces_mutex); NativeLoaderNamespace ns; if (!g_namespaces-\u0026gt;FindNamespaceByClassLoader(env, class_loader, \u0026amp;ns)) { // This is the case where the classloader was not created by ApplicationLoaders  // In this case we create an isolated not-shared namespace for it.  if (!g_namespaces-\u0026gt;Create(env, target_sdk_version, class_loader, false /* is_shared */, false /* is_for_vendor */, library_path, nullptr, \u0026amp;ns, error_msg)) { return nullptr; } } if (ns.is_android_namespace()) { android_dlextinfo extinfo; extinfo.flags = ANDROID_DLEXT_USE_NAMESPACE; extinfo.library_namespace = ns.get_android_ns(); void* handle = android_dlopen_ext(path, RTLD_NOW, \u0026amp;extinfo); if (handle == nullptr) { *error_msg = dlerror(); } *needs_native_bridge = false; return handle; } else { void* handle = NativeBridgeLoadLibraryExt(path, RTLD_NOW, ns.get_native_bridge_ns()); if (handle == nullptr) { *error_msg = NativeBridgeGetError(); } *needs_native_bridge = true; return handle; } bool FindNamespaceByClassLoader(JNIEnv* env, jobject class_loader, NativeLoaderNamespace* ns) { auto it = std::find_if(namespaces_.begin(), namespaces_.end(), [\u0026amp;](const std::pair\u0026lt;jweak, NativeLoaderNamespace\u0026gt;\u0026amp; value) { return env-\u0026gt;IsSameObject(value.first, class_loader); }); if (it != namespaces_.end()) { if (ns != nullptr) { *ns = it-\u0026gt;second; } return true; } return false; } bool is_android_namespace() const { return native_bridge_ns_ == nullptr; } external/libcxx/include/algorithm\n// find_if template \u0026lt;class _InputIterator, class _Predicate\u0026gt; inline _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR_AFTER_CXX17 _InputIterator find_if(_InputIterator __first, _InputIterator __last, _Predicate __pred) { for (; __first != __last; ++__first) if (__pred(*__first)) break; return __first; } bionic/libdl/libdl.cpp\nandroid_dlopen_ext __attribute__((__weak__)) void* android_dlopen_ext(const char* filename, int flag, const android_dlextinfo* extinfo) { const void* caller_addr = __builtin_return_address(0); return __loader_android_dlopen_ext(filename, flag, extinfo, caller_addr); } FindSymbol // No mutator lock since dlsym may block for a while if another thread is doing dlopen. void* FindSymbol(const std::string\u0026amp; symbol_name, const char* shorty = nullptr) REQUIRES(!Locks::mutator_lock_) { return NeedsNativeBridge() ? FindSymbolWithNativeBridge(symbol_name.c_str(), shorty) : FindSymbolWithoutNativeBridge(symbol_name.c_str()); } // No mutator lock since dlsym may block for a while if another thread is doing dlopen. void* FindSymbolWithoutNativeBridge(const std::string\u0026amp; symbol_name) REQUIRES(!Locks::mutator_lock_) { CHECK(!NeedsNativeBridge()); return dlsym(handle_, symbol_name.c_str()); } bionic/libdl/libdl.cpp\ndlsym __attribute__((__weak__)) void* dlsym(void* handle, const char* symbol) { const void* caller_addr = __builtin_return_address(0); return __loader_dlsym(handle, symbol, caller_addr); } JNI_OnLoad JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM *vm, void *reserved) { } art/runtime/jni_internal.cc\nRegisterNatives static jint RegisterNatives(JNIEnv* env, jclass java_class, const JNINativeMethod* methods, jint method_count) { ScopedObjectAccess soa(env); StackHandleScope\u0026lt;1\u0026gt; hs(soa.Self()); Handle\u0026lt;mirror::Class\u0026gt; c = hs.NewHandle(soa.Decode\u0026lt;mirror::Class\u0026gt;(java_class)); for (jint i = 0; i \u0026lt; method_count; ++i) { const char* name = methods[i].name; const char* sig = methods[i].signature; const void* fnPtr = methods[i].fnPtr; bool is_fast = false; // Notes about fast JNI calls:  //  // On a normal JNI call, the calling thread usually transitions  // from the kRunnable state to the kNative state. But if the  // called native function needs to access any Java object, it  // will have to transition back to the kRunnable state.  //  // There is a cost to this double transition. For a JNI call  // that should be quick, this cost may dominate the call cost.  //  // On a fast JNI call, the calling thread avoids this double  // transition by not transitioning from kRunnable to kNative and  // stays in the kRunnable state.  //  // There are risks to using a fast JNI call because it can delay  // a response to a thread suspension request which is typically  // used for a GC root scanning, etc. If a fast JNI call takes a  // long time, it could cause longer thread suspension latency  // and GC pauses.  //  // Thus, fast JNI should be used with care. It should be used  // for a JNI call that takes a short amount of time (eg. no  // long-running loop) and does not block (eg. no locks, I/O,  // etc.)  //  // A \u0026#39;!\u0026#39; prefix in the signature in the JNINativeMethod  // indicates that it\u0026#39;s a fast JNI call and the runtime omits the  // thread state transition from kRunnable to kNative at the  // entry.  if (*sig == \u0026#39;!\u0026#39;) { is_fast = true; ++sig; } // Note: the right order is to try to find the method locally  // first, either as a direct or a virtual method. Then move to  // the parent.  ArtMethod* m = nullptr; for (ObjPtr\u0026lt;mirror::Class\u0026gt; current_class = c.Get(); current_class != nullptr; current_class = current_class-\u0026gt;GetSuperClass()) { // Search first only comparing methods which are native.  m = FindMethod\u0026lt;true\u0026gt;(current_class.Ptr(), name, sig); if (m != nullptr) { break; } // Search again comparing to all methods, to find non-native methods that match.  m = FindMethod\u0026lt;false\u0026gt;(current_class.Ptr(), name, sig); if (m != nullptr) { break; } } const void* final_function_ptr = m-\u0026gt;RegisterNative(fnPtr); } } art_method.cc\nArtMethod::RegisterNative const void* ArtMethod::RegisterNative(const void* native_method) { CHECK(IsNative()) \u0026lt;\u0026lt; PrettyMethod(); CHECK(native_method != nullptr) \u0026lt;\u0026lt; PrettyMethod(); void* new_native_method = nullptr; Runtime::Current()-\u0026gt;GetRuntimeCallbacks()-\u0026gt;RegisterNativeMethod(this, native_method, /*out*/\u0026amp;new_native_method); SetEntryPointFromJni(new_native_method); return new_native_method; } SetEntryPointFromJni void SetEntryPointFromJni(const void* entrypoint) { DCHECK(IsNative()); SetEntryPointFromJniPtrSize(entrypoint, kRuntimePointerSize); } ALWAYS_INLINE void SetEntryPointFromJniPtrSize(const void* entrypoint, PointerSize pointer_size) { SetDataPtrSize(entrypoint, pointer_size); } ALWAYS_INLINE void SetDataPtrSize(const void* data, PointerSize pointer_size) { DCHECK(IsImagePointerSize(pointer_size)); SetNativePointer(DataOffset(pointer_size), data, pointer_size);//DataOffset,对应ArtMethod的data_字段 } static MemberOffset EntryPointFromJniOffset(PointerSize pointer_size) { return DataOffset(pointer_size); } static MemberOffset DataOffset(PointerSize pointer_size) { return MemberOffset(PtrSizedFieldsOffset(pointer_size) + OFFSETOF_MEMBER( PtrSizedFields, data_) / sizeof(void*) * static_cast\u0026lt;size_t\u0026gt;(pointer_size)); } static MemberOffset EntryPointFromQuickCompiledCodeOffset(PointerSize pointer_size) { return MemberOffset(PtrSizedFieldsOffset(pointer_size) + OFFSETOF_MEMBER( PtrSizedFields, entry_point_from_quick_compiled_code_) / sizeof(void*)//对应ArtMethod的entry_point_from_quick_compiled_code_字段  * static_cast\u0026lt;size_t\u0026gt;(pointer_size)); } art/runtime/runtime_callbacks.cc\nRuntimeCallbacks::RegisterNativeMethod void RuntimeCallbacks::RegisterNativeMethod(ArtMethod* method, const void* in_cur_method, /*out*/void** new_method) { void* cur_method = const_cast\u0026lt;void*\u0026gt;(in_cur_method); *new_method = cur_method; for (MethodCallback* cb : method_callbacks_) { cb-\u0026gt;RegisterNativeMethod(method, cur_method, new_method); if (*new_method != nullptr) { cur_method = *new_method; } } } art/openjdkjvmti/ti_method.cc\nti_method.cc.RegisterNativeMethod void RegisterNativeMethod(art::ArtMethod* method, const void* cur_method, /*out*/void** new_method) OVERRIDE REQUIRES_SHARED(art::Locks::mutator_lock_) { if (event_handler-\u0026gt;IsEventEnabledAnywhere(ArtJvmtiEvent::kNativeMethodBind)) { ...... } } 参考 【Android】动态链接库so的加载原理\nhttps://github.com/KeepSafe/ReLinker\nhttps://github.com/facebook/SoLoader\njava.lang.UnsatisfiedLinkError 的解决办法\n其他 bionic/linker/linker.cpp\nlinker.cpp load_library static bool load_library(android_namespace_t* ns, LoadTask* task, LoadTaskList* load_tasks, int rtld_flags, const std::string\u0026amp; realpath, bool search_linked_namespaces) { "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/zygote/systemserversource/",
	"title": "SystemServerSource",
	"tags": [],
	"description": "",
	"content": "main /** * The main entry point from zygote. */ public static void main(String[] args) { new SystemServer().run(); } run private void run() { // The system server should never make non-oneway calls  Binder.setWarnOnBlocking(true); // Ensure binder calls into the system always run at foreground priority.  BinderInternal.disableBackgroundScheduling(true); // Increase the number of binder threads in system_server  BinderInternal.setMaxThreads(sMaxBinderThreads); // Prepare the main looper thread (this thread).  android.os.Process.setThreadPriority( android.os.Process.THREAD_PRIORITY_FOREGROUND); android.os.Process.setCanSelfBackground(false); Looper.prepareMainLooper(); startBootstrapServices(); startCoreServices(); startOtherServices(); // Loop forever.  Looper.loop(); throw new RuntimeException(\u0026#34;Main thread loop unexpectedly exited\u0026#34;); } startOtherServices private void startOtherServices() { traceBeginAndSlog(\u0026#34;StartInputManagerService\u0026#34;); inputManager = new InputManagerService(context); traceEnd(); traceBeginAndSlog(\u0026#34;StartWindowManagerService\u0026#34;); // WMS needs sensor service ready  ConcurrentUtils.waitForFutureNoInterrupt(mSensorServiceStart, START_SENSOR_SERVICE); mSensorServiceStart = null; wm = WindowManagerService.main(context, inputManager, mFactoryTestMode != FactoryTest.FACTORY_TEST_LOW_LEVEL, !mFirstBoot, mOnlyCore, new PhoneWindowManager()); ServiceManager.addService(Context.WINDOW_SERVICE, wm, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL | DUMP_FLAG_PROTO); ServiceManager.addService(Context.INPUT_SERVICE, inputManager, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL); } "
},
{
	"uri": "https://huanle19891345.github.io/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/textureview/",
	"title": "textureview",
	"tags": [],
	"description": "",
	"content": "textureview 探索总结textureview知识\n TextureViewSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/textureview/textureviewsource/",
	"title": "TextureViewSource",
	"tags": [],
	"description": "",
	"content": "//TextureView private TextureLayer mLayer; private SurfaceTexture mSurface; private SurfaceTextureListener mListener; public void setSurfaceTextureListener(SurfaceTextureListener listener) { mListener = listener; } draw @Override public final void draw(Canvas canvas) { mPrivateFlags = (mPrivateFlags \u0026amp; ~PFLAG_DIRTY_MASK) | PFLAG_DRAWN; /* Simplify drawing to guarantee the layer is the only thing drawn - so e.g. no background, scrolling, or fading edges. This guarantees all drawing is in the layer, so drawing properties (alpha, layer paint) affect all of the content of a TextureView. */ if (canvas.isHardwareAccelerated()) { DisplayListCanvas displayListCanvas = (DisplayListCanvas) canvas; TextureLayer layer = getTextureLayer();//main  if (layer != null) { applyUpdate(); applyTransformMatrix(); mLayer.setLayerPaint(mLayerPaint); // ensure layer paint is up to date  displayListCanvas.drawTextureLayer(layer); } } } 创建或更新TextureLayer TextureLayer getTextureLayer() { if (mLayer == null) { if (mAttachInfo == null || mAttachInfo.mThreadedRenderer == null) { return null; } mLayer = mAttachInfo.mThreadedRenderer.createTextureLayer();//main1  boolean createNewSurface = (mSurface == null); if (createNewSurface) { // Create a new SurfaceTexture for the layer.  mSurface = new SurfaceTexture(false);//main2  nCreateNativeWindow(mSurface);//main2  } mLayer.setSurfaceTexture(mSurface);//main2  mSurface.setDefaultBufferSize(getWidth(), getHeight()); mSurface.setOnFrameAvailableListener(mUpdateListener, mAttachInfo.mHandler);//main3  if (mListener != null \u0026amp;\u0026amp; createNewSurface) { mListener.onSurfaceTextureAvailable(mSurface, getWidth(), getHeight());//main4  } mLayer.setLayerPaint(mLayerPaint); } if (mUpdateSurface) { // Someone has requested that we use a specific SurfaceTexture, so  // tell mLayer about it and set the SurfaceTexture to use the  // current view size.  mUpdateSurface = false; // Since we are updating the layer, force an update to ensure its  // parameters are correct (width, height, transform, etc.)  updateLayer();//main5  mMatrixChanged = true; mLayer.setSurfaceTexture(mSurface);//main5  mSurface.setDefaultBufferSize(getWidth(), getHeight());//main5  } return mLayer; } createTextureLayer nCreateTextureLayer /** * Creates a new hardware layer. A hardware layer built by calling this * method will be treated as a texture layer, instead of as a render target. * * @return A hardware layer */ TextureLayer createTextureLayer() { long layer = nCreateTextureLayer(mNativeProxy); return TextureLayer.adoptTextureLayer(this, layer); } //frameworks/base/core/jni/android_view_ThreadedRenderer.cpp static jlong android_view_ThreadedRenderer_createTextureLayer(JNIEnv* env, jobject clazz, jlong proxyPtr) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); DeferredLayerUpdater* layer = proxy-\u0026gt;createTextureLayer(); return reinterpret_cast\u0026lt;jlong\u0026gt;(layer); } //frameworks/base/libs/hwui/renderthread/RenderProxy.cpp DeferredLayerUpdater* RenderProxy::createTextureLayer() { return mRenderThread.queue().runSync([this]() -\u0026gt; auto { return mContext-\u0026gt;createTextureLayer(); }); } //frameworks/base/libs/hwui/renderthread/CanvasContext.cpp DeferredLayerUpdater* CanvasContext::createTextureLayer() { return mRenderPipeline-\u0026gt;createTextureLayer(); } CanvasContext* CanvasContext::create(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) { auto renderType = Properties::getRenderPipelineType(); switch (renderType) { case RenderPipelineType::OpenGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;OpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaOpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaVulkan: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaVulkanPipeline\u0026gt;(thread)); default: LOG_ALWAYS_FATAL(\u0026#34;canvas context type %d not supported\u0026#34;, (int32_t)renderType); break; } return nullptr; } 这里面是指Skia兼容的OpenGL模式。vulkan是当前性能更优，框架比起OpenGL es更加小巧的方案。当然Android P默认是使用SkiaOpenGLPipeline，而Android O是OpenGLPipeline。我们来讨论这一种。现在我们在讨论Android 9.0，理应解析SkiaOpenGLPipeline。当然从源码的角度来看Android P和O两者创建TextureLayer的逻辑上是一致的。\n//frameworks/base/libs/hwui/pipeline/skia/SkiaOpenGLPipeline.cpp DeferredLayerUpdater* SkiaOpenGLPipeline::createTextureLayer() { mEglManager.initialize(); return new DeferredLayerUpdater(mRenderThread.renderState(), createLayer, Layer::Api::OpenGL); } static Layer* createLayer(RenderState\u0026amp; renderState, uint32_t layerWidth, uint32_t layerHeight, sk_sp\u0026lt;SkColorFilter\u0026gt; colorFilter, int alpha, SkBlendMode mode, bool blend) { GlLayer* layer = new GlLayer(renderState, layerWidth, layerHeight, colorFilter, alpha, mode, blend); layer-\u0026gt;generateTexture(); return layer; } TextureLayer.adoptTextureLayer static TextureLayer adoptTextureLayer(ThreadedRenderer renderer, long layer) { return new TextureLayer(renderer, layer); } new SurfaceTexture public SurfaceTexture(boolean singleBufferMode) { mCreatorLooper = Looper.myLooper(); mIsSingleBuffered = singleBufferMode; nativeInit(true, 0, singleBufferMode, new WeakReference\u0026lt;SurfaceTexture\u0026gt;(this)); } new GLConsumer //frameworks/base/core/jni/android/graphics/SurfaceTexture.cpp static void SurfaceTexture_init(JNIEnv* env, jobject thiz, jboolean isDetached, jint texName, jboolean singleBufferMode, jobject weakThiz) { sp\u0026lt;IGraphicBufferProducer\u0026gt; producer; sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer; BufferQueue::createBufferQueue(\u0026amp;producer, \u0026amp;consumer); sp\u0026lt;GLConsumer\u0026gt; surfaceTexture; if (isDetached) { surfaceTexture = new GLConsumer(consumer, GL_TEXTURE_EXTERNAL_OES, true, !singleBufferMode); } else { surfaceTexture = new GLConsumer(consumer, texName, GL_TEXTURE_EXTERNAL_OES, true, !singleBufferMode); } SurfaceTexture_setSurfaceTexture(env, thiz, surfaceTexture); SurfaceTexture_setProducer(env, thiz, producer); jclass clazz = env-\u0026gt;GetObjectClass(thiz); if (clazz == NULL) { jniThrowRuntimeException(env, \u0026#34;Can\u0026#39;t find android/graphics/SurfaceTexture\u0026#34;); return; } sp\u0026lt;JNISurfaceTextureContext\u0026gt; ctx(new JNISurfaceTextureContext(env, weakThiz,clazz)); surfaceTexture-\u0026gt;setFrameAvailableListener(ctx); SurfaceTexture_setFrameAvailableListener(env, thiz, ctx);//GLConsumer本质上也是一个图元消费者。当Surface调用了queueBuffer之后，将会调用setFrameAvailableListener注册的监听。 } 当然在初始化GLConsumer过程中，分为2种方式一种是detach一种是非detach。这两个有什么区别呢？最主要的区别就是可以设置texName纹理id。因为OpenGL es的纹理是跟着线程的OpenGL的上下文走的。因此，在TextureView在不同线程渲染同一个SurfaceTexture，需要进行一次detach，重新绑定一次当前线程新的纹理。\nstatic void SurfaceTexture_setFrameAvailableListener(JNIEnv* env, jobject thiz, sp\u0026lt;GLConsumer::FrameAvailableListener\u0026gt; listener) { GLConsumer::FrameAvailableListener* const p = (GLConsumer::FrameAvailableListener*) env-\u0026gt;GetLongField(thiz, fields.frameAvailableListener); if (listener.get()) { listener-\u0026gt;incStrong((void*)SurfaceTexture_setSurfaceTexture); } if (p) { p-\u0026gt;decStrong((void*)SurfaceTexture_setSurfaceTexture); } env-\u0026gt;SetLongField(thiz, fields.frameAvailableListener, (jlong)listener.get()); } 每当有图元通过queueBuffer把图元传递进来则会调用如下方法：\nvoid JNISurfaceTextureContext::onFrameAvailable(const BufferItem\u0026amp; /* item */) { bool needsDetach = false; JNIEnv* env = getJNIEnv(\u0026amp;needsDetach); if (env != NULL) { env-\u0026gt;CallStaticVoidMethod(mClazz, fields.postEvent, mWeakThiz); } else { ALOGW(\u0026#34;onFrameAvailable event will not posted\u0026#34;); } if (needsDetach) { detachJNI(); } } 这个方法本质上是反射调用SurfaceTexture中的postEventFromNative方法：\nprivate static void postEventFromNative(WeakReference\u0026lt;SurfaceTexture\u0026gt; weakSelf) { SurfaceTexture st = weakSelf.get(); if (st != null) { Handler handler = st.mOnFrameAvailableHandler; if (handler != null) { handler.sendEmptyMessage(0); } } } nCreateNativeWindow(mSurface) //frameworks/base/core/jni/android_view_TextureView.cpp static void android_view_TextureView_createNativeWindow(JNIEnv* env, jobject textureView, jobject surface) { sp\u0026lt;IGraphicBufferProducer\u0026gt; producer(SurfaceTexture_getProducer(env, surface)); sp\u0026lt;ANativeWindow\u0026gt; window = new Surface(producer, true); window-\u0026gt;incStrong((void*)android_view_TextureView_createNativeWindow); SET_LONG(textureView, gTextureViewClassInfo.nativeWindow, jlong(window.get())); } sp\u0026lt;IGraphicBufferProducer\u0026gt; SurfaceTexture_getProducer(JNIEnv* env, jobject thiz) { return (IGraphicBufferProducer*)env-\u0026gt;GetLongField(thiz, fields.producer); } 把SurfaceTexture的GraphicBufferProducer设置到Surface中，之后这个Surface可以利用它进行图元出队和入队的操作\nmSurface.setOnFrameAvailableListener private final SurfaceTexture.OnFrameAvailableListener mUpdateListener = new SurfaceTexture.OnFrameAvailableListener() { @Override public void onFrameAvailable(SurfaceTexture surfaceTexture) { updateLayer(); invalidate(); } }; private void updateLayer() { synchronized (mLock) { mUpdateLayer = true; } } 绘制 通过draw方法的getTextureLayer方法初始化好TextureView的绘制环境。接着就会执行下面的方法\nif (layer != null) { applyUpdate();//1 TextureLayer更新准备  applyTransformMatrix();//2  mLayer.setLayerPaint(mLayerPaint); // ensure layer paint is up to date 3  displayListCanvas.drawTextureLayer(layer);//4  } applyUpdate private void applyUpdate() { if (mLayer == null) { return; } synchronized (mLock) { if (mUpdateLayer) { mUpdateLayer = false; } else { return; } } mLayer.prepare(getWidth(), getHeight(), mOpaque); mLayer.updateSurfaceTexture(); if (mListener != null) { mListener.onSurfaceTextureUpdated(mSurface); } } TextureLayer.prepare public boolean prepare(int width, int height, boolean isOpaque) { return nPrepare(mFinalizer.get(), width, height, isOpaque); } android_view_TextureLayer.cpp\nstatic jboolean TextureLayer_prepare(JNIEnv* env, jobject clazz, jlong layerUpdaterPtr, jint width, jint height, jboolean isOpaque) { DeferredLayerUpdater* layer = reinterpret_cast\u0026lt;DeferredLayerUpdater*\u0026gt;(layerUpdaterPtr); bool changed = false; changed |= layer-\u0026gt;setSize(width, height); changed |= layer-\u0026gt;setBlend(!isOpaque); return changed; } 可以看到prepare其实就是给DeferredLayerUpdater设置是否开启透明以及DeferredLayerUpdater的绘制范围。换句话说，就是TextureView绘制的宽高。保存到DeferredLayerUpdater中。\nTextureLayer.updateSurfaceTexture android_view_TextureLayer.cpp\nstatic void TextureLayer_updateSurfaceTexture(JNIEnv* env, jobject clazz, jlong layerUpdaterPtr) { DeferredLayerUpdater* layer = reinterpret_cast\u0026lt;DeferredLayerUpdater*\u0026gt;(layerUpdaterPtr); layer-\u0026gt;updateTexImage(); } 此时将会调用DeferredLayerUpdater的updateTexImage。打开了刷新的标志位。\napplyTransformMatrix private void applyTransformMatrix() { if (mMatrixChanged \u0026amp;\u0026amp; mLayer != null) { mLayer.setTransform(mMatrix); mMatrixChanged = false; } } //frameworks/base/core/java/android/view/TextureLayer.java  public void setTransform(Matrix matrix) { nSetTransform(mFinalizer.get(), matrix.native_instance); mRenderer.pushLayerUpdate(this); } nSetTransform nSetTransform把Matrix保存在DeferredLayerUpdater。\nmRenderer.pushLayerUpdate 是核心，调用ThreadRenderer的pushLayerUpdate，把TextureLayer压入栈中。\n//frameworks/base/core/jni/android_view_ThreadedRenderer.cpp static void android_view_ThreadedRenderer_pushLayerUpdate(JNIEnv* env, jobject clazz, jlong proxyPtr, jlong layerPtr) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); DeferredLayerUpdater* layer = reinterpret_cast\u0026lt;DeferredLayerUpdater*\u0026gt;(layerPtr); proxy-\u0026gt;pushLayerUpdate(layer); } //frameworks/base/libs/hwui/renderthread/RenderProxy.cpp void RenderProxy::pushLayerUpdate(DeferredLayerUpdater* layer) { mDrawFrameTask.pushLayerUpdate(layer); } 在这里就把DeferredLayerUpdater保存到DrawFrameTask中，等待ViewRootImpl后续流程统一把DrawFrameTask中保存的内容进行绘制。\n//frameworks/base/libs/hwui/renderthread/DrawFrameTask.cpp  /********************************************* * Single frame data *********************************************/ std::vector\u0026lt;sp\u0026lt;DeferredLayerUpdater\u0026gt; \u0026gt; mLayers; void DrawFrameTask::pushLayerUpdate(DeferredLayerUpdater* layer) { for (size_t i = 0; i \u0026lt; mLayers.size(); i++) { if (mLayers[i].get() == layer) { return; } } mLayers.push_back(layer); } DeferredLayerUpdater将会把没有保存过的layer保存到mLayers这个集合当中。\nTextureLayer.setLayerPaint static void TextureLayer_setLayerPaint(JNIEnv* env, jobject clazz, jlong layerUpdaterPtr, jlong paintPtr) { DeferredLayerUpdater* layer = reinterpret_cast\u0026lt;DeferredLayerUpdater*\u0026gt;(layerUpdaterPtr); if (layer) { Paint* paint = reinterpret_cast\u0026lt;Paint*\u0026gt;(paintPtr); layer-\u0026gt;setPaint(paint); } } DisplayListCanvas.drawTextureLayer //frameworks/base/core/java/android/view/DisplayListCanvas.java  void drawTextureLayer(TextureLayer layer) { nDrawTextureLayer(mNativeCanvasWrapper, layer.getLayerHandle()); } //frameworks/base/core/jni/android_view_DisplayListCanvas.cpp static void android_view_DisplayListCanvas_drawTextureLayer(jlong canvasPtr, jlong layerPtr) { Canvas* canvas = reinterpret_cast\u0026lt;Canvas*\u0026gt;(canvasPtr); DeferredLayerUpdater* layer = reinterpret_cast\u0026lt;DeferredLayerUpdater*\u0026gt;(layerPtr); canvas-\u0026gt;drawLayer(layer); } DisplayListCanvas对应在native层，也是根据pipe的类型生成对应不同的硬件渲染Canvas，在这里我们挑选默认的SkiaRecordingCanvas来聊聊。接下来就会调用SkiaRecordingCanvas的drawLayer方法。\nSkiaRecordingCanvas.drawLayer //frameworks/base/libs/hwui/pipeline/skia/SkiaRecordingCanvas.cpp void SkiaRecordingCanvas::drawLayer(uirenderer::DeferredLayerUpdater* layerUpdater) { if (layerUpdater != nullptr) { // Create a ref-counted drawable, which is kept alive by sk_sp in SkLiteDL.  sk_sp\u0026lt;SkDrawable\u0026gt; drawable(new LayerDrawable(layerUpdater)); drawDrawable(drawable.get()); } } 此时会使用一个智能指针包裹LayerDrawable。LayerDrawable则会持有DeferredLayerUpdater。drawDrawable绘制LayerDrawable中的内容。由于SkiaRecordingCanvas继承于SkiaCanvas。从上一篇文章可知，SkiaCanvas中真正在工作的是SkCanvas。我们直接看看SkCanvas的drawDrawable方法。\nSkCanvas.drawDrawable ///external/skia/src/core/SkCanvas.cpp void drawDrawable(SkDrawable* drawable, const SkMatrix* matrix = nullptr); void SkCanvas::drawDrawable(SkDrawable* dr, const SkMatrix* matrix) { #ifndef SK_BUILD_FOR_ANDROID_FRAMEWORK  TRACE_EVENT0(\u0026#34;skia\u0026#34;, TRACE_FUNC); #endif  RETURN_ON_NULL(dr); if (matrix \u0026amp;\u0026amp; matrix-\u0026gt;isIdentity()) { matrix = nullptr; } this-\u0026gt;onDrawDrawable(dr, matrix); } void SkCanvas::onDrawDrawable(SkDrawable* dr, const SkMatrix* matrix) { // drawable bounds are no longer reliable (e.g. android displaylist)  // so don\u0026#39;t use them for quick-reject  dr-\u0026gt;draw(this, matrix); } SkDrawable.draw ///external/skia/src/core/SkDrawable.cpp void SkDrawable::draw(SkCanvas* canvas, const SkMatrix* matrix) { SkAutoCanvasRestore acr(canvas, true); if (matrix) { canvas-\u0026gt;concat(*matrix); } this-\u0026gt;onDraw(canvas); .... } 在SkDrawable则会调用onDraw方法。onDraw是一个虚函数，在LayerDrawable中实现了。\nLayerDrawable.onDraw void LayerDrawable::onDraw(SkCanvas* canvas) { Layer* layer = mLayerUpdater-\u0026gt;backingLayer(); if (layer) { DrawLayer(canvas-\u0026gt;getGrContext(), canvas, layer); } } 会从DeferredLayerUpdater 获取Layer对象，而这个Layer对象就是通过DeferredLayerUpdater保存的函数指针生成的GLLayer。但是第一次刷新界面的时候，并没有诞生出一个GLLayer进行绘制。所以不会继续走。\n那么到这里，我们似乎遇到了瓶颈了，究竟是在什么时候才会真正的生成GLLayer。\n硬件加速绘制中的syncframestate方法就是把deferredlayerupdater转化为gllayer。\nDrawFrameTask.syncFrameState bool DrawFrameTask::syncFrameState(TreeInfo\u0026amp; info) { ATRACE_CALL(); int64_t vsync = mFrameInfo[static_cast\u0026lt;int\u0026gt;(FrameInfoIndex::Vsync)]; mRenderThread-\u0026gt;timeLord().vsyncReceived(vsync); bool canDraw = mContext-\u0026gt;makeCurrent(); mContext-\u0026gt;unpinImages(); for (size_t i = 0; i \u0026lt; mLayers.size(); i++) { mLayers[i]-\u0026gt;apply(); } mLayers.clear(); .... return info.prepareTextures; } 能看到，把OpenGL es的上下文切换为当前线程之后，调用每一个Layer的apply进行处理，并且清空mLayers集合。\n此时我们看看DeferredLayerUpdater的apply。\nDeferredLayerUpdater.apply ///frameworks/base/libs/hwui/DeferredLayerUpdater.cpp void DeferredLayerUpdater::apply() { if (!mLayer) { mLayer = mCreateLayerFn(mRenderState, mWidth, mHeight, mColorFilter, mAlpha, mMode, mBlend); } mLayer-\u0026gt;setColorFilter(mColorFilter); mLayer-\u0026gt;setAlpha(mAlpha, mMode); if (mSurfaceTexture.get()) { if (mLayer-\u0026gt;getApi() == Layer::Api::Vulkan) { ... } else { if (!mGLContextAttached) { mGLContextAttached = true; mUpdateTexImage = true; mSurfaceTexture-\u0026gt;attachToContext(static_cast\u0026lt;GlLayer*\u0026gt;(mLayer)-\u0026gt;getTextureId());//main  } if (mUpdateTexImage) { mUpdateTexImage = false; doUpdateTexImage();//main  } GLenum renderTarget = mSurfaceTexture-\u0026gt;getCurrentTextureTarget(); static_cast\u0026lt;GlLayer*\u0026gt;(mLayer)-\u0026gt;setRenderTarget(renderTarget);//main  } if (mTransform) { mLayer-\u0026gt;getTransform().load(*mTransform);//main  setTransform(nullptr); } } } 能看到如果判断到mLayer为空，则调用之前保存下来的方法指针生成一个GlLayer。mSurfaceTexture在这里就是上面保存下来的GLConsumer。\n 1.调用GlLayer的attachToContext进行上下文切换和GlLayer中的纹理id进行绑定。 2.调用 doUpdateTexImage 更新纹理数据 3.设置GlLayer渲染的纹理为GLConsumer当前渲染的纹理。 4.GlLayer保存变换矩阵。  \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.\nLayerDrawable.DrawLayer //frameworks/base/libs/hwui/pipeline/skia/LayerDrawable.cpp bool LayerDrawable::DrawLayer(GrContext* context, SkCanvas* canvas, Layer* layer, const SkRect* dstRect) { ... // transform the matrix based on the layer  SkMatrix layerTransform; layer-\u0026gt;getTransform().copyTo(layerTransform); sk_sp\u0026lt;SkImage\u0026gt; layerImage; const int layerWidth = layer-\u0026gt;getWidth(); const int layerHeight = layer-\u0026gt;getHeight(); if (layer-\u0026gt;getApi() == Layer::Api::OpenGL) { GlLayer* glLayer = static_cast\u0026lt;GlLayer*\u0026gt;(layer); GrGLTextureInfo externalTexture; externalTexture.fTarget = glLayer-\u0026gt;getRenderTarget(); externalTexture.fID = glLayer-\u0026gt;getTextureId(); externalTexture.fFormat = GL_RGBA8; GrBackendTexture backendTexture(layerWidth, layerHeight, GrMipMapped::kNo, externalTexture); layerImage = SkImage::MakeFromTexture(context, backendTexture, kTopLeft_GrSurfaceOrigin, kPremul_SkAlphaType, nullptr); } else { ... } if (layerImage) { SkMatrix textureMatrixInv; layer-\u0026gt;getTexTransform().copyTo(textureMatrixInv); // TODO: after skia bug https://bugs.chromium.org/p/skia/issues/detail?id=7075 is fixed  // use bottom left origin and remove flipV and invert transformations.  SkMatrix flipV; flipV.setAll(1, 0, 0, 0, -1, 1, 0, 0, 1); textureMatrixInv.preConcat(flipV); textureMatrixInv.preScale(1.0f / layerWidth, 1.0f / layerHeight); textureMatrixInv.postScale(layerWidth, layerHeight); SkMatrix textureMatrix; if (!textureMatrixInv.invert(\u0026amp;textureMatrix)) { textureMatrix = textureMatrixInv; } SkMatrix matrix = SkMatrix::Concat(layerTransform, textureMatrix); SkPaint paint; paint.setAlpha(layer-\u0026gt;getAlpha()); paint.setBlendMode(layer-\u0026gt;getMode()); paint.setColorFilter(layer-\u0026gt;getColorSpaceWithFilter()); const bool nonIdentityMatrix = !matrix.isIdentity(); if (nonIdentityMatrix) { canvas-\u0026gt;save(); canvas-\u0026gt;concat(matrix); } if (dstRect) { SkMatrix matrixInv; if (!matrix.invert(\u0026amp;matrixInv)) { matrixInv = matrix; } SkRect srcRect = SkRect::MakeIWH(layerWidth, layerHeight); matrixInv.mapRect(\u0026amp;srcRect); SkRect skiaDestRect = *dstRect; matrixInv.mapRect(\u0026amp;skiaDestRect); canvas-\u0026gt;drawImageRect(layerImage.get(), srcRect, skiaDestRect, \u0026amp;paint, SkCanvas::kFast_SrcRectConstraint); } else { canvas-\u0026gt;drawImage(layerImage.get(), 0, 0, \u0026amp;paint); } // restore the original matrix  if (nonIdentityMatrix) { canvas-\u0026gt;restore(); } } return layerImage; } 接下来将执行如下步骤：\n 1.判断到是OpenGL类型的pipeline。接着通过GlLayer保存的纹理对象生成GrBackendTexture里面保存着当前TextureLayer的宽高(也就是TextureView在draw中applyUpdate的保存下来的TextureView的宽高)。最后通过GrBackendTexture生成一个SkImage对象。 2.根据变换矩阵处理SkImage 3.canvas 在一个区域内绘制SkImage中的像素。  到这里面就完成了TextureView的解析。\n核心原理图 关键角色 总结一下，里面有几个十分关键的角色：\n 1.ThreadedRenderer 是硬件渲染的入口点，里面包含了所有硬件渲染的根RenderNode，以及一个根DisplayListCanvas。虽然每一个View一般都会包含自己的DisplayListCanvas。之所以存在一个根是为了公用一个DisplayListCanvas中的DisplayList。 2.CanvasContext 硬件渲染的上下文，根据当前模式选择合适的硬件渲染管道。而管道就是真正执行具体模式的绘制行为。 3.DrawFrameTask 保存所有的App中硬件渲染的Layer。当然这个Layer要和SF进程的Layer要区分，不是一个东西。在TextureView中是指DeferredLayerUpdater，真正执行具体行为的是GlLayer。 4.TextureLayer 在TextureView中承担一个TextureView 图层角色。其中包含了TextureView图元消费端SurfaceTexture，图层更新者DeferredLayerUpdater，以及ThreadedRenderer。 5.DeferredLayerUpdater 图层更新者。这相当于一个Holder，不会一开始就从内存中申请一个纹理对象。纹理对象可是很消耗内存的。因此会等到第一次draw调用之后，才会通过syncFrame的方法从CanvasContext生成GlLayer。GlLayer则是真正的控制图层，而这个图层实际上就是一个OpenGL es的纹理对象。 6.RenderNode 每一个View在硬件渲染对应的每一个节点。 7.DisplayListCanvas 通过RenderNode生成的一个画板。所有的像素都会画上去，并且可以和来自父View中DisplayListCanvas的DisplayList进行合并。  流程总结 graph LR subgraph firstFrame draw--\u0026gt;createTextureLayer,GLComsumer--\u0026gt;syncFrameState--\u0026gt;createGLLayer end createGLLayer--\u0026gt;|invalid|DrawLayer(\u0026quot;LayerDrawable.DrawLayer\u0026quot;) subgraph secondFrame DrawLayer--\u0026gt;|drawIntoDisplayListCanvas|CanvasContext.draw--\u0026gt;swapBuffers end 上面那个例子TextureView之所以可以正常的运作，是因为把SurfaceTexture设置到Camera中了。让Camera在背后操作图元消费者SurfaceTexture。\n重新梳理一次流程。\n 1.当我们把Camera都设置了TextureView之后，经过第一次的draw之后，将会创建一个TextureLayer，GLConsumer。此时draw的遍历结束，就会执行ThreadedRenderer的syncFrameState方法，生成真正的GlLayer，并且调用invalid进行下一轮的绘制。 2.进入到下一轮的绘制之后，将会继续调用DisplayListCanvas的drawTextureLayer，进行LayerDrawable.DrawLayer的方法调用，把像素绘制到DisplayListCanvas中，最后调用CanvasContext的draw的方法，并且通过其中的swapBuffers把图元发送的SF进程。  换句话说，我们在TextureView中不断的更新纹理的内容，而纹理的绘制和发送却依赖ViewRootImpl发送的draw信号。因此我们没有办法看到像软件渲染那样有lockCanvas和unlockCanvasAndPost的方法那样在绘制前后有一个明显的dequeueBuffer和queueBuffer的操作。如果阅读过我写的OpenGL es软件渲染一文，就能明白其实swapBuffer方法里面本身就带着dequeueBuffer和queueBuffer的方法。\n参考 Android 重学系列 SurfaceView和TextureView 源码浅析(下)\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/thread/",
	"title": "thread",
	"tags": [],
	"description": "",
	"content": "thread 探索总结thread知识\n StackTraceElement     ThreadState     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/handler/threadlocal/",
	"title": "ThreadLocal",
	"tags": [],
	"description": "",
	"content": "ThreadLocal模型 graph LR thread--\u0026gt;threadLocalMap threadLocalMap--\u0026gt;entry1 threadLocalMap--\u0026gt;entry2 threadLocalMap--\u0026gt;entryLooper threadLocalMap--\u0026gt;entryxxx entry1--\u0026gt;key=threadlocal1,value=T1 entry2--\u0026gt;key=threadlocal2,value=T2 entryLooper--\u0026gt;LooperEntry(key=threadlocal_Looper,value=Looper) LooperEntry--\u0026gt;MessageQueue  线性探测解决hash冲突 超过默认长度(16)的2/3时rehash减少hash冲突，扩容一倍 threadlocal作为key保存在entry中时是WeakReference，在被回收时清除记录，因此需要外部定义TheadLocal实例的地方配置为static，否则在外部回收threadlocal时，threadlocalmap中的entry也会被清理掉 lazy模式，只有添加第一个 元素时才通过createMap创建ThreadLocalMap  Thread /* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; /* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ThreadLocal threadLocalHashCode public class ThreadLocal\u0026lt;T\u0026gt; { /** * ThreadLocals rely on per-thread linear-probe hash maps attached * to each thread (Thread.threadLocals and * inheritableThreadLocals). The ThreadLocal objects act as keys, * searched via threadLocalHashCode. This is a custom hash code * (useful only within ThreadLocalMaps) that eliminates collisions * in the common case where consecutively constructed ThreadLocals * are used by the same threads, while remaining well-behaved in * less common cases. */ private final int threadLocalHashCode = nextHashCode(); private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() { return nextHashCode.getAndAdd(HASH_INCREMENT); } set /** * Sets the current thread\u0026#39;s copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the {@link #initialValue} * method to set the values of thread-locals. * * @param value the value to be stored in the current thread\u0026#39;s copy of * this thread-local. */ public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } get /** * Returns the value in the current thread\u0026#39;s copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the {@link #initialValue} method. * * @return the current thread\u0026#39;s value of this thread-local */ public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result = (T)e.value; return result; } } return setInitialValue(); } setInitialValue private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } initialValue /** * Returns the current thread\u0026#39;s \u0026#34;initial value\u0026#34; for this * thread-local variable. This method will be invoked the first * time a thread accesses the variable with the {@link #get} * method, unless the thread previously invoked the {@link #set} * method, in which case the {@code initialValue} method will not * be invoked for the thread. Normally, this method is invoked at * most once per thread, but it may be invoked again in case of * subsequent invocations of {@link #remove} followed by {@link #get}. * * \u0026lt;p\u0026gt;This implementation simply returns {@code null}; if the * programmer desires thread-local variables to have an initial * value other than {@code null}, {@code ThreadLocal} must be * subclassed, and this method overridden. Typically, an * anonymous inner class will be used. * * @return the initial value for this thread-local */ protected T initialValue() { return null; } createMap void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } ThreadLocalMap static class ThreadLocalMap { /** Construct a new map initially containing (firstKey, firstValue). * ThreadLocalMaps are constructed lazily, so we only create * one when we have at least one entry to put in it. */ ThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode \u0026amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); } } Entry /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as \u0026#34;stale entries\u0026#34; in the code that follows. */ static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } table /** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * Set the resize threshold to maintain at worst a 2/3 load factor. */ private void setThreshold(int len) { threshold = len * 2 / 3; } getEntry /** * Get the entry associated with key. This method * itself handles only the fast path: a direct hit of existing * key. It otherwise relays to getEntryAfterMiss. This is * designed to maximize performance for direct hits, in part * by making this method readily inlinable. * * @param key the thread local object * @return the entry associated with key, or null if no such */ private Entry getEntry(ThreadLocal\u0026lt;?\u0026gt; key) { int i = key.threadLocalHashCode \u0026amp; (table.length - 1); Entry e = table[i]; if (e != null \u0026amp;\u0026amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); } getEntryAfterMiss /** * Version of getEntry method for use when key is not found in * its direct hash slot. * * @param key the thread local object * @param i the table index for key\u0026#39;s hash code * @param e the entry at table[i] * @return the entry associated with key, or null if no such */ private Entry getEntryAfterMiss(ThreadLocal\u0026lt;?\u0026gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null; } nextIndex /** * Increment i modulo len. */ private static int nextIndex(int i, int len) { return ((i + 1 \u0026lt; len) ? i + 1 : 0); } set /** * Set the value associated with key. * * @param key the thread local object * @param value the value to be set */ private void set(ThreadLocal\u0026lt;?\u0026gt; key, Object value) { // We don\u0026#39;t use a fast path as with get() because it is at  // least as common to use set() to create new entries as  // it is to replace existing ones, in which case, a fast  // path would fail more often than not.  Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode \u0026amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) \u0026amp;\u0026amp; sz \u0026gt;= threshold) rehash(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/java/threadpoolexecutor/",
	"title": "ThreadPoolExecutor",
	"tags": [],
	"description": "",
	"content": "2.1 总体设计 继承关系 ThreadPoolExecutor实现的顶层接口是Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。ExecutorService接口增加了一些能力：（1）扩充执行任务的能力，补充可以为一个或一批异步任务生成Future的方法；（2）提供了管控线程池的方法，比如停止线程池的运行。AbstractExecutorService则是上层的抽象类，将执行任务的流程串联了起来，保证下层的实现只需关注一个执行任务的方法即可。最下层的实现类ThreadPoolExecutor实现最复杂的运行部分，ThreadPoolExecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。\nThreadPoolExecutor是如何运行，如何同时维护线程和执行任务的呢？其运行机制如下图所示：\n运行流程 线程池在内部实际上构建了一个生产者消费者模型，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。线程池的运行主要分成两部分：任务管理、线程管理。任务管理部分充当生产者的角色，当任务提交后，线程池会判断该任务后续的流转：（1）直接申请线程执行该任务；（2）缓冲到队列中等待线程执行；（3）拒绝该任务。线程管理部分是消费者，它们被统一维护在线程池内，根据任务请求进行线程的分配，当线程执行完任务后则会继续获取新的任务去执行，最终当线程获取不到任务的时候，线程就会被回收。\n接下来，我们会按照以下三个部分去详细讲解线程池运行机制：\n 线程池如何维护自身状态。 线程池如何管理任务。 线程池如何管理线程。  2.2 生命周期管理 线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。在具体实现中，线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起，如下代码所示：\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); ctl这个AtomicInteger类型，是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它同时包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，高3位保存runState，低29位保存workerCount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。通过阅读线程池源代码也可以发现，经常出现要同时判断线程池运行状态和线程数量的情况。线程池也提供了若干方法去供用户获得线程池当前的运行状态、线程个数。这里都使用的是位运算的方式，相比于基本运算，速度也会快很多。\n关于内部封装的获取生命周期状态、获取线程池线程数量的计算方法如以下代码所示：\nprivate static int runStateOf(int c) { return c \u0026amp; ~CAPACITY; } //计算当前运行状态 private static int workerCountOf(int c) { return c \u0026amp; CAPACITY; } //计算当前线程数量 private static int ctlOf(int rs, int wc) { return rs | wc; } //通过状态和线程数生成ctl ThreadPoolExecutor的运行状态有5种，分别为：\n运行状态 其生命周期转换如下入所示：\n生命周期转换 2.3 任务执行机制 2.3.1 任务调度 任务调度是线程池的主要入口，当用户提交了一个任务，接下来这个任务将如何执行都是由这个阶段决定的。了解这部分就相当于了解了线程池的核心运行机制。\n首先，所有任务的调度都是由execute方法完成的，这部分完成的工作是：检查现在线程池的运行状态、运行线程数、运行策略，决定接下来执行的流程，是直接申请线程执行，或是缓冲到队列中执行，亦或是直接拒绝该任务。其执行过程如下：\n 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。 如果workerCount \u0026lt; corePoolSize，则创建并启动一个线程来执行新提交的任务。 如果workerCount \u0026gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。 如果workerCount \u0026gt;= corePoolSize \u0026amp;\u0026amp; workerCount \u0026lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。 如果workerCount \u0026gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。  其执行流程如下图所示：\n执行流程execute 2.3.2 任务缓冲 任务缓冲模块是线程池能够管理任务的核心部分。线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是将任务和线程两者解耦，不让两者直接关联，才可以做后续的分配工作。线程池中是以生产者消费者模式，通过一个阻塞队列来实现的。阻塞队列缓存任务，工作线程从阻塞队列中获取任务。\n阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。\n下图中展示了线程1往阻塞队列中添加元素，而线程2从阻塞队列中移除元素：\n阻塞队列(BlockingQueue) 使用不同的队列可以实现不一样的任务存取策略。在这里，我们可以再介绍下阻塞队列的成员：\n阻塞队列的成员 2.3.3 任务申请 由上文的任务分配部分可知，任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。\n线程需要从任务缓存模块中不断地取任务执行，帮助线程从阻塞队列中获取任务，实现线程管理模块和任务管理模块之间的通信。这部分策略由getTask方法实现，其执行流程如下图所示：\n线程从阻塞队列中获取任务执行流程getTask getTask这部分进行了多次判断，为的是控制线程的数量，使其符合线程池的状态。如果线程池现在不应该持有那么多线程，则会返回null值。工作线程Worker会不断接收新任务去执行，而当工作线程Worker接收不到任务的时候，就会开始被回收。\n2.3.4 任务拒绝 任务拒绝模块是线程池的保护部分，线程池有一个最大的容量，当线程池的任务缓存队列已满，并且线程池中的线程数目达到maximumPoolSize时，就需要拒绝掉该任务，采取任务拒绝策略，保护线程池。\n拒绝策略是一个接口，其设计如下：\npublic interface RejectedExecutionHandler { void rejectedExecution(Runnable r, ThreadPoolExecutor executor); } 用户可以通过实现这个接口去定制拒绝策略，也可以选择JDK提供的四种已有拒绝策略，其特点如下：\n已有拒绝策略 2.4 Worker线程管理 2.4.1 Worker线程 线程池为了掌握线程的状态并维护线程的生命周期，设计了线程池内的工作线程Worker。我们来看一下它的部分代码：\nprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable{ final Thread thread;//Worker持有的线程  Runnable firstTask;//初始化的任务，可以为null } Worker这个工作线程，实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。thread是在调用构造方法时通过ThreadFactory来创建的线程，可以用来执行任务；firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务。\nWorker执行任务的模型如下图所示：\nWorker执行任务 线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。\nWorker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。\n1.lock方法一旦获取了独占锁，表示当前线程正在执行任务中。\n2.如果正在执行任务，则不应该中断线程。\n3.如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。\n4.线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。\n在线程回收过程中就使用到了这种特性，回收过程如下图所示：\n线程池回收过程 2.4.2 Worker线程增加 增加线程是通过线程池中的addWorker方法，该方法的功能就是增加一个线程，该方法不考虑线程池是在哪个阶段增加的该线程，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。addWorker方法有两个参数：firstTask、core。firstTask参数用于指定新增的线程执行的第一个任务，该参数可以为空；core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize，其执行流程如下图所示：\n申请线程执行addWorker 2.4.3 Worker线程回收 线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。\ntry { while (task != null || (task = getTask()) != null) { //执行任务  } } finally { processWorkerExit(w, completedAbruptly);//获取不到任务时，主动回收自己 } 线程回收的工作是在processWorkerExit方法完成的。\n线程销毁流程 事实上，在这个方法中，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程。\n2.4.4 Worker线程执行任务 在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的执行过程如下：\n1.while循环不断地通过getTask()方法获取任务。\n2.getTask()方法从阻塞队列中取任务。\n3.如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态。\n4.执行任务。\n5.如果getTask结果为null则跳出循环，执行processWorkerExit()方法，销毁线程。\n执行流程如下图所示：\n执行任务流程runWorker 参考 Java线程池实现原理及其在美团业务中的实践\n10问10答：你真的了解线程池吗？\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/thread/threadstate/",
	"title": "ThreadState",
	"tags": [],
	"description": "",
	"content": "浅析android 线程状态 java的6种线程状态定义在/java/lang/Thread.java中:\nhttps://docs.oracle.com/javase/7/docs/api/java/lang/Thread.State.html\n//Thread.java public class Thread implements Runnable { ... public enum State { /** * The thread has been created, but has never been started. */ NEW, /** * The thread may be run. */ RUNNABLE, /** * The thread is blocked and waiting for a lock. */ BLOCKED, /** * The thread is waiting. */ WAITING, /** * The thread is waiting for a specified amount of time. */ TIMED_WAITING, /** * The thread has been terminated. */ TERMINATED } ... } 在VMThread.java中, 可以看到下面的代码， native thread有10种状态, 对应着java thread的6种状态.\n//VMThread.java  /** * Holds a mapping from native Thread statuses to Java one. Required for * translating back the result of getStatus(). */ static final Thread.State[] STATE_MAP = new Thread.State[] { Thread.State.TERMINATED, // ZOMBIE  Thread.State.RUNNABLE, // RUNNING  Thread.State.TIMED_WAITING, // TIMED_WAIT  Thread.State.BLOCKED, // MONITOR  Thread.State.WAITING, // WAIT  Thread.State.NEW, // INITIALIZING  Thread.State.NEW, // STARTING  Thread.State.RUNNABLE, // NATIVE  Thread.State.WAITING, // VMWAIT  Thread.State.RUNNABLE // SUSPENDED  }; 在之前的文章中， 已经分析了android thread的底层实现其实就是linux下的pthread. 我们再看一下native层的Thread.cpp, 有这段代码:\nconst char* dvmGetThreadStatusStr(ThreadStatus status) { switch (status) { case THREAD_ZOMBIE: return \u0026#34;ZOMBIE\u0026#34;; case THREAD_RUNNING: return \u0026#34;RUNNABLE\u0026#34;; case THREAD_TIMED_WAIT: return \u0026#34;TIMED_WAIT\u0026#34;; case THREAD_MONITOR: return \u0026#34;MONITOR\u0026#34;; case THREAD_WAIT: return \u0026#34;WAIT\u0026#34;; case THREAD_INITIALIZING: return \u0026#34;INITIALIZING\u0026#34;; case THREAD_STARTING: return \u0026#34;STARTING\u0026#34;; case THREAD_NATIVE: return \u0026#34;NATIVE\u0026#34;; case THREAD_VMWAIT: return \u0026#34;VMWAIT\u0026#34;; case THREAD_SUSPENDED: return \u0026#34;SUSPENDED\u0026#34;; default: return \u0026#34;UNKNOWN\u0026#34;; } } 实际上， 写入traces.txt中的线程状态值就是这个函数返回的字符串. 所以我们就知道了如下的事实:\n\u0026#34;main\u0026#34; prio=5 tid=1 MONITOR 其实就是java中的BLOCKED状态. \u0026#34;Timer-0\u0026#34; daemon prio=5 tid=23 TIMED_WAIT 其实就是java中的TIMED_WAITING状态 \u0026#34;QMThreadPool #3\u0026#34; daemon prio=3 tid=22 WAIT 其实就是java中的WAITING状态 \u0026#34;WifiManager\u0026#34; prio=5 tid=20 NATIVE 其实就是java中的RUNNABLE状态 \u0026#34;Signal Catcher\u0026#34; daemon prio=5 tid=3 RUNNABLE 其实就是java中的RUNNABLE状态 "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/tinker/",
	"title": "tinker",
	"tags": [],
	"description": "",
	"content": "tinker 探索总结tinker知识\n 源码分析    Resource.arsc生成和结构     TinkerGradlePluginSource     TinkerSource      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/tinker/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/tinkergradlepluginsource/",
	"title": "TinkerGradlePluginSource",
	"tags": [],
	"description": "",
	"content": "keyTitle_decoder类设计\nkeyTitle_dexsectiondiffalgorithm类设计\nkeyTitle_dexsectionpatchalgorithm类设计\nbuild.gradle层 1：构建基准apk(仅仅发版时需要打开tinkerEnabled，开发自己debug时不需要打开)\n1.1: Copy apk,map,R文件到bakApk目录下\n1.2: 创建tinkerPatchDebug和tinkerPatchRelease的task执行的必要参数\n//tinker/tinker-sample-android/app/build.gradle def bakPath = file(\u0026#34;${buildDir}/bakApk/\u0026#34;) /** \\* you can use assembleRelease to build you base apk \\* use tinkerPatchRelease -POLD_APK= -PAPPLY_MAPPING= -PAPPLY_RESOURCE= to build patch \\* add apk from the build/bakApk */ ext { //for some reason, you may want to ignore tinkerBuild, such as instant run debug build?  tinkerEnabled = true //for normal build  //old apk file to build patch apk  tinkerOldApkPath = \u0026#34;${bakPath}/app-debug-0917-16-24-41.apk\u0026#34; //proguard mapping file to build patch apk  tinkerApplyMappingPath = \u0026#34;${bakPath}/app-debug-1018-17-32-47-mapping.txt\u0026#34; //resource R.txt to build patch apk, must input if there is resource changed  tinkerApplyResourcePath = \u0026#34;${bakPath}/app-debug-0424-15-02-56-R.txt\u0026#34; //only use for build all flavor, if not, just ignore this field  tinkerBuildFlavorDirectory = \u0026#34;${bakPath}/app-1018-17-32-47\u0026#34; } if (buildWithTinker()) { apply plugin: \u0026#39;com.tencent.tinker.patch\u0026#39; tinkerPatch { oldApk = getOldApkPath() ignoreWarning = false useSign = true tinkerEnable = buildWithTinker() buildConfig { applyMapping = getApplyMappingPath() applyResourceMapping = getApplyResourceMappingPath() tinkerId = getTinkerIdValue() keepDexApply = false isProtectedApp = false supportHotplugComponent = false } dex { dexMode = \u0026#34;jar\u0026#34; pattern = [\u0026#34;classes*.dex\u0026#34;, \u0026#34;assets/secondary-dex-?.jar\u0026#34;] loader = [ \u0026#34;tinker.sample.android.app.BaseBuildInfo\u0026#34; ] } lib { pattern = [\u0026#34;lib/*/*.so\u0026#34;] } res { pattern = [\u0026#34;res/*\u0026#34;, \u0026#34;assets/*\u0026#34;, \u0026#34;resources.arsc\u0026#34;, \u0026#34;AndroidManifest.xml\u0026#34;] ignoreChange = [\u0026#34;assets/sample_meta.txt\u0026#34;] largeModSize = 100 } packageConfig { configField(\u0026#34;patchMessage\u0026#34;, \u0026#34;tinker is sample to use\u0026#34;) configField(\u0026#34;platform\u0026#34;, \u0026#34;all\u0026#34;) configField(\u0026#34;patchVersion\u0026#34;, \u0026#34;1.0\u0026#34;) } sevenZip { zipArtifact = \u0026#34;com.tencent.mm:SevenZip:1.1.10\u0026#34; } } android.applicationVariants.all { variant -\u0026gt; /** \\* task type, you want to bak */ def taskName = variant.name tasks.all { if (\u0026#34;assemble${taskName.capitalize()}\u0026#34;.equalsIgnoreCase(it.name)) { it.doLast { copy { def fileNamePrefix = \u0026#34;${project.name}-${variant.baseName}\u0026#34; def newFileNamePrefix = hasFlavors ? \u0026#34;${fileNamePrefix}\u0026#34; : \u0026#34;${fileNamePrefix}-${date}\u0026#34; def destPath = hasFlavors ? file(\u0026#34;${bakPath}/${project.name}-${date}/${variant.flavorName}\u0026#34;) : bakPath if (variant.metaClass.hasProperty(variant, \u0026#39;packageApplicationProvider\u0026#39;)) { def packageAndroidArtifact = variant.packageApplicationProvider.get() if (packageAndroidArtifact != null) { try { from new File(packageAndroidArtifact.outputDirectory.getAsFile().get(), variant.outputs.first().apkData.outputFileName) } catch (Exception e) { from new File(packageAndroidArtifact.outputDirectory, variant.outputs.first().apkData.outputFileName) } } else { from variant.outputs.first().mainOutputFile.outputFile } } else { from variant.outputs.first().outputFile } into destPath rename { String fileName -\u0026gt; fileName.replace(\u0026#34;${fileNamePrefix}.apk\u0026#34;, \u0026#34;${newFileNamePrefix}.apk\u0026#34;) } from \u0026#34;${buildDir}/outputs/mapping/${variant.dirName}/mapping.txt\u0026#34; into destPath rename { String fileName -\u0026gt; fileName.replace(\u0026#34;mapping.txt\u0026#34;, \u0026#34;${newFileNamePrefix}-mapping.txt\u0026#34;) } from \u0026#34;${buildDir}/intermediates/symbols/${variant.dirName}/R.txt\u0026#34; from \u0026#34;${buildDir}/intermediates/symbol_list/${variant.dirName}/R.txt\u0026#34; into destPath rename { String fileName -\u0026gt; fileName.replace(\u0026#34;R.txt\u0026#34;, \u0026#34;${newFileNamePrefix}-R.txt\u0026#34;) } } } } } } TinkerPatchPlugin #tinker/tinker-build/tinker-patch-gradle-plugin/src/main/resources/META-INF/gradle-plugins/com.tencent.tinker.patch.properties implementation-class=com.tencent.tinker.build.gradle.TinkerPatchPlugin class TinkerPatchPlugin implements Plugin\u0026lt;Project\u0026gt; { @Override public void apply(Project project) { mProject = project mProject.extensions.create(\u0026#39;tinkerPatch\u0026#39;, TinkerPatchExtension) mProject.tinkerPatch.extensions.create(\u0026#39;buildConfig\u0026#39;, TinkerBuildConfigExtension, mProject) //mProject.tinkerPatch.extensions  mProject.tinkerPatch.extensions.create(\u0026#39;dex\u0026#39;, TinkerDexExtension, mProject) mProject.tinkerPatch.extensions.create(\u0026#39;lib\u0026#39;, TinkerLibExtension) mProject.tinkerPatch.extensions.create(\u0026#39;res\u0026#39;, TinkerResourceExtension) mProject.tinkerPatch.extensions.create(\u0026#34;arkHot\u0026#34;, TinkerArkHotExtension) mProject.tinkerPatch.extensions.create(\u0026#39;packageConfig\u0026#39;, TinkerPackageConfigExtension, mProject) mProject.tinkerPatch.extensions.create(\u0026#39;sevenZip\u0026#39;, TinkerSevenZipExtension, mProject) android.applicationVariants.all { variant -\u0026gt; def variantOutput = variant.outputs.first() def variantName = variant.name.capitalize() def variantData = variant.variantData //创建task： tinkerPatchDebug或tinkerPatchRelease, main  TinkerPatchSchemaTask tinkerPatchBuildTask = mProject.tasks.create(\u0026#34;tinkerPatch${variantName}\u0026#34;, TinkerPatchSchemaTask) //创建task: tinkerProcessDebugManifest,main  // Create a task to add a build TINKER_ID to AndroidManifest.xml  // This task must be called after \u0026#34;process${variantName}Manifest\u0026#34;, since it  // requires that an AndroidManifest.xml exists in `build/intermediates`.  TinkerManifestTask manifestTask = mProject.tasks.create(\u0026#34;tinkerProcess${variantName}Manifest\u0026#34;, TinkerManifestTask) tinkerPatchBuildTask.signConfig = variantData.variantConfiguration.signingConfig variant.outputs.each { output -\u0026gt; setPatchNewApkPath(configuration, output, variant, tinkerPatchBuildTask) setPatchOutputFolder(configuration, output, variant, tinkerPatchBuildTask) } manifestTask.mustRunAfter variantOutput.processManifest variantOutput.processResources.dependsOn manifestTask //main  TinkerResourceIdTask applyResourceTask = mProject.tasks.create(\u0026#34;tinkerProcess${variantName}ResourceId\u0026#34;, TinkerResourceIdTask) applyResourceTask.resDir = variantOutput.processResources.inputResourcesDir.getFiles().first() applyResourceTask.mustRunAfter manifestTask variantOutput.processResources.dependsOn applyResourceTask applyResourceTask.dependsOn mergeResourcesTask if (multiDexEnabled) {//main  TinkerMultidexConfigTask multidexConfigTask = mProject.tasks.create(\u0026#34;tinkerProcess${variantName}MultidexKeep\u0026#34;, TinkerMultidexConfigTask) multidexConfigTask.applicationVariant = variant multidexConfigTask.multiDexKeepProguard = getManifestMultiDexKeepProguard(variant) multidexConfigTask.mustRunAfter manifestTask multidexConfigTask.mustRunAfter variantOutput.processResources multidexTask.dependsOn multidexConfigTask if (configuration.buildConfig.keepDexApply \u0026amp;\u0026amp; FileOperation.isLegalFile(mProject.tinkerPatch.oldApk)) { com.tencent.tinker.build.gradle.transform.ImmutableDexTransform.inject(mProject, variant)//main  } } void setPatchNewApkPath(configuration, output, variant, tinkerPatchBuildTask) { tinkerPatchBuildTask.dependsOn variant.assemble//assembleDebug } ImmutableDexTransform\n@Override void transform(TransformInvocation transformInvocation) throws TransformException, IOException, InterruptedException {} TinkerPatchSchemaTask TinkerPatchExtension configuration def android String buildApkPath String outputFolder def signConfig public TinkerPatchSchemaTask() { description = \u0026#39;Assemble Tinker Patch\u0026#39; group = \u0026#39;tinker\u0026#39; outputs.upToDateWhen { false } configuration = project.tinkerPatch android = project.extensions.android } @TaskAction def tinkerPatch() { configuration.checkParameter() configuration.buildConfig.checkParameter() configuration.res.checkParameter() configuration.dex.checkDexMode() configuration.sevenZip.resolveZipFinalPath() builder.setOldApk(configuration.oldApk) .setNewApk(buildApkPath) .setOutBuilder(outputFolder) .setIgnoreWarning(configuration.ignoreWarning) .setAllowLoaderInAnyDex(configuration.allowLoaderInAnyDex) .setRemoveLoaderForAllDex(configuration.removeLoaderForAllDex) .setDexFilePattern(new ArrayList\u0026lt;String\u0026gt;(configuration.dex.pattern)) .setIsProtectedApp(configuration.buildConfig.isProtectedApp) .setIsComponentHotplugSupported(configuration.buildConfig.supportHotplugComponent) .setDexLoaderPattern(new ArrayList\u0026lt;String\u0026gt;(configuration.dex.loader)) .setDexIgnoreWarningLoaderPattern(new ArrayList\u0026lt;String\u0026gt;(configuration.dex.ignoreWarningLoader)) .setDexMode(configuration.dex.dexMode) .setSoFilePattern(new ArrayList\u0026lt;String\u0026gt;(configuration.lib.pattern)) .setResourceFilePattern(new ArrayList\u0026lt;String\u0026gt;(configuration.res.pattern)) .setResourceIgnoreChangePattern(new ArrayList\u0026lt;String\u0026gt;(configuration.res.ignoreChange)) .setResourceIgnoreChangeWarningPattern(new ArrayList\u0026lt;String\u0026gt;(configuration.res.ignoreChangeWarning)) .setResourceLargeModSize(configuration.res.largeModSize) .setUseApplyResource(configuration.buildConfig.usingResourceMapping) .setConfigFields(new HashMap\u0026lt;String, String\u0026gt;(configuration.packageConfig.getFields())) .setSevenZipPath(configuration.sevenZip.path) .setUseSign(configuration.useSign) .setArkHotPath(configuration.arkHot.path) .setArkHotName(configuration.arkHot.name) InputParam inputParam = builder.create() Runner.gradleRun(inputParam); Runner.thinkerPatch public static void gradleRun(InputParam inputParam) { mBeginTime = System.currentTimeMillis(); Runner m = new Runner(); m.run(inputParam); } private void run(InputParam inputParam) { loadConfigFromGradle(inputParam); try { //tinker-sample-android\\app\\build\\outputs\\apk/tinkerPatch/debug\\log.txt  Logger.initLogger(config); tinkerPatch();//main  } catch (IOException e) { e.printStackTrace(); goToError(); } finally { Logger.closeLogger(); } } protected void tinkerPatch() { Logger.d(\u0026#34;-----------------------Tinker patch begin-----------------------\u0026#34;); Logger.d(config.toString()); try { //gen patch  ApkDecoder decoder = new ApkDecoder(config); decoder.onAllPatchesStart(); decoder.patch(config.mOldApkFile, config.mNewApkFile);//main  decoder.onAllPatchesEnd(); //gen meta file and version file  PatchInfo info = new PatchInfo(config); info.gen();//输出assets/package_meta.txt文件记录版本信息  //build patch  PatchBuilder builder = new PatchBuilder(config); builder.buildPatch(); } catch (Throwable e) { e.printStackTrace(); goToError(); } Logger.d(\u0026#34;Tinker patch done, total time cost: %fs\u0026#34;, diffTimeFromBegin()); Logger.d(\u0026#34;Tinker patch done, you can go to file to find the output %s\u0026#34;, config.mOutFolder); Logger.d(\u0026#34;-----------------------Tinker patch end-------------------------\u0026#34;); } Decoder类设计 DexDiffDecoder ExcludedClassModifiedChecker public void checkIfExcludedClassWasModifiedInNewDex(File oldFile, File newFile) throws IOException, TinkerPatchException { int stmCode = STMCODE_START; while (stmCode != STMCODE_END) { switch (stmCode) { case STMCODE_START: { boolean isPrimaryDex = isPrimaryDex((oldFile == null ? newFile : oldFile)); if (isPrimaryDex) { if (oldFile == null) { stmCode = STMCODE_ERROR_PRIMARY_OLD_DEX_IS_MISSING; } else if (newFile == null) { stmCode = STMCODE_ERROR_PRIMARY_NEW_DEX_IS_MISSING; } else { dexCmptor.startCheck(oldDex, newDex);//main DexClassesComparator.startCheck public void startCheck(Dex oldDex, Dex newDex) { startCheck(DexGroup.wrap(oldDex), DexGroup.wrap(newDex)); } public void startCheck(DexGroup oldDexGroup, DexGroup newDexGroup) { //add, delete, change三个列表必须都是empty，才算是逻辑上一致 Set\u0026lt;String\u0026gt; deletedClassDescs = new HashSet\u0026lt;\u0026gt;(oldDescriptorOfClassesToCheck); deletedClassDescs.removeAll(newDescriptorOfClassesToCheck); Set\u0026lt;String\u0026gt; addedClassDescs = new HashSet\u0026lt;\u0026gt;(newDescriptorOfClassesToCheck); addedClassDescs.removeAll(oldDescriptorOfClassesToCheck); Set\u0026lt;String\u0026gt; mayBeChangedClassDescs = new HashSet\u0026lt;\u0026gt;(oldDescriptorOfClassesToCheck); mayBeChangedClassDescs.retainAll(newDescriptorOfClassesToCheck); for (String desc : mayBeChangedClassDescs) { DexClassInfo oldClassInfo = oldClassDescriptorToClassInfoMap.get(desc); DexClassInfo newClassInfo = newClassDescriptorToClassInfoMap.get(desc); switch (compareMode) { case COMPARE_MODE_NORMAL: { if (!isSameClass(//main  oldClassInfo.owner, newClassInfo.owner, oldClassInfo.classDef, newClassInfo.classDef )) { if (Utils.isStringMatchesPatterns(desc, patternsOfIgnoredRemovedClassDesc)) { logger.i(TAG, \u0026#34;Ignored changed class: %s\u0026#34;, desc); } else { logger.i(TAG, \u0026#34;Changed class: %s\u0026#34;, desc); changedClassDescToClassInfosMap.put( desc, new DexClassInfo[]{oldClassInfo, newClassInfo} ); } isSameClass private boolean isSameClass( Dex oldDex, Dex newDex, ClassDef oldClassDef, ClassDef newClassDef ) {//内部会有各种界别same的判断，内部还会调用isSameMethod，isSameCode等等，判断是否逻辑一致  if (oldClassDef.accessFlags != newClassDef.accessFlags) { return false; } if (!isSameClassDesc( oldDex, newDex, oldClassDef.supertypeIndex, newClassDef.supertypeIndex )) { return false; } short[] oldInterfaceIndices = oldDex.interfaceTypeIndicesFromClassDef(oldClassDef); short[] newInterfaceIndices = newDex.interfaceTypeIndicesFromClassDef(newClassDef); if (oldInterfaceIndices.length != newInterfaceIndices.length) { return false; } else { for (int i = 0; i \u0026lt; oldInterfaceIndices.length; ++i) { if (!isSameClassDesc(oldDex, newDex, oldInterfaceIndices[i], newInterfaceIndices[i])) { return false; } } } if (!isSameName(oldDex, newDex, oldClassDef.sourceFileIndex, newClassDef.sourceFileIndex)) { return false; } if (!isSameAnnotationDirectory( oldDex, newDex, oldClassDef.annotationsOffset, newClassDef.annotationsOffset )) { return false; } if (!isSameClassData( oldDex, newDex, oldClassDef.classDataOffset, newClassDef.classDataOffset )) { return false; } return isSameStaticValue( oldDex, newDex, oldClassDef.staticValuesOffset, newClassDef.staticValuesOffset ); } Dex差分 dexPatchGen.executeAndSaveTo(dexDiffOut);//Dex差分 DexSectionDiffAlgorithm类设计 二路归并算法是较小的指针+1，从而判断是删除old还是新增new\nDexPatchGenerator private DexSectionDiffAlgorithm\u0026lt;StringData\u0026gt; stringDataSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;Integer\u0026gt; typeIdSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;ProtoId\u0026gt; protoIdSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;FieldId\u0026gt; fieldIdSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;MethodId\u0026gt; methodIdSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;ClassDef\u0026gt; classDefSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;TypeList\u0026gt; typeListSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;AnnotationSetRefList\u0026gt; annotationSetRefListSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;AnnotationSet\u0026gt; annotationSetSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;ClassData\u0026gt; classDataSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;Code\u0026gt; codeSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;DebugInfoItem\u0026gt; debugInfoSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;Annotation\u0026gt; annotationSectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;EncodedValue\u0026gt; encodedArraySectionDiffAlg; private DexSectionDiffAlgorithm\u0026lt;AnnotationsDirectory\u0026gt; annotationsDirectorySectionDiffAlg; public DexPatchGenerator(File oldDexFile, File newDexFile) throws IOException { this(new Dex(oldDexFile), new Dex(newDexFile)); } public DexPatchGenerator(Dex oldDex, Dex newDex) { this.oldDex = oldDex; this.newDex = newDex; SparseIndexMap oldToNewIndexMap = new SparseIndexMap(); SparseIndexMap oldToPatchedIndexMap = new SparseIndexMap(); SparseIndexMap newToPatchedIndexMap = new SparseIndexMap(); SparseIndexMap selfIndexMapForSkip = new SparseIndexMap(); this.stringDataSectionDiffAlg = new StringDataSectionDiffAlgorithm( oldDex, newDex, oldToNewIndexMap, oldToPatchedIndexMap, newToPatchedIndexMap, selfIndexMapForSkip ); this.typeIdSectionDiffAlg = new TypeIdSectionDiffAlgorithm( oldDex, newDex, oldToNewIndexMap, oldToPatchedIndexMap, newToPatchedIndexMap, selfIndexMapForSkip ); executeAndSaveTo public void executeAndSaveTo(File file) throws IOException { OutputStream os = null; try { os = new BufferedOutputStream(new FileOutputStream(file)); executeAndSaveTo(os); } finally { StreamUtil.closeQuietly(os); } } public void executeAndSaveTo(OutputStream out) throws IOException { // Firstly, collect information of items we want to remove additionally  // in new dex and set them to corresponding diff algorithm implementations.  //首先移除需要ignore变更的class，如loader包中的，SampleApplication和BaseBuildInfo，这些类的差异无法通过tinker修复 ...... ((ClassDefSectionDiffAlgorithm) this.classDefSectionDiffAlg) .setTypeIdOfClassDefsToRemove(typeIdOfClassDefsToRemove); ((ClassDataSectionDiffAlgorithm) this.classDataSectionDiffAlg) .setOffsetOfClassDatasToRemove(offsetOfClassDatasToRemove); // Then, run diff algorithms according to sections\u0026#39; dependencies.  // The diff works on each sections obey such procedure:  // 1. Execute diff algorithms to calculate indices of items we need to add, del and replace.  // 2. Execute patch algorithm simulation to calculate indices and offsets mappings that is  // necessary to next section\u0026#39;s diff works.  // Immediately do the patch simulation so that we can know:  // 1. Indices and offsets mapping between old dex and patched dex.  // 2. Indices and offsets mapping between new dex and patched dex.  // These information will be used to do next diff works.  this.patchedStringIdsOffset = patchedHeaderOffset + patchedheaderSize; if (this.oldDex.getTableOfContents().stringIds.isElementFourByteAligned) { this.patchedStringIdsOffset = SizeOf.roundToTimesOfFour(this.patchedStringIdsOffset); } this.stringDataSectionDiffAlg.execute();//执行二路归并算法,结果存储到三种(add/del/replace)map中//main ... this.stringDataSectionDiffAlg.simulatePatchOperation(this.patchedStringDataItemsOffset);//main ...... // Finally, write results to patch file.  writeResultToStream(out);//main private void writeResultToStream(OutputStream os) throws IOException { DexDataBuffer buffer = new DexDataBuffer(); buffer.write(DexPatchFile.MAGIC); buffer.writeShort(DexPatchFile.CURRENT_VERSION); buffer.writeInt(this.patchedDexSize); // we will return here to write firstChunkOffset later.  int posOfFirstChunkOffsetField = buffer.position(); buffer.writeInt(0); buffer.writeInt(this.patchedStringIdsOffset); buffer.writeInt(this.patchedTypeIdsOffset); buffer.writeInt(this.patchedProtoIdsOffset); buffer.writeInt(this.patchedFieldIdsOffset); buffer.writeInt(this.patchedMethodIdsOffset); buffer.writeInt(this.patchedClassDefsOffset); buffer.writeInt(this.patchedMapListOffset); buffer.writeInt(this.patchedTypeListsOffset); buffer.writeInt(this.patchedAnnotationSetRefListItemsOffset); buffer.writeInt(this.patchedAnnotationSetItemsOffset); buffer.writeInt(this.patchedClassDataItemsOffset); buffer.writeInt(this.patchedCodeItemsOffset); buffer.writeInt(this.patchedStringDataItemsOffset); buffer.writeInt(this.patchedDebugInfoItemsOffset); buffer.writeInt(this.patchedAnnotationItemsOffset); buffer.writeInt(this.patchedEncodedArrayItemsOffset); buffer.writeInt(this.patchedAnnotationsDirectoryItemsOffset); buffer.write(this.oldDex.computeSignature(false)); int firstChunkOffset = buffer.position(); buffer.position(posOfFirstChunkOffsetField); buffer.writeInt(firstChunkOffset); buffer.position(firstChunkOffset); writePatchOperations(buffer, this.stringDataSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.typeIdSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.typeListSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.protoIdSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.fieldIdSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.methodIdSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.annotationSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.annotationSetSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.annotationSetRefListSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.annotationsDirectorySectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.debugInfoSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.codeSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.classDataSectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.encodedArraySectionDiffAlg.getPatchOperationList()); writePatchOperations(buffer, this.classDefSectionDiffAlg.getPatchOperationList()); byte[] bufferData = buffer.array(); os.write(bufferData); os.flush(); } private \u0026lt;T extends Comparable\u0026lt;T\u0026gt;\u0026gt; void writePatchOperations( DexDataBuffer buffer, List\u0026lt;PatchOperation\u0026lt;T\u0026gt;\u0026gt; patchOperationList ) { ...... buffer.writeUleb128(delOpIndexList.size()); int lastIndex = 0; for (Integer index : delOpIndexList) { buffer.writeSleb128(index - lastIndex); lastIndex = index; } buffer.writeUleb128(addOpIndexList.size()); lastIndex = 0; for (Integer index : addOpIndexList) { buffer.writeSleb128(index - lastIndex); lastIndex = index; } buffer.writeUleb128(replaceOpIndexList.size()); lastIndex = 0; for (Integer index : replaceOpIndexList) { buffer.writeSleb128(index - lastIndex); lastIndex = index; } for (T newItem : newItemList) { if (newItem instanceof StringData) { buffer.writeStringData((StringData) newItem); } else ...... Dex差分合成 new DexPatchApplier(oldDexFile, dexDiffOut).executeAndSaveTo(tempFullPatchedDexFile);//Dex差分合成 DexSectionPatchAlgorithm类设计 public DexPatchApplier(File oldDexIn, File patchFileIn) throws IOException { this(new Dex(oldDexIn), new DexPatchFile(patchFileIn)); } public DexPatchApplier(Dex oldDexIn, DexPatchFile patchFileIn) { this.oldDex = oldDexIn; this.patchFile = patchFileIn; this.patchedDex = new Dex(patchFileIn.getPatchedDexSize()); this.oldToPatchedIndexMap = new SparseIndexMap(); } DexPatchApplier.executeAndSaveTo public void executeAndSaveTo(File file) throws IOException { OutputStream os = null; try { os = new BufferedOutputStream(new FileOutputStream(file)); executeAndSaveTo(os); } finally { StreamUtil.closeQuietly(os); } } public void executeAndSaveTo(OutputStream out) throws IOException { // Before executing, we should check if this patch can be applied to  // old dex we passed in.  // Firstly, set sections\u0026#39; offset after patched, sort according to their offset so that  // the dex lib of aosp can calculate section size.  TableOfContents patchedToc = this.patchedDex.getTableOfContents(); patchedToc.header.off = 0; patchedToc.header.size = 1; patchedToc.mapList.size = 1; patchedToc.stringIds.off = this.patchFile.getPatchedStringIdSectionOffset(); patchedToc.typeIds.off = this.patchFile.getPatchedTypeIdSectionOffset(); patchedToc.typeLists.off = this.patchFile.getPatchedTypeListSectionOffset(); patchedToc.protoIds.off = this.patchFile.getPatchedProtoIdSectionOffset(); patchedToc.fieldIds.off = this.patchFile.getPatchedFieldIdSectionOffset(); patchedToc.methodIds.off = this.patchFile.getPatchedMethodIdSectionOffset(); patchedToc.classDefs.off = this.patchFile.getPatchedClassDefSectionOffset(); patchedToc.mapList.off = this.patchFile.getPatchedMapListSectionOffset(); patchedToc.stringDatas.off = this.patchFile.getPatchedStringDataSectionOffset(); patchedToc.annotations.off = this.patchFile.getPatchedAnnotationSectionOffset(); patchedToc.annotationSets.off = this.patchFile.getPatchedAnnotationSetSectionOffset(); patchedToc.annotationSetRefLists.off = this.patchFile.getPatchedAnnotationSetRefListSectionOffset(); patchedToc.annotationsDirectories.off = this.patchFile.getPatchedAnnotationsDirectorySectionOffset(); patchedToc.encodedArrays.off = this.patchFile.getPatchedEncodedArraySectionOffset(); patchedToc.debugInfos.off = this.patchFile.getPatchedDebugInfoSectionOffset(); patchedToc.codes.off = this.patchFile.getPatchedCodeSectionOffset(); patchedToc.classDatas.off = this.patchFile.getPatchedClassDataSectionOffset(); patchedToc.fileSize = this.patchFile.getPatchedDexSize(); Arrays.sort(patchedToc.sections); patchedToc.computeSizesFromOffsets(); // Secondly, run patch algorithms according to sections\u0026#39; dependencies.  this.stringDataSectionPatchAlg = new StringDataSectionPatchAlgorithm(patchFile, oldDex, patchedDex, oldToPatchedIndexMap); .... this.stringDataSectionPatchAlg.execute(); this.typeIdSectionPatchAlg.execute(); this.typeListSectionPatchAlg.execute(); this.protoIdSectionPatchAlg.execute(); this.fieldIdSectionPatchAlg.execute(); this.methodIdSectionPatchAlg.execute(); this.annotationSectionPatchAlg.execute(); this.annotationSetSectionPatchAlg.execute(); this.annotationSetRefListSectionPatchAlg.execute(); this.annotationsDirectorySectionPatchAlg.execute(); this.debugInfoSectionPatchAlg.execute(); this.codeSectionPatchAlg.execute(); this.classDataSectionPatchAlg.execute(); this.encodedArraySectionPatchAlg.execute(); this.classDefSectionPatchAlg.execute(); // Thirdly, write header, mapList. Calculate and write patched dex\u0026#39;s sign and checksum.  Dex.Section headerOut = this.patchedDex.openSection(patchedToc.header.off); patchedToc.writeHeader(headerOut); Dex.Section mapListOut = this.patchedDex.openSection(patchedToc.mapList.off); patchedToc.writeMap(mapListOut); this.patchedDex.writeHashes(); // Finally, write patched dex to file.  this.patchedDex.writeTo(out); } DexPatchFile public DexPatchFile(File file) throws IOException { this.buffer = new DexDataBuffer(ByteBuffer.wrap(FileUtils.readFile(file))); init(); } private void init() { byte[] magic = this.buffer.readByteArray(MAGIC.length); if (CompareUtils.uArrCompare(magic, MAGIC) != 0) { throw new IllegalStateException(\u0026#34;bad dex patch file magic: \u0026#34; + Arrays.toString(magic)); } this.version = this.buffer.readShort(); if (CompareUtils.uCompare(this.version, CURRENT_VERSION) != 0) { throw new IllegalStateException(\u0026#34;bad dex patch file version: \u0026#34; + this.version + \u0026#34;, expected: \u0026#34; + CURRENT_VERSION); } this.patchedDexSize = this.buffer.readInt(); this.firstChunkOffset = this.buffer.readInt(); this.patchedStringIdSectionOffset = this.buffer.readInt(); this.patchedTypeIdSectionOffset = this.buffer.readInt(); this.patchedProtoIdSectionOffset = this.buffer.readInt(); this.patchedFieldIdSectionOffset = this.buffer.readInt(); this.patchedMethodIdSectionOffset = this.buffer.readInt(); this.patchedClassDefSectionOffset = this.buffer.readInt(); this.patchedMapListSectionOffset = this.buffer.readInt(); this.patchedTypeListSectionOffset = this.buffer.readInt(); this.patchedAnnotationSetRefListSectionOffset = this.buffer.readInt(); this.patchedAnnotationSetSectionOffset = this.buffer.readInt(); this.patchedClassDataSectionOffset = this.buffer.readInt(); this.patchedCodeSectionOffset = this.buffer.readInt(); this.patchedStringDataSectionOffset = this.buffer.readInt(); this.patchedDebugInfoSectionOffset = this.buffer.readInt(); this.patchedAnnotationSectionOffset = this.buffer.readInt(); this.patchedEncodedArraySectionOffset = this.buffer.readInt(); this.patchedAnnotationsDirectorySectionOffset = this.buffer.readInt(); this.oldDexSignature = this.buffer.readByteArray(SizeOf.SIGNATURE); this.buffer.position(firstChunkOffset); } public DexDataBuffer getBuffer() { return buffer; } checkDexChange checkDexChange(origNewDex, patchedNewDex);//检查是否patchedNewDex(打完补丁的new dex)和原本的newDex在逻辑上保持一致 addTestDex tinker-build/tinker-patch-lib/src/main/resources/test.dex代码中固定的文件通过getResourceAsStream复制到当前patch的输出目录mTempResultDir\nprivate void addTestDex() throws IOException { //write test dex  String dexMode = \u0026#34;jar\u0026#34;; if (config.mDexRaw) { dexMode = \u0026#34;raw\u0026#34;; } final InputStream is = DexDiffDecoder.class.getResourceAsStream(\u0026#34;/\u0026#34; + TEST_DEX_NAME); String md5 = MD5.getMD5(is, 1024); is.close(); String meta = TEST_DEX_NAME + \u0026#34;,\u0026#34; + \u0026#34;\u0026#34; + \u0026#34;,\u0026#34; + md5 + \u0026#34;,\u0026#34; + md5 + \u0026#34;,\u0026#34; + 0 + \u0026#34;,\u0026#34; + 0 + \u0026#34;,\u0026#34; + 0 + \u0026#34;,\u0026#34; + dexMode; File dest = new File(config.mTempResultDir + \u0026#34;/\u0026#34; + TEST_DEX_NAME); FileOperation.copyResourceUsingStream(TEST_DEX_NAME, dest); Logger.d(\u0026#34;\\nAdd test install result dex: %s, size:%d\u0026#34;, dest.getAbsolutePath(), dest.length()); Logger.d(\u0026#34;DexDecoder:write test dex meta file data: %s\u0026#34;, meta); metaWriter.writeLineToInfoFile(meta); } PatchBuilder.buildPatch public void buildPatch() throws Exception { final File resultDir = config.mTempResultDir; generateUnsignedApk(unSignedApk);//将tinker_result文件夹下的内容打包到patch apk  signApk(unSignedApk, signedApk);执行jarsigner命令进行sign use7zApk(signedApk, signedWith7ZipApk, sevenZipOutPutDir); } Dex解析 aosp-dexutils-1.9.14.jar中包含dex字节码的处理库如Code类\nDex /** \\* Creates a new dex buffer from the dex file {@code file}. */ public Dex(File file) throws IOException { if (file.getName().endsWith(\u0026#34;.dex\u0026#34;)) { InputStream in = null; try { in = new BufferedInputStream(new FileInputStream(file)); loadFrom(in, (int) file.length()); } catch (Exception e) { throw new DexException(e); } } } private void loadFrom(InputStream in, int initSize) throws IOException { byte[] rawData = FileUtils.readStream(in, initSize);//rawData表示dex文件的byte数组  this.data = ByteBuffer.wrap(rawData); this.data.order(ByteOrder.LITTLE_ENDIAN); this.tableOfContents.readFrom(this);//main  } public void writeTo(OutputStream out) throws IOException { byte[] rawData = data.array(); out.write(rawData); out.flush(); } TableOfContents /** \\* The file header and map. */ TableOfContents { public final Section header = new Section(SECTION_TYPE_HEADER, true);//无Algorithm对应 public final Section stringIds = new Section(SECTION_TYPE_STRINGIDS, true);//ref StringDataSectionDiffAlgorithm public final Section typeIds = new Section(SECTION_TYPE_TYPEIDS, true);//ref TypeIdSectionDiffAlgorithm public final Section protoIds = new Section(SECTION_TYPE_PROTOIDS, true);//ref ProtoIdSectionDiffAlgorithm public final Section fieldIds = new Section(SECTION_TYPE_FIELDIDS, true);//ref FieldIdSectionDiffAlgorithm public final Section methodIds = new Section(SECTION_TYPE_METHODIDS, true);//ref MethodIdSectionDiffAlgorithm public final Section classDefs = new Section(SECTION_TYPE_CLASSDEFS, true);//ref ClassDefSectionDiffAlgorithm public final Section mapList = new Section(SECTION_TYPE_MAPLIST, true);//无Algorithm对应 public final Section typeLists = new Section(SECTION_TYPE_TYPELISTS, true);//TypeListSectionDiffAlgorithm public final Section annotationSetRefLists = new Section(SECTION_TYPE_ANNOTATIONSETREFLISTS, true);//ref ... public final Section annotationSets = new Section(SECTION_TYPE_ANNOTATIONSETS, true);ref... public final Section classDatas = new Section(SECTION_TYPE_CLASSDATA, false);ref... public final Section codes = new Section(SECTION_TYPE_CODES, true);ref... public final Section stringDatas = new Section(SECTION_TYPE_STRINGDATAS, false);ref... public final Section debugInfos = new Section(SECTION_TYPE_DEBUGINFOS, false);ref... public final Section annotations = new Section(SECTION_TYPE_ANNOTATIONS, false);ref... public final Section encodedArrays = new Section(SECTION_TYPE_ENCODEDARRAYS, false);//无Algorithm对应 public final Section annotationsDirectories = new Section(SECTION_TYPE_ANNOTATIONSDIRECTORIES, true);ref... //18个section，对应map size = 18,其中15个都一一对应一个SectionDiffAlgorithm类进行差分，在Algorithm子类的getTocSection方法中返回对应的Section public final Section[] sections = { header, stringIds, typeIds, protoIds, fieldIds, methodIds, classDefs, mapList, typeLists, annotationSetRefLists, annotationSets, classDatas, codes, stringDatas, debugInfos, annotations, encodedArrays, annotationsDirectories }; public int checksum; public byte[] signature; public int fileSize; public int linkSize; public int linkOff; public int dataSize; public int dataOff; } readFromDex public void readFrom(Dex dex) throws IOException { readHeader(dex.openSection(header)); // special case, since mapList.byteCount is available only after  // computeSizesFromOffsets() was invoked, so here we can\u0026#39;t use  // dex.openSection(mapList) to get dex section. Or  // an {@code java.nio.BufferUnderflowException} will be thrown.  readMap(dex.openSection(mapList.off)); computeSizesFromOffsets(); } //Dex public Section openSection(TableOfContents.Section tocSec) { int position = tocSec.off; if (position \u0026lt; 0 || position \u0026gt;= data.capacity()) { throw new IllegalArgumentException( \u0026#34;position=\u0026#34; + position + \u0026#34; length=\u0026#34; + data.capacity() ); } ByteBuffer sectionData = data.duplicate(); sectionData.order(ByteOrder.LITTLE_ENDIAN); // necessary?  sectionData.position(position);//设定指定section的起始地址position和大小byteCount  sectionData.limit(position + tocSec.byteCount); return new Section(\u0026#34;section\u0026#34;, sectionData); } readHeader private void readHeader(Dex.Section headerIn) throws UnsupportedEncodingException { byte[] magic = headerIn.readByteArray(8); int apiTarget = DexFormat.magicToApi(magic); if (apiTarget != DexFormat.API_NO_EXTENDED_OPCODES) { throw new DexException(\u0026#34;Unexpected magic: \u0026#34; + Arrays.toString(magic)); } checksum = headerIn.readInt(); signature = headerIn.readByteArray(20); fileSize = headerIn.readInt(); ...... stringIds.size = headerIn.readInt(); stringIds.off = headerIn.readInt(); typeIds.size = headerIn.readInt(); typeIds.off = headerIn.readInt(); protoIds.size = headerIn.readInt(); protoIds.off = headerIn.readInt(); ...... dataSize = headerIn.readInt(); dataOff = headerIn.readInt(); readMap private void readMap(Dex.Section in) throws IOException { int mapSize = in.readInt(); Section previous = null; for (int i = 0; i \u0026lt; mapSize; i++) { short type = in.readShort(); in.readShort(); // unused  Section section = getSection(type); int size = in.readInt(); int offset = in.readInt(); if ((section.size != 0 \u0026amp;\u0026amp; section.size != size) || (section.off != Section.UNDEF_OFFSET \u0026amp;\u0026amp; section.off != offset)) {//末尾map中的size和offset应该和header中的size,offset一致  throw new DexException(\u0026#34;Unexpected map value for 0x\u0026#34; + Integer.toHexString(type)); } section.size = size; section.off = offset; if (previous != null \u0026amp;\u0026amp; previous.off \u0026gt; section.off) { throw new DexException(\u0026#34;Map is unsorted at \u0026#34; + previous + \u0026#34;, \u0026#34; + section); } previous = section; } header.off = 0; Arrays.sort(sections); // Skip header section, since its offset must be zero.  for (int i = 1; i \u0026lt; sections.length; ++i) { if (sections[i].off == Section.UNDEF_OFFSET) { sections[i].off = sections[i - 1].off; } } } computeSizesFromOffsets public void computeSizesFromOffsets() { int end = fileSize; for (int i = sections.length - 1; i \u0026gt;= 0; i--) {//18个Section反向迭代，计算出每个Section的byteCount  Section section = sections[i]; if (section.off == Section.UNDEF_OFFSET) { continue; } if (section.off \u0026gt; end) { throw new DexException(\u0026#34;Map is unsorted at \u0026#34; + section); } section.byteCount = end - section.off; end = section.off; } dataOff = header.byteCount \\+ stringIds.byteCount \\+ typeIds.byteCount \\+ protoIds.byteCount \\+ fieldIds.byteCount \\+ methodIds.byteCount \\+ classDefs.byteCount; dataSize = fileSize - dataOff; } TableOfContents.Section public static class Section implements Comparable\u0026lt;Section\u0026gt; { public final short type; public boolean isElementFourByteAligned; public int size = 0;//数组大小  public int off = UNDEF_OFFSET;//起始地址  public int byteCount = 0;//整个Section所占区域大小  public Section(int type, boolean isElementFourByteAligned) { this.type = (short) type; this.isElementFourByteAligned = isElementFourByteAligned; if (type == SECTION_TYPE_HEADER) { off = 0; size = 1; byteCount = SizeOf.HEADER_ITEM; } else if (type == SECTION_TYPE_MAPLIST) { size = 1; } } public static abstract class Item\u0026lt;T\u0026gt; implements Comparable\u0026lt;T\u0026gt; { public int off; public Item(int off) { this.off = off; } } Dex.Section public final class Section extends DexDataBuffer { private final String name; private Section(String name, ByteBuffer data) { super(data); this.name = name; } } class DexDataBuffer { public DexDataBuffer(ByteBuffer data) { this.data = data; this.data.order(ByteOrder.LITTLE_ENDIAN); this.dataBound = data.limit(); this.isResizeAllowed = false; } } AbstractIndexMap.adjust(Code) public Code adjust(Code code) { int adjustedDebugInfoOffset = adjustDebugInfoItemOffset(code.debugInfoOffset); short[] adjustedInstructions = adjustInstructions(code.instructions);//main  Code.CatchHandler[] adjustedCatchHandlers = adjustCatchHandlers(code.catchHandlers); return new Code( code.off, code.registersSize, code.insSize, code.outsSize, adjustedDebugInfoOffset, adjustedInstructions, code.tries, adjustedCatchHandlers ); } private short[] adjustInstructions(short[] instructions) { if (instructions == null || instructions.length == 0) { return instructions; } InstructionTransformer insTrans = new InstructionTransformer(this); return insTrans.transform(instructions); } InstructionTransformer public short[] transform(short[] encodedInstructions) throws DexException { ShortArrayCodeOutput out = new ShortArrayCodeOutput(encodedInstructions.length);//因为每个指令的长度是u1 也就是0~255  InstructionPromoter ipmo = new InstructionPromoter();//地址转换，应对类似const-string 到const-string/jumbo的地址扩展情况  InstructionWriter iw = new InstructionWriter(out, ipmo); InstructionReader ir = new InstructionReader(new ShortArrayCodeInput(encodedInstructions)); try { // First visit, we collect mappings from original target address to promoted target address.  ir.accept(new InstructionTransformVisitor(ipmo));//main  // Then do the real transformation work.  ir.accept(new InstructionTransformVisitor(iw));//main  } catch (EOFException e) { throw new DexException(e); } return out.getArray(); } InstructionReader(被访问者) private final ShortArrayCodeInput codeIn; public InstructionReader(ShortArrayCodeInput in) { this.codeIn = in; } public void accept(InstructionVisitor iv) throws EOFException { codeIn.reset(); while (codeIn.hasMore()) { int currentAddress = codeIn.cursor(); int opcodeUnit = codeIn.read(); int opcodeForSwitch = Opcodes.extractOpcodeFromUnit(opcodeUnit);//main  switch (opcodeForSwitch) { case Opcodes.SPECIAL_FORMAT: { iv.visitZeroRegisterInsn(currentAddress, opcodeUnit, 0, InstructionCodec.INDEX_TYPE_NONE, 0, 0L); break; } case Opcodes.GOTO: { int opcode = InstructionCodec.byte0(opcodeUnit);//main  int target = (byte) InstructionCodec.byte1(opcodeUnit); // sign-extend  iv.visitZeroRegisterInsn(currentAddress, opcode, 0, InstructionCodec.INDEX_TYPE_NONE, currentAddress + target, 0L); break; } ...... case Opcodes.INVOKE_STATIC: case Opcodes.INVOKE_INTERFACE: { int opcode = InstructionCodec.byte0(opcodeUnit); int e = InstructionCodec.nibble2(opcodeUnit); int registerCount = InstructionCodec.nibble3(opcodeUnit); int index = codeIn.read(); int abcd = codeIn.read(); int a = InstructionCodec.nibble0(abcd); int b = InstructionCodec.nibble1(abcd); int c = InstructionCodec.nibble2(abcd); int d = InstructionCodec.nibble3(abcd); int indexType = InstructionCodec.getInstructionIndexType(opcode); switch (registerCount) { case 0: { iv.visitZeroRegisterInsn(currentAddress, opcode, index, indexType, 0, 0L); break; } case 1: { iv.visitOneRegisterInsn(currentAddress, opcode, index, indexType, 0, 0L, a); break; } case 2: { iv.visitTwoRegisterInsn(currentAddress, opcode, index, indexType, 0, 0L, a, b); break; } case 3: { iv.visitThreeRegisterInsn(currentAddress, opcode, index, indexType, 0, 0L, a, b, c); break; } case 4: { iv.visitFourRegisterInsn(currentAddress, opcode, index, indexType, 0, 0L, a, b, c, d); break; } case 5: { iv.visitFiveRegisterInsn(currentAddress, opcode, index, indexType, 0, 0L, a, b, c, d, e); break; } default: { throw new DexException(\u0026#34;bogus registerCount: \u0026#34; + Hex.uNibble(registerCount)); } InstructionVisitor类设计 classDiagram class InstructionVisitor { +visitZeroRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal) void +visitOneRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal, int a) void } InstructionVisitor\u0026lt;|--InstructionTransformVisitor InstructionTransformVisitor--*InstructionPromoter:delegate InstructionVisitor\u0026lt;|--InstructionPromoter InstructionVisitor\u0026lt;|--InstructionWriter InstructionTransformVisitor--*InstructionWriter:delegate InstructionVisitor private final InstructionVisitor prevIv; public InstructionVisitor(InstructionVisitor iv) { this.prevIv = iv; } public void visitZeroRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal) { if (prevIv != null) { prevIv.visitZeroRegisterInsn(currentAddress, opcode, index, indexType, target, literal); } } public void visitOneRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal, int a) { if (prevIv != null) { prevIv.visitOneRegisterInsn(currentAddress, opcode, index, indexType, target, literal, a); } } InstructionTransformVisitor @Override public void visitZeroRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal) { int mappedIndex = transformIndexIfNeeded(index, indexType); super.visitZeroRegisterInsn(currentAddress, opcode, mappedIndex, indexType, target, literal); } @Override public void visitOneRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal, int a) { int mappedIndex = transformIndexIfNeeded(index, indexType);//这里index为old index， mappedIndex为new dex中的 index  super.visitOneRegisterInsn(currentAddress, opcode, mappedIndex, indexType, target, literal, a); } InstructionWriter public void visitZeroRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal) { } public void visitOneRegisterInsn(int currentAddress, int opcode, int index, int indexType, int target, long literal, int a) { switch (opcode) { case Opcodes.CONST_STRING: { if (this.hasPromoter) { if (index \u0026gt; 0xFFFF) { codeOut.write( InstructionCodec.codeUnit(Opcodes.CONST_STRING_JUMBO, a), InstructionCodec.unit0(index), InstructionCodec.unit1(index) ); } else { short indexUnit = (short) index; codeOut.write(InstructionCodec.codeUnit(opcode, a), indexUnit); //写入到out字节码中的字符串 index 是new dex中的索引，这里把旧的 Code 字节码强行改变，所以在做对比的时候这两个的字节码是完全一样的，这个方法也不会将该方法打入补丁包中，这个过程对补丁包的大小影响很大，能减少好多原本没有改变的方法打入补丁包中  } 参考 https://www.zybuluo.com/dodola/note/554061\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/tinker/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/tinkersource/",
	"title": "TinkerSource",
	"tags": [],
	"description": "",
	"content": "TinkerApplication.attachBaseContext /** \\* tinkerFlags, which types is supported \\* dex only, library only, all support \\* default: TINKER_ENABLE_ALL */ private final int tinkerFlags; private final boolean tinkerLoadVerifyFlag; private final String delegateClassName; private final String loaderClassName; private ITinkerInlineFenceBridge mBridge = null; private static final String TINKER_LOADER_METHOD = \u0026#34;tryLoad\u0026#34;; @Override protected void attachBaseContext(Context base) { super.attachBaseContext(base); Thread.setDefaultUncaughtExceptionHandler(new TinkerUncaughtHandler(this)); onBaseContextAttached(base);//main  } private void onBaseContextAttached(Context base) { try { final long applicationStartElapsedTime = SystemClock.elapsedRealtime(); final long applicationStartMillisTime = System.currentTimeMillis(); loadTinker();//main  //补丁应用之后才初始化TinkerApplicationInlineFence类，并在其中反射构造SampleApplicationLike，达到修复application代码的目的  mBridge = createInlineFence(tinkerFlags, delegateClassName, tinkerLoadVerifyFlag, applicationStartElapsedTime, applicationStartMillisTime, tinkerResultIntent); mBridge.attachBaseContext(this, base); //reset save mode  if (useSafeMode) { ShareTinkerInternals.setSafeModeCount(this, 0); } } } loadTinker private void loadTinker() { try { //reflect tinker loader, because loaderClass may be define by user!  Class\u0026lt;?\u0026gt; tinkerLoadClass = Class.forName(loaderClassName, false, TinkerApplication.class.getClassLoader()); Method loadMethod = tinkerLoadClass.getMethod(TINKER_LOADER_METHOD, TinkerApplication.class); Constructor\u0026lt;?\u0026gt; constructor = tinkerLoadClass.getConstructor(); tinkerResultIntent = (Intent) loadMethod.invoke(constructor.newInstance(), this); } catch (Throwable e) { //has exception, put exception error code  tinkerResultIntent = new Intent(); ShareIntentUtil.setIntentReturnCode(tinkerResultIntent, ShareConstants.ERROR_LOAD_PATCH_UNKNOWN_EXCEPTION); tinkerResultIntent.putExtra(INTENT_PATCH_EXCEPTION, e); } } TinkerLoader.tryLoad class TinkerLoader extends AbstractTinkerLoader { /** * only main process can handle patch version change or incomplete */ @Override public Intent tryLoad(TinkerApplication app) { Log.d(TAG, \u0026#34;tryLoad test test\u0026#34;); Intent resultIntent = new Intent(); long begin = SystemClock.elapsedRealtime(); tryLoadPatchFilesInternal(app, resultIntent); long cost = SystemClock.elapsedRealtime() - begin; ShareIntentUtil.setIntentPatchCostTime(resultIntent, cost); return resultIntent; } private void tryLoadPatchFilesInternal(TinkerApplication app, Intent resultIntent) { //data dir, such as /data/data/tinker.sample.android/tinker File patchDirectoryFile = SharePatchFileUtil.getPatchDirectory(app); //tinker String patchDirectoryPath = patchDirectoryFile.getAbsolutePath(); //tinker/patch.info File patchInfoFile = SharePatchFileUtil.getPatchInfoFile(patchDirectoryPath); patchInfo = SharePatchInfo.readAndCheckPropertyWithLock(patchInfoFile, patchInfoLockFile); boolean isRemoveNewVersion = patchInfo.isRemoveNewVersion; // So far new version is not loaded in main process and other processes.  // We can remove new version directory safely.  if (mainProcess \u0026amp;\u0026amp; isRemoveNewVersion) { Log.w(TAG, \u0026#34;found clean patch mark and we are in main process, delete patch file now.\u0026#34;); String patchName = SharePatchFileUtil.getPatchVersionDirectory(newVersion); if (patchName != null) { String patchVersionDirFullPath = patchDirectoryPath + \u0026#34;/\u0026#34; + patchName; SharePatchFileUtil.deleteDir(patchVersionDirFullPath); SharePatchInfo.rewritePatchInfoFileWithLock(patchInfoFile, patchInfo, patchInfoLockFile); } } //tinker/patch-641e634c String patchVersionDirectory = patchDirectoryPath + \u0026#34;/\u0026#34; + patchName; File patchVersionDirectoryFile = new File(patchVersionDirectory); if (!patchVersionDirectoryFile.exists()) { //we may delete patch info file  ShareIntentUtil.setIntentReturnCode(resultIntent, ShareConstants.ERROR_LOAD_PATCH_VERSION_DIRECTORY_NOT_EXIST); return; } //tinker/patch-641e634c/patch-641e634c.apk  final String patchVersionFileRelPath = SharePatchFileUtil.getPatchVersionFile(version); File patchVersionFile = (patchVersionFileRelPath != null ? new File(patchVersionDirectoryFile.getAbsolutePath(), patchVersionFileRelPath) : null); ShareSecurityCheck securityCheck = new ShareSecurityCheck(app); int returnCode = ShareTinkerInternals.checkTinkerPackage(app, tinkerFlag, patchVersionFile, securityCheck); if (returnCode != ShareConstants.ERROR_PACKAGE_CHECK_OK) { //now we can load patch jar  if (!isArkHotRuning \u0026amp;\u0026amp; isEnabledForDex) { boolean loadTinkerJars = TinkerDexLoader.loadTinkerJars(app, patchVersionDirectory, oatDex, resultIntent, isSystemOTA, isProtectedApp);//main  } } TinkerDexLoader.loadTinkerJars /** \\* Load tinker JARs and add them to \\* the Application ClassLoader. */ @TargetApi(Build.VERSION_CODES.ICE_CREAM_SANDWICH) public static boolean loadTinkerJars(final TinkerApplication application, String directory, String oatDir, Intent intentResult, boolean isSystemOTA, boolean isProtectedApp) { BaseDexClassLoader classLoader = (BaseDexClassLoader) TinkerDexLoader.class.getClassLoader(); if (classLoader != null) { Log.i(TAG, \u0026#34;classloader: \u0026#34; + classLoader.toString()); } else { Log.e(TAG, \u0026#34;classloader is null\u0026#34;); ShareIntentUtil.setIntentReturnCode(intentResult, ShareConstants.ERROR_LOAD_PATCH_VERSION_DEX_CLASSLOADER_NULL); return false; } File optimizeDir = new File(directory + \u0026#34;/\u0026#34; + oatDir);//main ...... try { SystemClassLoaderAdder.installDexes(application, classLoader, optimizeDir, legalFiles, isProtectedApp);//main  } catch (Throwable e) { Log.e(TAG, \u0026#34;install dexes failed\u0026#34;); intentResult.putExtra(ShareIntentUtil.INTENT_PATCH_EXCEPTION, e); ShareIntentUtil.setIntentReturnCode(intentResult, ShareConstants.ERROR_LOAD_PATCH_VERSION_DEX_LOAD_EXCEPTION); return false; } return true; SystemClassLoaderAdder.installDexes public static void installDexes(Application application, BaseDexClassLoader loader, File dexOptDir, List\u0026lt;File\u0026gt; files, boolean isProtectedApp) throws Throwable { Log.i(TAG, \u0026#34;installDexes dexOptDir: \u0026#34; + dexOptDir.getAbsolutePath() + \u0026#34;, dex size:\u0026#34; + files.size()); if (!files.isEmpty()) { files = createSortedAdditionalPathEntries(files); ClassLoader classLoader = loader; if (Build.VERSION.SDK_INT \u0026gt;= 24 \u0026amp;\u0026amp; !isProtectedApp) { classLoader = AndroidNClassLoader.inject(loader, application); } //because in dalvik, if inner class is not the same classloader with it wrapper class.  //it won\u0026#39;t fail at dex2opt  if (Build.VERSION.SDK_INT \u0026gt;= 23) { V23.install(classLoader, files, dexOptDir);//main  } else if (Build.VERSION.SDK_INT \u0026gt;= 19) { V19.install(classLoader, files, dexOptDir); } else if (Build.VERSION.SDK_INT \u0026gt;= 14) { V14.install(classLoader, files, dexOptDir); } else { V4.install(classLoader, files, dexOptDir); } //install done  sPatchDexCount = files.size(); Log.i(TAG, \u0026#34;after loaded classloader: \u0026#34; + classLoader + \u0026#34;, dex size:\u0026#34; + sPatchDexCount); if (!checkDexInstall(classLoader)) { //reset patch dex  SystemClassLoaderAdder.uninstallPatchDex(classLoader); throw new TinkerRuntimeException(ShareConstants.CHECK_DEX_INSTALL_FAIL); } /** \\* Installer for platform versions 23. */ private static final class V23 { private static void install(ClassLoader loader, List\u0026lt;File\u0026gt; additionalClassPathEntries, File optimizedDirectory) throws IllegalArgumentException, IllegalAccessException, NoSuchFieldException, InvocationTargetException, NoSuchMethodException, IOException { /* The patched class loader is expected to be a descendant of \\* dalvik.system.BaseDexClassLoader. We modify its \\* dalvik.system.DexPathList pathList field to append additional DEX \\* file entries. */ Field pathListField = ShareReflectUtil.findField(loader, \u0026#34;pathList\u0026#34;); Object dexPathList = pathListField.get(loader); ArrayList\u0026lt;IOException\u0026gt; suppressedExceptions = new ArrayList\u0026lt;IOException\u0026gt;(); ShareReflectUtil.expandFieldArray(dexPathList, \u0026#34;dexElements\u0026#34;, makePathElements(dexPathList, new ArrayList\u0026lt;File\u0026gt;(additionalClassPathEntries), optimizedDirectory, suppressedExceptions));//main  if (suppressedExceptions.size() \u0026gt; 0) { for (IOException e : suppressedExceptions) { Log.w(TAG, \u0026#34;Exception in makePathElement\u0026#34;, e); throw e; }}} /** \\* A wrapper around \\* {@code private static final dalvik.system.DexPathList#makePathElements}. */ private static Object[] makePathElements( Object dexPathList, ArrayList\u0026lt;File\u0026gt; files, File optimizedDirectory, ArrayList\u0026lt;IOException\u0026gt; suppressedExceptions) throws IllegalAccessException, InvocationTargetException, NoSuchMethodException { Method makePathElements; try { makePathElements = ShareReflectUtil.findMethod(dexPathList, \u0026#34;makePathElements\u0026#34;, List.class, File.class, List.class); } catch (NoSuchMethodException e) { Log.e(TAG, \u0026#34;NoSuchMethodException: makePathElements(List,File,List) failure\u0026#34;); try { makePathElements = ShareReflectUtil.findMethod(dexPathList, \u0026#34;makePathElements\u0026#34;, ArrayList.class, File.class, ArrayList.class); } catch (NoSuchMethodException e1) { Log.e(TAG, \u0026#34;NoSuchMethodException: makeDexElements(ArrayList,File,ArrayList) failure\u0026#34;); try { Log.e(TAG, \u0026#34;NoSuchMethodException: try use v19 instead\u0026#34;); return V19.makeDexElements(dexPathList, files, optimizedDirectory, suppressedExceptions); } catch (NoSuchMethodException e2) { Log.e(TAG, \u0026#34;NoSuchMethodException: makeDexElements(List,File,List) failure\u0026#34;); throw e2; } } } return (Object[]) makePathElements.invoke(dexPathList, files, optimizedDirectory, suppressedExceptions); } } TinkerApplicationInlineFence.attachBaseContext interface ITinkerInlineFenceBridge { void attachBaseContext(TinkerApplication app, Context base); void onCreate(TinkerApplication app); void onConfigurationChanged(Configuration newConfig); void onTrimMemory(int level); void onLowMemory(); void onTerminate(); ClassLoader getClassLoader(ClassLoader cl); Context getBaseContext(Context base); AssetManager getAssets(AssetManager assets); Resources getResources(Resources res); Object getSystemService(String name, Object service); } class TinkerApplicationInlineFence implements ITinkerInlineFenceBridge { private final Intent mTinkerResultIntent; private ApplicationLike mApplicationLike = null; } @Override public void attachBaseContext(TinkerApplication app, Context base) { attachBaseContextImpl_$noinline$(app, base); } private void attachBaseContextImpl_$noinline$(TinkerApplication app, Context base) { try { dummyThrowExceptionMethod(); } finally { ensureDelegate(app);//main  if (mApplicationLike != null) { mApplicationLike.onBaseContextAttached(base);//main  } } } private synchronized void ensureDelegate(TinkerApplication app) { if (mApplicationLike == null) { mApplicationLike = (ApplicationLike) createDelegate(app); } } private Object createDelegate(TinkerApplication app) { try { // Use reflection to create the delegate so it doesn\u0026#39;t need to go into the primary dex.  // And we can also patch it  Class\u0026lt;?\u0026gt; delegateClass = Class.forName(mDelegateClassName, false, this.getClass().getClassLoader()); Constructor\u0026lt;?\u0026gt; constructor = delegateClass.getConstructor(Application.class, int.class, boolean.class, long.class, long.class, Intent.class); return constructor.newInstance(app, mTinkerFlags, mTinkerLoadVerifyFlag, mApplicationStartElapsedTime, mApplicationStartMillisTime, mTinkerResultIntent); } catch (Throwable e) { throw new TinkerRuntimeException(\u0026#34;createDelegate failed\u0026#34;, e); } } DefaultApplicationLike(\u0026hellip;) public DefaultApplicationLike(Application application, int tinkerFlags, boolean tinkerLoadVerifyFlag, long applicationStartElapsedTime, long applicationStartMillisTime, Intent tinkerResultIntent) { super(application, tinkerFlags, tinkerLoadVerifyFlag, applicationStartElapsedTime, applicationStartMillisTime, tinkerResultIntent); } mApplicationLike.onBaseContextAttached SampleApplicationLike类设计和原理 classDiagram class ApplicationLike { +getApplication: Application +getTinkerResultIntent: Intent } ApplicationLifeCycle\u0026lt;|--ApplicationLike ApplicationLike\u0026lt;|--DefaultApplicationLike DefaultApplicationLike\u0026lt;|--SampleApplicationLike graph LR 原先的自定义Application--\u0026gt;|代码迁移到|SampleApplicationLike--\u0026gt;|编译时生成注解中指定的|新的自定义Application--\u0026gt;|代理转发到|SampleApplicationLike @interface DefaultLifeCycle { String application(); String loaderClass() default \u0026#34;com.tencent.tinker.loader.TinkerLoader\u0026#34;; int flags(); boolean loadVerifyFlag() default false; } @DefaultLifeCycle(application = \u0026#34;tinker.sample.android.app.SampleApplication\u0026#34;, //application name to generate  flags = ShareConstants.TINKER_ENABLE_ALL, loadVerifyFlag = false) class SampleApplicationLike { /** * install multiDex before install tinker * so we don\u0026#39;t need to put the tinker lib classes in the main dex */ @TargetApi(Build.VERSION_CODES.ICE_CREAM_SANDWICH) @Override public void onBaseContextAttached(Context base) { super.onBaseContextAttached(base); //you must install multiDex whatever tinker is installed!  MultiDex.install(base); SampleApplicationContext.application = getApplication(); SampleApplicationContext.context = getApplication(); TinkerManager.setTinkerApplicationLike(this); TinkerManager.initFastCrashProtect(); //should set before tinker is installed  TinkerManager.setUpgradeRetryEnable(true); //optional set logIml, or you can use default debug log  TinkerInstaller.setLogIml(new MyLogImp()); //installTinker after load multiDex  //or you can put com.tencent.tinker.** to main dex  TinkerManager.installTinker(this);//main  Tinker tinker = Tinker.with(getApplication()); } } public void registerActivityLifecycleCallbacks(Application.ActivityLifecycleCallbacks callback) { getApplication().registerActivityLifecycleCallbacks(callback); } TinkerManager.installTinker private static ApplicationLike applicationLike; private static SampleUncaughtExceptionHandler uncaughtExceptionHandler; private static boolean isInstalled = false; public static void setUpgradeRetryEnable(boolean enable) { UpgradePatchRetry.getInstance(applicationLike.getApplication()).setRetryEnable(enable); } /** \\* you can specify all class you want. \\* sometimes, you can only install tinker in some process you want! * \\* @param appLike */ public static void installTinker(ApplicationLike appLike) { if (isInstalled) { TinkerLog.w(TAG, \u0026#34;install tinker, but has installed, ignore\u0026#34;); return; } //or you can just use DefaultLoadReporter  LoadReporter loadReporter = new SampleLoadReporter(appLike.getApplication()); //or you can just use DefaultPatchReporter  PatchReporter patchReporter = new SamplePatchReporter(appLike.getApplication()); //or you can just use DefaultPatchListener  PatchListener patchListener = new SamplePatchListener(appLike.getApplication()); //you can set your own upgrade patch if you need  AbstractPatch upgradePatchProcessor = new UpgradePatch(); TinkerInstaller.install(appLike, loadReporter, patchReporter, patchListener, SampleResultService.class, upgradePatchProcessor); isInstalled = true; } TinkerInstaller.install\npublic static Tinker install(ApplicationLike applicationLike, LoadReporter loadReporter, PatchReporter patchReporter, PatchListener listener, Class\u0026lt;? extends AbstractResultService\u0026gt; resultServiceClass, AbstractPatch upgradePatchProcessor) { Tinker tinker = new Tinker.Builder(applicationLike.getApplication()) .tinkerFlags(applicationLike.getTinkerFlags()) .loadReport(loadReporter) .listener(listener) .patchReporter(patchReporter) .tinkerLoadVerifyFlag(applicationLike.getTinkerLoadVerifyFlag()).build(); Tinker.create(tinker); tinker.install(applicationLike.getTinkerResultIntent(), resultServiceClass, upgradePatchProcessor); return tinker; } Tinker.install public static class Builder { public Builder(Context context) { if (context == null) { throw new TinkerRuntimeException(\u0026#34;Context must not be null.\u0026#34;); } this.context = context; this.mainProcess = TinkerServiceInternals.isInMainProcess(context); this.patchProcess = TinkerServiceInternals.isInTinkerPatchServiceProcess(context); this.patchDirectory = SharePatchFileUtil.getPatchDirectory(context); if (this.patchDirectory == null) { TinkerLog.e(TAG, \u0026#34;patchDirectory is null!\u0026#34;); return; } this.patchInfoFile = SharePatchFileUtil.getPatchInfoFile(patchDirectory.getAbsolutePath()); this.patchInfoLockFile = SharePatchFileUtil.getPatchInfoLockFile(patchDirectory.getAbsolutePath()); TinkerLog.w(TAG, \u0026#34;tinker patch directory: %s\u0026#34;, patchDirectory); } /**create custom tinker by {@link Tinker.Builder} * please do it when very first your app start. */ public static void create(Tinker tinker) { if (sInstance != null) { throw new TinkerRuntimeException(\u0026#34;Tinker instance is already set.\u0026#34;); } sInstance = tinker; } public void install(Intent intentResult) { install(intentResult, DefaultTinkerResultService.class, new UpgradePatch()); } public void install(Intent intentResult, Class\u0026lt;? extends AbstractResultService\u0026gt; serviceClass, AbstractPatch upgradePatch) { sInstalled = true; TinkerPatchService.setPatchProcessor(upgradePatch, serviceClass); TinkerLog.i(TAG, \u0026#34;try to install tinker, isEnable: %b, version: %s\u0026#34;, isTinkerEnabled(), ShareConstants.TINKER_VERSION); if (!isTinkerEnabled()) { TinkerLog.e(TAG, \u0026#34;tinker is disabled\u0026#34;); return; } if (intentResult == null) { throw new TinkerRuntimeException(\u0026#34;intentResult must not be null.\u0026#34;); } tinkerLoadResult = new TinkerLoadResult(); //从intentResult中获取loadTinker的结果tinkerResultIntent(位于TinkerApplication)，这个结果经过反射构造TinkerApplicationInlineFence和SampleApplicationLike等最终传入到此处  tinkerLoadResult.parseTinkerResult(getContext(), intentResult);//main  //after load code set  loadReporter.onLoadResult(patchDirectory, tinkerLoadResult.loadCode, tinkerLoadResult.costTime);//main  if (!loaded) { TinkerLog.w(TAG, \u0026#34;tinker load fail!\u0026#34;); } } tinkerLoadResult.parseTinkerResult public boolean parseTinkerResult(Context context, Intent intentResult) { Tinker tinker = Tinker.with(context); loadCode = ShareIntentUtil.getIntentReturnCode(intentResult); costTime = ShareIntentUtil.getIntentPatchCostTime(intentResult); systemOTA = ShareIntentUtil.getBooleanExtra(intentResult, ShareIntentUtil.INTENT_PATCH_SYSTEM_OTA, false); oatDir = ShareIntentUtil.getStringExtra(intentResult, ShareIntentUtil.INTENT_PATCH_OAT_DIR); useInterpretMode = ShareConstants.INTERPRET_DEX_OPTIMIZE_PATH.equals(oatDir); final String oldVersion = ShareIntentUtil.getStringExtra(intentResult, ShareIntentUtil.INTENT_PATCH_OLD_VERSION); final String newVersion = ShareIntentUtil.getStringExtra(intentResult, ShareIntentUtil.INTENT_PATCH_NEW_VERSION); //found uncaught exception, just return  Throwable exception = ShareIntentUtil.getIntentPatchException(intentResult); if (exception != null) { TinkerLog.i(TAG, \u0026#34;Tinker load have exception loadCode:%d\u0026#34;, loadCode); int errorCode = ShareConstants.ERROR_LOAD_EXCEPTION_UNKNOWN; switch (loadCode) { case ShareConstants.ERROR_LOAD_PATCH_UNKNOWN_EXCEPTION: errorCode = ShareConstants.ERROR_LOAD_EXCEPTION_UNKNOWN; break; case ShareConstants.ERROR_LOAD_PATCH_VERSION_DEX_LOAD_EXCEPTION: errorCode = ShareConstants.ERROR_LOAD_EXCEPTION_DEX; break; case ShareConstants.ERROR_LOAD_PATCH_VERSION_RESOURCE_LOAD_EXCEPTION: errorCode = ShareConstants.ERROR_LOAD_EXCEPTION_RESOURCE; break; case ShareConstants.ERROR_LOAD_PATCH_UNCAUGHT_EXCEPTION: errorCode = ShareConstants.ERROR_LOAD_EXCEPTION_UNCAUGHT; break; default: break; } tinker.getLoadReporter().onLoadException(exception, errorCode); return false; } switch (loadCode) { case ShareConstants.ERROR_LOAD_OK: TinkerLog.i(TAG, \u0026#34;oh yeah, tinker load all success\u0026#34;); tinker.setTinkerLoaded(true); // get load dex  dexes = ShareIntentUtil.getIntentPatchDexPaths(intentResult); libs = ShareIntentUtil.getIntentPatchLibsPaths(intentResult); packageConfig = ShareIntentUtil.getIntentPackageConfig(intentResult); if (useInterpretMode) { tinker.getLoadReporter().onLoadInterpret(ShareConstants.TYPE_INTERPRET_OK, null); } if (isMainProcess \u0026amp;\u0026amp; versionChanged) { //change the old version to new  tinker.getLoadReporter().onLoadPatchVersionChanged(oldVersion, newVersion, patchDirectory, patchVersionDirectory.getName()); } return true; LoadReporter DefaultLoadReporter @Override public void onLoadException(Throwable e, int errorCode) { //for unCaught or dex exception, disable tinker all the time with sp  switch (errorCode) { case ShareConstants.ERROR_LOAD_EXCEPTION_DEX: if (e.getMessage().contains(ShareConstants.CHECK_DEX_INSTALL_FAIL)) { TinkerLog.e(TAG, \u0026#34;patch loadReporter onLoadException: tinker dex check fail:\u0026#34; + e.getMessage()); } else { TinkerLog.i(TAG, \u0026#34;patch loadReporter onLoadException: patch load dex exception: %s\u0026#34;, e); } ShareTinkerInternals.setTinkerDisableWithSharedPreferences(context); TinkerLog.i(TAG, \u0026#34;dex exception disable tinker forever with sp\u0026#34;); break; case ShareConstants.ERROR_LOAD_EXCEPTION_RESOURCE: case ShareConstants.ERROR_LOAD_EXCEPTION_UNCAUGHT: case ShareConstants.ERROR_LOAD_EXCEPTION_UNKNOWN: ...... TinkerLog.e(TAG, \u0026#34;tinker load exception, welcome to submit issue to us: https://github.com/Tencent/tinker/issues\u0026#34;); TinkerLog.printErrStackTrace(TAG, e, \u0026#34;tinker load exception\u0026#34;); Tinker.with(context).setTinkerDisable(); checkAndCleanPatch(); } SampleLoadReporter onLoadResult @Override public void onLoadResult(File patchDirectory, int loadCode, long cost) { super.onLoadResult(patchDirectory, loadCode, cost); switch (loadCode) { case ShareConstants.ERROR_LOAD_OK: SampleTinkerReport.onLoaded(cost); break; } Looper.getMainLooper().myQueue().addIdleHandler(new MessageQueue.IdleHandler() { @Override public boolean queueIdle() { if (UpgradePatchRetry.getInstance(context).onPatchRetryLoad()) { SampleTinkerReport.onReportRetryPatch();//main  } return false; } }); } UpgradePatchRetry.onPatchRetryLoad //UpgradePatchRetry public boolean onPatchRetryLoad() { ...... TinkerInstaller.onReceiveUpgradePatch(context, path);//main } //TinkerInstaller /** * new patch file to install, try install them with :patch process */ public static void onReceiveUpgradePatch(Context context, String patchLocation) { Tinker.with(context).getPatchListener().onPatchReceived(patchLocation); } PatchListener interface PatchListener { int onPatchReceived(String path); } DefaultPatchListener onPatchReceived /** \\* when we receive a patch, what would we do? \\* you can overwrite it \\* */ @Override public int onPatchReceived(String path) { final File patchFile = new File(path); final String patchMD5 = SharePatchFileUtil.getMD5(patchFile); final int returnCode = patchCheck(path, patchMD5); if (returnCode == ShareConstants.ERROR_PATCH_OK) { runForgService(); TinkerPatchService.runPatchService(context, path);//main  } else { Tinker.with(context).getLoadReporter().onLoadPatchListenerReceiveFail(new File(path), returnCode); } return returnCode; } TinkerPatchService.runPatchService class TinkerPatchService extends IntentService { public static void setPatchProcessor(AbstractPatch upgradePatch, Class\u0026lt;? extends AbstractResultService\u0026gt; serviceClass) { upgradePatchProcessor = upgradePatch; resultServiceClass = serviceClass; //try to load  try { Class.forName(serviceClass.getName()); } catch (ClassNotFoundException e) { TinkerLog.printErrStackTrace(TAG, e, \u0026#34;patch processor class not found.\u0026#34;); } } } public static void runPatchService(final Context context, final String path) { TinkerLog.i(TAG, \u0026#34;run patch service...\u0026#34;); Intent intent = new Intent(context, TinkerPatchService.class); intent.putExtra(PATCH_PATH_EXTRA, path); intent.putExtra(RESULT_CLASS_EXTRA, resultServiceClass.getName()); try { context.startService(intent); } catch (Throwable thr) { TinkerLog.e(TAG, \u0026#34;run patch service fail, exception:\u0026#34; + thr); } } @Override protected void onHandleIntent(@Nullable Intent intent) { increasingPriority(); doApplyPatch(this, intent); } private static void doApplyPatch(Context context, Intent intent) { Tinker tinker = Tinker.with(context); tinker.getPatchReporter().onPatchServiceStart(intent);//超过maxRetryCount会清除patch，最大重试20次  PatchResult patchResult = new PatchResult(); try { if (upgradePatchProcessor == null) { throw new TinkerRuntimeException(\u0026#34;upgradePatchProcessor is null.\u0026#34;); } result = upgradePatchProcessor.tryPatch(context, path, patchResult);//main  } catch (Throwable throwable) { e = throwable; result = false; tinker.getPatchReporter().onPatchException(patchFile, e); } cost = SystemClock.elapsedRealtime() - begin; tinker.getPatchReporter() .onPatchResult(patchFile, result, cost); patchResult.isSuccess = result; patchResult.rawPatchFilePath = path; patchResult.costTime = cost; patchResult.e = e; AbstractResultService.runResultService(context, patchResult, getPatchResultExtra(intent));//main  sIsPatchApplying.set(false); PatchReporter DefaultPatchReporter.onPatchServiceStart /************************************ :patch process below ***************************************/ /** \\* use for report or some work at the beginning of TinkerPatchService \\* {@code TinkerPatchService.onHandleIntent} begin */ @Override public void onPatchServiceStart(Intent intent) { TinkerLog.i(TAG, \u0026#34;patchReporter onPatchServiceStart: patch service start\u0026#34;); shouldRetry = false; UpgradePatchRetry.getInstance(context).onPatchServiceStart(intent); } UpgradePatchRetry.onPatchServiceStart public void onPatchServiceStart(Intent intent) { String path = TinkerPatchService.getPatchPathExtra(intent); File patchFile = new File(path); String patchMd5 = SharePatchFileUtil.getMD5(patchFile); if (retryInfoFile.exists()) { retryInfo = RetryInfo.readRetryProperty(retryInfoFile); if (retryInfo.md5 == null || retryInfo.times == null || !patchMd5.equals(retryInfo.md5)) { copyToTempFile(patchFile);//main  retryInfo.md5 = patchMd5; retryInfo.times = \u0026#34;1\u0026#34;; } else { int nowTimes = Integer.parseInt(retryInfo.times); if (nowTimes \u0026gt;= maxRetryCount) { SharePatchFileUtil.safeDeleteFile(tempPatchFile); TinkerLog.w(TAG, \u0026#34;onPatchServiceStart retry more than max count, delete retry info file!\u0026#34;); return; } else { retryInfo.times = String.valueOf(nowTimes + 1); } } } else { copyToTempFile(patchFile);//main  retryInfo = new RetryInfo(patchMd5, \u0026#34;1\u0026#34;); } RetryInfo.writeRetryProperty(retryInfoFile, retryInfo); UpgradePatch.tryPatch @Override public boolean tryPatch(Context context, String tempPatchPath, PatchResult patchResult) { //we use destPatchFile instead of patchFile, because patchFile may be deleted during the patch process  if (!DexDiffPatchInternal.tryRecoverDexFiles(manager, signatureCheck, context, patchVersionDirectory, destPatchFile)) {//main  TinkerLog.e(TAG, \u0026#34;UpgradePatch tryPatch:new patch recover, try patch dex failed\u0026#34;); return false; } if (!ArkHotDiffPatchInternal.tryRecoverArkHotLibrary(manager, signatureCheck, context, patchVersionDirectory, destPatchFile)) { return false; } if (!BsDiffPatchInternal.tryRecoverLibraryFiles(manager, signatureCheck, context, patchVersionDirectory, destPatchFile)) { TinkerLog.e(TAG, \u0026#34;UpgradePatch tryPatch:new patch recover, try patch library failed\u0026#34;); return false; } if (!ResDiffPatchInternal.tryRecoverResourceFiles(manager, signatureCheck, context, patchVersionDirectory, destPatchFile)) { TinkerLog.e(TAG, \u0026#34;UpgradePatch tryPatch:new patch recover, try patch resource failed\u0026#34;); return false; } DexDiffPatchInternal\nprotected static boolean tryRecoverDexFiles(Tinker manager, ShareSecurityCheck checker, Context context, String patchVersionDirectory, File patchFile) { boolean result = patchDexExtractViaDexDiff(context, patchVersionDirectory, dexMeta, patchFile); } private static boolean patchDexExtractViaDexDiff(Context context, String patchVersionDirectory, String meta, final File patchFile) { String dir = patchVersionDirectory + \u0026#34;/\u0026#34; + DEX_PATH + \u0026#34;/\u0026#34;; if (!extractDexDiffInternals(context, dir, meta, patchFile, TYPE_DEX)) {//main  TinkerLog.w(TAG, \u0026#34;patch recover, extractDiffInternals fail\u0026#34;); return false; } final String optimizeDexDirectory = patchVersionDirectory + \u0026#34;/\u0026#34; + DEX_OPTIMIZE_PATH + \u0026#34;/\u0026#34;; return dexOptimizeDexFiles(context, legalFiles, optimizeDexDirectory, patchFile);//main patchDexFile,复用DexPatchApplier.executeAndSaveTo private static boolean extractDexDiffInternals(Context context, String dir, String meta, File patchFile, int type) { patchList.clear(); ShareDexDiffPatchInfo.parseDexDiffPatchInfo(meta, patchList); //check source crc instead of md5 for faster  String rawEntryCrc = String.valueOf(rawApkFileEntry.getCrc()); if (!rawEntryCrc.equals(oldDexCrc)) { TinkerLog.e(TAG, \u0026#34;apk entry %s crc is not equal, expect crc: %s, got crc: %s\u0026#34;, patchRealPath, oldDexCrc, rawEntryCrc); manager.getPatchReporter().onPatchTypeExtractFail(patchFile, extractedFile, info.rawName, type); return false; } patchDexFile(apk, patch, rawApkFileEntry, patchFileEntry, info, extractedFile); //patch合成之后比对(合成后的dex文件)和(生成patch之后立刻合成时得到的relatedInfo.newOrFullPatchedMd5)是否一致 //位于assets/dex_meta.txt中的kv[3]，产生于logDexesToDexMeta--logToDexMeta //String meta = fileName + \u0026#34;,\u0026#34; + parentRelative + \u0026#34;,\u0026#34; + destMd5InDvm + \u0026#34;,\u0026#34;  // + destMd5InArt + \u0026#34;,\u0026#34; + dexDiffMd5 + \u0026#34;,\u0026#34; + oldCrc + \u0026#34;,\u0026#34; + newOrFullPatchedCrc + \u0026#34;,\u0026#34; + dexMode;  if (!SharePatchFileUtil.verifyDexFileMd5(extractedFile, extractedFileMd5)) { TinkerLog.w(TAG, \u0026#34;Failed to recover dex file when verify patched dex: \u0026#34; + extractedFile.getPath()); manager.getPatchReporter().onPatchTypeExtractFail(patchFile, extractedFile, info.rawName, type); SharePatchFileUtil.safeDeleteFile(extractedFile); return false; } private static void patchDexFile( ZipFile baseApk, ZipFile patchPkg, ZipEntry oldDexEntry, ZipEntry patchFileEntry, ShareDexDiffPatchInfo patchInfo, File patchedDexFile) throws IOException { new DexPatchApplier(zis, patchFileStream).executeAndSaveTo(zos);//main } dexOptimizeDexFiles //DexDiffPatchInternal private static boolean dexOptimizeDexFiles(Context context, List\u0026lt;File\u0026gt; dexFiles, String optimizeDexDirectory, final File patchFile) { //try parallel dex optimizer  TinkerDexOptimizer.optimizeAll( context, dexFiles, optimizeDexDirectoryFile, new TinkerDexOptimizer.ResultCallback() {... TinkerDexOptimizer\npublic static boolean optimizeAll(Context context, Collection\u0026lt;File\u0026gt; dexFiles, File optimizedDir, boolean useInterpretMode, String targetISA, ResultCallback cb) { for (File dexFile : sortList) { OptimizeWorker worker = new OptimizeWorker(context, dexFile, optimizedDir, useInterpretMode, targetISA, cb); if (!worker.run()) { return false; } } return true; private static class OptimizeWorker { boolean run() { String optimizedPath = SharePatchFileUtil.optimizedPathFor(this.dexFile, this.optimizedDir); if (!ShareTinkerInternals.isArkHotRuning()) { if (useInterpretMode) {//默认false  interpretDex2Oat(dexFile.getAbsolutePath(), optimizedPath);//main  } else if (Build.VERSION.SDK_INT \u0026gt;= 28 || (Build.VERSION.SDK_INT \u0026gt;= 27 \u0026amp;\u0026amp; Build.VERSION.PREVIEW_SDK_INT != 0)) { NewClassLoaderInjector.triggerDex2Oat(context, dexFile.getAbsolutePath());//main  } else { DexFile.loadDex(dexFile.getAbsolutePath(), optimizedPath, 0);//main  } } interpretDex2Oat private void interpretDex2Oat(String dexFilePath, String oatFilePath) throws IOException { final List\u0026lt;String\u0026gt; commandAndParams = new ArrayList\u0026lt;\u0026gt;(); commandAndParams.add(\u0026#34;dex2oat\u0026#34;); // for 7.1.1, duplicate class fix  if (Build.VERSION.SDK_INT \u0026gt;= 24) { commandAndParams.add(\u0026#34;--runtime-arg\u0026#34;); commandAndParams.add(\u0026#34;-classpath\u0026#34;); commandAndParams.add(\u0026#34;--runtime-arg\u0026#34;); commandAndParams.add(\u0026#34;\u0026amp;\u0026#34;); } commandAndParams.add(\u0026#34;--dex-file=\u0026#34; + dexFilePath); commandAndParams.add(\u0026#34;--oat-file=\u0026#34; + oatFilePath); commandAndParams.add(\u0026#34;--instruction-set=\u0026#34; + targetISA); if (Build.VERSION.SDK_INT \u0026gt; 25) { commandAndParams.add(\u0026#34;--compiler-filter=quicken\u0026#34;); } else { commandAndParams.add(\u0026#34;--compiler-filter=interpret-only\u0026#34;); } final ProcessBuilder pb = new ProcessBuilder(commandAndParams); pb.redirectErrorStream(true); final Process dex2oatProcess = pb.start(); StreamConsumer.consumeInputStream(dex2oatProcess.getInputStream()); StreamConsumer.consumeInputStream(dex2oatProcess.getErrorStream()); try { final int ret = dex2oatProcess.waitFor(); if (ret != 0) { throw new IOException(\u0026#34;dex2oat works unsuccessfully, exit code: \u0026#34; + ret); } } } triggerDex2Oat //NewClassLoaderInjector public static void triggerDex2Oat(Context context, File dexOptDir, boolean useDLCOnAPI29AndAbove, String... dexPaths) throws Throwable { ClassLoader triggerClassLoader; if (useDLCOnAPI29AndAbove \u0026amp;\u0026amp; Build.VERSION.SDK_INT \u0026gt;= 29) { triggerClassLoader = createNewClassLoader(context.getClassLoader(), dexOptDir, useDLCOnAPI29AndAbove, dexPaths); } else { // Suggestion from Huawei: Only PathClassLoader (Perhaps other ClassLoaders known by system  // like DexClassLoader also works ?) can be used here to trigger dex2oat so that JIT  // mechanism can participate in runtime Dex optimization.  final StringBuilder sb = new StringBuilder(); boolean isFirst = true; for (String dexPath : dexPaths) { if (isFirst) { isFirst = false; } else { sb.append(File.pathSeparator); } sb.append(dexPath); } triggerClassLoader = new PathClassLoader(sb.toString(), ClassLoader.getSystemClassLoader()); } } DexFile.loadDex \u0026hellip;\u0026hellip;\nAbstractResultService.runResultService class AbstractResultService extends IntentService { public static void runResultService(Context context, PatchResult result, String resultServiceClass) { if (resultServiceClass == null) { throw new TinkerRuntimeException(\u0026#34;resultServiceClass is null.\u0026#34;); } try { Intent intent = new Intent(); intent.setClassName(context, resultServiceClass); intent.putExtra(RESULT_EXTRA, result); context.startService(intent); } catch (Throwable throwable) { TinkerLog.e(TAG, \u0026#34;run result service fail, exception:\u0026#34; + throwable); } } protected void onHandleIntent(Intent intent) { PatchResult result = (PatchResult) ShareIntentUtil.getSerializableExtra(intent, RESULT_EXTRA); onPatchResult(result);//main  } } DefaultTinkerResultService.onPatchResult /** \\* we may want to use the new patch just now!! */ @Override public void onPatchResult(PatchResult result) { if (result == null) { TinkerLog.e(TAG, \u0026#34;DefaultTinkerResultService received null result!!!!\u0026#34;); return; } TinkerLog.i(TAG, \u0026#34;DefaultTinkerResultService received a result:%s \u0026#34;, result.toString()); //first, we want to kill the recover process  TinkerServiceInternals.killTinkerPatchServiceProcess(getApplicationContext()); // if success and newPatch, it is nice to delete the raw file, and restart at once  // only main process can load an upgrade patch!  if (result.isSuccess) { deleteRawPatchFile(new File(result.rawPatchFilePath)); if (checkIfNeedKill(result)) { android.os.Process.killProcess(android.os.Process.myPid()); } else { TinkerLog.i(TAG, \u0026#34;I have already install the newly patch version!\u0026#34;); } } } SampleResultService.onPatchResult @Override public void onPatchResult(final PatchResult result) { //first, we want to kill the recover process  TinkerServiceInternals.killTinkerPatchServiceProcess(getApplicationContext()); Handler handler = new Handler(Looper.getMainLooper()); handler.post(new Runnable() { @Override public void run() { if (result.isSuccess) { Toast.makeText(getApplicationContext(), \u0026#34;patch success, please restart process\u0026#34;, Toast.LENGTH_LONG).show(); } else { Toast.makeText(getApplicationContext(), \u0026#34;patch fail, please check reason\u0026#34;, Toast.LENGTH_LONG).show(); } } }); // is success and newPatch, it is nice to delete the raw file, and restart at once  // for old patch, you can\u0026#39;t delete the patch file  if (result.isSuccess) { deleteRawPatchFile(new File(result.rawPatchFilePath)); //not like TinkerResultService, I want to restart just when I am at background!  //if you have not install tinker this moment, you can use TinkerApplicationHelper api  if (checkIfNeedKill(result)) { if (Utils.isBackground()) { TinkerLog.i(TAG, \u0026#34;it is in background, just restart process\u0026#34;); restartProcess(); } else { //we can wait process at background, such as onAppBackground  //or we can restart when the screen off  TinkerLog.i(TAG, \u0026#34;tinker wait screen to restart process\u0026#34;); new Utils.ScreenState(getApplicationContext(), new Utils.ScreenState.IOnScreenOff() { @Override public void onScreenOff() { restartProcess(); } }); } } else { TinkerLog.i(TAG, \u0026#34;I have already install the newly patch version!\u0026#34;); } } /** \\* you can restart your process through service or broadcast */ private void restartProcess() { TinkerLog.i(TAG, \u0026#34;app is background now, i can kill quietly\u0026#34;); //you can send service or broadcast intent to restart your process  android.os.Process.killProcess(android.os.Process.myPid()); } 其他 Tinker cleanPatch /**clean all patch files */ public void cleanPatch() { final File patchInfoFile = SharePatchFileUtil.getPatchInfoFile(patchDirectory.getAbsolutePath()); final File patchInfoLockFile = SharePatchFileUtil.getPatchInfoLockFile(patchDirectory.getAbsolutePath()); final SharePatchInfo patchInfo = SharePatchInfo.readAndCheckPropertyWithLock(patchInfoFile, patchInfoLockFile); if (patchInfo != null) { patchInfo.isRemoveNewVersion = true;//标记目录：/data/data/${packageName}/tinker/patch.info中的标记信息，下次loadTinker时会根据这个标记清除对应patch目录信息 /*patchinfo.oldVersion表示当前正在使用的已经apply/load完成之后的patch patchinfo.newVersion表示当前已经成功patch，但还没有apply完成的patch*/ SharePatchInfo.rewritePatchInfoFileWithLock(patchInfoFile, patchInfo, patchInfoLockFile); } } 重试patch @Override public void onLoadResult(File patchDirectory, int loadCode, long cost) { super.onLoadResult(patchDirectory, loadCode, cost); switch (loadCode) { case ShareConstants.ERROR_LOAD_OK: SampleTinkerReport.onLoaded(cost); break; } Looper.myQueue().addIdleHandler(() -\u0026gt; { if (UpgradePatchRetry.getInstance(context).onPatchRetryLoad()) { SampleTinkerReport.onReportRetryPatch(); } return false; }); } UpgradePatchRetry::onPatchRetryLoad test.dex检测流程 构建出的patch会包含test.dex文件，内部符合dex文件结构，仅仅包含一个class“com.tencent.tinker.loader.TinkerTestDexLoad”，其静态检测方法返回true，用于在install之后进行SystemClassLoaderAdder.checkDexInstall校验，以判别是否成功插入修复的dex文件\ntinker_data 位置:（work/Desktop20200621/）\npatch过程会将patch文件放入/data/data/${applicationId}/tinker/，目录结构为\ntinker\u0026ndash;patch.info\n​ \u0026ndash;info.lock\n​ \u0026ndash;patch332ed5cc\u0026ndash;res\u0026ndash;\n​ \u0026ndash;dex\u0026ndash;tinker_classN.apk(内含多个dex，其中既有test.dex重命名之后的dex)\n​ \u0026ndash;odex\u0026ndash;tinker_classN.dex\n​ patch-332ed5cc.apk\n​\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/touch/touch/",
	"title": "Touch",
	"tags": [],
	"description": "",
	"content": "原理图 graph TB subgraph 3Down事件添加gestureRecognizer到pointerRouter,后续才会分发过来 pointerRouter.addRoute end subgraph 4分发pointerRouter.addRoute添加进来的监听 pointerRouter.route_event end subgraph 1Down事件时确定HitTestResult PointerDownEvent end subgraph 2发给HitTestResult每个元素 PointerAllEvent end PointerDownEvent--\u0026gt;|hitTest|HitTestResult--\u0026gt;HitTestTarget1 HitTestResult--\u0026gt;|RenderPointerListener.handleEvent|RawGestureDetectorState._handlePointerDown--\u0026gt;|addPointer_event|gestureRecognizer1 HitTestResult--\u0026gt;HitTestTargetXxx HitTestResult--\u0026gt;|handleEvent|GestureBinding.handleEvent--\u0026gt;pointerRouter.route_event GestureBinding.handleEvent--\u0026gt;|Down?|gestureArena.close GestureBinding.handleEvent--\u0026gt;|Up?|gestureArena.sweep RawGestureDetectorState._handlePointerDown--\u0026gt;|addPointer_event|gestureRecognizerXxx--\u0026gt;|Down|pointerRouter.addRoute gestureRecognizerXxx--\u0026gt;|Down|gestureArena.add PointerAllEvent--\u0026gt;|dispatchEvent|HitTestResult 类设计 GestureBinding.initInstances /// A binding for the gesture subsystem. //mixin GestureBinding on BindingBase implements HitTestable, HitTestDispatcher, HitTestTarget @override void initInstances() { super.initInstances(); _instance = this; window.onPointerDataPacket = _handlePointerDataPacket; } GestureBinding._handlePointerDataPacket void _handlePointerDataPacket(ui.PointerDataPacket packet) { // We convert pointer data to logical pixels so that e.g. the touch slop can be  // defined in a device-independent manner.  _pendingPointerEvents.addAll(PointerEventConverter.expand(packet.data, window.devicePixelRatio)); if (!locked) _flushPointerEventQueue(); } void _flushPointerEventQueue() { assert(!locked); while (_pendingPointerEvents.isNotEmpty) _handlePointerEvent(_pendingPointerEvents.removeFirst()); } GestureBinding._handlePointerEvent void _handlePointerEvent(PointerEvent event) { HitTestResult hitTestResult; if (event is PointerDownEvent || event is PointerSignalEvent) { assert(!_hitTests.containsKey(event.pointer)); hitTestResult = HitTestResult(); hitTest(hitTestResult, event.position);//main  if (event is PointerDownEvent) { _hitTests[event.pointer] = hitTestResult; } } else if (event is PointerUpEvent || event is PointerCancelEvent) { hitTestResult = _hitTests.remove(event.pointer); } else if (event.down) { // Because events that occur with the pointer down (like  // PointerMoveEvents) should be dispatched to the same place that their  // initial PointerDownEvent was, we want to re-use the path we found when  // the pointer went down, rather than do hit detection each time we get  // such an event.  hitTestResult = _hitTests[event.pointer]; } if (hitTestResult != null || event is PointerHoverEvent || event is PointerAddedEvent || event is PointerRemovedEvent) { dispatchEvent(event, hitTestResult);//main  } hitTest RendererBinding.hitTest //GestureBinding /// Determine which [HitTestTarget] objects are located at a given position.  @override // from HitTestable  void hitTest(HitTestResult result, Offset position) { result.add(HitTestEntry(this)); } //mixin RendererBinding on BindingBase, ServicesBinding, SchedulerBinding, GestureBinding, SemanticsBinding, HitTestable { @override void hitTest(HitTestResult result, Offset position) { assert(renderView != null); renderView.hitTest(result, position: position); super.hitTest(result, position); } RenderView.hitTest //class RenderView extends RenderObject with RenderObjectWithChildMixin\u0026lt;RenderBox\u0026gt; { /// Determines the set of render objects located at the given position. bool hitTest(HitTestResult result, { Offset position }) { if (child != null) child.hitTest(BoxHitTestResult.wrap(result), position: position); result.add(HitTestEntry(this)); return true; } RenderBox.hitTest //RenderBox /// Determines the set of render objects located at the given position.  bool hitTest(BoxHitTestResult result, { @required Offset position }) { if (_size.contains(position)) { if (hitTestChildren(result, position: position) || hitTestSelf(position)) { result.add(BoxHitTestEntry(this, position)); return true; } } return false; /// Override this method to check whether any children are located at the  /// given position.  /// Used by [hitTest]. If you override [hitTest] and do not call this  /// function, then you don\u0026#39;t need to implement this function. @protected bool hitTestChildren(BoxHitTestResult result, { Offset position }) =\u0026gt; false; /// Override this method if this render object can be hit even if its  /// children were not hit.  /// The caller is responsible for transforming [position] from global  /// coordinates to its location relative to the origin of this [RenderBox].  /// This [RenderBox] is responsible for checking whether the given position is  /// within its bounds.  /// Used by [hitTest]. If you override [hitTest] and do not call this  /// function, then you don\u0026#39;t need to implement this function.  @protected bool hitTestSelf(Offset position) =\u0026gt; false; dispatchEvent /// Dispatch an event to a hit test result\u0026#39;s path. @override // from HitTestDispatcher  void dispatchEvent(PointerEvent event, HitTestResult hitTestResult) { // No hit test information implies that this is a hover or pointer  // add/remove event.  if (hitTestResult == null) { pointerRouter.route(event); return; } for (HitTestEntry entry in hitTestResult.path) { try { entry.target.handleEvent(event.transformed(entry.transform), entry);//main  } catch (exception, stack) { } } } handleEvent RenderPointerListener.handleEvent renderpointerlistener\nGestureBinding.handleEvent @override // from HitTestTarget  void handleEvent(PointerEvent event, HitTestEntry entry) { pointerRouter.route(event); if (event is PointerDownEvent) { gestureArena.close(event.pointer); } else if (event is PointerUpEvent) { gestureArena.sweep(event.pointer); } else if (event is PointerSignalEvent) { pointerSignalResolver.resolve(event); } } PointerRouter.route(event) /// A routing table for [PointerEvent] events.  /// Calls the routes registered for this pointer event.  ///  /// Routes are called in the order in which they were added to the  /// PointerRouter object.  void route(PointerEvent event) { final Map\u0026lt;PointerRoute, Matrix4?\u0026gt;? routes = _routeMap[event.pointer]; final Map\u0026lt;PointerRoute, Matrix4?\u0026gt; copiedGlobalRoutes = Map\u0026lt;PointerRoute, Matrix4?\u0026gt;.from(_globalRoutes); if (routes != null) { _dispatchEventToRoutes( event, routes, Map\u0026lt;PointerRoute, Matrix4?\u0026gt;.from(routes), ); } _dispatchEventToRoutes(event, _globalRoutes, copiedGlobalRoutes); } gestureArena.close /// Prevents new members from entering the arena.  /// Called after the framework has finished dispatching the pointer down event.  void close(int pointer) { final _GestureArena state = _arenas[pointer]; if (state == null) return; // This arena either never existed or has been resolved.  state.isOpen = false; _tryToResolveArena(pointer, state); } void _tryToResolveArena(int pointer, _GestureArena state) { assert(_arenas[pointer] == state); assert(!state.isOpen); if (state.members.length == 1) { scheduleMicrotask(() =\u0026gt; _resolveByDefault(pointer, state)); } else if (state.members.isEmpty) { _arenas.remove(pointer); } else if (state.eagerWinner != null) { _resolveInFavorOf(pointer, state, state.eagerWinner); } } void _resolveByDefault(int pointer, _GestureArena state) { if (!_arenas.containsKey(pointer)) return; // Already resolved earlier.  final List\u0026lt;GestureArenaMember\u0026gt; members = state.members; assert(members.length == 1); _arenas.remove(pointer); state.members.first.acceptGesture(pointer); } void _resolveInFavorOf(int pointer, _GestureArena state, GestureArenaMember member) { _arenas.remove(pointer); for (GestureArenaMember rejectedMember in state.members) { if (rejectedMember != member) rejectedMember.rejectGesture(pointer); } member.acceptGesture(pointer); } gestureArena.sweep /// Forces resolution of the arena, giving the win to the first member.  ///  /// Sweep is typically after all the other processing for a [PointerUpEvent]  /// have taken place. It ensures that multiple passive gestures do not cause a  /// stalemate that prevents the user from interacting with the app.  ///  /// Recognizers that wish to delay resolving an arena past [PointerUpEvent]  /// should call [hold] to delay sweep until [release] is called.  void sweep(int pointer) { final _GestureArena? state = _arenas[pointer]; if (state == null) return; // This arena either never existed or has been resolved.  assert(!state.isOpen); if (state.isHeld) { state.hasPendingSweep = true; assert(_debugLogDiagnostic(pointer, \u0026#39;Delaying sweep\u0026#39;, state)); return; // This arena is being held for a long-lived member.  } _arenas.remove(pointer); if (state.members.isNotEmpty) { // First member wins.  assert(_debugLogDiagnostic(pointer, \u0026#39;Winner: ${state.members.first}\u0026#39;)); state.members.first.acceptGesture(pointer); // Give all the other members the bad news.  for (int i = 1; i \u0026lt; state.members.length; i++) state.members[i].rejectGesture(pointer); } } GestureDetector /// A widget that detects gestures.  /// If this widget has a child, it defers to that child for its sizing behavior. /// If it does not have a child, it grows to fit the parent instead. GestureDetector extends StatelessWidget { /// The widget below this widget in the tree.  final Widget child; GestureDetector({ Key key, this.child, this.onTapDown, this.onTapUp, this.onTap, this.onTapCancel, this.onSecondaryTapDown, this.onSecondaryTapUp, this.onSecondaryTapCancel, this.onDoubleTap, this.onLongPress, this.onLongPressStart, this.onLongPressMoveUpdate, this.onLongPressUp, this.onLongPressEnd, this.onVerticalDragDown, this.onVerticalDragStart, this.onVerticalDragUpdate, this.onVerticalDragEnd, this.onVerticalDragCancel, this.onHorizontalDragDown, this.onHorizontalDragStart, this.onHorizontalDragUpdate, this.onHorizontalDragEnd, this.onHorizontalDragCancel, this.onForcePressStart, this.onForcePressPeak, this.onForcePressUpdate, this.onForcePressEnd, this.onPanDown, this.onPanStart, this.onPanUpdate, this.onPanEnd, this.onPanCancel, this.onScaleStart, this.onScaleUpdate, this.onScaleEnd, this.behavior, this.excludeFromSemantics = false, this.dragStartBehavior = DragStartBehavior.start, }) } @override Widget build(BuildContext context) { final Map\u0026lt;Type, GestureRecognizerFactory\u0026gt; gestures = \u0026lt;Type, GestureRecognizerFactory\u0026gt;{}; if ( onTapDown != null || onTapUp != null || onTap != null || onTapCancel != null || onSecondaryTapDown != null || onSecondaryTapUp != null || onSecondaryTapCancel != null ) { gestures[TapGestureRecognizer] = GestureRecognizerFactoryWithHandlers\u0026lt;TapGestureRecognizer\u0026gt;(//main  () =\u0026gt; TapGestureRecognizer(debugOwner: this), (TapGestureRecognizer instance) { instance ..onTapDown = onTapDown ..onTapUp = onTapUp ..onTap = onTap ..onTapCancel = onTapCancel ..onSecondaryTapDown = onSecondaryTapDown ..onSecondaryTapUp = onSecondaryTapUp ..onSecondaryTapCancel = onSecondaryTapCancel; }, ); } ...... return RawGestureDetector( gestures: gestures, behavior: behavior, excludeFromSemantics: excludeFromSemantics, child: child, ); GestureRecognizerFactoryWithHandlers /// Factory for creating gesture recognizers.  ///  /// `T` is the type of gesture recognizer this class manages.  ///  /// Used by [RawGestureDetector.gestures].  GestureRecognizerFactory\u0026lt;T extends GestureRecognizer\u0026gt; { /// Must return an instance of T.  T constructor(); } /// Factory for creating gesture recognizers that delegates to callbacks. GestureRecognizerFactoryWithHandlers\u0026lt;T extends GestureRecognizer\u0026gt; { /// Signature for closures that implement [GestureRecognizerFactory.constructor].  typedef GestureRecognizerFactoryConstructor\u0026lt;T extends GestureRecognizer\u0026gt; = T Function(); /// Signature for closures that implement [GestureRecognizerFactory.initializer].  typedef GestureRecognizerFactoryInitializer\u0026lt;T extends GestureRecognizer\u0026gt; = void Function(T instance); /// Creates a gesture recognizer factory with the given callbacks.  ///  /// The arguments must not be null.  const GestureRecognizerFactoryWithHandlers(this._constructor, this._initializer) final GestureRecognizerFactoryConstructor\u0026lt;T\u0026gt; _constructor; final GestureRecognizerFactoryInitializer\u0026lt;T\u0026gt; _initializer; @override T constructor() =\u0026gt; _constructor(); @override void initializer(T instance) =\u0026gt; _initializer(instance); } RawGestureDetector /// A widget that detects gestures described by the given gesture\u2028/// factories. RawGestureDetector extends StatefulWidget { /// The gestures that this widget will attempt to recognize.  ///  /// This should be a map from [GestureRecognizer] subclasses to  /// [GestureRecognizerFactory] subclasses specialized with the same type.  final Map\u0026lt;Type, GestureRecognizerFactory\u0026gt; gestures; /// The widget below this widget in the tree.  final Widget child; @override RawGestureDetectorState createState() =\u0026gt; RawGestureDetectorState(); } RawGestureDetectorState RawGestureDetectorState extends State\u0026lt;RawGestureDetector\u0026gt; { @override Widget build(BuildContext context) { Widget result = Listener(//main  onPointerDown: _handlePointerDown, behavior: widget.behavior ?? _defaultBehavior, child: widget.child, ); if (!widget.excludeFromSemantics) result = _GestureSemantics( child: result, assignSemantics: _updateSemanticsForRenderObject, ); return result; } } _handlePointerDown void _handlePointerDown(PointerDownEvent event) { assert(_recognizers != null); for (GestureRecognizer recognizer in _recognizers.values) recognizer.addPointer(event); } Listener /// A widget that calls callbacks in response to common pointer events.  /// Rather than listening for raw pointer events, consider listening for  /// higher-level gestures using [GestureDetector].  /// If it has a child, this widget defers to the child for sizing behavior. If  /// it does not have a child, it grows to fit the parent instead. Listener extends StatelessWidget { const Listener({ Key key, this.onPointerDown, this.onPointerMove, this.onPointerUp, this.onPointerCancel, this.onPointerSignal, this.behavior = HitTestBehavior.deferToChild, Widget child, }) @override Widget build(BuildContext context) { Widget result = _child; result = _PointerListener( onPointerDown: onPointerDown, onPointerUp: onPointerUp, onPointerMove: onPointerMove, onPointerCancel: onPointerCancel, onPointerSignal: onPointerSignal, behavior: behavior, child: result, ); return result; } _PointerListener _PointerListener extends SingleChildRenderObjectWidget { final PointerDownEventListener onPointerDown; final PointerMoveEventListener onPointerMove; final PointerUpEventListener onPointerUp; final PointerCancelEventListener onPointerCancel; final PointerSignalEventListener onPointerSignal; final HitTestBehavior behavior; @override RenderPointerListener createRenderObject(BuildContext context) { return RenderPointerListener( onPointerDown: onPointerDown, onPointerMove: onPointerMove, onPointerUp: onPointerUp, onPointerCancel: onPointerCancel, onPointerSignal: onPointerSignal, behavior: behavior, ); } } RenderPointerListener.handleEvent /// Calls callbacks in response to common pointer events.  /// It responds to events that can construct gestures, such as when the  /// pointer is pressed, moved, then released or canceled. RenderPointerListener extends RenderProxyBoxWithHitTestBehavior { /// Called when a pointer comes into contact with the screen (for touch  /// pointers), or has its button pressed (for mouse pointers) at this widget\u0026#39;s  /// location.  PointerDownEventListener onPointerDown; /// Called when a pointer that triggered an [onPointerDown] changes position.  PointerMoveEventListener onPointerMove; /// Called when a pointer that triggered an [onPointerDown] is no longer in  /// contact with the screen.  PointerUpEventListener onPointerUp; /// Called when the input from a pointer that triggered an [onPointerDown] is  /// no longer directed towards this receiver.  PointerCancelEventListener onPointerCancel; /// Called when a pointer signal occurs over this object.  PointerSignalEventListener onPointerSignal; @override void handleEvent(PointerEvent event, HitTestEntry entry) { assert(debugHandleEvent(event, entry)); if (onPointerDown != null \u0026amp;\u0026amp; event is PointerDownEvent) return onPointerDown(event); if (onPointerMove != null \u0026amp;\u0026amp; event is PointerMoveEvent) return onPointerMove(event); if (onPointerUp != null \u0026amp;\u0026amp; event is PointerUpEvent) return onPointerUp(event); if (onPointerCancel != null \u0026amp;\u0026amp; event is PointerCancelEvent) return onPointerCancel(event); if (onPointerSignal != null \u0026amp;\u0026amp; event is PointerSignalEvent) return onPointerSignal(event); } } _handlepointerdown\nGestureRecognizer addPointer_event /// Registers a new pointer that might be relevant to this gesture detector. void addPointer(PointerDownEvent event) { _pointerToKind[event.pointer] = event.kind; if (isPointerAllowed(event)) { addAllowedPointer(event);//main  } else { handleNonAllowedPointer(event); } } /// Registers a new pointer that\u0026#39;s been checked to be allowed by this gesture recognizer.  ///  /// Subclasses of [GestureRecognizer] are supposed to override this method  /// instead of [addPointer] because [addPointer] will be called for each  /// pointer being added while [addAllowedPointer] is only called for pointers  /// that are allowed by this recognizer.  @protected void addAllowedPointer(PointerDownEvent event) { } PrimaryPointerGestureRecognizer.addAllowedPointer //PrimaryPointerGestureRecognizer  @override void addAllowedPointer(PointerDownEvent event) { startTrackingPointer(event.pointer, event.transform);//main  if (state == GestureRecognizerState.ready) { state = GestureRecognizerState.possible; primaryPointer = event.pointer; initialPosition = OffsetPair(local: event.localPosition, global: event.position); if (deadline != null) _timer = Timer(deadline, () =\u0026gt; didExceedDeadlineWithEvent(event)); } } OneSequenceGestureRecognizer.startTrackingPointer /// Causes events related to the given pointer ID to be routed to this recognizer. @protected void startTrackingPointer(int pointer, [Matrix4 transform]) { //事件传递的最后一站其实就是GestureBinding.handleEvent方法，到最后就是调用pointer.route方法路由事件，所以还要调用GestureRecognizer的handleEvent方法。  GestureBinding.instance.pointerRouter.addRoute(pointer, handleEvent, transform);//main  _trackedPointers.add(pointer); assert(!_entries.containsValue(pointer)); _entries[pointer] = _addPointerToArena(pointer);//main  } /// Called when a pointer event is routed to this recognizer.  @protected void handleEvent(PointerEvent event); pointerRouter.addRoute /// Adds a route to the routing table.  ///  /// Whenever this object routes a [PointerEvent] corresponding to  /// pointer, call route.  ///  /// Routes added reentrantly within [PointerRouter.route] will take effect when  /// routing the next event.  void addRoute(int pointer, PointerRoute route, [Matrix4? transform]) { final Map\u0026lt;PointerRoute, Matrix4?\u0026gt; routes = _routeMap.putIfAbsent( pointer, () =\u0026gt; \u0026lt;PointerRoute, Matrix4?\u0026gt;{}, ); assert(!routes.containsKey(route)); routes[route] = transform; } OneSequenceGestureRecognizer._addPointerToArena GestureArenaEntry _addPointerToArena(int pointer) { if (_team != null) return _team.add(pointer, this); return GestureBinding.instance.gestureArena.add(pointer, this);//main  } GestureArenaManager add /// The first member to accept or the last member to not reject wins. GestureArenaManager { //每组point操作(一次down-\u0026gt;move-\u0026gt;up)对应一个竞技场地_GestureArena，  //每个竞技场地_GestureArena对应多个Recognizer同场竞技  final Map\u0026lt;int, _GestureArena\u0026gt; _arenas = \u0026lt;int, _GestureArena\u0026gt;{}; /// Adds a new member (e.g., gesture recognizer) to the arena.  GestureArenaEntry add(int pointer, GestureArenaMember member) { final _GestureArena state = _arenas.putIfAbsent(pointer, () { return _GestureArena();//main  }); state.add(member); return GestureArenaEntry._(this, pointer, member);//main  } } 参考 HitTestResult /// The result of performing a hit test. /// An unmodifiable list of [HitTestEntry] objects recorded during the hit test.  ///  /// The first entry in the path is the most specific, typically the one at  /// the leaf of tree being hit tested. Event propagation starts with the most  /// specific (i.e., first) entry and proceeds in order through the path.  Iterable\u0026lt;HitTestEntry\u0026gt; get path =\u0026gt; _path; final List\u0026lt;HitTestEntry\u0026gt; _path; add /// Add a [HitTestEntry] to the path.  ///  /// The new entry is added at the end of the path, which means entries should  /// be added in order from most specific to least specific, typically during an  /// upward walk of the tree being hit tested.  void add(HitTestEntry entry) { _path.add(entry); } HitTestEntry /// Data collected during a hit test about a specific [HitTestTarget].  ///  /// Subclass this object to pass additional information from the hit test phase  /// to the event propagation phase.  /// Creates a hit test entry.  HitTestEntry(this.target); /// The [HitTestTarget] encountered during the hit test.  final HitTestTarget target; HitTestTarget /// An object that can handle events. HitTestTarget { /// Override this method to receive events.  void handleEvent(PointerEvent event, HitTestEntry entry); } PointerEvent.pointer abstract class PointerEvent with Diagnosticable { /// Unique identifier for the pointer, not reused. Changes for each new  /// pointer down event.  final int pointer; } https://flutter.dev/docs/development/ui/advanced/gestures\n十三、全面深入触摸和滑动原理· Flutter 完整开发实战详解系列\n事实上并不是所有的控件的 RenderObject 子类都会处理 handleEvent ，大部分时候，只有带有 RenderPointerListener (RenderObject) / Listener (Widget) 的才会处理 handleEvent 事件，并且从上述源码可以看出，handleEvent 的执行是不会被拦截打断的。\nFlutter中的事件流和手势简析\nHitTestResult中的路径顺序一般就是：\n目标节点\u0026ndash;\u0026gt;父节点\u0026ndash;\u0026gt;根节点\u0026ndash;\u0026gt;GestureBinding\n接着PointerDown，PointerMove，PointerUp，PointerCancel等事件分发，都根据这个顺序来遍历调用它们的handleEvent方法\nFlutter触摸事件(1)\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/touch/",
	"title": "touch",
	"tags": [],
	"description": "",
	"content": "touch 探索总结touch知识\n Touch     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/input/toucheventnative/",
	"title": "touchEventNative",
	"tags": [],
	"description": "",
	"content": "原理图 static const char *WAKE_LOCK_ID = \u0026#34;KeyEvents\u0026#34;; static const char *DEVICE_PATH = \u0026#34;/dev/input\u0026#34;; SystemServer startOtherServices private void startOtherServices() { inputManager = new InputManagerService(context); wm = WindowManagerService.main(context, inputManager, mFactoryTestMode != FactoryTest.FACTORY_TEST_LOW_LEVEL, !mFirstBoot, mOnlyCore, new PhoneWindowManager()); ServiceManager.addService(Context.WINDOW_SERVICE, wm, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL | DUMP_FLAG_PROTO); ServiceManager.addService(Context.INPUT_SERVICE, inputManager, /* allowIsolated= */ false, DUMP_FLAG_PRIORITY_CRITICAL); ...... inputManager.setWindowManagerCallbacks(wm.getInputMonitor()); inputManager.start(); } InputManagerService public class InputManagerService extends IInputManager.Stub { public InputManagerService(Context context) { this.mContext = context; this.mHandler = new InputManagerHandler(DisplayThread.get().getLooper()); mPtr = nativeInit(this, mContext, mHandler.getLooper().getQueue()); } } start public void start() { Slog.i(TAG, \u0026#34;Starting input manager\u0026#34;); nativeStart(mPtr); } registerInputChannel public void registerInputChannel(InputChannel inputChannel, InputWindowHandle inputWindowHandle) { nativeRegisterInputChannel(mPtr, inputChannel, inputWindowHandle, false); } frameworks/base/services/core/jni/com_android_server_input_InputManagerService.cpp\ncom_android_server_input_InputManagerService nativeInit static jlong nativeInit(JNIEnv* env, jclass /* clazz */, jobject serviceObj, jobject contextObj, jobject messageQueueObj) { sp\u0026lt;MessageQueue\u0026gt; messageQueue = android_os_MessageQueue_getMessageQueue(env, messageQueueObj); NativeInputManager* im = new NativeInputManager(contextObj, serviceObj, messageQueue-\u0026gt;getLooper()); im-\u0026gt;incStrong(0); return reinterpret_cast\u0026lt;jlong\u0026gt;(im); } nativeStart static void nativeStart(JNIEnv* env, jclass /* clazz */, jlong ptr) { NativeInputManager* im = reinterpret_cast\u0026lt;NativeInputManager*\u0026gt;(ptr); status_t result = im-\u0026gt;getInputManager()-\u0026gt;start(); } nativeRegisterInputChannel static void nativeRegisterInputChannel(JNIEnv* env, jclass /* clazz */, jlong ptr, jobject inputChannelObj, jobject inputWindowHandleObj, jboolean monitor) { NativeInputManager* im = reinterpret_cast\u0026lt;NativeInputManager*\u0026gt;(ptr); status_t status = im-\u0026gt;registerInputChannel( env, inputChannel, inputWindowHandle, monitor); } frameworks/base/services/core/jni/com_android_server_input_InputManagerService.cpp\nNativeInputManager NativeInputManager::NativeInputManager(jobject contextObj, jobject serviceObj, const sp\u0026lt;Looper\u0026gt;\u0026amp; looper) : mLooper(looper), mInteractive(true) { sp\u0026lt;EventHub\u0026gt; eventHub = new EventHub(); mInputManager = new InputManager(eventHub, this, this); } registerInputChannel status_t NativeInputManager::registerInputChannel(JNIEnv* /* env */, const sp\u0026lt;InputChannel\u0026gt;\u0026amp; inputChannel, const sp\u0026lt;InputWindowHandle\u0026gt;\u0026amp; inputWindowHandle, bool monitor) { ATRACE_CALL(); return mInputManager-\u0026gt;getDispatcher()-\u0026gt;registerInputChannel( inputChannel, inputWindowHandle, monitor); } frameworks/native/services/inputflinger/InputManager.cpp\nInputManager InputManager::InputManager( const sp\u0026lt;EventHubInterface\u0026gt;\u0026amp; eventHub, const sp\u0026lt;InputReaderPolicyInterface\u0026gt;\u0026amp; readerPolicy, const sp\u0026lt;InputDispatcherPolicyInterface\u0026gt;\u0026amp; dispatcherPolicy) { mDispatcher = new InputDispatcher(dispatcherPolicy); mReader = new InputReader(eventHub, readerPolicy, mDispatcher); initialize(); } initialize void InputManager::initialize() { mReaderThread = new InputReaderThread(mReader); mDispatcherThread = new InputDispatcherThread(mDispatcher); } start status_t InputManager::start() { status_t result = mDispatcherThread-\u0026gt;run(\u0026#34;InputDispatcher\u0026#34;, PRIORITY_URGENT_DISPLAY); result = mReaderThread-\u0026gt;run(\u0026#34;InputReader\u0026#34;, PRIORITY_URGENT_DISPLAY); return OK; } frameworks/native/services/inputflinger/EventHub.cpp\nEventHub EventHub EventHub::EventHub(void) : { mEpollFd = epoll_create(EPOLL_SIZE_HINT); mINotifyFd = inotify_init(); int result = inotify_add_watch(mINotifyFd, DEVICE_PATH, IN_DELETE | IN_CREATE); struct epoll_event eventItem; memset(\u0026amp;eventItem, 0, sizeof(eventItem)); eventItem.events = EPOLLIN; eventItem.data.u32 = EPOLL_ID_INOTIFY; result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mINotifyFd, \u0026amp;eventItem); int wakeFds[2]; result = pipe(wakeFds); mWakeReadPipeFd = wakeFds[0]; mWakeWritePipeFd = wakeFds[1]; result = fcntl(mWakeReadPipeFd, F_SETFL, O_NONBLOCK); result = fcntl(mWakeWritePipeFd, F_SETFL, O_NONBLOCK); eventItem.data.u32 = EPOLL_ID_WAKE; result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeReadPipeFd, \u0026amp;eventItem); } getEvents size_t EventHub::getEvents(int timeoutMillis, RawEvent* buffer, size_t bufferSize) { for (;;) { // Grab the next input event.  bool deviceChanged = false; while (mPendingEventIndex \u0026lt; mPendingEventCount) { const struct epoll_event\u0026amp; eventItem = mPendingEventItems[mPendingEventIndex++]; if (eventItem.data.u32 == EPOLL_ID_INOTIFY) { if (eventItem.events \u0026amp; EPOLLIN) { mPendingINotify = true; } continue; } ...... if (mPendingINotify \u0026amp;\u0026amp; mPendingEventIndex \u0026gt;= mPendingEventCount) { mPendingINotify = false; readNotifyLocked(); } } int pollResult = epoll_wait(mEpollFd, mPendingEventItems, EPOLL_MAX_EVENTS, timeoutMillis); } readNotifyLocked status_t EventHub::readNotifyLocked() { res = read(mINotifyFd, event_buf, sizeof(event_buf)); } frameworks/native/services/inputflinger/InputReader.cpp\nInputReaderThread threadLoop bool InputReaderThread::threadLoop() { mReader-\u0026gt;loopOnce(); return true; } frameworks/native/services/inputflinger/InputReader.cpp\nInputReader InputReader::InputReader(const sp\u0026lt;EventHubInterface\u0026gt;\u0026amp; eventHub, const sp\u0026lt;InputReaderPolicyInterface\u0026gt;\u0026amp; policy, const sp\u0026lt;InputListenerInterface\u0026gt;\u0026amp; listener) : mContext(this), mEventHub(eventHub), mPolicy(policy), { mQueuedListener = new QueuedInputListener(listener); } threadLoop bool InputReaderThread::threadLoop() { mReader-\u0026gt;loopOnce(); return true; } loopOnce void InputReader::loopOnce() { size_t count = mEventHub-\u0026gt;getEvents(timeoutMillis, mEventBuffer, EVENT_BUFFER_SIZE); if (count) { processEventsLocked(mEventBuffer, count); } // Flush queued events out to the listener.  // This must happen outside of the lock because the listener could potentially call  // back into the InputReader\u0026#39;s methods, such as getScanCodeState, or become blocked  // on another thread similarly waiting to acquire the InputReader lock thereby  // resulting in a deadlock. This situation is actually quite plausible because the  // listener is actually the input dispatcher, which calls into the window manager,  // which occasionally calls into the input reader.  mQueuedListener-\u0026gt;flush(); } getevents\nflush\nframeworks/native/services/inputflinger/InputListener.cpp\nQueuedInputListener flush void QueuedInputListener::flush() { size_t count = mArgsQueue.size(); for (size_t i = 0; i \u0026lt; count; i++) { NotifyArgs* args = mArgsQueue[i]; args-\u0026gt;notify(mInnerListener); delete args; } mArgsQueue.clear(); } NotifyMotionArgs notify void NotifyMotionArgs::notify(const sp\u0026lt;InputListenerInterface\u0026gt;\u0026amp; listener) const { listener-\u0026gt;notifyMotion(this); } notifymotion\nframeworks/native/services/inputflinger/InputDispatcher.cpp\nInputDispatcher threadLoop bool InputDispatcherThread::threadLoop() { mDispatcher-\u0026gt;dispatchOnce(); return true; } dispatchOnce void InputDispatcher::dispatchOnce() { // Run a dispatch loop if there are no pending commands.  // The dispatch loop might enqueue commands to run afterwards.  if (!haveCommandsLocked()) { dispatchOnceInnerLocked(\u0026amp;nextWakeupTime); } // Wait for callback or timeout or wake. (make sure we round up, not down)  nsecs_t currentTime = now(); int timeoutMillis = toMillisecondTimeoutDelay(currentTime, nextWakeupTime); mLooper-\u0026gt;pollOnce(timeoutMillis);//registerInputChannel时通过Looper.wake()唤醒线程 } notifyMotion void InputDispatcher::notifyMotion(const NotifyMotionArgs* args) { if (needWake) { mLooper-\u0026gt;wake(); } } dispatchOnceInnerLocked void InputDispatcher::dispatchOnceInnerLocked(nsecs_t* nextWakeupTime) { case EventEntry::TYPE_MOTION: { MotionEntry* typedEntry = static_cast\u0026lt;MotionEntry*\u0026gt;(mPendingEvent); if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; isAppSwitchDue) { dropReason = DROP_REASON_APP_SWITCH; } if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; isStaleEventLocked(currentTime, typedEntry)) { dropReason = DROP_REASON_STALE; } if (dropReason == DROP_REASON_NOT_DROPPED \u0026amp;\u0026amp; mNextUnblockedEvent) { dropReason = DROP_REASON_BLOCKED; } done = dispatchMotionLocked(currentTime, typedEntry, \u0026amp;dropReason, nextWakeupTime); break; } dispatchMotionLocked bool InputDispatcher::dispatchMotionLocked( nsecs_t currentTime, MotionEntry* entry, DropReason* dropReason, nsecs_t* nextWakeupTime) { dispatchEventLocked(currentTime, entry, inputTargets); return true; } dispatchEventLocked void InputDispatcher::dispatchEventLocked(nsecs_t currentTime, EventEntry* eventEntry, const Vector\u0026lt;InputTarget\u0026gt;\u0026amp; inputTargets) { for (size_t i = 0; i \u0026lt; inputTargets.size(); i++) { const InputTarget\u0026amp; inputTarget = inputTargets.itemAt(i); ssize_t connectionIndex = getConnectionIndexLocked(inputTarget.inputChannel); if (connectionIndex \u0026gt;= 0) { sp\u0026lt;Connection\u0026gt; connection = mConnectionsByFd.valueAt(connectionIndex); prepareDispatchCycleLocked(currentTime, connection, eventEntry, \u0026amp;inputTarget); } } prepareDispatchCycleLocked void InputDispatcher::prepareDispatchCycleLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection, EventEntry* eventEntry, const InputTarget* inputTarget) { enqueueDispatchEntriesLocked(currentTime, connection, splitMotionEntry, inputTarget); } enqueueDispatchEntriesLocked void InputDispatcher::enqueueDispatchEntriesLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection, EventEntry* eventEntry, const InputTarget* inputTarget) { bool wasEmpty = connection-\u0026gt;outboundQueue.isEmpty(); ...... // If the outbound queue was previously empty, start the dispatch cycle going.  if (wasEmpty \u0026amp;\u0026amp; !connection-\u0026gt;outboundQueue.isEmpty()) { startDispatchCycleLocked(currentTime, connection); } } startDispatchCycleLocked void InputDispatcher::startDispatchCycleLocked(nsecs_t currentTime, const sp\u0026lt;Connection\u0026gt;\u0026amp; connection) { EventEntry* eventEntry = dispatchEntry-\u0026gt;eventEntry; switch (eventEntry-\u0026gt;type) { case EventEntry::TYPE_KEY: { KeyEntry* keyEntry = static_cast\u0026lt;KeyEntry*\u0026gt;(eventEntry); // Publish the key event.  status = connection-\u0026gt;inputPublisher.publishKeyEvent(dispatchEntry-\u0026gt;seq, keyEntry-\u0026gt;deviceId, keyEntry-\u0026gt;source, dispatchEntry-\u0026gt;resolvedAction, dispatchEntry-\u0026gt;resolvedFlags, keyEntry-\u0026gt;keyCode, keyEntry-\u0026gt;scanCode, keyEntry-\u0026gt;metaState, keyEntry-\u0026gt;repeatCount, keyEntry-\u0026gt;downTime, keyEntry-\u0026gt;eventTime); break; } case EventEntry::TYPE_MOTION: { // Publish the motion event.  status = connection-\u0026gt;inputPublisher.publishMotionEvent(dispatchEntry-\u0026gt;seq, motionEntry-\u0026gt;deviceId, motionEntry-\u0026gt;source, motionEntry-\u0026gt;displayId, dispatchEntry-\u0026gt;resolvedAction, motionEntry-\u0026gt;actionButton, dispatchEntry-\u0026gt;resolvedFlags, motionEntry-\u0026gt;edgeFlags, motionEntry-\u0026gt;metaState, motionEntry-\u0026gt;buttonState, xOffset, yOffset, motionEntry-\u0026gt;xPrecision, motionEntry-\u0026gt;yPrecision, motionEntry-\u0026gt;downTime, motionEntry-\u0026gt;eventTime, motionEntry-\u0026gt;pointerCount, motionEntry-\u0026gt;pointerProperties, usingCoords); break; } publishmotionevent\nhandleReceiveCallback int InputDispatcher::handleReceiveCallback(int fd, int events, void* data) { InputDispatcher* d = static_cast\u0026lt;InputDispatcher*\u0026gt;(data); ssize_t connectionIndex = d-\u0026gt;mConnectionsByFd.indexOfKey(fd); sp\u0026lt;Connection\u0026gt; connection = d-\u0026gt;mConnectionsByFd.valueAt(connectionIndex); if (!(events \u0026amp; (ALOOPER_EVENT_ERROR | ALOOPER_EVENT_HANGUP))) { if (!(events \u0026amp; ALOOPER_EVENT_INPUT)) {//仅仅对ALOOPER_EVENT_INPUT事件类型进行处理  ALOGW(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received spurious callback for unhandled poll event. \u0026#34; \u0026#34;events=0x%x\u0026#34;, connection-\u0026gt;getInputChannelName().c_str(), events); return 1; } nsecs_t currentTime = now(); bool gotOne = false; status_t status; for (;;) { uint32_t seq; bool handled; status = connection-\u0026gt;inputPublisher.receiveFinishedSignal(\u0026amp;seq, \u0026amp;handled); if (status) { break; } d-\u0026gt;finishDispatchCycleLocked(currentTime, connection, seq, handled); gotOne = true; } if (gotOne) { d-\u0026gt;runCommandsLockedInterruptible(); if (status == WOULD_BLOCK) { return 1; } } }   Input系统—InputReader线程：通过EventHub从/dev/input节点获取事件，转换成EventEntry事件加入到InputDispatcher的mInboundQueue。\n  Input系统—InputDispatcher线程：从mInboundQueue队列取出事件，转换成DispatchEntry事件加入到connection的outboundQueue队列。再然后开始处理分发事件，取出outbound队列，放入waitQueue.\n  Input系统—UI线程\n：创建socket pair，分别位于”InputDispatcher”线程和focused窗口所在进程的UI主线程，可相互通信。\n UI主线程：通过setFdEvents()， 监听socket客户端，收到消息后回调NativeInputEventReceiver();【见小节2.1】 “InputDispatcher”线程： 通过IMS.registerInputChannel()，监听socket服务端，收到消息后回调handleReceiveCallback；【见小节3.1】    前面文章都是介绍了两个线程InputReader和InputDispatcher的工作过程。在InputDispatcher的过程讲到 调用InputChanel通过socket与远程进程通信，本文便展开讲解这个socket是如何建立的。\n对于InputReader和InputDispatcher都是运行在system_server进程； 用户点击的界面往往可能是某一个app，而每个app一般地都运行在自己的进程，这里就涉及到跨进程通信，app进程是如何与system进程建立通信。\nframeworks/native/libs/input/InputTransport.cpp\nInputPublisher publishMotionEvent status_t InputPublisher::publishMotionEvent( uint32_t seq,...... { return mChannel-\u0026gt;sendMessage(\u0026amp;msg); } InputConsumer sendFinishedSignal status_t InputConsumer::sendFinishedSignal(uint32_t seq, bool handled) { return sendUnchainedFinishedSignal(seq, handled); } sendUnchainedFinishedSignal status_t InputConsumer::sendUnchainedFinishedSignal(uint32_t seq, bool handled) { InputMessage msg; msg.header.type = InputMessage::TYPE_FINISHED; msg.body.finished.seq = seq; msg.body.finished.handled = handled; return mChannel-\u0026gt;sendMessage(\u0026amp;msg); } InputChannel(两个Socket实现双向监听) sendMessage status_t InputChannel::sendMessage(const InputMessage* msg) { size_t msgLength = msg-\u0026gt;size(); ssize_t nWrite; do { nWrite = ::send(mFd, msg, msgLength, MSG_DONTWAIT | MSG_NOSIGNAL); } while (nWrite == -1 \u0026amp;\u0026amp; errno == EINTR); Socket/Channel SystemServer进程 [-\u0026gt; WindowManagerService.java]\npublic int addWindow(Session session, IWindow client, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, InputChannel outInputChannel) { inputChannels数组：\n inputChannels[0]所对应的InputChannel名称的后缀为(server); inputChannels[1]所对应的InputChannel名称的后缀为(client)；  其中：\n 服务端inputChannels[0]保存到WindowState的mInputChannel； 客户端inputChannels[1]传递给outInputChannel，最终传递给ViewRootImpl的mInputChannel；  [-\u0026gt; InputTransport.cpp]\nstatus_t InputChannel::openInputChannelPair(const String8\u0026amp; name, sp\u0026lt;InputChannel\u0026gt;\u0026amp; outServerChannel, sp\u0026lt;InputChannel\u0026gt;\u0026amp; outClientChannel) { int sockets[2]; //真正创建socket对的地方【核心】  if (socketpair(AF_UNIX, SOCK_SEQPACKET, 0, sockets)) { ... return result; } int bufferSize = SOCKET_BUFFER_SIZE; //32k  setsockopt(sockets[0], SOL_SOCKET, SO_SNDBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[0], SOL_SOCKET, SO_RCVBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[1], SOL_SOCKET, SO_SNDBUF, \u0026amp;bufferSize, sizeof(bufferSize)); setsockopt(sockets[1], SOL_SOCKET, SO_RCVBUF, \u0026amp;bufferSize, sizeof(bufferSize)); String8 serverChannelName = name; serverChannelName.append(\u0026#34; (server)\u0026#34;); //创建InputChannel对象  outServerChannel = new InputChannel(serverChannelName, sockets[0]); String8 clientChannelName = name; clientChannelName.append(\u0026#34; (client)\u0026#34;); //创建InputChannel对象  outClientChannel = new InputChannel(clientChannelName, sockets[1]); return OK; } 该方法主要功能:\n 创建socket pair; (非阻塞式的socket) 设置两个socket的接收和发送的buffer上限为32KB; 创建client和server的Native层InputChannel对象;  sockets[0]所对应的InputChannel名称的后缀为(server); sockets[1]所对应的InputChannel名称的后缀为(client)    创建InputChannel对象位于文件InputTransport.cpp，如下：\nInputChannel::InputChannel(const String8\u0026amp; name, int fd) : mName(name), mFd(fd) { //将socket设置成非阻塞方式  int result = fcntl(mFd, F_SETFL, O_NONBLOCK); } frameworks/native/services/inputflinger/InputDispatcher.cpp\nregisterInputChannel status_t InputDispatcher::registerInputChannel(const sp\u0026lt;InputChannel\u0026gt;\u0026amp; inputChannel, const sp\u0026lt;InputWindowHandle\u0026gt;\u0026amp; inputWindowHandle, bool monitor) { { AutoMutex _l(mLock); ... //创建Connection[见小节2.8.4]  sp\u0026lt;Connection\u0026gt; connection = new Connection(inputChannel, inputWindowHandle, monitor); int fd = inputChannel-\u0026gt;getFd();//fd为socket fd  mConnectionsByFd.add(fd, connection); ... //将该fd添加到Looper监听[见小节2.8.5]  mLooper-\u0026gt;addFd(fd, 0, ALOOPER_EVENT_INPUT, handleReceiveCallback, this); } mLooper-\u0026gt;wake(); //connection改变, 则唤醒looper  return OK; } 将新创建的connection保存到mConnectionsByFd成员变量，“InputDispatcher”线程的Looper添加对socket服务端的监听功能； 当该socket有消息时便会唤醒该线程工作。\nViewRootImpl的setView()过程:\n 创建socket pair，作为InputChannel:  socket服务端保存到system_server中的WindowState的mInputChannel； socket客户端通过binder传回到远程进程的UI主线程ViewRootImpl的mInputChannel；   IMS.registerInputChannel()注册InputChannel，监听socket服务端：  Loop便是“InputDispatcher”线程的Looper; 回调方法handleReceiveCallback。    Socket/Channel app进程 [-\u0026gt; android_view_InputEventReceiver.cpp]\nvoid NativeInputEventReceiver::setFdEvents(int events) { if (mFdEvents != events) { mFdEvents = events; int fd = mInputConsumer.getChannel()-\u0026gt;getFd();//channel提供fd  if (events) { //将socket客户端的fd添加到主线程的消息池【见小节3.6.1】  mMessageQueue-\u0026gt;getLooper()-\u0026gt;addFd(fd, 0, events, this, NULL);//fd可读时触发本类的handleEvent回调  } else { mMessageQueue-\u0026gt;getLooper()-\u0026gt;removeFd(fd); } } } 此处的Looper便是UI主线程的Looper，将socket客户端的fd添加到UI线程的Looper来监听，回调方法为NativeInputEventReceiver。\n首先，通过openInputChannelPair来创建socket pair，作为InputChannel:\n socket服务端保存到system_server中的WindowState的mInputChannel； socket客户端通过binder传回到远程进程的UI主线程ViewRootImpl的mInputChannel(inputChannel是binder调用的out参数)；  紧接着，完成了两个线程的epoll监听工作：\n [小节2.8]IMS.registerInputChannel(): “InputDispatcher”线程监听socket服务端，收到消息后回调InputDispatcher.handleReceiveCallback()； [小节3.6]setFdEvents(): UI主线程监听socket客户端，收到消息后回调NativeInputEventReceiver.handleEvent().  system/core/libutils/Looper.cpp\nLooper.cpp pollInner int Looper::pollInner(int timeoutMillis) { // Invoke all response callbacks.  for (size_t i = 0; i \u0026lt; mResponses.size(); i++) { // Invoke the callback. Note that the file descriptor may be closed by  // the callback (and potentially even reused) before the function returns so  // we need to be a little careful when removing the file descriptor afterwards.  int callbackResult = response.request.callback-\u0026gt;handleEvent(fd, events, data); } } frameworks/base/core/jni/android_view_InputEventReceiver.cpp\nNativeInputEventReceiver handleEvent int NativeInputEventReceiver::handleEvent(int receiveFd, int events, void* data) { if (events \u0026amp; ALOOPER_EVENT_INPUT) { JNIEnv* env = AndroidRuntime::getJNIEnv(); status_t status = consumeEvents(env, false /*consumeBatches*/, -1, NULL); mMessageQueue-\u0026gt;raiseAndClearException(env, \u0026#34;handleReceiveCallback\u0026#34;); return status == OK || status == NO_MEMORY ? 1 : 0; } } consumeEvents status_t NativeInputEventReceiver::consumeEvents(JNIEnv* env, bool consumeBatches, nsecs_t frameTime, bool* outConsumedBatch) { for (;;) { uint32_t seq; InputEvent* inputEvent; int32_t displayId; status_t status = mInputConsumer.consume(\u0026amp;mInputEventFactory, consumeBatches, frameTime, \u0026amp;seq, \u0026amp;inputEvent, \u0026amp;displayId); jobject inputEventObj; switch (inputEvent-\u0026gt;getType()) { case AINPUT_EVENT_TYPE_KEY: if (kDebugDispatchCycle) { ALOGD(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received key event.\u0026#34;, getInputChannelName().c_str()); } inputEventObj = android_view_KeyEvent_fromNative(env, static_cast\u0026lt;KeyEvent*\u0026gt;(inputEvent)); break; case AINPUT_EVENT_TYPE_MOTION: { if (kDebugDispatchCycle) { ALOGD(\u0026#34;channel \u0026#39;%s\u0026#39; ~ Received motion event.\u0026#34;, getInputChannelName().c_str()); } MotionEvent* motionEvent = static_cast\u0026lt;MotionEvent*\u0026gt;(inputEvent); if ((motionEvent-\u0026gt;getAction() \u0026amp; AMOTION_EVENT_ACTION_MOVE) \u0026amp;\u0026amp; outConsumedBatch) { *outConsumedBatch = true; } inputEventObj = android_view_MotionEvent_obtainAsCopy(env, motionEvent); break; } default: assert(false); // InputConsumer should prevent this from ever happening  inputEventObj = NULL; } if (inputEventObj) { env-\u0026gt;CallVoidMethod(receiverObj.get(), gInputEventReceiverClassInfo.dispatchInputEvent, seq, inputEventObj, displayId); } InputEventReceiver dispatchInputEvent // Called from native code.  @SuppressWarnings(\u0026#34;unused\u0026#34;) private void dispatchInputEvent(int seq, InputEvent event, int displayId) { mSeqMap.put(event.getSequenceNumber(), seq); onInputEvent(event, displayId); } finishInputEvent public final void finishInputEvent(InputEvent event, boolean handled) { nativeFinishInputEvent(mReceiverPtr, seq, handled); } frameworks/base/core/jni/android_view_InputEventReceiver.cpp\nandroid_view_InputEventReceiver nativeFinishInputEvent static void nativeFinishInputEvent(JNIEnv* env, jclass clazz, jlong receiverPtr, jint seq, jboolean handled) { sp\u0026lt;NativeInputEventReceiver\u0026gt; receiver = reinterpret_cast\u0026lt;NativeInputEventReceiver*\u0026gt;(receiverPtr); status_t status = receiver-\u0026gt;finishInputEvent(seq, handled); } finishInputEvent status_t NativeInputEventReceiver::finishInputEvent(uint32_t seq, bool handled) { status_t status = mInputConsumer.sendFinishedSignal(seq, handled); } sendfinishedsignal\n参考 \u0026laquo;深入理解Android : 卷3 第五章 输入系统\u0026raquo;\nInput系统—事件处理全过程\nInput系统—ANR原理分析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/ffmpeg/examples/transcodingsource/",
	"title": "TranscodingSource",
	"tags": [],
	"description": "",
	"content": "https://www.ffmpeg.org/ffmpeg.html\nTranscoding Detailed description The transcoding process in ffmpeg for each output can be described by the following diagram:\n _______ ______________ | | | | | input | demuxer | encoded data | decoder | file | ---------\u0026gt; | packets | -----+ |_______| |______________| | av_read_frame AVPacket v ---------\u0026gt; _________ | | | decoded |AVFrame | frames | |_________| ________ ______________ | | | | | |fliter | output | \u0026lt;-------- | encoded data | \u0026lt;----+ | file | muxer | packets | encoder |________| |______________| AVPacket ffmpeg calls the libavformat library (containing demuxers) to read input files and get packets containing encoded data from them. When there are multiple input files, ffmpeg tries to keep them synchronized by tracking lowest timestamp on any active input stream.\nEncoded packets are then passed to the decoder (unless streamcopy is selected for the stream, see further for a description). The decoder produces uncompressed frames (raw video/PCM audio/\u0026hellip;) which can be processed further by filtering (see next section). After filtering, the frames are passed to the encoder, which encodes them and outputs encoded packets. Finally those are passed to the muxer, which writes the encoded packets to the output file.\nFiltering Before encoding, ffmpeg can process raw audio and video frames using filters from the libavfilter library. Several chained filters form a filter graph. ffmpeg distinguishes between two types of filtergraphs: simple and complex.\nSimple filtergraphs Simple filtergraphs are those that have exactly one input and output, both of the same type. In the above diagram they can be represented by simply inserting an additional step between decoding and encoding:\n _________ ______________ | | | | | decoded | | encoded data | | frames |\\ _ | packets | |_________| \\ /||______________| \\ __________ / simple _\\|| | / encoder filtergraph | filtered |/ | frames | |__________| Complex filtergraphs Complex filtergraphs are those which cannot be described as simply a linear processing chain applied to one stream. This is the case, for example, when the graph has more than one input and/or output, or when output stream type is different from input. They can be represented with the following diagram:\n _________ | | | input 0 |\\ __________ |_________| \\ | | \\ _________ /| output 0 | \\ | | / |__________| _________ \\| complex | / | | | |/ | input 1 |----\u0026gt;| filter |\\ |_________| | | \\ __________ /| graph | \\ | | / | | \\| output 1 | _________ / |_________| |__________| | | / | input 2 |/ |_________| Context图解 graph LR AVFormatContext--\u0026gt;AVCodecContext--\u0026gt;AVFilterContext static Filed static AVFormatContext *ifmt_ctx;//DEMUX,比如把输入的input.mp4拆分为audio和video的ES数据 static AVFormatContext *ofmt_ctx;//MUX，比如把编码好的audio/video ES数据打包成output.ts  typedef struct FilteringContext { AVFilterContext *buffersink_ctx; AVFilterContext *buffersrc_ctx; AVFilterGraph *filter_graph; AVPacket *enc_pkt; AVFrame *filtered_frame; } FilteringContext; static FilteringContext *filter_ctx; typedef struct StreamContext { AVCodecContext *dec_ctx; AVCodecContext *enc_ctx; AVFrame *dec_frame; } StreamContext; static StreamContext *stream_ctx; main int main(int argc, char **argv) { int ret; AVPacket *packet = NULL; unsigned int stream_index; unsigned int i; if (argc != 3) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Usage: %s \u0026lt;input file\u0026gt; \u0026lt;output file\u0026gt;\\n\u0026#34;, argv[0]); return 1; } if ((ret = open_input_file(argv[1])) \u0026lt; 0) goto end; if ((ret = open_output_file(argv[2])) \u0026lt; 0) goto end; if ((ret = init_filters()) \u0026lt; 0) goto end; if (!(packet = av_packet_alloc())) goto end; /* read all packets */ while (1) { if ((ret = av_read_frame(ifmt_ctx, packet)) \u0026lt; 0) break; stream_index = packet-\u0026gt;stream_index; av_log(NULL, AV_LOG_DEBUG, \u0026#34;Demuxer gave frame of stream_index %u\\n\u0026#34;, stream_index); if (filter_ctx[stream_index].filter_graph) { StreamContext *stream = \u0026amp;stream_ctx[stream_index]; av_log(NULL, AV_LOG_DEBUG, \u0026#34;Going to reencode\u0026amp;filter the frame\\n\u0026#34;); av_packet_rescale_ts(packet, ifmt_ctx-\u0026gt;streams[stream_index]-\u0026gt;time_base, stream-\u0026gt;dec_ctx-\u0026gt;time_base); ret = avcodec_send_packet(stream-\u0026gt;dec_ctx, packet); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Decoding failed\\n\u0026#34;); break; } while (ret \u0026gt;= 0) { ret = avcodec_receive_frame(stream-\u0026gt;dec_ctx, stream-\u0026gt;dec_frame); if (ret == AVERROR_EOF || ret == AVERROR(EAGAIN)) break; else if (ret \u0026lt; 0) goto end; stream-\u0026gt;dec_frame-\u0026gt;pts = stream-\u0026gt;dec_frame-\u0026gt;best_effort_timestamp; ret = filter_encode_write_frame(stream-\u0026gt;dec_frame, stream_index); if (ret \u0026lt; 0) goto end; } } else { /* remux this frame without reencoding */ av_packet_rescale_ts(packet, ifmt_ctx-\u0026gt;streams[stream_index]-\u0026gt;time_base, ofmt_ctx-\u0026gt;streams[stream_index]-\u0026gt;time_base); ret = av_interleaved_write_frame(ofmt_ctx, packet); if (ret \u0026lt; 0) goto end; } av_packet_unref(packet); } /* flush filters and encoders */ for (i = 0; i \u0026lt; ifmt_ctx-\u0026gt;nb_streams; i++) { /* flush filter */ if (!filter_ctx[i].filter_graph) continue; ret = filter_encode_write_frame(NULL, i); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Flushing filter failed\\n\u0026#34;); goto end; } /* flush encoder */ ret = flush_encoder(i); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Flushing encoder failed\\n\u0026#34;); goto end; } } av_write_trailer(ofmt_ctx); end: av_packet_free(\u0026amp;packet); for (i = 0; i \u0026lt; ifmt_ctx-\u0026gt;nb_streams; i++) { avcodec_free_context(\u0026amp;stream_ctx[i].dec_ctx); if (ofmt_ctx \u0026amp;\u0026amp; ofmt_ctx-\u0026gt;nb_streams \u0026gt; i \u0026amp;\u0026amp; ofmt_ctx-\u0026gt;streams[i] \u0026amp;\u0026amp; stream_ctx[i].enc_ctx) avcodec_free_context(\u0026amp;stream_ctx[i].enc_ctx); if (filter_ctx \u0026amp;\u0026amp; filter_ctx[i].filter_graph) { avfilter_graph_free(\u0026amp;filter_ctx[i].filter_graph); av_packet_free(\u0026amp;filter_ctx[i].enc_pkt); av_frame_free(\u0026amp;filter_ctx[i].filtered_frame); } av_frame_free(\u0026amp;stream_ctx[i].dec_frame); } av_free(filter_ctx); av_free(stream_ctx); avformat_close_input(\u0026amp;ifmt_ctx); if (ofmt_ctx \u0026amp;\u0026amp; !(ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) avio_closep(\u0026amp;ofmt_ctx-\u0026gt;pb); avformat_free_context(ofmt_ctx); if (ret \u0026lt; 0) av_log(NULL, AV_LOG_ERROR, \u0026#34;Error occurred: %s\\n\u0026#34;, av_err2str(ret)); return ret ? 1 : 0; } open_input_file http://lazybing.github.io/blog/2017/01/01/ffmpeg-sdk-learning/ \u0026ndash;FFMpeg 解封装实现\n//打开并解析要转码的源文件(如input.mp4)，并分配相应的decoder //比如，源文件是input.mp4(H264+AAC),那么就有2个stream，分配2个decoder，H264 decoder \u0026amp; AAC decoder static int open_input_file(const char *filename) { int ret; unsigned int i; ifmt_ctx = NULL; //open input file, and allocate format context  if ((ret = avformat_open_input(\u0026amp;ifmt_ctx, filename, NULL, NULL)) \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Cannot open input file\\n\u0026#34;); return ret; } //retrive stream information  if ((ret = avformat_find_stream_info(ifmt_ctx, NULL)) \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Cannot find stream information\\n\u0026#34;); return ret; } stream_ctx = av_mallocz_array(ifmt_ctx-\u0026gt;nb_streams, sizeof(*stream_ctx)); if (!stream_ctx) return AVERROR(ENOMEM); for (i = 0; i \u0026lt; ifmt_ctx-\u0026gt;nb_streams; i++) { AVStream *stream = ifmt_ctx-\u0026gt;streams[i]; //Find the AVCodec Depending on the CODEC_ID  const AVCodec *dec = avcodec_find_decoder(stream-\u0026gt;codecpar-\u0026gt;codec_id); AVCodecContext *codec_ctx; if (!dec) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Failed to find decoder for stream #%u\\n\u0026#34;, i); return AVERROR_DECODER_NOT_FOUND; } //Allocate the AVCodecContext  codec_ctx = avcodec_alloc_context3(dec); if (!codec_ctx) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Failed to allocate the decoder context for stream #%u\\n\u0026#34;, i); return AVERROR(ENOMEM); } ret = avcodec_parameters_to_context(codec_ctx, stream-\u0026gt;codecpar); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Failed to copy decoder parameters to input decoder context \u0026#34; \u0026#34;for stream #%u\\n\u0026#34;, i); return ret; } /* Reencode video \u0026amp; audio and remux subtitles etc. */ if (codec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO || codec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_AUDIO) { if (codec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) codec_ctx-\u0026gt;framerate = av_guess_frame_rate(ifmt_ctx, stream, NULL); /* Open decoder */ ret = avcodec_open2(codec_ctx, dec, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Failed to open decoder for stream #%u\\n\u0026#34;, i); return ret; } } stream_ctx[i].dec_ctx = codec_ctx; //Allocate AVFrame to Store the Decode Data  stream_ctx[i].dec_frame = av_frame_alloc(); if (!stream_ctx[i].dec_frame) return AVERROR(ENOMEM); } //输出format日志信息  av_dump_format(ifmt_ctx, 0, filename, 0); return 0; } avformat_open_input\u0026ndash;分配AVFormatContext结构 对于给定的需要 AV 分离的输入文件，使用avformat_open_input打开输入文件，并分配AVFormatContext结构\n//ps:指向由用户提供的AVFormatContext结构体，该结构体通过avformat_alloc_context分配，如果它是一个 NULL，该结构在此函数内分配并负值给 ps。 //filename:指向需要打开的流的名称。 //fmt：如果是 non-NULL,该参数指定输入的文件格式，否则输入文件的格式自动根据文件本身自动获取。 //options:此处可以为 NULL。 //返回值：成功返回0，否则返回 AVERROR。 int avformat_open_input(AVFormatContext **ps, const char *filename, const AVInputFormat *fmt, AVDictionary **options) { avformat_find_stream_info int avformat_find_stream_info(AVFormatContext *ic, AVDictionary **options) { avcodec_find_decoder //该函数参数为AVCodecID指定了请求的解码器，成功返回解码器，否则返回 NULL。 const AVCodec *avcodec_find_decoder(enum AVCodecID id) { return find_codec(id, av_codec_is_decoder); } int av_codec_is_decoder(const AVCodec *codec) { return codec \u0026amp;\u0026amp; (codec-\u0026gt;decode || codec-\u0026gt;receive_frame); } static const AVCodec *find_codec(enum AVCodecID id, int (*x)(const AVCodec *)) { const AVCodec *p, *experimental = NULL; void *i = 0; id = remap_deprecated_codec_id(id); while ((p = av_codec_iterate(\u0026amp;i))) { if (!x(p)) continue; if (p-\u0026gt;id == id) { if (p-\u0026gt;capabilities \u0026amp; AV_CODEC_CAP_EXPERIMENTAL \u0026amp;\u0026amp; !experimental) { experimental = p; } else return p; } } return experimental; } const AVCodec *av_codec_iterate(void **opaque) { uintptr_t i = (uintptr_t)*opaque; const AVCodec *c = codec_list[i]; ff_thread_once(\u0026amp;av_codec_static_init, av_codec_init_static); if (c) *opaque = (void*)(i + 1); return c; } avcodec_open2(OpenDecoder) //Open the Decoder //该函数的主要作用是根据给定的AVCodec初始化AVCodecContext,在使用该函数之前，待初始化的AVCodecContext结构需要先使用avcodec_alloc_context3分配好。其中的参数 AVCodec可以通过avcodec_find_decoder_by_nameavcodec_find_encoder_by_nameavcodec_find_decoder或avcodec_find_endcoder来获取。在进行真正的解码之前，必须调用该函数。  //avctx:即将初始化的AVCodecContext结构体。 //codec：打开的解码器，如果它是non-NULL codec,并在之前传递给了avcodec_alloc_context3或avcodec_get_context_defaults3，该参数必须为 NULL 或之前传递的 CODEC。 //Options：此处我们设置为 NULL。 //返回值：成功返回0，出错返回一个负值。 int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options) { open_output_file \u0026ndash;FFMpeg 封装实现\n//打开输出文件,分配相应的encoder static int open_output_file(const char *filename) { AVStream *out_stream; AVStream *in_stream; AVCodecContext *dec_ctx, *enc_ctx; const AVCodec *encoder; int ret; unsigned int i; ofmt_ctx = NULL; avformat_alloc_output_context2(\u0026amp;ofmt_ctx, NULL, NULL, filename); if (!ofmt_ctx) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not create output context\\n\u0026#34;); return AVERROR_UNKNOWN; } for (i = 0; i \u0026lt; ifmt_ctx-\u0026gt;nb_streams; i++) { out_stream = avformat_new_stream(ofmt_ctx, NULL); if (!out_stream) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Failed allocating output stream\\n\u0026#34;); return AVERROR_UNKNOWN; } in_stream = ifmt_ctx-\u0026gt;streams[i]; dec_ctx = stream_ctx[i].dec_ctx; if (dec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO || dec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_AUDIO) { /* in this example, we choose transcoding to same codec */ encoder = avcodec_find_encoder(dec_ctx-\u0026gt;codec_id); if (!encoder) { av_log(NULL, AV_LOG_FATAL, \u0026#34;Necessary encoder not found\\n\u0026#34;); return AVERROR_INVALIDDATA; } enc_ctx = avcodec_alloc_context3(encoder); if (!enc_ctx) { av_log(NULL, AV_LOG_FATAL, \u0026#34;Failed to allocate the encoder context\\n\u0026#34;); return AVERROR(ENOMEM); } /* In this example, we transcode to same properties (picture size, * sample rate etc.). These properties can be changed for output * streams easily using filters */ if (dec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { enc_ctx-\u0026gt;height = dec_ctx-\u0026gt;height; enc_ctx-\u0026gt;width = dec_ctx-\u0026gt;width; enc_ctx-\u0026gt;sample_aspect_ratio = dec_ctx-\u0026gt;sample_aspect_ratio; /* take first format from list of supported formats */ if (encoder-\u0026gt;pix_fmts) enc_ctx-\u0026gt;pix_fmt = encoder-\u0026gt;pix_fmts[0]; else enc_ctx-\u0026gt;pix_fmt = dec_ctx-\u0026gt;pix_fmt; /* video time_base can be set to whatever is handy and supported by encoder */ enc_ctx-\u0026gt;time_base = av_inv_q(dec_ctx-\u0026gt;framerate); } else { enc_ctx-\u0026gt;sample_rate = dec_ctx-\u0026gt;sample_rate; enc_ctx-\u0026gt;channel_layout = dec_ctx-\u0026gt;channel_layout; enc_ctx-\u0026gt;channels = av_get_channel_layout_nb_channels(enc_ctx-\u0026gt;channel_layout); /* take first format from list of supported formats */ enc_ctx-\u0026gt;sample_fmt = encoder-\u0026gt;sample_fmts[0]; enc_ctx-\u0026gt;time_base = (AVRational){1, enc_ctx-\u0026gt;sample_rate}; } if (ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_GLOBALHEADER) enc_ctx-\u0026gt;flags |= AV_CODEC_FLAG_GLOBAL_HEADER; /* Third parameter can be used to pass settings to encoder */ ret = avcodec_open2(enc_ctx, encoder, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Cannot open video encoder for stream #%u\\n\u0026#34;, i); return ret; } ret = avcodec_parameters_from_context(out_stream-\u0026gt;codecpar, enc_ctx); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Failed to copy encoder parameters to output stream #%u\\n\u0026#34;, i); return ret; } out_stream-\u0026gt;time_base = enc_ctx-\u0026gt;time_base; stream_ctx[i].enc_ctx = enc_ctx; } } av_dump_format(ofmt_ctx, 0, filename, 1); if (!(ofmt_ctx-\u0026gt;oformat-\u0026gt;flags \u0026amp; AVFMT_NOFILE)) { ret = avio_open(\u0026amp;ofmt_ctx-\u0026gt;pb, filename, AVIO_FLAG_WRITE); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Could not open output file \u0026#39;%s\u0026#39;\u0026#34;, filename); return ret; } } /* init muxer, write output file header */ ret = avformat_write_header(ofmt_ctx, NULL); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Error occurred when opening output file\\n\u0026#34;); return ret; } return 0; avformat_new_stream 该函数完成向 AVFormatContext 结构体中所代表的媒体文件中添加数据流\n//s:AVFormatContext 结构，表示要封装生成的视频文件。 //c：视频或音频流的编码器的指针。 //返回值：指向生成的 stream 对象的指针；失败则返回 NULL AVStream *avformat_new_stream(AVFormatContext *s, const AVCodec *c) { avcodec_find_encoder const AVCodec *avcodec_find_encoder(enum AVCodecID id) { return find_codec(id, av_codec_is_encoder); } avcodec_open2(openEncoder) avio_open int avio_open(AVIOContext **s, const char *filename, int flags) { return avio_open2(s, filename, flags, NULL, NULL); } avformat_write_header int avformat_write_header(AVFormatContext *s, AVDictionary **options) { init_filters static int init_filters(void) { const char *filter_spec; unsigned int i; int ret; filter_ctx = av_malloc_array(ifmt_ctx-\u0026gt;nb_streams, sizeof(*filter_ctx)); if (!filter_ctx) return AVERROR(ENOMEM); for (i = 0; i \u0026lt; ifmt_ctx-\u0026gt;nb_streams; i++) { filter_ctx[i].buffersrc_ctx = NULL; filter_ctx[i].buffersink_ctx = NULL; filter_ctx[i].filter_graph = NULL; if (!(ifmt_ctx-\u0026gt;streams[i]-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_AUDIO || ifmt_ctx-\u0026gt;streams[i]-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO)) continue; if (ifmt_ctx-\u0026gt;streams[i]-\u0026gt;codecpar-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) filter_spec = \u0026#34;null\u0026#34;; /* passthrough (dummy) filter for video */ else filter_spec = \u0026#34;anull\u0026#34;; /* passthrough (dummy) filter for audio */ ret = init_filter(\u0026amp;filter_ctx[i], stream_ctx[i].dec_ctx, stream_ctx[i].enc_ctx, filter_spec); if (ret) return ret; filter_ctx[i].enc_pkt = av_packet_alloc(); if (!filter_ctx[i].enc_pkt) return AVERROR(ENOMEM); filter_ctx[i].filtered_frame = av_frame_alloc(); if (!filter_ctx[i].filtered_frame) return AVERROR(ENOMEM); } return 0; } static int init_filter(FilteringContext* fctx, AVCodecContext *dec_ctx, AVCodecContext *enc_ctx, const char *filter_spec) { char args[512]; int ret = 0; const AVFilter *buffersrc = NULL; const AVFilter *buffersink = NULL; AVFilterContext *buffersrc_ctx = NULL; AVFilterContext *buffersink_ctx = NULL; AVFilterInOut *outputs = avfilter_inout_alloc(); AVFilterInOut *inputs = avfilter_inout_alloc(); AVFilterGraph *filter_graph = avfilter_graph_alloc(); if (!outputs || !inputs || !filter_graph) { ret = AVERROR(ENOMEM); goto end; } if (dec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_VIDEO) { buffersrc = avfilter_get_by_name(\u0026#34;buffer\u0026#34;); buffersink = avfilter_get_by_name(\u0026#34;buffersink\u0026#34;); if (!buffersrc || !buffersink) { av_log(NULL, AV_LOG_ERROR, \u0026#34;filtering source or sink element not found\\n\u0026#34;); ret = AVERROR_UNKNOWN; goto end; } ret = avfilter_graph_create_filter(\u0026amp;buffersrc_ctx, buffersrc, \u0026#34;in\u0026#34;, args, NULL, filter_graph); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Cannot create buffer source\\n\u0026#34;); goto end; } ret = avfilter_graph_create_filter(\u0026amp;buffersink_ctx, buffersink, \u0026#34;out\u0026#34;, NULL, NULL, filter_graph); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Cannot create buffer sink\\n\u0026#34;); goto end; } ret = av_opt_set_bin(buffersink_ctx, \u0026#34;pix_fmts\u0026#34;, (uint8_t*)\u0026amp;enc_ctx-\u0026gt;pix_fmt, sizeof(enc_ctx-\u0026gt;pix_fmt), AV_OPT_SEARCH_CHILDREN); if (ret \u0026lt; 0) { av_log(NULL, AV_LOG_ERROR, \u0026#34;Cannot set output pixel format\\n\u0026#34;); goto end; } } else if (dec_ctx-\u0026gt;codec_type == AVMEDIA_TYPE_AUDIO) { ...... } ...... if ((ret = avfilter_graph_parse_ptr(filter_graph, filter_spec, \u0026amp;inputs, \u0026amp;outputs, NULL)) \u0026lt; 0) goto end; if ((ret = avfilter_graph_config(filter_graph, NULL)) \u0026lt; 0) goto end; /* Fill FilteringContext */ fctx-\u0026gt;buffersrc_ctx = buffersrc_ctx; fctx-\u0026gt;buffersink_ctx = buffersink_ctx; fctx-\u0026gt;filter_graph = filter_graph; end: avfilter_inout_free(\u0026amp;inputs); avfilter_inout_free(\u0026amp;outputs); return ret; avfilter_get_by_name avfilter_graph_create_filter avfilter_graph_parse_ptr avfilter_graph_config av_packet_alloc av_frame_alloc Demux av_packet_alloc av_read_frame /** * Return the next frame of a stream. * This function returns what is stored in the file, and does not validate * that what is there are valid frames for the decoder. It will split what is * stored in the file into frames and return one for each call. It will not * omit invalid data between valid frames so as to give the decoder the maximum * information possible for decoding. */ int av_read_frame(AVFormatContext *s, AVPacket *pkt) { Decode avcodec_send_packet //Supply raw packet data as input to a decoder. int avcodec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt); avcodec_receive_frame //Return decoded output data from a decoder. int avcodec_receive_frame(AVCodecContext *avctx, AVFrame *frame); Filter av_buffersrc_add_frame_flags /* push the decoded frame into the filtergraph */ //Add a frame to the buffer source. int av_buffersrc_add_frame_flags(AVFilterContext *buffer_src, AVFrame *frame, int flags); av_buffersink_get_frame /* pull filtered frames from the filtergraph */ // Get a frame with filtered data from sink and put it in frame. int av_buffersink_get_frame(AVFilterContext *ctx, AVFrame *frame); Encode avcodec_send_frame /** Supply a raw video or audio frame to the encoder. Use avcodec_receive_packet() * to retrieve buffered output packets. */ int avcodec_send_frame(AVCodecContext *avctx, const AVFrame *frame); avcodec_receive_packet //Read encoded data from the encoder. int avcodec_receive_packet(AVCodecContext *avctx, AVPacket *avpkt); mux av_interleaved_write_frame /* mux encoded frame */ //Write a packet to an output media file ensuring correct interleaving. int av_interleaved_write_frame(AVFormatContext *s, AVPacket *pkt); av_write_trailer /** * Write the stream trailer to an output media file and free the * file private data. */ int av_write_trailer(AVFormatContext *s); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/gradlejenkins/transform/",
	"title": "Transform",
	"tags": [],
	"description": "",
	"content": "注册Transform 1. //com.android.build.gradle.internal.dsl.BaseAppModuleExtension_Decorated实例 def android = project.extensions.getByType(AppExtension) 或 AppPlugin appPlugin = getProject().getPlugins().getPlugin(AppPlugin.class) //com.android.build.gradle.internal.dsl.BaseAppModuleExtension_Decorated实例 def android = appPlugin.getExtension() 2. android.registerTransform(new MyClassTransform(project));  Transform执行时机 图解 graph LR registerTransform--\u0026gt;addTransform(\u0026quot;BaseExtension.transforms.add(transform);\u0026quot;)--\u0026gt;|TaskManager.createPostCompilationTasks|transformManager.addTransform--\u0026gt;TransformTask.transform public abstract class BaseExtension implements AndroidConfig { public void registerTransform(@NonNull Transform transform, Object... dependencies) { transforms.add(transform); transformDependencies.add(Arrays.asList(dependencies)); } @Override @NonNull public List\u0026lt;Transform\u0026gt; getTransforms() { return ImmutableList.copyOf(transforms); } public abstract class TaskManager { public void createPostCompilationTasks( @NonNull final VariantScope variantScope) { // ----- External Transforms -----  // apply all the external transforms.  List\u0026lt;Transform\u0026gt; customTransforms = extension.getTransforms(); List\u0026lt;List\u0026lt;Object\u0026gt;\u0026gt; customTransformsDependencies = extension.getTransformsDependencies(); for (int i = 0, count = customTransforms.size(); i \u0026lt; count; i++) { Transform transform = customTransforms.get(i); List\u0026lt;Object\u0026gt; deps = customTransformsDependencies.get(i); transformManager.addTransform( public abstract class TransformTask extends StreamBasedTask { @TaskAction void transform(final IncrementalTaskInputs incrementalTaskInputs) throws IOException, TransformException, InterruptedException { transform.transform( new TransformInvocationBuilder(context) .addInputs(consumedInputs.getValue()) .... .build()); 总结 注册之后自定义transform类被包裹在多个对应的transformTask(每个构建变体一个)中，其transform对象为该自定义transform类实例(每个构建变体内部都是同一个实例)\n//TransformTask @TaskAction void transform(final IncrementalTaskInputs incrementalTaskInputs) throws IOException, TransformException, InterruptedException { 对于每个assemble执行的构建变体，都会走一次自定义transform的transform方法，其中的outputProvider路径有区分:\nbuild\\intermediates\\transforms\\MatrixTraceTransform\\debug\nbuild\\intermediates\\transforms\\MatrixTraceTransform\\release\nTransform转换 public interface TransformInput { Collection\u0026lt;JarInput\u0026gt; getJarInputs(); Collection\u0026lt;DirectoryInput\u0026gt; getDirectoryInputs(); } private void doTransform(TransformInvocation transformInvocation) throws ExecutionException, InterruptedException { Collection\u0026lt;TransformInput\u0026gt; inputs = transformInvocation.getInputs(); for (TransformInput input : inputs) { for (DirectoryInput directoryInput : input.getDirectoryInputs()) { } for (JarInput inputJar : input.getJarInputs()) { } } 所谓 Transform 就是对输入的 class 文件转变成目标字节码文件，TransformInput 就是这些输入文件的抽象。目前它包括两部分：DirectoryInput 集合与 JarInput 集合。\nDirectoryInput 代表以源码方式参与项目编译的所有目录结构及其目录下的源码文件，可以借助于它来修改输出文件的目录结构以及目标字节码文件。\nJarInput 代表以 jar 包方式参与项目编译的所有本地 jar 包或远程 jar 包，可以借助它来动态添加 jar 包。\ninput build\\intermediates\\javac\\debug\\classes\\sample\\tencent\\matrix\\BuildConfig.class\nTransform 的工作原理 很明显的一个链式结构。其中，红色的 Transform 代表自定义 Transform ，蓝色的代表系统的 Transform 。\n每个 Transform 其实都是一个 Gradle 的 Task ， Android 编译器中的 TaskManager 会将每个 Transform 串联起来。第一个 Transform 接收来自 javac 编译的结果，以及拉取到本地的第三方依赖和 resource 资源。这些编译的中间产物在 Transform 链上流动，每个 Transform 节点都可以对 class 进行处理再传递到下一个 Transform 。我们自定义的 Transform 会插入到链的最前面，可以在 TaskManager 类的 createPostCompilationTasks 方法中找到相关逻辑\n参考 Android动态编译技术:Plugin Transform Javassist操作Class文件\nhttp://tools.android.com/tech-docs/new-build-system/transform-api\nGradle 学习之 Android 插件的 Transform API\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/2livedata/transformations/",
	"title": "Transformations",
	"tags": [],
	"description": "",
	"content": "map 图解 sequenceDiagram SourceLiveData-\u0026gt;\u0026gt;ResultMediatorLivedata: onChanged ResultMediatorLivedata-\u0026gt;\u0026gt;ResultMediatorLivedata: setValue(mapFunction.apply(x)) inline fun \u0026lt;X, Y\u0026gt; LiveData\u0026lt;X\u0026gt;.map(crossinline transform: (X) -\u0026gt; Y): LiveData\u0026lt;Y\u0026gt; = Transformations.map(this) { transform(it) } public static \u0026lt;X, Y\u0026gt; LiveData\u0026lt;Y\u0026gt; map( @NonNull LiveData\u0026lt;X\u0026gt; source, @NonNull final Function\u0026lt;X, Y\u0026gt; mapFunction) { final MediatorLiveData\u0026lt;Y\u0026gt; result = new MediatorLiveData\u0026lt;\u0026gt;(); result.addSource(source, new Observer\u0026lt;X\u0026gt;() { @Override public void onChanged(@Nullable X x) { result.setValue(mapFunction.apply(x)); } }); return result; } switchMap 图解 sequenceDiagram SourceLiveData-\u0026gt;\u0026gt;SwitchedLiveData: switchMapFunction.apply(x) SwitchedLiveData-\u0026gt;\u0026gt;ResultMediatorLivedata: onChanged ResultMediatorLivedata-\u0026gt;\u0026gt;ResultMediatorLivedata: setValue(y) inline fun \u0026lt;X, Y\u0026gt; LiveData\u0026lt;X\u0026gt;.switchMap( crossinline transform: (X) -\u0026gt; LiveData\u0026lt;Y\u0026gt; ): LiveData\u0026lt;Y\u0026gt; = Transformations.switchMap(this) { transform(it) } public static \u0026lt;X, Y\u0026gt; LiveData\u0026lt;Y\u0026gt; switchMap( @NonNull LiveData\u0026lt;X\u0026gt; source, @NonNull final Function\u0026lt;X, LiveData\u0026lt;Y\u0026gt;\u0026gt; switchMapFunction) { final MediatorLiveData\u0026lt;Y\u0026gt; result = new MediatorLiveData\u0026lt;\u0026gt;(); result.addSource(source, new Observer\u0026lt;X\u0026gt;() { LiveData\u0026lt;Y\u0026gt; mSource; @Override public void onChanged(@Nullable X x) { LiveData\u0026lt;Y\u0026gt; newLiveData = switchMapFunction.apply(x); if (mSource == newLiveData) { return; } if (mSource != null) { result.removeSource(mSource); } mSource = newLiveData; if (mSource != null) { result.addSource(mSource, new Observer\u0026lt;Y\u0026gt;() { @Override public void onChanged(@Nullable Y y) { result.setValue(y); } }); } } }); return result; } distinctUntilChanged /** * Creates a new [LiveData] object does not emit a value until the source `this` LiveData value * has been changed. The value is considered changed if `equals()` yields `false`. */ @Suppress(\u0026#34;NOTHING_TO_INLINE\u0026#34;) inline fun \u0026lt;X\u0026gt; LiveData\u0026lt;X\u0026gt;.distinctUntilChanged(): LiveData\u0026lt;X\u0026gt; = Transformations.distinctUntilChanged(this) public static \u0026lt;X\u0026gt; LiveData\u0026lt;X\u0026gt; distinctUntilChanged(@NonNull LiveData\u0026lt;X\u0026gt; source) { final MediatorLiveData\u0026lt;X\u0026gt; outputLiveData = new MediatorLiveData\u0026lt;\u0026gt;(); outputLiveData.addSource(source, new Observer\u0026lt;X\u0026gt;() { boolean mFirstTime = true; @Override public void onChanged(X currentValue) { final X previousValue = outputLiveData.getValue(); if (mFirstTime || (previousValue == null \u0026amp;\u0026amp; currentValue != null) || (previousValue != null \u0026amp;\u0026amp; !previousValue.equals(currentValue))) { mFirstTime = false; outputLiveData.setValue(currentValue); } } }); return outputLiveData; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/databinding/twowaydatabinding/",
	"title": "TwoWayDataBinding",
	"tags": [],
	"description": "",
	"content": "https://developer.android.com/topic/libraries/data-binding/two-way\nInfinite loops using two-way data binding Be careful not to introduce infinite loops when using two-way data binding. When the user changes an attribute, the method annotated using @InverseBindingAdapter is called, and the value is assigned to the backing property. This, in turn, would call the method annotated using @BindingAdapter, which would trigger another call to the method annotated using @InverseBindingAdapter, and so on.\nFor this reason, it\u0026rsquo;s important to break possible infinite loops by comparing new and old values in the methods annotated using @BindingAdapter.\nTwoWayDataBinding ensure that the view\u0026rsquo;s attribute is changed before update it if it\u0026rsquo;s in two way binding\ngraph TB subgraph DataFlow UserAction/Lifecycle--\u0026gt;LoadData end subgraph TwoWayDataBinding Attribute--\u0026gt;|Change by user,and call method|AttrChanged(\u0026quot;method annotated with BindingAdapter-\u0026quot;app:xxxAttrChanged\u0026quot;\u0026quot;) --\u0026gt;|InverseBindingListener.onChange|DataBindingSystem(\u0026quot;DataBindingSystem knows attribute has changed\u0026quot;) --\u0026gt;|Call annotated InverseBindingAdapter, assign value to|BackingProperty(\u0026quot;BackingProperty:LiveData\u0026quot;) --\u0026gt;|Call annotated BindingAdapter, may change attribute|Attribute LoadData--\u0026gt;|Resource\u0026lt;\u0026gt;|BackingProperty end TextViewBindingAdapter上的对应 @BindingAdapter(value = {\u0026#34;android:beforeTextChanged\u0026#34;, \u0026#34;android:onTextChanged\u0026#34;, \u0026#34;android:afterTextChanged\u0026#34;, \u0026#34;android:textAttrChanged\u0026#34;}, requireAll = false) public static void setTextWatcher(TextView view, final BeforeTextChanged before, final OnTextChanged on, final AfterTextChanged after, final InverseBindingListener textAttrChanged) { final TextWatcher newValue; if (before == null \u0026amp;\u0026amp; after == null \u0026amp;\u0026amp; on == null \u0026amp;\u0026amp; textAttrChanged == null) { newValue = null; } else { newValue = new TextWatcher() { @Override public void beforeTextChanged(CharSequence s, int start, int count, int after) { if (before != null) { before.beforeTextChanged(s, start, count, after); } } @Override public void onTextChanged(CharSequence s, int start, int before, int count) { if (on != null) { on.onTextChanged(s, start, before, count); } if (textAttrChanged != null) { textAttrChanged.onChange(); } } @InverseBindingAdapter(attribute = \u0026#34;android:text\u0026#34;, event = \u0026#34;android:textAttrChanged\u0026#34;) public static String getTextString(TextView view) { return view.getText().toString(); } @BindingAdapter(\u0026#34;android:text\u0026#34;) public static void setText(TextView view, CharSequence text) { final CharSequence oldText = view.getText(); if (text == oldText || (text == null \u0026amp;\u0026amp; oldText.length() == 0)) { return; } if (text instanceof Spanned) { if (text.equals(oldText)) { return; // No change in the spans, so don\u0026#39;t set anything.  } } else if (!haveContentsChanged(text, oldText)) { return; // No content changes, so don\u0026#39;t set anything.  } view.setText(text); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/ui/",
	"title": "ui",
	"tags": [],
	"description": "",
	"content": "ui 探索总结ui知识\n webview    WebView      动画    AnimatorSource      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/3viewmodel/viewmodel/",
	"title": "ViewModel",
	"tags": [],
	"description": "",
	"content": "类设计 基于androidx.lifecycle:lifecycle-viewmodel:2.1.0\n保存viewModelStore handleDestroyActivity ActivityThread.java\n@Override public void handleDestroyActivity(IBinder token, boolean finishing, int configChanges, boolean getNonConfigInstance, String reason) {//转屏时传递的getNonConfigInstance为true  ActivityClientRecord r = performDestroyActivity(token, finishing, configChanges, getNonConfigInstance, reason); } handledestroyactivity由来\n/** Core implementation of activity destroy call. */ ActivityClientRecord performDestroyActivity(IBinder token, boolean finishing, int configChanges, boolean getNonConfigInstance, String reason) { ActivityClientRecord r = mActivities.get(token); Class\u0026lt;? extends Activity\u0026gt; activityClass = null; if (r != null) { if (finishing) { r.activity.mFinished = true; } performPauseActivityIfNeeded(r, \u0026#34;destroy\u0026#34;); if (!r.stopped) { callActivityOnStop(r, false /* saveState */, \u0026#34;destroy\u0026#34;); } if (getNonConfigInstance) { r.lastNonConfigurationInstances = r.activity.retainNonConfigurationInstances(); } r.lastNonConfigurationInstances.activity.custom\ninto r.lastNonConfigurationInstances.activity.viewModelStore 其中的activity也是一个NonConfigurationInstances实例\nNonConfigurationInstances retainNonConfigurationInstances() { Object activity = onRetainNonConfigurationInstance(); NonConfigurationInstances nci = new NonConfigurationInstances(); nci.activity = activity; return nci; } /** * Retain all appropriate non-config state. You can NOT * override this yourself! Use a {@link androidx.lifecycle.ViewModel} if you want to * retain your own non config state. */ @Override @Nullable public final Object onRetainNonConfigurationInstance() { Object custom = onRetainCustomNonConfigurationInstance();//保存用户自定义数据，可重写  ViewModelStore viewModelStore = mViewModelStore; if (viewModelStore == null) { // No one called getViewModelStore(), so see if there was an existing  // ViewModelStore from our last NonConfigurationInstance  NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { viewModelStore = nc.viewModelStore; } } if (viewModelStore == null \u0026amp;\u0026amp; custom == null) { return null; } NonConfigurationInstances nci = new NonConfigurationInstances(); nci.custom = custom; nci.viewModelStore = viewModelStore; return nci; } 恢复viewModelStore 从ActivityClientRecord中提取保存mLastNonConfigurationInstances LaunchActivityItem.java\npublic void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { ActivityClientRecord r = new ActivityClientRecord(token, mIntent, mIdent, mInfo, mOverrideConfig, mCompatInfo, mReferrer, mVoiceInteractor, mState, mPersistentState, mPendingResults, mPendingNewIntents, mIsForward, mProfilerInfo, client);//这里并没有初始化lastNonConfigurationInstances  client.handleLaunchActivity(r, pendingActions, null /* customIntent */); } ActivityThread.java\npublic Activity handleLaunchActivity(ActivityClientRecord r, PendingTransactionActions pendingActions, Intent customIntent) {//转屏时通过relaunchAcitivtyItem进行，这里的r包含lastNonConfigurationInstances  final Activity a = performLaunchActivity(r, customIntent); } /** Core implementation of activity launch. */ private Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) { activity.attach(appContext, this, getInstrumentation(), r.token, r.ident, app, r.intent, r.activityInfo, title, r.parent, r.embeddedID, r.lastNonConfigurationInstances, config, r.referrer, r.voiceInteractor, window, r.configCallback); r.lastNonConfigurationInstances = null; } Activity.java\nfinal void attach(Context context, ActivityThread aThread, Instrumentation instr, IBinder token, int ident, Application application, Intent intent, ActivityInfo info, CharSequence title, Activity parent, String id, NonConfigurationInstances lastNonConfigurationInstances, Configuration config, String referrer, IVoiceInteractor voiceInteractor, Window window, ActivityConfigCallback activityConfigCallback) { attachBaseContext(context); mLastNonConfigurationInstances = lastNonConfigurationInstances; } 从lastNonConfigurationInstance中提取并保存mViewModelStore ComponentActivity.java\npublic ViewModelStore getViewModelStore() { if (mViewModelStore == null) { NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { // Restore the ViewModelStore from NonConfigurationInstances  mViewModelStore = nc.viewModelStore; } if (mViewModelStore == null) { mViewModelStore = new ViewModelStore(); } } return mViewModelStore; } public Object getLastNonConfigurationInstance() { return mLastNonConfigurationInstances != null ? mLastNonConfigurationInstances.activity : null; } 使用mViewModelStore ViewModelProvider /** * Creates {@code ViewModelProvider}, which will create {@code ViewModels} via the given * {@code Factory} and retain them in the given {@code store}. * * @param store {@code ViewModelStore} where ViewModels will be stored. * @param factory factory a {@code Factory} which will be used to instantiate * new {@code ViewModels} */ public ViewModelProvider(@NonNull ViewModelStore store, @NonNull Factory factory) { mFactory = factory; mViewModelStore = store; } Factory public interface Factory { /** * Creates a new instance of the given {@code Class}. * \u0026lt;p\u0026gt; * * @param modelClass a {@code Class} whose instance is requested * @param \u0026lt;T\u0026gt; The type parameter for the ViewModel. * @return a newly created ViewModel */ @NonNull \u0026lt;T extends ViewModel\u0026gt; T create(@NonNull Class\u0026lt;T\u0026gt; modelClass); } KeyedFactory abstract static class KeyedFactory implements Factory { public abstract \u0026lt;T extends ViewModel\u0026gt; T create(@NonNull String key, @NonNull Class\u0026lt;T\u0026gt; modelClass); @NonNull @Override public \u0026lt;T extends ViewModel\u0026gt; T create(@NonNull Class\u0026lt;T\u0026gt; modelClass) { throw new UnsupportedOperationException(\u0026#34;create(String, Class\u0026lt;?\u0026gt;) must be called on \u0026#34; + \u0026#34;implementaions of KeyedFactory\u0026#34;); } } get public \u0026lt;T extends ViewModel\u0026gt; T get(@NonNull Class\u0026lt;T\u0026gt; modelClass) { String canonicalName = modelClass.getCanonicalName(); return get(DEFAULT_KEY + \u0026#34;:\u0026#34; + canonicalName, modelClass); } public \u0026lt;T extends ViewModel\u0026gt; T get(@NonNull String key, @NonNull Class\u0026lt;T\u0026gt; modelClass) { ViewModel viewModel = mViewModelStore.get(key); if (modelClass.isInstance(viewModel)) { //noinspection unchecked  return (T) viewModel; } if (mFactory instanceof KeyedFactory) { viewModel = ((KeyedFactory) (mFactory)).create(key, modelClass); } else { viewModel = (mFactory).create(modelClass); } mViewModelStore.put(key, viewModel); //noinspection unchecked  return (T) viewModel; } ViewModelStore private final HashMap\u0026lt;String, ViewModel\u0026gt; mMap = new HashMap\u0026lt;\u0026gt;(); final void put(String key, ViewModel viewModel) { ViewModel oldViewModel = mMap.put(key, viewModel); if (oldViewModel != null) { oldViewModel.onCleared(); } } final ViewModel get(String key) { return mMap.get(key); } public final void clear() { for (ViewModel vm : mMap.values()) { vm.clear(); } mMap.clear(); } } ViewModel private final Map\u0026lt;String, Object\u0026gt; mBagOfTags = new HashMap\u0026lt;\u0026gt;(); protected void onCleared() { } final void clear() { mCleared = true; if (mBagOfTags != null) { synchronized (mBagOfTags) { for (Object value : mBagOfTags.values()) { // see comment for the similar call in setTagIfAbsent  closeWithRuntimeException(value); } } } onCleared(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/3viewmodel/viewmodelscope_delegate/",
	"title": "ViewModelScope_Delegate",
	"tags": [],
	"description": "",
	"content": "ViewModel初始化委托 https://stackoverflow.com/questions/58106707/how-does-kotlin-use-this-by-delegate-to-instantiate-the-viewmodel\nby viewModels(...) is part of fragment-ktx library, it\u0026rsquo;s a convienience short hand for creating a lazy delegate obtaining ViewModels.\n// creates lazy delegate for obtaining zero-argument MyViewModel private val viewModel : MyViewModel by viewModels() // it\u0026#39;s functionally equal to: private val viewModel by lazy { ViewModelProvider(this).get(MyViewModel::class.java) } // with factory: private val viewModel : MyViewModel by viewModels { getViewModelFactory() } // is equal to: private val viewModel by lazy { ViewModelProvider(this, getViewModelFactory()).get(MyViewModel::class.java) } ComponentActivity.viewModels @MainThread inline fun \u0026lt;reified VM : ViewModel\u0026gt; ComponentActivity.viewModels( noinline factoryProducer: (() -\u0026gt; Factory)? = null ): Lazy\u0026lt;VM\u0026gt; { val factoryPromise = factoryProducer ?: { defaultViewModelProviderFactory } return ViewModelLazy(VM::class, { viewModelStore }, factoryPromise) } ViewModelLazy class ViewModelLazy\u0026lt;VM : ViewModel\u0026gt; ( private val viewModelClass: KClass\u0026lt;VM\u0026gt;, private val storeProducer: () -\u0026gt; ViewModelStore, private val factoryProducer: () -\u0026gt; ViewModelProvider.Factory ) : Lazy\u0026lt;VM\u0026gt; { private var cached: VM? = null override val value: VM get() { val viewModel = cached return if (viewModel == null) { val factory = factoryProducer() val store = storeProducer() ViewModelProvider(store, factory).get(viewModelClass.java).also { cached = it } } else { viewModel } } override fun isInitialized() = cached != null } JVM target 1.8 Cannot inline bytecode built with JVM target 1.8 into bytecode that is being built with JVM target 1.6. Please specify proper \u0026lsquo;-jvm-target\u0026rsquo; option\nhttps://stackoverflow.com/questions/48988778/cannot-inline-bytecode-built-with-jvm-target-1-8-into-bytecode-that-is-being-bui\n解决方式：\nandroid { kotlinOptions { jvmTarget = JavaVersion.VERSION_1_8.toString() } } viewModelScope原理 public ComponentActivity() { getLifecycle().addObserver(new LifecycleEventObserver() { @Override public void onStateChanged(@NonNull LifecycleOwner source, @NonNull Lifecycle.Event event) { if (event == Lifecycle.Event.ON_DESTROY) { if (!isChangingConfigurations()) { getViewModelStore().clear(); } } } }); } viewModelStore.clear /** * Clears internal storage and notifies ViewModels that they are no longer used. */ public final void clear() { for (ViewModel vm : mMap.values()) { vm.clear(); } mMap.clear(); } viewModel.clear @MainThread final void clear() { mCleared = true; // Since clear() is final, this method is still called on mock objects  // and in those cases, mBagOfTags is null. It\u0026#39;ll always be empty though  // because setTagIfAbsent and getTag are not final so we can skip  // clearing it  if (mBagOfTags != null) { synchronized (mBagOfTags) { for (Object value : mBagOfTags.values()) { // see comment for the similar call in setTagIfAbsent  closeWithRuntimeException(value); } } } onCleared(); } private static void closeWithRuntimeException(Object obj) { if (obj instanceof Closeable) { try { ((Closeable) obj).close(); } catch (IOException e) { throw new RuntimeException(e); } } } coroutineContext.cancel private const val JOB_KEY = \u0026#34;androidx.lifecycle.ViewModelCoroutineScope.JOB_KEY\u0026#34; /** * [CoroutineScope] tied to this [ViewModel]. * This scope will be canceled when ViewModel will be cleared, i.e [ViewModel.onCleared] is called * * This scope is bound to * [Dispatchers.Main.immediate][kotlinx.coroutines.MainCoroutineDispatcher.immediate] */ val ViewModel.viewModelScope: CoroutineScope get() { val scope: CoroutineScope? = this.getTag(JOB_KEY) if (scope != null) { return scope } return setTagIfAbsent(JOB_KEY, CloseableCoroutineScope(SupervisorJob() + Dispatchers.Main.immediate)) } internal class CloseableCoroutineScope(context: CoroutineContext) : Closeable, CoroutineScope { override val coroutineContext: CoroutineContext = context override fun close() { coroutineContext.cancel() } } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/vsync/",
	"title": "Vsync",
	"tags": [],
	"description": "",
	"content": "原理图 Vsync App进程 graph TB DisplayEventDispatcher::scheduleVsync--\u0026gt;eventConnection.requestNextVsync sequenceDiagram participant JavaDispalyEventReveiver participant NativeDisplayEventReceiver participant Looper participant BitTube NativeDisplayEventReceiver-\u0026gt;\u0026gt;+Looper: looper.addFd Looper--\u0026gt;\u0026gt;-NativeDisplayEventReceiver: fd可读 NativeDisplayEventReceiver-\u0026gt;\u0026gt;+NativeDisplayEventReceiver: handleEvent NativeDisplayEventReceiver-\u0026gt;\u0026gt;-BitTube: recvObjects BitTube--\u0026gt;\u0026gt;NativeDisplayEventReceiver: return NativeDisplayEventReceiver-\u0026gt;\u0026gt;JavaDispalyEventReveiver:dispatchVsnc frameworks/base/libs/androidfw/DisplayEventDispatcher.cpp\nDisplayEventDispatcher.cpp initialize status_t DisplayEventDispatcher::initialize() { status_t result = mReceiver.initCheck(); int rc = mLooper-\u0026gt;addFd(mReceiver.getFd(), 0, Looper::EVENT_INPUT, this, NULL); return OK; } handleEvent int DisplayEventDispatcher::handleEvent(int, int events, void*) { // Drain all pending events, keep the last vsync.  nsecs_t vsyncTimestamp; int32_t vsyncDisplayId; uint32_t vsyncCount; if (processPendingEvents(\u0026amp;vsyncTimestamp, \u0026amp;vsyncDisplayId, \u0026amp;vsyncCount)) { dispatchVsync(vsyncTimestamp, vsyncDisplayId, vsyncCount); } return 1; // keep the callback } scheduleVsync status_t DisplayEventDispatcher::scheduleVsync() { if (!mWaitingForVsync) { // Drain all pending events.  if (processPendingEvents(\u0026amp;vsyncTimestamp, \u0026amp;vsyncDisplayId, \u0026amp;vsyncCount)) { this, ns2ms(static_cast\u0026lt;nsecs_t\u0026gt;(vsyncTimestamp))); } status_t status = mReceiver.requestNextVsync(); mWaitingForVsync = true; } return OK; } frameworks/native/libs/gui/DisplayEventReceiver.cpp\nDisplayEventReceiver.cpp sp\u0026lt;IDisplayEventConnection\u0026gt; mEventConnection; std::unique_ptr\u0026lt;gui::BitTube\u0026gt; mDataChannel; DisplayEventReceiver() /* * DisplayEventReceiver creates and registers an event connection with * SurfaceFlinger. VSync events are disabled by default. Call setVSyncRate * or requestNextVsync to receive them. * Other events start being delivered immediately. */ DisplayEventReceiver::DisplayEventReceiver(ISurfaceComposer::VsyncSource vsyncSource) { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService()); if (sf != NULL) { mEventConnection = sf-\u0026gt;createDisplayEventConnection(vsyncSource); if (mEventConnection != NULL) { mDataChannel = std::make_unique\u0026lt;gui::BitTube\u0026gt;(); mEventConnection-\u0026gt;stealReceiveChannel(mDataChannel.get()); } } } getFd int DisplayEventReceiver::getFd() const { if (mDataChannel == NULL) return NO_INIT; return mDataChannel-\u0026gt;getFd(); } getEvents ssize_t DisplayEventReceiver::getEvents(DisplayEventReceiver::Event* events, size_t count) { return DisplayEventReceiver::getEvents(mDataChannel.get(), events, count); } ssize_t DisplayEventReceiver::getEvents(gui::BitTube* dataChannel, Event* events, size_t count) { return gui::BitTube::recvObjects(dataChannel, events, count); } requestNextVsync status_t DisplayEventReceiver::requestNextVsync() { if (mEventConnection != NULL) { mEventConnection-\u0026gt;requestNextVsync(); return NO_ERROR; } return NO_INIT; } frameworks/native/libs/gui/BitTube.cpp\nBitTube getFd int BitTube::getFd() const { return mReceiveFd; } frameworks/native/libs/gui/SurfaceComposerClient.cpp\nframeworks/native/libs/gui/include/private/gui/ComposerService.h\nComposerService // This holds our connection to the composer service (i.e. SurfaceFlinger). // If the remote side goes away, we will re-establish the connection. // Users of this class should not retain the value from // getComposerService() for an extended period. class ComposerService : public Singleton\u0026lt;ComposerService\u0026gt; { sp\u0026lt;ISurfaceComposer\u0026gt; mComposerService; sp\u0026lt;IBinder::DeathRecipient\u0026gt; mDeathObserver; } getComposerService // Get a connection to the Composer Service. This will block until  // a connection is established. /*static*/ sp\u0026lt;ISurfaceComposer\u0026gt; ComposerService::getComposerService() { ComposerService\u0026amp; instance = ComposerService::getInstance(); Mutex::Autolock _l(instance.mLock); if (instance.mComposerService == NULL) { ComposerService::getInstance().connectLocked(); assert(instance.mComposerService != NULL); } return instance.mComposerService; } connectLocked void ComposerService::connectLocked() { const String16 name(\u0026#34;SurfaceFlinger\u0026#34;); while (getService(name, \u0026amp;mComposerService) != NO_ERROR) {//get SurfaceFlinger Service  usleep(250000); } assert(mComposerService != NULL); // Create the death listener.  class DeathObserver : public IBinder::DeathRecipient { ComposerService\u0026amp; mComposerService; virtual void binderDied(const wp\u0026lt;IBinder\u0026gt;\u0026amp; who) { ALOGW(\u0026#34;ComposerService remote (surfaceflinger) died [%p]\u0026#34;, who.unsafe_get()); mComposerService.composerServiceDied(); } public: explicit DeathObserver(ComposerService\u0026amp; mgr) : mComposerService(mgr) { } }; mDeathObserver = new DeathObserver(*const_cast\u0026lt;ComposerService*\u0026gt;(this)); IInterface::asBinder(mComposerService)-\u0026gt;linkToDeath(mDeathObserver); } composerServiceDied void ComposerService::composerServiceDied() { Mutex::Autolock _l(mLock); mComposerService = NULL; mDeathObserver = NULL; } frameworks/native/libs/binder/include/binder/IServiceManager.h\nIServiceManager getService template\u0026lt;typename INTERFACE\u0026gt; status_t getService(const String16\u0026amp; name, sp\u0026lt;INTERFACE\u0026gt;* outService) { const sp\u0026lt;IServiceManager\u0026gt; sm = defaultServiceManager(); if (sm != NULL) { *outService = interface_cast\u0026lt;INTERFACE\u0026gt;(sm-\u0026gt;getService(name)); if ((*outService) != NULL) return NO_ERROR; } return NAME_NOT_FOUND; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/vsync_surfaceflinger/",
	"title": "Vsync_SurfaceFlinger",
	"tags": [],
	"description": "",
	"content": "Android-SurfaceFlinger启动与绘图原理\n创建 HWComposer 对象(通过 HAL 层的 HWComposer 硬件模块 或 软件模拟产生 Vsync 信号)，现在的 Android 系统基本上都可以看成是通过硬件 HWComposer 产生 Vsync 信号，而不使用软件模拟，所以下面解析都只谈及硬件 HWComposer 的 Vsync 信号；\nChoreographer 会通过上面创建的 APP 延时源 mEventThreadSource 对象及其对应的 EventThread 线程来监听同步模拟发出的 Vsync 信号，然后进行绘制(measure/layout/draw)操作。具体逻辑见 Android-Choreographer原理。\nSurfaceFlinger类设计 classDiagram IBinder\u0026lt;|--BBinder BBinder\u0026lt;|--BnInterface IInterface\u0026lt;|--ISurfaceComposer BnInterface\u0026lt;|--BnSurfaceComposer ISurfaceComposer\u0026lt;|--BnSurfaceComposer: 泛型类型 BnSurfaceComposer\u0026lt;|--SurfaceFlinger system/core/rootdir/init.rc\ninit.rc on property:vold.decrypt=trigger_restart_framework stop surfaceflinger start surfaceflinger # A/B update verifier that marks a successful boot. exec_start update_verifier class_start main class_start late_start frameworks/native/services/surfaceflinger/surfaceflinger.rc\nsurfaceflinger.rc service surfaceflinger /system/bin/surfaceflinger class core animation user system group graphics drmrpc readproc onrestart restart zygote writepid /dev/stune/foreground/tasks socket pdx/system/vr/display/client stream 0666 system graphics u:object_r:pdx_display_client_endpoint_socket:s0 socket pdx/system/vr/display/manager stream 0666 system graphics u:object_r:pdx_display_manager_endpoint_socket:s0 socket pdx/system/vr/display/vsync stream 0666 system graphics u:object_r:pdx_display_vsync_endpoint_socket:s0 frameworks/native/services/surfaceflinger/main_surfaceflinger.cpp\nmain_surfaceflinger.cpp main int main(int, char**) { // When SF is launched in its own process, limit the number of  // binder threads to 4.  ProcessState::self()-\u0026gt;setThreadPoolMaxThreadCount(4); // start the thread pool  sp\u0026lt;ProcessState\u0026gt; ps(ProcessState::self()); ps-\u0026gt;startThreadPool(); // instantiate surfaceflinger  sp\u0026lt;SurfaceFlinger\u0026gt; flinger = new SurfaceFlinger(); setpriority(PRIO_PROCESS, 0, PRIORITY_URGENT_DISPLAY); set_sched_policy(0, SP_FOREGROUND); // initialize before clients can connect  flinger-\u0026gt;init(); // publish surface flinger  sp\u0026lt;IServiceManager\u0026gt; sm(defaultServiceManager()); sm-\u0026gt;addService(String16(SurfaceFlinger::getServiceName()), flinger, false, IServiceManager::DUMP_FLAG_PRIORITY_CRITICAL); // run surface flinger in this thread  flinger-\u0026gt;run(); return 0; } frameworks/native/services/surfaceflinger/SurfaceFlinger.h\nSurfaceFlinger SurfaceFlinger class SurfaceFlinger : public BnSurfaceComposer, public PriorityDumper, private IBinder::DeathRecipient, private HWC2::ComposerCallback { // these are thread safe  mutable std::unique_ptr\u0026lt;MessageQueue\u0026gt; mEventQueue{std::make_unique\u0026lt;impl::MessageQueue\u0026gt;()}; VSyncModulator mVsyncModulator; DispSync mPrimaryDispSync; using CreateBufferQueueFunction = std::function\u0026lt;void(sp\u0026lt;IGraphicBufferProducer\u0026gt;* /* outProducer */, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* /* outConsumer */, bool /* consumerIsSurfaceFlinger */)\u0026gt;; CreateBufferQueueFunction mCreateBufferQueue; using CreateNativeWindowSurfaceFunction = std::function\u0026lt;std::unique_ptr\u0026lt;NativeWindowSurface\u0026gt;(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp;)\u0026gt;; CreateNativeWindowSurfaceFunction mCreateNativeWindowSurface; } SurfaceFlinger::SurfaceFlinger(SurfaceFlinger::SkipInitializationTag) : BnSurfaceComposer(), Display(false), ...... mMainThreadId(std::this_thread::get_id()), mCreateBufferQueue(\u0026amp;BufferQueue::createBufferQueue), mCreateNativeWindowSurface(\u0026amp;impl::NativeWindowSurface::create) {} onFirstRef void SurfaceFlinger::onFirstRef() { mEventQueue-\u0026gt;init(this); } init void SurfaceFlinger::init() { // start the EventThread  mEventThreadSource = std::make_unique\u0026lt;DispSyncSource\u0026gt;(\u0026amp;mPrimaryDispSync, SurfaceFlinger::vsyncPhaseOffsetNs, true, \u0026#34;app\u0026#34;); mEventThread = std::make_unique\u0026lt;impl::EventThread\u0026gt;(mEventThreadSource.get(), [this]() { resyncWithRateLimit(); }, impl::EventThread::InterceptVSyncsCallback(), \u0026#34;appEventThread\u0026#34;); mSfEventThreadSource = std::make_unique\u0026lt;DispSyncSource\u0026gt;(\u0026amp;mPrimaryDispSync, SurfaceFlinger::sfVsyncPhaseOffsetNs, true, \u0026#34;sf\u0026#34;); mSFEventThread = std::make_unique\u0026lt;impl::EventThread\u0026gt;(mSfEventThreadSource.get(), [this]() { resyncWithRateLimit(); }, [this](nsecs_t timestamp) { mInterceptor-\u0026gt;saveVSyncEvent(timestamp); mEventQueue-\u0026gt;setEventThread(mSFEventThread.get()); mVsyncModulator.setEventThread(mSFEventThread.get()); // Get a RenderEngine for the given display / config (can\u0026#39;t fail)  getBE().mRenderEngine = RE::impl::RenderEngine::create(HAL_PIXEL_FORMAT_RGBA_8888, hasWideColorDisplay ? RE::RenderEngine::WIDE_COLOR_SUPPORT : 0); getBE().mHwc.reset( new HWComposer(std::make_unique\u0026lt;Hwc2::impl::Composer\u0026gt;(getBE().mHwcServiceName))); getBE().mHwc-\u0026gt;registerCallback(this, getBE().mComposerSequenceId); mEventControlThread = std::make_unique\u0026lt;impl::EventControlThread\u0026gt;( [this](bool enabled) { setVsyncEnabled(HWC_DISPLAY_PRIMARY, enabled); }); // set initial conditions (e.g. unblank default device)  initializeDisplays(); } onVsyncReceived void SurfaceFlinger::onVsyncReceived(int32_t sequenceId, hwc2_display_t displayId, int64_t timestamp) { Mutex::Autolock lock(mStateLock); // Ignore any vsyncs from a previous hardware composer.  if (sequenceId != getBE().mComposerSequenceId) { return; } int32_t type; if (!getBE().mHwc-\u0026gt;onVsync(displayId, timestamp, \u0026amp;type)) { return; } bool needsHwVsync = false; { // Scope for the lock  Mutex::Autolock _l(mHWVsyncLock); if (type == DisplayDevice::DISPLAY_PRIMARY \u0026amp;\u0026amp; mPrimaryHWVsyncEnabled) { needsHwVsync = mPrimaryDispSync.addResyncSample(timestamp); } } if (needsHwVsync) { enableHardwareVsync(); } else { disableHardwareVsync(false); } } disableHardwareVsync void SurfaceFlinger::disableHardwareVsync(bool makeUnavailable) { Mutex::Autolock _l(mHWVsyncLock); if (mPrimaryHWVsyncEnabled) { //eventControl(HWC_DISPLAY_PRIMARY, SurfaceFlinger::EVENT_VSYNC, false);  mEventControlThread-\u0026gt;setVsyncEnabled(false); mPrimaryDispSync.endResync(); mPrimaryHWVsyncEnabled = false; } if (makeUnavailable) { mHWVsyncAvailable = false; } } run void SurfaceFlinger::run() { do { waitForEvent(); } while (true); } waitForEvent void SurfaceFlinger::waitForEvent() { mEventQueue-\u0026gt;waitMessage(); } onMessageReceived void SurfaceFlinger::onMessageReceived(int32_t what) { switch (what) { case MessageQueue::INVALIDATE: { bool refreshNeeded = handleMessageTransaction(); refreshNeeded |= handleMessageInvalidate(); refreshNeeded |= mRepaintEverything; if (refreshNeeded) { // Signal a refresh if a transaction modified the window state,  // a new buffer was latched, or if HWC has requested a full  // repaint  signalRefresh();//call handleMessageRefresh()  } break; } case MessageQueue::REFRESH: { handleMessageRefresh(); break; } } } handleMessageRefresh void SurfaceFlinger::handleMessageRefresh() { ATRACE_CALL(); mRefreshPending = false; nsecs_t refreshStartTime = systemTime(SYSTEM_TIME_MONOTONIC); preComposition(refreshStartTime); rebuildLayerStacks(); setUpHWComposer(); doDebugFlashRegions(); doTracing(\u0026#34;handleRefresh\u0026#34;); logLayerStats(); doComposition(); postComposition(refreshStartTime); mPreviousPresentFence = getBE().mHwc-\u0026gt;getPresentFence(HWC_DISPLAY_PRIMARY); mHadClientComposition = false; for (size_t displayId = 0; displayId \u0026lt; mDisplays.size(); ++displayId) { const sp\u0026lt;DisplayDevice\u0026gt;\u0026amp; displayDevice = mDisplays[displayId]; mHadClientComposition = mHadClientComposition || getBE().mHwc-\u0026gt;hasClientComposition(displayDevice-\u0026gt;getHwcDisplayId()); } mVsyncModulator.onRefreshed(mHadClientComposition); mLayersWithQueuedFrames.clear(); } createDisplayEventConnection sp\u0026lt;IDisplayEventConnection\u0026gt; SurfaceFlinger::createDisplayEventConnection( ISurfaceComposer::VsyncSource vsyncSource) { if (vsyncSource == eVsyncSourceSurfaceFlinger) { return mSFEventThread-\u0026gt;createEventConnection(); } else { return mEventThread-\u0026gt;createEventConnection(); } } resyncWithRateLimit void SurfaceFlinger::resyncWithRateLimit() { static constexpr nsecs_t kIgnoreDelay = ms2ns(500); // No explicit locking is needed here since EventThread holds a lock while calling this method  static nsecs_t sLastResyncAttempted = 0; const nsecs_t now = systemTime(); if (now - sLastResyncAttempted \u0026gt; kIgnoreDelay) { resyncToHardwareVsync(false); } sLastResyncAttempted = now; } resyncToHardwareVsync void SurfaceFlinger::resyncToHardwareVsync(bool makeAvailable) { Mutex::Autolock _l(mHWVsyncLock); if (makeAvailable) { mHWVsyncAvailable = true; } else if (!mHWVsyncAvailable) { // Hardware vsync is not currently available, so abort the resync  // attempt for now  return; } const auto\u0026amp; activeConfig = getBE().mHwc-\u0026gt;getActiveConfig(HWC_DISPLAY_PRIMARY); const nsecs_t period = activeConfig-\u0026gt;getVsyncPeriod(); mPrimaryDispSync.reset(); mPrimaryDispSync.setPeriod(period); if (!mPrimaryHWVsyncEnabled) { mPrimaryDispSync.beginResync(); //eventControl(HWC_DISPLAY_PRIMARY, SurfaceFlinger::EVENT_VSYNC, true);  mEventControlThread-\u0026gt;setVsyncEnabled(true); mPrimaryHWVsyncEnabled = true; } } setVsyncEnabled void SurfaceFlinger::setVsyncEnabled(int disp, int enabled) { getHwComposer().setVsyncEnabled(disp, enabled ? HWC2::Vsync::Enable : HWC2::Vsync::Disable); } frameworks/native/libs/gui/include/gui/ISurfaceComposer.h\nVsyncSource enum VsyncSource { eVsyncSourceApp = 0, eVsyncSourceSurfaceFlinger = 1 }; ComposerCallbackBridge :IComposerCallback ComposerCallback* mCallback; onVsync Return\u0026lt;void\u0026gt; onVsync(Hwc2::Display display, int64_t timestamp) override { mCallback-\u0026gt;onVsyncReceived(mSequenceId, display, timestamp); return Void(); } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\nDispSyncSource DispSync* mDispSync; Mutex mCallbackMutex; // Protects the following  VSyncSource::Callback* mCallback = nullptr; onDispSyncEvent virtual void onDispSyncEvent(nsecs_t when) { VSyncSource::Callback* callback; { Mutex::Autolock lock(mCallbackMutex); callback = mCallback; if (mTraceVsync) { mValue = (mValue + 1) % 2; ATRACE_INT(mVsyncEventLabel.string(), mValue); } } if (callback != nullptr) { callback-\u0026gt;onVSyncEvent(when); } } frameworks/native/services/surfaceflinger/EventThread.cpp\nEventThread class EventThread : public android::EventThread, private VSyncSource::Callback { class Connection : public BnDisplayEventConnection { public: explicit Connection(EventThread* eventThread); virtual ~Connection(); virtual status_t postEvent(const DisplayEventReceiver::Event\u0026amp; event); // count \u0026gt;= 1 : continuous event. count is the vsync rate  // count == 0 : one-shot event that has not fired  // count ==-1 : one-shot event that fired this round / disabled  int32_t count; private: virtual void onFirstRef(); status_t stealReceiveChannel(gui::BitTube* outChannel) override; status_t setVsyncRate(uint32_t count) override; void requestNextVsync() override; // asynchronous  EventThread* const mEventThread; gui::BitTube mChannel; }; EventThread() EventThread::EventThread(VSyncSource* src, ResyncWithRateLimitCallback resyncWithRateLimitCallback, InterceptVSyncsCallback interceptVSyncsCallback, const char* threadName) : mVSyncSource(src), mResyncWithRateLimitCallback(resyncWithRateLimitCallback), mInterceptVSyncsCallback(interceptVSyncsCallback) { for (auto\u0026amp; event : mVSyncEvent) { event.header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; event.header.id = 0; event.header.timestamp = 0; event.vsync.count = 0; } mThread = std::thread(\u0026amp;EventThread::threadMain, this); pthread_setname_np(mThread.native_handle(), threadName); pid_t tid = pthread_gettid_np(mThread.native_handle()); // Use SCHED_FIFO to minimize jitter  constexpr int EVENT_THREAD_PRIORITY = 2; struct sched_param param = {0}; param.sched_priority = EVENT_THREAD_PRIORITY; if (pthread_setschedparam(mThread.native_handle(), SCHED_FIFO, \u0026amp;param) != 0) { ALOGE(\u0026#34;Couldn\u0026#39;t set SCHED_FIFO for EventThread\u0026#34;); } set_sched_policy(tid, SP_FOREGROUND); } threadMain void EventThread::threadMain() NO_THREAD_SAFETY_ANALYSIS { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mMutex); while (mKeepRunning) { DisplayEventReceiver::Event event; Vector\u0026lt;sp\u0026lt;EventThread::Connection\u0026gt; \u0026gt; signalConnections; signalConnections = waitForEventLocked(\u0026amp;lock, \u0026amp;event); // dispatch events to listeners...  const size_t count = signalConnections.size(); for (size_t i = 0; i \u0026lt; count; i++) { const sp\u0026lt;Connection\u0026gt;\u0026amp; conn(signalConnections[i]); // now see if we still need to report this event  status_t err = conn-\u0026gt;postEvent(event); } } } waitForEventLocked // This will return when (1) a vsync event has been received, and (2) there was // at least one connection interested in receiving it when we started waiting. Vector\u0026lt;sp\u0026lt;EventThread::Connection\u0026gt; \u0026gt; EventThread::waitForEventLocked( std::unique_lock\u0026lt;std::mutex\u0026gt;* lock, DisplayEventReceiver::Event* event) { ...... if (!timestamp \u0026amp;\u0026amp; !eventPending) { // wait for something to happen  if (waitForVSync) { // This is where we spend most of our time, waiting  // for vsync events and new client registrations.  //  // If the screen is off, we can\u0026#39;t use h/w vsync, so we  // use a 16ms timeout instead. It doesn\u0026#39;t need to be  // precise, we just need to keep feeding our clients.  //  // We don\u0026#39;t want to stall if there\u0026#39;s a driver bug, so we  // use a (long) timeout when waiting for h/w vsync, and  // generate fake events when necessary.  bool softwareSync = mUseSoftwareVSync; auto timeout = softwareSync ? 16ms : 1000ms; if (mCondition.wait_for(*lock, timeout) == std::cv_status::timeout) { if (!softwareSync) { ALOGW(\u0026#34;Timed out waiting for hw vsync; faking it\u0026#34;); } // FIXME: how do we decide which display id the fake  // vsync came from ?  mVSyncEvent[0].header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; mVSyncEvent[0].header.id = DisplayDevice::DISPLAY_PRIMARY; mVSyncEvent[0].header.timestamp = systemTime(SYSTEM_TIME_MONOTONIC); mVSyncEvent[0].vsync.count++; } } else { // Nobody is interested in vsync, so we just want to sleep.  // h/w vsync should be disabled, so this will wait until we  // get a new connection, or an existing connection becomes  // interested in receiving vsync again.  mCondition.wait(*lock); } // here we\u0026#39;re guaranteed to have a timestamp and some connections to signal  // (The connections might have dropped out of mDisplayEventConnections  // while we were asleep, but we\u0026#39;ll still have strong references to them.)  return signalConnections; } onVSyncEvent void EventThread::onVSyncEvent(nsecs_t timestamp) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); mVSyncEvent[0].header.type = DisplayEventReceiver::DISPLAY_EVENT_VSYNC; mVSyncEvent[0].header.id = 0; mVSyncEvent[0].header.timestamp = timestamp; mVSyncEvent[0].vsync.count++; mCondition.notify_all();//唤醒EventThread线程 } Connection::postEvent status_t EventThread::Connection::postEvent(const DisplayEventReceiver::Event\u0026amp; event) { ssize_t size = DisplayEventReceiver::sendEvents(\u0026amp;mChannel, \u0026amp;event, 1); return size \u0026lt; 0 ? status_t(size) : status_t(NO_ERROR); } createEventConnection sp\u0026lt;BnDisplayEventConnection\u0026gt; EventThread::createEventConnection() const { return new Connection(const_cast\u0026lt;EventThread*\u0026gt;(this)); } Connection::stealReceiveChannel /* * stealReceiveChannel() returns a BitTube to receive events from. Only the receive file * descriptor of outChannel will be initialized, and this effectively \u0026#34;steals\u0026#34; the receive * channel from the remote end (such that the remote end can only use its send channel). */ status_t EventThread::Connection::stealReceiveChannel(gui::BitTube* outChannel) { outChannel-\u0026gt;setReceiveFd(mChannel.moveReceiveFd()); return NO_ERROR; } Connection::requestNextVsync void EventThread::Connection::requestNextVsync() { mEventThread-\u0026gt;requestNextVsync(this); } requestNextVsync void EventThread::requestNextVsync(const sp\u0026lt;EventThread::Connection\u0026gt;\u0026amp; connection) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); if (mResyncWithRateLimitCallback) { mResyncWithRateLimitCallback();//callback resyncWithRateLimit in SurfaceFlinger  } if (connection-\u0026gt;count \u0026lt; 0) { connection-\u0026gt;count = 0; mCondition.notify_all(); } } frameworks/native/services/surfaceflinger/EventControlThread.cpp\nEventControlThread setVsyncEnabled void EventControlThread::setVsyncEnabled(bool enabled) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); mVsyncEnabled = enabled; mCondition.notify_all(); } threadMain // Unfortunately std::unique_lock gives warnings with -Wthread-safety void EventControlThread::threadMain() NO_THREAD_SAFETY_ANALYSIS { auto keepRunning = true; auto currentVsyncEnabled = false; while (keepRunning) { mSetVSyncEnabled(currentVsyncEnabled); std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mMutex); mCondition.wait(lock, [this, currentVsyncEnabled, keepRunning]() NO_THREAD_SAFETY_ANALYSIS { return currentVsyncEnabled != mVsyncEnabled || keepRunning != mKeepRunning; }); currentVsyncEnabled = mVsyncEnabled; keepRunning = mKeepRunning; } } frameworks/native/libs/gui/DisplayEventReceiver.cpp\nDisplayEventReceiver sendEvents ssize_t DisplayEventReceiver::sendEvents(gui::BitTube* dataChannel, Event const* events, size_t count) { return gui::BitTube::sendObjects(dataChannel, events, count); } frameworks/native/libs/gui/BitTube.cpp\nBitTube // Socket buffer size. The default is typically about 128KB, which is much larger than we really // need. So we make it smaller. static const size_t DEFAULT_SOCKET_BUFFER_SIZE = 4 * 1024; BitTube() BitTube::BitTube(size_t bufsize) { init(bufsize, bufsize); } init void BitTube::init(size_t rcvbuf, size_t sndbuf) { int sockets[2]; if (socketpair(AF_UNIX, SOCK_SEQPACKET, 0, sockets) == 0) { size_t size = DEFAULT_SOCKET_BUFFER_SIZE; setsockopt(sockets[0], SOL_SOCKET, SO_RCVBUF, \u0026amp;rcvbuf, sizeof(rcvbuf)); setsockopt(sockets[1], SOL_SOCKET, SO_SNDBUF, \u0026amp;sndbuf, sizeof(sndbuf)); // since we don\u0026#39;t use the \u0026#34;return channel\u0026#34;, we keep it small...  setsockopt(sockets[0], SOL_SOCKET, SO_SNDBUF, \u0026amp;size, sizeof(size)); setsockopt(sockets[1], SOL_SOCKET, SO_RCVBUF, \u0026amp;size, sizeof(size)); fcntl(sockets[0], F_SETFL, O_NONBLOCK); fcntl(sockets[1], F_SETFL, O_NONBLOCK); mReceiveFd.reset(sockets[0]); mSendFd.reset(sockets[1]); } else { mReceiveFd.reset(); ALOGE(\u0026#34;BitTube: pipe creation failed (%s)\u0026#34;, strerror(errno)); } } sendObjects ssize_t BitTube::sendObjects(BitTube* tube, void const* events, size_t count, size_t objSize) { const char* vaddr = reinterpret_cast\u0026lt;const char*\u0026gt;(events); ssize_t size = tube-\u0026gt;write(vaddr, count * objSize); // ALOGE_IF(size\u0026lt;0, \u0026#34;error %d sending %d events\u0026#34;, size, count);  return size \u0026lt; 0 ? size : size / static_cast\u0026lt;ssize_t\u0026gt;(objSize); } write ssize_t BitTube::write(void const* vaddr, size_t size) { ssize_t err, len; do { len = ::send(mSendFd, vaddr, size, MSG_DONTWAIT | MSG_NOSIGNAL); // cannot return less than size, since we\u0026#39;re using SOCK_SEQPACKET  err = len \u0026lt; 0 ? errno : 0; } while (err == EINTR); return err == 0 ? len : -err; } recvObjects ssize_t BitTube::recvObjects(BitTube* tube, void* events, size_t count, size_t objSize) { char* vaddr = reinterpret_cast\u0026lt;char*\u0026gt;(events); ssize_t size = tube-\u0026gt;read(vaddr, count * objSize); // ALOGE_IF(size\u0026lt;0, \u0026#34;error %d receiving %d events\u0026#34;, size, count);  return size \u0026lt; 0 ? size : size / static_cast\u0026lt;ssize_t\u0026gt;(objSize); } rameworks/native/services/surfaceflinger/DispSync.cpp\nDispSync // mThread is the thread from which all the callbacks are called.  sp\u0026lt;DispSyncThread\u0026gt; mThread; init void DispSync::init(bool hasSyncFramework, int64_t dispSyncPresentTimeOffset) { mThread-\u0026gt;run(\u0026#34;DispSync\u0026#34;, PRIORITY_URGENT_DISPLAY + PRIORITY_MORE_FAVORABLE); reset(); beginResync(); } addResyncSample bool DispSync::addResyncSample(nsecs_t timestamp) { updateModelLocked(); } updateModelLocked void DispSync::updateModelLocked() { mThread-\u0026gt;updateModel(mPeriod, mPhase, mReferenceTime); } frameworks/native/services/surfaceflinger/DispSync.cpp\nDispSyncThread class DispSyncThread : public Thread { Vector\u0026lt;EventListener\u0026gt; mEventListeners; } threadLoop virtual bool threadLoop() { status_t err; nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); while (true) { targetTime = computeNextEventTimeLocked(now); bool isWakeup = false; if (now \u0026lt; targetTime) { if (kTraceDetailedInfo) ATRACE_NAME(\u0026#34;DispSync waiting\u0026#34;); if (targetTime == INT64_MAX) { ALOGV(\u0026#34;[%s] Waiting forever\u0026#34;, mName); err = mCond.wait(mMutex); } else { ALOGV(\u0026#34;[%s] Waiting until %\u0026#34; PRId64, mName, ns2us(targetTime)); err = mCond.waitRelative(mMutex, targetTime - now); } } callbackInvocations = gatherCallbackInvocationsLocked(now); if (callbackInvocations.size() \u0026gt; 0) { fireCallbackInvocations(callbackInvocations); } } } gatherCallbackInvocationsLocked Vector\u0026lt;CallbackInvocation\u0026gt; gatherCallbackInvocationsLocked(nsecs_t now) { Vector\u0026lt;CallbackInvocation\u0026gt; callbackInvocations; nsecs_t onePeriodAgo = now - mPeriod; for (size_t i = 0; i \u0026lt; mEventListeners.size(); i++) { nsecs_t t = computeListenerNextEventTimeLocked(mEventListeners[i], onePeriodAgo); if (t \u0026lt; now) { CallbackInvocation ci; ci.mCallback = mEventListeners[i].mCallback; ci.mEventTime = t; callbackInvocations.push(ci); mEventListeners.editItemAt(i).mLastEventTime = t; } } return callbackInvocations; } fireCallbackInvocations void fireCallbackInvocations(const Vector\u0026lt;CallbackInvocation\u0026gt;\u0026amp; callbacks) { for (size_t i = 0; i \u0026lt; callbacks.size(); i++) { callbacks[i].mCallback-\u0026gt;onDispSyncEvent(callbacks[i].mEventTime); } } updateModel void updateModel(nsecs_t period, nsecs_t phase, nsecs_t referenceTime) { Mutex::Autolock lock(mMutex); mPeriod = period; mPhase = phase; mReferenceTime = referenceTime; mCond.signal(); } frameworks/native/services/surfaceflinger/MessageQueue.h\nMessageQueue namespace impl { class MessageQueue final : public android::MessageQueue { class Handler : public MessageHandler { enum { eventMaskInvalidate = 0x1, eventMaskRefresh = 0x2, eventMaskTransaction = 0x4 }; MessageQueue\u0026amp; mQueue; int32_t mEventMask; public: explicit Handler(MessageQueue\u0026amp; queue) : mQueue(queue), mEventMask(0) {} virtual void handleMessage(const Message\u0026amp; message); void dispatchRefresh(); void dispatchInvalidate(); }; friend class Handler; sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; sp\u0026lt;Looper\u0026gt; mLooper; android::EventThread* mEventThread; sp\u0026lt;IDisplayEventConnection\u0026gt; mEvents; gui::BitTube mEventTube; sp\u0026lt;Handler\u0026gt; mHandler; } init void MessageQueue::init(const sp\u0026lt;SurfaceFlinger\u0026gt;\u0026amp; flinger) { mFlinger = flinger; mLooper = new Looper(true);//system/core/include/utils/Looper.h  mHandler = new Handler(*this); } setEventThread void MessageQueue::setEventThread(android::EventThread* eventThread) { if (mEventThread == eventThread) { return; } if (mEventTube.getFd() \u0026gt;= 0) { mLooper-\u0026gt;removeFd(mEventTube.getFd()); } mEventThread = eventThread; mEvents = eventThread-\u0026gt;createEventConnection(); mEvents-\u0026gt;stealReceiveChannel(\u0026amp;mEventTube); mLooper-\u0026gt;addFd(mEventTube.getFd(), 0, Looper::EVENT_INPUT, MessageQueue::cb_eventReceiver, this); } waitMessage void MessageQueue::waitMessage() { do { IPCThreadState::self()-\u0026gt;flushCommands(); int32_t ret = mLooper-\u0026gt;pollOnce(-1); switch (ret) { case Looper::POLL_WAKE: case Looper::POLL_CALLBACK: continue; case Looper::POLL_ERROR: ALOGE(\u0026#34;Looper::POLL_ERROR\u0026#34;); continue; case Looper::POLL_TIMEOUT: // timeout (should not happen)  continue; default: // should not happen  ALOGE(\u0026#34;Looper::pollOnce() returned unknown status %d\u0026#34;, ret); continue; } } while (true); } cb_eventReceiver int MessageQueue::cb_eventReceiver(int fd, int events, void* data) { MessageQueue* queue = reinterpret_cast\u0026lt;MessageQueue*\u0026gt;(data); return queue-\u0026gt;eventReceiver(fd, events); } eventReceiver int MessageQueue::eventReceiver(int /*fd*/, int /*events*/) { ssize_t n; DisplayEventReceiver::Event buffer[8]; while ((n = DisplayEventReceiver::getEvents(\u0026amp;mEventTube, buffer, 8)) \u0026gt; 0) { for (int i = 0; i \u0026lt; n; i++) { if (buffer[i].header.type == DisplayEventReceiver::DISPLAY_EVENT_VSYNC) { mHandler-\u0026gt;dispatchInvalidate(); break; } } } return 1; } Handler::dispatchInvalidate void MessageQueue::Handler::dispatchInvalidate() { if ((android_atomic_or(eventMaskInvalidate, \u0026amp;mEventMask) \u0026amp; eventMaskInvalidate) == 0) { mQueue.mLooper-\u0026gt;sendMessage(this, Message(MessageQueue::INVALIDATE)); } } Handler::handleMessage void MessageQueue::Handler::handleMessage(const Message\u0026amp; message) { switch (message.what) { case INVALIDATE: android_atomic_and(~eventMaskInvalidate, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; case REFRESH: android_atomic_and(~eventMaskRefresh, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; } } frameworks/native/services/surfaceflinger/DisplayHardware/HWC2.h\nComposerCallback // Implement this interface to receive hardware composer events. // // These callback functions will generally be called on a hwbinder thread, but // when first registering the callback the onHotplugReceived() function will // immediately be called on the thread calling registerCallback(). // // All calls receive a sequenceId, which will be the value that was supplied to // HWC2::Device::registerCallback(). It\u0026#39;s used to help differentiate callbacks // from different hardware composer instances. class ComposerCallback { public: virtual void onHotplugReceived(int32_t sequenceId, hwc2_display_t display, Connection connection) = 0; virtual void onRefreshReceived(int32_t sequenceId, hwc2_display_t display) = 0; virtual void onVsyncReceived(int32_t sequenceId, hwc2_display_t display, int64_t timestamp) = 0; virtual ~ComposerCallback() = default; };  frameworks/native/libs/gui/IGraphicBufferProducer.cpp\nIGraphicBufferProducer.cpp queueBuffer virtual status_t queueBuffer(int buf, const QueueBufferInput\u0026amp; input, QueueBufferOutput* output) { Parcel data, reply; data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor()); data.writeInt32(buf); data.write(input); status_t result = remote()-\u0026gt;transact(QUEUE_BUFFER, data, \u0026amp;reply); return result; } onTransact status_t BnGraphicBufferProducer::onTransact( uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags) { switch(code) { case QUEUE_BUFFER: { CHECK_INTERFACE(IGraphicBufferProducer, data, reply); int buf = data.readInt32(); QueueBufferInput input(data); QueueBufferOutput output; status_t result = queueBuffer(buf, input, \u0026amp;output); reply-\u0026gt;write(output); reply-\u0026gt;writeInt32(result); return NO_ERROR; } │79 status_t MonitoredProducer::queueBuffer(int slot, const QueueBufferInput\u0026amp; input, │80 QueueBufferOutput* output) { \u0026gt;│81 return mProducer-\u0026gt;queueBuffer(slot, input, output); │82 } │83 │750 status_t BufferQueueProducer::queueBuffer(int slot, │751 const QueueBufferInput \u0026amp;input, QueueBufferOutput *output) { \u0026gt;│977 frameAvailableListener-\u0026gt;onFrameAvailable(item); │46 void BufferQueue::ProxyConsumerListener::onFrameAvailable( │47 const BufferItem\u0026amp; item) { │48 sp\u0026lt;ConsumerListener\u0026gt; listener(mConsumerListener.promote()); │49 if (listener != NULL) { \u0026gt;│50 listener-\u0026gt;onFrameAvailable(item); │51 } │52 } │104 void ConsumerBase::onFrameAvailable(const BufferItem\u0026amp; item) { │105 CB_LOGV(\u0026#34;onFrameAvailable\u0026#34;); │106 │107 sp\u0026lt;FrameAvailableListener\u0026gt; listener; │108 { // scope for the lock  │109 Mutex::Autolock lock(mFrameAvailableMutex); │110 listener = mFrameAvailableListener.promote(); │111 } │112 │113 if (listener != NULL) { │114 CB_LOGV(\u0026#34;actually calling onFrameAvailable\u0026#34;); \u0026gt;│115 listener-\u0026gt;onFrameAvailable(item); │116 } │117 } │723 // ---------------------------------------------------------------------------  │724 // Interface implementation for SurfaceFlingerConsumer::ContentsChangedListener  │725 // ---------------------------------------------------------------------------  │726 │727 void BufferLayer::onFrameAvailable(const BufferItem\u0026amp; item) { │728 // Add this buffer from our internal queue tracker  │729 { // Autolock scope B+\u0026gt;│730 Mutex::Autolock lock(mQueueItemLock); "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/webrtc/",
	"title": "webrtc",
	"tags": [],
	"description": "",
	"content": "webrtc 探索总结webrtc知识\n WebRTC源码下载和编译     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/webrtc/webrtc%E6%BA%90%E7%A0%81%E4%B8%8B%E8%BD%BD%E5%92%8C%E7%BC%96%E8%AF%91/",
	"title": "WebRTC源码下载和编译",
	"tags": [],
	"description": "",
	"content": "下载和编译步骤 1. GET DEPOT TOOLS LINUX / MAC Clone the depot_tools repository:\n$ git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git Add depot_tools to the front of your PATH (you will probably want to put this in your ~/.bashrc or ~/.zshrc). Assuming you cloned depot_tools to /path/to/depot_tools:\n$ export PATH=/path/to/depot_tools:$PATH 2. 安装python 2.7 3. Download Source Create a working directory, enter it, and run:\n$ fetch --nohooks webrtc_android //会在当前执行目录中下载文件到src文件夹 $ gclient sync 4. preCompile # 进入到src目录中 cd src # 执行完后，当前目录应为 /home/webrtc/webrtc_android/src # 下载 java相关命令和包，以及其他一些必要的软件和包 build/install-build-deps-android.sh # 执行过程中要输入 sudo 密码 5. Compile (需要在ubuntu英文语言环境下编译)\nGenerate projects using GN.\nMake sure your current working directory is src/ of your workspace. Then run:\ngn gen out/Debug --args='target_os=\u0026quot;android\u0026quot; target_cpu=\u0026quot;arm\u0026quot;' Compile using:\nautoninja -C out/Debug 其他注意点  无需通过fetch android下载chrome的android checkout，如果这么做，可能遇到错误：  error: RPC failed; curl 56 GnuTLS recv error (-9): A TLS packet with unexpected length was received. fatal: The remote end hung up unexpectedly fatal: early EOF fatal: index-pack failed 此时需要更新git版本为官网最新版本，重试fetch android\n下面的多个错误，原因是文件所在位置为macOS，必须放到ubuntu下，文件系统格式不同  OSError: [Errno 1] Operation not permitted\nError: Command \u0026lsquo;vpython src/build/download_nacl_toolchains.py \u0026ndash;mode nacl_core_sdk sync \u0026ndash;extract\u0026rsquo; returned non-zero exit status 1 in /media/psf/Home/git/demo/webrtc/android\nmakelink Operation not permitted\nCannot utime: Operation not permitted\n编译输出文件路径 \u0026hellip;./webrtc_android/src/out/Debug/lib.java/sdk/android/libwebrtc.jar\n\u0026hellip;/webrtc_android/src/out/Debug/libjingle_peerconnection_so.so\n\u0026hellip;/webrtc_android/src/out/Debug/lib.unstripped/libjingle_peerconnection_so.so\n\u0026hellip;/webrtc_android/src/out/Debug/clang_x64/protoc\n关于HackWebRTC native debug项目 https://github.com/HackWebRTC/webrtc/tree/hack_webrtc/sdk/android_gradle\n该项目组在脚本中配置固定的文件路径导致无法在新版webrtc源码上编译\nCMakeLists.txt\n${WEBRTC_REPO}/sdk/libs/ffmpeg/lib/Android/${ANDROID_ABI}/libswresample.a  Libjingle_peerconnection_so.so位于项目项目webrtc/prebuild_libs/中 动态配置java source依赖目录  // def newProjectRoot = \u0026#34;$webrtc_repo/sdk/android_gradle\u0026#34;  def newProjectRoot = rootProject.rootDir sourceSets.main.java.srcDirs = [ \u0026#34;$newProjectRoot/../android/api\u0026#34;, \u0026#34;$newProjectRoot/../android/src/java\u0026#34;, \u0026#34;$newProjectRoot/../../rtc_base/java/src\u0026#34;, \u0026#34;$newProjectRoot/../../modules/audio_device/android/java/src\u0026#34;, \u0026#34;$newProjectRoot/webrtc/src/main/java\u0026#34;, ]  androidCompileSdkVersion = 30   配置本地native调试目录:\n  # the absolute path of WebRTC Android checkout, please use exactly the same commit as this repo. webrtc_repo=/Users/qianpianpian/git/demo/webrtc/webrtc_android/src # the relative path of where generated source file is put, relative to `webrtc_repo`. webrtc_build_dir=out/android_studio # the relative path of Android sdk jar, relative to `webrtc_repo`. android_jar=third_party/android_sdk/public/platforms/android-30/android.jar # the absolute path of Python 2.x executable py2=/usr/bin/python # the absolute path of protoc executable, see README about how to create it. protoc=/Users/qianpianpian/git/demo/webrtc/webrtcOut/protoc 参考 https://webrtc.googlesource.com/src/+/refs/heads/master/docs/native-code/android/index.md\nUbuntu18.04 从头开始编译 Android Native WebRTC\nhttps://github.com/mail2chromium/Compile_WebRTC_Library_For_Android\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/ui/webview/webview/",
	"title": "WebView",
	"tags": [],
	"description": "",
	"content": "WebView优化 一般来说，WebView 渲染需要经过下面几个步骤\n 解析 HTML 文件 加载 JavaScript 和 CSS 文件 解析并执行 JavaScript 构建 DOM 结构 加载图片等资源 页面加载完毕  而 loadFinish 实际上是在页面加载完毕阶段，而 DOM 构建完成时页面结构就已经基本渲染完成，所以从用户真实体验的角度出发，我们以 DOM 结构构建完成（即 domReady）的时间点作为页面加载完成时间点。\n模板优化 模板拆分 原先:\n优化后:\n还能不能更快一点呢？当然能！\n为了提高页面的加载速度，客户端通过一定的策略去预加载新闻数据，这样在理想状态下用户进入页面时看到页面时就可以直接使用缓存的数据，用户在看新闻的时候可以实现完全离线化，避免受到网络的影响。\n模板预热 模板复用 网络优化 CDN 加速 渲染优化 服务端预渲染 客户端渲染 所以在详情页中，我们会将图片和视频等非文字内容通过原生组件的方式放在客户端进行渲染，既可以提高渲染效率，也可以减少不必要的流量消耗。\n原生化渲染还有一个好处，图片越来越成为文章体验的重要部分，对于多图文章，我们在 Feed 页面也可以智能加载详情页需要的图片，增加用户的文章首屏体验。\n白屏优化 而在 Android 中，我们采用的是自研内核 WebView，也会遇到一些奇奇怪怪的坑。\n 多线程读模板文件问题，WebView 在运行中会读取的文件模板，如果此时另外一个线程同时更新模板文件时，就出现了模板加载问题，所以需要保证模板加载的原子性 Render 卡死问题，内核是一个比较复杂的逻辑，内部渲染极少数情况也会出现 Render 卡死问题，但是在详情页整体用户的量级下，即使只有十万分之一的可能，对用户来说也是一个比较大的问题，此时我们会从业务上做白屏监控进行重试  当然不管是 iOS 和 Android， WebView 加载的逻辑都比较复杂，有时候怎么重试也无法成功，这个时候我们会直接降级到加载线上的详情页，优先保证用户的体验。\n总结 限于篇幅原因，我们还做了很多其他事情，包括请求精简，push 文章预拉取，数据注入的方式优化等等，也做了很多其他的方向的探索，这里不做展开，希望有机会能再分享给大家。\n最后总结一下我们在优化详情页打开速度之后的一些想法\n 数据很重要，我们在优化加载速度之前做的第一件事情其实是建立了一个详情页的数据看板，只有通过数据我们才能真正了解目前线上用户的现状，从真实用户的体验中找到瓶颈和优化点。 用户体验优先，优化方案有很多，除了加载速度之外，还需要从整体应用体验出发，选择对用户最佳的方案 追求极致，其实最开始的优化是比较简单的，但是越到后面越难，需要一点点抠细节，才能达到极致的用户体验  参考 WebView性能、体验分析与优化\n今日头条品质优化 - 图文详情页秒开实践\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/ui/webview/",
	"title": "webview",
	"tags": [],
	"description": "",
	"content": "webview 探索总结webview知识\n WebView     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B8%B2%E6%9F%93/widget/",
	"title": "Widget",
	"tags": [],
	"description": "",
	"content": "graph LR State--\u0026gt;|持有|Widget Element--\u0026gt;|持有|State Element--\u0026gt;|持有|Widget Build 触发State.build时机 graph LR after_initState--\u0026gt;State.build after_didUpdateWidget--\u0026gt;State.build after_setState--\u0026gt;State.build after_dependencyChange--\u0026gt;State.build after_deactiveAndReinsertIntoTree--\u0026gt;State.build 挂载树核心方法调用 graph LR mount--\u0026gt;_firstBuild--\u0026gt;reBuild--\u0026gt;performRebuild--\u0026gt;|1|build--\u0026gt;|stateless|StatelessWidget.build build--\u0026gt;|stateful|State.build buildOwner.buildScope--\u0026gt;reBuild performRebuild--\u0026gt;|2|updateChild updateChild--\u0026gt;|优先更新而非重新创建child|canUpdate{\u0026quot;canUpdate?\u0026quot;}--\u0026gt;|yes|child.updateWithNewWidget; canUpdate--\u0026gt;|no|inflateWidgetForNewChildElement--\u0026gt;mount 挂载树挂载过程 graph TB parentElement--\u0026gt;|2:performRebuild|currentElement currentElement--\u0026gt;|1:mount|parentElement currentElement--\u0026gt;|3:buildMyWidget|currentElement currentElement--\u0026gt;|4:newWidget.createElement|childElement childElement--\u0026gt;|5:mount|currentElement 类设计 State.setState //State\u0026lt;T extends StatefulWidget\u0026gt; /** setState方法标记对应的element需要build 如果当前位于一帧内例如点击(input处理+动画+drawFrame)，在调用setState方法之后会触发drawFrame进而触发reBuild 如果当前不位于一帧内，则会策划一次frame*/ @protected void setState(VoidCallback fn) { final dynamic result = fn() as dynamic; _element.markNeedsBuild(); } Element.markNeedsBuild /// Marks the element as dirty and adds it to the global list of widgets to  /// rebuild in the next frame.  ///  /// Since it is inefficient to build an element twice in one frame,  /// applications and widgets should be structured so as to only mark  /// widgets dirty during event handlers before the frame begins, not during  /// the build itself.  void markNeedsBuild() { _dirty = true; owner.scheduleBuildFor(this); } //WidgetsBinding.initInstance时会初始化buildOwner.onBuildScheduled = _handleBuildScheduled;  /// Adds an element to the dirty elements list so that it will be rebuilt /// when [WidgetsBinding.drawFrame] calls [buildScope]. void scheduleBuildFor(Element element) { if (!_scheduledFlushDirtyElements \u0026amp;\u0026amp; onBuildScheduled != null) { //如果当前不在一次整体frame流程中，则会调用onBuildScheduled,eq:_handleBuildScheduled策划一次frame  _scheduledFlushDirtyElements = true; onBuildScheduled(); } _dirtyElements.add(element); element._inDirtyList = true; } void _handleBuildScheduled() { ensureVisualUpdate();//may call scheduleFrame(); } 调用WidgetsBinding.drawFrame\ndrawframe\nbuildOwner.buildScope(renderViewElement) /// Establishes a scope for updating the widget tree, and calls the given  /// `callback`, if any. Then, builds all the elements that were marked as  /// dirty using [scheduleBuildFor], in depth order.  /// The dirty list is processed after `callback` returns, building all the  /// elements that were marked as dirty using [scheduleBuildFor], in depth  /// order. If elements are marked as dirty while this method is running, they  /// must be deeper than the `context` node, and deeper than any  /// previously-built node in this pass.  /// To flush the current dirty list without performing any other work, this  /// function can be called with no callback. This is what the framework does  /// each frame, in [WidgetsBinding.drawFrame].  void buildScope(Element context, [ VoidCallback callback ]) { callback(); _dirtyElements.sort(Element._sort); _dirtyElementsNeedsResorting = false; int dirtyCount = _dirtyElements.length; int index = 0; while (index \u0026lt; dirtyCount) { _dirtyElements[index].rebuild(); } } Elements.rebuild /// Called by the [BuildOwner] when [BuildOwner.scheduleBuildFor] has been  /// called to mark this element dirty, by [mount] when the element is first  /// built, and by [update] when the widget has changed.  void rebuild() { performRebuild(); } ComponentElements.performRebuild /// Calls the [StatelessWidget.build] method of the [StatelessWidget] object  /// (for stateless widgets) or the [State.build] method of the [State] object  /// (for stateful widgets) and then updates the widget tree.  ///  /// Called automatically during [mount] to generate the first build, and by  /// [rebuild] when the element needs updating.  @override void performRebuild() { built = build(); _child = updateChild(_child, built, slot); } ComponentElements.build /// Subclasses should override this function to actually call the appropriate  /// `build` function (e.g., [StatelessWidget.build] or [State.build]) for  /// their widget.  @protected Widget build(); Element.updateChild /// Update the given child with the given new configuration.  ///  /// This method is the core of the widgets system. It is called each time we  /// are to add, update, or remove a child based on an updated configuration.  // | | **newWidget == null** | **newWidget != null** |  /// | :-----------------: | :--------------------- | :---------------------- |  /// | **child == null** | Returns null. | Returns new [Element]. |  /// | **child != null** | Old child is removed, returns null. | Old child updated if possible, returns child or new [Element].  @protected Element updateChild(Element child, Widget newWidget, dynamic newSlot) { if(canUpdate) { child.update(newWidget); } else { return inflateWidget(newWidget, newSlot); } } Element.update(newWidget) inflateWidget /// Create an element for the given widget and add it as a child of this element in the given slot. @protected Element inflateWidget(Widget newWidget, dynamic newSlot) { final Element newChild = newWidget.createElement(); newChild.mount(this, newSlot); return newChild; } newChild.mount(this, newSlot); //Element /// Add this element to the tree in the given slot of the given parent.  ///  /// The framework calls this function when a newly created element is added to  /// the tree for the first time. Use this method to initialize state that  /// depends on having a parent. State that is independent of the parent can  /// more easily be initialized in the constructor.  ///  /// This method transitions the element from the \u0026#34;initial\u0026#34; lifecycle state to  /// the \u0026#34;active\u0026#34; lifecycle state. @mustCallSuper void mount(Element parent, dynamic newSlot) { _parent = parent; _slot = newSlot; _depth = _parent != null ? _parent.depth + 1 : 1; _active = true; if (parent != null) // Only assign ownership if the parent is non-null  _owner = parent.owner; if (widget.key is GlobalKey) { final GlobalKey key = widget.key; key._register(this); } _updateInheritance(); assert(() { _debugLifecycleState = _ElementLifecycle.active; return true; }()); } //ComponentElement @override void mount(Element parent, dynamic newSlot) { super.mount(parent, newSlot); _firstBuild(); } RenderObjectElement.mount @override void mount(Element parent, dynamic newSlot) { super.mount(parent, newSlot); _renderObject = widget.createRenderObject(this);//main  attachRenderObject(newSlot);//main  _dirty = false; } widget.createRenderObject \u0026hellip;\u0026hellip;\nattachRenderObject @override void attachRenderObject(dynamic newSlot) { _slot = newSlot; _ancestorRenderObjectElement = _findAncestorRenderObjectElement(); _ancestorRenderObjectElement?.insertChildRenderObject(renderObject, newSlot);//main  final ParentDataElement\u0026lt;RenderObjectWidget\u0026gt; parentDataElement = _findAncestorParentDataElement(); if (parentDataElement != null) _updateParentData(parentDataElement.widget); } RenderObjectElement _findAncestorRenderObjectElement() { Element ancestor = _parent; while (ancestor != null \u0026amp;\u0026amp; ancestor is! RenderObjectElement) ancestor = ancestor._parent; return ancestor; } ParentDataElement\u0026lt;RenderObjectWidget\u0026gt; _findAncestorParentDataElement() { Element ancestor = _parent; while (ancestor != null \u0026amp;\u0026amp; ancestor is! RenderObjectElement) { if (ancestor is ParentDataElement\u0026lt;RenderObjectWidget\u0026gt;) return ancestor; ancestor = ancestor._parent; } return null; } RenderObjectElement.update(renderObjectWidget) @override void update(covariant RenderObjectWidget newWidget) { super.update(newWidget); widget.updateRenderObject(this, renderObject);//内部可能会markNeedsLayout或markNeedsPaint进行更新重绘  _dirty = false; } PipelineOwner.flushLayout \u0026ndash;\u0026gt;RenderObject._layoutWithoutResize;\nvoid _layoutWithoutResize() { performLayout(); markNeedsSemanticsUpdate(); markNeedsPaint(); } RenderFlex.performLayout /// Displays its children in a one-dimensional array. @override void performLayout() { while (child != null) { //配置childParentData供自己使用  final FlexParentData childParentData = child.parentData; //对child进行layout  child.layout(innerConstraints, parentUsesSize: true); allocatedSize += _getMainSize(child); crossSize = math.max(crossSize, _getCrossSize(child)); } //设置自己的size size = constraints.constrain(Size(idealSize, crossSize)); RenderObject.layout /// The parent\u0026#39;s [performLayout] method should call the [layout] of all its  /// children unconditionally. void layout(Constraints constraints, { bool parentUsesSize = false }) { RenderObject relayoutBoundary; if (!parentUsesSize || sizedByParent || constraints.isTight || parent is! RenderObject) { relayoutBoundary = this; } else { final RenderObject parent = this.parent; relayoutBoundary = parent._relayoutBoundary; } if (!_needsLayout \u0026amp;\u0026amp; constraints == _constraints \u0026amp;\u0026amp; relayoutBoundary == _relayoutBoundary) { return; } _constraints = constraints; _relayoutBoundary = relayoutBoundary; if (sizedByParent) { performResize(); } performLayout();//single child\u0026#39;s performLayout  markNeedsSemanticsUpdate(); _needsLayout = false; markNeedsPaint();//main RenderObject.markNeedsPaint /// Mark this render object as having changed its visual appearance.  /// * [RepaintBoundary], to scope a subtree of render objects to their own  /// layer, thus limiting the number of nodes that [markNeedsPaint] must mark  /// dirty.  void markNeedsPaint() { if (_needsPaint) return; _needsPaint = true; if (isRepaintBoundary) { // If we always have our own layer, then we can just repaint  // ourselves without involving any other nodes.  assert(_layer is OffsetLayer); if (owner != null) { owner._nodesNeedingPaint.add(this); owner.requestVisualUpdate(); } } else if (parent is RenderObject) { final RenderObject parent = this.parent; parent.markNeedsPaint(); } else { if (owner != null) owner.requestVisualUpdate(); } } PipelineOwner.flushCompositingBits \u0026ndash;\u0026gt;renderObject._updateCompositingBits();\nrenderObject._updateCompositingBits void _updateCompositingBits() { if (!_needsCompositingBitsUpdate) return; final bool oldNeedsCompositing = _needsCompositing; _needsCompositing = false; visitChildren((RenderObject child) { child._updateCompositingBits(); if (child.needsCompositing) _needsCompositing = true; }); if (isRepaintBoundary || alwaysNeedsCompositing) _needsCompositing = true; if (oldNeedsCompositing != _needsCompositing) markNeedsPaint(); _needsCompositingBitsUpdate = false; } PipelineOwner.flushPaint \u0026ndash;\u0026gt;PaintingContext.repaintCompositedChild(renderObject)\nPaintingContext.repaintCompositedChild(renderObject) /// A place to paint.  ///  /// Rather than holding a canvas directly, [RenderObject]s paint using a painting  /// context. The painting context has a [Canvas], which receives the  /// individual draw operations, and also has functions for painting child  /// render objects.  PaintingContext{} static void repaintCompositedChild(RenderObject child, { bool debugAlsoPaintedParent = false }) { assert(child._needsPaint); _repaintCompositedChild( child, debugAlsoPaintedParent: debugAlsoPaintedParent, ); } static void _repaintCompositedChild( RenderObject child, { bool debugAlsoPaintedParent = false, PaintingContext childContext, }) { assert(child.isRepaintBoundary); OffsetLayer childLayer = child._layer; if (childLayer == null) { child._layer = childLayer = OffsetLayer(); } else { assert(childLayer is OffsetLayer); childLayer.removeAllChildren(); } childContext ??= PaintingContext(child._layer, child.paintBounds); child._paintWithContext(childContext, Offset.zero);//main  // Double-check that the paint method did not replace the layer (the first  // check is done in the [layer] setter itself).  assert(identical(childLayer, child._layer)); childContext.stopRecordingIfNeeded(); paint总结 graph LR _paintWithContext--\u0026gt;paint--\u0026gt;|isParent|PaintingContext.paintChild--\u0026gt;|child.isRepaintBoundary|stopRecordingAnd_compositeChild PaintingContext.paintChild--\u0026gt;|notBoundary|child._paintWithContext--\u0026gt;_paintWithContext paint--\u0026gt;|isChild|paintIntoCanvas renderObject._paintWithContext void _paintWithContext(PaintingContext context, Offset offset) { if (_needsLayout) return; _needsPaint = false; paint(context, offset);//main } RenderFlex.paint @override void paint(PaintingContext context, Offset offset) { if (!_hasOverflow) { defaultPaint(context, offset);//main  return; } // There\u0026#39;s no point in drawing the children if we\u0026#39;re empty.  if (size.isEmpty) return; // We have overflow. Clip it.  context.pushClipRect(needsCompositing, offset, Offset.zero \u0026amp; size, defaultPaint); paintOverflowIndicator(context, offset, Offset.zero \u0026amp; size, overflowChildRect, overflowHints: debugOverflowHints); /// Paints each child by walking the child list forwards.  void defaultPaint(PaintingContext context, Offset offset) { ChildType child = firstChild; while (child != null) { final ParentDataType childParentData = child.parentData; context.paintChild(child, childParentData.offset + offset);//main  child = childParentData.nextSibling; } } PaintingContext.paintChild /// Paint a child [RenderObject].  ///  /// If the child has its own composited layer, the child will be composited  /// into the layer subtree associated with this painting context. Otherwise,  /// the child will be painted into the current PictureLayer for this context.  /// 只有绘制边界节点才有layer。render tree的根节点renderView也是一个绘制边界 //将所有的repaintBoundary按照tree结构生成LayerTree，并用各自的offsetLayer去绘制自己和自己的children  void paintChild(RenderObject child, Offset offset) { if (child.isRepaintBoundary) { stopRecordingIfNeeded(); _compositeChild(child, offset); } else { child._paintWithContext(this, offset); } stopRecordingIfNeeded @protected @mustCallSuper void stopRecordingIfNeeded() { if (!_isRecording) return; _currentLayer.picture = _recorder.endRecording();//main  _currentLayer = null; _recorder = null; _canvas = null; } /// Finishes recording graphical operations.  ///  /// Returns a picture containing the graphical operations that have been  /// recorded thus far. After calling this function, both the picture recorder  /// and the canvas objects are invalid and cannot be used further.  Picture endRecording() { if (_canvas == null) throw StateError(\u0026#39;PictureRecorder did not start recording.\u0026#39;); final Picture picture = Picture._(); _endRecording(picture); _canvas!._recorder = null; _canvas = null; return picture; } _compositeChild void _compositeChild(RenderObject child, Offset offset) { // Create a layer for our child, and paint the child into it.  // paint 是 deepest first，因此tree底部的一条repaint boundary绘制完成后，_needsPaint为false，不会重复绘制，但要求对应的layer挂到layerTree上  if (child._needsPaint) { repaintCompositedChild(child, debugAlsoPaintedParent: true); } assert(child._layer is OffsetLayer); final OffsetLayer childOffsetLayer = child._layer; childOffsetLayer.offset = offset; appendLayer(child._layer); } @protected void appendLayer(Layer layer) { assert(!_isRecording); layer.remove(); _containerLayer.append(layer); } RenderImage.paint @override void paint(PaintingContext context, Offset offset) { paintImage( canvas: context.canvas, rect: offset \u0026amp; size, image: _image!, ...... ); } PaintingContext.canvas @override Canvas get canvas { if (_canvas == null) _startRecording(); return _canvas!; } _startRecording void _startRecording() { assert(!_isRecording); _currentLayer = PictureLayer(estimatedBounds);//main  _recorder = ui.PictureRecorder(); _canvas = Canvas(_recorder); _containerLayer.append(_currentLayer); } /// Records a [Picture] containing a sequence of graphical operations. /// /// To begin recording, construct a [Canvas] to record the commands. /// To end recording, use the [PictureRecorder.endRecording] method. class PictureRecorder extends NativeFieldWrapperClass2 { /// An object representing a sequence of recorded graphical operations. /// /// To create a [Picture], use a [PictureRecorder]. /// /// A [Picture] can be placed in a [Scene] using a [SceneBuilder], via /// the [SceneBuilder.addPicture] method. A [Picture] can also be /// drawn into a [Canvas], using the [Canvas.drawPicture] method. @pragma(\u0026#39;vm:entry-point\u0026#39;) class Picture extends NativeFieldWrapperClass2 { canvas.drawXxx void paintImage({ required Canvas canvas, required Rect rect, required ui.Image image, ...... }) { ...... canvas.save(); canvas.drawImageRect(image, sourceRect, destinationRect, paint); canvas.restore(); renderView.compositeFrame /// The root of the render tree. RenderView { /// Uploads the composited layer tree to the engine.  /// Actually causes the output of the rendering pipeline to appear on screen.  void compositeFrame() { final ui.SceneBuilder builder = ui.SceneBuilder(); final ui.Scene scene = layer.buildScene(builder);//main  if (automaticSystemUiAdjustment) _updateSystemChrome(); _window.render(scene);//执行render()将layer树发送给GPU线程,main  scene.dispose(); } layer.buildScene(builder) ContainerLayer.buildScene /// A composited layer that has a list of children. // ContainerLayer  /// Consider this layer as the root and build a scene (a tree of layers)  /// in the engine.  // The reason this method is in the `ContainerLayer` class rather than  // `PipelineOwner` or other singleton level is because this method can be used  // both to render the whole layer tree (e.g. a normal application frame) and  // to render a subtree (e.g. `OffsetLayer.toImage`).  ui.Scene buildScene(ui.SceneBuilder builder) { updateSubtreeNeedsAddToScene(); addToScene(builder); // Clearing the flag _after_ calling `addToScene`, not _before_. This is  // because `addToScene` calls children\u0026#39;s `addToScene` methods, which may  // mark this layer as dirty.  _needsAddToScene = false; final ui.Scene scene = builder.build(); return scene; } @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { addChildrenToScene(builder, layerOffset); } /// Uploads all of this layer\u0026#39;s children to the engine. void addChildrenToScene(ui.SceneBuilder builder, [ Offset childOffset = Offset.zero ]) { Layer child = firstChild; while (child != null) { if (childOffset == Offset.zero) { child._addToSceneWithRetainedRendering(builder); } else { child.addToScene(builder, childOffset); } child = child.nextSibling; } } PictureLayer.addToScene @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { builder.addPicture(layerOffset, picture, isComplexHint: isComplexHint, willChangeHint: willChangeHint);//main  } OffsetLayer.addToScene /// A layer that is displayed at an offset from its parent layer. OffsetLayer { @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { // Skia has a fast path for concatenating scale/translation only matrices.  // Hence pushing a translation-only transform layer should be fast. For  // retained rendering, we don\u0026#39;t want to push the offset down to each leaf  // node. Otherwise, changing an offset layer on the very high level could  // cascade the change to too many leaves.  engineLayer = builder.pushOffset(layerOffset.dx + offset.dx, layerOffset.dy + offset.dy, oldLayer: _engineLayer);//main  addChildrenToScene(builder);//main  builder.pop(); } } TransformLayer.addToScene /// A composited layer that applies a given transformation matrix to its  /// children.  ///  /// This class inherits from [OffsetLayer] to make it one of the layers that  /// can be used at the root of a [RenderObject] hierarchy.  TransformLayer { @override void addToScene(ui.SceneBuilder builder, [ Offset layerOffset = Offset.zero ]) { assert(transform != null); _lastEffectiveTransform = transform; final Offset totalOffset = offset + layerOffset; if (totalOffset != Offset.zero) { _lastEffectiveTransform = Matrix4.translationValues(totalOffset.dx, totalOffset.dy, 0.0) ..multiply(_lastEffectiveTransform); } engineLayer = builder.pushTransform(_lastEffectiveTransform.storage, oldLayer: _engineLayer); addChildrenToScene(builder);//main  builder.pop(); } } _window.render(scene)总结 _window.render(scene);//执行render()将layer树发送给GPU线程,main  /** Updates the view\u0026#39;s rendering on the GPU with the newly provided Scene. To record graphical operations, 1. first create a PictureRecorder, then construct a Canvas, passing that PictureRecorder to its constructor. 2. After issuing all the graphical operations, 3. call the PictureRecorder.endRecording function on the PictureRecorder to obtain the final Picture that represents the issued graphical operations. 4. Next, create a SceneBuilder, and add the Picture to it using SceneBuilder.addPicture. 5. With the SceneBuilder.build method you can then obtain a Scene object, which you can 6. display to the user via this render function. **/ void render(Scene scene) =\u0026gt; _render(scene, this); void _render(Scene scene, FlutterView view) native \u0026#39;PlatformConfiguration_render\u0026#39;; graph LR subgraph PictureRcorder _startRecording--\u0026gt;canvas.drawXxx--\u0026gt;endRecording end subgraph SceneBuidler endRecording--\u0026gt;|Picture|buildScene(\u0026quot;layer.buildScene(scenebuilder)\u0026quot;) end subgraph render buildScene--\u0026gt;|Scene|_window.render end _window.render中surface相关细节\n其他 RenderObject markNeedsLayout void markNeedsLayout() { if (_needsLayout) { return; } if (_relayoutBoundary != this) { markParentNeedsLayout(); } else { _needsLayout = true; if (owner != null) { owner._nodesNeedingLayout.add(this); owner.requestVisualUpdate(); } } dropChild @override void dropChild(RenderObject child) { super.dropChild(child); markNeedsLayout(); markNeedsCompositingBitsUpdate(); markNeedsSemanticsUpdate(); } SemanticsConfiguration /// Describes the semantic information associated with the owning  /// [RenderObject].  ///  /// The information provided in the configuration is used to generate the  /// semantics tree.  SemanticsConfiguration "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/workmanager/workmanager/",
	"title": "WorkManager",
	"tags": [],
	"description": "",
	"content": "https://developer.android.com/topic/libraries/architecture/workmanager/\nAndroid新技术之从Service到WorkManager\n使用 WorkManager 处理需要立刻执行的后台任务\nWorkManager 流程分析和源码解析 | 开发者说·DTalk\nWorkManager 的特点与适用场景 特点   保证任务一定会被执行 WorkManager 有自己的数据库，每一个任务的信息与任务状态，都会保存在本地数据库中。所以即使程序没有在运行，或者在设备重启等情况下，WorkManager 依然可以保证任务的执行，只是不保证任务立即被执行。\n  合理使用设备资源 在执行很多周期性或非立即执行的任务时，WorkManager 提供我们 API，帮助我们合理利用设备资源，避免不必要的内存，流量，电量等消耗。\n  适用场景  可延迟进行的任务 a.满足某些条件才执行的任务，如需要在充电时才执行的任务。 b.用户无感知或可延迟感知的任务，如同步配置信息，同步资源，同步通讯录等。 定期重复性任务，但时效性要求不高的，如定期 log 上传，数据备份等。 退出应用后还应继续执行的未完成任务。  WorkManager 的使用 WorkManager 的使用非常简单，分为如下几个步骤:\n 创建一个后台任务 Worker。 定义 WorkRequest，配置运行任务的方式和时间。 将任务提交给系统处理。 观察 Worker 的进度或状态。  WorkManager 流程分析与源码解析 这个章节将会从以下几个方面梳理 WorkManager 的流程与源码:\n 创建 a. WorkManager的初始化 b. WorkRequest的创建 非约束条件任务的执行 带约束条件任务的执行  4.1 创建 首先梳理一下 WorkManager 的初始化过程。\n4.1.1. WorkManager 的初始化 WorkManagerInitializer 在默认的情况下，WorkManager 并不是在我们调用 WorkManager.getInstance() 时创建的。通过反编译一下 apk，会发现在 AndroidManifest 文件中注册了名为 WorkManagerInitializer 的 ContentProvider。因此 WorkManager 在 app 冷启动的时候已经被创建。\n//AndroidManifest.xml \u0026lt;provider android:name=\u0026#34;androidx.work.impl.WorkManagerInitializer\u0026#34; android:exported=\u0026#34;false\u0026#34; android:multiprocess=\u0026#34;true\u0026#34; android:authorities=\u0026#34;com.jandroid.multivideo.workmanager-init\u0026#34; android:directBootAware=\u0026#34;false\u0026#34; /\u0026gt; WorkManagerInitializer 的 onCreate() 方法:\n//WorkManagerInitializer public boolean onCreate() { // Initialize WorkManager with the default configuration.  WorkManager.initialize(getContext(), new Configuration.Builder().build()); return true; } 我们继续看 initialize() 的实现，由于 WorkManager 是个抽象类，真正的构造方法是在他的子类 WorkManagerImpl 实现的:\nWorkManagerImpl //WorkManagerImpl @RestrictTo(RestrictTo.Scope.LIBRARY_GROUP) public static void initialize(@NonNull Context context, @NonNull Configuration configuration) { synchronized (sLock) { if (sDelegatedInstance != null \u0026amp;\u0026amp; sDefaultInstance != null) { throw new IllegalStateException(\u0026#34;WorkManager is already initialized. Did you \u0026#34; + \u0026#34;try to initialize it manually without disabling \u0026#34; + \u0026#34;WorkManagerInitializer? See \u0026#34; + \u0026#34;WorkManager#initialize(Context, Configuration) or the class level \u0026#34; + \u0026#34;Javadoc for more information.\u0026#34;); } if (sDelegatedInstance == null) { context = context.getApplicationContext(); if (sDefaultInstance == null) { sDefaultInstance = new WorkManagerImpl( context, configuration, new WorkManagerTaskExecutor(configuration.getTaskExecutor())); } sDelegatedInstance = sDefaultInstance; } } } 此时 sDelegatedInstance 为 null，WorkManager 会先创建一个默认的 WorkManagerTaskExecutor 对象，用来执行 WorkManager 的任务。之后创建一个 WorkManagerImpl 对象:\n//WorkManagerImpl  @RestrictTo(RestrictTo.Scope.LIBRARY_GROUP) public WorkManagerImpl( @NonNull Context context, @NonNull Configuration configuration, @NonNull TaskExecutor workTaskExecutor) { this(context, configuration, workTaskExecutor, context.getResources().getBoolean(R.bool.workmanager_test_configuration)); } //WorkManagerImpl  @RestrictTo(RestrictTo.Scope.LIBRARY_GROUP) public WorkManagerImpl( @NonNull Context context, @NonNull Configuration configuration, @NonNull TaskExecutor workTaskExecutor, boolean useTestDatabase) { this(context, configuration, workTaskExecutor, WorkDatabase.create( context.getApplicationContext(), workTaskExecutor.getBackgroundExecutor(), useTestDatabase) ); } WorkDatabase.create WorkManager 在此时创建了数据库。WorkDatabase.create() 将任务列表序列化到本地，记录每一个任务的属性，执行条件，执行顺序及执行状态等。从而保证任务在冷启动或硬件重启后，可以根据条件继续执行。接着看 this() 的实现:\n//WorkManagerImpl  @RestrictTo(RestrictTo.Scope.LIBRARY_GROUP) public WorkManagerImpl( @NonNull Context context, @NonNull Configuration configuration, @NonNull TaskExecutor workTaskExecutor, @NonNull WorkDatabase database) { Context applicationContext = context.getApplicationContext(); Logger.setLogger(new Logger.LogcatLogger(configuration.getMinimumLoggingLevel())); List\u0026lt;Scheduler\u0026gt; schedulers = createSchedulers(applicationContext, workTaskExecutor); Processor processor = new Processor( context, configuration, workTaskExecutor, database, schedulers); internalInit(context, configuration, workTaskExecutor, database, schedulers, processor); } 到这里有三个重要的初始化步骤。分别是 createSchedulers() 来根据 Build Version 创建不同的 Schedulers 进行任务调度，Processor() 用来管理 Schedulers 的执行，和 internalInit() 真正的初始化。先看 createSchedulers() 的实现:\ncreateSchedulers //WorkManagerImpl  @RestrictTo(RestrictTo.Scope.LIBRARY_GROUP) @NonNull public List\u0026lt;Scheduler\u0026gt; createSchedulers( @NonNull Context context, @NonNull TaskExecutor taskExecutor) { return Arrays.asList( Schedulers.createBestAvailableBackgroundScheduler(context, this), // Specify the task executor directly here as this happens before internalInit.  // GreedyScheduler creates ConstraintTrackers and controllers eagerly.  new GreedyScheduler(context, taskExecutor, this)); } return 一个 Scheduler 数组。其中 GreedyScheduler() 是常驻的，用来执行没有任何约束的非周期性的任务。接下来看 createBestAvailableBackgroundScheduler() 的实现。\n//Scheduler  @NonNull static Scheduler createBestAvailableBackgroundScheduler( @NonNull Context context, @NonNull WorkManagerImpl workManager) { Scheduler scheduler; if (Build.VERSION.SDK_INT \u0026gt;= WorkManagerImpl.MIN_JOB_SCHEDULER_API_LEVEL) { scheduler = new SystemJobScheduler(context, workManager); setComponentEnabled(context, SystemJobService.class, true); Logger.get().debug(TAG, \u0026#34;Created SystemJobScheduler and enabled SystemJobService\u0026#34;); } else { scheduler = tryCreateGcmBasedScheduler(context); if (scheduler == null) { scheduler = new SystemAlarmScheduler(context); setComponentEnabled(context, SystemAlarmService.class, true); Logger.get().debug(TAG, \u0026#34;Created SystemAlarmScheduler\u0026#34;); } } return scheduler; } 这段代码对 build version 进行了判断。若 \u0026gt;=23，则返回 SystemJobScheduler()，即利用 JobScheduler 进行任务管理。\u0026lt;23 的时候先尝试使用 GcmScheduler 进行管理。若无法创建 GcmScheduler 则返回 SystemAlarmScheduler() 使用 AlamManager 进行任务管理。返回的这个 Scheduler 是用来执行周期性，或者有约束性的任务。由此可见，WorkManager 创建了两个 Scheduler，分别为执行非约束非周期性任务的 GreedyScheduler，和执行约束性周期性任务的 SystemJobScheduler/GcmBasedScheduler/SystemAlarmScheduler。\n这几种 Scheduler 的构造和执行之后再分析。\nProcessor 之后初始化 Processor。Processor 存储了 Configuration，TaskExecutor，WorkDatabase，schedulers 等，用来在适当的时机进行任务调度。再来看\ninternalInit(): //WorkManagerImpl  private void internalInit(@NonNull Context context, @NonNull Configuration configuration, @NonNull TaskExecutor workTaskExecutor, @NonNull WorkDatabase workDatabase, @NonNull List\u0026lt;Scheduler\u0026gt; schedulers, @NonNull Processor processor) { context = context.getApplicationContext(); mContext = context; mConfiguration = configuration; mWorkTaskExecutor = workTaskExecutor; mWorkDatabase = workDatabase; mSchedulers = schedulers; mProcessor = processor; mPreferenceUtils = new PreferenceUtils(workDatabase); mForceStopRunnableCompleted = false; // Checks for app force stops.  mWorkTaskExecutor.executeOnBackgroundThread(new ForceStopRunnable(context, this)); } 记录了 Configuration，TaskExecutor，WorkDatabase，schedulers，Processor 等。然后我们看最后一行执行语句，启动了一个 ForceStopRunnable，这个 Runnable 是干什么用的呢？直接看 run() 的实现:\n//ForceStopRunnable  @Override public void run() { // Migrate the database to the no-backup directory if necessary.  WorkDatabasePathHelper.migrateDatabase(mContext); // Clean invalid jobs attributed to WorkManager, and Workers that might have been  // interrupted because the application crashed (RUNNING state).  Logger.get().debug(TAG, \u0026#34;Performing cleanup operations.\u0026#34;); try { boolean needsScheduling = cleanUp(); if (shouldRescheduleWorkers()) { Logger.get().debug(TAG, \u0026#34;Rescheduling Workers.\u0026#34;); mWorkManager.rescheduleEligibleWork(); // Mark the jobs as migrated.  mWorkManager.getPreferenceUtils().setNeedsReschedule(false); } else if (isForceStopped()) { Logger.get().debug(TAG, \u0026#34;Application was force-stopped, rescheduling.\u0026#34;); mWorkManager.rescheduleEligibleWork(); } else if (needsScheduling) { Logger.get().debug(TAG, \u0026#34;Found unfinished work, scheduling it.\u0026#34;); Schedulers.schedule( mWorkManager.getConfiguration(), mWorkManager.getWorkDatabase(), mWorkManager.getSchedulers()); } mWorkManager.onForceStopRunnableCompleted(); } catch (SQLiteCantOpenDatabaseException | SQLiteDatabaseCorruptException | SQLiteAccessPermException exception) { // ForceStopRunnable is usually the first thing that accesses a database (or an app\u0026#39;s  // internal data directory). This means that weird PackageManager bugs are attributed  // to ForceStopRunnable, which is unfortunate. This gives the developer a better error  // message.  String message = \u0026#34;The file system on the device is in a bad state. WorkManager cannot access \u0026#34; + \u0026#34;the app\u0026#39;s internal data store.\u0026#34;; Logger.get().error(TAG, message, exception); throw new IllegalStateException(message, exception); } } 这段代码的实现细节先不做深究。但是很明显，这个 Runnable 的作用就是在 WorkManager 初始化过程中，发现了未完成的，需要重新执行的任务，或者 app 被强制 kill 的情况下，直接对 Scheduler 进行调度。到此，一个 WorkManager 的初始化流程就完成了。\n总结:   WorkManager 的初始化是在 app 冷启动后，由 WorkManagerInitializer 这个 ContentProvider 执行的。\n  初始化过程包含了 Configuration，WorkManagerTaskExecutor，WorkDatabase，Schedulers，Processor 等的初始化过程。\n  Schedulers 有两个。\n(1) GreedyScheduler: 执行没有任何约束的非周期性的任务。\n(2) SystemJobScheduler/GcmBasedScheduler/SystemAlarmScheduler: 执行周期性或者有约束性的任务。优先返回 SystemJobScheduler，在 build version 小于 23 的情况下先尝试返回 GcmBasedScheduler，若返回为空再返回 SystemAlarmScheduler。\n  初始化的最后，会根据情况找到需要被执行的任务进行调度执行。\n  WorkManager 的初始化流程图:\n4.1.2. WorkRequest 的创建 总结: WorkRequest 的创建是为了持有三个重要的成员变量。分别是:\n mId: 由 UUID 生成的任务 id。 mWorkSpec: 每个任务的属性。 mTags: 每个任务的标签。  WorkRequest 创建的流程图\n4.2 非约束条件任务的执行过程 总结:   在 WorkManager 执行了 enqueue() 后，创建 WorkContinuationImpl 对象执行 enqueue() 方法。\n  WorkContinuationImpl 持有的 EnqueueRunnable 对象将任务添加到 db，并交给 Schedulers 去调度。\n  Schedulers 将任务交给每一个 Scheduler 去处理。在我们的示例中，GreedyScheduler 会先处理这个任务。\n  GreedyScheduler 经过一系列判断后，调用 WorkManager 的 startWork() 方法执行这种一次性，非延迟，无约束的任务。\n  WorkManager 持有的 StartWorkRunnable 对象会将任务交给 Processor 去处理，执行 startWork() 方法。\n  Processor 创建一个 WorkerWrapper 对象，由它去调用 Worker 的 startWork() 方法，执行我们自定义 worker 的任务，并返回相应的 result。\n  任务完成后，WorkerWrapper 会根据 result 对任务状态，db 等进行更新，然后 schedule 下一个任务。\n  WorkManager 任务执行流程图:\n4.3 带约束的任务的执行过程 4.3.1. SystemJobScheduler (Build Version \u0026gt;=23) SystemJobScheduler 使用的是 JobScheduler 来调度执行任务。由于 JobScheduler 的实现过程分析不在本文的讨论范围(总体是binder调用到SystemServer创建的JobSchedulerService进行处理)，所以只看 WorkManager 是如何使用 JobScheduler 进行任务调度的。通常 JobScheduler 的使用步骤如下:\n 创建 JobService 配置 JobInfo 执行  4.3.2. SystemAlarmScheduler (Build Version \u0026lt;23) SystemAlarmScheduler 使用的是 AlarmManager 来调度执行任务。由于 AlarmManager 的实现过程分析不在本文的讨论范围(也是SystemServer创建的AlarmManagerService)，所以只看 WorkManager 是如何使用 AlarmManager 进行任务调度的。反编译 apk 后，在 AndroidManifest 里有如下 receiver 注册:\n结语 WorkManager 的使用方法简单，但是在使用时还是要分清场景，适用于可延迟，周期性，必须执行完成的任务。通过对源码的分析，WorkManager 会针对不同 Android 版本的选择适当的策略。细致阅读代码，会发现针对指定的系统版本还有一些小的优化点。WorkManager 目前已经比较稳定，所以如果在场景适合的情况下，推荐使用 WorkManager 来代替原有的任务管理方案。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/workmanager/",
	"title": "workmanager",
	"tags": [],
	"description": "",
	"content": "workmanager 探索总结workmanager知识\n WorkManager     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/xcrash/",
	"title": "xcrash",
	"tags": [],
	"description": "",
	"content": "xcrash 探索总结xcrash知识\n 1xCrash原理     linuxApi     xCrashAnr     xCrashNativeCrash     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/xcrash/xcrashanr/",
	"title": "xCrashAnr",
	"tags": [],
	"description": "",
	"content": "总结 API level \u0026lt; 21 new FileObserver(\u0026quot;/data/anr/\u0026quot;, CLOSE_WRITE)\nAPI level \u0026gt;= 21 SIGQUIT\nELFFormat 图解 sequenceDiagram SystemServer-\u0026gt;\u0026gt;xcc_signal_trace_register:SIGQUIT xcc_signal_trace_register-\u0026gt;\u0026gt;xcc_signal_trace_register:xc_trace_handler xcc_signal_trace_register-\u0026gt;\u0026gt;xc_trace_dumper:write(xc_trace_notifier, \u0026amp;data, sizeof(data) Note over xcc_signal_trace_register,xc_trace_dumper:和xc_trace_dumper线程通过阻塞式io通信 xc_trace_dumper-\u0026gt;\u0026gt;xc_trace_dumper: xc_trace_load_symbols activate xc_trace_dumper xc_trace_dumper-\u0026gt;\u0026gt;xc_trace_dumper: xc_dl_create Note right of xc_trace_dumper: xc_dl_find_map_start,/proc/self/maps中找到指定so,设置self-\u0026gt;map_start Note right of xc_trace_dumper: xc_dl_file_open(open and mmap so) Note right of xc_trace_dumper: xc_dl_parse_elf xc_trace_dumper-\u0026gt;\u0026gt;xc_trace_dumper: xc_dl_sym Note right of xc_trace_dumper: read each .symtab/.dynsym, 需要str_offset作为index指向的str等于当前目标str,则找到Sym Note right of xc_trace_dumper: (void *)(self-\u0026gt;map_start + sym-\u0026gt;st_value - self-\u0026gt;load_bias); Note right of xc_trace_dumper: Runtime::DumpForSigQuit(std::ostream\u0026amp; os)，dump本进程anr信息 deactivate xc_trace_dumper xc_trace_dumper-\u0026gt;\u0026gt;xc_trace_dumper: xc_trace_libart_runtime_dump activate xc_trace_dumper deactivate xc_trace_dumper Note right of xc_trace_dumper: 转调动态链接的系统so方法处理 xc_trace_init //xc_trace.c int xc_trace_init(JNIEnv *env, int rethrow, unsigned int logcat_system_lines, unsigned int logcat_events_lines, unsigned int logcat_main_lines, int dump_fds, int dump_network_info) { //capture SIGQUIT only for ART  if(xc_common_api_level \u0026lt; 21) return 0; //is Android Lollipop (5.x)?  xc_trace_is_lollipop = ((21 == xc_common_api_level || 22 == xc_common_api_level) ? 1 : 0); //init for JNI callback  xc_trace_init_callback(env); //create event FD  if(0 \u0026gt; (xc_trace_notifier = eventfd(0, EFD_CLOEXEC))) return XCC_ERRNO_SYS; //register signal handler  if(0 != (r = xcc_signal_trace_register(xc_trace_handler))) goto err2;//main  //create thread for dump trace  if(0 != (r = pthread_create(\u0026amp;thd, NULL, xc_trace_dumper, NULL))) goto err1;//main  return 0; xcc_signal_trace_register //注册SIGQUIT信号处理函数 int xcc_signal_trace_register(void (*handler)(int, siginfo_t *, void *)) { } xc_trace_handler static void xc_trace_handler(int sig, siginfo_t *si, void *uc) { uint64_t data; if(xc_trace_notifier \u0026gt;= 0) { data = 1; XCC_UTIL_TEMP_FAILURE_RETRY(write(xc_trace_notifier, \u0026amp;data, sizeof(data)));//和xc_trace_dumper线程通过阻塞式io通信  } } xc_trace_dumper static void *xc_trace_dumper(void *arg) { while(1) { //block here, waiting for sigquit  XCC_UTIL_TEMP_FAILURE_RETRY(read(xc_trace_notifier, \u0026amp;data, sizeof(data))); ...... //write header info  if(0 != xc_trace_write_header(fd, trace_time)) goto end; xc_trace_load_symbols()//main xc_trace_check_address_valid() dup2(fd, STDERR_FILENO) \u0026lt; 0//接收下面的stderr输出  xc_trace_libart_runtime_dump(*xc_trace_libart_runtime_instance, xc_trace_libcpp_cerr);//转调动态链接的系统so方法处理，是系统在data/anr中trace.txt文件中当前pid的部分,main  skip: if(0 != xcc_util_write_str(fd, \u0026#34;\\n\u0026#34;XCC_UTIL_THREAD_END\u0026#34;\\n\u0026#34;)) goto end; //write other info  if(0 != xcc_util_record_logcat(fd, xc_common_process_id, xc_common_api_level, xc_trace_logcat_system_lines, xc_trace_logcat_events_lines, xc_trace_logcat_main_lines)) goto end; if(xc_trace_dump_fds) if(0 != xcc_util_record_fds(fd, xc_common_process_id)) goto end; if(xc_trace_dump_network_info) if(0 != xcc_util_record_network_info(fd, xc_common_process_id, xc_common_api_level)) goto end; if(0 != xcc_meminfo_record(fd, xc_common_process_id)) goto end; end: //close log file  xc_common_close_trace_log(fd); //rethrow SIGQUIT to ART Signal Catcher  if(xc_trace_rethrow) xc_trace_send_sigquit(); //JNI callback  //Do we need to implement an emergency buffer for disk exhausted?  if(NULL == xc_trace_cb_method) continue; if(NULL == (j_pathname = (*env)-\u0026gt;NewStringUTF(env, pathname))) continue; (*env)-\u0026gt;CallStaticVoidMethod(env, xc_common_cb_class, xc_trace_cb_method, j_pathname, NULL); XC_JNI_IGNORE_PENDING_EXCEPTION(); (*env)-\u0026gt;DeleteLocalRef(env, j_pathname); xc_trace_load_symbols static int xc_trace_load_symbols() {//动态链接系统so执行任务  if(xc_common_api_level \u0026gt;= 29) libcpp = xc_dl_create(XCC_UTIL_LIBCPP_APEX); if(NULL == libcpp \u0026amp;\u0026amp; NULL == (libcpp = xc_dl_create(XCC_UTIL_LIBCPP))) goto end; if(NULL == (xc_trace_libcpp_cerr = xc_dl_sym(libcpp, XCC_UTIL_LIBCPP_CERR))) goto end;//main  if(xc_common_api_level \u0026gt;= 29) libart = xc_dl_create(XCC_UTIL_LIBART_APEX); if(NULL == libart \u0026amp;\u0026amp; NULL == (libart = xc_dl_create(XCC_UTIL_LIBART))) goto end; if(NULL == (xc_trace_libart_runtime_instance = (void **)xc_dl_sym(libart, XCC_UTIL_LIBART_RUNTIME_INSTANCE))) goto end; if(NULL == (xc_trace_libart_runtime_dump = (xcc_util_libart_runtime_dump_t)xc_dl_sym(libart, XCC_UTIL_LIBART_RUNTIME_DUMP))) goto end;//main xc_dl_create xc_dl_t *xc_dl_create(const char *pathname) { xc_dl_t *self; if(NULL == (self = calloc(1, sizeof(xc_dl_t)))) return NULL; self-\u0026gt;fd = -1; self-\u0026gt;data = MAP_FAILED; TAILQ_INIT(\u0026amp;(self-\u0026gt;symbolsq)); //main  if(0 != xc_dl_find_map_start(self, pathname)) goto err;//确保/proc/self/maps中包含指定的so,设置self-\u0026gt;map_start  if(0 != xc_dl_file_open(self, pathname)) goto err;//mmap so  if(0 != xc_dl_parse_elf(self)) goto err; return self; err: xc_dl_destroy(\u0026amp;self); return NULL; } xc_dl_find_map_start static int xc_dl_find_map_start(xc_dl_t *self, const char *pathname) { FILE *f = NULL; char line[512]; uintptr_t offset; int pos; char *p; int r = XCC_ERRNO_NOTFND; if(NULL == (f = fopen(\u0026#34;/proc/self/maps\u0026#34;, \u0026#34;r\u0026#34;))) return XCC_ERRNO_SYS; while(fgets(line, sizeof(line), f)) { //main  if(2 != sscanf(line, \u0026#34;%\u0026#34;SCNxPTR\u0026#34;-%*\u0026#34;SCNxPTR\u0026#34; %*4s %\u0026#34;SCNxPTR\u0026#34; %*x:%*x %*d%n\u0026#34;, \u0026amp;(self-\u0026gt;map_start), \u0026amp;offset, \u0026amp;pos)) continue; if(0 != offset) continue; p = xcc_util_trim(line + pos); if(0 != strcmp(p, pathname)) continue; r = 0; //found  break; } fclose(f); return r; } xc_dl_file_open(open and mmap so) static int xc_dl_file_open(xc_dl_t *self, const char *pathname) { //open file,main  if(0 \u0026gt; (self-\u0026gt;fd = XCC_UTIL_TEMP_FAILURE_RETRY(open(pathname, O_RDONLY | O_CLOEXEC)))) return XCC_ERRNO_SYS; //get file size  //mmap the file,main  if(MAP_FAILED == (self-\u0026gt;data = (uint8_t *)mmap(NULL, self-\u0026gt;size, PROT_READ, MAP_PRIVATE, self-\u0026gt;fd, 0))) return XCC_ERRNO_SYS; return 0; } xc_dl_parse_elf static int xc_dl_parse_elf(xc_dl_t *self) { ElfW(Ehdr) *ehdr; ElfW(Phdr) *phdr; ElfW(Shdr) *shdr, *str_shdr; xc_dl_symbols_t *symbols; size_t i, cnt = 0; //get ELF header  if(NULL == (ehdr = xc_dl_file_get(self, 0, sizeof(ElfW(Ehdr))))) return XCC_ERRNO_FORMAT; //find load_bias in program headers  for(i = 0; i \u0026lt; ehdr-\u0026gt;e_phnum * ehdr-\u0026gt;e_phentsize; i += ehdr-\u0026gt;e_phentsize) { if(NULL == (phdr = xc_dl_file_get(self, ehdr-\u0026gt;e_phoff + i, sizeof(ElfW(Phdr))))) return XCC_ERRNO_FORMAT; //PT_LOAD The array element specifies a loadable segment  //p_offset: This member holds the offset from the beginning of the file at which the first byte of the segment resides  if((PT_LOAD == phdr-\u0026gt;p_type) \u0026amp;\u0026amp; (phdr-\u0026gt;p_flags \u0026amp; PF_X) \u0026amp;\u0026amp; (0 == phdr-\u0026gt;p_offset))//main  { //p_vaddr: This member holds the virtual address at which the first byte of the segment resides in memory.  self-\u0026gt;load_bias = phdr-\u0026gt;p_vaddr; break; } } //find symbol tables in section headers  for(i = ehdr-\u0026gt;e_shentsize; i \u0026lt; ehdr-\u0026gt;e_shnum * ehdr-\u0026gt;e_shentsize; i += ehdr-\u0026gt;e_shentsize) { if(NULL == (shdr = xc_dl_file_get(self, ehdr-\u0026gt;e_shoff + i, sizeof(ElfW(Shdr))))) return XCC_ERRNO_FORMAT; //SHT_SYMTAB This section holds a symbol table.  //SHT_DYNSYM This section holds a minimal set of dynamic linking symbols.  if(SHT_SYMTAB == shdr-\u0026gt;sh_type || SHT_DYNSYM == shdr-\u0026gt;sh_type)//main  { //sh_link This member holds a section header table index link  //e_shnum This member holds the number of entries in the section header table.  if(shdr-\u0026gt;sh_link \u0026gt;= ehdr-\u0026gt;e_shnum) continue; //e_shoff This member holds the section header table\u0026#39;s file offset in bytes  //e_shentsize This member holds a sections header\u0026#39;s size in bytes. A section header is one entry in the section header table; all entries are the same size.  // sh_type This member categorizes the section\u0026#39;s contents and semantics.  // SHT_STRTAB This section holds a string table. An object file may have multiple string table sections.  if(NULL == (str_shdr = xc_dl_file_get(self, ehdr-\u0026gt;e_shoff + shdr-\u0026gt;sh_link * ehdr-\u0026gt;e_shentsize, sizeof(ElfW(Shdr))))) return XCC_ERRNO_FORMAT; if(SHT_STRTAB != str_shdr-\u0026gt;sh_type) continue;//main  if(NULL == (symbols = malloc(sizeof(xc_dl_symbols_t)))) return XCC_ERRNO_NOMEM; //sh_offset This member\u0026#39;s value holds the byte offset from the beginning of the file to the first byte in the section  symbols-\u0026gt;sym_offset = shdr-\u0026gt;sh_offset; //sh_size This member holds the section\u0026#39;s size in bytes.  symbols-\u0026gt;sym_end = shdr-\u0026gt;sh_offset + shdr-\u0026gt;sh_size; //sh_entsize Some sections hold a table of fixed-sized entries, such as a symbol table.  //For such a section, this member gives the size in bytes for each entry.  symbols-\u0026gt;sym_entry_size = shdr-\u0026gt;sh_entsize; symbols-\u0026gt;str_offset = str_shdr-\u0026gt;sh_offset; symbols-\u0026gt;str_end = str_shdr-\u0026gt;sh_offset + str_shdr-\u0026gt;sh_size; TAILQ_INSERT_TAIL(\u0026amp;(self-\u0026gt;symbolsq), symbols, link);//main  cnt++; } } if(0 == cnt) return XCC_ERRNO_FORMAT; return 0; } xc_dl_sym void *xc_dl_sym(xc_dl_t *self, const char *symbol) { xc_dl_symbols_t *symbols; ElfW(Sym) *sym;//main  size_t offset, str_offset; char *str; TAILQ_FOREACH(symbols, \u0026amp;(self-\u0026gt;symbolsq), link)//main  { for(offset = symbols-\u0026gt;sym_offset; offset \u0026lt; symbols-\u0026gt;sym_end; offset += symbols-\u0026gt;sym_entry_size) { //read .symtab / .dynsym  if(NULL == (sym = xc_dl_file_get(self, offset, sizeof(ElfW(Sym))))) break;//main  // st_shndx Every symbol table entry is \u0026#34;defined\u0026#34; in relation to somesection.  // This member holds the relevant section header table index.  if(SHN_UNDEF == sym-\u0026gt;st_shndx) continue; //read .strtab / .dynstr  //st_name This member holds an index into the object file\u0026#39;s symbol string table,  //which holds character representations of the symbol names.  //If the value is nonzero, it represents a string table index that gives the symbol name.  //Otherwise, the symbol has no name.  str_offset = symbols-\u0026gt;str_offset + sym-\u0026gt;st_name;//main  if(str_offset \u0026gt;= symbols-\u0026gt;str_end) continue; if(NULL == (str = xc_dl_file_get_string(self, str_offset))) continue; //compare symbol name  if(0 != strcmp(symbol, str)) continue; //found  //st_value This member gives the value of the associated symbol.是地址  return (void *)(self-\u0026gt;map_start + sym-\u0026gt;st_value - self-\u0026gt;load_bias);//main  } } return NULL; } 其他 XCC_UTIL_LIBART_RUNTIME_DUMP:DumpForSigQuit xcc_util_libart_runtime_dump_t //对应libart.so中art/runtime/runtime.cc的方法Runtime::DumpForSigQuit(std::ostream\u0026amp; os)，dump本进程的anr信息 #define XCC_UTIL_LIBART_RUNTIME_DUMP \u0026#34;_ZN3art7Runtime14DumpForSigQuitERNSt3__113basic_ostreamIcNS1_11char_traitsIcEEEE\u0026#34;  //symbol address in libc++.so and libart.so static void *xc_trace_libcpp_cerr = NULL; typedef void (*xcc_util_libart_runtime_dump_t)(void *runtime, void *ostream); "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/xcrash/xcrashnativecrash/",
	"title": "xCrashNativeCrash",
	"tags": [],
	"description": "",
	"content": "原理时序图 sequenceDiagram CrashProcess-\u0026gt;\u0026gt;CrashProcess: xcc_signal_crash_register Note right of CrashProcess: 迭代注册每种信号监听,接收到信号调用xc_crash_signal_handler CrashProcess-\u0026gt;\u0026gt;CrashProcess: xc_crash_signal_handler(int sig, siginfo_t *si, void *uc) CrashProcess-\u0026gt;\u0026gt;DumperProcess: pid_t dumper_pid = xc_crash_fork(xc_crash_exec_dumper); CrashProcess-\u0026gt;\u0026gt;CrashProcess: waitpid(dumper_pid,...) Note right of CrashProcess: wait the crash dumper process terminated DumperProcess-\u0026gt;\u0026gt;DumperProcess: xc_crash_exec_dumper(void *arg) DumperProcess-\u0026gt;\u0026gt;DumperProcess: execl执行libxcrash_dumper.so.main activate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_process_create activate DumperProcess Note right of DumperProcess: 统计崩溃进程所有线程信息到队列xcd_core_proc-\u0026gt;thds，通过读取/proc/%d/task\u0026quot;, self-\u0026gt;pid实现 deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;CrashProcess: xcd_process_suspend_threads(xcd_core_proc) activate DumperProcess Note over DumperProcess,CrashProcess: suspend all threads in Crash process,通过系统调用ptrace(PTRACE_ATTACH, self-\u0026gt;tid,...))实现 deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_process_load_info activate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcc_util_get_process_name activate DumperProcess Note right of DumperProcess: /proc/%d/cmdline,pid deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_thread_load_info(\u0026amp;(thd-\u0026gt;t)); activate DumperProcess Note right of DumperProcess: 迭代每个线程,load thread info,\u0026quot;/proc/%d/comm\u0026quot;, tid,设置tname deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_thread_load_regs(\u0026amp;(thd-\u0026gt;t)); activate DumperProcess Note right of DumperProcess: 迭代每个非crash线程,load thread regs,ptrace(PTRACE_GETREGSET, self-\u0026gt;tid...),设置regs deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_thread_load_regs_from_ucontext(\u0026amp;(thd-\u0026gt;t), self-\u0026gt;uc); activate DumperProcess Note right of DumperProcess: crash线程,load thread regs,从uc中获取并设置regs deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_maps_create(\u0026amp;(self-\u0026gt;maps), self-\u0026gt;pid) activate DumperProcess Note right of DumperProcess: load maps,\u0026quot;/proc/%d/maps\u0026quot;, pid,设置maps deactivate DumperProcess deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_process_record activate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: 记录写入崩溃线程信息 activate DumperProcess DumperProcess-\u0026gt;\u0026gt;DumperProcess: xcd_thread_load_frames activate DumperProcess Note right of DumperProcess: 循环每次读取一个栈帧信息,根据rel_pc等信息在xcd_elf_step时更新regs_copy deactivate DumperProcess deactivate DumperProcess deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;CrashProcess: xcd_process_resume_threads(xcd_core_proc) activate DumperProcess Note over DumperProcess,CrashProcess: resume all threads in the process，遍历线程ptrace(PTRACE_DETACH, self-\u0026gt;tid,) deactivate DumperProcess deactivate DumperProcess DumperProcess-\u0026gt;\u0026gt;CrashProcess: _exit dumper process XCrash.init public static synchronized int init(Context ctx, InitParameters params) { //save log dir  if (TextUtils.isEmpty(params.logDir)) { params.logDir = ctx.getFilesDir() + \u0026#34;/tombstones\u0026#34;; } XCrash.logDir = params.logDir; //init file manager  FileManager.getInstance().initialize( params.logDir, params.javaLogCountMax, params.nativeLogCountMax, params.anrLogCountMax, params.placeholderCountMax, params.placeholderSizeKb, params.logFileMaintainDelayMs); //init java crash handler  if (params.enableJavaCrashHandler) { JavaCrashHandler.getInstance().initialize( pid, processName, appId, params.appVersion, params.logDir, params.javaRethrow, params.javaLogcatSystemLines, params.javaLogcatEventsLines, params.javaLogcatMainLines, params.javaDumpFds, params.javaDumpNetworkInfo, params.javaDumpAllThreads, params.javaDumpAllThreadsCountMax, params.javaDumpAllThreadsWhiteList, params.javaCallback); } //init ANR handler (API level \u0026lt; 21)  if (params.enableAnrHandler \u0026amp;\u0026amp; Build.VERSION.SDK_INT \u0026lt; 21) { AnrHandler.getInstance().initialize( ctx, pid, processName, appId, params.appVersion, params.logDir, params.anrCheckProcessState, params.anrLogcatSystemLines, params.anrLogcatEventsLines, params.anrLogcatMainLines, params.anrDumpFds, params.anrDumpNetworkInfo, params.anrCallback); } //init native crash handler / ANR handler (API level \u0026gt;= 21)  int r = Errno.OK; if (params.enableNativeCrashHandler || (params.enableAnrHandler \u0026amp;\u0026amp; Build.VERSION.SDK_INT \u0026gt;= 21)) { r = NativeHandler.getInstance().initialize(//main  ctx, params.libLoader, appId, params.appVersion, params.logDir, params.enableNativeCrashHandler, params.nativeRethrow, params.nativeLogcatSystemLines, params.nativeLogcatEventsLines, params.nativeLogcatMainLines, params.nativeDumpElfHash, params.nativeDumpMap, params.nativeDumpFds, params.nativeDumpNetworkInfo, params.nativeDumpAllThreads, params.nativeDumpAllThreadsCountMax, params.nativeDumpAllThreadsWhiteList, params.nativeCallback, params.enableAnrHandler \u0026amp;\u0026amp; Build.VERSION.SDK_INT \u0026gt;= 21, params.anrRethrow, params.anrCheckProcessState, params.anrLogcatSystemLines, params.anrLogcatEventsLines, params.anrLogcatMainLines, params.anrDumpFds, params.anrDumpNetworkInfo, params.anrCallback); } //maintain tombstone and placeholder files in a background thread with some delay  FileManager.getInstance().maintain(); return r; xc_jni_init //xc_jni.c static jint xc_jni_init(JNIEnv *env, jobject thiz, jint api_level, jstring os_version, jstring abi_list, jstring manufacturer, jstring brand, jstring model, jstring build_fingerprint, jstring app_id, jstring app_version, jstring app_lib_dir, jstring log_dir, jboolean crash_enable, jboolean crash_rethrow, jint crash_logcat_system_lines, jint crash_logcat_events_lines, jint crash_logcat_main_lines, jboolean crash_dump_elf_hash, jboolean crash_dump_map, jboolean crash_dump_fds, jboolean crash_dump_network_info, jboolean crash_dump_all_threads, jint crash_dump_all_threads_count_max, jobjectArray crash_dump_all_threads_whitelist, jboolean trace_enable, jboolean trace_rethrow, jint trace_logcat_system_lines, jint trace_logcat_events_lines, jint trace_logcat_main_lines, jboolean trace_dump_fds, jboolean trace_dump_network_info) { //common init  if(0 != xc_common_init((int)api_level, //main  c_os_version, c_abi_list, c_manufacturer, c_brand, c_model, c_build_fingerprint, c_app_id, c_app_version, c_app_lib_dir, c_log_dir)) goto clean; if(crash_enable)//对应native crash  { //crash init  r_crash = xc_crash_init(env,//main  crash_rethrow ? 1 : 0, (unsigned int)crash_logcat_system_lines, (unsigned int)crash_logcat_events_lines, (unsigned int)crash_logcat_main_lines, crash_dump_elf_hash ? 1 : 0, crash_dump_map ? 1 : 0, crash_dump_fds ? 1 : 0, crash_dump_network_info ? 1 : 0, crash_dump_all_threads ? 1 : 0, (unsigned int)crash_dump_all_threads_count_max, c_crash_dump_all_threads_whitelist, c_crash_dump_all_threads_whitelist_len); } if(trace_enable)//对应anr  { //trace init  r_trace = xc_trace_init(env, trace_rethrow ? 1 : 0, (unsigned int)trace_logcat_system_lines, (unsigned int)trace_logcat_events_lines, (unsigned int)trace_logcat_main_lines, trace_dump_fds ? 1 : 0, trace_dump_network_info ? 1 : 0); } xc_common_init //xc_common.c int xc_common_init(int api_level, const char *os_version, const char *abi_list, const char *manufacturer, const char *brand, const char *model, const char *build_fingerprint, const char *app_id, const char *app_version, const char *app_lib_dir, const char *log_dir) { //check or create log directory  if(0 != (r = xc_util_mkdirs(log_dir))) goto err; //create prepared FD for FD exhausted case  xc_common_open_prepared_fd(1); xc_common_open_prepared_fd(0); return 0; } xc_crash_init int xc_crash_init(JNIEnv *env, int rethrow, unsigned int logcat_system_lines, unsigned int logcat_events_lines, unsigned int logcat_main_lines, int dump_elf_hash, int dump_map, int dump_fds, int dump_network_info, int dump_all_threads, unsigned int dump_all_threads_count_max, const char **dump_all_threads_whitelist, size_t dump_all_threads_whitelist_len) { //init the local unwinder for fallback mode  xcc_unwind_init(xc_common_api_level);//main  //init for JNI callback  xc_crash_init_callback(env);//main  //struct info passed to the dumper process  memset(\u0026amp;xc_crash_spot, 0, sizeof(xcc_spot_t)); xc_crash_spot.api_level = xc_common_api_level; xc_crash_spot.crash_pid = xc_common_process_id; xc_crash_spot.start_time = xc_common_start_time; xc_crash_spot.time_zone = xc_common_time_zone; xc_crash_spot.logcat_system_lines = logcat_system_lines; xc_crash_spot.logcat_events_lines = logcat_events_lines; xc_crash_spot.logcat_main_lines = logcat_main_lines; xc_crash_spot.dump_elf_hash = dump_elf_hash; xc_crash_spot.dump_map = dump_map; xc_crash_spot.dump_fds = dump_fds; xc_crash_spot.dump_network_info = dump_network_info; xc_crash_spot.dump_all_threads = dump_all_threads; xc_crash_spot.dump_all_threads_count_max = dump_all_threads_count_max; xc_crash_spot.os_version_len = strlen(xc_common_os_version); xc_crash_spot.kernel_version_len = strlen(xc_common_kernel_version); xc_crash_spot.abi_list_len = strlen(xc_common_abi_list); xc_crash_spot.manufacturer_len = strlen(xc_common_manufacturer); xc_crash_spot.brand_len = strlen(xc_common_brand); xc_crash_spot.model_len = strlen(xc_common_model); xc_crash_spot.build_fingerprint_len = strlen(xc_common_build_fingerprint); xc_crash_spot.app_id_len = strlen(xc_common_app_id); xc_crash_spot.app_version_len = strlen(xc_common_app_version); xc_crash_init_dump_all_threads_whitelist(dump_all_threads_whitelist, dump_all_threads_whitelist_len); //register signal handler  return xcc_signal_crash_register(xc_crash_signal_handler);//main xcc_unwind_init //xcc_unwind.c void xcc_unwind_init(int api_level) { #if defined(__arm__) || defined(__i386__)  if(api_level \u0026gt;= 16 \u0026amp;\u0026amp; api_level \u0026lt;= 20) { xcc_unwind_libcorkscrew_init();//main  } #endif  if(api_level \u0026gt;= 21 \u0026amp;\u0026amp; api_level \u0026lt;= 23) { xcc_unwind_libunwind_init();//main  } } xcc_unwind_libcorkscrew_init //xcc_unwind_libcorkscrew.c void xcc_unwind_libcorkscrew_init(void) { if(NULL == (libcorkscrew = dlopen(\u0026#34;libcorkscrew.so\u0026#34;, RTLD_NOW))) return; //获取libcorkscrew.so中的以下方法加载到内存中的地址,main  if(NULL == (unwind_backtrace_signal_arch = (t_unwind_backtrace_signal_arch)dlsym(libcorkscrew, \u0026#34;unwind_backtrace_signal_arch\u0026#34;))) goto err; if(NULL == (acquire_my_map_info_list = (t_acquire_my_map_info_list)dlsym(libcorkscrew, \u0026#34;acquire_my_map_info_list\u0026#34;))) goto err; release_my_map_info_list = (t_release_my_map_info_list)dlsym(libcorkscrew, \u0026#34;release_my_map_info_list\u0026#34;); if(NULL == (get_backtrace_symbols = (t_get_backtrace_symbols)dlsym(libcorkscrew, \u0026#34;get_backtrace_symbols\u0026#34;))) goto err; free_backtrace_symbols = (t_free_backtrace_symbols)dlsym(libcorkscrew, \u0026#34;free_backtrace_symbols\u0026#34;); return; err: dlclose(libcorkscrew); libcorkscrew = NULL; } xcc_unwind_libunwind_init //xcc_unwind_libunwind.c void xcc_unwind_libunwind_init(void) { if(NULL == (libunwind = dlopen(\u0026#34;libunwind.so\u0026#34;, RTLD_NOW))) return; //main  if(NULL == (unw_init_local = (t_unw_init_local)dlsym(libunwind, \u0026#34;_U\u0026#34;UNW_TARGET\u0026#34;_init_local\u0026#34;))) goto err; if(NULL == (unw_get_reg = (t_unw_get_reg)dlsym(libunwind, \u0026#34;_U\u0026#34;UNW_TARGET\u0026#34;_get_reg\u0026#34;))) goto err; if(NULL == (unw_step = (t_unw_step)dlsym(libunwind, \u0026#34;_U\u0026#34;UNW_TARGET\u0026#34;_step\u0026#34;))) goto err; return; err: dlclose(libunwind); libunwind = NULL; } xc_crash_init_callback static void xc_crash_init_callback(JNIEnv *env) { if(NULL == xc_common_cb_class) return; xc_crash_cb_method = (*env)-\u0026gt;GetStaticMethodID(env, xc_common_cb_class, XC_CRASH_CALLBACK_METHOD_NAME, XC_CRASH_CALLBACK_METHOD_SIGNATURE); XC_JNI_CHECK_NULL_AND_PENDING_EXCEPTION(xc_crash_cb_method, err); //eventfd and a new thread for callback  if(0 \u0026gt; (xc_crash_cb_notifier = eventfd(0, EFD_CLOEXEC))) goto err; if(0 != pthread_create(\u0026amp;xc_crash_cb_thd, NULL, xc_crash_callback_thread, NULL)) goto err;//main  return; xc_crash_callback_thread static void *xc_crash_callback_thread(void *arg) { //do callback: xcrash/NativeHandler. crashCallback(),main  (*env)-\u0026gt;CallStaticVoidMethod(env, xc_common_cb_class, xc_crash_cb_method, j_pathname, j_emergency, j_dump_java_stacktrace, j_is_main_thread, j_thread_name); xcc_signal_crash_register //xcc_signal.c int xcc_signal_crash_register(void (*handler)(int, siginfo_t *, void *)) { stack_t ss; if(NULL == (ss.ss_sp = calloc(1, XCC_SIGNAL_CRASH_STACK_SIZE))) return XCC_ERRNO_NOMEM; ss.ss_size = XCC_SIGNAL_CRASH_STACK_SIZE; ss.ss_flags = 0; if(0 != sigaltstack(\u0026amp;ss, NULL)) return XCC_ERRNO_SYS;//main  struct sigaction act;//main  memset(\u0026amp;act, 0, sizeof(act)); sigfillset(\u0026amp;act.sa_mask); act.sa_sigaction = handler;//main  act.sa_flags = SA_RESTART | SA_SIGINFO | SA_ONSTACK;//main  size_t i; for(i = 0; i \u0026lt; sizeof(xcc_signal_crash_info) / sizeof(xcc_signal_crash_info[0]); i++) //每次迭代注册一种信号监听,main  if(0 != sigaction(xcc_signal_crash_info[i].signum, \u0026amp;act, \u0026amp;(xcc_signal_crash_info[i].oldact))) return XCC_ERRNO_SYS; return 0; } xc_crash_signal_handler //xc_crash.c static void xc_crash_signal_handler(int sig, siginfo_t *si, void *uc) { //restore the original/default signal handler  if(xc_crash_rethrow) { if(0 != xcc_signal_crash_unregister()) goto exit; } else { if(0 != xcc_signal_crash_ignore()) goto exit; } //create and open log file  if((xc_crash_log_fd = xc_common_open_crash_log(xc_crash_log_pathname, sizeof(xc_crash_log_pathname), \u0026amp;xc_crash_log_from_placeholder)) \u0026lt; 0) goto end; memcpy(\u0026amp;(xc_crash_spot.siginfo), si, sizeof(siginfo_t));//main  memcpy(\u0026amp;(xc_crash_spot.ucontext), uc, sizeof(ucontext_t));//main  //spawn crash dumper process  errno = 0; pid_t dumper_pid = xc_crash_fork(xc_crash_exec_dumper);//main  //parent process ...  //wait the crash dumper process terminated  errno = 0; int status = 0; int wait_r = XCC_UTIL_TEMP_FAILURE_RETRY(waitpid(dumper_pid, \u0026amp;status, __WALL));//main  ...... if(xc_crash_log_fd \u0026gt;= 0) { //record java stacktrace  xc_xcrash_record_java_stacktrace();//main  //we have written all the required information in the native layer, close the FD  close(xc_crash_log_fd); xc_crash_log_fd = -1; } //JNI callback  xc_crash_callback(); ...... xc_crash_fork static int xc_crash_fork(int (*fn)(void *)) { #ifndef __i386__  return clone(fn, xc_crash_child_stack, CLONE_VFORK | CLONE_FS | CLONE_UNTRACED, NULL); #else  pid_t dumper_pid = fork();//main  if(-1 == dumper_pid) { return -1; } else if(0 == dumper_pid) { //child process ...  char msg = \u0026#39;a\u0026#39;; XCC_UTIL_TEMP_FAILURE_RETRY(write(xc_crash_child_notifier[1], \u0026amp;msg, sizeof(char))); syscall(SYS_close, xc_crash_child_notifier[0]); syscall(SYS_close, xc_crash_child_notifier[1]); _exit(fn(NULL));//main  } else { //parent process ...  char msg; XCC_UTIL_TEMP_FAILURE_RETRY(read(xc_crash_child_notifier[0], \u0026amp;msg, sizeof(char))); syscall(SYS_close, xc_crash_child_notifier[0]); syscall(SYS_close, xc_crash_child_notifier[1]); return dumper_pid; } #endif } xc_crash_exec_dumper //xc_crash.c static int xc_crash_exec_dumper(void *arg) { //escape to the dumper process  errno = 0; execl(xc_crash_dumper_pathname, XCC_UTIL_XCRASH_DUMPER_FILENAME, NULL);//执行libxcrash_dumper.so,main  return 100 + errno; libxcrash_dumper.so.main //xcd_core.c int main(int argc, char** argv) { //don\u0026#39;t leave a zombie process  alarm(30); //read args from stdin  if(0 != xcd_core_read_args()) exit(1);//main  //open log file  if(0 \u0026gt; (xcd_core_log_fd = XCC_UTIL_TEMP_FAILURE_RETRY(open(xcd_core_log_pathname, O_WRONLY | O_CLOEXEC)))) exit(2); //register signal handler for catching self-crashing  xcc_unwind_init(xcd_core_spot.api_level); xcc_signal_crash_register(xcd_core_signal_handler); //create process object,统计崩溃进程所有线程信息到队列xcd_core_proc-\u0026gt;thds，通过读取/proc/%d/task\u0026#34;, self-\u0026gt;pid实现  if(0 != xcd_process_create(\u0026amp;xcd_core_proc, xcd_core_spot.crash_pid,//main  xcd_core_spot.crash_tid, \u0026amp;(xcd_core_spot.siginfo), \u0026amp;(xcd_core_spot.ucontext))) exit(3); //suspend all threads in the process  xcd_process_suspend_threads(xcd_core_proc);//main  //load process info  if(0 != xcd_process_load_info(xcd_core_proc)) exit(4);//main  //record system info,记录并写入tombstone文件开头的系统信息  if(0 != xcd_sys_record(xcd_core_log_fd, xcd_core_spot.time_zone, xcd_core_spot.start_time, xcd_core_spot.crash_time, xcd_core_app_id, xcd_core_app_version, xcd_core_spot.api_level, xcd_core_os_version, xcd_core_kernel_version, xcd_core_abi_list, xcd_core_manufacturer, xcd_core_brand, xcd_core_model, xcd_core_build_fingerprint)) exit(5); //record process info,main  if(0 != xcd_process_record(xcd_core_proc, xcd_core_log_fd, xcd_core_spot.logcat_system_lines, xcd_core_spot.logcat_events_lines, xcd_core_spot.logcat_main_lines, xcd_core_spot.dump_elf_hash, xcd_core_spot.dump_map, xcd_core_spot.dump_fds, xcd_core_spot.dump_network_info, xcd_core_spot.dump_all_threads, xcd_core_spot.dump_all_threads_count_max, xcd_core_dump_all_threads_whitelist, xcd_core_spot.api_level)) exit(6); //resume all threads in the process  xcd_process_resume_threads(xcd_core_proc);//遍历线程PTRACE_DETACH,main  return 0; xcd_process_suspend_threads void xcd_process_suspend_threads(xcd_process_t *self) { xcd_thread_info_t *thd; TAILQ_FOREACH(thd, \u0026amp;(self-\u0026gt;thds), link)//每个线程都暂停  xcd_thread_suspend(\u0026amp;(thd-\u0026gt;t));//main } void xcd_thread_suspend(xcd_thread_t *self) { if(0 != ptrace(PTRACE_ATTACH, self-\u0026gt;tid, NULL, NULL)) { self-\u0026gt;status = XCD_THREAD_STATUS_ATTACH; return; } xcd_process_load_info int xcd_process_load_info(xcd_process_t *self) { int r; xcd_thread_info_t *thd; char buf[256]; // /proc/%d/cmdline,pid  xcc_util_get_process_name(self-\u0026gt;pid, buf, sizeof(buf)); if(NULL == (self-\u0026gt;pname = strdup(buf))) self-\u0026gt;pname = \u0026#34;unknown\u0026#34;; TAILQ_FOREACH(thd, \u0026amp;(self-\u0026gt;thds), link) { //load thread info,main  xcd_thread_load_info(\u0026amp;(thd-\u0026gt;t));//\u0026#34;/proc/%d/comm\u0026#34;, tid,设置tname  //load thread regs,main  if(thd-\u0026gt;t.tid != self-\u0026gt;crash_tid) xcd_thread_load_regs(\u0026amp;(thd-\u0026gt;t));//ptrace(PTRACE_GETREGSET, self-\u0026gt;tid...),设置regs  else xcd_thread_load_regs_from_ucontext(\u0026amp;(thd-\u0026gt;t), self-\u0026gt;uc);//从uc中获取并设置regs  } //load maps,main  if(0 != (r = xcd_maps_create(\u0026amp;(self-\u0026gt;maps), self-\u0026gt;pid)))//\u0026#34;/proc/%d/maps\u0026#34;, pid,设置maps  XCD_LOG_ERROR(\u0026#34;PROCESS: create maps failed, errno=%d\u0026#34;, r); return 0; } xcd_process_record //xcd_process.c/h int xcd_process_record(xcd_process_t *self, int log_fd, unsigned int logcat_system_lines, unsigned int logcat_events_lines, unsigned int logcat_main_lines, int dump_elf_hash, int dump_map, int dump_fds, int dump_network_info, int dump_all_threads, unsigned int dump_all_threads_count_max, char *dump_all_threads_whitelist, int api_level) { //记录写入崩溃线程信息  TAILQ_FOREACH(thd, \u0026amp;(self-\u0026gt;thds), link) { if(thd-\u0026gt;t.tid == self-\u0026gt;crash_tid) { if(0 != (r = xcd_thread_record_info(\u0026amp;(thd-\u0026gt;t), log_fd, self-\u0026gt;pname))) return r; if(0 != (r = xcd_process_record_signal_info(self, log_fd))) return r; if(0 != (r = xcd_process_record_abort_message(self, log_fd, api_level))) return r; if(0 != (r = xcd_thread_record_regs(\u0026amp;(thd-\u0026gt;t), log_fd))) return r; if(0 == xcd_thread_load_frames(\u0026amp;(thd-\u0026gt;t), self-\u0026gt;maps))//main  { if(0 != (r = xcd_thread_record_backtrace(\u0026amp;(thd-\u0026gt;t), log_fd))) return r;//main  if(0 != (r = xcd_thread_record_buildid(\u0026amp;(thd-\u0026gt;t), log_fd, dump_elf_hash, xcc_util_signal_has_si_addr(self-\u0026gt;si) ? (uintptr_t)self-\u0026gt;si-\u0026gt;si_addr : 0))) return r; if(0 != (r = xcd_thread_record_stack(\u0026amp;(thd-\u0026gt;t), log_fd))) return r; if(0 != (r = xcd_thread_record_memory(\u0026amp;(thd-\u0026gt;t), log_fd))) return r; } if(dump_map) if(0 != (r = xcd_maps_record(self-\u0026gt;maps, log_fd))) return r; if(0 != (r = xcc_util_record_logcat(log_fd, self-\u0026gt;pid, api_level, logcat_system_lines, logcat_events_lines, logcat_main_lines))) return r; if(dump_fds) if(0 != (r = xcc_util_record_fds(log_fd, self-\u0026gt;pid))) return r; if(dump_network_info) if(0 != (r = xcc_util_record_network_info(log_fd, self-\u0026gt;pid, api_level))) return r; if(0 != (r = xcc_meminfo_record(log_fd, self-\u0026gt;pid))) return r; break; } } if(!dump_all_threads) return 0; //统计白名单中每个线程信息  //parse thread name whitelist regex  re = xcd_process_build_whitelist_regex(dump_all_threads_whitelist, \u0026amp;re_cnt); TAILQ_FOREACH(thd, \u0026amp;(self-\u0026gt;thds), link) { if(thd-\u0026gt;t.tid != self-\u0026gt;crash_tid) { //check regex for thread name  if(NULL != re \u0026amp;\u0026amp; re_cnt \u0026gt; 0 \u0026amp;\u0026amp; !xcd_process_if_need_dump(thd-\u0026gt;t.tname, re, re_cnt)) { continue; } thd_matched_regex++; //check dump count limit  if(dump_all_threads_count_max \u0026gt; 0 \u0026amp;\u0026amp; thd_dumped \u0026gt;= dump_all_threads_count_max) { thd_ignored_by_limit++; continue; } if(0 != (r = xcc_util_write_str(log_fd, XCC_UTIL_THREAD_SEP))) goto end; if(0 != (r = xcd_thread_record_info(\u0026amp;(thd-\u0026gt;t), log_fd, self-\u0026gt;pname))) goto end; if(0 != (r = xcd_thread_record_regs(\u0026amp;(thd-\u0026gt;t), log_fd))) goto end; if(0 == xcd_thread_load_frames(\u0026amp;(thd-\u0026gt;t), self-\u0026gt;maps)) { if(0 != (r = xcd_thread_record_backtrace(\u0026amp;(thd-\u0026gt;t), log_fd))) goto end; if(0 != (r = xcd_thread_record_stack(\u0026amp;(thd-\u0026gt;t), log_fd))) goto end; } thd_dumped++; } } end: if(self-\u0026gt;nthds \u0026gt; 1) { if(0 == thd_dumped) if(0 != (r = xcc_util_write_str(log_fd, XCC_UTIL_THREAD_SEP))) goto ret; if(0 != (r = xcc_util_write_format(log_fd, \u0026#34;total threads (exclude the crashed thread): %zu\\n\u0026#34;, self-\u0026gt;nthds - 1))) goto ret; if(NULL != re \u0026amp;\u0026amp; re_cnt \u0026gt; 0) if(0 != (r = xcc_util_write_format(log_fd, \u0026#34;threads matched whitelist: %d\\n\u0026#34;, thd_matched_regex))) goto ret; if(dump_all_threads_count_max \u0026gt; 0) if(0 != (r = xcc_util_write_format(log_fd, \u0026#34;threads ignored by max count limit: %d\\n\u0026#34;, thd_ignored_by_limit))) goto ret; if(0 != (r = xcc_util_write_format(log_fd, \u0026#34;dumped threads: %u\\n\u0026#34;, thd_dumped))) goto ret; if(0 != (r = xcc_util_write_str(log_fd, XCC_UTIL_THREAD_END))) goto ret; } ret: return r; xcd_thread_load_frames //xcd_thread.h/c int xcd_thread_load_frames(xcd_thread_t *self, xcd_maps_t *maps) { if(XCD_THREAD_STATUS_OK != self-\u0026gt;status) return XCC_ERRNO_STATE; //do NOT ignore  return xcd_frames_create(\u0026amp;(self-\u0026gt;frames), \u0026amp;(self-\u0026gt;regs), maps, self-\u0026gt;pid);//main } int xcd_frames_create(xcd_frames_t **self, xcd_regs_t *regs, xcd_maps_t *maps, pid_t pid) { if(NULL == (*self = malloc(sizeof(xcd_frames_t)))) return XCC_ERRNO_NOMEM; (*self)-\u0026gt;pid = pid; (*self)-\u0026gt;regs = regs; (*self)-\u0026gt;maps = maps; TAILQ_INIT(\u0026amp;((*self)-\u0026gt;frames)); (*self)-\u0026gt;frames_num = 0; xcd_frames_load(*self);//main  return 0; } //xcd_frames.c static void xcd_frames_load(xcd_frames_t *self) { xcd_frame_t *frame; xcd_map_t *map; xcd_map_t *map_sp; xcd_elf_t *elf; xcd_regs_t regs_copy = *(self-\u0026gt;regs);//main  while(self-\u0026gt;frames_num \u0026lt; XCD_FRAMES_MAX) { cur_pc = xcd_regs_get_pc(\u0026amp;regs_copy);//循环的每次通过更新regs_copy进行，每次读取一个栈帧信息,main  cur_sp = xcd_regs_get_sp(\u0026amp;regs_copy); if(NULL != (map = xcd_maps_find_map(self-\u0026gt;maps, cur_pc)))//main  { //get relative pc,main  rel_pc = xcd_map_get_rel_pc(map, step_pc, self-\u0026gt;pid, (void *)self-\u0026gt;maps); step_pc = rel_pc; elf = xcd_map_get_elf(map, self-\u0026gt;pid, (void *)self-\u0026gt;maps); if(NULL != elf) { load_bias = xcd_elf_get_load_bias(elf); memory = xcd_elf_get_memory(elf); } if(adjust_pc) pc_adjustment = xcd_regs_get_adjust_pc(rel_pc, load_bias, memory); step_pc -= pc_adjustment; } adjust_pc = 1; if(0 == xcd_elf_step(elf, rel_pc, step_pc, \u0026amp;regs_copy, \u0026amp;finished, \u0026amp;sigreturn))//main  stepped = 1; else stepped = 0; ...... //If the pc and sp didn\u0026#39;t change, then consider everything stopped.  if(cur_pc == xcd_regs_get_pc(\u0026amp;regs_copy) \u0026amp;\u0026amp; cur_sp == xcd_regs_get_sp(\u0026amp;regs_copy)) break; } xcd_regs_get_pc //xcd_regs_arm64.c uintptr_t xcd_regs_get_pc(xcd_regs_t *self) { return self-\u0026gt;r[XCD_REGS_PC]; } xcd_maps_find_map //xcd_maps.h.c xcd_map_t *xcd_maps_find_map(xcd_maps_t *self, uintptr_t pc) { xcd_maps_item_t *mi; TAILQ_FOREACH(mi, \u0026amp;(self-\u0026gt;maps), link) if(pc \u0026gt;= mi-\u0026gt;map.start \u0026amp;\u0026amp; pc \u0026lt; mi-\u0026gt;map.end) return \u0026amp;(mi-\u0026gt;map); return NULL; } xcd_map_get_rel_pc //xcd.map.c uintptr_t xcd_map_get_rel_pc(xcd_map_t *self, uintptr_t pc, pid_t pid, void *maps_obj) { xcd_elf_t *elf = xcd_map_get_elf(self, pid, maps_obj); uintptr_t load_bias = (NULL == elf ? 0 : xcd_elf_get_load_bias(elf)); return pc - self-\u0026gt;start + load_bias + self-\u0026gt;elf_offset; } 其他 xcd_process //xcd_process.c/h struct xcd_process { pid_t pid; char *pname; pid_t crash_tid; ucontext_t *uc; siginfo_t *si; xcd_thread_info_queue_t thds; size_t nthds; xcd_maps_t *maps; }; xcd_process_t typedef struct xcd_process xcd_process_t; xcd_thread_info_t typedef struct xcd_thread_info { xcd_thread_t t; TAILQ_ENTRY(xcd_thread_info,) link; } xcd_thread_info_t; xcd_thread_status_t //xcd_thread.h/c typedef enum { XCD_THREAD_STATUS_OK = 0, XCD_THREAD_STATUS_UNKNOWN, XCD_THREAD_STATUS_REGS, XCD_THREAD_STATUS_ATTACH, XCD_THREAD_STATUS_ATTACH_WAIT } xcd_thread_status_t; xcd_thread_t //xcd_thread.h/c typedef struct xcd_thread { xcd_thread_status_t status; pid_t pid; pid_t tid; char *tname; xcd_regs_t regs; xcd_frames_t *frames; } xcd_thread_t; xcd_frames //xcd_frames.c struct xcd_frames { pid_t pid; xcd_regs_t *regs; xcd_maps_t *maps; xcd_frame_queue_t frames; size_t frames_num; }; xcd_frames_t typedef struct xcd_frames xcd_frames_t; xcd_maps struct xcd_maps { xcd_maps_item_queue_t maps; pid_t pid; }; xcd_maps_t typedef struct xcd_maps xcd_maps_t; xcd_maps_item,xcd_maps_item_t xcd_maps_item_queue_t typedef struct xcd_maps_item { xcd_map_t map; TAILQ_ENTRY(xcd_maps_item,) link; } xcd_maps_item_t; typedef TAILQ_HEAD(xcd_maps_item_queue, xcd_maps_item,) xcd_maps_item_queue_t; xcd_map,xcd_map_t typedef struct xcd_map { //base info from /proc/\u0026lt;PID\u0026gt;/maps  uintptr_t start; uintptr_t end; size_t offset; uint16_t flags; char *name; //ELF  xcd_elf_t *elf; int elf_loaded; size_t elf_offset; size_t elf_start_offset; } xcd_map_t; 参考 stack unwinding \u0026laquo;Advanced Design and Implementation of Virtual Machines\u0026raquo;\n第八章 stack unwinding\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/zygote/",
	"title": "zygote",
	"tags": [],
	"description": "",
	"content": "zygote 探索总结zygote知识\n SystemServerSource     ZygoteSource     Zygote进程     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/zygote/zygotesource/",
	"title": "ZygoteSource",
	"tags": [],
	"description": "",
	"content": "原理图 sequenceDiagram ZygoteProcess-\u0026gt;\u0026gt;ZygoteProcess: ZygoteInit.main activate ZygoteProcess ZygoteProcess-\u0026gt;\u0026gt;SystemServerProcess: forkSystemServer activate SystemServerProcess SystemServerProcess-\u0026gt;\u0026gt;SystemServerProcess: handleSystemServerProcess activate SystemServerProcess SystemServerProcess-\u0026gt;\u0026gt;SystemServerProcess: ZygoteInit.zygoteInit deactivate SystemServerProcess activate SystemServerProcess SystemServerProcess-\u0026gt;\u0026gt;SystemServerProcess: SystemServer.main deactivate SystemServerProcess deactivate SystemServerProcess activate ZygoteProcess ZygoteProcess-\u0026gt;\u0026gt;ZygoteProcess: runSelectLoop SystemServerProcess-\u0026gt;\u0026gt;ZygoteProcess: notify activate ZygoteProcess ZygoteProcess-\u0026gt;\u0026gt;ZygoteProcess: processOneCommand ZygoteProcess-\u0026gt;\u0026gt;ChildAppProcess: Zygote.forkAndSpecialize deactivate ZygoteProcess activate ChildAppProcess ChildAppProcess-\u0026gt;\u0026gt;ChildAppProcess: handleChildProc activate ChildAppProcess ChildAppProcess-\u0026gt;\u0026gt;ChildAppProcess: ZygoteInit.zygoteInit deactivate ChildAppProcess activate ChildAppProcess ChildAppProcess-\u0026gt;\u0026gt;ChildAppProcess: ActivityThead.main deactivate ChildAppProcess deactivate ChildAppProcess deactivate ZygoteProcess deactivate ZygoteProcess ZygoteInit.main public static void main(String argv[]) { ZygoteServer zygoteServer = new ZygoteServer(); for (int i = 1; i \u0026lt; argv.length; i++) { if (\u0026#34;start-system-server\u0026#34;.equals(argv[i])) { startSystemServer = true; } else if (\u0026#34;--enable-lazy-preload\u0026#34;.equals(argv[i])) { enableLazyPreload = true; } else if (argv[i].startsWith(ABI_LIST_ARG)) { abiList = argv[i].substring(ABI_LIST_ARG.length()); } else if (argv[i].startsWith(SOCKET_NAME_ARG)) { socketName = argv[i].substring(SOCKET_NAME_ARG.length()); } else { throw new RuntimeException(\u0026#34;Unknown command line argument: \u0026#34; + argv[i]); } } zygoteServer.registerServerSocketFromEnv(socketName); if (startSystemServer) { Runnable r = forkSystemServer(abiList, socketName, zygoteServer); // {@code r == null} in the parent (zygote) process, and {@code r != null} in the  // child (system_server) process.  if (r != null) { r.run(); return; } } Log.i(TAG, \u0026#34;Accepting command socket connections\u0026#34;); // The select loop returns early in the child process after a fork and  // loops forever in the zygote.  caller = zygoteServer.runSelectLoop(abiList); // We\u0026#39;re in the child process and have exited the select loop. Proceed to execute the  // command.  if (caller != null) { caller.run(); } } forkSystemServer private static Runnable forkSystemServer(String abiList, String socketName, ZygoteServer zygoteServer) { /* Request to fork the system server process */ pid = Zygote.forkSystemServer( parsedArgs.uid, parsedArgs.gid, parsedArgs.gids, parsedArgs.runtimeFlags, null, parsedArgs.permittedCapabilities, parsedArgs.effectiveCapabilities); /* For child process */ if (pid == 0) { if (hasSecondZygote(abiList)) { waitForSecondaryZygote(socketName); } zygoteServer.closeServerSocket(); return handleSystemServerProcess(parsedArgs); } /** @return 0 if this is the child, pid of the child * if this is the parent, or -1 on error. */ public static int forkSystemServer(int uid, int gid, int[] gids, int runtimeFlags, int[][] rlimits, long permittedCapabilities, long effectiveCapabilities) { int pid = nativeForkSystemServer( uid, gid, gids, runtimeFlags, rlimits, permittedCapabilities, effectiveCapabilities); // Enable tracing as soon as we enter the system_server.  if (pid == 0) { Trace.setTracingEnabled(true, runtimeFlags); } return pid; } SystemServer handleSystemServerProcess /** * Finish remaining work for the newly forked system server process. */ private static Runnable handleSystemServerProcess(ZygoteConnection.Arguments parsedArgs) { ClassLoader cl = null; if (systemServerClasspath != null) { cl = createPathClassLoader(systemServerClasspath, parsedArgs.targetSdkVersion); Thread.currentThread().setContextClassLoader(cl); } /* * Pass the remaining arguments to SystemServer. */ return ZygoteInit.zygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, cl); } zygoteInit public static final Runnable zygoteInit(int targetSdkVersion, String[] argv, ClassLoader classLoader) { Slog.d(RuntimeInit.TAG, \u0026#34;RuntimeInit: Starting application from zygote\u0026#34;); RuntimeInit.commonInit(); ZygoteInit.nativeZygoteInit(); return RuntimeInit.applicationInit(targetSdkVersion, argv, classLoader); } RuntimeInit.commonInit @UnsupportedAppUsage protected static final void commonInit() { /* * set handlers; these apply to all threads in the VM. Apps can replace * the default handler, but not the pre handler. */ LoggingHandler loggingHandler = new LoggingHandler(); RuntimeHooks.setUncaughtExceptionPreHandler(loggingHandler); Thread.setDefaultUncaughtExceptionHandler(new KillApplicationHandler(loggingHandler)); } frameworks/base/core/jni/AndroidRuntime.cpp\nnativeZygoteInit static void com_android_internal_os_ZygoteInit_nativeZygoteInit(JNIEnv* env, jobject clazz) { gCurRuntime-\u0026gt;onZygoteInit(); } frameworks/base/cmds/app_process/app_main.cpp\nvirtual void onZygoteInit() { sp\u0026lt;ProcessState\u0026gt; proc = ProcessState::self(); ALOGV(\u0026#34;App process: starting thread pool.\\n\u0026#34;); proc-\u0026gt;startThreadPool(); } RuntimeInit.applicationInit protected static Runnable applicationInit(int targetSdkVersion, String[] argv, ClassLoader classLoader) { // If the application calls System.exit(), terminate the process  // immediately without running any shutdown hooks. It is not possible to  // shutdown an Android application gracefully. Among other things, the  // Android runtime shutdown hooks close the Binder driver, which can cause  // leftover running threads to crash before the process actually exits.  nativeSetExitWithoutCleanup(true); // We want to be fairly aggressive about heap utilization, to avoid  // holding on to a lot of memory that isn\u0026#39;t needed.  VMRuntime.getRuntime().setTargetHeapUtilization(0.75f); VMRuntime.getRuntime().setTargetSdkVersion(targetSdkVersion); final Arguments args = new Arguments(argv); // The end of of the RuntimeInit event (see #zygoteInit).  Trace.traceEnd(Trace.TRACE_TAG_ACTIVITY_MANAGER); // Remaining arguments are passed to the start class\u0026#39;s static main  return findStaticMain(args.startClass, args.startArgs, classLoader); } //ActivityThread的全类名由AMS startProcess时写入到socket，zygoteServer再读取，传递过来 protected static Runnable findStaticMain(String className, String[] argv, ClassLoader classLoader) { cl = Class.forName(className, true, classLoader); Method m; m = cl.getMethod(\u0026#34;main\u0026#34;, new Class[] { String[].class }); return new MethodAndArgsCaller(m, argv); ZygoteServer runSelectLoop /** * Runs the zygote process\u0026#39;s select loop. Accepts new connections as * they happen, and reads commands from connections one spawn-request\u0026#39;s * worth at a time. */ Runnable runSelectLoop(String abiList) { ArrayList\u0026lt;FileDescriptor\u0026gt; fds = new ArrayList\u0026lt;FileDescriptor\u0026gt;(); ArrayList\u0026lt;ZygoteConnection\u0026gt; peers = new ArrayList\u0026lt;ZygoteConnection\u0026gt;(); fds.add(mServerSocket.getFileDescriptor()); peers.add(null); while (true) { StructPollfd[] pollFds = new StructPollfd[fds.size()]; for (int i = 0; i \u0026lt; pollFds.length; ++i) { pollFds[i] = new StructPollfd(); pollFds[i].fd = fds.get(i); pollFds[i].events = (short) POLLIN; } try { Os.poll(pollFds, -1); } catch (ErrnoException ex) { throw new RuntimeException(\u0026#34;poll failed\u0026#34;, ex); } for (int i = pollFds.length - 1; i \u0026gt;= 0; --i) { if ((pollFds[i].revents \u0026amp; POLLIN) == 0) { continue; } if (i == 0) { ZygoteConnection newPeer = acceptCommandPeer(abiList); peers.add(newPeer); fds.add(newPeer.getFileDesciptor()); } else { try { ZygoteConnection connection = peers.get(i); final Runnable command = connection.processOneCommand(this); } } } } ZygoteConnection.processOneCommand /** * Reads one start command from the command socket. If successful, a child is forked and a * {@code Runnable} that calls the childs main method (or equivalent) is returned in the child * process. {@code null} is always returned in the parent process (the zygote). */ Runnable processOneCommand(ZygoteServer zygoteServer) { args = readArgumentList();//读取socket数据，解析启动参数  parsedArgs = new Arguments(args); pid = Zygote.forkAndSpecialize(parsedArgs.uid, parsedArgs.gid, parsedArgs.gids, parsedArgs.runtimeFlags, rlimits, parsedArgs.mountExternal, parsedArgs.seInfo, parsedArgs.niceName, fdsToClose, fdsToIgnore, parsedArgs.startChildZygote, parsedArgs.instructionSet, parsedArgs.appDataDir); if (pid == 0) { // in child  zygoteServer.setForkChild(); zygoteServer.closeServerSocket(); IoUtils.closeQuietly(serverPipeFd); serverPipeFd = null; return handleChildProc(parsedArgs, descriptors, childPipeFd, parsedArgs.startChildZygote); } else { // In the parent. A pid \u0026lt; 0 indicates a failure and will be handled in  // handleParentProc.  IoUtils.closeQuietly(childPipeFd); childPipeFd = null; handleParentProc(pid, descriptors, serverPipeFd); return null; } ChildProcess handleChildProc private Runnable handleChildProc(Arguments parsedArgs, FileDescriptor[] descriptors, FileDescriptor pipeFd, boolean isZygote) { if (!isZygote) { return ZygoteInit.zygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, null /* classLoader */); } else { return ZygoteInit.childZygoteInit(parsedArgs.targetSdkVersion, parsedArgs.remainingArgs, null /* classLoader */); } zygoteInit zygoteinit\n参考 \u0026laquo;深入理解Android 卷1 4.4.1ActivityManagerService发送请求\u0026gt;\nZygote为什么使用Socket不用Binder fork()不支持多线程，如果使用Binder则fork()时可能会丢弃binder线程池中的任务或造成死锁，而通过socket进行单线程可以解决这个问题\n安全性?\nRuntimeInit.main //没啥机会调用到\n@UnsupportedAppUsage public static final void main(String[] argv) { enableDdms(); commonInit(); /* * Now that we\u0026#39;re running in interpreted code, call back into native code * to run the system. */ nativeFinishInit(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/zygote/zygote%E8%BF%9B%E7%A8%8B/",
	"title": "Zygote进程",
	"tags": [],
	"description": "",
	"content": "What is the Zygote copy-on-write heap?\nAll \u0026ldquo;Zygote-based\u0026rdquo; processes have memory pages that are identical among them.\nThose pages are not copied, instead everything is linked to the same memory page. This reduces the amount on RAM used by all the \u0026ldquo;Zygote-based\u0026rdquo; processes.\nIf one of those process writes new data into such a page the page is automatically copied before the write actually takes place (because otherwise the memory of all forks would be changed).\nThis mechanism is called copy-on-write.\nhttps://en.wikipedia.org/wiki/Copy-on-write\nCopy-on-write From Wikipedia, the free encyclopedia\nCopy-on-write (CoW or COW), sometimes referred to as implicit sharing[1] or shadowing,[2] is a resource-management technique used in computer programming to efficiently implement a \u0026ldquo;duplicate\u0026rdquo; or \u0026ldquo;copy\u0026rdquo; operation on modifiable resources.[3] If a resource is duplicated but not modified, it is not necessary to create a new resource; the resource can be shared between the copy and the original. Modifications must still create a copy, hence the technique: the copy operation is deferred to the first write. By sharing resources in this way, it is possible to significantly reduce the resource consumption of unmodified copies, while adding a small overhead to resource-modifying operations.\nIn virtual memory management Copy-on-write finds its main use in sharing the virtual memory of operating system processes, in the implementation of the fork system call. Typically, the process does not modify any memory and immediately executes a new process, replacing the address space entirely. Thus, it would be wasteful to copy all of the process\u0026rsquo;s memory during a fork, and instead the copy-on-write technique is used.\nCopy-on-write can be implemented efficiently using the page table by marking certain pages of memory as read-only and keeping a count of the number of references to the page. When data is written to these pages, the kernel intercepts the write attempt and allocates a new physical page, initialized with the copy-on-write data, although the allocation can be skipped if there is only one reference. The kernel then updates the page table with the new (writable) page, decrements the number of references, and performs the write. The new allocation ensures that a change in the memory of one process is not visible in another\u0026rsquo;s.\nIn multithreaded systems, COW can be implemented without the use of traditional locking and instead use compare-and-swap to increment or decrement the internal reference counter. Since the original resource will never be altered, it can safely be copied by multiple threads (after the reference count was increased) without the need of performance-expensive locking such as mutexes.\nAndroid性能优化之系统资源预加载的思考\nZygote fork内存分配\nEach app process is forked from an existing process called Zygote. The Zygote process starts when the system boots and loads common framework code and resources (such as activity themes). To start a new app process, the system forks the Zygote process then loads and runs the app\u0026rsquo;s code in the new process. This approach allows most of the RAM pages allocated for framework code and resources to be shared across all app processes.\nMost static data is mmapped into a process. This technique allows data to be shared between processes, and also allows it to be paged out when needed. Example static data include: Dalvik code (by placing it in a pre-linked .odex file for direct mmapping), app resources (by designing the resource table to be a structure that can be mmapped and by aligning the zip entries of the APK), and traditional project elements like native code in .so files.\nn many places, Android shares the same dynamic RAM across processes using explicitly allocated shared memory regions (either with ashmem or gralloc). For example, window surfaces use shared memory between the app and screen compositor, and cursor buffers use shared memory between the content provider and client.\n初识Zygote进程\n第4章 深入理解 Zygote\n4.4 Zygote的分裂 前文已经讲道，Zygote分裂出嫡长子system_server后，就通过runSelectLoopMode等待并处理来自客户的消息，那么，谁会向Zygote发送消息呢？这里，以一个Activity的启动为例，具体分析Zygote是如何分裂和繁殖的。\n4.4.1 ActivityManagerService发送请求 ActivityManagerService也是由SystemServer创建的。假设通过startActivit来启动一个新的Activity，而这个Activity附属于一个还未启动的进程，那么这个进程该如何启动呢？先来看看ActivityManagerService中的startProcessLocked函数，代码如下所示：\n4.4.2 有求必应之响应请求 前面有一节，题目叫“有求必应之等待请求”，那么这一节“有求必应之响应请求”会回到ZygoteInit。下面就看看它是如何处理请求的。\nZygote分裂子进程后，自己将在handleParentProc中做一些扫尾工作，然后继续等待请求进行下一次分裂。\n这个android.app.ActivityThread类，实际上是Android中apk程序所对应的进程，它的main函数就是apk程序的main函数。从这个类的命名（android.app）中也可以看出些端倪。\n通过这一节的分析，读者可以想到，Android系统运行的那些apk程序，其父都是zygote。这一点，可以通过adb shell登录后，用ps命令查看进程和父进程号来确认。\n4.4.3 关于 Zygote分裂的总结\n源码分析 — ActivityThread(一)之main()的调用 (Android应用进程的孵化)\n小结： Zygote响应请求的流程\n Zygote 进程调用 ZygoteInit.runSelectLoop() 开启一个轮训器； SystemServer 进程发送消息到 Zygote ，在 ZygoteConnection.readArgumentList() 中接收消息； Zygote 通过 fork 创建子进程； 子进程调用android.app.ActivityThread.main() 方法；  其实，这个原理跟 Handler 的 Looper 原理很像，Looper开启一个轮训器，不断的从 MessageQueue 中获取最新的 Message，进而处理这个消息； 而在 ZygoteInit.runSelectLoop() 也是启动一个轮训器，从指定的 Socket 中读取数据，然后进行处理；\n"
},
{
	"uri": "https://huanle19891345.github.io/en/kotlin/coroutine/%E4%BD%BF%E7%94%A8%E6%8C%82%E8%B5%B7%E5%87%BD%E6%95%B0%E6%9D%A5%E5%B0%81%E8%A3%85%E5%9B%9E%E8%B0%83/",
	"title": "使用挂起函数来封装回调",
	"tags": [],
	"description": "",
	"content": "graph LR lifecycleScope--\u0026gt;|destory时通知|协程被取消 subgraph 协程挂起时,也就是异步任务执行时,需要考虑双向通知 协程被取消--\u0026gt;|cont.invokeOnCancellation通知|取消异步任务 异步任务被取消或异常--\u0026gt;|通知|取消协程/通知协程异常 end 参考 在 View 上使用挂起函数\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/",
	"title": "内存优化",
	"tags": [],
	"description": "",
	"content": "内存优化 探索总结内存优化知识\n 1manageMemory     2OOM     3Hprof_binary_dump_format     4DumpHprof     5LeakCanary2     6LeakCanary2Analyze     7KOOMSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/ui/%E5%8A%A8%E7%94%BB/",
	"title": "动画",
	"tags": [],
	"description": "",
	"content": "动画 探索总结动画知识\n AnimatorSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%8A%A8%E7%94%BB/",
	"title": "动画",
	"tags": [],
	"description": "",
	"content": "动画 探索总结动画知识\n 动画     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%8A%A8%E7%94%BB/%E5%8A%A8%E7%94%BB/",
	"title": "动画",
	"tags": [],
	"description": "",
	"content": "类设计 原理图 AnimationController() /// An [AnimationController] needs a [TickerProvider], which is configured using  /// the `vsync` argument on the constructor.  ///  /// The [TickerProvider] interface describes a factory for [Ticker] objects. A  /// [Ticker] is an object that knows how to register itself with the  /// [SchedulerBinding] and fires a callback every frame. The  /// [AnimationController] class uses a [Ticker] to step through the animation  /// that it controls.  class AnimationController extends Animation\u0026lt;double\u0026gt; with AnimationEagerListenerMixin, AnimationLocalListenersMixin, AnimationLocalStatusListenersMixin AnimationController({ double value, this.duration, this.reverseDuration, this.debugLabel, this.lowerBound = 0.0, this.upperBound = 1.0, this.animationBehavior = AnimationBehavior.normal, @required TickerProvider vsync, }) : assert(lowerBound != null), assert(upperBound != null), assert(upperBound \u0026gt;= lowerBound), assert(vsync != null), _direction = _AnimationDirection.forward { _ticker = vsync.createTicker(_tick); _internalSetValue(value ?? lowerBound); } vsync.createTicker(_tick) SingleTickerProviderStateMixin.createTicker //mixin SingleTickerProviderStateMixin\u0026lt;T extends StatefulWidget\u0026gt; on State\u0026lt;T\u0026gt; implements TickerProvider @override Ticker createTicker(TickerCallback onTick) { _ticker = Ticker(onTick, debugLabel: kDebugMode ? \u0026#39;created by $this\u0026#39; : null); // We assume that this is called from initState, build, or some sort of  // event handler, and that thus TickerMode.of(context) would return true. We  // can\u0026#39;t actually check that here because if we\u0026#39;re in initState then we\u0026#39;re  // not allowed to do inheritance checks yet.  return _ticker; _internalSetValue void _internalSetValue(double newValue) { _value = newValue.clamp(lowerBound, upperBound); if (_value == lowerBound) { _status = AnimationStatus.dismissed; } else if (_value == upperBound) { _status = AnimationStatus.completed; } else { _status = (_direction == _AnimationDirection.forward) ? AnimationStatus.forward : AnimationStatus.reverse; } } forward /// Starts running this animation forwards (towards the end). TickerFuture forward({ double from }) { _direction = _AnimationDirection.forward; if (from != null) value = from; return _animateToInternal(upperBound);//main } _animateToInternal TickerFuture _animateToInternal(double target, { Duration duration, Curve curve = Curves.linear }) { double scale = 1.0; ...... Duration simulationDuration = duration; if (simulationDuration == null) { final double range = upperBound - lowerBound; final double remainingFraction = range.isFinite ? (target - _value).abs() / range : 1.0; final Duration directionDuration = (_direction == _AnimationDirection.reverse \u0026amp;\u0026amp; reverseDuration != null) ? reverseDuration : this.duration; simulationDuration = directionDuration * remainingFraction; } else if (target == value) { // Already at target, don\u0026#39;t animate.  simulationDuration = Duration.zero; } stop(); ...... return _startSimulation(_InterpolationSimulation(_value, target, simulationDuration, curve, scale));//main stop void stop({ bool canceled = true }) { _simulation = null; _lastElapsedDuration = null; _ticker.stop(canceled: canceled); //Ticker /// Stops calling this [Ticker]\u0026#39;s callback. void stop({ bool canceled = false }) { if (!isActive) return; final TickerFuture localFuture = _future; _future = null; _startTime = null; unscheduleTick(); if (canceled) { localFuture._cancel(this); } else { localFuture._complete(); } } /// Cancels the frame callback that was requested by [scheduleTick], if any. @protected void unscheduleTick() { if (scheduled) { SchedulerBinding.instance.cancelFrameCallbackWithId(_animationId); _animationId = null; } _startSimulation TickerFuture _startSimulation(Simulation simulation) { _simulation = simulation; _lastElapsedDuration = Duration.zero; _value = simulation.x(0.0).clamp(lowerBound, upperBound); final TickerFuture result = _ticker.start();//main  _status = (_direction == _AnimationDirection.forward) ? AnimationStatus.forward : AnimationStatus.reverse; _checkStatusChanged(); return result; Ticker.start /// Starts the clock for this [Ticker]. If the ticker is not [muted], then this  /// also starts calling the ticker\u0026#39;s callback once per animation frame.  TickerFuture start() { _future = TickerFuture._(); if (shouldScheduleTick) { scheduleTick();//main  } if (SchedulerBinding.instance.schedulerPhase.index \u0026gt; SchedulerPhase.idle.index \u0026amp;\u0026amp; SchedulerBinding.instance.schedulerPhase.index \u0026lt; SchedulerPhase.postFrameCallbacks.index) _startTime = SchedulerBinding.instance.currentFrameTimeStamp; return _future; scheduleTick /// Schedules a tick for the next frame.  ///  /// This should only be called if [shouldScheduleTick] is true.  @protected void scheduleTick({ bool rescheduling = false }) { assert(!scheduled); assert(shouldScheduleTick); _animationId = SchedulerBinding.instance.scheduleFrameCallback(_tick, rescheduling: rescheduling);//main, callback method: _tick  } SchedulerBinding.scheduleFrame int scheduleFrameCallback(FrameCallback callback, { bool rescheduling = false }) { scheduleFrame(); _nextFrameCallbackId += 1; _transientCallbacks[_nextFrameCallbackId] = _FrameCallbackEntry(callback, rescheduling: rescheduling); return _nextFrameCallbackId; } void scheduleFrame() { if (_hasScheduledFrame || !_framesEnabled) return; window.scheduleFrame(); _hasScheduledFrame = true; } //Window void scheduleFrame() native \u0026#39;Window_scheduleFrame\u0026#39;; Ticker frameCallback method _tick void _tick(Duration timeStamp) { _animationId = null; _startTime ??= timeStamp; _onTick(timeStamp - _startTime); // The onTick callback may have scheduled another tick already, for  // example by calling stop then start again.  if (shouldScheduleTick) scheduleTick(rescheduling: true); } AnimationController._tick void _tick(Duration elapsed) { _lastElapsedDuration = elapsed; final double elapsedInSeconds = elapsed.inMicroseconds.toDouble() / Duration.microsecondsPerSecond; assert(elapsedInSeconds \u0026gt;= 0.0); _value = _simulation.x(elapsedInSeconds).clamp(lowerBound, upperBound);//main, update value  if (_simulation.isDone(elapsedInSeconds)) { _status = (_direction == _AnimationDirection.forward) ? AnimationStatus.completed : AnimationStatus.dismissed; stop(canceled: false); } notifyListeners(); _checkStatusChanged(); } _InterpolationSimulation.x(double timeInSeconds) class _InterpolationSimulation extends Simulation final double _durationInSeconds; final double _begin; final double _end; final Curve _curve; @override double x(double timeInSeconds) { final double t = (timeInSeconds / _durationInSeconds).clamp(0.0, 1.0); if (t == 0.0) return _begin; else if (t == 1.0) return _end; else return _begin + (_end - _begin) * _curve.transform(t); } Animatable.animate /// Returns a new [Animation] that is driven by the given animation but that  /// takes on values determined by this object.  ///  /// Essentially this returns an [Animation] that automatically applies the  /// [evaluate] method to the parent\u0026#39;s value.  ///  /// See also:  ///  /// * [AnimationController.drive], which does the same thing from the  /// opposite starting point.  Animation\u0026lt;T\u0026gt; animate(Animation\u0026lt;double\u0026gt; parent) { return _AnimatedEvaluation\u0026lt;T\u0026gt;(parent, this); } _AnimatedEvaluation.getValue _AnimatedEvaluation\u0026lt;T\u0026gt; extends Animation\u0026lt;T\u0026gt; with AnimationWithParentMixin\u0026lt;double\u0026gt; { @override final Animation\u0026lt;double\u0026gt; parent; final Animatable\u0026lt;T\u0026gt; _evaluatable; @override T get value =\u0026gt; _evaluatable.evaluate(parent); } Animatable.evaluate T evaluate(Animation\u0026lt;double\u0026gt; animation) =\u0026gt; transform(animation.value); T transform(double t); /// A linear interpolation between a beginning and ending value. Tween\u0026lt;T extends dynamic\u0026gt; extends Animatable\u0026lt;T\u0026gt; { /// Returns the interpolated value for the current value of the given animation.  @override T transform(double t) { if (t == 0.0) return begin; if (t == 1.0) return end; return lerp(t); } /// Returns the value this variable has at the given animation clock value.  @protected T lerp(double t) { return begin + (end - begin) * t; } } Demo import \u0026#39;package:flutter/animation.dart\u0026#39;; import \u0026#39;package:flutter/material.dart\u0026#39;; void main() =\u0026gt; runApp(LogoApp()); { _LogoAppState createState() =\u0026gt; _LogoAppState(); } class _LogoAppState extends State\u0026lt;LogoApp\u0026gt; { class _LogoAppState extends State\u0026lt;LogoApp\u0026gt; with SingleTickerProviderStateMixin { Animation\u0026lt;double\u0026gt; animation; AnimationController controller; @override void initState() { super.initState(); controller = AnimationController(duration: const Duration(seconds: 2), vsync: this); animation = Tween\u0026lt;double\u0026gt;(begin: 0, end: 300).animate(controller) ..addListener(() { setState(() { // The state that has changed here is the animation object’s value.  }); }); controller.forward(); } @override Widget build(BuildContext context) { return Center( child: Container( margin: EdgeInsets.symmetric(vertical: 10), height: 300, width: 300, height: animation.value, width: animation.value, child: FlutterLogo(), ), ); } @override void dispose() { controller.dispose(); super.dispose(); } } AnimatedWidget /// A widget that rebuilds when the given [Listenable] changes value. abstract class AnimatedWidget extends StatefulWidget { /// Creates a widget that rebuilds when the given listenable changes.  ///  /// The [listenable] argument is required.  const AnimatedWidget({ Key key, @required this.listenable, }) /// Subclasses typically do not override this method.  @override _AnimatedState createState() =\u0026gt; _AnimatedState(); class _AnimatedState extends State\u0026lt;AnimatedWidget\u0026gt; { @override void initState() { super.initState(); widget.listenable.addListener(_handleChange); } @override void dispose() { widget.listenable.removeListener(_handleChange); super.dispose(); } void _handleChange() { setState(() { // The listenable\u0026#39;s state is our build state, and it changed already.  }); } AnimatedBuilder /// A general-purpose widget for building animations. class AnimatedBuilder extends AnimatedWidget { /// Creates an animated builder.  ///  /// The [animation] and [builder] arguments must not be null.  const AnimatedBuilder({ Key key, @required Listenable animation, @required this.builder, this.child, }) 参考 https://flutter.dev/docs/development/ui/animations\n深入理解Flutter动画原理\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%8C%85%E4%BD%93%E7%A7%AF/",
	"title": "包体积",
	"tags": [],
	"description": "",
	"content": "包体积 探索总结包体积知识\n 包体积压缩     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%8C%85%E4%BD%93%E7%A7%AF/%E5%8C%85%E4%BD%93%E7%A7%AF%E5%8E%8B%E7%BC%A9/",
	"title": "包体积压缩",
	"tags": [],
	"description": "",
	"content": "AndroidBuildProcess Shrink your code To shrink your app’s code, R8 first determines all entry points into your app’s code based on the combined set of configuration files. These entry points include all classes that the Android platform may use to open your app’s Activities or services. Starting from each entry point, R8 inspects your app’s code to build a graph of all methods, member variables, and other classes that your app might access at runtime. Code that is not connected to that graph is considered unreachable and may be removed from the app.\nStrip native libraries Shrink your resources Resource shrinking works only in conjunction with code shrinking. After the code shrinker removes all unused code, the resource shrinker can identify which resources the app still uses. This is especially true when you add code libraries that include resources—you must remove unused library code so the library resources become unreferenced and, thus, removable by the resource shrinker.\nObfuscate your code The purpose of obfuscation is to reduce your app size by shortening the names of your app’s classes, methods, and fields. The following is an example of obfuscation using R8\nCode optimization In order to shrink your app even further, R8 inspects your code at a deeper level to remove more unused code or, where possible, rewrite your code to make it less verbose.\n 10536027字节压缩到4926912字节,压缩了将近53%\n总结\n\\1. 脚本中开启资源混淆和资源压缩\n\\2. 用7zip代替zip\n3.gradle脚本中开启代码混淆优化和无用资源删除\n\\4. 用更小的图，使用压缩工具压缩图片大小\n\\5. 去除无用的资源，语言，本地so库，二方三方库和分辨率\n\\6. 用更小的库\n\\7. 尝试将android support库彻底踢出你的项目\n\\8. 定期清理代码\n\\9. 尝试用H5编写界面，图片云端获取\n\\10. 尝试插件化业务模块\n\\11. 寻找到zip文件夹中所有用STORE形式存储的文件（不限于raw目录下），尝试压缩，以及替代方案加载这些资源\n12. 尝试webp的图片加载方案，寻求突破\n最后，继续学习和尝试新的优化方案\n参考 APK 瘦身记，如何实现高达 53% 的压缩效果\nAndroid App包瘦身优化实践\nhttps://github.com/shwenzhang/AndResGuard\nhttp://tools.android.com/tech-docs/new-build-system/build-workflow\nhttps://developer.android.com/studio/build/shrink-code\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/ashmem/%E5%8C%BF%E5%90%8D%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98ashmem/",
	"title": "匿名共享内存Ashmem",
	"tags": [],
	"description": "",
	"content": "原理图 sequenceDiagram sharedMemory-\u0026gt;\u0026gt;+ashmem_dev: 1: ashmem_create_region ashmem_dev-\u0026gt;\u0026gt;ashmem_dev : fd = __ashmem_open() 创建ashmem_area放入file-\u0026gt;private_data ashmem_dev-\u0026gt;\u0026gt;ashmem_dev: ioctl(fd, ASHMEM_SET_NAME, buf) ashmem_dev-\u0026gt;\u0026gt;ashmem_dev: ioctl(fd, ASHMEM_SET_SIZE, size) ashmem_dev-\u0026gt;\u0026gt;-sharedMemory: fd sharedMemory-\u0026gt;\u0026gt;+Os : 2: mmap Os-\u0026gt;\u0026gt;-ashmem : ashmem_mmap ashmem-\u0026gt;\u0026gt;+shmem: vmfile = shmem_file_setup shmem-\u0026gt;\u0026gt;shmem: shmem_get_inode shmem-\u0026gt;\u0026gt;-shmem: alloc_file ashmem-\u0026gt;\u0026gt;shmem: shmem_set_file sharedMemory-\u0026gt;\u0026gt;ashmem_dev: 3: native_write ashmem_dev-\u0026gt;\u0026gt;ashmem: unpinned \u0026amp;\u0026amp; ashmem_pin_region ashmem_dev-\u0026gt;\u0026gt;shmem: env-\u0026gt;GetByteArrayRegion shmem-\u0026gt;\u0026gt;+shmem: shmem_fault Note right of shmem: 触发缺页中断 shmem-\u0026gt;\u0026gt;-shmem: shmem_getpage分配真实物理页 ashmem_dev-\u0026gt;\u0026gt;ashmem: ashmem_unpin_region MemoryFile public MemoryFile(String name, int length) throws IOException { try { mSharedMemory = SharedMemory.create(name, length); mMapping = mSharedMemory.mapReadWrite(); } catch (ErrnoException ex) { ex.rethrowAsIOException(); } } SharedMemory create public static @NonNull SharedMemory create(@Nullable String name, int size) throws ErrnoException { return new SharedMemory(nCreate(name, size)); } nCreate\nSharedMemory::cons private SharedMemory(FileDescriptor fd) { mFileDescriptor = fd; mSize = nGetSize(mFileDescriptor); mMemoryRegistration = new MemoryRegistration(mSize); mCleaner = Cleaner.create(mFileDescriptor, new Closer(mFileDescriptor, mMemoryRegistration)); } mapReadWrite public @NonNull ByteBuffer mapReadWrite() throws ErrnoException { return map(OsConstants.PROT_READ | OsConstants.PROT_WRITE, 0, mSize); } map public @NonNull ByteBuffer map(int prot, int offset, int length) throws ErrnoException { checkOpen(); validateProt(prot); //mmap  long address = Os.mmap(0, length, prot, OsConstants.MAP_SHARED, mFileDescriptor, offset); boolean readOnly = (prot \u0026amp; OsConstants.PROT_WRITE) == 0; Runnable unmapper = new Unmapper(address, length, mMemoryRegistration.acquire()); return new DirectByteBuffer(length, address, mFileDescriptor, unmapper, readOnly); } Os public static long mmap(long address, long byteCount, int prot, int flags, FileDescriptor fd, long offset) throws ErrnoException { // BlockGuardOs extends ForwardingOs中被代理的Os的mmap,也就是Linux的mmap  return Libcore.os.mmap(address, byteCount, prot, flags, fd, offset); } Libcore public final class Libcore { private Libcore() { } /** * Direct access to syscalls. Code should strongly prefer using {@link #os} * unless it has a strong reason to bypass the helpful checks/guards that it * provides. */ public static Os rawOs = new Linux(); /** * Access to syscalls with helpful checks/guards. */ public static Os os = new BlockGuardOs(rawOs); } Linux mmap public native long mmap(long address, long byteCount, int prot, int flags, FileDescriptor fd, long offset) throws ErrnoException; frameworks/base/core/jni/android_os_SharedMemory.cpp\nandroid_os_SharedMemory SharedMemory_create static jobject SharedMemory_create(JNIEnv* env, jobject, jstring jname, jint size) { // Name is optional so we can\u0026#39;t use ScopedUtfChars for this as it throws NPE on null  const char* name = jname ? env-\u0026gt;GetStringUTFChars(jname, nullptr) : nullptr; int fd = ashmem_create_region(name, size); // Capture the error, if there is one, before calling ReleaseStringUTFChars  int err = fd \u0026lt; 0 ? errno : 0; if (name) { env-\u0026gt;ReleaseStringUTFChars(jname, name); } return jniCreateFileDescriptor(env, fd); } libnativehelper/JNIHelp.cpp\nJNIHelp jniCreateFileDescriptor jobject jniCreateFileDescriptor(C_JNIEnv* env, int fd) { JNIEnv* e = reinterpret_cast\u0026lt;JNIEnv*\u0026gt;(env); if (fileDescriptorInitMethod == nullptr) { InitFieldsAndMethods(e); } jobject fileDescriptor = (*env)-\u0026gt;NewObject(e, JniConstants::fileDescriptorClass, fileDescriptorInitMethod); // NOTE: NewObject ensures that an OutOfMemoryError will be seen by the Java  // caller if the alloc fails, so we just return NULL when that happens.  if (fileDescriptor != NULL) { jniSetFileDescriptorOfFD(env, fileDescriptor, fd); } return fileDescriptor; } system/core/libcutils/ashmem-dev.cpp\nashmem-dev #define ASHMEM_DEVICE \u0026#34;/dev/ashmem\u0026#34; ashmem_create_region /* * ashmem_create_region - creates a new ashmem region and returns the file * descriptor, or \u0026lt;0 on error * * `name\u0026#39; is an optional label to give the region (visible in /proc/pid/maps) * `size\u0026#39; is the size of the region, in page-aligned bytes */ int ashmem_create_region(const char *name, size_t size) { int ret, save_errno; int fd = __ashmem_open(); if (fd \u0026lt; 0) { return fd; } if (name) { char buf[ASHMEM_NAME_LEN] = {0}; strlcpy(buf, name, sizeof(buf)); ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_NAME, buf)); } ret = TEMP_FAILURE_RETRY(ioctl(fd, ASHMEM_SET_SIZE, size)); return fd; } __ashmem_open static int __ashmem_open() { int fd; pthread_mutex_lock(\u0026amp;__ashmem_lock); fd = __ashmem_open_locked(); pthread_mutex_unlock(\u0026amp;__ashmem_lock); return fd; } __ashmem_open_locked /* logistics of getting file descriptor for ashmem */ static int __ashmem_open_locked() { int ret; struct stat st; int fd = TEMP_FAILURE_RETRY(open(ASHMEM_DEVICE, O_RDWR | O_CLOEXEC)); if (fd \u0026lt; 0) { return fd; } ret = TEMP_FAILURE_RETRY(fstat(fd, \u0026amp;st)); __ashmem_rdev = st.st_rdev; return fd; } drivers/staging/android/ashmem.c\nashmem.c #define ASHMEM_NAME_DEF\t\u0026#34;dev/ashmem\u0026#34; ashmem_open static int ashmem_open(struct inode *inode, struct file *file) { struct ashmem_area *asma; int ret; ret = generic_file_open(inode, file); if (unlikely(ret)) return ret; asma = kmem_cache_zalloc(ashmem_area_cachep, GFP_KERNEL); if (unlikely(!asma)) return -ENOMEM; INIT_LIST_HEAD(\u0026amp;asma-\u0026gt;unpinned_list); memcpy(asma-\u0026gt;name, ASHMEM_NAME_PREFIX, ASHMEM_NAME_PREFIX_LEN); asma-\u0026gt;prot_mask = PROT_MASK; file-\u0026gt;private_data = asma; return 0; } ashmem_mmap static int ashmem_mmap(struct file *file, struct vm_area_struct *vma) { struct ashmem_area *asma = file-\u0026gt;private_data; int ret = 0; if (!asma-\u0026gt;file) { char *name = ASHMEM_NAME_DEF; struct file *vmfile; if (asma-\u0026gt;name[ASHMEM_NAME_PREFIX_LEN] != \u0026#39;\\0\u0026#39;) name = asma-\u0026gt;name; /* ... and allocate the backing shmem file */ //shmem_file_setup是原生linux的共享内存机制,匿名共享内存其实就是在Linux共享内存的基础上做了改进 \tvmfile = shmem_file_setup(name, asma-\u0026gt;size, vma-\u0026gt;vm_flags); if (IS_ERR(vmfile)) { ret = PTR_ERR(vmfile); goto out; } vmfile-\u0026gt;f_mode |= FMODE_LSEEK; asma-\u0026gt;file = vmfile; } get_file(asma-\u0026gt;file); if (vma-\u0026gt;vm_flags \u0026amp; VM_SHARED) shmem_set_file(vma, asma-\u0026gt;file); else { if (vma-\u0026gt;vm_file) fput(vma-\u0026gt;vm_file); vma-\u0026gt;vm_file = asma-\u0026gt;file; } return ret; } mm/shmem.c\nshmem.c shmem_file_setup /** * shmem_file_setup - get an unlinked file living in tmpfs * @name: name for dentry (to be seen in /proc/\u0026lt;pid\u0026gt;/maps * @size: size to be set for the file * @flags: VM_NORESERVE suppresses pre-accounting of the entire object size */ struct file *shmem_file_setup(const char *name, loff_t size, unsigned long flags) { return __shmem_file_setup(name, size, flags, 0); } __shmem_file_setup static struct file *__shmem_file_setup(const char *name, loff_t size, unsigned long flags, unsigned int i_flags) { inode = shmem_get_inode(sb, NULL, S_IFREG | S_IRWXUGO, 0, flags);//分配inode，分配成功就好比建立了文件，也许并未存在真实文件映射  res = alloc_file(\u0026amp;path, FMODE_WRITE | FMODE_READ, \u0026amp;shmem_file_operations); return res; } shmem_set_file void shmem_set_file(struct vm_area_struct *vma, struct file *file) { if (vma-\u0026gt;vm_file) fput(vma-\u0026gt;vm_file); vma-\u0026gt;vm_file = file; vma-\u0026gt;vm_ops = \u0026amp;shmem_vm_ops; } //TODO shmem_vm_ops结构体的定义是下面两者中的哪一种，通过debug确定\nstatic const struct vm_operations_struct shmem_vm_ops = { .fault\t= shmem_fault, .map_pages\t= filemap_map_pages, #ifdef CONFIG_NUMA \t.set_policy = shmem_set_policy, .get_policy = shmem_get_policy, #endif }; #define shmem_vm_ops\tgeneric_file_vm_ops  const struct vm_operations_struct generic_file_vm_ops = { .fault\t= filemap_fault, .map_pages\t= filemap_map_pages, .page_mkwrite\t= filemap_page_mkwrite, }; 参考 Android匿名共享内存（Ashmem）原理\nAndroid系统匿名共享内存（Anonymous Shared Memory）C++调用接口分析（1）\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%90%8E%E5%8F%B0%E4%BB%BB%E5%8A%A1/",
	"title": "后台任务",
	"tags": [],
	"description": "",
	"content": "后台任务 探索总结后台任务知识\n 后台任务处理     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%90%8E%E5%8F%B0%E4%BB%BB%E5%8A%A1/%E5%90%8E%E5%8F%B0%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86/",
	"title": "后台任务处理",
	"tags": [],
	"description": "",
	"content": "https://developer.android.com/guide/background/\n图 1. 此决策树可帮助您确定哪个类别最适合您的后台任务。\n推荐的解决方案 下面几部分将介绍针对各个后台任务类型的推荐解决方案。\n即时任务 对于应在用户离开特定作用域或完成某项互动时结束的任务，我们建议使用 Kotlin 协程。许多 Android KTX 库都包含适用于常见应用组件（如 ViewModel）和常见应用生命周期的现成可用的协程作用域。\n如果您是 Java 编程语言用户，请参阅 Android 上的线程处理，了解推荐的选项。\n对于应立即执行并需要继续处理的任务，即使用户将应用放在后台运行或重启设备，我们也建议使用 WorkManager 并利用其对长时间运行的任务的支持。\n在特定情况下（例如使用媒体播放或主动导航功能时），您可能希望直接使用前台服务。\n延期任务 凡是不直接与用户互动相关且日后可随时运行的任务，都可以延期执行。建议为延期任务使用 WorkManager 解决方案。\n如果您希望某些可延期异步任务即使在应用退出或设备重启后仍能正常运行，使用 WorkManager 可以轻松地调度这些任务。如需了解如何调度这些类型的任务，请参阅 WorkManager 相关文档。\n精确任务 需要在精确时间点执行的任务可以使用 AlarmManager。\n如需详细了解 AlarmManager，请参阅设置重复闹铃时间。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/",
	"title": "启动流程",
	"tags": [],
	"description": "",
	"content": "启动流程 探索总结启动流程知识\n ART启动流程     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E5%93%8D%E5%BA%94%E5%BC%8F%E6%9E%B6%E6%9E%84/",
	"title": "响应式架构",
	"tags": [],
	"description": "",
	"content": "响应式架构 探索总结响应式架构知识\n 1跨组件传递数据     2Provider     3异步_响应式_状态管理     stream    Stream      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%9F%8B%E7%82%B9/",
	"title": "埋点",
	"tags": [],
	"description": "",
	"content": "埋点 探索总结埋点知识\n 埋点     易观方舟     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%9F%8B%E7%82%B9/%E5%9F%8B%E7%82%B9/",
	"title": "埋点",
	"tags": [],
	"description": "",
	"content": "功能需求：\n我们希望提供以下功能\n 和业务无关的代码，我们希望能够以无需手动埋点的方式进行监控，包括页面生命周期、JSON耗时，网络耗时、SQL查询耗时、点击事件、页面进入等 对特定方法进行耗时监控，我们希望用户给方法加上注解就可以，称之为半埋点 编译期，需要能够支持配置，包括对哪些页面、哪些操作进行监控 运行期，能够动态下发配置，包括各类耗时监控的上报开关和阈值等  代码埋点 **代码埋点是指在某个事件发生时调用数据发送接口上报数据。**例如开发人员按照产品/运营的需求，在Web页面/App的源码里面添加行为上报的代码，当用户的行为满足某一个条件时，这些代码就会被执行，向服务器上报行为数据。这种方案是最基础的方案，每次增加或者修改数据上报的条件，都需要开发人员的参与，并且只能在下一个版本上线后才能看到效果。基本上所有的数据平台都提供了这类数据上报的SDK，将行为上报的后台服务器接口封装成了简单的客户端SDK接口。开发者可以通过嵌入这类SDK，在埋点的地方调用少量的代码就可以上报行为数据。\n全埋点 全埋点指的是将Web页面/App内产生的所有的、满足某个条件的行为，全部上报到后台服务器。例如把一个App中所有的按钮点击都进行上报，然后由产品/运营去后台筛选所需要的行为数据。这种方案的优点非常明显，就是可以不用在新增/修改行为上报条件时，再找开发人员去修改埋点的代码。然而它的缺点也和优点一样明显，那就是上报的数据量比代码埋点大很多，里面可能很多是没有价值的数据。此外，这种方案更倾向于独立去看待用户的行为，而没有关注行为的上下文，给数据分析带来了一些难度。很多公司也提供了这类功能的SDK，通过静态或者动态的方式，“Hook”了原有的App代码，从而实现了行为的监测，在数据上报时通常是采用累积多条再上报的方案来合并请求。\n可视化埋点 可视化埋点技术揭秘\n▌什么是可视化埋点 **可视化埋点是指通过可视化工具配置采集节点，在App/Web解析配置查找节点，监听节点产生的事件并上报。**例如产品在Web页面/App的界面上进行圈选，配置需要监测界面上哪一个元素，然后保存这个配置，当App启动时会从后台服务器获得产品/运营预先圈选好的配置，然后根据这份配置查找并监测App界面上的元素，当某一个元素满足条件时，就会上报行为数据到后台服务器。有了暴力的全埋点技术方案，很容易联想到按需埋点，可视化埋点就是一种按需配置埋点的方案。现在也有一些公司提供了这类SDK，圈选监测元素时，有的是提供一个Web管理界面，手机在安装并初始化了SDK之后，可以和管理界面了连接，让用户在Web管理界面上配置需要监测的元素，有的是直接让用户在手机上圈选元素进行埋点。\n可视化埋点，通常是指用户通过设备连接用户行为分析工具的数据接入管理界面，对可交互且交互后有效果的页面元素（如：图片、按钮、链接等），直接在界面上进行操作实现数据埋点，下发采集代码生效回数的埋点方式。这种方式所见即所得，跳过代码部署、测试验证和发版过程，极大提升生产力。\n▌可视化埋点的具体流程 首先手机APP嵌入开启可视化功能的SDK，通过WebSocket的方式和服务器、前端进行相互通信，SDK会定时收到服务器下发的页面请求；然后会上报页面快照和界面因子信息到服务器，服务器收到信息后会根据界面因子信息对页面的每个元素进行分析，根据控件的类型来标记哪些页面元素是可以被埋点的；最后将可埋点信息交给前端渲染，此时，前端Web页面上展示就的就是可以埋点的页面。\n埋点人员在渲染出来的前端Web页面上进行框选，标记事件属性等进行埋点。前端Web页面会将对应的埋点信息传递给服务器保存，SDK则会通过策略定时从服务器获取埋点信息。\n以上就是整个埋点的大体工作流程，具体包含WebSocket通信过程以及具体的埋点过程。下面就针对这两个过程分别进行细致的介绍。\n▌WebSocket通信 由于埋点过程中需要设备APP与前端埋点Web页面进行长时间的连接，并且连接期间双方需要进行互相通信，所以就需要一种高效的支持双向通信的协议来支持这种场景。\nWebSocket是用于在Web浏览器和服务器之间进行任意的双向数据传输的一种技术，它基于TCP协议实现，包含初始的握手过程，以及后续的多次数据帧双向传输过程。其目的是在应用和服务器进行频繁双向通信时，可以避免Server端被打开多个HTTP连接进行工作，节约资源、提高了工作效率和资源利用率。WebSocket被广泛用于Web的实时消息通信系统中。它实现了浏览器与服务器全双工通信，将会替代基于HTTP的Ajax长轮询的拉取消息模式。建立了WebSocket连接后，只要客户端和服务器端任意一端不主动断开连接前，通信行为都是在一个持久连接上发起，后续数据与请求都通过帧序列的形式进行传输。\n在具体的连接过程中，其实前端Web页面和SDK与服务器的连接都是基于WebSocket的，并且这两个连接最终会建立一个一对一的对应关系。易观在埋点的过程中规定，同一个版本的APP只允许一台设备进行连接埋点。流程如下图：\n该图描述的是SDK如何与服务器建立WebSocket连接以及如何与前端Web页面进行关联，具体有以下几个步骤：\n1.埋点人员打开埋点Web页面，页面与服务器建立连接。\n2.打开手机APP(已经提前集成了易观可视化埋点功能的SDK)，手机摇一摇建立WebSocket连接。\n3.服务端通过WebSocket连接请求该手机的设备信息。\n4.手机收到服务器的请求后获取对应的设备信息，然后通过WebSocket上报设备信息到服务器。\n5.服务器收到设备的信息后发送到步骤一的Web页面进行显示。\n6.埋点人员在Web页面选择手机进行关联，同时服务器通过WebSocket发送快照请求到手机。\n以上就是具体的设备的连接过程，到此为止，服务器与手机就已经建立了一个可以相互通信的长连接，并且与Web页面进行了关联，如果此时再有同一版本的APP进行连接，页面会提示用户该版本的APP已经进行连接了。\n接下来就是埋点过程中，服务器会定时向手机下发请求信息来获取最新的页面信息：\n1.服务器定时请求手机的快照信息，手机在收到快照请求后发送快照信息到服务器。\n2.WebSocket服务器收到手机的快照信息后，首先把标志置为false，待解析完快照信息后发送至Web界面进行展示。\n3.发送成功后把标志置为true,定时服务根据标志来决定是否继续请求快照。\n4.心跳包为APP以及WEB端定时发送，来保证WebSocket的长连接畅通。\n以上就是埋点过程中，整个WebSocket的工作流程。这里面有几个需要注意的地方：\n1.SDK通过WebSocket上报的页面快照信息大小是根据当前页面的复杂度来决定的。如果当前页面包含的元素比较多，那么上传的快照信息就会比较大，这样上传至服务器就会比较慢。在网络不好的情况下出错的概率就比较大。易观在这方面做了一些优化，会对上传的信息进行一些优化和压缩处理，从而尽可能兼顾效率的同时保证上报数据的连续性和完整性。\n2.SDK上报快照信息是被动的，是通过服务器来控制的。服务器会定时（比如每隔几秒）请求SDK上报信息。这样就会有一个问题，就是SDK在此期间没有发生页面的切换，页面信息没有变化，这时候收到服务器请求就无需上报快照信息，否则既浪费带宽，体验上也不好。所以易观在这方面也做了优化，服务端和SDK通过某些机制来尽量减少比较大的交互过程，尽量减少不必要的请求。\n▌埋点过程 下面介绍一下具体的埋点过程，先看下图：\n埋点过程是通过Http协议来实现的。服务器提供相关的埋点查询/新增/修改/删除的接口。埋点人员通过浏览器在具体的埋点Web页面对埋点元素进行框选，继而填写对应的事件名称，然后点击相应的新增/修改/删除按钮即可。\n用户编辑的所有的埋点信息最终都会保存到MySQL数据库中。用户最新的快照信息会保存在Redis中一段时间，供用户修改埋点的时候调用。用户编辑完所有的埋点后点击部署按钮，所有的埋点就会实时生效，其他设备上的APP就会获取到部署后的埋点信息。\n至此，可视化埋点的流程和技术细节就介绍完了。\n参考 强大！asm插桩实现android端无埋点性能监控！\nAndroid埋点技术分析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/",
	"title": "基础数据结构",
	"tags": [],
	"description": "",
	"content": "dex文件里class_def ArtField 一个ArtField对象仅仅是代表一个Java类的成员变量，但它自己并不提供空间来存储这个Java成员变量的内容。Class LinkFields时我们将看到这个Java成员变量所需的存储空间在什么地方\n.... private： GcRoot\u0026lt;mirror::Class\u0026gt; declaring_class_; //该成员变量在哪个类中被定义  uint32_t access_flags_; //该成员变量的访问标记  //该成员变量在dex文件中field_ids数组中的索引，注意，它是由图8-7中encoded_field结  //构体中field_idx_diff计算而来  uint32_t field_dex_idx_; //如果ArtField所代表的成员变量是类的静态成员变量，则下面的offset_代表是该变量实际的存储  //空间在图8-13里Class内存布局中的起始位置。如果是非静态成员变量，则offset_指向图8-13中  //Object内存布局里对应的位置。  uint32_t offset_; ArtMethod 7.0\n...... protected: //下面这四个成员变量的解释可参考图8-7  GcRoot\u0026lt;mirror::Class\u0026gt; declaring_class_; //本函数在哪个类中声明  uint32_t access_flags_; uint32_t dex_code_item_offset_; //表示某个方法在dex文件method_ids数组中的索引  uint32_t dex_method_index_; //与ArtField的field_index_类似，下面这个成员变量和Class类如何管理它的成员函数有关。  //如果这个ArtMethod对应的是一个static或direct函数，则method_index_是指向定义它的类的methods_中的索引。 //如果这个ArtMethod是virtual函数，则method_index_是指向它的VTable中的索引。注意，可能多个类的VTable都包含该//ArtMethod对象（比如Object的那11个方法），所以要保证这个method_index_在不同VTable中都有相同的值——这也是//LinkMethods中那三个函数比较复杂的原因。  uint16_t method_index_; //热度。函数每被调用一次，该值递增1。一旦超过某个阈值，该函数可能就需要被编译成本地方法以加  //快执行速度了。  uint16_t hotness_count_; struct PACKED(4) PtrSizedFields { //指向declaring_class_-\u0026gt;dex_cache_的resolved_methods_成员，详情需结合下文对Dex-Cache的介绍。  ArtMethod** dex_cache_resolved_methods_; //指针的指针，指向declaring_class_-\u0026gt;dex_cache_的dex_cache_resolved_types_成员，详情需结合下文对DexCache的介绍  GcRoot\u0026lt;mirror::Class\u0026gt;* dex_cache_resolved_types_; //下面两个变量是函数指针，它们是一个ArtMethod对象代表的Java方法的入口函数地址。  //我们后续章节介绍Java代码执行的时候再来讨论它  void* entry_point_from_jni_; // Method dispatch from quick compiled code invokes this pointer which may cause bridging into  // the interpreter.  void* entry_point_from_quick_compiled_code_; } ptr_sized_fields_; } 9.0上的差异\n// Must be the last fields in the method.  struct PtrSizedFields { // Depending on the method type, the data is  // - native method: pointer to the JNI function registered to this method  // or a function to resolve the JNI function,  // - conflict method: ImtConflictTable,  // - abstract/interface method: the single-implementation if any,  // - proxy method: the original interface method or constructor,  // - other methods: the profiling data.  void* data_; // Method dispatch from quick compiled code invokes this pointer which may cause bridging into  // the interpreter.  void* entry_point_from_quick_compiled_code_; } ptr_sized_fields_; DexCache ..... private: HeapReference\u0026lt;Object\u0026gt; dex_; //dex文件对应的路径  HeapReference\u0026lt;String\u0026gt; location_; //实际为DexFile*，指向所关联的那个Dex文件。  uint64_t dex_file_; /*实际为ArtField**，指向ArtField*数组，成员的数据类型为ArtField*。该数组存储了一个Dex 文件中定义的所有类的成员变量。另外，只有那些经解析后得到的ArtField对象才会存到这个数组里。 该字段和Dex文件里的field_ids数组有关。 */ uint64_t resolved_fields_; /*实际为ArtMethod**，指向ArtMethod*数组，成员的数据类型为ArtMethod*。该数组存储了一个 Dex文件中定义的所有类的成员函数。另外，只有那些经解析后得到的ArtMethod对象才会存到这 个数组里。该字段和Dex文件里的method_ids数组有关。 */ uint64_t resolved_methods_; /*实际为GCRoot\u0026lt;Class\u0026gt;*，指向GcRoot\u0026lt;Class\u0026gt;数组，成员的数据类型为GcRoot\u0026lt;Class\u0026gt;（本质 质上就是mirror::Class*）,它存储的内容直接指向dex文件里用到的或自定义数据类型所对应的Class对象。它存储该dex文件里使用的数据类型信息数组。该字段和Dex文件里的type_ids数组有关。 */ uint64_t resolved_types_; /*实际为GCRoot\u0026lt;String\u0026gt;*，指向GcRoot\u0026lt;String\u0026gt;数组，包括该dex文件里使用的字符串信息数组。 注意，GcRoot\u0026lt;String\u0026gt;本质上就是mirror::String*。该字段和Dex文件的string_ids数组有关 */ uint64_t strings_; //下面四个变量分别表示上述四个数组的长度  uint32_t num_resolved_fields_; uint32_t num_resolved_methods_; uint32_t num_resolved_types_; uint32_t num_strings_; }; class Class : public Object public: /*下面这个枚举变量用于描述类的状态。上文曾介绍过，一个类从dex文件里被加载到最终能被使 用将经历很多个操作步骤。这些操作并不是连续执行的，而是可能被分散在不同的地方以不同的时 机来执行不同的操作。所以，需要过类的状态来描述某个类当前处于什么阶段，这样便可知道下一 步需要做什么工作。Class对象创建之初，其状态为kStatusNotReady，最终可正常使用的状 态为kStatusInitialized。下文分析类加载的相关代码时，读者可看到状态是如何转变的。 */ enum Status { kStatusRetired = -2, kStatusError = -1, kStatusNotReady = 0, kStatusIdx = 1, kStatusLoaded = 2, kStatusResolving = 3, kStatusResolved = 4, kStatusVerifying = 5, kStatusRetryVerificationAtRuntime = 6, kStatusVerifyingAtRuntime = 7, kStatusVerified = 8, kStatusInitializing = 9, kStatusInitialized = 10, kStatusMax = 11, }; //加载本类的ClassLoader对象，如果为空，则为bootstrap system loader  HeapReference\u0026lt;ClassLoader\u0026gt; class_loader_; //下面这个成员变量对数组类才有意义，用于表示数组元素的类型。比如，对String[][][]类而  //言，component_type_代表String[][]。本章后文介绍数组类的时候还会讨论它。  HeapReference\u0026lt;Class\u0026gt; component_type_; //该类缓存在哪个DexCahce对象中。注意，有些类是由虚拟机直接创建的，而不是从Dex文件里  //读取的。比如基础数据类型。这种情况下dex_cache_取值为空。  HeapReference\u0026lt;DexCache\u0026gt; dex_cache_; /*结合图8-6可知，IfTable从ObjectArray\u0026lt;Object\u0026gt;派生，所以它实际上是一个数组容器。 为什么不直接使用它的父类ObjectArray\u0026lt;Object\u0026gt;呢？根据ART虚拟机的设计，IfTable中 的一个索引位置其实包含两项内容，第一项是该类所实现的接口类的Class对象，第二项则是 和第一项接口类有关的接口函数信息。笔者先用伪代码来描述IfTable中索引x对应的内容： 第一项内容：具体位置为iftable_内部数组[x+0]，元素类型为Class*，代表某个接口类 第二项内容：具体位置为iftable_内部数组[x+1]，元素类型为PointArray*。如图8-6可知， PointArray也是一个数组。其具体内容我们下文再详述。 另外，对类A而言，它的iftable_所包含的信息来自于如下三个方面： （1）类A自己所实现的接口类。 （2）类A从父类（direct superclass）那里获取的信息。 （3）类A从接口父类（direct super interface）那里获取的信息。 笔者先不介绍上面所谓的信息具体是什么，下文将对IfTable的元素构成做详细代码分析。 */ HeapReference\u0026lt;IfTable\u0026gt; iftable_; //本类的类名  HeapReference\u0026lt;String\u0026gt; name_; //代表父类。如果本类代表Object或基础数据类型，则该成员变量为空  HeapReference\u0026lt;Class\u0026gt; super_class_; /*virtual methods table。它指向一个PointArray数组，元素的类型为ArtMethod*。 这个vtable_的内容很丰富，下面的章节会详细介绍它。 */ HeapReference\u0026lt;PointerArray\u0026gt; vtable_; //类的访问标志。该字段的低16位可虚拟机自行定义使用  uint32_t access_flags_; uint64_t dex_cache_strings_; //指向DexCache的strings_成员变量实际为LengthPrefixedArray\u0026lt;ArtField\u0026gt;，代表本  //类声明的非静态成员变量。注意，这个LengthPrefixedArray的元素类型是ArtField，不  //是ArtField*。  uint64_t ifields_; /*下面这三个变量需配合使用。其中，methods_实际为LengthPrefixedArray\u0026lt;ArtMethod\u0026gt;， 代表该类自己定义的成员函数。它包括类里定义的virtual和direct的成员函数，也包括从接 口类中继承得到的默认函数以及所谓的miranda函数（下文将介绍接口类的默认实现函数以及 miranda函数）。methods_中元素排列如下： （1）[0,virtual_methods_offset_)为本类包含的direct成员函数 （2）[virtual_methods_offset_,copied_methods_offset_)为本类包含的virtual 成员函数 （3）[copied_methods_offset_,...)为剩下的诸如miranda函数等内容 */ uint64_t methods_; uint16_t copied_methods_offset_; uint16_t virtual_methods_offset_; uint64_t sfields_; //同ifields_类似，只不过保存的是本类的静态成员变量  uint32_t class_flags_; //虚拟机内部使用  uint32_t class_size_; //当分配一个类对象时，用于说明这个类对象所需的内存大小  pid_t clinit_thread_id_; //代表执行该类初始化函数的线程ID  int32_t dex_class_def_idx_; //本类在dex文件中class_defs数组对应元素的索引  int32_t dex_type_idx_; //本类在dex文件里type_ids中的索引  //下面两个成员变量表示本类定义的引用类型的非静态和静态成员变量的个数  uint32_t num_reference_instance_fields_; uint32_t num_reference_static_fields_; //该类的实例所占据的内存大小。也就是我们在Java层new一个该类的实例时，这个实例所需的内存大小  uint32_t object_size_; /*下面这个变量的低16位存储的是Primitive::Type枚举值，其定义如下： enum Type { kPrimNot = 0, kPrimBoolean, kPrimByte, kPrimChar, kPrimShort, kPrimInt, kPrimLong, kPrimFloat, kPrimDouble, kPrimVoid, kPrimInt, kPrimLong, kPrimFloat, kPrimDouble, kPrimVoid, kPrimLast = kPrimVoid }; 其中，kPrimNot表示非基础数据类型，即它代表引用类型。 primitive_type_的高16位另有作用，后文碰到再述 */ uint32_t primitive_type_; //下面这个变量指向一个内存地址，该地址中存储的是一个位图，它和Class中用于表示引用类型  //的非静态成员变量的信息（ifields）有关。  uint32_t reference_instance_offsets_; Status status_; //类的状态  /*特别注意。虽然下面三个成员变量定义在注释语句中，但实际的Class对象内存空间可能包含 对应的内容，笔者称之为Class的隐含成员变量。它们的取值情况我们下文会详细介绍*/ /*Embedded Imtable（内嵌Interface Method Table）,是一个固定大小的数组。数组元素 的类型为ImTableEntry，但代码中并不存在这样的数据类型。实际上，下面这个隐含成员变量 的声明可用 ArtMethod* embedded_imtable_[0]来表示 */ //ImTableEntry embedded_imtable_[0];  /*Embedded Vtable（内嵌Virtual Table），是一个非固定大小的数组。数组元素为VTable- Entry，但代码中也不存在这样的数据类型。和上面的embedded_imtable_类似，它的声明 也可用ArtMethod* embedded_vtable_[0]来表示 */。 //VTableEntry embedded_vtable_[0];  //下面这个数组存储Class中的静态成员变量的信息  //uint32_t fields_[0];  //再次请读者注意，以上三个隐含成员变量的内容将在下文介绍。  //指向代表java/lang/Class的类对象。注意，它是static类型，它不是隐含成员变量  static GcRoot\u0026lt;Class\u0026gt; java_lang_Class_; }; "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%A4%9A%E8%BF%9B%E7%A8%8B/",
	"title": "多进程",
	"tags": [],
	"description": "",
	"content": "多进程 探索总结多进程知识\n binder    1BinderServiceManager     2BinderServer     3BinderClient     4BinderKernel     BinderDeath     Binder原理      mmkv     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%AD%98%E5%82%A8/",
	"title": "存储",
	"tags": [],
	"description": "",
	"content": "存储 探索总结存储知识\n sharedpreferences    SharedPreferences      "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%AE%89%E5%85%A8/",
	"title": "安全",
	"tags": [],
	"description": "",
	"content": "安全 探索总结安全知识\n app签名     应用安全     网络请求安全     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%B8%83%E5%B1%80%E4%BC%98%E5%8C%96/",
	"title": "布局优化",
	"tags": [],
	"description": "",
	"content": "布局优化 探索总结布局优化知识\n 布局优化     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/%E5%B8%83%E5%B1%80%E4%BC%98%E5%8C%96/%E5%B8%83%E5%B1%80%E4%BC%98%E5%8C%96/",
	"title": "布局优化",
	"tags": [],
	"description": "",
	"content": "布局加载优化 graph LR 正面解决(正面解决)--\u0026gt;去IO,去解析--\u0026gt;|solution|frontSolution(\u0026quot;X2C,Anko,Compose\u0026quot;) 正面解决--\u0026gt;去反射--\u0026gt;|solution|frontSolution 侧面解决--\u0026gt;异步加载--\u0026gt;|solution|AsyncLayoutInflater 我们可以看到，在setContentView中主要有两个耗时操作：\n1.解析xml,获取XmlResourceParser,这是IO过程。\n2.通过createViewFromTag,创建View对象，用到了反射。\n以上两点就是布局加载可能导致卡顿的原因，也是布局的性能瓶颈。\n耗时监听 AOP(Aspectj,ASM) @Around(\u0026#34;execution(* android.app.Activity.setContentView(..))\u0026#34;) public void getSetContentViewTime(ProceedingJoinPoint joinPoint) { Signature signature = joinPoint.getSignature(); String name = signature.toShortString(); long time = System.currentTimeMillis(); try { joinPoint.proceed(); } catch (Throwable throwable) { throwable.printStackTrace(); } Log.i(\u0026#34;aop inflate\u0026#34;,name + \u0026#34; cost \u0026#34; + (System.currentTimeMillis() - time)); } 上面用的Aspectj，比较简单，上面的注解的意思是在setContentView方法执行内部去调用我们写好的getSetContentViewTime方法。 这样就可以获取相应的耗时。我们可以看下打印的日志：\nI/aop inflate: AppCompatActivity.setContentView(..) cost 69 I/aop inflate: AppCompatActivity.setContentView(..) cost 25 这样就可以实现无侵入的监控每个页面布局加载的耗时。\n获取任一控件耗时 有时为了更精确的知道到底是哪个控件加载耗时，比如我们新添加了自定义View,需要监控它的性能。 我们可以利用setFactory2来监听每个控件的加载耗时。首先我们来回顾下setContentView方法：\npublic final View tryCreateView(@Nullable View parent, @NonNull String name, ... View view; if (mFactory2 != null) { view = mFactory2.onCreateView(parent, name, context, attrs); } else if (mFactory != null) { view = mFactory.onCreateView(name, context, attrs); } else { view = null; } ... return view; } 在真正进行反射实例化xml结点前，会调用mFactory2的onCreateView方法。 这样如果我们重写onCreateView方法，在其前后加上耗时统计，即可获取每个控件的加载耗时。\nprivate fun initItemInflateListener(){ LayoutInflaterCompat.setFactory2(layoutInflater, object : Factory2 { override fun onCreateView( parent: View?, name: String, context: Context, attrs: AttributeSet ): View? { val time = System.currentTimeMillis() val view = delegate.createView(parent, name, context, attrs) Log.i(\u0026#34;inflate Item\u0026#34;,name + \u0026#34; cost \u0026#34; + (System.currentTimeMillis() - time)) return view } override fun onCreateView(name: String, context: Context, attrs: AttributeSet): View? { return null } }) } 如上所示：真正的创建View的方法，仍然是调用delegate.createView,我们只是其之前与之后做了埋点。\n注意，initItemInflateListener需要在onCreate之前调用。这样就可以比较方便地实现监听每个控件的加载耗时。\n参考 //编译生成xml\u0026ndash;\u0026gt;javaView\nhttps://github.com/iReaderAndroid/X2C\n//仅仅优化反射\nandroid \u0026ldquo;退一步\u0026quot;的布局加载优化\nAndroid布局优化（三）使用AsyncLayoutInflater异步加载布局\nAndroid 布局优化真的难，从入门到放弃\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%80%E5%87%BA/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8/",
	"title": "应用启动",
	"tags": [],
	"description": "",
	"content": "原理图 上述流程4——5之间还有一个过程，即当ActivityManagerService调用attachApplicationLocked时会跨进程调用thread.bindApplication通知应用进程发消息并调用handleBindApplication，内部会第一次初始化应用进程的mResources和mClassLoader给LoadedApk\nActivity.startActivity public void startActivityForResult(@RequiresPermission Intent intent, int requestCode, @Nullable Bundle options) { if (mParent == null) { options = transferSpringboardActivityOptions(options); Instrumentation.ActivityResult ar = mInstrumentation.execStartActivity( this, mMainThread.getApplicationThread(), mToken, this, intent, requestCode, options); } } Instrumentation.execStartActivity public ActivityResult execStartActivity( Context who, IBinder contextThread, IBinder token, Activity target, Intent intent, int requestCode, Bundle options) { IApplicationThread whoThread = (IApplicationThread) contextThread; int result = ActivityManager.getService() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target != null ? target.mEmbeddedID : null, requestCode, 0, null, options); ActivityManager.getService().startActivity public static IActivityManager getService() { return IActivityManagerSingleton.get(); } private static final Singleton\u0026lt;IActivityManager\u0026gt; IActivityManagerSingleton = new Singleton\u0026lt;IActivityManager\u0026gt;() { @Override protected IActivityManager create() { final IBinder b = ServiceManager.getService(Context.ACTIVITY_SERVICE); final IActivityManager am = IActivityManager.Stub.asInterface(b); return am; } }; public abstract class Singleton\u0026lt;T\u0026gt; { private T mInstance; protected abstract T create(); public final T get() { synchronized (this) { if (mInstance == null) { mInstance = create(); } return mInstance; } } } ActivityManagerService.startActivity @Override public final int startActivity(IApplicationThread caller, String callingPackage, Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, Bundle bOptions) { return startActivityAsUser(caller, callingPackage, intent, resolvedType, resultTo, resultWho, requestCode, startFlags, profilerInfo, bOptions, UserHandle.getCallingUserId()); } public final int startActivityAsUser(IApplicationThread caller, String callingPackage, Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, Bundle bOptions, int userId, boolean validateIncomingUser) { enforceNotIsolatedCaller(\u0026#34;startActivity\u0026#34;); userId = mActivityStartController.checkTargetUser(userId, validateIncomingUser, Binder.getCallingPid(), Binder.getCallingUid(), \u0026#34;startActivityAsUser\u0026#34;); // TODO: Switch to user app stacks here.  return mActivityStartController.obtainStarter(intent, \u0026#34;startActivityAsUser\u0026#34;) .setCaller(caller) .setCallingPackage(callingPackage) .setResolvedType(resolvedType) .setResultTo(resultTo) .setResultWho(resultWho) .setRequestCode(requestCode) .setStartFlags(startFlags) .setProfilerInfo(profilerInfo) .setActivityOptions(bOptions) .setMayWait(userId) .execute(); } /** * Starts an activity based on the request parameters provided earlier. * @return The starter result. */ int execute() { return startActivity(mRequest.caller, mRequest.intent, mRequest.ephemeralIntent, mRequest.resolvedType, mRequest.activityInfo,......; } private int startActivity(IApplicationThread caller, Intent intent, Intent ephemeralIntent,......) { ActivityRecord r = new ActivityRecord(mService, callerApp, callingPid, callingUid, callingPackage, intent, resolvedType, aInfo, mService.getGlobalConfiguration(), resultRecord, resultWho, requestCode, componentSpecified, voiceSession != null, mSupervisor, checkedOptions, sourceRecord); return startActivity(r, sourceRecord, voiceSession, voiceInteractor, startFlags, true /* doResume */, checkedOptions, inTask, outActivity); } private int startActivity(final ActivityRecord r, ActivityRecord sourceRecord, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, int startFlags, boolean doResume, ActivityOptions options, TaskRecord inTask, ActivityRecord[] outActivity) { int result = START_CANCELED; try { result = startActivityUnchecked(r, sourceRecord, voiceSession, voiceInteractor, startFlags, doResume, options, inTask, outActivity); private int startActivityUnchecked(final ActivityRecord r, ActivityRecord sourceRecord, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, int startFlags, boolean doResume, ActivityOptions options, TaskRecord inTask, ActivityRecord[] outActivity) { final TaskRecord taskToAffiliate = (mLaunchTaskBehind \u0026amp;\u0026amp; mSourceRecord != null) ? mSourceRecord.getTask() : null; // Should this be considered a new task?  int result = START_SUCCESS; if (mStartActivity.resultTo == null \u0026amp;\u0026amp; mInTask == null \u0026amp;\u0026amp; !mAddingToTask \u0026amp;\u0026amp; (mLaunchFlags \u0026amp; FLAG_ACTIVITY_NEW_TASK) != 0) { newTask = true; result = setTaskFromReuseOrCreateNewTask(taskToAffiliate, topStack); } else if (mSourceRecord != null) { result = setTaskFromSourceRecord(); } else if (mInTask != null) { result = setTaskFromInTask(); } else { // This not being started from an existing activity, and not part of a new task...  // just put it in the top task, though these days this case should never happen.  setTaskToCurrentTopOrCreateNewTask(); } mSupervisor.resumeFocusedStackTopActivityLocked(mTargetStack, mStartActivity,mOptions); boolean resumeFocusedStackTopActivityLocked( ActivityStack targetStack, ActivityRecord target, ActivityOptions targetOptions) { final ActivityRecord r = mFocusedStack.topRunningActivityLocked(); if (r == null || !r.isState(RESUMED)) { mFocusedStack.resumeTopActivityUncheckedLocked(null, null); } return false; } boolean resumeTopActivityUncheckedLocked(ActivityRecord prev, ActivityOptions options) { boolean result = false; try { // Protect against recursion.  mStackSupervisor.inResumeTopActivity = true; result = resumeTopActivityInnerLocked(prev, options); } finally { mStackSupervisor.inResumeTopActivity = false; } return result; } @GuardedBy(\u0026#34;mService\u0026#34;) private boolean resumeTopActivityInnerLocked(ActivityRecord prev, ActivityOptions options) { mStackSupervisor.startSpecificActivityLocked(next, true, false); } void startSpecificActivityLocked(ActivityRecord r, boolean andResume, boolean checkConfig) { // Is this activity\u0026#39;s application already running?  ProcessRecord app = mService.getProcessRecordLocked(r.processName, r.info.applicationInfo.uid, true); if (app != null \u0026amp;\u0026amp; app.thread != null) { //进程已经启动  try { if ((r.info.flags\u0026amp;ActivityInfo.FLAG_MULTIPROCESS) == 0 || !\u0026#34;android\u0026#34;.equals(r.info.packageName)) { // Don\u0026#39;t add this if it is a platform component that is marked  // to run in multiple processes, because this is actually  // part of the framework so doesn\u0026#39;t make sense to track as a  // separate apk in the process.  app.addPackage(r.info.packageName, r.info.applicationInfo.longVersionCode, mService.mProcessStats); } realStartActivityLocked(r, app, andResume, checkConfig); return; } } //启动应用进程  mService.startProcessLocked(r.processName, r.info.applicationInfo, true, 0, \u0026#34;activity\u0026#34;, r.intent.getComponent(), false, false, true); } startProcessLocked @GuardedBy(\u0026#34;this\u0026#34;) final ProcessRecord startProcessLocked(String processName, ApplicationInfo info, boolean knownToBeDead, int intentFlags, String hostingType, ComponentName hostingName, boolean allowWhileBooting, boolean isolated, boolean keepIfLarge) { return startProcessLocked(processName, info, knownToBeDead, intentFlags, hostingType, hostingName, allowWhileBooting, isolated, 0 /* isolatedUid */, keepIfLarge, null /* ABI override */, null /* entryPoint */, null /* entryPointArgs */, null /* crashHandler */); } @GuardedBy(\u0026#34;this\u0026#34;) final ProcessRecord startProcessLocked(String processName, ApplicationInfo info, boolean knownToBeDead, int intentFlags, String hostingType, ComponentName hostingName, boolean allowWhileBooting, boolean isolated, int isolatedUid, boolean keepIfLarge, String abiOverride, String entryPoint, String[] entryPointArgs, Runnable crashHandler) { ProcessRecord app; if (app == null) { app = newProcessRecordLocked(info, processName, isolated, isolatedUid); } final boolean success = startProcessLocked(app, hostingType, hostingNameStr, abiOverride); return success ? app : null; } @GuardedBy(\u0026#34;this\u0026#34;) private final boolean startProcessLocked(ProcessRecord app, String hostingType, String hostingNameStr, String abiOverride) { return startProcessLocked(app, hostingType, hostingNameStr, false /* disableHiddenApiChecks */, abiOverride); } /** * @return {@code true} if process start is successful, false otherwise. */ @GuardedBy(\u0026#34;this\u0026#34;) private final boolean startProcessLocked(ProcessRecord app, String hostingType, String hostingNameStr, boolean disableHiddenApiChecks, String abiOverride) { ...... return startProcessLocked(hostingType, hostingNameStr, entryPoint, app, uid, gids, runtimeFlags, mountExternal, seInfo, requiredAbi, instructionSet, invokeWith, startTime); } @GuardedBy(\u0026#34;this\u0026#34;) private boolean startProcessLocked(String hostingType, String hostingNameStr, String entryPoint, ProcessRecord app, int uid, int[] gids, int runtimeFlags, int mountExternal, String seInfo, String requiredAbi, String instructionSet, String invokeWith, long startTime) { final ProcessStartResult startResult = startProcess(hostingType, entryPoint, app, uid, gids, runtimeFlags, mountExternal, seInfo, requiredAbi, instructionSet, invokeWith, startTime); } private ProcessStartResult startProcess(String hostingType, String entryPoint, ProcessRecord app, int uid, int[] gids, int runtimeFlags, int mountExternal, String seInfo, String requiredAbi, String instructionSet, String invokeWith, long startTime) { startResult = Process.start(entryPoint, app.processName, uid, uid, gids, runtimeFlags, mountExternal, app.info.targetSdkVersion, seInfo, requiredAbi, instructionSet, app.info.dataDir, invokeWith, new String[] {PROC_START_SEQ_IDENT + app.startSeq}); } public static final ZygoteProcess zygoteProcess = new ZygoteProcess(ZYGOTE_SOCKET, SECONDARY_ZYGOTE_SOCKET); public static final ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { return zygoteProcess.start(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, zygoteArgs); } frameworks/base/core/java/android/os/ZygoteProcess.java\nZygoteProcess.start /** * The name of the socket used to communicate with the primary zygote. */ private final LocalSocketAddress mSocket; /** * The name of the secondary (alternate ABI) zygote socket. */ private final LocalSocketAddress mSecondarySocket; public final Process.ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { return startViaZygote(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, false /* startChildZygote */, zygoteArgs); private Process.ProcessStartResult startViaZygote(final String processClass, final String niceName, final int uid, final int gid, final int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, boolean startChildZygote, String[] extraArgs) throws ZygoteStartFailedEx { synchronized(mLock) { return zygoteSendArgsAndGetResult(openZygoteSocketIfNeeded(abi), argsForZygote); } } openZygoteSocketIfNeeded /** * Tries to open socket to Zygote process if not already open. If * already open, does nothing. May block and retry. Requires that mLock be held. */ @GuardedBy(\u0026#34;mLock\u0026#34;) private ZygoteState openZygoteSocketIfNeeded(String abi) throws ZygoteStartFailedEx { if (primaryZygoteState == null || primaryZygoteState.isClosed()) { primaryZygoteState = ZygoteState.connect(mSocket); } if (primaryZygoteState.matches(abi)) { return primaryZygoteState; } // The primary zygote didn\u0026#39;t match. Try the secondary.  if (secondaryZygoteState == null || secondaryZygoteState.isClosed()) { secondaryZygoteState = ZygoteState.connect(mSecondarySocket); } if (secondaryZygoteState.matches(abi)) { return secondaryZygoteState; } public static ZygoteState connect(LocalSocketAddress address) throws IOException { DataInputStream zygoteInputStream = null; BufferedWriter zygoteWriter = null; final LocalSocket zygoteSocket = new LocalSocket(); zygoteSocket.connect(address); //inputStream，读取Zygote发来的数据  zygoteInputStream = new DataInputStream(zygoteSocket.getInputStream()); //outputStream,写入socket数据  zygoteWriter = new BufferedWriter(new OutputStreamWriter(zygoteSocket.getOutputStream()), 256); String abiListString = getAbiList(zygoteWriter, zygoteInputStream); return new ZygoteState(zygoteSocket, zygoteInputStream, zygoteWriter, Arrays.asList(abiListString.split(\u0026#34;,\u0026#34;))); } /** * Queries the zygote for the list of ABIS it supports. */ @GuardedBy(\u0026#34;mLock\u0026#34;) private static String getAbiList(BufferedWriter writer, DataInputStream inputStream) throws IOException { // Each query starts with the argument count (1 in this case)  writer.write(\u0026#34;1\u0026#34;); // ... followed by a new-line.  writer.newLine(); // ... followed by our only argument.  writer.write(\u0026#34;--query-abi-list\u0026#34;); writer.newLine(); writer.flush(); // The response is a length prefixed stream of ASCII bytes.  int numBytes = inputStream.readInt(); byte[] bytes = new byte[numBytes]; inputStream.readFully(bytes); return new String(bytes, StandardCharsets.US_ASCII); } zygoteSendArgsAndGetResult /** * Sends an argument list to the zygote process, which starts a new child * and returns the child\u0026#39;s pid. Please note: the present implementation * replaces newlines in the argument list with spaces. * * @throws ZygoteStartFailedEx if process start failed for any reason */ @GuardedBy(\u0026#34;mLock\u0026#34;) private static Process.ProcessStartResult zygoteSendArgsAndGetResult( ZygoteState zygoteState, ArrayList\u0026lt;String\u0026gt; args) throws ZygoteStartFailedEx { /** * See com.android.internal.os.SystemZygoteInit.readArgumentList() * Presently the wire format to the zygote process is: * a) a count of arguments (argc, in essence) * b) a number of newline-separated argument strings equal to count * * After the zygote process reads these it will write the pid of * the child or -1 on failure, followed by boolean to * indicate whether a wrapper process was used. */ final BufferedWriter writer = zygoteState.writer; final DataInputStream inputStream = zygoteState.inputStream; writer.write(Integer.toString(args.size())); writer.newLine(); for (int i = 0; i \u0026lt; sz; i++) { String arg = args.get(i); writer.write(arg); writer.newLine(); } writer.flush(); // Should there be a timeout on this?  Process.ProcessStartResult result = new Process.ProcessStartResult(); // Always read the entire result from the input stream to avoid leaving  // bytes in the stream for future process starts to accidentally stumble  // upon.  result.pid = inputStream.readInt(); result.usingWrapper = inputStream.readBoolean(); return result; Zygote启动AppProcess 参考\nActivityThread.main final ApplicationThread mAppThread = new ApplicationThread(); Looper.prepareMainLooper(); public static void main(String[] args) { Looper.prepareMainLooper(); } IActivityManager.attachApplication ActivityThread thread = new ActivityThread(); thread.attach(false, startSeq); private void attach(boolean system, long startSeq) { RuntimeInit.setApplicationObject(mAppThread.asBinder()); final IActivityManager mgr = ActivityManager.getService(); try { mgr.attachApplication(mAppThread, startSeq); } catch (RemoteException ex) { throw ex.rethrowFromSystemServer(); } } Looper.loop() Looper.loop(); ActivityManagerService.attachApplication @Override public final void attachApplication(IApplicationThread thread, long startSeq) { synchronized (this) { int callingPid = Binder.getCallingPid(); final int callingUid = Binder.getCallingUid(); final long origId = Binder.clearCallingIdentity(); attachApplicationLocked(thread, callingPid, callingUid, startSeq); Binder.restoreCallingIdentity(origId); } } @GuardedBy(\u0026#34;this\u0026#34;) private final boolean attachApplicationLocked(IApplicationThread thread, int pid, int callingUid, long startSeq) { AppDeathRecipient adr = new AppDeathRecipient(app, pid, thread); thread.asBinder().linkToDeath(adr, 0); app.deathRecipient = adr; thread.bindApplication(....) StackSupervisor.attachApplicationLocked(app)//realStartActivityLocked  } linkToDeath配置AppDeathRecipient监听appDeath private final class AppDeathRecipient implements IBinder.DeathRecipient { final ProcessRecord mApp; final int mPid; final IApplicationThread mAppThread; @Override public void binderDied() { synchronized(ActivityManagerService.this) { appDiedLocked(mApp, mPid, mAppThread, true); } } } thread.bindApplication class ApplicationThread { public final void bindApplication(String processName, ApplicationInfo appInfo, List\u0026lt;ProviderInfo\u0026gt; providers, ComponentName instrumentationName, ProfilerInfo profilerInfo, Bundle instrumentationArgs, IInstrumentationWatcher instrumentationWatcher, IUiAutomationConnection instrumentationUiConnection, int debugMode, boolean enableBinderTracking, boolean trackAllocation, boolean isRestrictedBackupMode, boolean persistent, Configuration config, CompatibilityInfo compatInfo, Map services, Bundle coreSettings, String buildSerial, boolean autofillCompatibilityEnabled) { sendMessage(H.BIND_APPLICATION, data); } public void handleMessage(Message msg) { switch (msg.what) { case BIND_APPLICATION: AppBindData data = (AppBindData)msg.obj; handleBindApplication(data); break; private void handleBindApplication(AppBindData data) { data.info = getPackageInfoNoCheck(data.appInfo, data.compatInfo); app = data.info.makeApplication(data.restrictedBackupMode, null); installContentProviders(app, data.providers); mInstrumentation.callApplicationOnCreate(app); } getPackageInfo初始化LoadedApk @Override public final LoadedApk getPackageInfoNoCheck(ApplicationInfo ai, CompatibilityInfo compatInfo) { return getPackageInfo(ai, compatInfo, null, false, true, false); } private LoadedApk getPackageInfo(ApplicationInfo aInfo, CompatibilityInfo compatInfo, ClassLoader baseLoader, boolean securityViolation, boolean includeCode, boolean registerPackage) { packageInfo = new LoadedApk(this, aInfo, compatInfo, baseLoader, securityViolation, includeCode \u0026amp;\u0026amp; (aInfo.flags\u0026amp;ApplicationInfo.FLAG_HAS_CODE) != 0, registerPackage); } LoadedApk.makeApplication public Application makeApplication(boolean forceDefaultAppClass, Instrumentation instrumentation) { if (mApplication != null) { return mApplication; } java.lang.ClassLoader cl = getClassLoader(); if (!mPackageName.equals(\u0026#34;android\u0026#34;)) { initializeJavaContextClassLoader(); } ContextImpl appContext = ContextImpl.createAppContext(mActivityThread, this); app = mActivityThread.mInstrumentation.newApplication(cl, appClass, appContext); appContext.setOuterContext(app); mActivityThread.mAllApplications.add(app); mApplication = app; } public ClassLoader getClassLoader() { synchronized (this) { if (mClassLoader == null) { createOrUpdateClassLoaderLocked(null /*addedPaths*/); } return mClassLoader; } } Instrumentation.newApplication public Application newApplication(ClassLoader cl, String className, Context context) throws InstantiationException, IllegalAccessException, ClassNotFoundException { Application app = getFactory(context.getPackageName()) .instantiateApplication(cl, className); app.attach(context); return app; } private AppComponentFactory getFactory(String pkg) { if (pkg == null) { Log.e(TAG, \u0026#34;No pkg specified, disabling AppComponentFactory\u0026#34;); return AppComponentFactory.DEFAULT; } if (mThread == null) { Log.e(TAG, \u0026#34;Uninitialized ActivityThread, likely app-created Instrumentation,\u0026#34; + \u0026#34; disabling AppComponentFactory\u0026#34;, new Throwable()); return AppComponentFactory.DEFAULT; } LoadedApk apk = mThread.peekPackageInfo(pkg, true); // This is in the case of starting up \u0026#34;android\u0026#34;.  if (apk == null) apk = mThread.getSystemContext().mPackageInfo; return apk.getAppFactory(); } AppComponentFactory.instantiateApplication public @NonNull Application instantiateApplication(@NonNull ClassLoader cl, @NonNull String className) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (Application) cl.loadClass(className).newInstance(); } Application.attach /* package */ final void attach(Context context) { attachBaseContext(context); mLoadedApk = ContextImpl.getImpl(context).mPackageInfo; } installContentProviders mInstrumentation.callApplicationOnCreate public void callApplicationOnCreate(Application app) { app.onCreate(); } realStartActivityLocked boolean attachApplicationLocked(ProcessRecord app) throws RemoteException { realStartActivityLocked(activity, app, top == activity /* andResume */, true /* checkConfig */)) } Create activity launch transaction final boolean realStartActivityLocked(ActivityRecord r, ProcessRecord app, boolean andResume, boolean checkConfig) throws RemoteException { // Create activity launch transaction.  final ClientTransaction clientTransaction = ClientTransaction.obtain(app.thread, r.appToken); clientTransaction.addCallback(LaunchActivityItem.obtain(new Intent(r.intent), System.identityHashCode(r), r.info, // TODO: Have this take the merged configuration instead of separate global  // and override configs.  mergedConfiguration.getGlobalConfiguration(), mergedConfiguration.getOverrideConfiguration(), r.compat, r.launchedFromPackage, task.voiceInteractor, app.repProcState, r.icicle, r.persistentState, results, newIntents, mService.isNextTransitionForward(), profilerInfo)); // Set desired final state.  final ActivityLifecycleItem lifecycleItem; if (andResume) { lifecycleItem = ResumeActivityItem.obtain(mService.isNextTransitionForward()); } else { lifecycleItem = PauseActivityItem.obtain(); } clientTransaction.setLifecycleStateRequest(lifecycleItem); // Schedule transaction.  mService.getLifecycleManager().scheduleTransaction(clientTransaction); } /** * Schedule a transaction, which may consist of multiple callbacks and a lifecycle request. * @param transaction A sequence of client transaction items. * @throws RemoteException * * @see ClientTransaction */ void scheduleTransaction(ClientTransaction transaction) throws RemoteException { final IApplicationThread client = transaction.getClient(); transaction.schedule(); if (!(client instanceof Binder)) { // If client is not an instance of Binder - it\u0026#39;s a remote call and at this point it is  // safe to recycle the object. All objects used for local calls will be recycled after  // the transaction is executed on client in ActivityThread.  transaction.recycle(); } } ClientTransaction.java\n/** Get the target client of the transaction. */ public IApplicationThread getClient() { return mClient; } /** * Schedule the transaction after it was initialized. It will be send to client and all its * individual parts will be applied in the following sequence: * 1. The client calls {@link #preExecute(ClientTransactionHandler)}, which triggers all work * that needs to be done before actually scheduling the transaction for callbacks and * lifecycle state request. * 2. The transaction message is scheduled. * 3. The client calls {@link TransactionExecutor#execute(ClientTransaction)}, which executes * all callbacks and necessary lifecycle transitions. */ public void schedule() throws RemoteException { mClient.scheduleTransaction(this); } @Override public void scheduleTransaction(ClientTransaction transaction) throws RemoteException { ActivityThread.this.scheduleTransaction(transaction); } public final class ActivityThread extends ClientTransactionHandler { } /** * Defines operations that a {@link android.app.servertransaction.ClientTransaction} or its items * can perform on client. * @hide */ public abstract class ClientTransactionHandler { // Schedule phase related logic and handlers.  /** Prepare and schedule transaction for execution. */ void scheduleTransaction(ClientTransaction transaction) { transaction.preExecute(this); sendMessage(ActivityThread.H.EXECUTE_TRANSACTION, transaction); } case EXECUTE_TRANSACTION: final ClientTransaction transaction = (ClientTransaction) msg.obj; mTransactionExecutor.execute(transaction); if (isSystem()) { // Client transactions inside system process are recycled on the client side  // instead of ClientLifecycleManager to avoid being cleared before this  // message is handled.  transaction.recycle(); } // TODO(lifecycler): Recycle locally scheduled transactions.  break; public void execute(ClientTransaction transaction) { final IBinder token = transaction.getActivityToken(); executeCallbacks(transaction); } /** Cycle through all states requested by callbacks and execute them at proper times. */ @VisibleForTesting public void executeCallbacks(ClientTransaction transaction) { final List\u0026lt;ClientTransactionItem\u0026gt; callbacks = transaction.getCallbacks(); final int size = callbacks.size(); for (int i = 0; i \u0026lt; size; ++i) { final ClientTransactionItem item = callbacks.get(i); item.execute(mTransactionHandler, token, mPendingActions); LaunchActivityItem.execute @Override public void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { Trace.traceBegin(TRACE_TAG_ACTIVITY_MANAGER, \u0026#34;activityStart\u0026#34;); ActivityClientRecord r = new ActivityClientRecord(token, mIntent, mIdent, mInfo, mOverrideConfig, mCompatInfo, mReferrer, mVoiceInteractor, mState, mPersistentState, mPendingResults, mPendingNewIntents, mIsForward, mProfilerInfo, client); //ActivityThread实例  client.handleLaunchActivity(r, pendingActions, null /* customIntent */); Trace.traceEnd(TRACE_TAG_ACTIVITY_MANAGER); } newActivity activity.attach mInstrumentation.callActivityOnCreate 记录ActivityClientRecord /** * Extended implementation of activity launch. Used when server requests a launch or relaunch. */ @Override public Activity handleLaunchActivity(ActivityClientRecord r, PendingTransactionActions pendingActions, Intent customIntent) { final Activity a = performLaunchActivity(r, customIntent); } /** Core implementation of activity launch. */ private Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) { ContextImpl appContext = createBaseContextForActivity(r); Activity activity = null; java.lang.ClassLoader cl = appContext.getClassLoader(); activity = mInstrumentation.newActivity(cl, component.getClassName(), r.intent); r.intent.setExtrasClassLoader(cl); r.intent.prepareToEnterProcess(); if (r.state != null) { r.state.setClassLoader(cl); } Application app = r.packageInfo.makeApplication(false, mInstrumentation); appContext.setOuterContext(activity); activity.attach(appContext, this, getInstrumentation(), r.token, r.ident, app, r.intent, r.activityInfo, title, r.parent, r.embeddedID, r.lastNonConfigurationInstances, config, r.referrer, r.voiceInteractor, window, r.configCallback); mInstrumentation.callActivityOnCreate(activity, r.state); r.activity = activity; r.setState(ON_CREATE); mActivities.put(r.token, r); } public Activity newActivity(ClassLoader cl, String className, Intent intent) throws InstantiationException, IllegalAccessException, ClassNotFoundException { String pkg = intent != null \u0026amp;\u0026amp; intent.getComponent() != null ? intent.getComponent().getPackageName() : null; return getFactory(pkg).instantiateActivity(cl, className, intent); } 其他 ContextImpl.createAppContext static ContextImpl createAppContext(ActivityThread mainThread, LoadedApk packageInfo) { if (packageInfo == null) throw new IllegalArgumentException(\u0026#34;packageInfo\u0026#34;); ContextImpl context = new ContextImpl(null, mainThread, packageInfo, null, null, null, 0, null); context.setResources(packageInfo.getResources()); return context; } getResources public Resources getResources() { if (mResources == null) { final String[] splitPaths; try { splitPaths = getSplitPaths(null); } catch (NameNotFoundException e) { // This should never fail.  throw new AssertionError(\u0026#34;null split not found\u0026#34;); } mResources = ResourcesManager.getInstance().getResources(null, mResDir,//main  splitPaths, mOverlayDirs, mApplicationInfo.sharedLibraryFiles, Display.DEFAULT_DISPLAY, null, getCompatibilityInfo(), getClassLoader());//main  } return mResources; } getClassLoader public ClassLoader getClassLoader() { synchronized (this) { if (mClassLoader == null) { createOrUpdateClassLoaderLocked(null /*addedPaths*/); } return mClassLoader; } } createOrUpdateClassLoaderLocked private void createOrUpdateClassLoaderLocked(List\u0026lt;String\u0026gt; addedPaths) { if (mClassLoader == null) { mClassLoader = ApplicationLoaders.getDefault().getClassLoader( \u0026#34;\u0026#34; /* codePath */, mApplicationInfo.targetSdkVersion, isBundledApp, librarySearchPath, libraryPermittedPath, mBaseClassLoader, null /* classLoaderName */); mAppComponentFactory = createAppFactory(mApplicationInfo, mClassLoader); } if (addedPaths != null \u0026amp;\u0026amp; addedPaths.size() \u0026gt; 0) { //更新PathClassLoader实例  final String add = TextUtils.join(File.pathSeparator, addedPaths); ApplicationLoaders.getDefault().addPath(mClassLoader, add); // Setup the new code paths for profiling.  needToSetupJitProfiles = true; } ApplicationLoaders.getClassLoader private ClassLoader getClassLoader(String zip, int targetSdkVersion, boolean isBundled, String librarySearchPath, String libraryPermittedPath, ClassLoader parent, String cacheKey, String classLoaderName) { /* \\* This is the parent we use if they pass \u0026#34;null\u0026#34; in. In theory \\* this should be the \u0026#34;system\u0026#34; class loader; in practice we \\* don\u0026#39;t use that and can happily (and more efficiently) use the \\* bootstrap class loader. */ //ClassLoader.getSystemClassLoader()是PathClassLoader,再getParent为BootClassLoader  ClassLoader baseParent = ClassLoader.getSystemClassLoader().getParent(); /* \\* If we\u0026#39;re one step up from the base class loader, find \\* something in our cache. Otherwise, we create a whole \\* new ClassLoader for the zip archive. */ if (parent == baseParent) { ClassLoader loader = mLoaders.get(cacheKey); if (loader != null) { return loader; } ClassLoader classloader = ClassLoaderFactory.createClassLoader( zip, librarySearchPath, libraryPermittedPath, parent, targetSdkVersion, isBundled, classLoaderName); mLoaders.put(cacheKey, classloader); return classloader; } ClassLoader loader = ClassLoaderFactory.createClassLoader(zip, null, parent, classLoaderName); ClassLoaderFactory.createClassLoader /** \\* Create a ClassLoader and initialize a linker-namespace for it. */ public static ClassLoader createClassLoader(String dexPath, String librarySearchPath, String libraryPermittedPath, ClassLoader parent, int targetSdkVersion, boolean isNamespaceShared, String classloaderName) { final ClassLoader classLoader = createClassLoader(dexPath, librarySearchPath, parent, classloaderName); String errorMessage = createClassloaderNamespace(classLoader, targetSdkVersion, librarySearchPath, libraryPermittedPath, isNamespaceShared, isForVendor); return classLoader; } /** \\* Same as {@code createClassLoader} below, except that no associated namespace \\* is created. */ public static ClassLoader createClassLoader(String dexPath, String librarySearchPath, ClassLoader parent, String classloaderName) { if (isPathClassLoaderName(classloaderName)) { return new PathClassLoader(dexPath, librarySearchPath, parent); } else if (isDelegateLastClassLoaderName(classloaderName)) { return new DelegateLastClassLoader(dexPath, librarySearchPath, parent); } throw new AssertionError(\u0026#34;Invalid classLoaderName: \u0026#34; + classloaderName); } /** \\* Returns true if {@code name} is the encoding for either PathClassLoader or DexClassLoader. \\* The two class loaders are grouped together because they have the same behaviour. */ public static boolean isPathClassLoaderName(String name) { // For null values we default to PathClassLoader. This cover the case when packages  // don\u0026#39;t specify any value for their class loaders.  return name == null || PATH_CLASS_LOADER_NAME.equals(name) || DEX_CLASS_LOADER_NAME.equals(name); } private static native String createClassloaderNamespace(ClassLoader classLoader,...) createAppComponentFactory private AppComponentFactory createAppFactory(ApplicationInfo appInfo, ClassLoader cl) { if (appInfo.appComponentFactory != null \u0026amp;\u0026amp; cl != null) { try { return (AppComponentFactory) cl.loadClass(appInfo.appComponentFactory) .newInstance(); } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) { Slog.e(TAG, \u0026#34;Unable to instantiate appComponentFactory\u0026#34;, e); } } return AppComponentFactory.DEFAULT; } AppComponentFactory public static final AppComponentFactory DEFAULT = new AppComponentFactory(); public @NonNull Application instantiateApplication(@NonNull ClassLoader cl, @NonNull String className) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (Application) cl.loadClass(className).newInstance(); } public @NonNull Activity instantiateActivity(@NonNull ClassLoader cl, @NonNull String className, @Nullable Intent intent) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (Activity) cl.loadClass(className).newInstance(); } public @NonNull Service instantiateService(@NonNull ClassLoader cl, @NonNull String className, @Nullable Intent intent) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (Service) cl.loadClass(className).newInstance(); } public @NonNull BroadcastReceiver instantiateReceiver(@NonNull ClassLoader cl, @NonNull String className, @Nullable Intent intent) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (BroadcastReceiver) cl.loadClass(className).newInstance(); } public @NonNull ContentProvider instantiateProvider(@NonNull ClassLoader cl, @NonNull String className) throws InstantiationException, IllegalAccessException, ClassNotFoundException { return (ContentProvider) cl.loadClass(className).newInstance(); } ContextImpl.createActivityContext //ActivityThread private ContextImpl createBaseContextForActivity(ActivityClientRecord r) { ContextImpl appContext = ContextImpl.createActivityContext( this, r.packageInfo, r.activityInfo, r.token, displayId, r.overrideConfig); return appContext; static ContextImpl createActivityContext(ActivityThread mainThread, LoadedApk packageInfo, ActivityInfo activityInfo, IBinder activityToken, int displayId, Configuration overrideConfiguration) { ClassLoader classLoader = packageInfo.getClassLoader();//main  if (packageInfo.getApplicationInfo().requestsIsolatedSplitLoading()) { Trace.traceBegin(Trace.TRACE_TAG_RESOURCES, \u0026#34;SplitDependencies\u0026#34;); try { classLoader = packageInfo.getSplitClassLoader(activityInfo.splitName); splitDirs = packageInfo.getSplitPaths(activityInfo.splitName); ContextImpl context = new ContextImpl(null, mainThread, packageInfo, activityInfo.splitName, activityToken, null, 0, classLoader); final ResourcesManager resourcesManager = ResourcesManager.getInstance(); // Create the base resources for which all configuration contexts for this Activity  // will be rebased upon.  context.setResources(resourcesManager.createBaseActivityResources(activityToken, packageInfo.getResDir(), splitDirs, packageInfo.getOverlayDirs(), packageInfo.getApplicationInfo().sharedLibraryFiles, displayId, overrideConfiguration, compatInfo, classLoader)); context.mDisplay = resourcesManager.getAdjustedDisplay(displayId, context.getResources()); return context; LoadedApk initializeJavaContextClassLoader private void initializeJavaContextClassLoader() { ClassLoader contextClassLoader = (sharable) ? new WarningContextClassLoader() : mClassLoader; Thread.currentThread().setContextClassLoader(contextClassLoader); ContextImpl final @NonNull ActivityThread mMainThread; final @NonNull LoadedApk mPackageInfo; private @Nullable ClassLoader mClassLoader; @Override public ClassLoader getClassLoader() { return mClassLoader != null ? mClassLoader : (mPackageInfo != null ? mPackageInfo.getClassLoader() : ClassLoader.getSystemClassLoader()); } static ContextImpl getImpl(Context context) { Context nextContext; while ((context instanceof ContextWrapper) \u0026amp;\u0026amp; (nextContext=((ContextWrapper)context).getBaseContext()) != null) { context = nextContext; } return (ContextImpl)context; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E9%80%80%E5%87%BA/",
	"title": "应用启动退出",
	"tags": [],
	"description": "",
	"content": "应用启动退出 探索总结应用启动退出知识\n 应用启动     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%AE%89%E5%85%A8/%E5%BA%94%E7%94%A8%E5%AE%89%E5%85%A8/",
	"title": "应用安全",
	"tags": [],
	"description": "",
	"content": "防Hook 第一、Xposed框架将Hook信息存储在字段fieldCache，methodCache，constructorCache 中， 利用java 反射机制获取这些信息，检测Hook信息中是否含有App中敏感的方法，字段，构造方法\n第二、检测进程中使用so名中包含关键”hack|inject|hook|call” 的信息，这个主要是防止有的人不用这个Xposed框架，而是直接自己写一个注入功能\n第三、root检测原理是：是否含有su程序和ro.secure是否为1\n第四、防止被Hook的方式就是可以查看XposedBridge这个类，有一个全局的hook开关，所有有的应用在启动的时候就用反射把这个值设置成true，这样Xposed的hook功能就是失效了\n第五、如果应用被Xposed进行hook操作之后，抛出的异常堆栈信息中就会包含Xposed字样，所以可以通过应用自身内部抛出异常来检测是否包含Xposed字段来进行防护\nLog 泄露app中的信息\n线上仅仅写入文件，不打印log\n完整性校验(防篡改)，签名 \u0026lt;应用安全防护和逆向分析\u0026gt;\u0026ndash;第12章\n MANIFEST.MF文件  包含了apk文件中所有文件的数据摘要内容SHA1+Base64,属性名为\u0026quot;SHA1-Digest\u0026quot;(安全散列算法) 另外还有一个\u0026quot;Name\u0026quot;属性，值为该文件在apk包中的路径, 例子:\nManifest-Version: 1.0 Name: AUTHORS SHA1-Digest: tNG7y16mMckMxD5PMWbMbm15YuM= Name: AndroidManifest.xml SHA1-Digest: DpoXWRs62IFQkzew0PZZ1IhBr4E= Name: META-INF/android.arch.lifecycle_livedata.version SHA1-Digest: OxxKFJcpzAROGjnfMbNijNv1+JU=  CERT.SF文件 计算MANIFEST.MF文件整体的SHA1值，再经过BASE64编码后记录在主属性(文件头)上的\u0026quot;SHA1-Digest-Mainifest\u0026quot;属性下 MANIFEST.MF文件的每个条目做一个SHA1+Base64之后记录在同名块中，属性名为\u0026quot;SHA1-Digest\u0026quot;, 例子:  Signature-Version: 1.0 Created-By: 1.0 (Android) SHA1-Digest-Manifest: lCe0n/umuXx2pJRbNdAPxSJQGyU= X-Android-APK-Signed: 2 Name: AUTHORS SHA1-Digest: NJvhMmfYrxh85l+E46t/lOXoRmk= Name: AndroidManifest.xml SHA1-Digest: N/26hYDkRfJLe6NEN7232YcVe1M= Name: META-INF/android.arch.lifecycle_livedata.version SHA1-Digest: MlMwWIwNpuS2rz/AzXm5Hqaliu4=  CERT.RSA文件 对CERT.SF文件用私钥加密出签名，再将签名以及包含公钥信息的数字证书一同写入CERT.RSA  二进制文件，因为RSA文件加密了，所以需要用openssl命令查看内容\nopenssl pkcs7 -inform DER -in CERT.RSA -noout -print_certs -text 证书信息和X.509证书格式对应\n一个完整的签名过程如下所示：\nDex 完整性校验 crc或者hash\n可以将 CRC 值存储在 string 资源文件中，当然也可以放在自己的服务器上， 通过运行时从服务器获取校验值。基本步骤如下：\n[*]首先在代码中完成校验值比对的逻辑，此部分代码后续不能再改变，否则 CRC 值会发生变化； [*]从生成的 APK 文件中提取出 classes.dex 文件，计算其 CRC 值，其他 hash 值类似； [*]将计算出的值放入 strings.xml 文件中。 APK 完整性校验 由于在开发 Android 应用程序时，无法知道完整 APK 文 件的 Hash 值，所以这个 Hash 值的存储无法像 Dex 完整性校验那样放在 strings.xml 文件中， 所以可以考虑将值放在服务器端，因为对 APK 的任何改动都会影响到最后的 Hash 值。\n签名安全(防止二次打包) 本地验证 在应用入口处添加签名(或签名的md5)验证，如果发现签名不正确就立刻退出程序 可以考虑在native进行签名验证\n服务端验证 将签名信息携带请求参数中参与加密，服务端进行签名校验，失败就返回错误数据即可\n二次打包者很难伪造我们的签名，所以我们可以在程序中插入签名检查的代码，提高攻击门槛。我们可以在so中判断当前应用的签名，前面分析过，只要别人拿不到你的keystore就没办法伪造你的签名\ncontext--pacakgeManager--packageInfo--signatures获取当前应用签名和正确的比对 防止二次打包，判断签名是否一致。 获取apk的签名hash值与apk的签名文件的hash值进行判断，不一致说明apk被二次打包。 获取签名hash值的代码如下：\npublic int getSignature(String packageName) { PackageManager pm = this.getPackageManager(); PackageInfo pi = null; int sig = 0; try { pi = pm.getPackageInfo(packageName, PackageManager.GET_SIGNATURES); Signature[] s = pi.signatures; sig = s[0].hashCode(); } catch (Exception e1) { sig = 0; e1.printStackTrace(); } return sig; } Manifest Cheating\n利用后缀为png的非png文件\nAPK 伪加密 APK 实际上是 Zip 压缩文件，但是 Android 系统在解析 APK 文件时，和传统的解压缩软 件在解析 Zip 文件时还是有所差异的，利用这种差异可以实现给 APK 文件加密的功能。Zip 文件格式可以参考 MasterKey 漏洞分析的一篇文章。在 Central Directory 部分的 File Header 头 文件中，有一个 2 字节长的名为 General purpose bit flags 的字段，这个字段中每一位的作用 可以参考 Zip 文件格式规范的 4.4.4 部分，其中如果第 0 位置 1，则表示 Zip 文件的该 Central Directory 是加密的，如果使用传统的解压缩软件打开这个 Zip 文件，在解压该部分 Central Directory 文件时，是需要输入密码的，如图 14 所示。但是 Android 系统在解析 Zip 文件时并 没有使用这一位，也就是说这一位是否置位对 APK 文件在 Android 系统的运行没有任何影响。 一般在逆向 APK 文件时，会首先使用 apktool 来完成资源文件的解析，dex 文件的反汇编工 作，但如果将 Zip 文件中 Central Directory 的 General purpose bit flags 第 0 位置 1 的话， apktool(version:1.5.2)将无法完成正常的解析工作，如图 15 所示，但是又不会影响到 APK 在 Android 系统上的正常运行\n图 14 传统解压缩软件需要输入密码进行解压缩\n图 15 apktool 解析伪加密的 APK 文件失败\n模拟器检测 在分析 APK 的过程中会借助于 Android 模拟器，比如分析网络行为，动态调试等。 因此从 APK 自我保护的角度出发，可以增加对 APK 当前运行环境的检测，判断是否运行在 模拟器中，如果运行在模拟器中可以选择退出整个应用程序的执行或者跳到其他分支。\n1.属性检测 例如Build.BRAND 和 Build.DEVICE。 另外还可以通过检测 IMEI，IMSI 等值来判断是否是模拟器，在模拟器中，这两个值默认 分别是 000000000000000 和 310260000000000，通过以下代码可以获取 IMSI 值：\n1. TelephonyManager manager = (TelephonyManager)getSystemService(TELEPHONY_SERVICE); 2. String imsi = manager.getSubscriberId(); 2.虚拟机文件检测 相 对 于 真 实 设 备 ， Android 模 拟 器 中 存 在 一 些 特 殊 的 文 件 或 者 目 录 ， 如 /system/bin/qemu-props，该可执行文件可以用来在模拟器中设置系统属性。另外还有 /system/lib/libc_malloc_debug_qemu.so 文件以及/sys/qemu_trace 目录。我们可以通过检测这些 特殊文件或者目录是否存在来判断 Android 应用程序是否运行在模拟器中\n3.基于 Cache 行为的模拟器检测方法 BlueBox 关于 Android 模拟器检测的方法 http://bluebox.com/corporate-blog/android-emulator-detection/\n4.基于代码指令执行的模拟器检测方法 DexLabs 关于 Android 模拟器检测的方法 http://dexlabs.org/blog/btdetect\n5.其他方法 其他一些检测方法，可以参考如下文献：\n[*]DISSECTING THE ANDROID BOUNCER [*]逃离安卓动态检测 [*]Guns and Smoke to Defeat Mobile Malware [*]DEX EDUCATION 201 ANTI-EMULATION [*]INSECURE MAGZINE 34 – Introduction to Android malware analysis 反调试检测 在对 APK 逆向分析时，往往会采取动态调试技术，可以使用 netbeans+apktool 对反汇编 生成的 smali 代码进行动态调试。为了防止 APK 被动态调试，可以检测是否有调试器连接。\nisDebuggerConnected或debuggable Android 系统在 android.os.Debug 类中提供了 isDebuggerConnected()方法，用于检测是否有调 试器连接。可以在 Application 类中调用 isDebuggerConnected()方法，判断是否有调试器连接， 如果有，直接退出程序。\n除了 isDebuggerConnected 方法，还可以通过在 AndroidManifest 文件的 application 节点中 加入 android:debuggable=”false”使得程序不可被调试，这样如果希望调试代码，则需要修改 该值为 true，因此可以在代码中检查这个属性的值，判断程序是否被修改过，代码如下：\n1. if(getApplicationInfo().flags \u0026amp;= ApplicationInfo.FLAG_DEBUGGABLE != 0){ 2. System.out.println(\u0026#34;Debug\u0026#34;); 3. android.os.Process.killProcess(android.os.Process.myPid()); 4. } linux ptrace机制 破解者使用IDA进行动态方式调试so文件，从而获得重要信息，利用IDA进行so动态调试是基于进行的注入技术，然后使用linux中的ptrace机制，进行调试目标进程的附加操作。ptrace机制有一个特点，如果一个进程被调试了，在他进程的status文件中有一个字段TracerPid会记录调试者的进程id\n//查找进程号 ps |grep com.example.xxx //打开该进程的status文件 cat /proc/${pid}/status 反调试：轮询遍历自己进程的status文件，读取TracerPid字段，如果大于0，代表自己的应用在被人调试，所以立马退出程序\n破解者仍然可以通过IDA给JNI_OnLoad方法下断点，然后调试，找到检测轮询代码，使用nop指令替换检测指令，就相当于把检测代码给注释了。\nIDA调试，循环检查端口 我们在之前破解逆向的时候，需要借助一个强大利器，那就是IDA，在使用IDA的时候，我们知道需要在设备中启动android_server作为通信，那么这个启动就会默认占用端口23946\n我们可以查看设备的tcp端口使用情况 cat /proc/net/tcp\n其中5D8A转化成十进制就是23946，而看到uid是0，因为我们运行android_server是root身份的，uid肯定是0了。所以我们可以利用端口检查方式来进行反调试策略，当然这种方式不是万能的，后面会详细介绍如何解决这样的反调试方法。同时还要检查有没有android_server这个进程，有的话也是表示有可能被调试了。\n当然还有最近很常用的Frida框架，他的端口号是27042和27043，以及进程名是frida-server。另可错杀一千不能放过一个。\n混淆 可以增加破解难度并减少apk包大小\n代码混淆 现在破解查看java层代码有以下两种方式：\n 直接解压classes.dex文件，使用dex2jar工具转换为jar文件之后再用jd-gui工具查看类结构 使用apktool工具直接反编译apk，得到并阅读smali源码  ProGuard ProGuard 是一款免费的 Java 代码混淆工具，提供了文件压缩、优化、混淆和 审核功能\n由于在某些情况下，ProGuard 会错误地认为某些代码没有被使用，如在 只在 AndroidManifest 文件中引用的类，从 JNI 中调用的方法等。对于这些情况，需要在 proguard-project.txt 文件中添加-keep 命令，用来保留类或方法。关于 ProGuard 更加详细的配 置项可以参考 ProGuard Manual。\nDexGuard DexGuard 是特别 针对 Android 的一款代码优化混淆的收费软件，提供代码优化混淆、字符串加密、类加密、 Assets 资源加密、隐藏对敏感 API 的调用、篡改检测以及移除 Log 代码。DexGuard 的进一步 分析可以参考 JEB 上的相关 blog，可以在这里总结一下：\n1．字符串加密 2．assets 加密\n资源混淆 微信已经开源：https://github.com/shwenzhang/AndResGuard\n微信资源混淆AndResGuard原理\n资源混淆核心处理过程如下： 1、生成新的资源文件目录，里面对资源文件路径进行混淆(其中涉及如何复用旧的mapping文件)，例如将res/drawable/hello.png混淆为r/s/a.png，并将映射关系输出到mapping文件中。\n2、对资源id进行混淆(其中涉及如何复用旧的mapping文件)，并将映射关系输出到mapping文件中。\n3、生成新的resources.arsc文件，里面对资源项值字符串池、资源项key字符串池、进行混淆替换，对资源项entry中引用的资源项字符串池位置进行修正、并更改相应大小，并打包生成新的apk。\n不能被混淆的代码 枚举 枚举类内部存在 values 方法，混淆后该方法会被重新命名，并抛出 NoSuchMethodException。Android 系统默认的混淆规则中已经添加了对于枚举类的处理，我们无需再去做额外工作。\n被反射的元素 原因在于：代码混淆过程中，被反射使用的元素会被重命名，然而反射依旧是按照先前的名称去寻找元素，所以会经常发生 NoSuchMethodException 和 NoSuchFiledException 问题。\n实体类 实体类即我们常说的\u0026quot;数据类\u0026quot;，当然经常伴随着序列化与反序列化操作。很多人也应该都想到了，混淆是将原本有特定含义的\u0026quot;元素\u0026quot;转变为无意义的名称，所以，经过混淆的\u0026quot;洗礼\u0026quot;之后，序列化之后的 value 对应的 key 已然变为没有意义的字段，这肯定是我们不希望的。 反序列化的过程创建对象从根本上来说还是借助于反射，混淆之后 key 会被改变，所以也会违背我们预期的效果。\n四大组件 Android 中的四大组件同样不应该被混淆。原因在于：\n 四大组件使用前都需要在 AndroidManifest.xml文件中进行注册声明，然而混淆处理之后，四大组件的类名就会被篡改，实际使用的类与 manifest 中注册的类并不匹配，故而出错。 其他应用程序访问组件时可能会用到类的包名加类名，如果经过混淆，可能会无法找到对应组件或者产生异常。  JNI 调用的Java 方法 当 JNI 调用的 Java 方法被混淆后，方法名会变成无意义的名称，这就与 C++ 中原本的 Java 方法名不匹配，因而会无法找到所调用的方法。\n其他不应该被混淆的  自定义控件不需要被混淆 JavaScript 调用 Java 的方法不应混淆 Java 的 native 方法不应该被混淆 项目中引用的第三方库也不建议混淆  WebView WebView明文存储密码带来的安全漏洞 WebView组件默认开启了密码保存功能，会提示用户是否保存密码，当用户选择保存在WebView中输入的用户名和密码，则会被明文保存到应用数据目录的databases/webview.db中。攻击者可能通过root的方式访问该应用的WebView数据库，从而窃取本地明文存储的用户名和密码。\n解决方案：\n开发者调用 WebView.getSettings().setSavePassword(false)，显示调用API设置为false，让WebView不存储密码\n动态注册Receiver风险 使用BroadcastReceiver组件需要动态注册或者静态注册，如果动态注册广播，即在代码中使用registerReceiver()方法注册BroadcastReceiver，只有当registerReceiver()的代码执行到了才进行注册，取消时则调用unregisterReceiver()方法。但registerReceiver()方法注册的BroadcastReceiver是全局的并且默认可导出的，如果没有限制访问权限，可以被任意外部APP访问，向其传递Intent来执行特定的功能。因此，动态注册的BroadcastReceive可能会导致拒绝服务攻击、APP数据泄漏或是越权调用等安全风险\n解决方案：\n 在 AndroidManifest.xml 文件中使用静态注册 BroadcastReceiver，同时设置 exported=\u0026ldquo;false\u0026rdquo;，不被外部应用调用。 必须动态注册 BroadcastReceiver时，使用registerReceiver(BroadcastReceiver,IntentFilter,broadcastPermission,android.os.Handle)函数注册。 Android8.0新特性想要支持静态广播、需要添加intent.setComponent(new ComponentName（）），详情可以自行查阅  exported配置为true风险 Activity、Service、Provider、Receiver四大组件若配置为android:exported =”true”，将可以被外部应用调用，这样存在安全隐患的风险。\n解决方案：\n在应用的AndroidManifest.xml文件中，设置组件的android:exported属性为false或者通过设置自定义权限来限制对这些组件的访问。\nNDK 一般来说，如果代码中对处理速度有较高要求或者为了更好地控制硬件，抑或者为了 复用既有的 C/C++代码，都可以考虑通过 JNI 来实现对 Native 代码的调用。 由于逆向 Native 程序的汇编代码要比逆向 Java 汇编代码困难，因此可以考虑在关键代 码部位使用 Native 代码，如注册验证，加解密操作等。\n万一别人将你的so库直接copy出来拿去用了呢？因此，我们还需要在native层对应用的包名、签名进行鉴权校验，如果不是自己的应用，不返回相关信息，或者直接退出应用！\nhttps://www.jianshu.com/p/fe0206f8be5b\n安全数据自动加密到so A simple way to encrypt your secure data like passwords into a native .so library.\nhttps://github.com/MEiDIK/Cipher.so\n优化方案(支持library module):\nlibrary module: 在plugin中代码写死所有library的安全数据，之后copy cpp并修改之后生成so，以get(\u0026quot;${key1}\u0026quot;)方式暴露方法给调用者提供key1获取安全数据\napplication module: 根据plugin中的library安全数据，配合app中配置的安全数据，copy cpp并修改之后生成so(同名so)，删除所有library module下的so\nELF和反汇编 我们发现了之前辛苦藏到so中的字符串\u0026quot;Hello from C++\u0026quot;。如果想看代码实现，可以使用objdump命令，能看到反汇编后的代码。 现在我们可以理解ELF文件已经是机器指令了，我们如果想看一些代码逻辑，要么像机器一样读机器指令，要么把这些机器指令反编译成人类方便阅读的汇编代码(汇编语言人类也很难读的好吧)，这个过程我们就是反汇编。 当然真正去破解一些so文件时，使用上面的办法效率太低，这是可以去使用一些专业的破解工具，里面集成了很多很强大的功能，可以大大提高工作效率，例如使用IDA直接把so打开，我们可以很方便的定位到jni函数：\n从这个例子的分析，我们为了增加破解难度，可以动态注册jni函数并且自定义函数名，避免破解者一眼就找到Java_com_xxx这样的native函数。另外一点就是要隐藏在字符串，不可以直接明文写在代码中，至少做个拼接吧，或者添加一定的逻辑动态生成。大家可以想一下，还有没有其他的办法增加破解难度？\n应用加固 DEX加固  源项目(需要加固加密的apk) 加壳项目(使用加壳项目对源apk进行加密，并将加密后的源apk和脱壳apk进行合并得到新的apk) 脱壳项目-android项目(此时得到的已经不是一个完整意义上的apk程序了，它的主要工作是解密源apk，然后加载源apk，让其可以正常运行起来)  具体是修改dex head中的checksum,signature和file_size并将加密后的源apk和其大小追加到dex文件末尾就行\nhttps://www.jianshu.com/p/4ff48b761ff6 运行脱壳程序加载原dex文件\nDalvik虚拟机会加载我们经过修改的新的classes.dex文件，并最先运行ProxyApplication类\n在attachBaseContext方法里，主要做两个工作：\n读取classes.dex文件末尾记录加密dex文件大小的数值，则加密dex文件在新classes.dex文件中的位置为：len(新classes.dex文件) – len(加密dex文件大小)。然后将加密的dex文件读取出来，加密并保存到资源目录下\n然后使用自定义的DexClassLoader加载解密后的原dex文件\n在onCreate方法中，主要做两个工作：\n通过反射修改ActivityThread类，并将Application指向原dex文件中的Application\n创建原Application对象，并调用原Application的onCreate方法启动原程序\n使用像xposed框架这样的hook技术，类似于降维打击，可以绕过加固技术轻松获取到dex文件。目前的乐固、360等大厂加固都可以绕过，从原理上看，加固技术对于这种hook技术获取dex也没有什么好办法，作为APP的作者，需要加强hook方面的防御来提高加固技术的安全性\nso加固 \u0026lt;应用安全防护和逆向分析\u0026gt;\u0026ndash;第十四章\n数据安全 加密和JNI写入Native层 秘钥及敏感信息不要在类中硬编码敏感信息，可以使用JNI将敏感信息写到Native层。\nSharePreferences 首先不应当使用SharePreferences来存放敏感信息，sharedpreferces存储的xml文件数据可能被反编译拿到。存储一些配置信息时也要配置好访问权限，如私有的访问权限 MODE_PRIVATE（Activity.MODE_PRIVATE,//默认操作模式，代表该文件是私有数据，只能被应用本身访问，在该模式下，写入的内容会覆盖原文件的内容），避免配置信息被篡改。\nSQLite数据库文件的安全性  描述：敏感信息是否明文存储 检测：检测数据库里面的重要信息，比如账号密码之类的是否明文存储 建议：重要信息进行加密存储  allowBackUp属性 \u0026lt;应用安全防护和逆向分析\u0026gt;\u0026ndash;第十一章\n逆向工具对抗 在逆向分析 Android 应用程序时，一般会使用 apktool，baksmali/smali，dex2jar，androguard， jdGUI 以及 IDA Pro 等。因此可以考虑使得这些工具在反编译 APK 时出错来保护 APK，这些工 具大部分都是开源的，可以通过阅读其源代码，分析其在解析 APK、dex 等文件存在的缺陷， 在开发 Android 应用程序时加以利用。\n总结 APK 自我保护的技术并不能做到完全的保护作用，只是提高了逆向分析的难度， 在实际运用中应该根据情况多种技术结合使用。这些技术其实很多来源于 Android 恶意代码， 所以可以关注 Android 恶意代码中使用的一些技术来应用到自己开发的 Android 应用程序中。\n参考 APK 的自我保护\nhttp://www.droidsec.cn/\nhttps://developer.android.com/topic/security/data\nAndroid安全防护\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/apk%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD/%E5%BA%94%E7%94%A8%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD%E8%BF%87%E7%A8%8B/",
	"title": "应用安装和卸载过程",
	"tags": [],
	"description": "",
	"content": "安装过程： 1.程序安装的4大步骤\n（1） 拷贝apk文件到指定目录 在Android系统中，apk安装文件是会被保存起来的，默认情况下，用户安装的apk首先会被拷贝到 /data/app 目录下。\n/data/app目录是用户有权限访问的目录，在安装apk的时候会自动选择该目录存放用户安装的文件，而系统出厂的apk文件则被放到了 /system 分区下,包括 /system/app，/system/vendor/app，以及 /system/priv-app 等等，该分区只有Root权限的用户才能访问，这也就是为什么在没有Root手机之前，我们无法删除系统出厂的app的原因了。\nPackageInstaller所在的app进程先将其apk copy到data/user_de/0/com.android.packageinstaller/no_backup/package859349096673958696.apk中\n复制APK安装包到data/app目录下，首先copy到data/app/vmdl609226785.tmp/base.apk\n（2） 解压apk，拷贝文件，创建应用的数据目录 为了加快app的启动速度，apk在安装的时候，会首先将app的可执行文件（dex）拷贝到 /data/dalvik-cache 目录，缓存起来。\n然后，在/data/data/目录下创建应用程序的数据目录（以应用的包名命名），存放应用的相关数据，如数据库、xml文件、cache、二进制的so动态库等等，\n（3） 解析apk的AndroidManifinest.xml文件 Android系统中，也有一个类似注册表的东西，用来记录当前所有安装的应用的基本信息，每次系统安装或者卸载了任何apk文件，都会更新这个文件。这个文件位于如下目录：\n/data/system/packages.xml\n系统在安装apk的过程中，会解析apk的AndroidManifinest.xml文件，提取出这个apk的重要信息写入到packages.xml文件中，这些信息包括：权限、应用包名、APK的安装位置、版本、userID等等。\n由此，我们就知道了为啥一些应用市场和软件管理类的app能够很清楚地知道当前手机所安装的所有的app，以及这些app的详细信息了。\n另外一件事就是Linux的用户Id和用户组Id，以便他可以获得合适的运行权限。\n以上这些都是由PackageManagerService完成的。\n（4） 显示快捷方式 这些应用程序只是相当于在PackageManagerService服务注册好了，如果我们想要在Android桌面上看到这些应用程序，还需要有一个Home应用程序，负责从PackageManagerService服务中把这些安装好的应用程序取出来，并以友好的方式在桌面上展现出来，例如以快捷图标的形式。在Android系统中，负责把系统中已经安装的应用程序在桌面中展现出来的Home应用程序就是Launcher了\nPackageManagerService的启动过程 Android系统在启动的过程中，会启动一个应用程序管理服务PackageManagerService，这个服务负责扫描系统中特定的目录，找到里面的应用程序文件，即以Apk为后缀的文件，然后对这些文件进解析，得到应用程序的相关信息。应用程序管理服务PackageManagerService安装应用程序的过程，其实就是解析析应用程序配置文件AndroidManifest.xml的过程，并从里面得到得到应用程序的相关信息，例如得到应用程序的组件Activity、Service、Broadcast Receiver和Content Provider等信息，有了这些信息后，通过ActivityManagerService这个服务，我们就可以在系统中正常地使用这些应用程序了。应用程序管理服务PackageManagerService是系统启动的时候由SystemServer组件启动的，启后它就会执行应用程序安装的过程，因此，本文将从SystemServer启动PackageManagerService服务的过程开始分析系统中的应用程序安装的过程。\n卸载过程 删除安装过程中在上述三个目录下创建的文件及目录。\n参考 Android应用安装过程及原理\nAndroid应用安装流程(基于Android9.0)\nAndroid应用程序安装过程解析(源码角度)\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/jni/%E5%BC%82%E5%B8%B8/",
	"title": "异常",
	"tags": [],
	"description": "",
	"content": "原理图 graph LR 解释执行--\u0026gt;异常投递--\u0026gt;|case Instruction::THROW|setException(\u0026quot;异常对象赋值给Thread的tlsPtr_exception的成员变量\u0026quot;) 解释执行--\u0026gt;异常处理--\u0026gt;HANDLE_PENDING_EXCEPTION--\u0026gt;|找到能处理该异常的指令码|ArtMethod::FindCatchBlock 机器码执行--\u0026gt;InstructionCodeGeneratorX86::VisitThrow--\u0026gt;artDeliverExceptionFromCode--\u0026gt;setException artDeliverExceptionFromCode--\u0026gt;|找到异常处理处的指令位置|findCatch(\u0026quot;exception_handler.FindCatch(exception);\u0026quot;) 解释执行异常抛出和处理 被抛出的异常对象赋值给Thread tlsPtr_exception的成员变量，异常投递的工作就算完成；\n接下来就是异常处理的过程。以switch/case方式来解释执行的代码中，下面这个宏用于判断是否有异常发生并处理它。\nDex_instruction_list.h\n#define DEX_INSTRUCTION_LIST(V) \\ V(0x27, THROW, \u0026#34;throw\u0026#34;, k11x, false, kIndexNone, kThrow, kVerifyRegA) \\ interpreter_switch_impl.cc\nExecuteSwitchImpl template\u0026lt;bool do_access_check, bool transaction_active\u0026gt; JValue ExecuteSwitchImpl(......) { ......　//该函数详情见10.2.3.1节  do { dex_pc = inst-\u0026gt;GetDexPc(insns); ...... inst_data = inst-\u0026gt;Fetch16(0); switch (inst-\u0026gt;Opcode(inst_data)) { //switch/case方式执行不同的dex指令  ...... case Instruction::THROW: { //抛异常  PREAMBLE(); Object* exception = shadow_frame.GetVRegReference( inst-\u0026gt;VRegA_11x(inst_data)); if (UNLIKELY(exception == nullptr)) { //Throw抛出的异常对象为空，则重新抛一个空指针异常  ThrowNullPointerException(\u0026#34;throw with null exception\u0026#34;); } else if (.....) {.....} else { /*注意：Thread tlsPtr_有一个名为exception的成员变量，其类型为Throwable*。 其他代码逻辑要检查是否有异常发生的话，只要判断tlsPtr_exception是否为nullptr 即可。如果tlsPtr_ exception不为空指针，则表明有异常发生。 下面的SetException函数将把抛出的异常对象赋值给tlsPtr_exception*///main  self-\u0026gt;SetException(exception-\u0026gt;AsThrowable()); } HANDLE_PENDING_EXCEPTION(); //检查是否有异常发生，并做对应处理。main  break; } ..... } HANDLE_PENDING_EXCEPTION define HANDLE_PENDING_EXCEPTION() \\ do { \\ self-\u0026gt;AllowThreadSuspension(); \\ /*下面这个函数用于从当前正在执行的方法里找到对应的catch处理语句，如果能处理所抛出 的异常，则返回异常处理对应的dex指令码的位置*/ uint32_t found_dex_pc = FindNextInstructionFollowingException(self,\\ shadow_frame, inst-\u0026gt;GetDexPc(insns), instrumentation); \\ //如果本方法无法处理这个异常，则要退出整个方法的执行  if (found_dex_pc == DexFile::kDexNoIndex) { \\ ......\\ } \\ return JValue(); /* 退出本方法的执行，调用者将继续检查并处理异常 */ \\ } else { \\ //如果本方法catch住了所抛出的异常，则找到对应的处理指令  int32_t displacement = static_cast\u0026lt;int32_t\u0026gt;(found_dex_pc) - \\static_cast\u0026lt;int32_t\u0026gt;(dex_pc); \\ inst = inst-\u0026gt;RelativeAt(displacement); \\ } \\ } while (false) interpreter_common.cc\nFindNextInstructionFollowingException uint32_t FindNextInstructionFollowingException( Thread* self, ShadowFrame\u0026amp; shadow_frame, uint32_t dex_pc, const instrumentation::Instrumentation* instrumentation) { self-\u0026gt;VerifyStack(); StackHandleScope\u0026lt;2\u0026gt; hs(self); Handle\u0026lt;mirror::Throwable\u0026gt; exception(hs.NewHandle(self-\u0026gt;GetException())); ...... bool clear_exception = false; //调用ArtMethod的FindCatchBlock。  uint32_t found_dex_pc = shadow_frame.GetMethod()-\u0026gt;FindCatchBlock( hs.NewHandle(exception-\u0026gt;GetClass()), dex_pc, \u0026amp;clear_exception); if (found_dex_pc == DexFile::kDexNoIndex \u0026amp;\u0026amp; instrumentation != nullptr) { //如果本方法无法处理这个异常，则表示要进行栈回溯。此时将触发Instrumentation的  //MethodUnwindEvent函数  instrumentation-\u0026gt;MethodUnwindEvent(self, shadow_frame.GetThisObject(), shadow_frame.GetMethod(), dex_pc); } else {......} return found_dex_pc; } ArtMethod::FindCatchBlock art_quick_to_interpreter_bridge quick_entrypoints_x86.S\nRETURN_OR_DELIVER_PENDING_EXCEPTION MACRO0(RETURN_OR_DELIVER_PENDING_EXCEPTION) #检查Thread tlsPtr_ exception变量是否为空，如果不为空，则跳转到DELIVER_PENDING_EXCEPTION宏处,main  cmpl MACRO_LITERAL(0),%fs:THREAD_EXCEPTION_OFFSET jne 1f ret 1: DELIVER_PENDING_EXCEPTION #异常处理宏 END_MACRO DELIVER_PENDING_EXCEPTION MACRO0(DELIVER_PENDING_EXCEPTION) #异常处理宏定义  #该宏内部将设置tlsPtr_ managed_stack top_quick_frame_的值  SETUP_SAVE_ALL_CALLEE_SAVE_FRAME ebx, ebx subl MACRO_LITERAL(12), %esp pushl %fs:THREAD_SELF_OFFSET #调用artDeliverPendingExceptionFromCode函数,main  call SYMBOL(artDeliverPendingExceptionFromCode) UNREACHABLE END_MACRO quick_throw_entrypoints.cc\nextern \u0026#34;C\u0026#34; NO_RETURN void artDeliverPendingExceptionFromCode(Thread* self) { ScopedQuickEntrypointChecks sqec(self); self-\u0026gt;QuickDeliverException(); //调用Thread QuickDeliverException函数 } 机器码异常抛出和处理 code_generator_x86.cc\nvoid InstructionCodeGeneratorX86::VisitThrow(HThrow* instruction) { codegen_-\u0026gt;InvokeRuntime(QUICK_ENTRY_POINT(pDeliverException), instruction, instruction-\u0026gt;GetDexPc(), nullptr); CheckEntrypointTypes\u0026lt;kQuickDeliverException, void, mirror::Object*\u0026gt;(); } quick_entrypoints_x86.S\nart_quick_deliver_exception ONE_ARG_RUNTIME_EXCEPTION art_quick_deliver_exception, \\ artDeliverExceptionFromCode #调用C++层artDeliverExceptionFromCode //ONE_ARG_RUNTIME_EXCEPTION是一个宏，其内部调用SETUP_SAVE_CALLEE_SAVE_FRAME， //由于artDeliverExceptionFromCode位于虚拟机执行层，所以需要设置tlsPtr_managed_stack top_quick_frame_ MACRO2(ONE_ARG_RUNTIME_EXCEPTION, c_name, cxx_name) DEFINE_FUNCTION VAR(c_name) SETUP_SAVE_ALL_CALLEE_SAVE_FRAME ebx, ebx mov %esp, %ecx // Outgoing argument set up subl MACRO_LITERAL(8), %esp pushl %fs:THREAD_SELF_OFFSET PUSH eax call CALLVAR(cxx_name) UNREACHABLE END_FUNCTION VAR(c_name) END_MACRO quick_throw_entrypoints.cc\nartDeliverExceptionFromCode extern \u0026#34;C\u0026#34; NO_RETURN void artDeliverExceptionFromCode( mirror::Throwable* exception, Thread* self){ ScopedQuickEntrypointChecks sqec(self); if (exception == nullptr) { self-\u0026gt;ThrowNewException(\u0026#34;Ljava/lang/NullPointerException;\u0026#34;, \u0026#34;throw with null exception\u0026#34;); } else { self-\u0026gt;SetException(exception); //设置tlsPtr_ exception  } self-\u0026gt;QuickDeliverException(); //还是调用Thread类的QuickDeliverException } thread.cc\nQuickDeliverException void Thread::QuickDeliverException() { mirror::Throwable* exception = GetException(); //判断是否为Deoptimize相关的异常。此处不讨论Deoptimize的情况，所以  //is_deoptimization为false  bool is_deoptimization = (exception == GetDeoptimizationException()); if (!is_deoptimization) { instrumentation::Instrumentation* instrumentation = Runtime::Current()-\u0026gt;GetInstrumentation(); if (instrumentation-\u0026gt;HasExceptionCaughtListeners() \u0026amp;\u0026amp; IsExceptionThrownByCurrentMethod(exception)) { StackHandleScope\u0026lt;1\u0026gt; hs(this); HandleWrapper\u0026lt;mirror::Throwable\u0026gt; h_exception(hs.NewHandleWrapper( \u0026amp;exception)); instrumentation-\u0026gt;ExceptionCaughtEvent(this, exception); } ...... } ClearException(); QuickExceptionHandler exception_handler(this, is_deoptimization); if (is_deoptimization) { //DeoptimizeStack函数的详情见10.4.2.2节  exception_handler.DeoptimizeStack(); } else { //FindCatch非常关键，它将找到异常处理处的指令位置（pc）,main  exception_handler.FindCatch(exception); } exception_handler.UpdateInstrumentationStack(); exception_handler.DoLongJump(); //跳转到异常处理对应的地址 } quick_exception_handler.cc\nQuickExceptionHandler::FindCatch void QuickExceptionHandler::FindCatch(mirror::Throwable* exception) { StackHandleScope\u0026lt;1\u0026gt; hs(self_); Handle\u0026lt;mirror::Throwable\u0026gt; exception_ref(hs.NewHandle(exception)); //关键类  CatchBlockStackVisitor visitor(self_, context_, \u0026amp;exception_ref, this); visitor.WalkStack(true); //输入参数为true  if (clear_exception_) {} else { self_-\u0026gt;SetException(exception_ref.Get()); } //如果异常处理的代码位于机器码中，则再补充设置一些信息。这部分内容和机器码编译有一些关系，建  //议读者暂时不要理会  if (*handler_quick_frame_ != nullptr \u0026amp;\u0026amp; handler_method_header_ != nullptr \u0026amp;\u0026amp; handler_method_header_-\u0026gt;IsOptimized()) { SetCatchEnvironmentForOptimizedHandler(\u0026amp;visitor); } } class CatchBlockStackVisitor FINAL : public StackVisitor { ...... bool VisitFrame() (Locks::mutator_lock_) {//main  /*获取当前正在访问的方法。根据图10-14所示，我们依次会访问到Runtime ArtMethod、方法B、方 法A。最后将进入虚拟机执行X1。 */ ArtMethod* method = GetMethod(); exception_handler_-\u0026gt;SetHandlerFrameDepth(GetFrameDepth()); //如果method为空，表示当前所访问的方法为虚拟机执行层  if (method == nullptr) { /*①注意，如果if条件满足，则表明栈回溯到了虚拟机执行层，这时我们不能再继续回溯虚拟机执行层的函数了，只能先jump回（Quick-ExceptionHandler的主要功能就是long jump，即长跳转到目标指令位置）X1调用方法A的返回处。*/ exception_handler_-\u0026gt;SetHandlerQuickFramePc(GetCurrentQuickFramePc());//返回X1中方法A的返回地址  exception_handler_-\u0026gt;SetHandlerQuickFrame(GetCurrentQuickFrame()); exception_handler_-\u0026gt;SetHandlerMethodHeader( GetCurrentOatQuickMethodHeader()); uint32_t next_dex_pc; ArtMethod* next_art_method; /*GetNextMethodAndDexPc函数内部也会做WalkStack进行栈回溯操作，找到紧挨着当前 虚拟机执行层中的上一个方法。在图10-14中，X1往上没有调用者了，所以下面这个函数 返回false。如果X1之上还有调用者，则返回那个函数的一些信息。 */ bool has_next = GetNextMethodAndDexPc(\u0026amp;next_art_method, \u0026amp;next_dex_pc); exception_handler_-\u0026gt;SetHandlerDexPc(next_dex_pc); exception_handler_-\u0026gt;SetHandlerMethod(next_art_method); ...... return false; // End stack walk.  } //略过Runtime ArtMethod  if (method-\u0026gt;IsRuntimeMethod()) { return true; } /*从method中catch语句中找到是否有能处理该异常的地方。该函数和解释执行层中的FindNextInstruc- tionFollowingException函数类似，请读者自行阅读它。假设图10-14中的方法B、方法A均无法 处理此异常，则HandleTryItems将返回true *///main  return HandleTryItems(method); } 应用层异常处理 图解 graph TB mJavaVM.DetachCurrentThread--\u0026gt;Thread::Destroy--\u0026gt;Thread::HandleUncaughtExceptions--\u0026gt;|Jni调用java层Thread的uncaughtExceptionHandler|Thead.uncaughtExceptionHandler--\u0026gt;TheadGroup--\u0026gt;ThreadStaticUncaughtExceptionHandler AndroidRuntime\nAndroidRuntime::start void AndroidRuntime::start(const char* className, const Vector\u0026lt;String8\u0026gt;\u0026amp; options, bool zygote){ JniInvocation jni_invocation; jni_invocation.Init(NULL); JNIEnv* env; //启动虚拟机  if (startVm(\u0026amp;mJavaVM, \u0026amp;env, zygote) != 0) { return; } ...... char* slashClassName = toSlashClassName(className); jclass startClass = env-\u0026gt;FindClass(slashClassName); if (startClass == NULL) {..... } else { //假设startMeth是图10-14中的方法A  jmethodID startMeth = env-\u0026gt;GetStaticMethodID(startClass, \u0026#34;main\u0026#34;, \u0026#34;([Ljava/lang/String;)V\u0026#34;); if (startMeth == NULL) {......} else { /*下面的CallStaciVoidMethod将触发图10-14的虚拟机执行X1，其内部调用方法 A。根据上文所述，Thread QuickDeliverException的执行完后，longjmp将跳 转到X1调用方法A返回后的指令处，就好像方法A执行完了一样（实际上没有）。 所以，下面的CallStaticVoidMethod将返回。 main*/ env-\u0026gt;CallStaticVoidMethod(startClass, startMeth, strArray); } } free(slashClassName); if (mJavaVM-\u0026gt;DetachCurrentThread() != JNI_OK)//main  ALOGW(\u0026#34;Warning: unable to detach main thread\\n\u0026#34;); if (mJavaVM-\u0026gt;DestroyJavaVM() != 0) ALOGW(\u0026#34;Warning: VM did not shut down cleanly\\n\u0026#34;); java_vm_ext.cc\nDetachCurrentThread static jint DetachCurrentThread(JavaVM* vm) { ...... JavaVMExt* raw_vm = reinterpret_cast\u0026lt;JavaVMExt*\u0026gt;(vm); Runtime* runtime = raw_vm-\u0026gt;GetRuntime(); runtime-\u0026gt;DetachCurrentThread(); //内部将调用当前线程的Destroy方法,main  return JNI_OK; } Thread.cc\nThread::Destroy void Thread::Destroy() { Thread* self = this; ...... if (tlsPtr_.opeer != nullptr) { ScopedObjectAccess soa(self); //调用为该线程设置的UncaughtExceptionHandler对象。感兴趣的读者可自行研究该函数。main  HandleUncaughtExceptions(soa); RemoveFromThreadGroup(soa); } ...... } Thread::HandleUncaughtExceptions void Thread::HandleUncaughtExceptions(ScopedObjectAccess\u0026amp; soa) { if (!IsExceptionPending()) { return; } ScopedLocalRef\u0026lt;jobject\u0026gt; peer(tlsPtr_.jni_env, soa.AddLocalReference\u0026lt;jobject\u0026gt;(tlsPtr_.opeer)); ScopedThreadStateChange tsc(this, kNative); // Get and clear the exception.  ScopedLocalRef\u0026lt;jthrowable\u0026gt; exception(tlsPtr_.jni_env, tlsPtr_.jni_env-\u0026gt;ExceptionOccurred()); tlsPtr_.jni_env-\u0026gt;ExceptionClear(); // If the thread has its own handler, use that.  ScopedLocalRef\u0026lt;jobject\u0026gt; handler(tlsPtr_.jni_env, tlsPtr_.jni_env-\u0026gt;GetObjectField(peer.get(), WellKnownClasses::java_lang_Thread_uncaughtHandler)); if (handler.get() == nullptr) { // Otherwise use the thread group\u0026#39;s default handler.  handler.reset(tlsPtr_.jni_env-\u0026gt;GetObjectField(peer.get(), WellKnownClasses::java_lang_Thread_group)); } // Call the handler.  tlsPtr_.jni_env-\u0026gt;CallVoidMethod(handler.get(),//main  WellKnownClasses::java_lang_Thread__UncaughtExceptionHandler_uncaughtException, peer.get(), exception.get()); // If the handler threw, clear that exception too.  tlsPtr_.jni_env-\u0026gt;ExceptionClear(); } Jni.h / jni_internal.cc\nExceptionOccurred /* * C++ object wrapper. * * This is usually overlaid on a C struct whose first element is a * JNINativeInterface*. We rely somewhat on compiler behavior. */ struct _JNIEnv { jthrowable ExceptionOccurred() { return functions-\u0026gt;ExceptionOccurred(this); } static jthrowable ExceptionOccurred(JNIEnv* env) { ScopedObjectAccess soa(env); mirror::Object* exception = soa.Self()-\u0026gt;GetException(); return soa.AddLocalReference\u0026lt;jthrowable\u0026gt;(exception); } Thread.cc\ntlsPtr_.jni_env { ... // Every thread may have an associated JNI environment  JNIEnvExt* jni_env; } tlsPtr_; GetException mirror::Throwable* GetException() const SHARED_REQUIRES(Locks::mutator_lock_) { return tlsPtr_.exception; } IsExceptionPending bool IsExceptionPending() const { return tlsPtr_.exception != nullptr; } Thread.java.uncaughtExceptionHandler // null unless explicitly set  private volatile UncaughtExceptionHandler uncaughtExceptionHandler; ThreadGroup.java.uncaughtException public void uncaughtException(Thread t, Throwable e) { if (parent != null) { parent.uncaughtException(t, e); } else { Thread.UncaughtExceptionHandler ueh = Thread.getDefaultUncaughtExceptionHandler(); if (ueh != null) { ueh.uncaughtException(t, e); } else if (!(e instanceof ThreadDeath)) { System.err.print(\u0026#34;Exception in thread \\\u0026#34;\u0026#34; \\+ t.getName() + \u0026#34;\\\u0026#34; \u0026#34;); e.printStackTrace(System.err); } } } Thread.java.defaultUncaughtExceptionHandler // null unless explicitly set  private static volatile UncaughtExceptionHandler defaultUncaughtExceptionHandler; "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%BC%82%E5%B8%B8/",
	"title": "异常",
	"tags": [],
	"description": "",
	"content": "异常 探索总结异常知识\n 1javacrash    JavaCrashSystemHandle      anr    1ANRSystmHandle     2ANRMonitor_CollectInfo     3ANRAnalysisRootCause      nativecrash    1nativeCrash选型和整体流程     nativeCrash1SystemHandle     nativeCrash2Monitor_CollectStack     nativeCrash3SymbolRecovery     nativeCrash4AnalysisRootCause      xcrash    1xCrash原理     linuxApi     xCrashAnr     xCrashNativeCrash      "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%80%9D%E6%83%B3/",
	"title": "思想",
	"tags": [],
	"description": "",
	"content": "思想 探索总结思想知识\n IOC     程序设计规范     继承和组合     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/",
	"title": "性能优化",
	"tags": [],
	"description": "",
	"content": "性能优化 探索总结性能优化知识\n apm    MatrixGradlePlugin     MatrixSource     Matrix接入后遇到的问题     Matrix研究     resource    MatrixResourcePlugin       内存优化    coroutine    kotlin协程     kotlin协程Source     kotlin协程取消     kotlin协程异常     使用挂起函数来封装回调       布局优化    布局优化      "
},
{
	"uri": "https://huanle19891345.github.io/en/",
	"title": "技术探索总结",
	"tags": [],
	"description": "",
	"content": "技术探索总结 探索客户端技术背后的原理细节\nAOSP研究方式  android    aop    ASM访客者模式     JDK动态代理     编译插桩和动态代理      art    1类编译    dex2oat     dex2oat介绍      2类加载    Android_N混合编译与对热补丁影响解析     类加载     类加载虚拟机层      alloc_gc    1Space     2Alloc     AllocRelated     GC     GC1_MS_CMS     GC2_ConcurrentCopying     GC3_MarkCompact     GC4_Semi_Space     Runtime_VisitRoots      ART_Lock     jni    _解释执行7_0     java_jni方法调用原理     Jni数据转换     SystemLoadLibrary     异常      启动流程    ART启动流程      基础数据结构     混合编译_运行    JVM_JIT     混合编译_运行       gradlejenkins    AndroidPlugin     android打包    Android打包      GradleDebug     GradlePlugin     Gradle打包过程     Transform      jetpack    arch    1lifecycle    Lifecycle     LifecycleCoroutine      2livedata    1MediatorLiveData     LiveData     LiveDataCoroutine     Transformations      3viewmodel    SaveAndRestoreInstanceState     SavedStateHandle     SavingStates     ViewModel     ViewModelScope_Delegate      Coroutines     databinding    Databinding     TwoWayDataBinding      di    DI     HiltSource      架构实现    KaptGenerateViewModel     架构思考和实现     架构思考和实现Inner       compose    Compose     ComposeSource     LayoutNode     ReComposition      SupportToAndroidx     workmanager    WorkManager       ndk    ELF文件结构     JNI     native_hook      system    ashmem    匿名共享内存Ashmem      bitmap    Bitmap     BitmapSource      handler    Epoll     Looper     ThreadLocal      input    touchEventNative      kernel    kernel      layoutinflater    LayoutInflater      surfaceview    SurfaceViewSource      textureview    TextureViewSource      thread    StackTraceElement     ThreadState      zygote    SystemServerSource     ZygoteSource     Zygote进程      后台任务    后台任务处理      多进程    binder    1BinderServiceManager     2BinderServer     3BinderClient     4BinderKernel     BinderDeath     Binder原理      mmkv    MMKV       应用启动退出    应用启动      源码研究方法    Syscall查找方式      系统绘制    Graphics     measurelayoutdraw    measure      Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制       ui    webview    WebView      动画    AnimatorSource       包体积    包体积压缩      埋点    埋点     易观方舟      存储    sharedpreferences    SharedPreferences       安全    app签名     应用安全     网络请求安全      性能优化    apm    MatrixGradlePlugin     MatrixSource     Matrix接入后遇到的问题     Matrix研究     resource    MatrixResourcePlugin       内存优化    1manageMemory     2OOM     3Hprof_binary_dump_format     4DumpHprof     5LeakCanary2     6LeakCanary2Analyze     7KOOMSource      布局优化    布局优化       插件化    1插件化面临的问题     apk安装和卸载    应用安装和卸载过程      Hook     qigsaw    Qigsaw      shadow    Shadow     ShadowPlugin     ShadowSource      插件化技术选型      热修复字节码    1hotfixResearch     AndFix     AndFixSource     Dex文件格式     MultiDex     tinker    源码分析    Resource.arsc生成和结构     TinkerGradlePluginSource     TinkerSource        稳定性    异常    1javacrash    JavaCrashSystemHandle      anr    1ANRSystmHandle     2ANRMonitor_CollectInfo     3ANRAnalysisRootCause      nativecrash    1nativeCrash选型和整体流程     nativeCrash1SystemHandle     nativeCrash2Monitor_CollectStack     nativeCrash3SymbolRecovery     nativeCrash4AnalysisRootCause      xcrash    1xCrash原理     linuxApi     xCrashAnr     xCrashNativeCrash        自动化测试    android代码自测       java    BlockingQueue     java并发     ThreadPoolExecutor      kotlin    coroutine    kotlin协程     kotlin协程Source     kotlin协程取消     kotlin协程异常     使用挂起函数来封装回调       linux    linux_io      思想    IOC     程序设计规范     继承和组合      方向和趋势    音视频    ffmpeg    examples    TranscodingSource      FFmpegDebug      webrtc    WebRTC源码下载和编译      编解码    编解码知识        跨平台    flutter    1startup    1startup     2startup_embedder_framwwork     3flutter_surface     4startup_dart_framework      engine    Engine     FlutterEngineCache     FlutterEngineDebug环境搭建     FlutterEngineGroup      touch    Touch      动画    动画      响应式架构    1跨组件传递数据     2Provider     3异步_响应式_状态管理     stream    Stream       混合开发    FlutterBoost     FlutterBoost3     混合开发      渲染    Widget     渲染      路由    路由      通信    EventChannel     MessageLoop     MethodChannel     Pigeon        "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/",
	"title": "插件化",
	"tags": [],
	"description": "",
	"content": "插件化 探索总结插件化知识\n 1插件化面临的问题     apk安装和卸载    应用安装和卸载过程      Hook     qigsaw    1ANRSystmHandle     2ANRMonitor_CollectInfo     3ANRAnalysisRootCause      shadow    Shadow     ShadowPlugin     ShadowSource      插件化技术选型     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E6%8F%92%E4%BB%B6%E5%8C%96/%E6%8F%92%E4%BB%B6%E5%8C%96%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B/",
	"title": "插件化技术选型",
	"tags": [],
	"description": "",
	"content": "Shadow(腾讯) Qigsaw(爱奇艺) https://developer.android.google.cn/guide/app-bundle\n VirtualAPK(滴滴) https://github.com/didi/VirtualAPK\nhttps://blog.csdn.net/u012124438/article/details/74118905\n我们可以先启动一个已经在AndroidManifest.xml里面声明过的替身Activity，让这个Activity进入AMS进程接受检验；最后在换成我们真正需要启动的Activity；这样就成功欺骗了AMS进程\nAtlas(阿里) https://blog.csdn.net/M075097/article/details/79225030\n;//-----2.3.3替换系统原生ClassLoader为DelegateClassLoad AndroidHack.injectClassLoader(packageName, newClassLoaderer) //-----2.3.4 替换系统的Instrumentation为InstrumentationHook，该类是一个系统与用户之间交互的介质层，大部分调用的功能操作都会流过此类之后再进一步调  AndroidHack.injectInstrumentationHook(new InstrumentationHook(AndroidHack.getInstrumentation(), application.getBaseContext() ActivityManagerDelegate activityManagerProxy = new ActivityManagerDelegate(); Object gDefault = null; if(Build.VERSION.SDK_INT\u0026gt;25 || (Build.VERSION.SDK_INT==25\u0026amp;\u0026amp;Build.VERSION.PREVIEW_SDK_INT\u0026gt;0)){ gDefault=AtlasHacks.ActivityManager_IActivityManagerSingleton.get(AtlasHacks.ActivityManager.getmClass()); }else{ gDefault=AtlasHacks.ActivityManagerNative_gDefault.get(AtlasHacks.ActivityManagerNative.getmClass()); } AtlasHacks.Singleton_mInstance.hijack(gDefault, activityManagerProxy); RePlugin(360) Replugin与DroidPlugin框架比较\n虽然唯一Hook点为宿主Application#LoadedApk中的classLoader对象，但源码中依然存在着众多的invoke反射，和google禁止使用非公开api的策略相违背\nNeptune(爱奇艺)  插件的安装与加载  https://github.com/iqiyi/Neptune/blob/master/docs/SDK%E5%8E%9F%E7%90%86/%E6%8F%92%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8A%A0%E8%BD%BD.md\n Neptune/docs/SDK原理/插件的代理实现机制.md  https://github.com/iqiyi/Neptune/blob/master/docs/SDK%E5%8E%9F%E7%90%86/%E6%8F%92%E4%BB%B6%E7%9A%84%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6.md\nHydra(美团-未开源) "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/",
	"title": "方向和趋势",
	"tags": [],
	"description": "",
	"content": "方向和趋势 探索总结方向和趋势知识\n 音视频    ffmpeg    examples    TranscodingSource      FFmpegDebug      webrtc    WebRTC源码下载和编译      编解码    编解码知识       "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%9F%8B%E7%82%B9/%E6%98%93%E8%A7%82%E6%96%B9%E8%88%9F/",
	"title": "易观方舟",
	"tags": [],
	"description": "",
	"content": "模块设计 graph TB 采集策略--\u0026gt;|控制触发|采集 采集--\u0026gt;自动采集--\u0026gt;全埋点监听touch--\u0026gt;|onGlobalLayout|hookDecorViewClick--\u0026gt;|mOnTouchListener|HookTouchListener--\u0026gt;trackEvent 采集--\u0026gt;手动采集--\u0026gt;trackEvent 上报策略--\u0026gt;|控制触发|上报 /** com/analysys/process/HeatMap.java * 反射给View注册监听 */ private void hookViewClick(View view) throws Exception {  ans-sdk/analysys_core/src/main/java/com/analysys/AutomaticAcquisition.java\nAutomaticAcquisition onActivityCreated @Override public void onActivityCreated(final Activity activity, Bundle savedInstanceState) { AnalysysConfig config = AgentProcess.getInstance().getConfig(); if (config.isAutoTrackClick()) { AnalysysUtil.onActivityCreated(activity); } if (config.isAutoHeatMap()) { initHeatMap(new WeakReference\u0026lt;\u0026gt;(activity)); } } initHeatMap private void initHeatMap(final WeakReference\u0026lt;Activity\u0026gt; wa) { layoutListener = new ViewTreeObserver.OnGlobalLayoutListener() { @Override public void onGlobalLayout() { if (wa == null) { return; } final Activity activity = wa.get(); if (activity != null) { activity.getWindow().getDecorView().post(new Runnable() { @Override public void run() { try { HeatMap.getInstance().hookDecorViewClick(activity.getWindow().getDecorView()); } catch (Throwable ignore) { ExceptionUtil.exceptionThrow(ignore); } } }); } } }; } onActivityResumed @Override public void onActivityResumed(Activity activity) { if (AgentProcess.getInstance().getConfig().isAutoHeatMap()) { checkLayoutListener(new WeakReference\u0026lt;\u0026gt;(activity), true); } } checkLayoutListener private void checkLayoutListener(WeakReference\u0026lt;Activity\u0026gt; wr, boolean isResume) { if (wr != null) { Activity activity = wr.get(); if (layoutListener != null) { View rootView = activity.findViewById(android.R.id.content); if (isResume) { rootView.getViewTreeObserver().addOnGlobalLayoutListener(layoutListener); } else { if (Build.VERSION.SDK_INT \u0026gt; 15) { rootView.getViewTreeObserver().removeOnGlobalLayoutListener(layoutListener); } } } } } ans-sdk/analysys_core/src/main/java/com/analysys/process/HeatMap.java\nHeatMap hookDecorViewClick /*** * 递归调用解析view * @param decorView 根节点view */ public void hookDecorViewClick(View decorView) throws Exception { if (decorView instanceof ViewGroup) { hookViewClick(decorView); int count = ((ViewGroup) decorView).getChildCount(); for (int i = 0; i \u0026lt; count; i++) { if (((ViewGroup) decorView).getChildAt(i) instanceof ViewGroup) { hookDecorViewClick(((ViewGroup) decorView).getChildAt(i)); } else { hookViewClick(((ViewGroup) decorView).getChildAt(i)); } } } else { hookViewClick(decorView); } } hookViewClick /** * 反射给View注册监听 */ private void hookViewClick(View view) throws Exception { int visibility = view.getVisibility(); if (visibility == 4 || visibility == 8) { return; } if (!view.getGlobalVisibleRect(new Rect())) { return; } Class viewClass = Class.forName(\u0026#34;android.view.View\u0026#34;); Method getListenerInfoMethod = viewClass.getDeclaredMethod(\u0026#34;getListenerInfo\u0026#34;); if (!getListenerInfoMethod.isAccessible()) { getListenerInfoMethod.setAccessible(true); } Object listenerInfoObject = getListenerInfoMethod.invoke(view); Class mListenerInfoClass = Class.forName(\u0026#34;android.view.View$ListenerInfo\u0026#34;); Field mOnClickListenerField = mListenerInfoClass.getDeclaredField(\u0026#34;mOnTouchListener\u0026#34;); // Log.d(\u0026#34;sanbo\u0026#34;, view.hashCode() + \u0026#34;-----\u0026#34; + HeatMap.HookTouchListener.class.getName() + // \u0026#34; \u0026lt;-------\u0026gt; \u0026#34; + mOnClickListenerField.getType().getName());  mOnClickListenerField.setAccessible(true); Object touchListenerObj = mOnClickListenerField.get(listenerInfoObject); if (!(touchListenerObj instanceof HookTouchListener)) { // printLog(view, touchListenerObj);  HookTouchListener touchListenerProxy = new HookTouchListener((View.OnTouchListener) touchListenerObj); mOnClickListenerField.set(listenerInfoObject, touchListenerProxy); } } HookTouchListener.onTouch private class HookTouchListener implements View.OnTouchListener { private View.OnTouchListener onTouchListener; private HookTouchListener(View.OnTouchListener onTouchListener) { this.onTouchListener = onTouchListener; } @Override public boolean onTouch(final View v, final MotionEvent event) { try { if (event.getAction() == MotionEvent.ACTION_DOWN) { // 黑白名单判断  if (isTackHeatMap(v)) { setCoordinate(v, event); } } catch (Throwable ignore) { ExceptionUtil.exceptionThrow(ignore); } } return onTouchListener.onTouch(v, event); return false; } } setCoordinate private void setCoordinate(final View v, final MotionEvent event) { if (isTouch(rawX, rawY)) { AThreadPool.asyncLowPriorityExecutor(new Runnable() { @Override public void run() { final String path = PathGeneral.getInstance().general(v); boolean isAddPath = setPath(path); if (isAddPath) { rx = rawX; ry = rawY; setClickCoordinate(); setClickContent(v); clickInfo.putAll(pageInfo); AgentProcess.getInstance().pageTouchInfo(clickInfo,currentTime); } } }); } } pagetouchinfo\ncom/analysys/allgro/plugin/ASMProbeHelp.java\nASMProbeHelp.java trackViewOnClick public void trackViewOnClick(final View v, final boolean hasTrackClickAnn) { try { final long currentTime = System.currentTimeMillis(); AThreadPool.asyncLowPriorityExecutor(new Runnable() { @Override public void run() { try { if (isInLimitTime(v)) { return; } for (ASMHookAdapter observer : mObservers) { observer.trackViewOnClick(v, hasTrackClickAnn,currentTime); } } catch (Throwable ignore) { ExceptionUtil.exceptionThrow(ignore); } } }); }catch (Throwable ignore){ ExceptionUtil.exceptionThrow(ignore); } } com/analysys/allgro/plugin/ViewClickProbe.java\nViewClickProbe extends ASMHookAdapter trackViewOnClick @Override public void trackViewOnClick(View v, boolean hasTrackClickAnn,long currentTime) { try { Map\u0026lt;String, Object\u0026gt; viewInfo = new HashMap\u0026lt;\u0026gt;(); String[] viewTypeAndText = AllegroUtils.getViewTypeAndText(v); viewInfo.put(Constants.ELEMENT_TYPE, viewTypeAndText[0]); viewInfo.put(Constants.ELEMENT_CONTENT, viewTypeAndText[1]); String path = PathGeneral.getInstance().general(v); viewInfo.put(Constants.ELEMENT_PATH,path); String idName = AllegroUtils.getViewIdResourceName(v); if (!TextUtils.isEmpty(idName)) { viewInfo.put(Constants.ELEMENT_ID, idName); } autoTrackClick(pageObj, viewInfo, hasTrackClickAnn,currentTime); } catch (Throwable ignore) { ExceptionUtil.exceptionThrow(ignore); } } autoTrackClick private void autoTrackClick(Object pageObj, Map\u0026lt;String, Object\u0026gt; elementInfo, boolean hasTrackClickAnn,long currentTime) throws Throwable { if (pageObj != null) { // 获取页面相关信息  elementInfo.putAll(AllegroUtils.getPageInfo(pageObj,true)); // if(elementInfo!=null\u0026amp;\u0026amp;elementInfo.containsKey(Constants.PARENT_URL)){  // 去除此字段 // elementInfo.remove(Constants.PARENT_URL); // }  } AgentProcess.getInstance().autoTrackViewClick(elementInfo,currentTime); }  com/analysys/process/AgentProcess.java\nAgentProcess.java pageTouchInfo /** * Touch事件处理 */ void pageTouchInfo(final Map\u0026lt;String, Object\u0026gt; screenDetail,final long currentTime) { try { Context context = AnalysysUtil.getContext(); Map\u0026lt;String, Object\u0026gt; screenInfo = CommonUtils.deepCopy(screenDetail); if (context != null) { JSONObject eventData = DataAssemble.getInstance(context).getEventData( currentTime,Constants.API_APP_CLICK, Constants.APP_CLICK, null, screenInfo); trackEvent(context, Constants.API_APP_CLICK, Constants.APP_CLICK, eventData); } } catch (Throwable ignore) { ExceptionUtil.exceptionThrow(ignore); } } autoTrackViewClick /** * 点击自动上报 * * @param clickInfo 点击上报信息 */ public void autoTrackViewClick(final Map\u0026lt;String, Object\u0026gt; clickInfo,final long currentTime) throws Throwable { Context context = AnalysysUtil.getContext(); if (context != null) { JSONObject eventData = DataAssemble.getInstance(context).getEventData(currentTime,Constants.API_USER_CLICK, Constants.USER_CLICK, null, clickInfo); trackEvent(context, Constants.API_USER_CLICK, Constants.USER_CLICK, eventData); } } trackEvent /** * 接口数据处理 */ private void trackEvent(Context context, String apiName, String eventName, JSONObject eventData) { if (!CommonUtils.isEmpty(eventName) \u0026amp;\u0026amp; checkoutEvent(eventData)) { // 此处重置重传传次数，解决处于重传状态时，触发新事件重传次数不够三次  //SharedUtil.remove(mContext, Constants.SP_FAILURE_COUNT);  if (LogBean.getCode() == Constants.CODE_SUCCESS) { LogPrompt.showLog(apiName, true); } EasytouchProcess.getInstance().setEventMessage(eventData.toString()); if (mEventObserver != null) { mEventObserver.onEvent(eventName, eventData); } UploadManager.getInstance(context).sendManager(eventName, eventData); } } com/analysys/network/UploadManager.java\nUploadManager.java sendManager /** * 判断 发送数据 */ public void sendManager(String type, JSONObject sendData) { if (CommonUtils.isEmpty(sendData)) { return; } dbCacheCheck(); TableAllInfo.getInstance(mContext).insert(sendData.toString(), type); if (CommonUtils.isMainProcess(mContext)) { BaseSendStatus sendStatus = PolicyManager.getPolicyType(mContext); if (sendStatus.isSend(mContext)) { sendUploadMessage(); } } else { LogPrompt.processFailed(); } } sendUploadMessage /** * 发送实时消息 */ private void sendUploadMessage() { if (mHandler.hasMessages(delayUploadData)) { mHandler.removeMessages(uploadData); } Message msg = Message.obtain(); msg.what = uploadData; mHandler.sendMessage(msg); } SendHandler.handleMessage /** * 处理数据压缩,上传和返回值解析 */ private class SendHandler extends Handler { private SendHandler(Looper looper) { super(looper); } @Override public void handleMessage(Message msg) { try { String url = CommonUtils.getUrl(mContext); if (!CommonUtils.isEmpty(url)) { int what = msg.what; if (what == uploadData || what == delayUploadData) { uploadData(url); } else if (what == updateTime) { calibrationTime(url); } } else { LogPrompt.showErrLog(LogPrompt.URL_ERR); } } catch (Throwable ignore) { ExceptionUtil.exceptionThrow(ignore); } } } uploadData /** * 数据上传 */ private void uploadData(String url) throws IOException, JSONException { if (NetworkUtils.isNetworkAvailable(mContext)) { JSONArray eventArray = TableAllInfo.getInstance(mContext).select(); // 上传数据检查校验  eventArray = checkUploadData(eventArray); if (!CommonUtils.isEmpty(eventArray)) { LogPrompt.showSendMessage(url, eventArray); encryptData(url, String.valueOf(eventArray)); } else { TableAllInfo.getInstance(mContext).deleteData(); } } else { LogPrompt.networkErr(); } } encryptData /** * 数据加密 */ private void encryptData(String url, String value) throws IOException { if (CommonUtils.isEmpty(spv)) { spv = CommonUtils.getSpvInfo(mContext); } Map\u0026lt;String, String\u0026gt; headInfo = null; String encryptData; if (Constants.encryptType != 0) { encryptData = encrypt(value, Constants.encryptType); if (!TextUtils.isEmpty(encryptData)) { headInfo = getHeadInfo(); if (!CommonUtils.isEmpty(headInfo)) { LogPrompt.encryptLog(true); } else { encryptData = value; } } else { encryptData = value; } } else { encryptData = value; } String zipData = CommonUtils.messageZip(encryptData); sendRequest(url, zipData, headInfo); } sendRequest /** * 发送数据 */ private void sendRequest(String url, String dataInfo, Map\u0026lt;String, String\u0026gt; headInfo) { try { String returnInfo; if (url.startsWith(Constants.HTTP)) { returnInfo = RequestUtils.postRequest(url, dataInfo, spv, headInfo); } else { returnInfo = RequestUtils.postRequestHttps(mContext, url, dataInfo, spv, headInfo); } policyAnalysys(analysysStrategy(returnInfo)); } catch (Throwable ignore) { ExceptionUtil.exceptionThrow(ignore); } } 参考 https://docs.analysys.cn/integration/sdk/android/andoird-quick\nhttps://github.com/analysys/ans-android-sdk\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/",
	"title": "架构实现",
	"tags": [],
	"description": "",
	"content": "架构实现 探索总结架构实现知识\n KaptGenerateViewModel     架构思考和实现     架构思考和实现Inner     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/%E6%9E%B6%E6%9E%84%E6%80%9D%E8%80%83%E5%92%8C%E5%AE%9E%E7%8E%B0/",
	"title": "架构思考和实现",
	"tags": [],
	"description": "",
	"content": "架构设计过程 架构思考 graph LR subgraph 抽象客观事物 页面开发任务--\u0026gt;|抽象出模型|数据处理并展示 end subgraph 发现客观问题 数据处理并展示--\u0026gt;|发现问题|splitArch(需要分离界面和数据,分层架构) 数据处理并展示--\u0026gt;|发现问题|数据处理需要考虑界面生命周期 数据处理并展示--\u0026gt;|发现问题|ViewController需要声明式更新 数据处理并展示--\u0026gt;|发现问题|数据需要保留 数据处理并展示--\u0026gt;|发现问题|需要处理异步任务(\u0026quot;需要处理异步任务,结构化并发\u0026quot;) 数据处理并展示--\u0026gt;|发现问题|需要数据源emit多数据项 数据处理并展示--\u0026gt;|发现问题|需要抽象数据策略 数据处理并展示--\u0026gt;|发现问题|callback影响可读性 数据处理并展示--\u0026gt;|发现问题|层间依赖内部引用不灵活 数据处理并展示--\u0026gt;|发现问题|IOC时模板代码且无scope end subgraph 解决问题 splitArch--\u0026gt;|解决方案|MVC,MVP,MVVM(\u0026quot;MVC,MVP,MVVM(数据驱动)\u0026quot;) 数据处理需要考虑界面生命周期--\u0026gt;|解决方案|LifecycleAware组件 ViewController需要声明式更新--\u0026gt;|解决方案|DataBinding 数据需要保留--\u0026gt;|解决方案|ViewModel等三段式保留方案 需要处理异步任务--\u0026gt;|解决方案|Coroutine1(Coroutine) 需要数据源emit多数据项--\u0026gt;|解决方案|Flow 需要抽象数据策略--\u0026gt;|解决方案|NetworkBoundResource类族 callback影响可读性--\u0026gt;|解决方案|Coroutine2(Coroutine,Flow) 层间依赖内部引用不灵活--\u0026gt;|解决方案|IOC传入依赖 IOC时模板代码且无scope--\u0026gt;|解决方案|DI框架,如Hilt end 架构设计 Jetpack架构组件的通用落地设计如下\n各层内设计 View Layer 类设计 Activity和Fragment是同样的继承结构设计，以Activity为例:\nclassDiagram class CommonActivity { +inflateContent(savedInstanceState: Bundle?)* +init(savedInstanceState: Bundle?)* } class CommonInflateActivity { +inflateContent(savedInstanceState: Bundle?) +getLayoutId()*Int } class DataBindingActivity~VDB : ViewDataBinding~{ +inflateContent(savedInstanceState: Bundle?) +init(savedInstanceState: Bundle?) -bindVariable(activityDataBinding: VDB) +getLayoutId()* Int +getVariableMap()* Map } class ViewModelCommonActivity~VM : BaseViewModel~ { ~VM viewModel } class ViewModelBindingActivity~VDB : ViewDataBinding, VM : BaseViewModel~ { ~VM viewModel +getVariableMap()Map +getViewModelVariableId()*Int } BaseActivity\u0026lt;|--CommonActivity CommonActivity\u0026lt;|--CommonInflateActivity CommonActivity\u0026lt;|--DataBindingActivity CommonInflateActivity\u0026lt;|--ViewModelCommonActivity DataBindingActivity\u0026lt;|--ViewModelBindingActivity Hilt构造并注入viewmodel DataBinding场景细分 ViewModel Layer Hilt注入需要的Domain层Repository Data load type Trigger by lifecycle event automatic val userNameLiveData = liveData { emit(userRepository.getUserNameFromCache()) } as MutableLiveData //two way data binding Trigger by user action event solution1: use liveData coroutine and reObserve only when user event happens, must remove previous observer\nsolution2: use _ private mutableLiveData and public liveData, use fun updateXxx() = viewModelScope.launch(Dispatchers) { update private mutableLiveData}\n//expose immutable LiveData to ViewController when one way data binding private val _uidLiveData = MutableLiveData\u0026lt;String\u0026gt;() val uidLiveData: LiveData\u0026lt;String\u0026gt; get() = _uidLiveData fun updateLoginData() { viewModelScope.launch { // Coroutine that will be canceled when the ViewModel is cleared.  userRepository.login(userNameLiveData.value, passwordLiveData.value) .collect { emit(it, _uidLiveData)//use kotlin extension  } } } LiveData封装思路 graph LR subgraph Encapsulation purpose Target(\u0026quot;generic parse Resource\u0026lt;\u0026gt; data struct and emit\u0026quot;) end subgraph Encapsulation way Target--\u0026gt;Extend(\u0026quot;1. Extend: Implement LiveDataScope logic alone, because CoroutineLiveData is internel\u0026quot;) Target--\u0026gt;Combine/Delegate(\u0026quot;2. Combine/Delegate: use Transformations/MediatorLiveData, custom .map and Observer\u0026quot;) Target--\u0026gt;FunctionExtension(\u0026quot;3. FunctionExtension\u0026quot;) end Model Layer Hilt注入Singleton DataSource @Singleton class UserRepository @Inject constructor( private val userInMemoryDataSource: UserInMemoryDataSource, private val userLocalDataSource: UserLocalDataSource, private val userRemoteDataSource: UserRemoteDataSource ) { 具体设计如上架构设计图 架构设计图\nDataCallbackReplacement NetworkBoundResource类设计 classDiagram class IFlowDataStrategy~ResultType~ { +loadAsFlow: Flow~Resource~ResultType~~ } class BaseFlowDataStrategy~ResultType~ { -resultSource: Resource\u0026lt;ResultType\u0026gt;? = null +FlowCollector\u0026lt;Resource\u0026lt;ResultType\u0026gt;\u0026gt;.emitIfDifferent(newValue: Resource\u0026lt;ResultType\u0026gt;) } class NetworkBoundResource~ResultType, RequestType~ { +loadAsFlow:Flow\u0026lt;Resource\u0026lt;ResultType\u0026gt;\u0026gt; } class SimpleResource~ResultType~ { +loadAsFlow:Flow\u0026lt;Resource\u0026lt;ResultType\u0026gt;\u0026gt; } class SimpleResourceFlow~ResultType~ { +loadAsFlow:Flow\u0026lt;Resource\u0026lt;ResultType\u0026gt;\u0026gt; } class IFlowDataLoader~T~ { +load:Flow\u0026lt;Resource\u0026lt;T\u0026gt;\u0026gt; } class IDataLoader~T~ { +load:Resource\u0026lt;T\u0026gt; } IFlowDataStrategy\u0026lt;|--BaseFlowDataStrategy BaseFlowDataStrategy\u0026lt;|--NetworkBoundResource BaseFlowDataStrategy\u0026lt;|--SimpleResource BaseFlowDataStrategy\u0026lt;|--SimpleResourceFlow IFlowDataLoader\u0026lt;|--SimpleResourceFlow IDataLoader\u0026lt;|--SimpleResource 结构化并发,协程 optimizeofnetworkboundresource5.6.\n模块引用和数据通知 graph TB View(\u0026quot;ViewController\u0026quot;)--\u0026gt;|reference|ViewModel--\u0026gt;|reference|Repository--\u0026gt;|reference|LocalDataSource Repository(\u0026quot;DomainRepository\u0026quot;)--\u0026gt;|reference|RemoteDataSource ViewModel(\u0026quot;PageViewModel\u0026quot;)--\u0026gt;|LiveData,eq: Callback|View Repository--\u0026gt;|Flow,eq: Stream|ViewModel "
},
{
	"uri": "https://huanle19891345.github.io/en/android/jetpack/arch/%E6%9E%B6%E6%9E%84%E5%AE%9E%E7%8E%B0/%E6%9E%B6%E6%9E%84%E6%80%9D%E8%80%83%E5%92%8C%E5%AE%9E%E7%8E%B0inner/",
	"title": "架构思考和实现Inner",
	"tags": [],
	"description": "",
	"content": "分层架构 https://developer.android.com/jetpack/guide#overview\nNetworkBoundResource数据策略 https://developer.android.com/jetpack/guide#addendum\n ResueViewmodels Should I reuse view models in different views?\nI noticed that I have views that need the same information like others. But sometimes you need 5 properties of the view model and sometimes only 2.\nDo you share such view model over many views or do you create a separate view model for each view or maybe do you prefere an inheritance or composition strategy?\nFor me there are some disadvantages for sharing view models:\n Principle of Least Surprise: It is strange to fill only 2 properties of 5 of a view model and get null reference exception, because you don\u0026rsquo;t want to query additional data of the database. When the view model has 5 properties I expect that all are filled. The exceptions prove the rule. Unused properties make the code less readable (Why is that property present if it isn\u0026rsquo;t being used?) Separation of Concerns/Single Responsibility Principle: The view model cluttered up on complex sites, because you have to suit different needs for each view. If logic is involved its getting more complex, too.Also, sometimes you may want to add extra properties in your ViewModel that are absolutely specific to your View and that you don\u0026rsquo;t need in other Views. I think it puts the burden on the view to decide which ViewModel to call and that can get confusing.  What do you think? How do you handle such circumstances?\nAnswers:\nIn the project I am working on, each view has its own ViewModel, however we also have CollectionViewModels, which are shared/referenced by multiple view models.\nThink - a list of Suppliers, that needs to be displayed in multiple screens in your application - and is bound to a variety of controls - a list box, grid view, whatever you need. Having just one ViewModel makes for simpler update/refresh logic of the list of Suppliers.\nTLDR: I would only reuse view models, if all usage cases use the ViewModel in the same way. I.e. they all use the same properties etc.\ngraph LR subgraph 合理 View1(View)--\u0026gt;|combine|PageViewModel1(\u0026quot;PageViewModel1(VOLiveData,VOLiveData,...)\u0026quot;)--\u0026gt;DomainRepositoryNew1(\u0026quot;DomainRepository1(Flow)\u0026quot;) PageViewModel1--\u0026gt;DomainRepositoryNew2(\u0026quot;DomainRepository2(Flow)\u0026quot;) PageViewModel1--\u0026gt;DomainRepositoryNew3(\u0026quot;DomainRepository3(Flow)\u0026quot;) DomainRepositoryNew1--\u0026gt;LocalDataSourceNew1(\u0026quot;LocalDataSource1\u0026quot;) DomainRepositoryNew1--\u0026gt;RemoteDataSourceNew1(\u0026quot;RemoteDataSource1\u0026quot;) end subgraph 不合理 View(View)--\u0026gt;|combine|DomainViewModel1(\u0026quot;DomainViewModel1(DTOLiveData,DTOLiveData,...)\u0026quot;)--\u0026gt;DomainRepository1(\u0026quot;DomainRepository1(Flow)\u0026quot;) View(View)--\u0026gt;|combine|DomainViewModel2(\u0026quot;DomainViewModel2(DTOLiveData,DTOLiveData,...)\u0026quot;)--\u0026gt;DomainRepository2(\u0026quot;DomainRepository2(Flow)\u0026quot;) View(View)--\u0026gt;|combine|DomainViewModel3(\u0026quot;DomainViewModel3(DTOLiveData,DTOLiveData,...)\u0026quot;)--\u0026gt;DomainRepository3(\u0026quot;DomainRepository3(Flow)\u0026quot;) DomainRepository1--\u0026gt;LocalDataSource1(\u0026quot;LocalDataSource1\u0026quot;) DomainRepository1--\u0026gt;RemoteDataSource1(\u0026quot;RemoteDataSource1\u0026quot;) end PageViewModel层内复用 graph LR PageViewModel层内复用方式--\u0026gt;UseCase(\u0026quot;类似UseCase(plaid项目)添加中间层对repository进行访问\u0026quot;) PageViewModel层内复用方式--\u0026gt;Viewmodel继承或组合,委托 PageViewModel层内复用方式--\u0026gt;interface多实现进行复用 Slicing your ViewModel with Delegates\nKotlin delegates in Android development — Part 2\nOptimizeOfNetworkBoundResource  使用Coroutine Flow替代基于MediatorLiveData的回调通知   取消回调，可读性增加，协程的异步处理更加优雅，替代了原本appExecutors的线程切换和回调 支持使用flow的各种操作符 支持更细粒度的异步任务取消，原本仅支持异步任务之间的取消(通过MediatorLiveData实现取消监听)，修改后支持协程挂起函数内部的两种不同的取消方式，参考博客中协程取消的文章    loadFromDb返回值进行Resource包裹,以支持失败等异常情况处理\n  loadFromDb太具体，改为loadFromLocal\n  异步任务封装为挂起函数，子类继承时按需选择是否需要切换线程以及选择线程类型，提升灵活性\n  另外saveCallResult不在约束为只能固定在io线程\n Use combine instead of extend, because\n Sometimes we don\u0026rsquo;t want to implement all the abstract method. Generic type can be auto inferred Wrap this class is more convenient then subClass it,Wrap NetworkBoundResource if you don\u0026rsquo;t like the callback-like usage or reuse code  the disadvantage is that if we use function parameters passed to NetworkBoundResource constructor, each function will generate a lambda class and new instance when do construct NetworkBoundResource, which can be optimize by inline keyword.\n  https://medium.com/androiddevelopers/coroutines-on-android-part-ii-getting-started-3bff117176dd\n//Wrap NetworkBoundResource if you don\u0026#39;t like the callback-like usage or reuse code return NetworkBoundResource( localDataLoader = { withContext(Dispatchers.IO) { LogUtil.logWithThread(TAG, \u0026#34;loadFromLocal begin\u0026#34;) val localResource = userLocalDataSource.login(userName) LogUtil.logWithThread(TAG, \u0026#34;loadFromLocal end\u0026#34;) localResource } }, remoteDataLoader = { //use coroutineScope {} or supervisorScope {} to get CoroutineScope which will be used to propagate parentContext  //to receive parent(viewModel) cancellation event  coroutineScope { val result1 = async(Dispatchers.IO) { LogUtil.logWithThread(TAG, \u0026#34;loadFromRemote1, this = $this\u0026#34;) userRemoteDataSource.login(userName, password) } val result2 = async(Dispatchers.IO) { LogUtil.logWithThread(TAG, \u0026#34;loadFromRemote2, this = $this\u0026#34;) userRemoteDataSource.loginWithCallbackAdapter(userName, password) } val resource1 = result1.await() val resource2 = result2.await() Resource.success(\u0026#34;${resource1.data}\\n${resource2.data}\u0026#34;) } }, saveRemoteResult = { data -\u0026gt; LogUtil.logWithThread(TAG, \u0026#34;saveRemoteResult\u0026#34;) userLocalDataSource.saveUid(userName, data) } ).loadAsFlow()   /** * async issue: * --async callback: suspendCancellableCoroutine{} + resume * -- sync : call directly * * cancelable issue: * -- io thread: suspendCancellableCoroutine{} + cont.invokeOnCancellation * -- cpu thread: coroutineScope{} + isActive */ private suspend fun loginWithCallbackAdapterInner(userName: String, password: String) = withContext(Dispatchers.IO) {//switch thread if you want  suspendCancellableCoroutine\u0026lt;Resource\u0026lt;String\u0026gt;\u0026gt; { cont -\u0026gt; LogUtil.logWithThread( UserRepository.TAG, \u0026#34;loginWithCallbackAdapterInner cont = $cont\u0026#34; ) //set cancellation handler before start sync request  //use CoroutineScope.isActive collaborative cancellation when doing cpu intensive work  cont.invokeOnCancellation { LogUtil.logWithThread(UserRepository.TAG, \u0026#34;onCancellation2 cause = $it\u0026#34;) } //sync or async callback, cancellation handler will be invoked before cont.resume,  //after continuation cancel event happened  CallbackContainer().start(object : CallbackContainer.Callback() { override fun onSuccess() { cont.resume( Resource.success(\u0026#34;Uid from remote adapter userName = $userName+ password = $password.\u0026#34;), onCancellation = { cause: Throwable -\u0026gt; }) } override fun onFailed(throwable: Throwable) { cont.resumeWithException(throwable) } }) } }   multiShots时使用Flow的callbackFlow\n应用架构指南 Common architectural principles Separation of concerns\u0026ndash;单一职责 Drive UI from a model Best practices  Avoid designating your app\u0026rsquo;s entry points—such as activities, services, and broadcast receivers—as sources of data. Create well-defined boundaries of responsibility between various modules of your app. Expose as little as possible from each module. Consider how to make each module testable in isolation. Focus on the unique core of your app so it stands out from other apps. Persist as much relevant and fresh data as possible. Assign one data source to be the single source of truth.  Single source of truth It\u0026rsquo;s common for different REST API endpoints to return the same data. For example, if our backend has another endpoint that returns a list of friends, the same user object could come from two different API endpoints, maybe even using different levels of granularity. If the UserRepository were to return the response from the Webservice request as-is, without checking for consistency, our UIs could show confusing information because the version and format of data from the repository would depend on the endpoint most recently called.\nFor this reason, our UserRepository implementation saves web service responses into the database. Changes to the database then trigger callbacks on active LiveData objects. Using this model, the database serves as the single source of truth, and other parts of the app access it using our UserRepository. Regardless of whether you use a disk cache, we recommend that your repository designate a data source as the single source of truth for the rest of your app.\nDataBinding DataBinding包中的ObservebleFile作用跟LiveData基本一致，但ObservebleFile有一个去重的效果，\n为什么很多人说DataBinding很难调试？ 经常听一些小伙伴提DataBinding不好用，原因是要在xml中写业务逻辑不好调试，对于这个观点我是持否定态度的。并不是我同意xml中写业务逻辑这一观点，我觉得碰到问题就得去解决问题，如果解决问题的路上有障碍就尽量扫清障碍，而不是一味的逃避。\n如{vm.isShow ? View.VISIBLE : View.GONE}之类的业务逻辑不写在xml放在哪好呢？关于这个问题我在上篇文章Data Mapper章节中描述的很清楚，拿到后端数据转换成本地模型(此过程会编写所有数据相关逻辑)，本地模型与设计图一一对应，不但可以将视图与后段隔离，而且可以解决xml中编写业务逻辑的问题。\nMVVM MVVM其实是前端领域一个专注于界面开发的架构模式，总共分为View、ViewModel、Repository三个模块 (需严格按照单一设计原则划分)\n View(视图层):专门做视图渲染以及UI逻辑的处理 Repository(远程): 代表远程仓库，从Repository取需要的数据 ViewModel: Repository取出的数据需暂存到ViewModel，同时将数据映射到视图层  分层固然重要，但MVVM最核心点是通过ViewModel做数据驱动UI以及双向绑定的操作用来解决数据/UI的一致性问题。\n好的架构不应该局限到某一种模式(MVC/MVP/MVVM)上，需要根据自己项目的实际情况不断添砖加瓦。如果你们的后端比较善变我建议引入Data Mapper的概念～如果你经常和同事开发同一个界面，可以试图将每一条业务逻辑封装到use case中，这样大概率可以解决Git冲突的问题..等等等等，总之只要能实实在在 提高 开发效率以及项目稳定性的架构就是好架构.\n参考 关于android架构，你是否还在生搬硬套？\nReuseViewModel的思考 废弃方案:\n (单一职责)DomainViewmodel怎样通过继承和组合实现自定义liveData数据效果，(最小知道原则)然后解决view对viewmodel  graph LR View--\u0026gt;|VO!=DTO|PageViewModel(\u0026quot;PageViewModel(VOLiveData,VOLiveData,...)\u0026quot;)--\u0026gt;|combineOrInheritedMulti|DomainViewModel View--\u0026gt;|VO==DTO|DomainViewModel(\u0026quot;DomainViewModel(DTOLiveData,DTOLiveData,...)\u0026quot;)--\u0026gt;Repository(\u0026quot;Repository(Flow)\u0026quot;)--\u0026gt;DataSource(\u0026quot;DataSource(Flow)\u0026quot;) 思考  多层之间的接口怎么约定 是否需要自动生成代码，需要的话，目标是怎样的效果  "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/",
	"title": "混合开发",
	"tags": [],
	"description": "",
	"content": "混合开发 探索总结混合开发知识\n FlutterBoost     FlutterBoost3     混合开发     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91/",
	"title": "混合开发",
	"tags": [],
	"description": "",
	"content": "Flutter和native混合开发 Binding to native C/C++ code using dart:ffi\nWriting custom platform-specific code Writing custom platform-specific code\nFlutter’s platform-specific API support does not rely on code generation, but rather on a flexible message passing style:\n The Flutter portion of the app sends messages to its host, the iOS or Android portion of the app, over a platform channel.  static const platform = const MethodChannel(\u0026#39;samples.flutter.dev/battery\u0026#39;); try { final int result = await platform.invokeMethod(\u0026#39;getBatteryLevel\u0026#39;); batteryLevel = \u0026#39;Battery level at $result% .\u0026#39;; } on PlatformException catch (e) { batteryLevel = \u0026#34;Failed to get battery level: \u0026#39;${e.message}\u0026#39;.\u0026#34;; }  The host listens on the platform channel, and receives the message. It then calls into any number of platform-specific APIs—using the native programming language—and sends a response back to the client, the Flutter portion of the app.  class MainActivity() : FlutterActivity() { private val CHANNEL = \u0026#34;samples.flutter.dev/battery\u0026#34; override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) GeneratedPluginRegistrant.registerWith(this) MethodChannel(flutterView, CHANNEL).setMethodCallHandler { call, result -\u0026gt; // Note: this method is invoked on the main thread.  if (call.method == \u0026#34;getBatteryLevel\u0026#34;) { val batteryLevel = getBatteryLevel()//android平台api调用获取  if (batteryLevel != -1) { result.success(batteryLevel) } else { result.error(\u0026#34;UNAVAILABLE\u0026#34;, \u0026#34;Battery level not available.\u0026#34;, null) } } else { result.notImplemented() } } Messages and responses are passed asynchronously, to ensure the user interface remains responsive.\nPlatform Channel用于Flutter与Native之间的消息传递，整个过程的消息与响应是异步执行，不会阻塞用户界面。Flutter引擎框架已完成桥接的通道，这样开发者只需在Native层编写定制的Android/iOS代码，即可在Dart代码中直接调用，这也就是Flutter Plugin插件的一种形式。\nSeparate platform-specific code from UI code\nIf you expect to use your platform-specific code in multiple Flutter apps, it can be useful to separate the code into a platform plugin located in a directory outside your main application. See developing packages for details.\nPublish platform-specific code as a package\nTo share your platform-specific code with other developers in the Flutter ecosystem, see publishing packages.\n google官方混合开发方案 https://github.com/flutter/flutter/wiki/Add-Flutter-to-existing-apps\n来了！Flutter混合开发专题一\n原生和Flutter交互\n//从安卓原生页面跳转到FlutterDemoActivity页面使用如下方法将routeName传递过去： Intent intent = new Intent(this, FlutterDemoActivity.class); Bundle bundle = new Bundle(); bundle.putString(\u0026#34;routeName\u0026#34;, \u0026#34;first\u0026#34;); intent.putExtras(bundle); startActivity(intent); //flutter_host_android工程的java源码包下新建一个FlutterDemoActivity类，onCreate方法中的实现如下： public static final String CHANNEL_NAME = \u0026#34;com.flutterbus/demo\u0026#34;; @Override protected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); // 获取由上一个页面传过来的routeName  String routeName = \u0026#34;\u0026#34;; Intent intent = getIntent(); if (intent != null \u0026amp;\u0026amp; intent.getExtras() != null) { routeName = intent.getExtras().getString(\u0026#34;routeName\u0026#34;); } // 根据指定routeName创建FlutterView用来展示对应dart中的Widget  FlutterView flutterView = Flutter.createView(this, this.getLifecycle(), routeName); // 创建Platform Channel用来和Flutter层进行交互  new MethodChannel(flutterView, CHANNEL_NAME).setMethodCallHandler(new MethodChannel.MethodCallHandler() { @Override public void onMethodCall(MethodCall methodCall, MethodChannel.Result result) { methodCall(methodCall, result); } }); setContentView(flutterView); } /** * 处理dart层传来的方法调用 */ private void methodCall(MethodCall call, MethodChannel.Result result) { if (call.method.equals(\u0026#34;gotoNativePage\u0026#34;)) { startActivity(new Intent(this, NativeActivity.class)); result.success(true); } else { result.notImplemented(); } } //routeName在Flutter端是如何起到作用的呢，可以看下Flutter module中dart代码: void main() =\u0026gt; runApp(_widgetForRoute(window.defaultRouteName)); Widget _widgetForRoute(String route) { switch (route) { case \u0026#39;first\u0026#39;: return MyApp(); case \u0026#39;second\u0026#39;: return MyApp(); default: return Center( child: Text(\u0026#39;Unknown route: $route\u0026#39;, textDirection: TextDirection.ltr), ); } } java中创建FlutterView时其实就是将routeName设置为window的defaultRouteName，这样在dart端运行的时候就会根据defaultRouteName来展示对应的Widget了。而上面java层我们定义了Platform Channel，这样Flutter端就可以在dart层通过MethodChannel传递消息给java层从而实现两端的交互。\nstatic final String channelName = \u0026#34;com.flutterbus/demo\u0026#34;; Future\u0026lt;Null\u0026gt; jumpToNativePage() async { MethodChannel methodChannel = MethodChannel(channelName); await methodChannel.invokeMethod(\u0026#34;gotoNativePage\u0026#34;); } 至此，安卓原生工程集成Flutter就完成了，后续我们想用Flutter实现UI界面都可以在Flutter module工程中编写，原生想跳转到指定Flutter页面设置好routeName即可，dart的main函数会根据routeName来跳转到不同的Widget。\n总结\n以上就是官方提供的混合开发方案了，这个方案有一个巨大的缺点，就是在原生和Flutter页面叠加跳转时内存不断增大，因为FlutterView和FlutterViewController每次跳转都会新建一个对象，从而Embedder层的AndroidShellHolder和FlutterEngine都会创建新对象，UI Thread、IO Thread、GPU Thread和Shell都创建新的对象，唯独共享的只有DartVM对象，但是RootIsolate也是独立的，所以Flutter页面之前的数据不能共享，这样就很难将一些全局性的公用数据保存在Flutter中，所以这套方案比较适合开发不带有共享数据的独立页面，但是页面又不能太多，因为创建的Flutter页面越多内存就会暴增，尤其是在iOS上还有内存泄露的问题。\nAdd-to-App 如果您想要体验 Add-to-App 功能，请参阅文档或浏览我们的示例项目，我们在这些项目中展示了多种集成场景。\nAdd-to-App 文档 https://flutter.dev/docs/development/add-to-app\nhttps://flutter.dev/docs/development/add-to-app/android/project-setup\nhttps://flutter.dev/docs/development/add-to-app/android/add-flutter-screen\n示例项目 https://github.com/flutter/samples/tree/master/add_to_app\nFlutterEngineCache Note: To warm up a FlutterEngine, you must execute a Dart entrypoint. Keep in mind that the moment executeDartEntrypoint() is invoked, your Dart entrypoint method begins executing. If your Dart entrypoint invokes runApp() to run a Flutter app, then your Flutter app behaves as if it were running in a window of zero size until this FlutterEngine is attached to a FlutterActivity, FlutterFragment, or FlutterView. Make sure that your app behaves appropriately between the time you warm it up and the time you display Flutter content.\nNote: When using a cached FlutterEngine, that FlutterEngine outlives any FlutterActivity or FlutterFragment that displays it. Keep in mind that Dart code begins executing as soon as you pre-warm the FlutterEngine, and continues executing after the destruction of your FlutterActivity/FlutterFragment. To stop executing and clear resources, obtain your FlutterEngine from the FlutterEngineCache and destroy the FlutterEngine with FlutterEngine.destroy().\nNote: Runtime performance isn’t the only reason that you might pre-warm and cache a FlutterEngine. A pre-warmed FlutterEngine executes Dart code independent from a FlutterActivity, which allows such a FlutterEngine to be used to execute arbitrary Dart code at any moment. Non-UI application logic can be executed in a FlutterEngine, like networking and data caching, and in background behavior within a Service or elsewhere. When using a FlutterEngine to execute behavior in the background, be sure to adhere to all Android restrictions on background execution.\n同一个engine内部切换具体显示内容的方式 By setting the initial route of the navigation channel, the associated FlutterEngine displays the desired route upon initial execution of the runApp() Dart function.\nChanging the initial route property of the navigation channel after the initial execution of runApp() has no effect. ==Developers who would like to use the same FlutterEngine between different Activitys and Fragments and switch the route between those displays need to setup a method channel and explicitly instruct their Dart code to change Navigator routes.==\n FlutterFragment // With a new FlutterEngine. val flutterFragment = FlutterFragment.withNewEngine() .initialRoute(\u0026#34;myInitialRoute/\u0026#34;) .build() Note: FlutterFragment’s initial route property has no effect when a pre-warmed FlutterEngine is used because the pre-warmed FlutterEngine already chose an initial route. The initial route can be chosen explicitly when pre-warming a FlutterEngine.\nFlutterFragment flutterFragment = FlutterFragment.withNewEngine() .dartEntrypoint(\u0026#34;mySpecialEntrypoint\u0026#34;) .build(); Note: FlutterFragment’s Dart entrypoint property has no effect when a pre-warmed FlutterEngine is used because the pre-warmed FlutterEngine already executed a Dart entrypoint. The Dart entrypoint can be chosen explicitly when pre-warming a FlutterEngine.\n https://github.com/alibaba/flutter_boost\n已开源|码上用它开始Flutter混合开发——FlutterBoost\nFlutter混合开发二-FlutterBoost使用介绍\nflutterboost1.0到2.0，我一共做了这几件事\u0026hellip;\nFlutterBoost集成  Demo同级目录创建一个Flutter module项目，取名为flutter_boost_module，将Flutter module项目引入集成到原生项目中，集成方式参考《Flutter混合开发专题一》 Flutter module项目集成FlutterBoost,在flutter_boost_module项目的pubspec.yaml文件中添加依赖插件配置dependencies:flutter_boost: ^0.0.411,配置完成后执行flutter packages get命令下载依赖插件到本地 引入FlutterBoost的安卓工程代码了，在app目录下的build.gradle中添加以下项目依赖implementation project(':flutter_boost') Flutter module项目使用FlutterBoost,在main方法中运行的rootWidget中注册页面  @override void initState() { super.initState(); FlutterBoost.singleton.registerPageBuilders({ \u0026#39;flutterbus://flutterFirstPage\u0026#39;: (pageName, params, _) { print(\u0026#34;first flutterPage params:$params\u0026#34;); ... return FirstPage(); }, \u0026#39;flutterbus://flutterSecondPage\u0026#39;: (pageName, params, _) { print(\u0026#34;second flutterPage params:$params\u0026#34;); ... return SecondPage(); }, }); FlutterBoost.handleOnStartPage(); } @override Widget build(BuildContext context) { return MaterialApp( title: \u0026#39;Flutter Boost example\u0026#39;, builder: FlutterBoost.init(), home: Container()); } 安卓原生项目中使用FlutterBoost,Flutter引擎加载及FlutterBoostPlugin初始化  public static void init(final Application app) { //此处必须启动初始化，主要是载入Flutter引擎文件  FlutterMain.startInitialization(app); FlutterBoostPlugin.init(new IPlatform() { @Override public Application getApplication() { return app; } @Override public Activity getMainActivity() { return MainActivity.sRef.get(); } @Override public boolean isDebug() { return true; } @Override public boolean startActivity(Context context, String url, int requestCode) { Debuger.log(\u0026#34;startActivity url=\u0026#34;+url); return PageRouter.openPageByUrl(context,url,requestCode); } @Override public Map getSettings() { return null; } }); } Flutter页面对应Native容器,FlutterBoost初始化完成之后，针对Flutter中的页面我们需要在原生中创建对应的Native容器，即FlutterBoost中定义的Container，可以是Activity也可以是Fragment，这里我们使用Activity实现.  FlutterBoost已经为我们实现好了Activity类型的容器BoostFlutterActivity，该类实现了IFlutterViewContainer接口，我们自定义容器时只需要继承该Activity并实现三个方法即可，其中\n  getContainerName即是容器的名称，和Flutter层注册PageBuilder相对应；\n  getContainerParams为该容器需要传递给Flutter层对应Widget的参数，页面跳转接收的参数传递给Flutter页面就是在这里处理，需要将数据包装到Map中；\n  onRegisterPlugins是为该页面注册插件；\n   页面跳转路由\n  Native页面跳转Flutter页面\n  Native页面跳转Flutter页面其实就是打开一个Flutter页面对应的Native容器，我们可以根据路由来进行跳转操作\nFlutter页面跳转Native页面  我们只需要在Flutter端使用FlutterBoost提供的方法进行跳转即可，比如我需要从FirstWidget跳转到FirstNativeActivity页面，该页面对应的url为“flutterbus://nativeFirstPage”，我们可以执行以下代码\nFlutterBoost.singleton.openPage(\u0026#34;flutterbus://nativeFirstPage\u0026#34;, { \u0026#34;query\u0026#34;: {\u0026#34;description\u0026#34;: \u0026#34;大家好，我来自First Flutter页面!!!!!!!!\u0026#34;} }); 其中query对应的值是要传递给下一个页面的参数，不需要也可以不传。\nFlutter页面跳转Flutter页面，两种方式：  FlutterBoost\nFlutterBoost.singleton.openPage(\u0026#34;flutterbus://flutterSecondPage\u0026#34;, {}); Navigator\nNavigator.of(context).push(MaterialPageRoute(builder: (context){ return SecondPage(enterType: 1,); })); 如果两种跳转方式混合使用会在页面返回时出现一定的问题，因为FlutterBoost提供了关闭当前页面的方法FlutterBoost.singleton.closePageForContext(context);，而使用Navigator跳转的话该方法是不起作用的，所以我们在Widget页面中定义了enterType来区分，默认使用FlutterBoost的跳转方式，如果使用Navigator跳转Flutter Widget页面，则需要传入enterType=1，这样在返回当前页面时使用如下方法进行处理\nvoid exitPage(BuildContext context) { if (enterType == 0) { FlutterBoost.singleton.closePageForContext(context); } else { Navigator.pop(context); } } 页面跳转的返回值问题   参考 https://github.com/alibaba-flutter/flutter-boot\nflutter-boot介绍\nFlutter Boost3.0初探\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/",
	"title": "混合编译_运行",
	"tags": [],
	"description": "",
	"content": "混合编译_运行 探索总结混合编译_运行知识\n JVM_JIT     混合编译_运行     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/%E6%B7%B7%E5%90%88%E7%BC%96%E8%AF%91_%E8%BF%90%E8%A1%8C/",
	"title": "混合编译_运行",
	"tags": [],
	"description": "",
	"content": "How ART works ART uses ahead-of-time (AOT) compilation, and starting in Android 7.0 (Nougat or N), it uses a hybrid ==combination of AOT, just-in-time (JIT) compilation, and profile-guided compilation==. The combination of all these compilation modes is ==configurable== and will be discussed in this section. As an example, Pixel devices are configured with the following compilation flow:\n An application is initially installed without any AOT compilation. The first few times the application runs, it will be ==interpreted, and methods frequently executed will be JIT compiled==. When the device is idle and charging, ==a compilation daemon runs to AOT-compile frequently used code based on a profile generated during the first runs==. The next restart of an application will use the ==profile-guided code and avoid doing JIT compilation at runtime for methods already compiled. Methods that get JIT-compiled during the new runs will be added to the profile, which will then be picked up by the compilation daemon==.  JIT和AOT共存\n 应用在安装的时候dex不会再被编译 App运行时,dex文件先通过解析器被直接执行，热点函数会被识别并被JIT编译后存储在 jit code cache 中并生成profile文件以记录热点函数的信息。以供AOT编译时生成机器码 手机进入 IDLE（空闲） 或者 Charging（充电） 状态的时候，系统会扫描 App 目录下的 profile 文件并执行 AOT 过程进行编译。  ART comprises a compiler (the dex2oat tool) and a runtime (libart.so) that is loaded for starting the Zygote. The dex2oat tool takes an APK file and generates one or more compilation artifact files that the runtime loads. The number of files, their extensions, and names are subject to change across releases, but as of the Android O release, the files being generated are:\n .vdex: contains the uncompressed DEX code of the APK, with some additional metadata to speed up verification. .odex: contains AOT compiled code for methods in the APK. .art (optional): contains ART internal representations of some strings and classes listed in the APK, used to speed application startup.  Compilation options Compilation options for ART are of two categories:\n System ROM configuration: what code gets AOT-compiled when building a system image. Runtime configuration: how ART compiles and runs ==applications== on a device.  One core ART option to configure these two categories is compiler filters. Compiler filters drive how ART compiles DEX code and is an option passed to the dex2oat tool. Starting in Android O, there are four officially supported filters:\n verify: only run DEX code verification. quicken: run DEX code verification and optimize some DEX instructions to get better interpreter performance. speed: run DEX code verification and AOT-compile all methods. speed-profile: run DEX code verification and AOT-compile methods listed in a profile file.  Runtime configuration Jit options Package manager options Dex2oat options Implementing ART Just-In-Time (JIT) Compiler https://source.android.com/devices/tech/dalvik/jit-compiler\nAndroid runtime (ART) includes a just-in-time (JIT) compiler with code profiling that continually improves the performance of Android applications as they run. ==The JIT compiler complements ART\u0026rsquo;s current ahead-of-time (AOT) compiler and improves runtime performance, saves storage space, and speeds application and system updates.== It also improves upon the AOT compiler by avoiding system slowdown during automatic application updates or recompilation of applications during over-the-air (OTA) updates.\nAlthough JIT and AOT use the same compiler with a similar set of optimizations, the generated code might not be identical. ==JIT makes use of runtime type information, can do better inlining, and makes on stack replacement (OSR) compilation possible==, all of which generates slightly different code.\nJIT architecture Figure 1. JIT architecture.\nJIT compilation JIT compilation involves the following activities:\nFigure 2. Profile-guided compilation.\n The user runs the app, which then triggers ART to load the .dex file.   If the .oat file (the AOT binary for the .dex file) is available, ART uses it directly. Although .oat files are generated regularly, they don\u0026rsquo;t always contain compiled code (AOT binary). If the .oat file does not contain compiled code, ART runs through JIT and the interpreter to execute the .dex file.  JIT is enabled for any application that is not compiled according to the speed compilation filter (which says \u0026ldquo;compile as much as you can from the app\u0026rdquo;). The JIT profile data is dumped to a file in a system directory that only the application can access. The AOT compilation (dex2oat) daemon parses that file to drive its compilation.  JIT workflow  华为公布的方舟编译器到底对安卓软件生态会有多大影响？\nAndroid 平台的绝大多数应用是使用 Java 语言写的，CPU 只能理解汇编指令，无法直接识别 Java语言的虚拟机指令；为了让 CPU 能运行 Java语言编写的程序，一般有两种办法：\n  「计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决」引入一个中间层，这个中间层负责 Java代码的执行，然后这个中间层本身编译为 ==CPU 能理解的汇编指令==，也就是 CPU -\u0026gt; 中间层 -\u0026gt; Java 代码。如果这个中间层采用 Java 语言直接作为输入，理解一句 Java 语句就把Java语言翻译一下让CPU 执行一段，我们一般称这种模式为「解释执行」。毋庸置疑这种方式效率是相当低效的。\n  直接把 Java 语言翻译成==CPU能理解的机器语言==。这里又有两种方式： 在程序运行之前直接把 Java 代码编译为机器语言。这种模式我们称之为 AOT （Ahead of time）编译。 在程序运行起来之后，实时地把 Java 语言编译为机器语言然后执行。这种模式称之为 JIT（Just in time） 编译。\n  背景介绍完了回到 Android 平台上面，Android 平台分为几个阶段：\n 在 Android 5.0 正式采用 ART 之前，Android 采用的是 解释执行 + 辣鸡 JIT 的方式执行 Java代码。在这个阶段是货真价实的「边解释边执行」的模式，代码效率相当低下，再加上那时候同样辣鸡的 GC （垃圾回收），Android 用起来真是惨不忍睹。 Android 5.0 ～ Android 6.0 。Google 推出了 ART （Android Runtime）来解决之前的 Java 代码执行效率问题。这个阶段采用的是完全 AOT 模式；Android 应用在安装的时候，系统会把所有Java代码提前编译为机器码。这种模式有两个缺点不能忍：   安装速度巨慢。即使是现在吊炸天的 855 采用 AOT 模式编译一下安装包比较大的应用（如支付宝）可能就要一分钟。那个时候的 CPU 可不如现在，安装一个应用都让你等得头皮发麻。更要命的时候，系统 OTA 开机会对所有的应用执行 AOT 操作，这时候你的开机速度可能要半个小时。。。 占用磁盘空间，Java 代码编译为机器码之后体积会急剧膨胀。  Android 7.0 ～ 现在。Google做了很大的改进，基于这样一个事实：我们使用一个应用的时候，基本每个人只使用它一小部分功能，为什么要把所有代码全编译呢？只编译你经常用的那部分代码不就 OK 了，这样安装的时候啥也不干速度飞快，等你用的时候系统就能知道哪部分代码经常被执行，把这部分代码编译为机器码，运行起来速度也快。于是 Google 又引入了 JIT，这时候的执行模式是 AOT + JIT + 解释执行。    应用安装的时候不执行 AOT 编译，安装速度飞快。初次使用应用的时候没有机器码，因此只能解释执行。\n  应用运行起来之后，系统收集经常被运行的代码的信息，做两件事：1）在必要的时候在运行时直接把 Java 代码编译为机器码 （JIT），然后使用机器码执行提高运行效率。2）把这个「经常被运行的代码信息保存起来」\n  设备空闲的时候，系统拿出应用运行时候保存的「热点代码信息」直接把这些代码编译为机器码 （AOT）\n  关于 Android 7.0 系统的演进可以参阅这里：http://s3.amazonaws.com/connect.linaro.org/las16/Presentations/Tuesday/LAS16-201%20-%20ART%20JIT%20in%20Android%20N.pdf\n  8.0上改进了解释器，解释模式执行效率大幅提升；\nAndroid 9.0上提供了预先放置热点代码的方式，应用在安装的时候就能知道常用代码会被提前编译。可以看到，当前 Android 平台的执行模式在空间占用+安装速度+运行速度上已经达到了一个很好的平衡。\n 回到华为的这个方舟编译器上面，现在的 Android 是边解释边执行的吗？可以说是，也可以说不是。上面我已经提到了，现在的 Android 是 解释执行 + 还算可以的JIT + AOT 的模式。并且，你也可以手动把应用的代码全部提前编译达到完全 AOT 的效果（很多答案里面提到的 AOT 就是说的这种）；不过这属于开倒车，Google 肯定不会这么做。这样做效果有多大呢？这个我有发言权。之前在支付宝做性能优化的时候，我干过这么一回事：让应用在后台运行的时候请求系统直接采用 everything 模式编译支付宝，本地测试启动速度有爆炸性提升（30%~50%）；但是灰度测试的时候效果不明显，为什么呢？其一是后台全编译运行成功率低，其二是系统的 JIT + 后台 AOT 不是吃素的；考虑到耗电/占空间的问题压根没上线。所以如果华为只是简单地用这种方式去避免所谓的「边解释边执行」那就相当滴 low，但是按照 GPU Turbo这种黑科技来看，我觉得不太可能是这个。 除了 Android 系统的这种 AOT 之外，难道没有别的办法了吗？我不负责任地猜测一下，方舟编译器是不是在Android 应用打包成APK的时候，直接把 Java 代码编译为了机器码？注意这个跟Android系统的那个 AOT 是不样的，系统是在应用安装或者系统空闲的时候做编译；这种方式你下载到的安装包就是编译好的了，不需要系统动手。如果是第一种，辣鸡华为。如果是第二种，吊炸天！！！当然还有别的可能，不管咋样，静待开源 ：）  9102年了，还不知道android为什么卡？\nAndroid 源码分析（十） Dalvik 虚拟机创建过程\n虚拟机 理解Android虚拟机体系结构\n4.2 Dalvik类加载器 一个dex文件需要类加载器加载原生类和Java类，然后通过解释器根据指令集对Dalvik字节码进行解释和执行。Dalvik类加载器使用mmap函数，将dex文件映射到内存中，通过普通的内存读取操作即可访问dex文件，然后解析dex文件内容并加载其中的类到哈希表中。\n4.2.1 解析dex 总的来说，dex文件可以抽象为三个部分：头部、索引、数据。通过头部可以知道索引的位置和数目，以及数据区的起始位置。将dex文件映射到内存后，Dalvik会调用dexFileParse函数对其进行分析，分析的结果放到DexFile数据结构中。DexFile中的baseAddr指向映射区的起始位置，pClassDefs指向class索引的起始位置。为了加快class的查找速度，还创建一个哈希表，对class名字进行哈希并生成索引。\n4.2.2 加载class 解析工作完成后就进行class的加载，加载的类需要用ClassObject数据结构来存储。\ntypedef struct Object { ClassObject* clazz; // 类型对象  Lock lock; // 锁对象 } Object; 其中clazz指向ClassObject对象，还包含一个Lock对象。如果其它线程想要获取它的锁，只有等这个线程释放。Dalvik每加载一个class都会对应一个ClassObject对象，加载过程会在内存中分配几个区域，分别存放directMethod, virtualMethod, sfield, ifield。这些信息从dex文件的数据区中读取。字段Field的定义如下：\nstruct Field { ClassObject* clazz; //所属类型  const char* name; // 变量名称  const char* signature; // 如“Landroid/os/Debug;”  u4 accessFlags; // 访问标记  #ifdef PROFILE_FIELD_ACCESS  u4 gets; u4 puts; #endif }; 待得到class索引后，实际的加载由loadClassFromDex来完成。首先它会读取class的具体数据，分别加载directMethod, virtualMethod, ifield和sfield，然后为ClassObject数据结构分配内存，并读取dex文件的相关信息。加载完成后，将加载的class通过dvmAddClassToHash函数放入哈希表，以方便下次查找；最后，通过dvmLinkClass查找该类的超类，如果有接口类则加载相应的接口类。\n4.3 Dalvik解释器 对于任何虚拟机来说，解释器无疑是核心的部分，所有的Java字节码都经过解释器解释执行。由于Dalvik解释器的效率很重要，Android分别实现了C语言版和各种汇编语言版的解释器。解释器通常是循环执行，需要一个入口函数调用处理程序执行第一条指令，而后每条指令执行时引出下一条指令，通过函数指针调用处理程序。\n5 Android的启动 启动电源，加载引导程序到RAM BootLoader引导 Linux Kernel启动 Init进程创建 Init fork出Zygote进程，Zygote进程创建虚拟机；创建系统服务 Android Home Launcher启动 华为新贵！方舟编译器的荣光和使命\n第一个命门\nJava的“虚拟机”\n前面提到，Java为了能够实现跨平台操作，便借助虚拟机来调度硬件平台资源。在虚拟机里，还需要集成翻译器或者编译器，来将Java的字节码（即中间代码）解释成机器听得懂的机器语言，或者直接编译成机器直接执行的010101的机器码。\n2008年，Android 1.0刚发布的时候，使用的是一个叫Dalvik的虚拟机，里面集成了一个解释器，每次用户在安卓手机上运行APP时，就会叫醒这个解释器，来给安卓的硬件解释APP想要干嘛。这就相当于新闻发布会，发言人讲一句自己的母语，然后再由专业翻译将其翻译成外国记者听得懂的语言，效率非常低下，一个小时可能也问不了几个问题。\n谷歌意识到这个问题严重拖了安卓手机的后腿，所以通过一年多的努力，在2010年中发布了2.2版本，引入了JIT(Just in Time，即时编译)机制。JIT比较聪明，当用户在安卓手机运行APP时，会同时将用户经常使用的功能编译为机器能直接执行的010101机器码，不用每一句每一句的去翻译。当出现不常用的功能时，再把解释器叫起来翻译。\nJIT虽然变聪明了一点，但是每次启动APP都要先编译一次，不能一劳永逸。加上Dalvik虚拟机性能比较落后，所以谷歌在2014年10月推出了Android 5.0版本，将虚拟机从Dalvik替代成ART（Android Run Time），同时把JIT的编译器替代成AOT (Ahead of Time)。意思就是说，APP在下载后安装到手机上时同时把能编译的代码先编译成机器听得懂的101010。剩下不太好翻译的代码，就在用户使用时再叫醒解释器来翻译。AOT相比JIT的好处，就是不用每次打开APP都需要先编译一遍。但是，坏处就是用户安装APP的时间有点长。\n越来越多的用户吐槽为什么安装一个APP也慢吞吞。于是，谷歌在2017年Android 7.0又做了一点改进，安装时先不编译中间代码，而是在用户空闲时将能够编译成机器码的那部分代码，通过AOT编译器先静态编译了。如果AOT还没来得及编译或者不能编译，再叫醒JIT+解释器两个难兄难弟来顶住。这种机制，相当于用时间换空间，既缩短了用户安装APP的等待时间，又将虚拟机里编译器和解释器能做的优化提升到最大效率了。\n很多人以为华为方舟编译器就是Android 7.0的ART虚拟机，其实不然。\n无论是编译器还是解释器，只是在虚拟机上打补丁。手机上的虚拟机+编译器+解释器本身不仅占用硬件资源，还无法最大发挥软件运行性能。正因如此，所以绝大部分手机厂商只能无奈的通过简单粗暴提升安卓手机的内存和存储空间，来弥补虚拟机的弊端。\n这就是安卓的第一个命门，虚拟机先天不足。\n参考 https://source.android.com/devices/tech/dalvik/\nhttps://source.android.com/devices/tech/dalvik/configure\nUsing Profile-Guided Optimization (PGO)\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B8%B2%E6%9F%93/",
	"title": "渲染",
	"tags": [],
	"description": "",
	"content": "渲染 探索总结渲染知识\n Widget     渲染     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E6%B8%B2%E6%9F%93/%E6%B8%B2%E6%9F%93/",
	"title": "渲染",
	"tags": [],
	"description": "",
	"content": "绘制渲染 三棵树 https://flutter.dev/docs/resources/architectural-overview#layout-and-rendering\nWidget Tree，Element Tree 以及 RenderObject Tree 。根据它们的功能我将它翻译成模型树，状态树和渲染树，也正是通过这三棵树维护起了整个应用的视图数据。\n开发者通过Widget配置，Framework通过比对Widget配置来更新Element，最后调度RenderObject Tree完成布局排列和绘制。\n Widget Tree  存放属性的描述信息，更像是一个Model。同一个Widget可以同时描述多个渲染树中的节点，但是它是不可修改的，因此它只会被创建或销毁。\nWidget是为Element描述需要的配置， 负责创建Element，决定Element是否需要更新。Flutter Framework通过差分算法比对Widget树前后的变化，决定Element的State是否改变。当重建Widget树后并未发生改变， 则Element不会触发重绘，则就是Widget树的重建并不一定会触发Element树的重建。\n Element Tree  存放上下文状态信息，同时持有 Widget和RenderObject的引用。像是一个Controller控制着状态的更新(initial, mount,amount,activate,deactivate,update)。\nElement表示Widget配置树的特定位置的一个实例，同时持有Widget和RenderObject，负责管理Widget配置和RenderObject渲染。Element状态由Flutter Framework管理， 开发人员只需更改Widget即可。\n RenderObject Tree  实现了layout和paint事件，是最终渲染的View视图。\nRenderObject表示渲染树的一个对象，负责真正的渲染工作，比如测量大小、位置、绘制等都由RenderObject完成。\n渲染库（Rendering） Flutter的控件树在实际显示时会转换成对应的渲染对象（RenderObject）树来实现布局和绘制操作。渲染库主要提供的功能类有：\nabstract class RendererBinding extends BindingBase with ServicesBinding, SchedulerBinding, HitTestable { ... } abstract class RenderObject extends AbstractNode with DiagnosticableTreeMixin implements HitTestTarget { abstract class RenderBox extends RenderObject { ... } class RenderParagraph extends RenderBox { ... } class RenderImage extends RenderBox { ... } class RenderFlex extends RenderBox with ContainerRenderObjectMixin\u0026lt;RenderBox, FlexParentData\u0026gt;, RenderBoxContainerDefaultsMixin\u0026lt;RenderBox, FlexParentData\u0026gt;, DebugOverflowIndicatorMixin { ... } RendererBinding是渲染树和Flutter引擎的胶水层，负责管理帧重绘、窗口尺寸和渲染相关参数变化的监听。\nRenderObject渲染树中所有节点的基类，定义了布局、绘制和合成相关的接口。\nRenderBox和其三个常用的子类RenderParagraph、RenderImage、RenderFlex则是具体布局和绘制逻辑的实现类。\n控件树中的每个控件通过实现RenderObjectWidget#createRenderObject(BuildContext context) → RenderObject方法来创建对应的不同类型的RenderObject对象，组成渲染对象树。\n 渲染机制—UI线程 Flutter渲染机制—UI线程\u0026ndash;详细\n渲染机制—GPU线程 Flutter渲染机制—GPU线程\u0026ndash;详细\nFlutter 视图绘制\nFlutter有别于其他跨平台开发的一大特点是它自带UI组件和渲染器，而不是通过一些Bridge去做平台适配。其中自带UI组件在Flutter的Framework层而渲染器在Engine层，那么Google工程师面临的问题是如何尽可能快的（在VSync信号间隔内）完成这次传递？\nFlutter app只有在状态发生变化的时候需要触发渲染流水线。当你的app什么都不做的时候是不需要重新渲染页面的。所以，Vsync信号需要Flutter app去调度。比如我们都知道如果你的某个页面需要发生变化的时候有可能会调用State.setState()，这个调用Flutter框架最终会发起一个调度Vsync信号的请求给底层。然后底层会在Vsync信号到来的时候驱动渲染流水线开始运作，最后把新的页面显示到屏幕上。\n从UI绘制的整体流程来看,从用户的输入①到界面上动画的进度更新②，然后开始视图数据的build③，通过Layout④来确定视图的Position和Size，接下来是视图数据的Paint⑤和Composite⑥，最后是将合成后的视图数据进行\u0026quot;光栅化\u0026quot;处理使它真正的变成一个个像素填充的数据并提交给GPU。\n整个渲染流水线是运行在UI线程里的，以Vsync信号为驱动，在框架渲染完成之后会输出layer tree。 layer tree被送入engine，engine会把layer tree调度到GPU线程，在GPU线程内合成（compsite）layer tree，然后由Skia 2D渲染引擎渲染后送入GPU显示。\nFlutter只关心向 GPU提供视图数据，GPU的 VSync信号同步到 UI线程，UI线程使用 Dart来构建抽象的视图结构，这份数据结构在 GPU线程进行图层合成，视图数据提供给 Skia引擎渲染为 GPU数据，这些数据通过 OpenGL或者 Vulkan提供给 GPU。\nGPU线程通过skia向GPU硬件绘制一帧的数据，GPU将帧信息保存到FrameBuffer里面，然后视频控制器会根据VSync信号从FrameBuffer取帧数据传递给显示器，从而显示出最终的画面。\nhttps://flutter.dev/docs/resources/architectural-overview#from-user-input-to-the-gpu\nAnimate 遍历_transientCallbacks，执行动画回调方法；\nBuild 在这个阶段Flutter，在这个阶段那些需要被重新构建的Widget会在此时被重新构建。也就是我们熟悉的StatelessWidget.build()或者State.build()被调用的时候。\n对于dirty的元素会执行build构造，没有dirty元素则不会执行，对应于buildScope()\nLayout 布局的计算\n计算渲染对象的大小和位置，此时是RenderObject.performLayout()被调用的时候。\n对应于flushLayout()，这个过程可能会嵌套再调用build操作；\n因为Flutter极大地简化了布局的逻辑，所以整个布局过程中只需要深度遍历一次：\n渲染对象树中的每个对象都会在布局过程中接受父对象的Constraints参数，决定自己的大小，然后父对象就可以按照自己的逻辑决定各个子对象的位置，完成布局过程。子对象不存储自己在容器中的位置，所以在它的位置发生改变时并不需要重新布局或者绘制。子对象的位置信息存储在它自己的parentData字段中，但是该字段由它的父对象负责维护，自身并不关心该字段的内容。同时也因为这种简单的布局逻辑，Flutter可以在某些节点设置布局边界（Relayout boundary），即当边界内的任何对象发生重新布局时，不会影响边界外的对象，反之亦然：\nCompositing bits 更新具有脏合成位的任何渲染对象， 对应于flushCompositingBits()；\nPaint 将绘制命令记录到Layer， 对应于flushPaint()；\n访问需要绘制的任何渲染对象，在此阶段，渲染对象有机会将绘制命令记录到[PictureLayer]，并构建其他合成的[Layer]\n布局的绘制，此时是RenderObject.paint()被调用的时候\n布局完成后，我们开始真正的绘制。它与layout不同点在于，layout是先有child的size再有parent的size，draw是先绘制parent再child。 布局完成后，渲染对象树中的每个节点都有了明确的尺寸和位置，Flutter会把所有对象绘制到不同的图层上：\n因为绘制节点时也是深度遍历，可以看到第二个节点在绘制它的背景和前景不得不绘制在不同的图层上，因为第四个节点切换了图层（因为“4”节点是一个需要独占一个图层的内容，比如视频），而第六个节点也一起绘制到了红色图层。这样会导致第二个节点的前景（也就是“5”）部分需要重绘时，和它在逻辑上毫不相干但是处于同一图层的第六个节点也必须重绘。为了避免这种情况，Flutter提供了另外一个“重绘边界”的概念：\n在进入和走出重绘边界时，Flutter会强制切换新的图层，这样就可以避免边界内外的互相影响。典型的应用场景就是ScrollView，当滚动内容重绘时，一般情况下其他内容是不需要重绘的。虽然重绘边界可以在任何节点手动设置，但是一般不需要我们来实现，Flutter提供的控件默认会在需要设置的地方自动设置。\nFlutter框架分析（七）\u0026ndash; 绘制\n函数markNeedsPaint()首先做的是把自己的标志位_needsPaint设置为true。然后会向上查找最近的一个isRepaintBoundary为true的祖先节点。直到找到这样的节点，才会把这个节点加入到_nodesNeedingPaint列表中，也就是说，并不是任意一个需要重绘的RenderObject就会被加入这个列表，而是往上找直到找到最近的一个isRepaintBoundary为true才会放入这个列表，换句话说，这个列表里只有isRepaintBoundary为true这种类型的节点。也就是说重绘的起点是从“重绘边界”开始的。\n这里的_layer属性就是我们之前说的图层，这个属性只有绘制边界的RenderObject才会有值。一般的RenderObject这个属性是null。\nCompositing 将Compositing bits发送给GPU， 对应于compositeFrame()；\n setState更新 Flutter的setState更新原理和流程\n深入理解setState更新机制\n可见，setState()过程主要工作是记录所有的脏元素，添加到BuildOwner对象的_dirtyElements成员变量，然后调用scheduleFrame来注册Vsync回调。当下一次vsync信号的到来时会执行handleBeginFrame()和handleDrawFrame()来更新UI。\nState lifecycle\nFlutter性能优化之局部刷新 利用GlobalKey\nclass _TestWidgetState extends State\u0026lt;TestWidget\u0026gt; { int _count=0; GlobalKey\u0026lt;TextWidgetState\u0026gt; textKey = GlobalKey(); @override Widget build(BuildContext context) { return Center( child: Column( mainAxisAlignment: MainAxisAlignment.center, children: \u0026lt;Widget\u0026gt;[ TextWidget(textKey),///需要更新的Text ButtonWidget( onPressed: () { ///点击button，调用TextWidget的onPressed方法 ///在TextWidget的onPressed中单独调用TextWidget的setState， _count++; textKey.currentState.onPressed(_count); },  Flutter视图绘制(2)\u0026ndash;android绘制流程\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/tinker/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/",
	"title": "源码分析",
	"tags": [],
	"description": "",
	"content": "源码分析 探索总结源码分析知识\n Resource.arsc生成和结构     TinkerGradlePluginSource     TinkerSource     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E6%BA%90%E7%A0%81%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95/",
	"title": "源码研究方法",
	"tags": [],
	"description": "",
	"content": "源码研究方法 探索总结源码研究方法知识\n Syscall查找方式     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%83%AD%E4%BF%AE%E5%A4%8D%E5%AD%97%E8%8A%82%E7%A0%81/",
	"title": "热修复字节码",
	"tags": [],
	"description": "",
	"content": "热修复字节码 探索总结热修复字节码知识\n 1hotfixResearch     AndFix     AndFixSource     Dex文件格式     MultiDex     tinker    源码分析    Resource.arsc生成和结构     TinkerGradlePluginSource     TinkerSource       "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E7%BB%98%E5%88%B6/",
	"title": "硬件加速绘制",
	"tags": [],
	"description": "",
	"content": "硬件加速绘制 Android硬件加速过程分析\n理解Android硬件加速原理的小白文\nAndroid硬件加速原理与实现\n总结：\n CPU更擅长复杂逻辑控制，而GPU得益于大量ALU和并行结构设计，更擅长数学运算。 页面由各种基础元素（DisplayList）构成，渲染时需要进行大量浮点运算。 硬件加速条件下，CPU用于控制复杂绘制逻辑，构建或更新DisplayList；GPU用于完成图形计算，渲染DisplayList。 硬件加速条件下，刷新界面尤其是播放动画时，CPU只重建或更新必要的DisplayList，进一步提高渲染效率。   软硬件加速的区别 软硬件加速的区别主要是==图形的绘制究竟是GPU来处理还是CPU，如果是GPU==，就认为是硬件加速绘制，反之，软件绘制。\n不仅仅限定在绘制方面，绘制之前，在如何构建绘制区域上，硬件加速也做出了很大优化，因此硬件加速特性可以从下面两部分来分析：\n ==前期策略：如何构建需要绘制的区域== ==后期绘制：单独渲染线程，依赖GPU进行绘制==  无论是软件绘制还是硬件加速，==绘制内存的分配都是类似的，都是需要请求SurfaceFlinger服务分配一块内存==，只不过硬件加速有可能从FrameBuffer硬件缓冲区直接分配内存（SurfaceFlinger一直这么干的），==两者的绘制都是在APP端，绘制完成之后同样需要通知SurfaceFlinger进行合成，在这个流程上没有任何区别==，真正的区别在于在APP端如何完成UI数据绘制\n软件绘制同硬件加速的区别主要是在绘制上，内存分配、图层合成等整体流程是一样的，只不过硬件加速相比软件绘制算法更加合理，同时采用单独的渲染线程，减轻了主线程的负担。\n软件绘制跟硬件加速的分歧点 ViewRootImpl.java\nprivate void draw(boolean fullRedrawNeeded) { ... if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { //关键点1 是否开启硬件加速  if (mAttachInfo.mHardwareRenderer != null \u0026amp;\u0026amp; mAttachInfo.mHardwareRenderer.isEnabled()) { ... dirty.setEmpty(); mBlockResizeBuffer = false; //关键点2 硬件加速绘制  mAttachInfo.mHardwareRenderer.draw(mView, mAttachInfo, this); } else { ... //关键点3 软件绘制  if (!drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty)) { return; } ... 其实到这里软件绘制跟硬件加速的分歧点已经找到了，就是ViewRootImpl在draw的时候，如果需要硬件加速就利用 HardwareRenderer进行draw，否则走软件绘制流程，drawSoftware其实很简单，利用Surface.lockCanvas，向SurfaceFlinger申请一块匿名共享内存内存分配，同时获取一个普通的SkiaCanvas，用于调用Skia库，进行图形绘制，\nprivate boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty) { final Canvas canvas; try { //关键点1  canvas = mSurface.lockCanvas(dirty); .. //关键点2 绘制  mView.draw(canvas); .. //关键点3 通知SurfaceFlinger进行图层合成  surface.unlockCanvasAndPost(canvas); } ... return true; } 默认情况下Skia的绘制没有采用GPU渲染的方式（虽然Skia也能用GPU渲染），也就说默认drawSoftware工作完全由CPU来完成，不会牵扯到GPU的操作，但是8.0之后，Google逐渐加重了Skia，开始让Skia接手OpenGL，间接统一调用，将来还可能是Skia同Vulkan的结合，不过这里不是重点。重点看下HardwareRenderer所进行的硬件加速绘制。\nHardwareRenderer硬件加速绘制模型 开头说过，硬件加速绘制包括两个阶段：==构建阶段+绘制阶段==，所谓构建就是递归遍历所有视图，将需要的操作缓存下来，之后再交给单独的Render线程利用OpenGL渲染。在Android硬件加速框架中，==View视图被抽象成RenderNode节点==，==View中的绘制都会被抽象成一个个DrawOp（DisplayListOp）==，比如View中drawLine，构建中就会被抽象成一个DrawLintOp，drawBitmap操作会被抽象成DrawBitmapOp，==每个子View的绘制被抽象成DrawRenderNodeOp，每个DrawOp有对应的OpenGL绘制命令，同时内部也握着绘图所需要的数据==。如下所示：\n如此以来，==每个View不仅仅握有自己DrawOp List，同时还拿着子View的绘制入口，如此递归==，便能够统计到所有的绘制Op，很多分析都称==为Display List==，源码中也是这么来命名类的，不过这里其实更像是一个树，而不仅仅是List，示意如下：\n构建完成后，就可以==将这个绘图Op树交给Render线程进行绘制==，这里是同软件绘制很不同的地方，软件绘制时，View一般都在主线程中完成绘制，而硬件加速，除非特殊要求，一般都是在单独线程中完成绘制，如此以来就分担了主线程很多压力，提高了UI线程的响应速度。\nAndroid硬件加速（二）-RenderThread与OpenGL GPU渲染\n利用HardwareRenderer构建DrawOp集 HardwareRenderer是整个硬件加速绘制的入口，实现是一个ThreadedRenderer对象，从名字能看出，ThreadedRenderer应该跟一个Render线程息息相关，不过ThreadedRenderer是在UI线程中创建的，那么与UI线程也必定相关，其主要作用：\n ==在UI线程中完成DrawOp集构建== ==负责跟渲染线程通信==  可见ThreadedRenderer的作用是很重要的，简单看一下实现：\nThreadedRenderer(Context context, boolean translucent) { ... //新建native node  long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); //新建NativeProxy  mNativeProxy = nCreateProxy(translucent, rootNodePtr); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } 从上面代码看出，ThreadedRenderer中有一个==RootNode==用来标识整个DrawOp树的根节点，有个这个根节点就可以访问所有的绘制Op，同时还有个==RenderProxy对象，这个对象就是用来跟渲染线程进行通信的句柄==，看一下其构造函数：\nRenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()) , mContext(nullptr) { SETUP_TASK(createContext); args-\u0026gt;translucent = translucent; args-\u0026gt;rootRenderNode = rootRenderNode; args-\u0026gt;thread = \u0026amp;mRenderThread; args-\u0026gt;contextFactory = contextFactory; mContext = (CanvasContext*) postAndWait(task); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext); } 从RenderThread::getInstance()可以看出，==RenderThread是一个单例线程==，也就是说，每个进程最多只有一个硬件渲染线程，这样就不会存在多线程并发访问冲突问题。下面就接着看ThreadedRenderer的draw函数，如何构建渲染Op树：\nThreadedRenderer::draw @Override void draw(View view, AttachInfo attachInfo, HardwareDrawCallbacks callbacks) { attachInfo.mIgnoreDirtyState = true; final Choreographer choreographer = attachInfo.mViewRootImpl.mChoreographer; choreographer.mFrameInfo.markDrawStart(); //关键点1：构建View的DrawOp树  updateRootDisplayList(view, callbacks); //关键点2：通知RenderThread线程绘制  int syncResult = nSyncAndDrawFrame(mNativeProxy, frameInfo, frameInfo.length); ... } 关键点1 updateRootDisplayList，构建RootDisplayList，其实就是构建View的DrawOp树，==updateRootDisplayList会进而调用根View的updateDisplayListIfDirty，让其递归子View的updateDisplayListIfDirty，从而完成DrawOp树的创==建，简述一下流程：\nupdateRootDisplayList private void updateRootDisplayList(View view, HardwareDrawCallbacks callbacks) { updateViewTreeDisplayList(view); if (mRootNodeNeedsUpdate || !mRootNode.isValid()) { //获取DisplayListCanvas, 利用View的RenderNode获取一个DisplayListCanvas  DisplayListCanvas canvas = mRootNode.start(mSurfaceWidth, mSurfaceHeight); try { //利用canvas缓存Op, 利用DisplayListCanvas构建并缓存所有的DrawOp  final int saveCount = canvas.save(); canvas.translate(mInsetLeft, mInsetTop); callbacks.onHardwarePreDraw(canvas); canvas.insertReorderBarrier(); canvas.drawRenderNode(view.updateDisplayListIfDirty()); canvas.insertInorderBarrier(); callbacks.onHardwarePostDraw(canvas); canvas.restoreToCount(saveCount); mRootNodeNeedsUpdate = false; } finally { //将所有Op填充到RootRenderNode, 将DisplayListCanvas缓存的DrawOp填充到RenderNode  mRootNode.end(canvas); } } } View.java递归构建DrawOp @NonNull public RenderNode updateDisplayListIfDirty() { final RenderNode renderNode = mRenderNode; ... // start 获取一个 DisplayListCanvas 用于绘制 硬件加速  final DisplayListCanvas canvas = renderNode.start(width, height); try { // 是否是textureView  final HardwareLayer layer = getHardwareLayer(); if (layer != null \u0026amp;\u0026amp; layer.isValid()) { canvas.drawHardwareLayer(layer, 0, 0, mLayerPaint); } else if (layerType == LAYER_TYPE_SOFTWARE) { // 是否强制软件绘制  buildDrawingCache(true); Bitmap cache = getDrawingCache(true); if (cache != null) { canvas.drawBitmap(cache, 0, 0, mLayerPaint); } } else { // 如果仅仅是ViewGroup，并且自身不用绘制，直接递归子View  if ((mPrivateFlags \u0026amp; PFLAG_SKIP_DRAW) == PFLAG_SKIP_DRAW) { dispatchDraw(canvas); } else { //调用自己draw，如果是ViewGroup会递归子View  draw(canvas); } } } finally { //缓存构建Op  renderNode.end(canvas); setDisplayListProperties(renderNode); } } return renderNode; } ViewGroup::dispatchDraw @Override protected void dispatchDraw(Canvas canvas) { boolean usingRenderNodeProperties = canvas.isRecordingFor(mRenderNode); final int childrenCount = mChildrenCount; final View[] children = mChildren; int flags = mGroupFlags; for (int i = 0; i \u0026lt; childrenCount; i++) { final int childIndex = getAndVerifyPreorderedIndex(childrenCount, i, customOrder); final View child = getAndVerifyPreorderedView(preorderedList, children, childIndex); if ((child.mViewFlags \u0026amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) { more |= drawChild(canvas, child, drawingTime); } } } protected boolean drawChild(Canvas canvas, View child, long drawingTime) { return child.draw(canvas, this, drawingTime); } View::draw boolean draw(Canvas canvas, ViewGroup parent, long drawingTime) { boolean drawingWithRenderNode = mAttachInfo != null \u0026amp;\u0026amp; mAttachInfo.mHardwareAccelerated \u0026amp;\u0026amp; hardwareAcceleratedCanvas; if (drawingWithRenderNode) { renderNode = updateDisplayListIfDirty(); } } drawLine 假如在View onDraw中，有个drawLine，这里就会调用DisplayListCanvas的drawLine函数，DisplayListCanvas及RenderNode类图大概如下 DisplayListCanvas的drawLine函数最终会进入DisplayListCanvas.cpp的drawLine，\nvoid DisplayListCanvas::drawLines(const float* points, int count, const SkPaint\u0026amp; paint) { points = refBuffer\u0026lt;float\u0026gt;(points, count); addDrawOp(new (alloc()) DrawLinesOp(points, count, refPaint(\u0026amp;paint))); } 可以看到，这里构建了一个DrawLinesOp，并添加到DisplayListCanvas的缓存列表中去，如此递归便可以完成DrawOp树的构建，在构建后利用RenderNode的end函数，将DisplayListCanvas中的数据缓存到RenderNode中去：\npublic void end(DisplayListCanvas canvas) { canvas.onPostDraw(); long renderNodeData = canvas.finishRecording(); //将DrawOp缓存到RenderNode中去  nSetDisplayListData(mNativeRenderNode, renderNodeData); // canvas 回收掉]  canvas.recycle(); mValid = true; } RenderThread渲染UI到Graphic Buffer DrawOp树构建完毕后，UI线程利用RenderProxy向RenderThread线程发送一个DrawFrameTask任务请求，RenderThread被唤醒，开始渲染，大致流程如下：\n 首先进行DrawOp的==合并== 接着绘制特殊的Layer 最后==绘制其余所有的DrawOpList== 调用swapBuffers将前面已经绘制好的图形缓冲区提交给Surface Flinger合成和显示。  syncAndDrawFrame static int android_view_ThreadedRenderer_syncAndDrawFrame(JNIEnv* env, jobject clazz, jlong proxyPtr, jlongArray frameInfo, jint frameInfoSize) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); env-\u0026gt;GetLongArrayRegion(frameInfo, 0, frameInfoSize, proxy-\u0026gt;frameInfo()); return proxy-\u0026gt;syncAndDrawFrame(); } RenderProxy::syncAndDrawFrame int RenderProxy::syncAndDrawFrame() { return mDrawFrameTask.drawFrame(); } DrawFrameTask::drawFrame int DrawFrameTask::drawFrame() { postAndWait(); return mSyncResult; } DrawFrameTask::postAndWait void DrawFrameTask::postAndWait() { AutoMutex _lock(mLock); mRenderThread-\u0026gt;queue().post([this]() { run(); }); mSignal.wait(mLock); } DrawFrameTask::run void DrawFrameTask::run() { canUnblockUiThread = syncFrameState(info); // Grab a copy of everything we need  CanvasContext* context = mContext; // From this point on anything in \u0026#34;this\u0026#34; is *UNSAFE TO ACCESS*  if (canUnblockUiThread) { unblockUiThread(); } if (CC_LIKELY(canDrawThisFrame)) { context-\u0026gt;draw(); } else { // wait on fences so tasks don\u0026#39;t overlap next frame  context-\u0026gt;waitOnFences(); } if (!canUnblockUiThread) { unblockUiThread(); } } CanvasContext::draw void CanvasContext::draw() { mCurrentFrameInfo-\u0026gt;markIssueDrawCommandsStart(); Frame frame = mRenderPipeline-\u0026gt;getFrame(); SkRect windowDirty = computeDirtyRect(frame, \u0026amp;dirty); bool drew = mRenderPipeline-\u0026gt;draw(frame, windowDirty, dirty, mLightGeometry, \u0026amp;mLayerUpdateQueue, mContentDrawBounds, mOpaque, mWideColorGamut, mLightInfo, mRenderNodes, \u0026amp;(profiler())); bool didSwap = mRenderPipeline-\u0026gt;swapBuffers(frame, drew, windowDirty, mCurrentFrameInfo, \u0026amp;requireSwap); } 绘制内存的由来 DrawOp树的构建只是在普通的==用户内存==中，而部分数据对于SurfaceFlinger都是不可见的，之后又绘制到==共享内存==中的数据才会被SurfaceFlinger合成，之前分析过软件绘制的共享内存是来自匿名共享内存，那么硬件加速的共享内存来自何处呢？到这里可能要倒回去看看ViewRootImpl\nprivate void performTraversals() { ... if (mAttachInfo.mHardwareRenderer != null) { try { hwInitialized = mAttachInfo.mHardwareRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { mSurface.allocateBuffers(); } } catch (OutOfResourcesException e) { handleOutOfResourcesException(e); return; } } .... /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } frameworks/native/libs/gui/include/gui/Surface.h\n/* Allocates buffers based on the current dimensions/format.*/ void allocateBuffers(); frameworks/native/libs/gui/Surface.cpp\nvoid Surface::allocateBuffers() { uint32_t reqWidth = mReqWidth ? mReqWidth : mUserWidth; uint32_t reqHeight = mReqHeight ? mReqHeight : mUserHeight; mGraphicBufferProducer-\u0026gt;allocateBuffers(reqWidth, reqHeight, mReqFormat, mReqUsage); } frameworks/native/libs/gui/include/gui/IGraphicBufferProducer.h\n// Allocates buffers based on the given dimensions/format.  //  // This function will allocate up to the maximum number of buffers  // permitted by the current BufferQueue configuration. It will use the  // given format, dimensions, and usage bits, which are interpreted in the  // same way as for dequeueBuffer, and the async flag must be set the same  // way as for dequeueBuffer to ensure that the correct number of buffers are  // allocated. This is most useful to avoid an allocation delay during  // dequeueBuffer. If there are already the maximum number of buffers  // allocated, this function has no effect.  virtual void allocateBuffers(uint32_t width, uint32_t height, PixelFormat format, uint64_t usage) = 0; BufferQueueCore相关属性定义 frameworks/native/libs/gui/include/gui/BufferQueueCore.h\n// mSlots is an array of buffer slots that must be mirrored on the producer  // side. This allows buffer ownership to be transferred between the producer  // and consumer without sending a GraphicBuffer over Binder. The entire  // array is initialized to NULL at construction time, and buffers are  // allocated for a slot when requestBuffer is called with that slot\u0026#39;s index.  BufferQueueDefs::SlotsType mSlots; // mQueue is a FIFO of queued buffers used in synchronous mode.  Fifo mQueue; // mFreeSlots contains all of the slots which are FREE and do not currently  // have a buffer attached.  std::set\u0026lt;int\u0026gt; mFreeSlots; // mFreeBuffers contains all of the slots which are FREE and currently have  // a buffer attached.  std::list\u0026lt;int\u0026gt; mFreeBuffers; frameworks/native/libs/gui/include/gui/BufferQueueDefs.h\nnamespace BufferQueueDefs { typedef BufferSlot SlotsType[NUM_BUFFER_SLOTS]; } // namespace BufferQueueDefs frameworks/native/libs/ui/include/ui/BufferQueueDefs.h\nnamespace BufferQueueDefs { // BufferQueue will keep track of at most this value of buffers.  // Attempts at runtime to increase the number of buffers past this  // will fail.  static constexpr int NUM_BUFFER_SLOTS = 64; } // namespace BufferQueueDefs frameworks/native/libs/gui/include/gui/Surface.h\nstruct BufferSlot { sp\u0026lt;GraphicBuffer\u0026gt; buffer; Region dirtyRegion; }; 对于硬件加速的场景，请求SurfaceFlinger内存分配的时机会稍微提前，而不是像软件绘制，由Surface的lockCanvas发起，主要目的是：预先分配slot位置，避免在渲染的时候再申请，一是避免分配失败，浪费了CPU之前的准备工作，二是也可以将渲染线程个工作简化，减少延时。不过，还是会存在另一个问题，一个APP进程，==同一时刻会有多个Surface绘图界面，但是渲染线程只有一个，那么究竟渲染那个呢==？这个时候就需要将Surface与渲染线程（上下文）绑定。\nSurface与渲染线程（上下文）绑定 static jboolean android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;ANativeWindow\u0026gt; window = android_view_Surface_getNativeWindow(env, jsurface); return proxy-\u0026gt;initialize(window); } 首先通过android_view_Surface_getNativeWindowSurface获取Surface，在Native层,Surface对应一个ANativeWindow,接着，通过RenderProxy类的成员函数initialize将前面获得的ANativeWindow绑定到RenderThread\nbool RenderProxy::initialize(const sp\u0026lt;ANativeWindow\u0026gt;\u0026amp; window) { SETUP_TASK(initialize); args-\u0026gt;context = mContext; args-\u0026gt;window = window.get(); return (bool) postAndWait(task); } 仍旧是向渲染线程发送消息，让其绑定当前Window，其实就是调用CanvasContext的initialize函数，让绘图上下文绑定绘图内存：\nbool CanvasContext::initialize(ANativeWindow* window) { setSurface(window);//main  if (mCanvas) return false; mCanvas = new OpenGLRenderer(mRenderThread.renderState()); mCanvas-\u0026gt;initProperties(); return true; } CanvasContext通过setSurface将当前要渲染的Surface绑定到到RenderThread中，大概流程是通过eglApi获得一个EGLSurface，EGLSurface封装了一个绘图表面，进而，==通过eglApi将EGLSurface设定为当前渲染窗口==，并将绘图内存等信息进行同步，==之后通过RenderThread绘制的时候才能知道是在哪个窗口上进行绘制==。之后，再创建一个OpenGLRenderer对象，后面执行OpenGL相关操作的时候，其实就是通过OpenGLRenderer来进行的。\n合并操作和绘制 真正调用OpenGL绘制之前还有一些合并操作，这是Android硬件加速做的优化，回过头继续走draw流程，其实就是走OpenGLRenderer的drawRenderNode进行递归处理：\nvoid OpenGLRenderer::drawRenderNode(RenderNode* renderNode, Rect\u0026amp; dirty, int32_t replayFlags) { ... \u0026lt;!--构建deferredList--\u0026gt; DeferredDisplayList deferredList(mState.currentClipRect(), avoidOverdraw); DeferStateStruct deferStruct(deferredList, *this, replayFlags); \u0026lt;!--合并及分组--\u0026gt; renderNode-\u0026gt;defer(deferStruct, 0); \u0026lt;!--绘制layer--\u0026gt; flushLayers(); startFrame(); \u0026lt;!--绘制 DrawOp树--\u0026gt; deferredList.flush(*this, dirty); ... } 先看下renderNode-\u0026gt;defer(deferStruct, 0)，合并操作，DrawOp树并不是直接被绘制的，而是首先通过DeferredDisplayList进行一个合并优化，这个是Android硬件加速中采用的一种优化手段，不仅可以减少不必要的绘制，还可以将相似的绘制集中处理，提高绘制速度。\nvoid RenderNode::defer(DeferStateStruct\u0026amp; deferStruct, const int level) { DeferOperationHandler handler(deferStruct, level); issueOperations\u0026lt;DeferOperationHandler\u0026gt;(deferStruct.mRenderer, handler); } RenderNode::defer其实内含递归操作，比如，如果当前RenderNode代表DecorView，它就会递归所有的子View进行合并优化处理\n合并及优化的流程及算法，其实主要就是根据DrawOp树构建DeferedDisplayList。在合并过程中，DrawOp被分为两种：需要合的与不需要合并的，并分别缓存在不同的列表中，\n 无法合并的按照类型分别存放在Batch*mBatchLookup[kOpBatch_Count]中 可以合并的按照类型及MergeID存储到TinyHashMap\u0026lt;mergeid_t, DrawBatch*\u0026gt;mMergingBatches[kOpBatch_Count]中  合并之后，DeferredDisplayList Vector\u0026lt;Batch * \u0026gt; mBatches 包含全部整合后的绘制命令，之后渲染即可，需要注意的是这里的合并并不是多个变一个，只是做了一个集合，主要是方便使用各资源纹理等，比如绘制文字的时候，需要根据文字的纹理进行渲染，而这个时候就需要查询文字的纹理坐标系，合并到一起方便统一处理，一次渲染，减少资源加载的浪费。\n它的主要特点是==在另一个Render线程使用OpenGL进行绘制==，这个是它最重要的特点。而mBatches中所有的DrawOp都会通过OpenGL被绘制到GraphicBuffer中，最后通过swapBuffers通知SurfaceFlinger合成。\nframeworks/base/libs/hwui/renderthread/OpenGLPipeline.cpp\nOpenGLPipeline.swapBuffers bool OpenGLPipeline::swapBuffers(const Frame\u0026amp; frame, bool drew, const SkRect\u0026amp; screenDirty, FrameInfo* currentFrameInfo, bool* requireSwap) { ...... if (*requireSwap \u0026amp;\u0026amp; (CC_UNLIKELY(!mEglManager.swapBuffers(frame, screenDirty)))) { return false; } return *requireSwap; } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%80%9D%E6%83%B3/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/",
	"title": "程序设计规范",
	"tags": [],
	"description": "",
	"content": "  单一职责原则 Single Responsibility Principle\n  依赖倒置原则 Dependence Inversion Principle\n  接口隔离原则 Interface Segregation Principle\n  迪米特法则(最小知道原则)\n  合成复用原则\n  开闭原则\n  里氏替换原则 Liskov Substitution Principle\n  对于工程最佳实践的形而上的思考过程，就是：\n把工程实践中遇到的问题，从问题类型和解法类型，两个角度去归类，总结出一些有限适用的原则，就从点到了面。把诸多总结出的原则，组合应用到自己的项目代码中，就是把多个面结合起来构建了一套立体的最佳实践的方案。\n组合原则: 设计时考虑拼接组合\n吝啬原则: 除非确无它法避免, 不要编写庞大的程序\n透明性原则: 设计要可见，以便审查和调试\n通俗原则: 接口设计避免标新立异\n缄默原则: 如果一个程序没什么好说的，就沉默\n补救原则: 出现异常时，马上退出并给出足够错误信息\n 对于代码格式规范，100%严格执行，严重容不得一点沙。 文件绝不能超过 800 行，超过，一定要思考怎么拆文件。工程思维，就在于拆文件的时候积累。 函数对决不能超过 80 行，超过，一定要思考怎么拆函数，思考函数分组，层次。工程思维，就在于拆文件的时候积累。 代码嵌套层次不能超过 4 层，超过了就得改。多想想能不能 early return。工程思维，就在于拆文件的时候积累。  参考 腾讯万字Code Review规范出炉！别再乱写代码了\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A8%B3%E5%AE%9A%E6%80%A7/",
	"title": "稳定性",
	"tags": [],
	"description": "",
	"content": "稳定性 探索总结稳定性知识\n 异常    1javacrash    JavaCrashSystemHandle      anr    1ANRSystmHandle     2ANRMonitor_CollectInfo     3ANRAnalysisRootCause      nativecrash    1nativeCrash选型和整体流程     nativeCrash1SystemHandle     nativeCrash2Monitor_CollectStack     nativeCrash3SymbolRecovery     nativeCrash4AnalysisRootCause      xcrash    埋点     易观方舟       "
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/2%E7%B1%BB%E5%8A%A0%E8%BD%BD/%E7%B1%BB%E5%8A%A0%E8%BD%BD/",
	"title": "类加载",
	"tags": [],
	"description": "",
	"content": "动态加载dex和so https://alibaba.github.io/atlas/update/principle.html\nPathClassLoader自身负责主Apk的类和c库的查找路口；其parent BootClassloader负责framework sdk的内容的查找。\nPathClassLoader本身也是一个class，继承了BaseDexClassLoader（同DexClassLoader），里面查找过程在DexPathList里面实现（如下图） \u0026gt;\nDexPathList最终通过DexFile去loadClass，DexPathList可以理解为持有者DexFile以及nativeLibrary目录，再查找的时候遍历这些对象，直到找到需要的类或者c库，那么动态部署的方式就是把新修改的内容添加到这些对象的最前面，从而使得查找的过程中新修改的内容能够提前找到从而替换原有的（如下图）\nBaseDexClassLoader构造方法 private final DexPathList pathList; /** \\* Constructs an instance. \\* Note that all the *.jar and *.apk files from {@code dexPath} might be \\* first extracted in-memory before the code is loaded. This can be avoided \\* by passing raw dex files (*.dex) in the {@code dexPath}. * \\* @param dexPath the list of jar/apk files containing classes and \\* resources, delimited by {@code File.pathSeparator}, which \\* defaults to {@code \u0026#34;:\u0026#34;} on Android. \\* @param optimizedDirectory this parameter is deprecated and has no effect \\* @param librarySearchPath the list of directories containing native \\* libraries, delimited by {@code File.pathSeparator}; may be \\* {@code null} \\* @param parent the parent class loader */ public BaseDexClassLoader(String dexPath, File optimizedDirectory, String librarySearchPath, ClassLoader parent) { super(parent); this.pathList = new DexPathList(this, dexPath, librarySearchPath, null); if (reporter != null) { reporter.report(this.pathList.getDexPaths()); } } DexPathList构造方法 /** class definition context */ private final ClassLoader definingContext; /** \\* List of dex/resource (class path) elements. \\* Should be called pathElements, but the Facebook app uses reflection \\* to modify \u0026#39;dexElements\u0026#39; (http://b/7726934). */ private Element[] dexElements;//dexElements：描述defingContext ClassLoader所加载的dex文件  private final Element[] nativeLibraryPathElements; //ClassLoader除了加载类之外，加载native动态库的工作也可由它来完成。下面这个变量描述了definingContext ClassLoader可从哪几个目录中搜索目标动态库 private final List\u0026lt;File\u0026gt; nativeLibraryDirectories; /** \\* Constructs an instance. * \\* @param definingContext the context in which any as-yet unresolved \\* classes should be defined \\* @param dexPath list of dex/resource path elements, separated by \\* {@code File.pathSeparator} \\* @param librarySearchPath list of native library directory path elements, \\* separated by {@code File.pathSeparator} \\* @param optimizedDirectory directory where optimized {@code .dex} files \\* should be found and written to, or {@code null} to use the default \\* system directory for same */ public DexPathList(ClassLoader definingContext, String dexPath, String librarySearchPath, File optimizedDirectory) { // save dexPath for BaseDexClassLoader  this.dexElements = makeDexElements(splitDexPath(dexPath), optimizedDirectory, suppressedExceptions, definingContext); DexPathList.makePathElements private static Element[] makePathElements(List\u0026lt;File\u0026gt; files, File optimizedDirectory, List\u0026lt;IOException\u0026gt; suppressedExceptions) { return makeDexElements(files, optimizedDirectory, suppressedExceptions, null); /** \\* Makes an array of dex/resource path elements, one per element of \\* the given array. */ private static Element[] makeDexElements(List\u0026lt;File\u0026gt; files, File optimizedDirectory, List\u0026lt;IOException\u0026gt; suppressedExceptions, ClassLoader loader) { Element[] elements = new Element[files.size()]; int elementsPos = 0; for (File file : files) { if (name.endsWith(DEX_SUFFIX)) { // Raw dex file (not inside a zip/jar).  try { DexFile dex = loadDexFile(file, optimizedDirectory, loader, elements); if (dex != null) { elements[elementsPos++] = new Element(dex, null); } } return elements; Element构造方法 /** \\* Element of the dex/resource path. Note: should be called DexElement, but apps reflect on \\* this. */ /*package*/ static class Element { /** \\* A file denoting a zip file (in case of a resource jar or a dex jar), or a directory \\* (only when dexFile is null). */ private final File path; private final DexFile dexFile; /** \\* Element encapsulates a dex file. This may be a plain dex file (in which case dexZipPath \\* should be null), or a jar (in which case dexZipPath should denote the zip file). */ public Element(DexFile dexFile, File dexZipPath) { this.dexFile = dexFile; this.path = dexZipPath; } /** \\* Constructs a {@code DexFile} instance, as appropriate depending on whether \\* {@code optimizedDirectory} is {@code null}. An application image file may be associated with the {@code loader} if it is not null. */ private static DexFile loadDexFile(File file, File optimizedDirectory, ClassLoader loader, Element[] elements) throws IOException { if (optimizedDirectory == null) { return new DexFile(file, loader, elements); } else { String optimizedPath = optimizedPathFor(file, optimizedDirectory); return DexFile.loadDex(file.getPath(), optimizedPath, 0, loader, elements); } } DexFile.loadDex static DexFile loadDex(String sourcePathName, String outputPathName, int flags, ClassLoader loader, DexPathList.Element[] elements) throws IOException { return new DexFile(sourcePathName, outputPathName, flags, loader, elements); } DexFile构造方法 /* \\* Private version with class loader argument. * \\* @param file \\* the File object referencing the actual DEX file \\* @param loader \\* the class loader object creating the DEX file object \\* @param elements \\* the temporary dex path list elements from DexPathList.makeElements */ DexFile(File file, ClassLoader loader, DexPathList.Element[] elements) throws IOException { this(file.getPath(), loader, elements); } DexFile(String fileName, ClassLoader loader, DexPathList.Element[] elements) throws IOException { mCookie = openDexFile(fileName, null, 0, loader, elements); mInternalCookie = mCookie; mFileName = fileName; //System.out.println(\u0026#34;DEX FILE cookie is \u0026#34; + mCookie + \u0026#34; fileName=\u0026#34; + fileName);  } /* \\* Open a DEX file. The value returned is a magic VM cookie. On \\* failure, an IOException is thrown. */ private static Object openDexFile(String sourceName, String outputName, int flags, ClassLoader loader, DexPathList.Element[] elements) throws IOException { // Use absolute paths to enable the use of relative paths when testing on host.  return openDexFileNative(new File(sourceName).getAbsolutePath(), (outputName == null)? null: new File(outputName).getAbsolutePath(), flags, loader, elements); } /art/runtime/native/dalvik_system_DexFile.cc\n267static jobject DexFile_openDexFileNative(JNIEnv* env, 268 jclass, 269 jstring javaSourceName, 270 jstring javaOutputName ATTRIBUTE_UNUSED, 271 jint flags ATTRIBUTE_UNUSED, 272 jobject class_loader, 273 jobjectArray dex_elements) { ScopedUtfChars sourceName(env, javaSourceName); 279 Runtime* const runtime = Runtime::Current(); 280 ClassLinker* linker = runtime-\u0026gt;GetClassLinker(); 281 std::vector\u0026lt;std::unique_ptr\u0026lt;const DexFile\u0026gt;\u0026gt; dex_files; 282 std::vector\u0026lt;std::string\u0026gt; error_msgs; 283 const OatFile* oat_file = nullptr; //main 285 dex_files = runtime-\u0026gt;GetOatFileManager().OpenDexFilesFromOat(sourceName.c_str(), 286 class_loader, 287 dex_elements, 288 /*out*/ \u0026amp;oat_file, 289 /*out*/ \u0026amp;error_msgs); 291 if (!dex_files.empty()) { 292 jlongArray array = ConvertDexFilesToJavaArray(env, oat_file, dex_files); 293 if (array == nullptr) { 294 ScopedObjectAccess soa(env); 295 for (auto\u0026amp; dex_file : dex_files) { 296 if (linker-\u0026gt;IsDexFileRegistered(soa.Self(), *dex_file)) { 297 dex_file.release(); 298 } 299 } 300 } 301 return array; /art/runtime/oat_file_manager.h or cc\nOatFileManager::OpenDexFilesFromOat 84 // Finds or creates the oat file holding dex_location. Then loads and returns 85 // all corresponding dex files (there may be more than one dex file loaded 86 // in the case of multidex). 87 // This may return the original, unquickened dex files if the oat file could 88 // not be generated. 89 // 90 // Returns an empty vector if the dex files could not be loaded. In this 91 // case, there will be at least one error message returned describing why no 92 // dex files could not be loaded. The \u0026#39;error_msgs\u0026#39; argument must not be 93 // null, regardless of whether there is an error or not. 94 // 95 // This method should not be called with the mutator_lock_ held, because it 96 // could end up starving GC if we need to generate or relocate any oat files. 394std::vector\u0026lt;std::unique_ptr\u0026lt;const DexFile\u0026gt;\u0026gt; OatFileManager::OpenDexFilesFromOat( 395 const char* dex_location, 396 jobject class_loader, 397 jobjectArray dex_elements, 398 const OatFile** out_oat_file, 399 std::vector\u0026lt;std::string\u0026gt;* error_msgs) { 404 // Verify we aren\u0026#39;t holding the mutator lock, which could starve GC if we 405 // have to generate or relocate an oat file. 406 Thread* const self = Thread::Current(); 407 Locks::mutator_lock_-\u0026gt;AssertNotHeld(self); 408 Runtime* const runtime = Runtime::Current(); 410 std::unique_ptr\u0026lt;ClassLoaderContext\u0026gt; context; 411 // If the class_loader is null there\u0026#39;s not much we can do. This happens if a dex files is loaded 412 // directly with DexFile APIs instead of using class loaders. 413 if (class_loader == nullptr) { 416 context = nullptr; 417 } else { 418 context = ClassLoaderContext::CreateContextForClassLoader(class_loader, dex_elements); 419 } 420 421 OatFileAssistant oat_file_assistant(dex_location, 422 kRuntimeISA, 423 !runtime-\u0026gt;IsAotCompiler(), 424 only_use_system_oat_files_); 437 if (!oat_file_assistant.IsUpToDate()) { //main oat_file_assistant.MakeUpToDate(/*profile_changed*/ false, 452 actual_context, 453 /*out*/ \u0026amp;error_msg) /art/libdexfile/dex/dex_file.h\nclass DexFile 63// Dex file is the API that exposes native dex files (ordinary dex files) and CompactDex. 64// Originally, the dex file format used by ART was mostly the same as APKs. The only change was 65// quickened opcodes and layout optimizations. 66// Since ART needs to support both native dex files and CompactDex files, the DexFile interface 67// provides an abstraction to facilitate this. 68class DexFile { 83 // Raw header_item. 84 struct Header { 85 uint8_t magic_[8] = {}; 86 uint32_t checksum_ = 0; // See also location_checksum_ 87 uint8_t signature_[kSha1DigestSize] = {}; 88 uint32_t file_size_ = 0; // size of entire file 89 uint32_t header_size_ = 0; // offset to start of next section 90 uint32_t endian_tag_ = 0; 91 uint32_t link_size_ = 0; // unused 92 uint32_t link_off_ = 0; // unused 93 uint32_t map_off_ = 0; // unused 94 uint32_t string_ids_size_ = 0; // number of StringIds 95 uint32_t string_ids_off_ = 0; // file offset of StringIds array 96 uint32_t type_ids_size_ = 0; // number of TypeIds, we don\u0026#39;t support more than 65535 97 uint32_t type_ids_off_ = 0; // file offset of TypeIds array 98 uint32_t proto_ids_size_ = 0; // number of ProtoIds, we don\u0026#39;t support more than 65535 99 uint32_t proto_ids_off_ = 0; // file offset of ProtoIds array 100 uint32_t field_ids_size_ = 0; // number of FieldIds 101 uint32_t field_ids_off_ = 0; // file offset of FieldIds array 102 uint32_t method_ids_size_ = 0; // number of MethodIds 103 uint32_t method_ids_off_ = 0; // file offset of MethodIds array 104 uint32_t class_defs_size_ = 0; // number of ClassDefs 105 uint32_t class_defs_off_ = 0; // file offset of ClassDef array 106 uint32_t data_size_ = 0; // size of data section 107 uint32_t data_off_ = 0; // file offset of data section 108 109 // Decode the dex magic version 110 uint32_t GetVersion() const; 111 }; /art/runtime/oat_file_assistant.cc\nOatFileAssistant::MakeUpToDate 251OatFileAssistant::MakeUpToDate(bool profile_changed, 252 ClassLoaderContext* class_loader_context, 253 std::string* error_msg) { 262 OatFileInfo\u0026amp; info = GetBestInfo(); 273 switch (info.GetDexOptNeeded( 274 target, profile_changed, /*downgrade*/ false, class_loader_context)) { 275 case kNoDexOptNeeded: 276 return kUpdateSucceeded; 277 278 // TODO: For now, don\u0026#39;t bother with all the different ways we can call 279 // dex2oat to generate the oat file. Always generate the oat file as if it 280 // were kDex2OatFromScratch. 281 case kDex2OatFromScratch: 282 case kDex2OatForBootImage: 283 case kDex2OatForRelocation: 284 case kDex2OatForFilter: 285 return GenerateOatFileNoChecks(info, target, class_loader_context, error_msg); 286 } OatFileAssistant::GenerateOatFileNoChecks 698OatFileAssistant::ResultOfAttemptToUpdate OatFileAssistant::GenerateOatFileNoChecks( 699 OatFileAssistant::OatFileInfo\u0026amp; info, 700 CompilerFilter::Filter filter, 701 const ClassLoaderContext* class_loader_context, 702 std::string* error_msg) { 717 const std::string\u0026amp; oat_file_name = *info.Filename(); 718 const std::string\u0026amp; vdex_file_name = GetVdexFilename(oat_file_name); 43 Dex2oatFileWrapper vdex_file_wrapper(OS::CreateEmptyFile(vdex_file_name.c_str())); 744 File* vdex_file = vdex_file_wrapper.GetFile(); 759 Dex2oatFileWrapper oat_file_wrapper(OS::CreateEmptyFile(oat_file_name.c_str())); 760 File* oat_file = oat_file_wrapper.GetFile(); 773 std::vector\u0026lt;std::string\u0026gt; args; 774 args.push_back(\u0026#34;--dex-file=\u0026#34; + dex_location_); 775 args.push_back(\u0026#34;--output-vdex-fd=\u0026#34; + std::to_string(vdex_file-\u0026gt;Fd())); 776 args.push_back(\u0026#34;--oat-fd=\u0026#34; + std::to_string(oat_file-\u0026gt;Fd())); 777 args.push_back(\u0026#34;--oat-location=\u0026#34; + oat_file_name); 778 args.push_back(\u0026#34;--compiler-filter=\u0026#34; + CompilerFilter::NameOfFilter(filter)); 779 const std::string dex2oat_context = class_loader_context == nullptr 780 ? OatFile::kSpecialSharedLibrary 781 : class_loader_context-\u0026gt;EncodeContextForDex2oat(/*base_dir*/ \u0026#34;\u0026#34;); 782 args.push_back(\u0026#34;--class-loader-context=\u0026#34; + dex2oat_context); 784 if (!Dex2Oat(args, error_msg)) {//main 785 return kUpdateFailed; 786 } 787 788 if (vdex_file-\u0026gt;FlushCloseOrErase() != 0) { 789 *error_msg = \u0026#34;Unable to close vdex file \u0026#34; + vdex_file_name; 790 return kUpdateFailed; 791 } 792 793 if (oat_file-\u0026gt;FlushCloseOrErase() != 0) { 794 *error_msg = \u0026#34;Unable to close oat file \u0026#34; + oat_file_name; 795 return kUpdateFailed; 796 } 804 return kUpdateSucceeded; OatFileAssistant::Dex2Oat 807bool OatFileAssistant::Dex2Oat(const std::vector\u0026lt;std::string\u0026gt;\u0026amp; args, 808 std::string* error_msg) { 816 std::vector\u0026lt;std::string\u0026gt; argv; 817 argv.push_back(runtime-\u0026gt;GetCompilerExecutable()); 849 argv.insert(argv.end(), args.begin(), args.end()); 850 851 std::string command_line(android::base::Join(argv, \u0026#39; \u0026#39;)); 852 return Exec(argv, error_msg); /art/runtime/runtime.h\n723std::string Runtime::GetCompilerExecutable() const { 724 if (!compiler_executable_.empty()) { 725 return compiler_executable_; 726 } 727 std::string compiler_executable(GetAndroidRoot()); //getenv(\u0026#34;ANDROID_ROOT\u0026#34;) 728 compiler_executable += (kIsDebugBuild ? \u0026#34;/bin/dex2oatd\u0026#34; : \u0026#34;/bin/dex2oat\u0026#34;); //位于设备system/bin/dex2oat 729 return compiler_executable; 730} /art/dex2oat/dex2oat.cc\n3176int main(int argc, char** argv) { 3177 int result = static_cast\u0026lt;int\u0026gt;(art::Dex2oat(argc, argv)); 3184 return result; 3185} 具体参考类编译原理\nclassLoader.loadClass 方法调用时机 对于APPComponentFactory子类，LoadedApk进行调用 对于application和四大组件由instrumentation调用APPComponentFactory进行调用 对于view，由LayoutInflator在createView方法中进行调用 对于其他自定义类，由jvm进行调用 Class objects for array classes are not created by class loaders, but are created automatically as required by the Java runtime. The class loader for an array class, as returned by Class#getClassLoader() is the same as the class loader for its element type; if the element type is a primitive type, then the array class has no class loader.\nprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { // First, check if the class has already been loaded  Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found  // from the non-null parent class loader  } if (c == null) { // If still not found, then invoke findClass in order  // to find the class.  c = findClass(name);//main  } } return c; @Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { return Class.classForName(name, false, null); } /** Called after security checks have been made. */ @FastNative static native Class\u0026lt;?\u0026gt; classForName(String className, boolean shouldInitialize, ClassLoader classLoader) throws ClassNotFoundException; BootClassLoader.findClass class BootClassLoader extends ClassLoader { //BootClassLoader采用了单例构造的方式。所以一个Java进程只存在一个BootClassLoader对象  private static BootClassLoader instance; //Loader没有可委托的其他加载器了。  public BootClassLoader() { super(null); } //加载目标类，下文将分析其代码。  protected Class\u0026lt;?\u0026gt; findClass(String name) ... { return Class.classForName(name, false, null); } } art/runtime/native/java_lang_Class.cc\n// \u0026#34;name\u0026#34; is in \u0026#34;binary name\u0026#34; format, e.g. \u0026#34;dalvik.system.Debug$1\u0026#34;. static jclass Class_classForName(JNIEnv* env, jclass, jstring javaName, jboolean initialize,jobject javaLoader) { //注意传入的参数，javaName为JLS规范里定义的类名（如java.lang.String），  //initialize为false，javaLoader为false  ScopedFastNativeObjectAccess soa(env); ScopedUtfChars name(env, javaName); ...... //转成JVM规范使用的类名，如Ljava/lang/String;  std::string descriptor(DotToDescriptor(name.c_str())); StackHandleScope\u0026lt;2\u0026gt; hs(soa.Self()); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle( soa.Decode\u0026lt;mirror::ClassLoader*\u0026gt;(javaLoader))); ClassLinker* class_linker = Runtime::Current()-\u0026gt;GetClassLinker(); Handle\u0026lt;mirror::Class\u0026gt; c( hs.NewHandle(class_linker-\u0026gt;FindClass(soa.Self(),//main  descriptor.c_str(), class_loader))); ...... if (initialize) { //initialize为false的话，将只加载和链接目标类，不初始化它  class_linker-\u0026gt;EnsureInitialized(soa.Self(), c, true, true); } return soa.AddLocalReference\u0026lt;jclass\u0026gt;(c.Get()); } BaseDexClassLoader.findClass @Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { List\u0026lt;Throwable\u0026gt; suppressedExceptions = new ArrayList\u0026lt;Throwable\u0026gt;(); Class c = pathList.findClass(name, suppressedExceptions); return c; DexPathList.findClass /** \\* Finds the named class in one of the dex files pointed at by \\* this instance. This will find the one in the earliest listed \\* path element. If the class is found but has not yet been \\* defined, then this method will define it in the defining \\* context that this instance was constructed with. * \\* @param name of class to find \\* @param suppressed exceptions encountered whilst finding the class \\* @return the named class or {@code null} if the class is not \\* found in any of the dex files */ public Class\u0026lt;?\u0026gt; findClass(String name, List\u0026lt;Throwable\u0026gt; suppressed) { for (Element element : dexElements) { Class\u0026lt;?\u0026gt; clazz = element.findClass(name, definingContext, suppressed); if (clazz != null) { return clazz; } } public Class\u0026lt;?\u0026gt; findClass(String name, ClassLoader definingContext, List\u0026lt;Throwable\u0026gt; suppressed) { return dexFile != null ? dexFile.loadClassBinaryName(name, definingContext, suppressed) : null; } /libcore/dalvik/src/main/java/dalvik/system/DexFile.java\nDexFile.defineClass /** \\* See {@link #loadClass(String, ClassLoader)}. \\* This takes a \u0026#34;binary\u0026#34; class name to better match ClassLoader semantics. */ public Class loadClassBinaryName(String name, ClassLoader loader, List\u0026lt;Throwable\u0026gt; suppressed) { return defineClass(name, loader, mCookie, this, suppressed); } private static Class defineClass(String name, ClassLoader loader, Object cookie, DexFile dexFile, List\u0026lt;Throwable\u0026gt; suppressed) { Class result = null; try { result = defineClassNative(name, loader, cookie, dexFile); art/runtime/native/dalvik_system_DexFile.cc\nstatic jclass DexFile_defineClassNative(JNIEnv* env, jclass, jstring javaName, jobject javaLoader, jobject cookie, jobject dexFile) { ObjPtr\u0026lt;mirror::Class\u0026gt; result = class_linker-\u0026gt;DefineClass(soa.Self(), descriptor.c_str(), hash, class_loader, *dex_file, *dex_class_def); // Add the used dex file. This only required for the DexFile.loadClass API since normal  // class loaders already keep their dex files live.  class_linker-\u0026gt;InsertDexFileInToClassLoader(soa.Decode\u0026lt;mirror::Object\u0026gt;(dexFile), class_loader.Get()); PathClassLoader和DexClassLoader区别 两种ClassLoader区别在于DexClassLoader可以加载外置卡中的apk，而PathClassLoader用于加载已安装的apk，构造参数里只有优化路径的参数差异，PathClassLoader传入的是null，而DexClassLoader是可以传入的，这个差异最终是在oat_file_assistant.cc这个文件里的MakeUpToDate方法中进行判断处理，如果noDexOptNeeded(已安装apk)则直接返回，否则(未安装的apk)会进行Dex2Oat过程，这个过程需要这个优化路径，否则无法加载\n总结 https://www.jianshu.com/p/2216554d3291\nBaseDexClassLoader 的构造函数中创建一个DexPathList实例，DexPathList的构造函数会创建一个dexElements 数组\nBaseDexClassLoader 在findclass方法中调用了pathList.findClass，这个方法中会遍历dexpathlist中的dexElements数组，如果DexFile不为空那么调用DexFile类的loadClassBinaryName方法返回Class实例。\nTinker进行热修复的流程为：\n新dex与旧dex通过dex差分算法生成差异包 patch.dex\n将patch dex下发到客户端，客户端将patch dex与旧dex合成为新的全量dex\n将合成后的全量dex 插入到dex elements前面(此部分和QQ空间机制类似)，完成修复\n可见，Tinker和QQ空间方案最大的不同是，Tinker 下发新旧DEX的差异包，然后将差异包和旧包合成新dex之后进行dex的全量替换，这样也就避免了QQ空间中的插桩操作。\nhttps://blog.csdn.net/u010386612/article/details/51077291\nhttp://gityuan.com/2017/03/19/android-classloader/\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/art/2%E7%B1%BB%E5%8A%A0%E8%BD%BD/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%B1%82/",
	"title": "类加载虚拟机层",
	"tags": [],
	"description": "",
	"content": "Flow load class trigger flow graph TB EnsureInitialized--\u0026gt;InitializeClass InitializeClass--\u0026gt;MethodVerifier::VerifyClass MethodVerifier::VerifyClass--\u0026gt;MethodVerifier::VerifyMethods MethodVerifier::VerifyMethods--\u0026gt;MethodVerifier::VerifyMethod MethodVerifier::VerifyMethod--\u0026gt;MethodVerifier::CodeFlowVerifyInstruction MethodVerifier::CodeFlowVerifyInstruction--\u0026gt;ResolveType MethodVerifier::VerifyMethod--\u0026gt;ResolveType ResolveType--\u0026gt;FindClass FindClass--\u0026gt;DefineClass ClassLinkerSummary ClassLinker中其他一些常见函数。包括：\n·Resolve相关函数。虽然名称叫Resolve，但在ART代码里，它并非是图8-5类加载、链接和初始化阶段中提到的Resolve。相反，它甚至可能触发一个类的加载和链接流程。\n·FindClass：根据类的字符串名称搜索一个类。如果没有的话，则可能触发类的加载和链接流程。\ngraph LR ResolveMethod--\u0026gt;ResolveType ResolveField--\u0026gt;ResolveType ResolveType--\u0026gt;FindClass FindClass--\u0026gt;FindClassInBaseDexClassLoader--\u0026gt;FindClassInBaseDexClassLoaderClassPath--\u0026gt;DefineClass ResolveMethod template \u0026lt;ClassLinker::ResolveMode kResolveMode\u0026gt; ArtMethod* ClassLinker::ResolveMethod(const DexFile\u0026amp; dex_file, uint32_t method_idx, Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, ArtMethod* referrer, InvokeType type) { //和ResolveType类似，首先判断dex_cache中是否已经解析过这个方法了。  ArtMethod* resolved = dex_cache-\u0026gt;GetResolvedMethod(method_idx, image_pointer_size_); if (resolved != nullptr \u0026amp;\u0026amp; !resolved-\u0026gt;IsRuntimeMethod()) { if (kResolveMode == ClassLinker::kForceICCECheck) { //Java有诸如1.5、1.6这样的版本，在早期Java版本里，有些信息和现在的版本有差异，  //此处将检查是否有信息不兼容的地方（即check incompatible class change），  //如果检查失败，则会设置一个IncompatibleClassChangeError异常，笔者此处不拟讨论。  if (resolved-\u0026gt;CheckIncompatibleClassChange(type)) { ...... //设置异常  return nullptr; } } return resolved; } } // 如果dex_cache里并未缓存，则先解析该方法所在类的类型（由method_id.class_idx_表示）。  const DexFile::MethodId\u0026amp; method_id = dex_file.GetMethodId(method_idx); mirror::Class* klass = ResolveType(dex_file, method_id.class_idx_, dex_cache, class_loader);//main  ...... switch (type) { //type是指该函数的调用类型  case kDirect: case kStatic: /*FindDirectMethod是mirror Class的成员函数，有三个同名函数。在此处调用的函数中， 将沿着klass向上（即搜索klass的父类、祖父类等）搜索类所声明的direct方法，然后比较 这些方法的method_idx是否和输入的method_idx一样。如果一样，则认为找到目标函数。注 意，使用这种方法的时候需要注意比较method_idx是否相等时只有在二者保存在同一个DexCache 对象时才有意义。显然，这种一种优化搜索方法。 */ resolved = klass-\u0026gt;FindDirectMethod(dex_cache.Get(), method_idx, image_pointer_size_); break; case kInterface: if (UNLIKELY(!klass-\u0026gt;IsInterface())) { return nullptr; } else { //如果调用方式是kInterface，则搜索klass及祖父类中的virtual方法以及所  //实现的接口类里的成员方法。  resolved = klass-\u0026gt;FindInterfaceMethod(dex_cache.Get(), method_idx, image_pointer_size_); } break; ...... //其他处理  break; default: UNREACHABLE(); } //如果通过method_idx未找到对应的ArtMethod对象，则尝试通过函数名及签名信息再次搜索。  //通过签名信息来查找匹配函数的话就不会受制于同一个DexCache对象的要求，但比较字符串的  //速度会慢于上面所采用的比较整型变量method_idx的处理方式。  if (resolved == nullptr) { //name是指函数名  const char* name = dex_file.StringDataByIdx(method_id.name_idx_); //signature包含了函数的签名信息，就是函数参数及返回值的类型信息  const Signature signature = dex_file.GetMethodSignature(method_id); switch (type) { case kDirect: case kStatic: //调用另外一个FindDirectMethod，主要参数是signature  resolved = klass-\u0026gt;FindDirectMethod(name, signature, image_pointer_size_); break; ...... } } if (LIKELY(resolved != nullptr \u0026amp;\u0026amp; !resolved-\u0026gt;CheckIncompatibleClassChange(type))) { //如果找到这个方法，则将其存到dex_cache对象中，以method_idx为索引，存储在它的resolved_methods_成员中  dex_cache-\u0026gt;SetResolvedMethod(method_idx, resolved, image_pointer_size_); return resolved; } else { ....../*其他处理 */ } } ResolveField ArtField* ClassLinker::ResolveField(const DexFile\u0026amp; dex_file, uint32_t field_idx,Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader,bool is_static) { //如果已经解析过该成员变量，则返回  ArtField* resolved = dex_cache-\u0026gt;GetResolvedField(field_idx, image_pointer_size_); if (resolved != nullptr) { return resolved; } const DexFile::FieldId\u0026amp; field_id = dex_file.GetFieldId(field_idx); Thread* const self = Thread::Current(); StackHandleScope\u0026lt;1\u0026gt; hs(self); //先找到该成员变量对应的Class对象  Handle\u0026lt;mirror::Class\u0026gt; klass( hs.NewHandle(ResolveType(dex_file, field_id.class_idx_, dex_cache, class_loader))); ..... //下面这段代码用于从Class对象ifields_或sfields_中找到对应成员变量的ArtField对象。注  //意，在搜索过程中，会向上遍历Class派生关系树上的基类。  if (is_static) { resolved = mirror::Class::FindStaticField(self, klass,dex_cache.Get(), field_idx); } else { resolved = klass-\u0026gt;FindInstanceField(dex_cache.Get(), field_idx); } ...... //保存到DexCache resolved_fields_成员变量中  dex_cache-\u0026gt;SetResolvedField(field_idx, resolved, image_pointer_size_); return resolved; } ResolveType mirror::Class* ClassLinker::ResolveType(const DexFile\u0026amp; dex_file, uint16_t type_idx,......) { /*dex_cache的类型为mirror::DexCache，这里直接回顾本章上文对DexCache类的介绍。 它包含如下几个关键成员变量： （1）dex_file_(类型为uint64_t)：实际为DexFile*，指向该对象关联的那个Dex文件。 （2）resolved_fields_(uint64_t)：实际为ArtField*，指向ArtField数组，成员的数据类 型为ArtField。该数组存储了一个Dex文件中定义的所有类的成员变量。另外，只有那些经解 析后得到的ArtField对象才会存到这个数组里。该字段和Dex文件里的field_ids数组有关。 （3）resolved_methods_(uint64_t)：实际为ArtMethod*，指向ArtMethod数组，成员的 数据类型为ArtMethod。该数组存储了一个Dex文件中定义的所有类的成员函数。另外，只有 那些经解析后得到的ArtMethod对象才会存到这个数组里。该字段和Dex文件里的 method_ids数组有关。 （4）resolved_string_(uint64_t)：实际为GCRoot\u0026lt;String\u0026gt;*，指向GcRoot\u0026lt;String\u0026gt;数 组，包括该dex文件里使用的字符串信息数组。String是mirror::String。该字段和Dex 文件的string_ids数组有关 （5）resolved_classes_(uint64_t)：实际为GCRoot\u0026lt;Class\u0026gt;*，指向GcRoot\u0026lt;Class\u0026gt;数组，成 员的数据类型为GcRoot\u0026lt;Class\u0026gt;，存储该dex文件里使用的数据类型信息数组。该字段和Dex 文件里的type_ids数组有关 */ //从dex_cache里找到是否已经缓存过type_idx所代表的那个Class信息  mirror::Class* resolved = dex_cache-\u0026gt;GetResolvedType(type_idx); if (resolved == nullptr) { //如果没有缓存过，则需要找到并存起来  Thread* self = Thread::Current(); //找到这个type的字符串描述  const char* descriptor = dex_file.StringByTypeIdx(type_idx); //搜索这个字符串对应的类是否存在。FindClass在第7章中曾简单介绍过，后文还会详细讨论它  resolved = FindClass(self, descriptor, class_loader);//main  if (resolved != nullptr) { //类信息保存到DexCache对象中  dex_cache-\u0026gt;SetResolvedType(type_idx, resolved); } else { ...... //抛NoClassDefFoundError异常  ThrowNoClassDefFoundError(\u0026#34;Failed resolution of: %s\u0026#34;, descriptor); } return resolved; } FindClass mirror::Class* ClassLinker::FindClass(Thread* self, const char* descriptor, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { //如果字符串只有一个字符，则将搜索基础数据类对应的Class对象  if (descriptor[1] == \u0026#39;\\0\u0026#39;) { // only the descriptors of primitive types should be 1 character long, also avoid class lookup  // for primitive classes that aren\u0026#39;t backed by dex files.  return FindPrimitiveClass(descriptor[0]); } //搜索引用类型对应的类对象，首先根据字符串名计算hash值  const size_t hash = ComputeModifiedUtf8Hash(descriptor); // Find the class in the loaded classes table.  //从ClassLoader对应的ClassTable中根据hash值搜索目标类  ObjPtr\u0026lt;mirror::Class\u0026gt; klass = LookupClass(self, descriptor, hash, class_loader.Get()); //如果目标类已经存在，则确保它的状态大于或等于kStatusResoved。  //EnsureResolved并不会调用上文提到的实际加载或链接类的函数，它只是等待其他线程完成这个工作  if (klass != nullptr) { return EnsureResolved(self, descriptor, klass); } // Class is not yet loaded.  if (descriptor[0] != \u0026#39;[\u0026#39; \u0026amp;\u0026amp; class_loader == nullptr) { // Non-array class and the boot class loader, search the boot class path.  /*对bootstrap类而言，它们是由虚拟机加载的，所以没有对应的ClassLoader。 下面的FindInClassPath函数返回的ClassPathEntry是类型别名，其定义如下： typedef pair\u0026lt;const DexFile*,const DexFile::ClassDef*\u0026gt; ClassPathEntry */ //FindInClassPath将从boot class path里对应的文件中找到目标类所在的Dex文件和对应  //的ClassDef信息，然后调用DefineClass来加载目标类  ClassPathEntry pair = FindInClassPath(descriptor, hash, boot_class_path_); if (pair.second != nullptr) { return DefineClass(self, descriptor, hash, ScopedNullHandle\u0026lt;mirror::ClassLoader\u0026gt;(), *pair.first, *pair.second); } } ObjPtr\u0026lt;mirror::Class\u0026gt; result_ptr; bool descriptor_equals; //如果搜索的是数组类，则创建对应的数组类类对象。  if (descriptor[0] == \u0026#39;[\u0026#39;) { result_ptr = CreateArrayClass(self, descriptor, hash, class_loader); } else { //需要触发ClassLoader进行类加载(会调用defineClass启动类加载)。该函数请读者在学完8.7.9节  ScopedObjectAccessUnchecked soa(self); //7.0上对应的方法是FindClassInPathClassLoader  bool known_hierarchy = FindClassInBaseDexClassLoader(soa, self, descriptor, hash, class_loader, \u0026amp;result_ptr); } if(result_ptr == nullptr) { /*如果通过ClassLoader加载目标类失败，则下面的代码将转入Java层去执行ClassLoader的类 加载。根据代码中的注释所言，类加载失败需要抛出异常，而上面的FindClassInPathClass- Loader并不会添加异常信息，相反，它还会去掉其执行过程中其他函数因处理失败（比如Define- Class）而添加的异常信息。所以，接下来的代码将进入Java层去ClassLoader对象的load- Class函数，虽然目标类最终也会加载失败，但相关异常信息就能添加，同时整个调用的堆栈信息 也能正确反映出来。所以，这种处理方式应是ART虚拟机里为提升运行速度所做的优化处理吧 */ result.reset(soa.Env()-\u0026gt;CallObjectMethod(class_loader_object.get(), WellKnownClasses::java_lang_ClassLoader_loadClass, class_name_object.get())); } ...... // success, return mirror::Class*  return result_ptr.Ptr(); } LookupClass mirror::Class* ClassLinker::LookupClass(Thread* self, const char* descriptor, size_t hash, ObjPtr\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { ReaderMutexLock mu(self, *Locks::classlinker_classes_lock_); ClassTable* const class_table = ClassTableForClassLoader(class_loader); if (class_table != nullptr) { ObjPtr\u0026lt;mirror::Class\u0026gt; result = class_table-\u0026gt;Lookup(descriptor, hash); if (result != nullptr) { return result.Ptr(); } } return nullptr; } ClassTableForClassLoader ClassTable* ClassLinker::ClassTableForClassLoader(ObjPtr\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { return class_loader == nullptr ? boot_class_table_.get() : class_loader-\u0026gt;GetClassTable(); } art/runtime/class_table.cc\nClassTable::Lookup mirror::Class* ClassTable::Lookup(const char* descriptor, size_t hash) { DescriptorHashPair pair(descriptor, hash); ReaderMutexLock mu(Thread::Current(), lock_); for (ClassSet\u0026amp; class_set : classes_) { auto it = class_set.FindWithHash(pair, hash); if (it != class_set.end()) { return it-\u0026gt;Read(); } } return nullptr; } FindClassInBaseDexClassLoader_C层双亲委派 bool ClassLinker::FindClassInBaseDexClassLoader(ScopedObjectAccessAlreadyRunnable\u0026amp; soa, Thread* self, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, ObjPtr\u0026lt;mirror::Class\u0026gt;* result) { // Termination case: boot class loader.  if (IsBootClassLoader(soa, class_loader.Get())) { *result = FindClassInBootClassLoaderClassPath(self, descriptor, hash); return true; } if (IsPathOrDexClassLoader(soa, class_loader)) { // For regular path or dex class loader the search order is:  // - parent  // - class loader dex files  // Handles as RegisterDexFile may allocate dex caches (and cause thread suspension).  StackHandleScope\u0026lt;1\u0026gt; hs(self); Handle\u0026lt;mirror::ClassLoader\u0026gt; h_parent(hs.NewHandle(class_loader-\u0026gt;GetParent())); if (!FindClassInBaseDexClassLoader(soa, self, descriptor, hash, h_parent, result)) { return false; // One of the parents is not supported.  } if (*result != nullptr) { return true; // Found the class up the chain.  } // Search the current class loader classpath.  *result = FindClassInBaseDexClassLoaderClassPath(soa, descriptor, hash, class_loader); return true; } FindClassInBaseDexClassLoaderClassPath ObjPtr\u0026lt;mirror::Class\u0026gt; ClassLinker::FindClassInBaseDexClassLoaderClassPath( ScopedObjectAccessAlreadyRunnable\u0026amp; soa, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader) { ObjPtr\u0026lt;mirror::Class\u0026gt; ret; auto define_class = [\u0026amp;](const DexFile* cp_dex_file) REQUIRES_SHARED(Locks::mutator_lock_) { const DexFile::ClassDef* dex_class_def = OatDexFile::FindClassDef(*cp_dex_file, descriptor, hash); if (dex_class_def != nullptr) { //main  ObjPtr\u0026lt;mirror::Class\u0026gt; klass = DefineClass(soa.Self(), descriptor, hash, class_loader, *cp_dex_file, *dex_class_def); if (klass == nullptr) { CHECK(soa.Self()-\u0026gt;IsExceptionPending()) \u0026lt;\u0026lt; descriptor; soa.Self()-\u0026gt;ClearException(); // TODO: Is it really right to break here, and not check the other dex files?  } ret = klass; return false; // Found a Class (or error == nullptr), stop visit.  } return true; // Continue with the next DexFile.  }; VisitClassLoaderDexFiles(soa, class_loader, define_class); return ret; } DefineClassSummary 类的加载、链接和初始化\nClassLinker::DefineClass内部会调用SetupClass和LoadClass\n在ART虚拟机实现中，类的加载、链接及初始化过程可以很容易地从代表类状态Status枚举变量的定义里推导出来的。整个过程可分为\n  Load（对应终态为kStatusLoaded）\n  Resolve（对应终态为kStatusResolved）\n  Verify（对应终态为kStatusVerified）\n  Initialized（对应终态为kStatusInitialized）四个步骤。\n  art/runtime/class_linker.cc\nmirror::Class* ClassLinker::DefineClass(Thread* self, const char* descriptor, size_t hash, Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader, const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def) { mirror::DexCache* dex_cache = RegisterDexFile(dex_file, class_loader.Get()); klass-\u0026gt;SetDexCache(dex_cache); SetupClass(dex_file, dex_class_def, klass, class_loader.Get());//main  // Add the newly loaded class to the loaded classes table.  mirror::Class* existing = InsertClass(descriptor, klass.Get(), hash); // Load the fields and other things after we are inserted in the table. This is so that we don\u0026#39;t  // end up allocating unfree-able linear alloc resources and then lose the race condition. The  // other reason is that the field roots are only visited from the class table. So we need to be  // inserted before we allocate / fill in these fields.  LoadClass(self, dex_file, dex_class_def, klass);//load, main  LoadSuperAndInterfaces(klass, dex_file)//main  LinkClass(self, descriptor, klass, interfaces, \u0026amp;h_new_class) //reslove,main ...... return h_new_class.Get(); Load 图解 sequenceDiagram ClassLinker-\u0026gt;\u0026gt;ClassLinker: SetupClass activate ClassLinker Note right of ClassLinker: 根据ClassDef初始化mirror::class对象 deactivate ClassLinker ClassLinker-\u0026gt;\u0026gt;ClassLinker: LoadClassMembers activate ClassLinker ClassLinker-\u0026gt;\u0026gt;ClassLinker: AllocArtFieldArray activate ClassLinker Note right of ClassLinker: 依次Alloc和Load静态和非静态field,结果保存在LengthPrefixedArray\u0026lt;ArtField\u0026gt;* ifields,并设置到mirror::class deactivate ClassLinker ClassLinker-\u0026gt;\u0026gt;ClassLinker: LoadField activate ClassLinker deactivate ClassLinker ClassLinker-\u0026gt;\u0026gt;ClassLinker: AllocArtMethodArray activate ClassLinker Note right of ClassLinker: 遍历direct和virtual方法，逐个调用loadMethod和LinkCode deactivate ClassLinker ClassLinker-\u0026gt;\u0026gt;ClassLinker: LoadMethod activate ClassLinker deactivate ClassLinker ClassLinker-\u0026gt;\u0026gt;ClassLinker: LinkCode activate ClassLinker Note right of ClassLinker: 设置entry_point_from_quick_compiled_code_,oat_class != nullptr时设置为GetQuickCode() deactivate ClassLinker ClassLinker-\u0026gt;\u0026gt;ClassLinker: LoadSuperAndInterfaces activate ClassLinker Note right of ClassLinker: 调用ResolveType触发superClass和interfaces的类加载,更新当前klass状态为kStatusLoaded deactivate ClassLinker deactivate ClassLinker SetupClass void ClassLinker::SetupClass(const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def, Handle\u0026lt;mirror::Class\u0026gt; klass, mirror::ClassLoader* class_loader) { const char* descriptor = dex_file.GetClassDescriptor(dex_class_def); //SetClass是Class的基类mirror Object中的函数。Class也是一种Object，所以此处设置它的  //类类型为”java/lang/Class”对应的那个Class对象  klass-\u0026gt;SetClass(GetClassRoot(kJavaLangClass)); uint32_t access_flags = dex_class_def.GetJavaAccessFlags(); //设置访问标志及该类的加载器对象  klass-\u0026gt;SetAccessFlags(access_flags); klass-\u0026gt;SetClassLoader(class_loader); //设置klass的状态为kStatusIdx。  mirror::Class::SetStatus(klass, mirror::Class::kStatusIdx, nullptr); //设置klass的dex_class_def_idx_和dex_type_idx_成员变量。  klass-\u0026gt;SetDexClassDefIndex(dex_file.GetIndexForClassDef(dex_class_def)); klass-\u0026gt;SetDexTypeIndex(dex_class_def.class_idx_); } LoadClass void ClassLinker::LoadClass(Thread* self, const DexFile\u0026amp; dex_file, const DexFile::ClassDef\u0026amp; dex_class_def, Handle\u0026lt;mirror::Class\u0026gt; klass) { //class_data的内容就是图8-7中的class_data_item  const uint8_t* class_data = dex_file.GetClassData(dex_class_def); if (class_data == nullptr) { return; } bool has_oat_class = false; if (Runtime::Current()-\u0026gt;IsStarted() \u0026amp;\u0026amp; !Runtime::Current()-\u0026gt;IsAotCompiler()) { //如果不是编译虚拟机的话，则先尝试找到该类经dex2oat编译得到的OatClass信息  OatFile::OatClass oat_class = FindOatClass(dex_file, klass-\u0026gt;GetDexClassDefIndex(), \u0026amp;has_oat_class); if (has_oat_class) { LoadClassMembers(self, dex_file, class_data, klass, \u0026amp;oat_class); } } //不管有没有OatClass信息，最终调用的函数都是LoadClassMembers。  if (!has_oat_class) { LoadClassMembers(self, dex_file, class_data, klass, nullptr); } } void ClassLinker::LoadClassMembers(Thread* self, const DexFile\u0026amp; dex_file,const uint8_t* class_data, Handle\u0026lt;mirror::Class\u0026gt; klass,const OatFile::OatClass* oat_class) { //注意这个函数的参数，class_data为dex文件里的代表该类的class_data_item信息，  //而oat_class描述的是Oat文件里针对这个类提供的一些信息  { LinearAlloc* const allocator = GetAllocatorForClassLoader(klass-\u0026gt;GetClassLoader()); //创建class_data_item迭代器  ClassDataItemIterator it(dex_file, class_data); //分配用于存储目标类静态成员变量的固定长度数组sfields  LengthPrefixedArray\u0026lt;ArtField\u0026gt;* sfields = AllocArtFieldArray( self,allocator,it.NumStaticFields()); size_t num_sfields = 0; uint32_t last_field_idx = 0u; //遍历class_data_item中的静态成员变量数组，然后填充信息到sfields数组里  for (; it.HasNextStaticField(); it.Next()) { uint32_t field_idx = it.GetMemberIndex(); if (num_sfields == 0 || LIKELY(field_idx \u0026gt; last_field_idx)) { //加载这个ArtField的内容。下文将单独介绍此函数  LoadField(it, klass, \u0026amp;sfields-\u0026gt;At(num_sfields)); ++num_sfields; last_field_idx = field_idx; } } // 同理，分配代表该类非静态成员变量的数组  LengthPrefixedArray\u0026lt;ArtField\u0026gt;* ifields = AllocArtFieldArray(self, allocator, it.NumInstanceFields()); size_t num_ifields = 0u; last_field_idx = 0u; for (; it.HasNextInstanceField(); it.Next()) { uint32_t field_idx = it.GetMemberIndex(); if (num_ifields == 0 || LIKELY(field_idx \u0026gt; last_field_idx)) { LoadField(it, klass, \u0026amp;ifields-\u0026gt;At(num_ifields)); //类似的处理  ++num_ifields; last_field_idx = field_idx; } } //设置Class类的sfields_和ifields_成员变量  klass-\u0026gt;SetSFieldsPtr(sfields); klass-\u0026gt;SetIFieldsPtr(ifields); /*设置Class类的methods_成员变量。读者可回顾笔者对该成员变量的解释，它是一个Length- PrefixedArray\u0026lt;ArtMethod\u0026gt;数组，其元素布局为 （1）[0,virtual_methods_offset_)为本类包含的direct成员函数 （2）[virtual_methods_offset_,copied_methods_offset_)为本类包含的virtual 成员函数 （3）[copied_methods_offset_,...)为剩下的诸如miranda函数等内容。下面代码中， 先分配1和2所需要的元素空间，然后设置klass对应的成员变量，其中： klass-\u0026gt;methods_为AllocArtMethodArray的返回值， klass-\u0026gt;copied_methods_offset_为类direct和virtual方法个数之和 klass-\u0026gt;virtual_methods_offset_为类direct方法个数 */ klass-\u0026gt;SetMethodsPtr( AllocArtMethodArray(self, allocator, it.NumDirectMethods() +it.NumVirtualMethods()), it.NumDirectMethods(), it.NumVirtualMethods()); size_t class_def_method_index = 0; uint32_t last_dex_method_index = DexFile::kDexNoIndex; size_t last_class_def_method_index = 0; //遍历direct方法数组，加载它们然后关联字节码  for (size_t i = 0; it.HasNextDirectMethod(); i++, it.Next()) { ArtMethod* method = klass-\u0026gt;GetDirectMethodUnchecked(i, image_pointer_size_); //加载ArtMethod对象，并将其和字节码关联起来。  LoadMethod(self, dex_file, it, klass, method); //注意，oat_class信息只在LinkCode中用到。LinkCode留待10.1节介绍  LinkCode(method, oat_class, class_def_method_index); uint32_t it_method_index = it.GetMemberIndex(); if (last_dex_method_index == it_method_index) { method-\u0026gt;SetMethodIndex(last_class_def_method_index); } else { //设置ArtMethod的method_index_，该值其实就是这个ArtMethod  //位于上面klass methods_数组中的位置  method-\u0026gt;SetMethodIndex(class_def_method_index); last_dex_method_index = it_method_index; last_class_def_method_index = class_def_method_index; } class_def_method_index++; } //处理virtual方法。注意，对表示virtual方法的ArtMethod对象而言，它们的method_index_  //和klass methods_数组没有关系，也不在下面的循环中设置。  for (size_t i = 0; it.HasNextVirtualMethod(); i++, it.Next()) { ...... //和direct方法处理一样，唯一不同的是，此处不调用ArtMethod的SetMethod-Index函数，即不设置它的method_index_成员  } } } LoadField void ClassLinker::LoadField(const ClassDataItemIterator\u0026amp; it, Handle\u0026lt;mirror::Class\u0026gt; klass, ArtField* dst) { const uint32_t field_idx = it.GetMemberIndex(); dst-\u0026gt;SetDexFieldIndex(field_idx); //设置对应于dex文件里的那个field_idx  dst-\u0026gt;SetDeclaringClass(klass.Get()); //设置本成员变量由哪个Class对象定义  dst-\u0026gt;SetAccessFlags(it.GetFieldAccessFlags()); //设置访问标记 } LoadMethod void ClassLinker::LoadMethod(Thread* self, const DexFile\u0026amp; dex_file,const ClassDataItemIterator\u0026amp; it, Handle\u0026lt;mirror::Class\u0026gt; klass, ArtMethod* dst) { uint32_t dex_method_idx = it.GetMemberIndex(); const DexFile::MethodId\u0026amp; method_id = dex_file.GetMethodId(dex_method_idx); const char* method_name = dex_file.StringDataByIdx(method_id.name_idx_); //设置ArtMethod declaring_class_和dex_method_index_和成员变量  dst-\u0026gt;SetDexMethodIndex(dex_method_idx); dst-\u0026gt;SetDeclaringClass(klass.Get()); //设置dex_code_item_offset_成员变量  dst-\u0026gt;SetCodeItemOffset(it.GetMethodCodeItemOffset()); //设置ArtMethod ptr_sized_fields_结构体中的dex_cache_resolved_methods_和dex_cache_  //resolved_types_成员。读者可回顾上文对ArtMethod成员变量的介绍  dst-\u0026gt;SetDexCacheResolvedMethods(klass-\u0026gt;GetDexCache()-\u0026gt;GetResolvedMethods(), image_pointer_size_); dst-\u0026gt;SetDexCacheResolvedTypes(klass-\u0026gt;GetDexCache()-\u0026gt;GetResolvedTypes(), image_pointer_size_); uint32_t access_flags = it.GetMethodAccessFlags(); //处理访问标志。比如，如果函数名为”finalize”的话，设置该类为finalizable  if (UNLIKELY(strcmp(\u0026#34;finalize\u0026#34;, method_name) == 0)) { if (strcmp(\u0026#34;V\u0026#34;, dex_file.GetShorty(method_id.proto_idx_)) == 0) { //该类的class loader如果不为空，则表示不是boot class，也就是系统所必需的那些  //基础类  if (klass-\u0026gt;GetClassLoader() != nullptr){ //设置类的访问标记，增加kAccClassIsFinalizable。表示该类重载了finalize函数  klass-\u0026gt;SetFinalizable(); } else {...... } } } else if (method_name[0] == \u0026#39;\u0026lt;\u0026#39;) { ......//如果函数名为”\u0026lt;init\u0026gt;”或”\u0026lt;clinit\u0026gt;”，则设置访问标志位kAccConstructor  } dst-\u0026gt;SetAccessFlags(access_flags); } LinkCode void ClassLinker::LinkCode(ArtMethod* method, const OatFile::OatClass* oat_class, int32_t class_def_method_index) { Runtime* const runtime = Runtime::Current(); if (runtime-\u0026gt;IsAotCompiler()) { // The following code only applies to a non-compiler runtime.  return; } // Method shouldn\u0026#39;t have already been linked.  DCHECK(method-\u0026gt;GetEntryPointFromQuickCompiledCode() == nullptr); /*在下面的代码中： （1）oat_class的类型为OatFile::OatClass，其内容由oat文件中OatClass区域相应位置处的信息构成。 （2）oat_method的类型为OatFile::OatMethod，其内容由oat文件中OatMethod区域对应的OatQuickMethodHeader信息构成。*/ // Every kind of method should at least get an invoke stub from the oat_method.  // non-abstract methods also get their code pointers.  if (oat_class != nullptr) { /*获取该Java方法对应的OatMethod信息。如果它没有被编译过，则返回的OatMethod对象的code_ offset_取值为0。OatMethod.code_offset_指向对应机器码在oat文件中的位置。其值为0 就表示该方法不存在机器码。 */ const OatFile::OatMethod oat_method = oat_class-\u0026gt;GetOatMethod(class_def_method_index); /*设置ArtMethod ptr_sized_fields_entry_point_from_quick_compiled_code_为 Oat文件区域OatQuickMethodHeader的code_。读者可回顾第9章图9-41“oat和art文件 的关系”。code_处存储的就是该方法编译得到的机器码。注意，为节省篇幅，笔者以后用机器 码入口地址来指代entry_point_from_quick_compiled_code_成员变量。*/ oat_method.LinkMethod(method); } // Install entry point from interpreter.  const void* quick_code = method-\u0026gt;GetEntryPointFromQuickCompiledCode();//获取ArtMethod对象的机器码入口地址  /*在ShouldUseInterpreterEntrypoint函数中，如果机器码入口地址为空（该方法没有经过编译）， 或者虚拟机进入了调试状态，则必须使用解释执行的模式。这种情况下，该函数返回值enter_inter- preter为true。 */ bool enter_interpreter = ShouldUseInterpreterEntrypoint(method, quick_code); if (method-\u0026gt;IsStatic() \u0026amp;\u0026amp; !method-\u0026gt;IsConstructor()) { // For static methods excluding the class initializer, install the trampoline.  // It will be replaced by the proper entry point by ClassLinker::FixupStaticTrampolines  // after initializing class (see ClassLinker::InitializeClass method).  /*如果method为静态且不是类初始化\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;（它是类的静态构造方法）方法，则设置机器码入口 地址为art_quick_resolution_trampoline。根据9.5.4.4.1节的介绍可知。该地址对应的是 一段跳转代码，跳转的目标是artQuickResolutionTrampoline函数。它是一个特殊的函数，和 类的解析有关。注意，虽然在LinkCode中（该函数是在类初始化之前被调用的）设置的跳转目标为 artQuickResolutionTrampoline，但ClassLinker在初始化类的InitializeClass函数的最 后会通过调用FixupStaticTrampolines来尝试更新此处所设置的跳转地址为正确的地址, 更新机器码入口地址entry_point_from_quick_compiled_code_*/ method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickResolutionStub()); } else if (quick_code == nullptr \u0026amp;\u0026amp; method-\u0026gt;IsNative()) { /*如果method为jni方法，并且不存在机器码，则设置机器码入口地址为跳转代码art_quick_ generic_jni_trampoline，它的跳转目标为artQuickGenericJniTrampoline函数。*/ method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickGenericJniStub()); } else if (enter_interpreter) { // Set entry point from compiled code if there\u0026#39;s no code or in interpreter only mode.  /*enter_interpreter的取值来自ShouldUseInterpreterEntrypoint，一般而言，如果该 方法没有对应的机器码，或者在调试运行模式下，则enter_interpreter为true。对应的机 器码入口地址为art_quick_to_interpreter_bridge跳转代码，其跳转的目标 //为artQuickToInterpreterBridge函数。*/ method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickToInterpreterBridge()); } if (method-\u0026gt;IsNative()) { // Unregistering restores the dlsym lookup stub.  /*如果为jni方法，则调用ArtMethod的UnregisterNative函数，其内部主要设置ArtMethod tls_ptr_sized_.entry_point_from_jni_成员变量为跳转代码art_jni_dlsym_look- up_stub，跳转目标为artFindNativeMethod函数。为简单起见，笔者以后用jni机器码入口 地址指代entry_point_from_jni_成员变量。这部分内容和JNI有关，我们以后再讨论它。*/ method-\u0026gt;UnregisterNative(); if (enter_interpreter || quick_code == nullptr) { // We have a native method here without code. Then it should have either the generic JNI  // trampoline as entrypoint (non-static), or the resolution trampoline (static).  // TODO: this doesn\u0026#39;t handle all the cases where trampolines may be installed.  const void* entry_point = method-\u0026gt;GetEntryPointFromQuickCompiledCode(); DCHECK(IsQuickGenericJniStub(entry_point) || IsQuickResolutionStub(entry_point)); } } } art/runtime/oat_file.cc\nOatMethod::LinkMethod void OatFile::OatMethod::LinkMethod(ArtMethod* method) const { CHECK(method != nullptr); method-\u0026gt;SetEntryPointFromQuickCompiledCode(GetQuickCode()); } LoadSuperAndInterfaces bool ClassLinker::LoadSuperAndInterfaces(Handle\u0026lt;mirror::Class\u0026gt; klass, const DexFile\u0026amp; dex_file) { const DexFile::ClassDef\u0026amp; class_def = dex_file.GetClassDef(klass-\u0026gt;GetDexClassDefIndex()); //找到基类的id  uint16_t super_class_idx = class_def.superclass_idx_; //根据基类的id来解析它，返回值是代表基类的Class实例。  //ResolveType函数的内容将在8.7.8节中介绍  mirror::Class* super_class = ResolveType(dex_file, super_class_idx, klass.Get()); if (super_class == nullptr) { return false; } //做一些简单校验。比如，基类如果不允许派生，则返回失败  if (!klass-\u0026gt;CanAccess(super_class)) { return false; } klass-\u0026gt;SetSuperClass(super_class); //设置super_class_成员变量的值  //下面这个检查和编译有关系，笔者不拟讨论它，代码中的注释非常详细  if (!CheckSuperClassChange(klass, dex_file, class_def, super_class)) { return false; } //从dex文件里找到目标类实现了哪些接口类。参考图8-7所示class_def结构体中  //interfaces_off的含义  const DexFile::TypeList* interfaces = dex_file.GetInterfacesList(class_def); if (interfaces != nullptr) { for (size_t i = 0; i \u0026lt; interfaces-\u0026gt;Size(); i++) { uint16_t idx = interfaces-\u0026gt;GetTypeItem(i).type_idx_; //解析这个接口类。下文将介绍ResolveType函数  mirror::Class* interface = ResolveType(dex_file, idx, klass.Get()); ...... //如果接口类找不到或者接口类不允许继承，则返回错误  } } //设置klass的状态为kStatusLoaded  mirror::Class::SetStatus(klass, mirror::Class::kStatusLoaded, nullptr); return true; } Resolve/Link LinkClass相关函数\n进入LinkClass之前，先回顾上文SetupClass和LoadClass的结果。此时：\n·目标类的信息从dex文件里对应的class_def结构体及其他相关结构体已经提取并转换为一个mirror Class对象。\n·同时，该Class对象中代表本类的成员变量和成员函数信息也相应创建为对应的ArtField和ArtMethod的对象，并做好了相关设置。从Class类成员来说，它的methods_、sfields_、ifields_都设置好了。\nLinkClass bool ClassLinker::LinkClass(Thread* self,const char* descriptor, Handle\u0026lt;mirror::Class\u0026gt; klass, //待link的目标class  Handle\u0026lt;mirror::ObjectArray\u0026lt;mirror::Class\u0026gt;\u0026gt; interfaces, MutableHandle\u0026lt;mirror::Class\u0026gt;* h_new_class_out) { /*注意本函数的参数： （1）klass代表输入的目标类，其状态是kStatusLoaded。 （2）h_new_class_out为输出参数，代表LinkClass执行成功后所返回给调用者的、类状态切升级为 kStatusResolved的目标类。所以，这个变量才是LinkClass执行成功后的结果。*/ //Link基类  if (!LinkSuperClass(klass)) { return false; }//main  /*下面将创建一个ArtMethod*数组。数组大小为kImtSize。它是一个编译时常量，由编译参数ART_ IMT_SIZE指定，默认是64。IMT是Interface Method Table的缩写。如其名所示，它和接口所 实现的函数有关。其作用我们后文再介绍 */ ArtMethod* imt[mirror::Class::kImtSize]; std::fill_n(imt, arraysize(imt), //填充这个数组的内容为默认值  Runtime::Current()-\u0026gt;GetImtUnimplementedMethod()); //对该类所包含的方法（包括它实现的接口方法、继承自父类的方法等）进行处理  if (!LinkMethods(self, klass, interfaces, imt)) { return false;}//main  //下面两个函数分别对类的成员进行处理。  if (!LinkInstanceFields(self, klass)) { return false;}//main  size_t class_size; //尤其注意LinkStaticFields函数，它的返回值包括class_size，代表该类所需内存大小。  if (!LinkStaticFields(self, klass, \u0026amp;class_size)) { return false; }//main  //处理Class的reference_instance_offsets_成员变量  CreateReferenceInstanceOffsets(klass);//main  //当目标类是基础数据类、抽象类（不包括数组）、接口类时，下面的if条件满足  if (!klass-\u0026gt;IsTemp() || .....)) { ..... //对于非Temp的类，不需要额外的操作，所以klass的状态被置为kStatusResolved，然后再赋  //值给h_new_class_out。到此，目标类就算解析完了  mirror::Class::SetStatus(klass, mirror::Class::kStatusResolved, self); h_new_class_out-\u0026gt;Assign(klass.Get()); } else {//如果目标类是可实例化的，则需要做额外的处理  StackHandleScope\u0026lt;1\u0026gt; hs(self); //CopyOf很关键，它先创建一个大小为class_size的Class对象，然后，klass的信息将拷贝  //到这个新创建的Class对象中。在这个处理过程汇总，Class对象的类状态将被设置为kStatus-  //Resolving。  auto h_new_class = hs.NewHandle(klass-\u0026gt;CopyOf(self, class_size, imt, image_pointer_size_)); klass-\u0026gt;SetMethodsPtrUnchecked(nullptr, 0, 0); //清理klass的内容  ...... //清理klass的其他内容;  { ...... //更新ClassTable中对应的信息  mirror::Class* existing = table-\u0026gt;UpdateClass(descriptor, h_new_class.Get(), ComputeModifiedUtf8Hash(descriptor)); ...... } //设置klass的状态为kStatusRetired，表示该类已经被废弃  mirror::Class::SetStatus(klass, mirror::Class::kStatusRetired, self); //设置新类的状态为kStatusResolved，表示该类解析完毕。  mirror::Class::SetStatus( h_new_class, mirror::Class::kStatusResolved,self); h_new_class_out-\u0026gt;Assign(h_new_class.Get()); //赋值给输出参数  } return true; } LinkMethods bool ClassLinker::LinkMethods(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, Handle\u0026lt;mirror::ObjectArray\u0026lt;mirror::Class\u0026gt;\u0026gt; interfaces, ArtMethod** out_imt) { ...... std::unordered_map\u0026lt;size_t, ClassLinker::MethodTranslation\u0026gt; default_translations; //下面三个函数很复杂  return SetupInterfaceLookupTable(self, klass, interfaces) \u0026amp;\u0026amp; LinkVirtualMethods(self, klass, \u0026amp;default_translations) \u0026amp;\u0026amp; LinkInterfaceMethods(self, klass, default_translations, out_imt); } LinkInstanceFields bool ClassLinker::LinkInstanceFields(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass) { CHECK(klass.Get() != nullptr); return LinkFields(self, klass, false, nullptr); } LinkStaticFields bool ClassLinker::LinkStaticFields(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, size_t* class_size) { CHECK(klass.Get() != nullptr); return LinkFields(self, klass, true, class_size); } LinkFields bool ClassLinker::LinkFields(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, bool is_static, size_t* class_size) { //确定成员变量的个数  const size_t num_fields = is_static ? klass-\u0026gt;NumStaticFields() : klass-\u0026gt;NumInstanceFields(); //从Class中得到代表静态或非静态成员变量的数组  LengthPrefixedArray\u0026lt;ArtField\u0026gt;* const fields = is_static ? klass-\u0026gt;GetSFieldsPtr() : klass-\u0026gt;GetIFieldsPtr(); MemberOffset field_offset(0); if (is_static) { //如果是静态变量，则得到静态存储空间的起始位置。  field_offset = klass-\u0026gt;GetFirstReferenceStaticFieldOffsetDuringLinking( image_pointer_size_); } else { //获取基类的ObjectSize  mirror::Class* super_class = klass-\u0026gt;GetSuperClass(); if (super_class != nullptr) { field_offset = MemberOffset(super_class-\u0026gt;GetObjectSize()); } } //排序，引用类型放最前面，然后是long/double、int/float等。符合图8-13中的布局要求  std::deque\u0026lt;ArtField*\u0026gt; grouped_and_sorted_fields; for (size_t i = 0; i \u0026lt; num_fields; i++) { grouped_and_sorted_fields.push_back(\u0026amp;fields-\u0026gt;At(i)); } std::sort(grouped_and_sorted_fields.begin(), grouped_and_sorted_fields.end(),LinkFieldsComparator()); size_t current_field = 0; size_t num_reference_fields = 0; FieldGaps gaps; //先处理引用类型的变量  for (; current_field \u0026lt; num_fields; current_field++) { ArtField* field = grouped_and_sorted_fields.front(); Primitive::Type type = field-\u0026gt;GetTypeAsPrimitiveType(); bool isPrimitive = type != Primitive::kPrimNot; if (isPrimitive) { break; } ...... grouped_and_sorted_fields.pop_front(); num_reference_fields++; field-\u0026gt;SetOffset(field_offset); //设置ArtField的offset_变量  field_offset = MemberOffset(field_offset.Uint32Value() + sizeof(mirror::HeapReference\u0026lt;mirror::Object\u0026gt;)); } //我们在ComputeClassSize中曾提到说内存布局可以优化，下面的ShuffleForward就是处理这种优  //化。ShuffleForward是一个模板函数，内部会设置ArtField的offset_。  ShuffleForward\u0026lt;8\u0026gt;(\u0026amp;current_field, \u0026amp;field_offset, \u0026amp;grouped_and_sorted_fields, \u0026amp;gaps); ...... //处理4字节、2字节基础数据类型变量  ShuffleForward\u0026lt;1\u0026gt;(\u0026amp;current_field, \u0026amp;field_offset, \u0026amp;grouped_and_sorted_fields, \u0026amp;gaps); ...... //特殊处理java.lang.ref.Reference类。将它的非静态引用类型变量的个数减去一个。减去的这个  //变量是java Reference类中的referent成员，它和GC有关，需要特殊对待。后续章节会详细介绍GC。  if (!is_static \u0026amp;\u0026amp; klass-\u0026gt;DescriptorEquals(\u0026#34;Ljava/lang/ref/Reference;\u0026#34;)) { --num_reference_fields; } size_t size = field_offset.Uint32Value(); if (is_static) { klass-\u0026gt;SetNumReferenceStaticFields(num_reference_fields); *class_size = size; //设置Class最终所需内存大小  } else { klass-\u0026gt;SetNumReferenceInstanceFields(num_reference_fields); ...... //如果类的对象是固定大小（像数组、String则属于非固定大小），则设置Object所需内存大小  if (!klass-\u0026gt;IsVariableSize()) { ...... klass-\u0026gt;SetObjectSize(size); } } return true; } Verify 在ART虚拟机中，如果某个类校验通过的话，后续执行该类的方法时将跳过所谓的访问检查（Access Check）\ngraph TB dex2oat时verify_预校验--\u0026gt;软错误时kStatusRetryVerificationAtRuntime dex2oat时verify_预校验--\u0026gt;成功kStatusVerified 虚拟机运行时检查--\u0026gt;成功kStatusVerified 成功kStatusVerified--\u0026gt;该类methods_数组所有ArtMethod对象设置kAccSkipAccessChecks标志 成功kStatusVerified--\u0026gt;为类设置kAccVerification-Attempted标记 虚拟机运行时检查--\u0026gt;软错误时kStatusRetryVerificationAtRuntime 软错误时kStatusRetryVerificationAtRuntime--\u0026gt;MethodVerifier对该类进行校验 MethodVerifier对该类进行校验--\u0026gt;依旧软错误 依旧软错误--\u0026gt;为类设置kAccVerification-Attempted标记 VerifyClass void ClassLinker::VerifyClass(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, LogSeverity log_level) { ...... //可能有另外一个线程正在处理类的校验，此处省略的代码将处理这种情况判断该类是否  //已经通过校验（类状态大于或等于kStatusVerified）  if (klass-\u0026gt;IsVerified()) { /* Verify一个类是需要代价的（比如执行上两节代码所示MethodVerifier的相关函数是 需要花费时间），但付出这个代价会带来一定好处。在ART虚拟机中，如果某个类校验通 过的话，后续执行该类的方法时将跳过所谓的访问检查（Access Check）。Access Check 的具体内容将在后续章节介绍。此处举一个简单例子，比如访问检查将判断外部调用者是 否调用了某个类的私有函数。显然，Access Check将影响函数执行的时间。 下面的这个EnsureSkipAccessChecksMethods将做两件事情： （1）为klass methods_数组里的ArtMethod对象设置kAccSkipAccessChecks标志位 （2）为klass设置kAccVerificationAttempted标志位。这个标记位表示该类已经尝试过 校验了，无须再次校验。 这些标志位的作用我们以后碰见具体代码时再讲解。 */ EnsureSkipAccessChecksMethods(klass); return; } //如果类状态大于等于kStatusRetryVerificationAtRuntime并且当前进程是dex2oat(Is-  //AotCompiler用于判断当前进程是否为编译进程)，则直接返回。类的校验将留待真实的虚拟机  //进程来完成。  if (klass-\u0026gt;IsCompileTimeVerified() \u0026amp;\u0026amp; Runtime::Current()-\u0026gt;IsAotCompiler()) { return; } if (klass-\u0026gt;GetStatus() == mirror::Class::kStatusResolved) { //设置类状态为kStatusVerifying，表明klass正处于类校验阶段。  mirror::Class::SetStatus(klass, mirror::Class::kStatusVerifying, self); } else { //如果类的当前状态不是kStatusResolved，则表明该类在dex2oat时已经做过校  //验，但校验结果是kStatusRetryVerificationAtRuntime。所以此处需要在完  //整虚拟机环境下再做校验。  mirror::Class::SetStatus(klass, mirror::Class::SetStatus(klass, mirror::Class::kStatusVerifyingAtRuntime, self); } /*IsVerificationEnabled用于返回虚拟机是否开启了类校验的功能，它和verify_mode.h中定义 的枚举变量VerifyMode有关。该枚举变量有三种取值： （1）kNone：不做校验。 （2）kEnable：标准校验流程。其中，在dex2oat过程中会尝试做预校验（preverifying）。 （3）kSoftFail：强制为软校验失败。这种情况下，指令码在解释执行的时候会进行access check。这部分内容在dex2oat一章中有所体现，以后我们会提到。 从上述内容可知，在ART里，类校验的相关知识绝不仅仅只包含JLS规范中提到的那些诸如检查 字节码是否合法之类的部分，它还和dex2oat编译与Java方法如何执行等内容密切相关。*/ if (!Runtime::Current()-\u0026gt;IsVerificationEnabled()) { mirror::Class::SetStatus(klass, mirror::Class::kStatusVerified, self); EnsureSkipAccessChecksMethods(klass); return; } //先校验父类。AttemptSuperTypeVerification内部也会调用VerifyClass。  ...... //请读者自行阅读它  MutableHandle\u0026lt;mirror::Class\u0026gt; supertype(hs.NewHandle( klass-\u0026gt;GetSuperClass())); if (supertype.Get() != nullptr \u0026amp;\u0026amp; !AttemptSupertypeVerification(self, klass, supertype)) { return; } //如果父类校验通过，并且klass不是接口类的话，我们还要对klass所实现的接口类进行校验。校验  //接口类是从Java 1.8开始，接口类支持定义有默认实现的接口函数，默认函数包含实际的内容，所以  //需要校验。  if ((supertype.Get() == nullptr || supertype-\u0026gt;IsVerified()) \u0026amp;\u0026amp; !klass-\u0026gt;IsInterface()) { int32_t iftable_count = klass-\u0026gt;GetIfTableCount(); MutableHandle\u0026lt;mirror::Class\u0026gt; iface(hs.NewHandle\u0026lt;mirror::Class\u0026gt;(nullptr)); //遍历IfTable，获取其中的接口类。  for (int32_t i = 0; i \u0026lt; iftable_count; i++) { iface.Assign(klass-\u0026gt;GetIfTable()-\u0026gt;GetInterface(i)); //接口类没有默认接口函数，或者已经校验通过，则略过  if (LIKELY(!iface-\u0026gt;HasDefaultMethods() || iface-\u0026gt;IsVerified())) { continue; } else if (UNLIKELY(!AttemptSupertypeVerification(self, klass, iface))) { return; //接口类校验失败。直接返回  } else if (UNLIKELY(!iface-\u0026gt;IsVerified())) { //如果接口类校验后得到的状态为kStatusVerifyingAtRuntime，则跳出循环  supertype.Assign(iface.Get()); break; } } const DexFile\u0026amp; dex_file = *klass-\u0026gt;GetDexCache()-\u0026gt;GetDexFile(); mirror::Class::Status oat_file_class_status( mirror::Class::kStatusNotReady); /*下面这个函数其实只是用来判断klass是否已经在dex2oat阶段做过预校验了。这需要结合该类编译 结果来决定（包含在OatFile中的类状态）。除此之外，如果我们正在编译系统镜像时（即在dex2oat 进程中编译包含在Boot Image的类），则该函数也返回false。preverified如果为false，则将 调用MethodVerifier VerifyClass来做具体的校验工作。VerifyClassUsingOatFile还包含其 他几种返回false的情况，请读者自行阅读。*/ bool preverified = VerifyClassUsingOatFile(dex_file, klass.Get(), oat_file_class_status); verifier::MethodVerifier::FailureKind verifier_failure = verifier::MethodVerifier::kNoFailure; if (!preverified) { //没有预校验的处理  Runtime* runtime = Runtime::Current(); //调用MethodVerifier VerifyClass来完成具体的校验工作,main  verifier_failure = verifier::MethodVerifier::VerifyClass(self, klass.Get(), runtime-\u0026gt;GetCompilerCallbacks(),,...); } ...... if (preverified || verifier_failure != verifier::MethodVerifier::kHardFailure) { ...... if (verifier_failure == verifier::MethodVerifier::kNoFailure) { //自己和基类（或者接口类）的校验结果都正常，则类状态设置为kStatusVerified  if (supertype.Get() == nullptr || supertype-\u0026gt;IsVerified()) { mirror::Class::SetStatus(klass, mirror::Class::kStatusVerified, self); } else {......} } else { //对应校验结果为kSoftFail的情况  if (Runtime::Current()-\u0026gt;IsAotCompiler()) { //如果是dex2oat中出现这种情况，则设置类的状态为kStatusRetryVerificationAtRuntime  mirror::Class::SetStatus(klass, mirror::Class::kStatusRetryVerificationAtRuntime, self); } else { /*设置类状态为kStatusVerified，并且设置类标记位kAccVerificationAttempted。 注意，我们在上面代码中介绍过EnsureSkipAccessChecksMethods函数。这个函数将 （1）为klass methods_数组里的ArtMethod对象设置kAccSkipAccessChecks标志位 （2）为klass设置kAccVerificationAttempted标志位。 而下面的代码只设置了（2），没有设置（1）。所以，虽然类状态为kStatusVerified， 但在执行其方法时可能还要做Access Check */ mirror::Class::SetStatus(klass, mirror::Class::kStatusVerified, self); klass-\u0026gt;SetVerificationAttempted(); } } } else {...... } } else {...... } ....... //其他处理，略过 } MethodVerifier::VerifyClass MethodVerifier::FailureKind MethodVerifier::VerifyClass(Thread* self, mirror::Class* klass,......) { //待校验的类由kclass表示  //如果该类已经被校验过，则直接返回校验成功  if (klass-\u0026gt;IsVerified()) { return kNoFailure; } bool early_failure = false; std::string failure_message; //获取该class所在的Dex文件信息及该类在Dex文件里的class_def信息  const DexFile\u0026amp; dex_file = klass-\u0026gt;GetDexFile(); const DexFile::ClassDef* class_def = klass-\u0026gt;GetClassDef(); //获取该类的基类对象  mirror::Class* super = klass-\u0026gt;GetSuperClass(); std::string temp; //下面这个判断语句表示kclass没有基类，而它又不是Java Object类。显然，这是违背Java语言规范  //的—Java中，只有Object类才没有基类  if (super == nullptr \u0026amp;\u0026amp; strcmp(\u0026#34;Ljava/lang/Object;\u0026#34;, klass-\u0026gt;GetDescriptor(\u0026amp;temp)) != 0) { early_failure = true; failure_message = \u0026#34; that has no super class\u0026#34;; } else if (super != nullptr \u0026amp;\u0026amp; super-\u0026gt;IsFinal()) { //如果基类有派生类的话，基类不能为final  early_failure = true; } else if (class_def == nullptr) { //该类在Dex文件里没有class_def信息  early_failure = true; } if (early_failure) { ...... if (callbacks != nullptr) { //callbacks的类型是CompilerCallbacks，dex字节码转机器码的时候会用上它  ClassReference ref(\u0026amp;dex_file, klass-\u0026gt;GetDexClassDefIndex()); callbacks-\u0026gt;ClassRejected(ref); } return kHardFailure; //返回校验错误  } StackHandleScope\u0026lt;2\u0026gt; hs(self); Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache(hs.NewHandle(klass-\u0026gt;GetDexCache())); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle( klass-\u0026gt;GetClassLoader())); //进一步校验  return VerifyClass(self,\u0026amp;dex_file,dex_cache,......); } MethodVerifier::FailureKind MethodVerifier::VerifyClass(Thread* self, ......) { if ((class_def-\u0026gt;access_flags_ \u0026amp; (kAccAbstract | kAccFinal)) == (kAccAbstract | kAccFinal)) { return kHardFailure; //类不能同时是final又是abstract  } const uint8_t* class_data = dex_file-\u0026gt;GetClassData(*class_def); if (class_data == nullptr) { return kNoFailure; } //创建ClassDataItemIterator迭代器对象，通过它可以获取目标类的class_data_item里的内容  ClassDataItemIterator it(*dex_file, class_data); //不校验类的成员变量  while (it.HasNextStaticField() || it.HasNextInstanceField()) { it.Next(); } ClassLinker* linker = Runtime::Current()-\u0026gt;GetClassLinker(); //对本类所定义的Java方法进行校验。VerifyMethods在上一节已经介绍过了  MethodVerifier::FailureData data1 = VerifyMethods\u0026lt;true\u0026gt;(self, linker, dex_file, ......);//main  //校验本类中的virtual_methods数组  MethodVerifier::FailureData data2 = VerifyMethods\u0026lt;false\u0026gt;(self, linker, dex_file,......); //将校验结果合并到data1的结果中  data1.Merge(data2); //校验结果通过合并后的data1的成员来判断  if (data1.kind == kNoFailure) { return kNoFailure; } else { return data1.kind; } } MethodVerifier::VerifyMethods template \u0026lt;bool kDirect\u0026gt; MethodVerifier::FailureData MethodVerifier::VerifyMethods(Thread* self, ClassLinker* linker,const DexFile* dex_file, const DexFile::ClassDef* class_def,ClassDataItemIterator* it,...) { /* 注意这个函数的参数和返回值： （1）该函数为模板函数。结合图8-7，如果模板参数kDirect为true，则校验的将是目标类中 direct_methods的内容，否则为virtual_methods的内容。 （2）class_def的类型为DexFile::ClassDef。它是Dex文件里的一部分，class_def中最重 要的信息存储在class_data_item中，而class_data_item的内容可借助迭代器it来获取。 （3）self代表当前调用的线程对象。dex_file是目标类所在的Dex文件。 （4）返回值的类型为FailureData。它是MethodVeifier定义的内部类，其内部有一个名为kind 的成员变量，类型为枚举FailureKind，取值有如下三种情况： a) kNoFailure，表示校验无错。 b) kSoftFailure，表示校验软错误，该错误发生在从dex字节码转换为机器码时所做的校验过程 中。编译过程由dex2oat进程完成。dex2oat是一个简单的，仅用于编译的虚拟机进程，它包 含了前文提到的诸如heap、runtime等重要模块，但编译过程不会将所有相关类都加载到虚拟 机里，所以可能会出现编译过程中校验失败的情况。kSoftFailure失败并没有关系，这个类 在后续真正使用之时，虚拟机还会再次进行校验。 c) kHardFailure，表示校验错误，该错误表明校验失败。 */ MethodVerifier::FailureData failure_data; int64_t previous_method_idx = -1; /*同上，如果kDirect为true，则遍历class_data_item信息里的direct_methods数组， 否则遍历其中的virtual_methods数组（代表虚成员函数）。*/ while (HasNextMethod\u0026lt;kDirect\u0026gt;(it)) { self-\u0026gt;AllowThreadSuspension(); uint32_t method_idx = it-\u0026gt;GetMemberIndex(); ...... previous_method_idx = method_idx; /*InvokeType是枚举变量，和dex指令码里函数调用的方式有关：取值包括： （1）kStatic：对应invoke-static相关指令，调用类的静态方法。 （2）kDirect：对应invoke-direct相关指令，指调用那些非静态方法。包括两类，一类是 private修饰的成员函数，另外一类则是指类的构造函数。符合kStatic和kDirect调用类型 函数属于上文所述的direct methods（位于类的direct_methods数组中）。 （3）kVirtual：对应invoke-virtual相关指令，指调用非private、static或final修饰 的成员函数（注意，不包括调用构造函数）。 （4）kSuper：对应invoke-super相关指令，指在子类的函数中通过super来调用直接父类的 函数。注意，dex官方文档只是说invoke-super用于调用直接父类的virtual函数。但笔者测试 发现，必须写成\u0026#34;super.父类函数\u0026#34;的形式才能生成invoke-super指令。 （5）kInterface：对应invoke-interface相关指令，指调用接口中定义的函数。 以上枚举变量的解释可参考第3章最后所列举的谷歌官方文档。 下面代码中的GetMethodInvokeType是迭代器ClassDataItemIterator的成员函数，它将 返回当前所遍历的成员函数的调用方式（InvokeType）。注意，该函数返回kSuper的逻辑和官 方文档对kSuper的描述并不一致。按照该函数的逻辑，它永远也不可能返回kSuper。笔者在模拟 器上验证过这个问题，此处从未有返回过kSuper的情况。感兴趣的读者不妨做一番调研 */ InvokeType type = it-\u0026gt;GetMethodInvokeType(*class_def); //调用ClassLinker的ResolveMethod进行解析，下文将介绍此函数。  ArtMethod* method = linker-\u0026gt;ResolveMethod\u0026lt;ClassLinker::kNoICCECheckForCache\u0026gt;( *dex_file, method_idx, dex_cache, class_loader, nullptr, type); ...... //调用另外一个VerifyMethod函数，其代码见下文  MethodVerifier::FailureData result = VerifyMethod(self,method_idx,...); ...... return failure_data; } MethodVerifier::VerifyMethod MethodVerifier::FailureData MethodVerifier::VerifyMethod(Thread* self, ......) { MethodVerifier::FailureData result; /*创建一个MethodVerifier对象，然后调用它的Verify方法。其内部将校验method（类型为Art- Method*）所代表的Java方法。该方法对应的字节码在code_item（对应dex文件格式里的code_ item）中。 */ MethodVerifier verifier(self,dex_file, dex_cache, class_loader, ......); //Verify返回成功，表示校验通过。即使出现kSoftFailure的情况，该函数也会返回true  if (verifier.Verify()) {//main  ...... //failures_的类型为vector\u0026lt;VerifyError\u0026gt;。VerifyError为枚举变量，定义了校验中可能  //出现的错误情况  if (verifier.failures_.size() != 0) { result.kind = kSoftFailure; } if (method != nullptr) {.....} } else { /*Verify返回失败，但若错误原因是一些试验性指令导致的，则也属于软错误，Dex指令码中有 一些属于试验性质的指令，比如invokelambda。搜索dex_instruction.h文件里带kExperi- mental标记的指令码，即是ART虚拟机所支持的试验性指令 */ if (UNLIKELY(verifier.have_pending_experimental_failure_)) { result.kind = kSoftFailure; } else { result.kind = kHardFailure;} } ...... return result; } MethodVerifier::Verify bool MethodVerifier::Verify() { //从dex文件里取出该方法对应的method_id_item信息  const DexFile::MethodId\u0026amp; method_id = dex_file_-\u0026gt;GetMethodId(dex_method_idx_); //取出该函数的函数名  const char* method_name = dex_file_-\u0026gt;StringDataByIdx(method_id.name_idx_); /*根据函数名判断其是类实例的构造函数还是类的静态构造函数。代码中，\u0026#34;\u0026lt;init\u0026gt;\u0026#34;叫类实例构造函数 （instance constructor），而\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;叫类的静态构造函数（static constructor）。 */ bool instance_constructor_by_name = strcmp(\u0026#34;\u0026lt;init\u0026gt;\u0026#34;, method_name) == 0; bool static_constructor_by_name = strcmp(\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;, method_name) == 0; //上述条件有一个为true，则该函数被认为是构造函数  bool constructor_by_name = instance_constructor_by_name || static_constructor_by_name; /*如果该函数的访问标记（access flags，可参考第3章表3-1自己为构造函数，而函数名又不符合要 求，则设置校验的结果为VERIFY_ERROR_BAD_CLASS_HARD（VerifyError枚举值中的一种）。Fail 函数内部会处理VerifyError里定义的不同错误类型。其中以HARD结尾的枚举变量表示为硬错误 */ if ((method_access_flags_ \u0026amp; kAccConstructor) != 0) { if (!constructor_by_name) { Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; \u0026#34;method is marked as constructor, but not named accordingly\u0026#34;; return false; } is_constructor_ = true; } else if (constructor_by_name) { is_constructor_ = true; } //code_item_代表该函数的内容，如果为nullptr，则表示这个函数为抽象函数或native函数  if (code_item_ == nullptr) { //既不是抽象函数，也不是native函数，但又没有函数内容，校验肯定会失败  if ((method_access_flags_ \u0026amp; (kAccNative | kAccAbstract)) == 0) { Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; ......; //错误原因;  return false; } return true; } /*参考3.2.4节可知，ins_size_表示输入参数所占虚拟寄存器的个数，而registers_size_表示该 函数所需虚拟寄存器的总个数。显然，下面这个if条件为true的话，这个函数肯定会校验失败 */ if (code_item_-\u0026gt;ins_size_ \u0026gt; code_item_-\u0026gt;registers_size_) { Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; ......; Fail(VERIFY_ERROR_BAD_CLASS_HARD) \u0026lt;\u0026lt; ......; return false; } //insn_flags_将保存该方法里的指令码内容  insn_flags_.reset(arena_.AllocArray\u0026lt;InstructionFlags\u0026gt;( code_item_-\u0026gt;insns_size_in_code_units_)); std::uninitialized_fill_n(insn_flags_.get(), code_item_-\u0026gt;insns_size_in_code_units_, InstructionFlags()); //下面四个函数将对指令码的内容进行校验。读者不拟介绍它们，感兴趣的读者不妨自行研究。  bool result = ComputeWidthsAndCountOps(); result = result \u0026amp;\u0026amp; ScanTryCatchBlocks(); result = result \u0026amp;\u0026amp; VerifyInstructions(); result = result \u0026amp;\u0026amp; VerifyCodeFlow(); return result; } Initialize 执行clinit方法\nEnsureInitialized bool ClassLinker::EnsureInitialized(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; c, bool can_init_fields, bool can_init_parents) { if (c-\u0026gt;IsInitialized()) { EnsureSkipAccessChecksMethods(c, image_pointer_size_); return true; } // SubtypeCheckInfo::Initialized must happen-before any new-instance for that type.  const bool success = InitializeClass(self, c, can_init_fields, can_init_parents); return success; InitializeClass bool ClassLinker::InitializeClass(Thread* self, Handle\u0026lt;mirror::Class\u0026gt; klass, bool can_init_statics, bool can_init_parents) { ...... //多个线程也可能同时触发目标类的初始化工作，如果这个类已经初始化了，则直接返回  //判断是否能初始化目标类。因为该函数可以在dex2oat编译进程中调用，在编译进程中，某些情况下  //无须初始化类。这部分内容我们不关注，读者以后碰到相关代码时可回顾此处的处理。  if (!CanWeInitializeClass(klass.Get(), can_init_statics, can_init_parents)) { return false; } { //  ..... if (!klass-\u0026gt;IsVerified()) { //如果类还没有校验，则校验它  VerifyClass(self, klass); ...... } ...... /*下面这个函数将对klass做一些检查，大体功能包括： （1）如果klass是接口类，则直接返回，不做任何检查。 （2）如果klass和它的基类superclass是由两个不同的ClassLoader加载的，则需要对比检 查klass VTable和superclass VTable中对应项的两个ArtMethod是否有相同的签名 信息，即两个成员方法的返回值类型、输入参数的个数以及类型是否一致。 （3）如果klass有Iftable，则还需要检查klass IfTable中所实现的接口类的函数与对应 接口类里定义的接口函数是否有一样的签名信息。是否开展检查的前提条件也是klass和接 口类由不同的ClassLoader加载。如果检查失败，则会创建java.lang.LinkageError 错误信息。 */ if (!ValidateSuperClassDescriptors(klass)) {.....} ...... //设置执行类初始化操作的线程ID以及类状态为kStatusInitializing  klass-\u0026gt;SetClinitThreadId(self-\u0026gt;GetTid()); mirror::Class::SetStatus(klass, mirror::Class::kStatusInitializing, self); } //根据JLS规范，klass如果是接口类的话，则不需要初始化接口类的基类（其实就是Object）  if (!klass-\u0026gt;IsInterface() \u0026amp;\u0026amp; klass-\u0026gt;HasSuperClass()) { mirror::Class* super_class = klass-\u0026gt;GetSuperClass(); if (!super_class-\u0026gt;IsInitialized()) { ...... Handle\u0026lt;mirror::Class\u0026gt; handle_scope_super(hs.NewHandle(super_class)); bool super_initialized = InitializeClass(self, handle_scope_super, can_init_statics, true); ...... //基类初始化失败的处理  } } //初始化klass所实现的那些接口类  if (!klass-\u0026gt;IsInterface()) { size_t num_direct_interfaces = klass-\u0026gt;NumDirectInterfaces(); if (UNLIKELY(num_direct_interfaces \u0026gt; 0)) { MutableHandle\u0026lt;mirror::Class\u0026gt; handle_scope_iface(....); for (size_t i = 0; i \u0026lt; num_direct_interfaces; i++) { //handle_scope_iface代表一个接口类对象  handle_scope_iface.Assign(mirror::Class::GetDirectInterface( self, klass, i)); //检查接口类对象是否设置了kAccRecursivelyInitialized标记位。这个标记位表示  //这个接口类已初始化过了。该标志位是ART虚拟机内部处理类初始化时的一种优化手段  if (handle_scope_iface-\u0026gt;HasBeenRecursivelyInitialized()) {continue; } //初始化接口类，并递归初始化接口类的父接口类  bool iface_initialized = InitializeDefaultInterfaceRecursive(self, handle_scope_iface,......); if (!iface_initialized) { return false; } } } } /*到此，klass的父类及接口类都已经初始化了。接下来要初始化klass中的静态成员变量。读者可回 顾图8-7 class_def结构体，其最后一个成员变量为static_values_off，它代表该类静态成员 变量初始值存储的位置。找到这个位置，即可取出对应静态成员变量的初值。 */ const size_t num_static_fields = klass-\u0026gt;NumStaticFields(); if (num_static_fields \u0026gt; 0) { //找到klass对应的ClassDef信息以及对应的DexFile对象  const DexFile::ClassDef* dex_class_def = klass-\u0026gt;GetClassDef(); const DexFile\u0026amp; dex_file = klass-\u0026gt;GetDexFile(); StackHandleScope\u0026lt;3\u0026gt; hs(self); Handle\u0026lt;mirror::ClassLoader\u0026gt; class_loader(hs.NewHandle( klass-\u0026gt;GetClassLoader())); //找到对应的DexCache对象  Handle\u0026lt;mirror::DexCache\u0026gt; dex_cache(hs.NewHandle(klass-\u0026gt;GetDexCache())); ..... //遍历ClassDef中代表static_values_off的区域  EncodedStaticFieldValueIterator value_it(dex_file, \u0026amp;dex_cache, \u0026amp;class_loader, this, *dex_class_def); const uint8_t* class_data = dex_file.GetClassData(*dex_class_def); ClassDataItemIterator field_it(dex_file, class_data); if (value_it.HasNext()) { for ( ; value_it.HasNext(); value_it.Next(), field_it.Next()) { //找到对应的ArtField成员。下文会介绍ResolveField函数  ArtField* field = ResolveField(dex_file, field_it.GetMemberIndex(), dex_cache, class_loader, true); //设置该ArtField的初值，内部将调用Class的SetFieldXXX相关函数，它会在Class  //对象中存储对应静态成员变量内容的位置（其值为ArtField的offset_）上设置初值。  value_it.ReadValueToField\u0026lt;...\u0026gt;(field); } } } //找到类的\u0026#34;\u0026lt;clinit\u0026gt;\u0026#34;函数，并执行它  ArtMethod* clinit = klass-\u0026gt;FindClassInitializer(image_pointer_size_); if (clinit != nullptr) { JValue result; clinit-\u0026gt;Invoke(self, nullptr, 0, \u0026amp;result, \u0026#34;V\u0026#34;); } bool success = true; { if (.....) {......} else { //初始化正常  ..... //设置类状态为kStatusInitialized  mirror::Class::SetStatus(klass, mirror::Class::kStatusInitialized,self); //下面这个函数设置klass静态成员方法ArtMethod的trampoline入口地址。它和  //Java方法的执行有关，这部分内容我们留待后文再来介绍。  //更新机器码入口地址entry_point_from_quick_compiled_code_  FixupStaticTrampolines(klass.Get()); } } return success; } 类加载样例 图8-10　AbsClass0的情况\n图8-11　ConcreteClass的情况\n图8-12　ConcreteChildClass的情况\n方法表总结 ·methods_：仅保存在本类中定义的direct、virtual以及拷贝过来的方法。\n·vtable_或embedded_vtable_：如果一个类是可实例化的，则只存在embedded_vtable_变量，否则只存在vtable_。这两个变量保存的信息是一样的，即这个类所有的virtual方法。这个表内容可能会非常多，因为它包含了来自整个继承和实现关系上的所有类的virtual方法。\n·embedded_imtable_：如果一个类是可实例化的，则存在这个变量。它存储了接口类方法。embedded_imtable_本身起到快查表的作用，方便快速找到接口方法。\n·iftable_：存储了该类在接口实现（可能是父类的接口实现关系）实现关系上的信息，包括继承了哪些接口类，实际的接口方法。\n类加载之后Class和Instance的内存占用 图8-14　reference_instance_offsets_说明\n以下为参考代码 ClassLinker EnsureResolved mirror::Class* ClassLinker::EnsureResolved(Thread* self, const char* descriptor, mirror::Class* klass) { // For temporary classes we must wait for them to be retired.  if (init_done_ \u0026amp;\u0026amp; klass-\u0026gt;IsTemp()) { CHECK(!klass-\u0026gt;IsResolved()); if (klass-\u0026gt;IsErroneous()) { ThrowEarlierClassFailure(klass); return nullptr; } ShouldUseInterpreterEntrypoint bool ClassLinker::ShouldUseInterpreterEntrypoint(ArtMethod* method, const void* quick_code) { if (UNLIKELY(method-\u0026gt;IsNative() || method-\u0026gt;IsProxyMethod())) { return false; } if (quick_code == nullptr) { return true; } ...... } GetQuickToInterpreterBridge // Return the address of quick stub code for bridging from quick code to the interpreter. extern \u0026#34;C\u0026#34; void art_quick_to_interpreter_bridge(ArtMethod*); static inline const void* GetQuickToInterpreterBridge() { return reinterpret_cast\u0026lt;const void*\u0026gt;(art_quick_to_interpreter_bridge); } ThrowEarlierClassFailure void ClassLinker::ThrowEarlierClassFailure(ObjPtr\u0026lt;mirror::Class\u0026gt; c, bool wrap_in_no_class_def) { // The class failed to initialize on a previous attempt, so we want to throw  // a NoClassDefFoundError (v2 2.17.5). The exception to this rule is if we  // failed in verification, in which case v2 5.4.1 says we need to re-throw  // the previous error.  Runtime* const runtime = Runtime::Current(); if (!runtime-\u0026gt;IsAotCompiler()) { // Give info if this occurs at runtime.  std::string extra; if (GetVerifyError(c) != nullptr) { ObjPtr\u0026lt;mirror::Object\u0026gt; verify_error = GetVerifyError(c); if (verify_error-\u0026gt;IsClass()) { extra = mirror::Class::PrettyDescriptor(verify_error-\u0026gt;AsClass()); } else { extra = verify_error-\u0026gt;AsThrowable()-\u0026gt;Dump(); } } LOG(INFO) \u0026lt;\u0026lt; \u0026#34;Rejecting re-init on previously-failed class \u0026#34; \u0026lt;\u0026lt; c-\u0026gt;PrettyClass() \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; extra;//the stack log of NoClassDefFoundError came from here  } GetVerifyError static mirror::Object* GetVerifyError(ObjPtr\u0026lt;mirror::Class\u0026gt; c) REQUIRES_SHARED(Locks::mutator_lock_) { ObjPtr\u0026lt;mirror::ClassExt\u0026gt; ext(c-\u0026gt;GetExtData()); if (ext == nullptr) { return nullptr; } else { return ext-\u0026gt;GetVerifyError(); } } art/runtime/mirror/class-inl.h\nClass::GetExtData HeapReference\u0026lt;ClassExt\u0026gt; ext_data_; template\u0026lt;VerifyObjectFlags kVerifyFlags, ReadBarrierOption kReadBarrierOption\u0026gt; inline ClassExt* Class::GetExtData() { return GetFieldObject\u0026lt;ClassExt, kVerifyFlags, kReadBarrierOption\u0026gt;( OFFSET_OF_OBJECT_MEMBER(Class, ext_data_)); } art/runtime/mirror/class_ext.h\nclass_ext.h.GetVerifyError // C++ mirror of dalvik.system.ClassExt class MANAGED ClassExt : public Object { // The saved verification error of this class.  HeapReference\u0026lt;Object\u0026gt; verify_error_; Object* GetVerifyError() REQUIRES_SHARED(Locks::mutator_lock_) { return GetFieldObject\u0026lt;ClassExt\u0026gt;(OFFSET_OF_OBJECT_MEMBER(ClassExt, verify_error_)); } } art/runtime/oat_file-inl.h\noat_file-inl.h.GetQuickCode inline const void* OatFile::OatMethod::GetQuickCode() const { return GetOatPointer\u0026lt;const void*\u0026gt;(GetCodeOffset()); } inline uint32_t OatFile::OatMethod::GetCodeOffset() const { return (GetQuickCodeSize() == 0) ? 0 : code_offset_; } art/runtime/runtime.h\nruntime.h.IsAotCompiler // IsAotCompiler for compilers that don\u0026#39;t have a running runtime. Only dex2oat currently.  bool IsAotCompiler() const { return !UseJitCompilation() \u0026amp;\u0026amp; IsCompiler(); } // IsCompiler is any runtime which has a running compiler, either dex2oat or JIT.  bool IsCompiler() const { return compiler_callbacks_ != nullptr; } art/runtime/thread.cc\nThread::ThrowNewWrappedException void Thread::ThrowNewWrappedException(const char* exception_class_descriptor, const char* msg) { DCHECK(!runtime-\u0026gt;IsStarted() || exception_class-\u0026gt;IsThrowableClass()); Handle\u0026lt;mirror::Throwable\u0026gt; exception( hs.NewHandle(ObjPtr\u0026lt;mirror::Throwable\u0026gt;::DownCast(exception_class-\u0026gt;AllocObject(this)))); ArtMethod* exception_init_method = exception_class-\u0026gt;FindConstructor(signature, cl-\u0026gt;GetImagePointerSize()); InvokeWithJValues(soa, ref.get(), exception_init_method, jv_args); if (LIKELY(!IsExceptionPending())) { SetException(exception.Get()); } Thread::SetException void Thread::SetException(ObjPtr\u0026lt;mirror::Throwable\u0026gt; new_exception) { CHECK(new_exception != nullptr); // TODO: DCHECK(!IsExceptionPending());  tlsPtr_.exception = new_exception.Ptr(); } libcore/dalvik/src/main/java/dalvik/system/BaseDexClassLoader.java\nBaseDexClassLoader.findClass @Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { List\u0026lt;Throwable\u0026gt; suppressedExceptions = new ArrayList\u0026lt;Throwable\u0026gt;(); Class c = pathList.findClass(name, suppressedExceptions); if (c == null) { ClassNotFoundException cnfe = new ClassNotFoundException( \u0026#34;Didn\u0026#39;t find class \\\u0026#34;\u0026#34; + name + \u0026#34;\\\u0026#34; on path: \u0026#34; + pathList); for (Throwable t : suppressedExceptions) { cnfe.addSuppressed(t); } throw cnfe; } return c; } "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/",
	"title": "系统绘制",
	"tags": [],
	"description": "",
	"content": "系统绘制 探索总结系统绘制知识\n Graphics     measurelayoutdraw    measure      Vsync     Vsync_SurfaceFlinger     硬件加速绘制     绘制原理     软件绘制     "
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E7%BB%98%E5%88%B6%E5%8E%9F%E7%90%86/",
	"title": "绘制原理",
	"tags": [],
	"description": "",
	"content": "流程原理 ViewRootImpl.setView /** * We have one child */ public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) { // If the application owns the surface, don\u0026#39;t enable hardware acceleration  if (mSurfaceHolder == null) { // While this is supposed to enable only, it can effectively disable  // the acceleration too.  enableHardwareAcceleration(attrs); } // Schedule the first layout -before- adding to the window  // manager, to make sure we do the relayout before receiving  // any other events from the system.  requestLayout(); //mWindowSession是一个aidl，ViewRootImpl利用它来和WindowManagerService交互  //mWindow是一个aidl，WindowManagerService可以利用这个对象与服务端交互  res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); } enableHardwareAcceleration private void enableHardwareAcceleration(WindowManager.LayoutParams attrs) { // Try to enable hardware acceleration if requested  final boolean hardwareAccelerated = (attrs.flags \u0026amp; WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED) != 0; if (hardwareAccelerated) { mAttachInfo.mThreadedRenderer = ThreadedRenderer.create(mContext, translucent, attrs.getTitle().toString()); if (mAttachInfo.mThreadedRenderer != null) { mAttachInfo.mHardwareAccelerated = mAttachInfo.mHardwareAccelerationRequested = true; } } } 创建ThreadedRenderer /** * Creates a threaded renderer using OpenGL. * * @param translucent True if the surface is translucent, false otherwise * * @return A threaded renderer backed by OpenGL. */ public static ThreadedRenderer create(Context context, boolean translucent, String name) { ThreadedRenderer renderer = null; if (isAvailable()) { renderer = new ThreadedRenderer(context, translucent, name); } return renderer; } ThreadedRenderer(Context context, boolean translucent, String name) { long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); mIsOpaque = !translucent; mNativeProxy = nCreateProxy(translucent, rootNodePtr); nSetName(mNativeProxy, name); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nstatic jlong android_view_ThreadedRenderer_createRootRenderNode(JNIEnv* env, jobject clazz) { RootRenderNode* node = new RootRenderNode(env); node-\u0026gt;incStrong(0); node-\u0026gt;setName(\u0026#34;RootRenderNode\u0026#34;); return reinterpret_cast\u0026lt;jlong\u0026gt;(node); } /** * Adopts an existing native render node. */ public static RenderNode adopt(long nativePtr) { return new RenderNode(nativePtr); } 创建RendeProxy static jlong android_view_ThreadedRenderer_createProxy(JNIEnv* env, jobject clazz, jboolean translucent, jlong rootRenderNodePtr) { RootRenderNode* rootRenderNode = reinterpret_cast\u0026lt;RootRenderNode*\u0026gt;(rootRenderNodePtr); ContextFactoryImpl factory(rootRenderNode); return (jlong) new RenderProxy(translucent, rootRenderNode, \u0026amp;factory); } frameworks/base/libs/hwui/renderthread/RenderProxy.cpp\nRenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { } 创建RenderThread RenderThread\u0026amp; RenderThread::getInstance() { // This is a pointer because otherwise __cxa_finalize  // will try to delete it like a Good Citizen but that causes us to crash  // because we don\u0026#39;t want to delete the RenderThread normally.  static RenderThread* sInstance = new RenderThread(); gHasRenderThreadInstance = true; return *sInstance; } RenderThread::RenderThread() : ThreadBase() , mVsyncSource(nullptr) , mVsyncRequested(false) , mFrameCallbackTaskPending(false) , mRenderState(nullptr) , mEglManager(nullptr) , mVkManager(nullptr) { Properties::load(); start(\u0026#34;RenderThread\u0026#34;); } graph TB Thread--\u0026gt;ThreadBase ThreadBase--\u0026gt;ReanderThread 启动RenderThread bool RenderThread::threadLoop() { setpriority(PRIO_PROCESS, 0, PRIORITY_DISPLAY); if (gOnStartHook) { gOnStartHook(); } initThreadLocals(); while (true) { waitForWork(); processQueue(); ...... requestVsync(); } return false; } void RenderThread::initThreadLocals() { mDisplayInfo = DeviceInfo::queryDisplayInfo(); nsecs_t frameIntervalNanos = static_cast\u0026lt;nsecs_t\u0026gt;(1000000000 / mDisplayInfo.fps); mTimeLord.setFrameInterval(frameIntervalNanos); initializeDisplayEventReceiver(); mEglManager = new EglManager(*this); mRenderState = new RenderState(*this); mVkManager = new VulkanManager(*this); mCacheManager = new CacheManager(mDisplayInfo); } 配置DisplayEventReceiver的fd监听 void RenderThread::initializeDisplayEventReceiver() { LOG_ALWAYS_FATAL_IF(mVsyncSource, \u0026#34;Initializing a second DisplayEventReceiver?\u0026#34;); if (!Properties::isolatedProcess) { auto receiver = std::make_unique\u0026lt;DisplayEventReceiver\u0026gt;(); status_t status = receiver-\u0026gt;initCheck(); // Register the FD  mLooper-\u0026gt;addFd(receiver-\u0026gt;getFd(), 0, Looper::EVENT_INPUT, RenderThread::displayEventReceiverCallback, this); mVsyncSource = new DisplayEventReceiverWrapper(std::move(receiver)); } else { mVsyncSource = new DummyVsyncSource(this); } } frameworks/base/libs/hwui/thread/ThreadBase.h\nThreadBase.waitForWork void waitForWork() { nsecs_t nextWakeup; { std::unique_lock lock{mLock}; nextWakeup = mQueue.nextWakeup(lock); } int timeout = -1; if (nextWakeup \u0026lt; std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max()) { timeout = ns2ms(nextWakeup - WorkQueue::clock::now()); if (timeout \u0026lt; 0) timeout = 0; } int result = mLooper-\u0026gt;pollOnce(timeout); LOG_ALWAYS_FATAL_IF(result == Looper::POLL_ERROR, \u0026#34;RenderThread Looper POLL_ERROR!\u0026#34;); } nsecs_t nextWakeup(std::unique_lock\u0026lt;std::mutex\u0026gt;\u0026amp; lock) { if (mWorkQueue.empty()) { return std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max(); } else { return std::begin(mWorkQueue)-\u0026gt;runAt; } } 加入同步任务 RenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { mContext = mRenderThread.queue().runSync([\u0026amp;]() -\u0026gt; CanvasContext* { return CanvasContext::create(mRenderThread, translucent, rootRenderNode, contextFactory); }); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext, rootRenderNode); } ThreadBase.h\nWorkQueue\u0026amp; queue() { return mQueue; } frameworks/base/libs/hwui/thread/WorkQueue.h\ntemplate \u0026lt;class F\u0026gt; auto runSync(F\u0026amp;\u0026amp; func) -\u0026gt; decltype(func()) { std::packaged_task\u0026lt;decltype(func())()\u0026gt; task{std::forward\u0026lt;F\u0026gt;(func)}; post([\u0026amp;task]() { std::invoke(task); }); return task.get_future().get(); }; template \u0026lt;class F\u0026gt; void post(F\u0026amp;\u0026amp; func) { postAt(0, std::forward\u0026lt;F\u0026gt;(func)); } template \u0026lt;class F\u0026gt; void postAt(nsecs_t time, F\u0026amp;\u0026amp; func) { enqueue(WorkItem{time, std::function\u0026lt;void()\u0026gt;(std::forward\u0026lt;F\u0026gt;(func))}); } void enqueue(WorkItem\u0026amp;\u0026amp; item) { bool needsWakeup; { std::unique_lock _lock{mLock}; auto insertAt = std::find_if( std::begin(mWorkQueue), std::end(mWorkQueue), [time = item.runAt](WorkItem \u0026amp; item) { return item.runAt \u0026gt; time; }); needsWakeup = std::begin(mWorkQueue) == insertAt; mWorkQueue.emplace(insertAt, std::move(item)); } if (needsWakeup) { mWakeFunc();//ThreadBase构造时设置的: mLooper-\u0026gt;wake()  } } Looper唤醒后执行processQueue void processQueue() { mQueue.process(); } void process() { auto now = clock::now(); std::vector\u0026lt;WorkItem\u0026gt; toProcess; { std::unique_lock _lock{mLock}; if (mWorkQueue.empty()) return; toProcess = std::move(mWorkQueue); auto moveBack = find_if(std::begin(toProcess), std::end(toProcess), [\u0026amp;now](WorkItem\u0026amp; item) { return item.runAt \u0026gt; now; }); if (moveBack != std::end(toProcess)) { mWorkQueue.reserve(std::distance(moveBack, std::end(toProcess)) + 5); std::move(moveBack, std::end(toProcess), std::back_inserter(mWorkQueue)); toProcess.erase(moveBack, std::end(toProcess)); } } for (auto\u0026amp; item : toProcess) { item.work(); } } WorkQueue和WorkItem结构 WorkQueue std::function\u0026lt;void()\u0026gt; mWakeFunc; std::vector\u0026lt;WorkItem\u0026gt; mWorkQueue; struct WorkItem { nsecs_t runAt; std::function\u0026lt;void()\u0026gt; work; }; 执行任务CanvasContext::create frameworks/base/libs/hwui/renderthread/CanvasContext.cpp\n根据pipelineType创建对应的CanvasContext CanvasContext* CanvasContext::create(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) { auto renderType = Properties::getRenderPipelineType(); switch (renderType) { case RenderPipelineType::OpenGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;OpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaOpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaVulkan: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaVulkanPipeline\u0026gt;(thread)); default: LOG_ALWAYS_FATAL(\u0026#34;canvas context type %d not supported\u0026#34;, (int32_t)renderType); break; } return nullptr; } RenderPipeLine类设计 graph TB IRenderPipeline--\u0026gt;OpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaOpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaVulkanPipeline CanvasContext::CanvasContext(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory, std::unique_ptr\u0026lt;IRenderPipeline\u0026gt; renderPipeline) : mRenderThread(thread) , mGenerationID(0) , mOpaque(!translucent) , mAnimationContext(contextFactory-\u0026gt;createAnimationContext(mRenderThread.timeLord())) , mJankTracker(\u0026amp;thread.globalProfileData(), thread.mainDisplayInfo()) , mProfiler(mJankTracker.frames()) , mContentDrawBounds(0, 0, 0, 0) , mRenderPipeline(std::move(renderPipeline)) { rootRenderNode-\u0026gt;makeRoot(); mRenderNodes.emplace_back(rootRenderNode); mRenderThread.renderState().registerCanvasContext(this); mProfiler.setDensity(mRenderThread.mainDisplayInfo().density); } 执行任务mDrawFrameTask.setContext void DrawFrameTask::setContext(RenderThread* thread, CanvasContext* context, RenderNode* targetNode) { mRenderThread = thread; mContext = context; mTargetNode = targetNode; } requestLayout 策划下一帧 mWindowSession.addToDisplay app进程和wms所在的sytemserver进程通信的binder frameworks/base/core/java/android/view/IWindow.aidl\n/** * API back to a client window that the Window Manager uses to inform it of * interesting things happening. */ oneway interface IWindow {} frameworks/base/core/java/android/view/IWindowSession.aidl\n/** * System private per-application interface to the window manager. */ interface IWindowSession {} frameworks/base/services/core/java/com/android/server/wm/Session.java\nSession.addToDisplay,WMS.addWindow @Override public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId, outFrame, outContentInsets, outStableInsets, outOutsets, outDisplayCutout, outInputChannel); } public int addWindow(Session session, IWindow client, int seq, LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { //WindowState用来描述一个Window  //生成WindowState对象，它是ViewRootImpl 在WindowManager Service端的代表。在它的构造函数里，WindowState 会生成IWindowId.Stub 对象和DeathRecipient对象来分别监听Focus和窗口死亡的信息  final WindowState win = new WindowState(this, session, client, token, parentWindow, appOp[0], seq, attrs, viewVisibility, session.mUid, session.mCanAddInternalSystemWindow); //创建用于通信的SocketPair , 将其传给InputManagerService, 用于接下来的用户输入事件对应的响应窗口（参考Android的用户输入处理）  final boolean openInputChannels = (outInputChannel != null \u0026amp;\u0026amp; (attrs.inputFeatures \u0026amp; INPUT_FEATURE_NO_INPUT_CHANNEL) == 0); if (openInputChannels) { win.openInputChannel(outInputChannel); } //创建了一个Surface Session 并将Surface Session，WindowSession 还有WindowState 三者关联起来.  win.attach(); //mWindowMap是WindowManagerService用来保存当前所有Window新的的集合  mWindowMap.put(client.asBinder(), win); //一个token下会有多个win state。 其实token与PhoneWindow是一一对应的。  win.mToken.addWindow(win); } frameworks/base/services/core/java/com/android/server/wm/WindowState.java\nopenInputChannel void openInputChannel(InputChannel outInputChannel) { if (mInputChannel != null) { throw new IllegalStateException(\u0026#34;Window already has an input channel.\u0026#34;); } String name = getName(); InputChannel[] inputChannels = InputChannel.openInputChannelPair(name);//refer to TouchEventNative.md  mInputChannel = inputChannels[0]; mClientChannel = inputChannels[1]; mInputWindowHandle.inputChannel = inputChannels[0]; if (outInputChannel != null) { mClientChannel.transferTo(outInputChannel); mClientChannel.dispose(); mClientChannel = null; } else { // If the window died visible, we setup a dummy input channel, so that taps  // can still detected by input monitor channel, and we can relaunch the app.  // Create dummy event receiver that simply reports all events as handled.  mDeadWindowEventReceiver = new DeadWindowEventReceiver(mClientChannel); } mService.mInputManager.registerInputChannel(mInputChannel, mInputWindowHandle);//refer to TouchEventNative.md  } attach void attach() { mSession.windowAddedLocked(mAttrs.packageName); } void windowAddedLocked(String packageName) { if (mSurfaceSession == null) { mSurfaceSession = new SurfaceSession(); mService.mSessions.add(this); } } 创建SurfaceSession /** * An instance of this class represents a connection to the surface * flinger, from which you can create one or more Surface instances that will * be composited to the screen. */ public final class SurfaceSession { // Note: This field is accessed by native code.  private long mNativeClient; // SurfaceComposerClient* } /** Create a new connection with the surface flinger. */ public SurfaceSession() { mNativeClient = nativeCreate(); } frameworks/base/core/jni/android_view_SurfaceSession.cpp\nstatic jlong nativeCreate(JNIEnv* env, jclass clazz) { SurfaceComposerClient* client = new SurfaceComposerClient(); client-\u0026gt;incStrong((void*)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(client); } 创建SurfaceComposerClient void SurfaceComposerClient::onFirstRef() { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService());//sf 就是SurfaceFlinger Service  if (sf != 0 \u0026amp;\u0026amp; mStatus == NO_INIT) { auto rootProducer = mParent.promote(); sp\u0026lt;ISurfaceComposerClient\u0026gt; conn; conn = (rootProducer != nullptr) ? sf-\u0026gt;createScopedConnection(rootProducer) : sf-\u0026gt;createConnection(); if (conn != 0) { mClient = conn; mStatus = NO_ERROR; } } } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\n通知SurfaceFlinger.createConnection sp\u0026lt;ISurfaceComposerClient\u0026gt; SurfaceFlinger::createConnection() { return initClient(new Client(this)); } frameworks/native/services/surfaceflinger/Client.h\n创建Client作为BnSurfaceComposerClient class Client : public BnSurfaceComposerClient { public: ... void attachLayer(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle, const sp\u0026lt;Layer\u0026gt;\u0026amp; layer); void detachLayer(const Layer* layer); ... private: // ISurfaceComposerClient interface。 gbp很重要，它维护这一个应用程序的渲染 Buffer队列  virtual status_t createSurface(...sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp); virtual status_t destroySurface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle); //跨进程通信方法  virtual status_t onTransact(uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags); ... // constant  sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; // protected by mLock  DefaultKeyedVector\u0026lt; wp\u0026lt;IBinder\u0026gt;, wp\u0026lt;Layer\u0026gt; \u0026gt; mLayers; // 一个应用程序的所有Layer  ... }; performTraversals private void performTraversals() { // Execute enqueued actions on every traversal in case a detached view enqueued an action  host.dispatchAttachedToWindow(mAttachInfo, 0); relayoutResult = relayoutWindow(params, viewVisibility, insetsPending); if (mSurface.isValid()) { // If we are creating a new surface, then we need to  // completely redraw it. Also, when we get to the  // point of drawing it we will hold off and schedule  // a new traversal instead. This is so we can tell the  // window manager about all of the windows being displayed  // before actually drawing them, so it can display then  // all at once.  newSurface = true; mFullRedrawNeeded = true; mPreviousTransparentRegion.setEmpty(); // Only initialize up-front if transparent regions are not  // requested, otherwise defer to see if the entire window  // will be transparent  if (mAttachInfo.mThreadedRenderer != null) { hwInitialized = mAttachInfo.mThreadedRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { // Don\u0026#39;t pre-allocate if transparent regions  // are requested as they may not be needed  mSurface.allocateBuffers(); } } } // Ask host how big it wants to be  performMeasure(childWidthMeasureSpec, childHeightMeasureSpec); ...... performLayout(lp, mWidth, mHeight); ...... performDraw(); relayoutWindow private int relayoutWindow(WindowManager.LayoutParams params, int viewVisibility, boolean insetsPending) throws RemoteException { int relayoutResult = mWindowSession.relayout(mWindow, mSeq, params, (int) (mView.getMeasuredWidth() * appScale + 0.5f), (int) (mView.getMeasuredHeight() * appScale + 0.5f), viewVisibility, insetsPending ? WindowManagerGlobal.RELAYOUT_INSETS_PENDING : 0, frameNumber, mWinFrame, mPendingOverscanInsets, mPendingContentInsets, mPendingVisibleInsets, mPendingStableInsets, mPendingOutsets, mPendingBackDropFrame, mPendingDisplayCutout, mPendingMergedConfiguration, mSurface); } @Override public int relayout(IWindow window, int seq, WindowManager.LayoutParams attrs, int requestedWidth, int requestedHeight, int viewFlags, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper cutout, MergedConfiguration mergedConfiguration, Surface outSurface) { int res = mService.relayoutWindow(this, window, seq, attrs, requestedWidth, requestedHeight, viewFlags, flags, frameNumber, outFrame, outOverscanInsets, outContentInsets, outVisibleInsets, outStableInsets, outsets, outBackdropFrame, cutout, mergedConfiguration, outSurface); return res; } frameworks/base/services/core/java/com/android/server/wm/WindowManagerService.java\npublic int relayoutWindow(Session session, IWindow client, int seq, LayoutParams attrs, int requestedWidth, int requestedHeight, int viewVisibility, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outOutsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper outCutout, MergedConfiguration mergedConfiguration, Surface outSurface) { result = createSurfaceControl(outSurface, result, win, winAnimator); } private int createSurfaceControl(Surface outSurface, int result, WindowState win,WindowStateAnimator winAnimator) { ... surfaceController = winAnimator.createSurfaceLocked(win.mAttrs.type, win.mOwnerUid); ... surfaceController.getSurface(outSurface); } WindowSurfaceController createSurfaceLocked(int windowType, int ownerUid) { mSurfaceController = new WindowSurfaceController(mSession.mSurfaceSession, attrs.getTitle().toString(), width, height, format, flags, this, windowType, ownerUid); } new WindowSurfaceController() public WindowSurfaceController(SurfaceSession s, String name, int w, int h, int format, int flags, WindowStateAnimator animator, int windowType, int ownerUid) { final SurfaceControl.Builder b = win.makeSurface() .setParent(win.getSurfaceControl()) .setName(name) .setSize(w, h) .setFormat(format) .setFlags(flags) .setMetadata(windowType, ownerUid); mSurfaceControl = b.build(); } /** * Construct a new {@link SurfaceControl} with the set parameters. */ public SurfaceControl build() { return new SurfaceControl(mSession, mName, mWidth, mHeight, mFormat, mFlags, mParent, mWindowType, mOwnerUid); } /** Good practice is to first create the surface with the {@link #HIDDEN} flag * specified, open a transaction, set the surface layer, layer stack, alpha, * and position, call {@link #show} if appropriate, and close the transaction. **/ private SurfaceControl(SurfaceSession session, String name, int w, int h, int format, int flags, SurfaceControl parent, int windowType, int ownerUid) throws OutOfResourcesException, IllegalArgumentException { mNativeObject = nativeCreate(session, name, w, h, format, flags, parent != null ? parent.mNativeObject : 0, windowType, ownerUid); } frameworks/base/core/jni/android_view_SurfaceControl.cpp\nstatic jlong nativeCreate(JNIEnv* env, jclass clazz, jobject sessionObj, jstring nameStr, jint w, jint h, jint format, jint flags, jlong parentObject, jint windowType, jint ownerUid) { ScopedUtfChars name(env, nameStr); //这个client其实就是前面创建的SurfaceComposerClinent  sp\u0026lt;SurfaceComposerClient\u0026gt; client(android_view_SurfaceSession_getClient(env, sessionObj)); SurfaceControl *parent = reinterpret_cast\u0026lt;SurfaceControl*\u0026gt;(parentObject); sp\u0026lt;SurfaceControl\u0026gt; surface; status_t err = client-\u0026gt;createSurfaceChecked( String8(name.c_str()), w, h, format, \u0026amp;surface, flags, parent, windowType, ownerUid); surface-\u0026gt;incStrong((void *)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } status_t SurfaceComposerClient::createSurfaceChecked( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, sp\u0026lt;SurfaceControl\u0026gt;* outSurface, uint32_t flags, SurfaceControl* parent, int32_t windowType, int32_t ownerUid) { sp\u0026lt;SurfaceControl\u0026gt; sur; sp\u0026lt;IBinder\u0026gt; handle; sp\u0026lt;IBinder\u0026gt; parentHandle; sp\u0026lt;IGraphicBufferProducer\u0026gt; gbp; if (parent != nullptr) { parentHandle = parent-\u0026gt;getHandle(); } err = mClient-\u0026gt;createSurface(name, w, h, format, flags, parentHandle, windowType, ownerUid, \u0026amp;handle, \u0026amp;gbp); if (err == NO_ERROR) { *outSurface = new SurfaceControl(this, handle, gbp, true /* owned */); } return err; } status_t Client::createSurface( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, const sp\u0026lt;IBinder\u0026gt;\u0026amp; parentHandle, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp) { //postMessageSync到surfaceFlinger的主线程中处理消息任务，如下:  result = flinger-\u0026gt;createLayer(name, client, w, h, format, flags, windowType, ownerUid, handle, gbp, parent); } createLayer status_t SurfaceFlinger::createLayer( const String8\u0026amp; name, const sp\u0026lt;Client\u0026gt;\u0026amp; client, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* parent) { sp\u0026lt;Layer\u0026gt; layer; String8 uniqueName = getUniqueLayerName(name); switch (flags \u0026amp; ISurfaceComposerClient::eFXSurfaceMask) { case ISurfaceComposerClient::eFXSurfaceNormal: result = createBufferLayer(client, uniqueName, w, h, flags, format, handle, gbp, \u0026amp;layer); break; } result = addClientLayer(client, *handle, *gbp, layer, *parent); return result; } createBufferLayer status_t SurfaceFlinger::createBufferLayer(const sp\u0026lt;Client\u0026gt;\u0026amp; client, const String8\u0026amp; name, uint32_t w, uint32_t h, uint32_t flags, PixelFormat\u0026amp; format, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* outLayer) { // initialize the surfaces  switch (format) { case PIXEL_FORMAT_TRANSPARENT: case PIXEL_FORMAT_TRANSLUCENT: format = PIXEL_FORMAT_RGBA_8888; break; case PIXEL_FORMAT_OPAQUE: format = PIXEL_FORMAT_RGBX_8888; break; } sp\u0026lt;BufferLayer\u0026gt; layer = new BufferLayer(this, client, name, w, h, flags); status_t err = layer-\u0026gt;setBuffers(w, h, format, flags); if (err == NO_ERROR) { *handle = layer-\u0026gt;getHandle(); *gbp = layer-\u0026gt;getProducer(); *outLayer = layer; } return err; } frameworks/native/services/surfaceflinger/BufferLayer.cpp\nBufferLayer::onFirstRef void BufferLayer::onFirstRef() { // Creates a custom BufferQueue for SurfaceFlingerConsumer to use  sp\u0026lt;IGraphicBufferProducer\u0026gt; producer; sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer; BufferQueue::createBufferQueue(\u0026amp;producer, \u0026amp;consumer, true); //MonitoredProducer只是一个装饰类，它实际功能都委托给构造它的参数producer  mProducer = new MonitoredProducer(producer, mFlinger, this); mConsumer = new BufferLayerConsumer(consumer, mFlinger-\u0026gt;getRenderEngine(), mTextureName, this); const sp\u0026lt;const DisplayDevice\u0026gt; hw(mFlinger-\u0026gt;getDefaultDisplayDevice()); updateTransformHint(hw); } frameworks/native/libs/gui/BufferQueue.cpp\nBufferQueue::createBufferQueue void BufferQueue::createBufferQueue(sp\u0026lt;IGraphicBufferProducer\u0026gt;* outProducer, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* outConsumer, bool consumerIsSurfaceFlinger) { sp\u0026lt;BufferQueueCore\u0026gt; core(new BufferQueueCore()); sp\u0026lt;IGraphicBufferProducer\u0026gt; producer(new BufferQueueProducer(core, consumerIsSurfaceFlinger)); sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer(new BufferQueueConsumer(core)); *outProducer = producer; *outConsumer = consumer; } frameworks/native/libs/ui/include/ui/BufferQueueDefs.h\nNUM_BUFFER_SLOTS namespace android { namespace BufferQueueDefs { // BufferQueue will keep track of at most this value of buffers.  // Attempts at runtime to increase the number of buffers past this  // will fail.  static constexpr int NUM_BUFFER_SLOTS = 64; } // namespace BufferQueueDefs } // namespace android  frameworks/native/libs/gui/include/gui/BufferQueueCore.h\nBufferQueueCore // mQueue is a FIFO of queued buffers used in synchronous mode.  Fifo mQueue; // mFreeSlots contains all of the slots which are FREE and do not currently  // have a buffer attached.  std::set\u0026lt;int\u0026gt; mFreeSlots; // mFreeBuffers contains all of the slots which are FREE and currently have  // a buffer attached.  std::list\u0026lt;int\u0026gt; mFreeBuffers; // mConsumerListener is used to notify the connected consumer of  // asynchronous events that it may wish to react to. It is initially  // set to NULL and is written by consumerConnect and consumerDisconnect.  sp\u0026lt;IConsumerListener\u0026gt; mConsumerListener; frameworks/native/libs/gui/BufferQueueProducer.cpp\nBufferQueueProducer class BufferQueueProducer : public BnGraphicBufferProducer, private IBinder::DeathRecipient { frameworks/native/libs/gui/include/gui/BufferQueueConsumer.h\nBufferQueueConsumer class BufferQueueConsumer : public BnGraphicBufferConsumer { // connect connects a consumer to the BufferQueue. Only one  // consumer may be connected, and when that consumer disconnects the  // BufferQueue is placed into the \u0026#34;abandoned\u0026#34; state, causing most  // interactions with the BufferQueue by the producer to fail.  // controlledByApp indicates whether the consumer is controlled by  // the application.  //  // consumerListener may not be NULL.  virtual status_t connect(const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp); } getSurface void getSurface(Surface outSurface) { outSurface.copyFrom(mSurfaceControl); } copyFrom /** * Copy another surface to this one. This surface now holds a reference * to the same data as the original surface, and is -not- the owner. * This is for use by the window manager when returning a window surface * back from a client, converting it from the representation being managed * by the window manager to the representation the client uses to draw * in to it. * * @param other {@link SurfaceControl} to copy from. * */ public void copyFrom(SurfaceControl other) { long surfaceControlPtr = other.mNativeObject; long newNativeObject = nativeGetFromSurfaceControl(surfaceControlPtr); synchronized (mLock) { if (mNativeObject != 0) { nativeRelease(mNativeObject); } setNativeObjectLocked(newNativeObject); } } frameworks/base/core/jni/android_view_Surface.cpp\nstatic jlong nativeGetFromSurfaceControl(JNIEnv* env, jclass clazz, jlong surfaceControlNativeObj) { /* * This is used by the WindowManagerService just after constructing * a Surface and is necessary for returning the Surface reference to * the caller. At this point, we should only have a SurfaceControl. */ sp\u0026lt;SurfaceControl\u0026gt; ctrl(reinterpret_cast\u0026lt;SurfaceControl *\u0026gt;(surfaceControlNativeObj)); sp\u0026lt;Surface\u0026gt; surface(ctrl-\u0026gt;getSurface()); if (surface != NULL) { surface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); } return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } frameworks/native/libs/gui/SurfaceControl.cpp\nsp\u0026lt;Surface\u0026gt; SurfaceControl::getSurface() const { Mutex::Autolock _l(mLock); if (mSurfaceData == 0) { return generateSurfaceLocked(); } return mSurfaceData; } sp\u0026lt;Surface\u0026gt; SurfaceControl::generateSurfaceLocked() const { // This surface is always consumed by SurfaceFlinger, so the  // producerControlledByApp value doesn\u0026#39;t matter; using false.  //这个mGraphicBufferProducer其实就是上面分析的BufferQueueProducer  mSurfaceData = new Surface(mGraphicBufferProducer, false); return mSurfaceData; } Surface::Surface(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp; bufferProducer, bool controlledByApp) : mGraphicBufferProducer(bufferProducer), mAttachInfo.mThreadedRenderer.initialize(mSurface) /** * Initializes the threaded renderer for the specified surface. * @param surface The surface to render * @return True if the initialization was successful, false otherwise. */ boolean initialize(Surface surface) throws OutOfResourcesException { updateEnabledState(surface); nInitialize(mNativeProxy, surface); return status; } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nstatic void android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;Surface\u0026gt; surface = android_view_Surface_getSurface(env, jsurface); proxy-\u0026gt;initialize(surface); } RenderProxy::initialize void RenderProxy::initialize(const sp\u0026lt;Surface\u0026gt;\u0026amp; surface) { mRenderThread.queue().post( [ this, surf = surface ]() mutable { mContext-\u0026gt;setSurface(std::move(surf)); }); } CanvasContext::setSurface void CanvasContext::setSurface(sp\u0026lt;Surface\u0026gt;\u0026amp;\u0026amp; surface) { mNativeSurface = std::move(surface); ColorMode colorMode = mWideColorGamut ? ColorMode::WideColorGamut : ColorMode::Srgb; bool hasSurface = mRenderPipeline-\u0026gt;setSurface(mNativeSurface.get(), mSwapBehavior, colorMode); } frameworks/base/libs/hwui/renderthread/OpenGLPipeline.cpp\nOpenGLPipeline::setSurface bool OpenGLPipeline::setSurface(Surface* surface, SwapBehavior swapBehavior, ColorMode colorMode) { if (surface) { const bool wideColorGamut = colorMode == ColorMode::WideColorGamut; mEglSurface = mEglManager.createSurface(surface, wideColorGamut); } return false; } frameworks/base/libs/hwui/renderthread/EglManager.cpp\nEglManager::createSurface EGLSurface EglManager::createSurface(EGLNativeWindowType window, bool wideColorGamut) { initialize(); EGLSurface surface = eglCreateWindowSurface( mEglDisplay, wideColorGamut ? mEglConfigWideGamut : mEglConfig, window, attribs); return surface; } mSurface.allocateBuffers /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } static void nativeAllocateBuffers(JNIEnv* /* env */ , jclass /* clazz */, jlong nativeObject) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } surface-\u0026gt;allocateBuffers(); } Surface::allocateBuffers void Surface::allocateBuffers() { uint32_t reqWidth = mReqWidth ? mReqWidth : mUserWidth; uint32_t reqHeight = mReqHeight ? mReqHeight : mUserHeight; mGraphicBufferProducer-\u0026gt;allocateBuffers(reqWidth, reqHeight, mReqFormat, mReqUsage); } BufferQueueProducer::allocateBuffers void BufferQueueProducer::allocateBuffers(uint32_t width, uint32_t height, PixelFormat format, uint64_t usage) { Vector\u0026lt;sp\u0026lt;GraphicBuffer\u0026gt;\u0026gt; buffers; for (size_t i = 0; i \u0026lt; newBufferCount; ++i) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( allocWidth, allocHeight, allocFormat, BQ_LAYER_COUNT, allocUsage, allocName); status_t result = graphicBuffer-\u0026gt;initCheck(); buffers.push_back(graphicBuffer); } } frameworks/native/libs/ui/GraphicBuffer.cpp\nnew GraphicBuffer GraphicBuffer::GraphicBuffer(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t usage, std::string requestorName) : GraphicBuffer() { mInitCheck = initWithSize(inWidth, inHeight, inFormat, inLayerCount, usage, std::move(requestorName)); } status_t GraphicBuffer::initWithSize(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t inUsage, std::string requestorName) { GraphicBufferAllocator\u0026amp; allocator = GraphicBufferAllocator::get(); uint32_t outStride = 0; status_t err = allocator.allocate(inWidth, inHeight, inFormat, inLayerCount, inUsage, \u0026amp;handle, \u0026amp;outStride, mId, std::move(requestorName)); return err; } frameworks/native/libs/ui/GraphicBufferAllocator.cpp\nGraphicBufferAllocator GraphicBufferMapper\u0026amp; mMapper; const std::unique_ptr\u0026lt;const Gralloc2::Allocator\u0026gt; mAllocator; GraphicBufferAllocator::allocate status_t GraphicBufferAllocator::allocate(uint32_t width, uint32_t height, PixelFormat format, uint32_t layerCount, uint64_t usage, buffer_handle_t* handle, uint32_t* stride, uint64_t /*graphicBufferId*/, std::string requestorName) { Gralloc2::IMapper::BufferDescriptorInfo info = {}; info.width = width; info.height = height; info.layerCount = layerCount; info.format = static_cast\u0026lt;Gralloc2::PixelFormat\u0026gt;(format); info.usage = usage; Gralloc2::Error error = mAllocator-\u0026gt;allocate(info, stride, handle); } frameworks/native/libs/ui/include/ui/Gralloc2.h\n// A wrapper to IAllocator class Allocator { sp\u0026lt;IAllocator\u0026gt; mAllocator } Allocator::Allocator(const Mapper\u0026amp; mapper) : mMapper(mapper) { mAllocator = IAllocator::getService(); } Allocator::allocate Error Allocator::allocate(BufferDescriptor descriptor, uint32_t count, uint32_t* outStride, buffer_handle_t* outBufferHandles) const { Error error; auto ret = mAllocator-\u0026gt;allocate(descriptor, count, [\u0026amp;](const auto\u0026amp; tmpError, const auto\u0026amp; tmpStride, const auto\u0026amp; tmpBuffers) { error = tmpError; if (tmpError != Error::NONE) { return; } // import buffers  for (uint32_t i = 0; i \u0026lt; count; i++) { error = mMapper.importBuffer(tmpBuffers[i], \u0026amp;outBufferHandles[i]); if (error != Error::NONE) { for (uint32_t j = 0; j \u0026lt; i; j++) { mMapper.freeBuffer(outBufferHandles[j]); outBufferHandles[j] = nullptr; } return; } } *outStride = tmpStride; }); // make sure the kernel driver sees BC_FREE_BUFFER and closes the fds now  hardware::IPCThreadState::self()-\u0026gt;flushCommands(); return (ret.isOk()) ? error : kTransactionError; } hardware/interfaces/graphics/allocator/2.0/IAllocator.hal\ninterface IAllocator { /** * Allocates buffers with the properties specified by the descriptor. * * @param descriptor specifies the properties of the buffers to allocate. * @param count is the number of buffers to allocate. * @return error is NONE upon success. Otherwise, * BAD_DESCRIPTOR when the descriptor is invalid. * NO_RESOURCES when the allocation cannot be fulfilled at this * time. * UNSUPPORTED when any of the property encoded in the descriptor * is not supported. * @return stride is the number of pixels between two consecutive rows of * the buffers, when the concept of consecutive rows is defined. * Otherwise, it has no meaning. * @return buffers is an array of raw handles to the newly allocated * buffers. */ @entry @exit @callflow(next=\u0026#34;*\u0026#34;) allocate(BufferDescriptor descriptor, uint32_t count) generates (Error error, uint32_t stride, vec\u0026lt;handle\u0026gt; buffers); performDraw private boolean draw(boolean fullRedrawNeeded) { Surface surface = mSurface; if (!surface.isValid()) { return false; } if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { if (mAttachInfo.mThreadedRenderer != null \u0026amp;\u0026amp; mAttachInfo.mThreadedRenderer.isEnabled()) { mAttachInfo.mThreadedRenderer.draw(mView, mAttachInfo, this, callback); } else { drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty, surfaceInsets) } } } drawSoftware /** * @return true if drawing was successful, false if an error occurred */ private boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty, Rect surfaceInsets) { // Draw with software renderer.  final Canvas canvas; canvas = mSurface.lockCanvas(dirty); ...... mView.draw(canvas); ...... surface.unlockCanvasAndPost(canvas); } lockCanvas public Canvas lockCanvas(Rect inOutDirty) throws Surface.OutOfResourcesException, IllegalArgumentException { synchronized (mLock) { mLockedObject = nativeLockCanvas(mNativeObject, mCanvas, inOutDirty); return mCanvas; } } static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ANativeWindow_Buffer outBuffer; status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType, GraphicsJNI::defaultColorSpace()); SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits); } Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); if (dirtyRectPtr) { nativeCanvas-\u0026gt;clipRect(dirtyRect.left, dirtyRect.top, dirtyRect.right, dirtyRect.bottom, SkClipOp::kIntersect); } // Create another reference to the surface and return it. This reference  // should be passed to nativeUnlockCanvasAndPost in place of mNativeObject,  // because the latter could be replaced while the surface is locked.  sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } Surface::lock status_t Surface::lock(ANativeWindow_Buffer* outBuffer, ARect* inOutDirtyBounds) { ANativeWindowBuffer* out; int fenceFd = -1; status_t err = dequeueBuffer(\u0026amp;out, \u0026amp;fenceFd); sp\u0026lt;GraphicBuffer\u0026gt; backBuffer(GraphicBuffer::getSelf(out)); status_t res = backBuffer-\u0026gt;lockAsync( GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN, newDirtyRegion.bounds(), \u0026amp;vaddr, fenceFd); mLockedBuffer = backBuffer; outBuffer-\u0026gt;width = backBuffer-\u0026gt;width; outBuffer-\u0026gt;height = backBuffer-\u0026gt;height; outBuffer-\u0026gt;stride = backBuffer-\u0026gt;stride; outBuffer-\u0026gt;format = backBuffer-\u0026gt;format; outBuffer-\u0026gt;bits = vaddr; } Surface::dequeueBuffer int Surface::dequeueBuffer(android_native_buffer_t** buffer, int* fenceFd) { status_t result = mGraphicBufferProducer-\u0026gt;dequeueBuffer(\u0026amp;buf, \u0026amp;fence, reqWidth, reqHeight, reqFormat, reqUsage, \u0026amp;mBufferAge, enableFrameTimestamps ? \u0026amp;frameTimestamps : nullptr); sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; gbuf(mSlots[buf].buffer); if ((result \u0026amp; IGraphicBufferProducer::BUFFER_NEEDS_REALLOCATION) || gbuf == nullptr) { result = mGraphicBufferProducer-\u0026gt;requestBuffer(buf, \u0026amp;gbuf); } *buffer = gbuf.get(); return OK; } dequeuebuffer\nrequestbuffer\ndraw nativeUnlockCanvasAndPost static void nativeUnlockCanvasAndPost(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } // detach the canvas from the surface  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); nativeCanvas-\u0026gt;setBitmap(SkBitmap()); // unlock surface  status_t err = surface-\u0026gt;unlockAndPost(); } mAttachInfo.mThreadedRenderer.draw硬件绘制 硬件加速绘制\nBufferQueueProducer::dequeueBuffer status_t BufferQueueProducer::dequeueBuffer(int* outSlot, sp\u0026lt;android::Fence\u0026gt;* outFence, uint32_t width, uint32_t height, PixelFormat format, uint64_t usage, uint64_t* outBufferAge, FrameEventHistoryDelta* outTimestamps) { int found = BufferItem::INVALID_BUFFER_SLOT; while (found == BufferItem::INVALID_BUFFER_SLOT) { status_t status = waitForFreeSlotThenRelock(FreeSlotCaller::Dequeue, \u0026amp;found); } const sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; buffer(mSlots[found].mGraphicBuffer); *outSlot = found; if ((buffer == NULL) || buffer-\u0026gt;needsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { returnFlags |= BUFFER_NEEDS_REALLOCATION; } if (returnFlags \u0026amp; BUFFER_NEEDS_REALLOCATION) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( width, height, format, BQ_LAYER_COUNT, usage, {mConsumerName.string(), mConsumerName.size()}); status_t error = graphicBuffer-\u0026gt;initCheck(); } } waitForFreeSlotThenRelock status_t BufferQueueProducer::waitForFreeSlotThenRelock(FreeSlotCaller caller, int* found) const { // If we disconnect and reconnect quickly, we can be in a state where  // our slots are empty but we have many buffers in the queue. This can  // cause us to run out of memory if we outrun the consumer. Wait here if  // it looks like we have too many buffers queued up.  const int maxBufferCount = mCore-\u0026gt;getMaxBufferCountLocked(); bool tooManyBuffers = mCore-\u0026gt;mQueue.size() \u0026gt; static_cast\u0026lt;size_t\u0026gt;(maxBufferCount); if (tooManyBuffers) { BQ_LOGV(\u0026#34;%s: queue size is %zu, waiting\u0026#34;, callerString, mCore-\u0026gt;mQueue.size()); } else { // If in shared buffer mode and a shared buffer exists, always  // return it.  if (mCore-\u0026gt;mSharedBufferMode \u0026amp;\u0026amp; mCore-\u0026gt;mSharedBufferSlot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = mCore-\u0026gt;mSharedBufferSlot; } else { if (caller == FreeSlotCaller::Dequeue) { // If we\u0026#39;re calling this from dequeue, prefer free buffers  int slot = getFreeBufferLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else if (mCore-\u0026gt;mAllowAllocation) { *found = getFreeSlotLocked(); } } else { // If we\u0026#39;re calling this from attach, prefer free slots  int slot = getFreeSlotLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else { *found = getFreeBufferLocked(); } } } } } getFreeBufferLocked int BufferQueueProducer::getFreeBufferLocked() const { if (mCore-\u0026gt;mFreeBuffers.empty()) { return BufferQueueCore::INVALID_BUFFER_SLOT; } int slot = mCore-\u0026gt;mFreeBuffers.front(); mCore-\u0026gt;mFreeBuffers.pop_front(); return slot; } BufferQueueProducer::requestBuffer status_t BufferQueueProducer::requestBuffer(int slot, sp\u0026lt;GraphicBuffer\u0026gt;* buf) { mSlots[slot].mRequestBufferCalled = true; *buf = mSlots[slot].mGraphicBuffer; } SurfaceFlinger图像合成 frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\nvoid SurfaceFlinger::signalLayerUpdate() { mEventQueue-\u0026gt;invalidate(); } frameworks/native/services/surfaceflinger/MessageQueue.cpp\nvoid MessageQueue::invalidate() { mEvents-\u0026gt;requestNextVsync(); } frameworks/native/services/surfaceflinger/EventThread.cpp\nvoid EventThread::Connection::requestNextVsync() { mEventThread-\u0026gt;requestNextVsync(this); } void EventThread::requestNextVsync(const sp\u0026lt;EventThread::Connection\u0026gt;\u0026amp; connection) { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mMutex); if (mResyncWithRateLimitCallback) { mResyncWithRateLimitCallback(); } if (connection-\u0026gt;count \u0026lt; 0) { connection-\u0026gt;count = 0; mCondition.notify_all(); } } refertovsynclogic,gotomethod_cb_eventreceiver\nint MessageQueue::cb_eventReceiver(int fd, int events, void* data) { MessageQueue* queue = reinterpret_cast\u0026lt;MessageQueue*\u0026gt;(data); return queue-\u0026gt;eventReceiver(fd, events); } int MessageQueue::eventReceiver(int /*fd*/, int /*events*/) { ssize_t n; DisplayEventReceiver::Event buffer[8]; while ((n = DisplayEventReceiver::getEvents(\u0026amp;mEventTube, buffer, 8)) \u0026gt; 0) { for (int i = 0; i \u0026lt; n; i++) { if (buffer[i].header.type == DisplayEventReceiver::DISPLAY_EVENT_VSYNC) { mHandler-\u0026gt;dispatchInvalidate(); break; } } } return 1; } void MessageQueue::Handler::dispatchInvalidate() { if ((android_atomic_or(eventMaskInvalidate, \u0026amp;mEventMask) \u0026amp; eventMaskInvalidate) == 0) { mQueue.mLooper-\u0026gt;sendMessage(this, Message(MessageQueue::INVALIDATE)); } } void MessageQueue::Handler::handleMessage(const Message\u0026amp; message) { switch (message.what) { case INVALIDATE: android_atomic_and(~eventMaskInvalidate, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; case REFRESH: android_atomic_and(~eventMaskRefresh, \u0026amp;mEventMask); mQueue.mFlinger-\u0026gt;onMessageReceived(message.what); break; } } 于是进入 SF.onMessageReceived 方法，开始进行图形合成输出逻辑。\nvoid SurfaceFlinger::onMessageReceived(int32_t what) { switch (what) { case MessageQueue::INVALIDATE: { bool frameMissed = !mHadClientComposition \u0026amp;\u0026amp; mPreviousPresentFence != Fence::NO_FENCE \u0026amp;\u0026amp; (mPreviousPresentFence-\u0026gt;getSignalTime() == Fence::SIGNAL_TIME_PENDING); if (frameMissed) { mTimeStats.incrementMissedFrames(); if (mPropagateBackpressure) {// 丢帧且Backpressure则跳过此次Transaction和refresh  signalLayerUpdate(); break; } } bool refreshNeeded = handleMessageTransaction(); refreshNeeded |= handleMessageInvalidate(); refreshNeeded |= mRepaintEverything; if (refreshNeeded) { // Signal a refresh if a transaction modified the window state, a new buffer was latched,  // or if HWC has requested a full repaint  // 最终会调用 SF.handleMessageRefresh 方法  signalRefresh(); } break; } case MessageQueue::REFRESH: { handleMessageRefresh();//main  break; } } } void SurfaceFlinger::handleMessageRefresh() { nsecs_t refreshStartTime = systemTime(SYSTEM_TIME_MONOTONIC); // 如果图层有更新则执行 invalidate 过程  preComposition(refreshStartTime); // 重建每个显示屏的所有可见的 Layer 列表  rebuildLayerStacks(); // 更新 HWComposer 的 Layer  setUpHWComposer(); // 合成所有 Layer 的图像  doComposition(); // 回调每个 layer 的 onPostComposition 方法  postComposition(refreshStartTime); // 清空需要更新的 layers 列表  mLayersWithQueuedFrames.clear(); } 其他类结构参考 ViewRootImpl // These can be accessed by any thread, must be protected with a lock.  // Surface can never be reassigned or cleared (use Surface.clear()).  public final Surface mSurface = new Surface(); BufferQueueConsumer status_t BufferQueueConsumer::connect( const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp) { mCore-\u0026gt;mConsumerListener = consumerListener; mCore-\u0026gt;mConsumerControlledByApp = controlledByApp; return NO_ERROR; } Surface.java /** * Handle onto a raw buffer that is being managed by the screen compositor. * * \u0026lt;p\u0026gt;A Surface is generally created by or from a consumer of image buffers (such as a * {@link android.graphics.SurfaceTexture}, {@link android.media.MediaRecorder}, or * {@link android.renderscript.Allocation}), and is handed to some kind of producer (such as * {@link android.opengl.EGL14#eglCreateWindowSurface(android.opengl.EGLDisplay,android.opengl.EGLConfig,java.lang.Object,int[],int) OpenGL}, * {@link android.media.MediaPlayer#setSurface MediaPlayer}, or * {@link android.hardware.camera2.CameraDevice#createCaptureSession CameraDevice}) to draw * into.\u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Note:\u0026lt;/strong\u0026gt; A Surface acts like a * {@link java.lang.ref.WeakReference weak reference} to the consumer it is associated with. By * itself it will not keep its parent consumer from being reclaimed.\u0026lt;/p\u0026gt; */ public class Surface implements Parcelable { } frameworks/native/libs/gui/Surface.cpp\nSurface.cpp struct BufferSlot // mSurfaceTexture is the interface to the surface texture server. All  // operations on the surface texture client ultimately translate into  // interactions with the server using this interface.  sp\u0026lt;IGraphicBufferProducer\u0026gt; mGraphicBufferProducer; struct BufferSlot { sp\u0026lt;GraphicBuffer\u0026gt; buffer; Region dirtyRegion; }; // mSlots stores the buffers that have been allocated for each buffer slot.  // It is initialized to null pointers, and gets filled in with the result of  // IGraphicBufferProducer::requestBuffer when the client dequeues a buffer from a  // slot that has not yet been used. The buffer allocated to a slot will also  // be replaced if the requested buffer usage or geometry differs from that  // of the buffer allocated to a slot.  BufferSlot mSlots[NUM_BUFFER_SLOTS]; AttachInfo /** A set of information given to a view when it is attached to its parent window. */ final static class AttachInfo { } frameworks/base/libs/hwui/FrameInfo.h\nFrameInfo FrameInfoIndex enum class FrameInfoIndex { Flags = 0, IntendedVsync, Vsync, OldestInputEvent, NewestInputEvent, HandleInputStart, AnimationStart, PerformTraversalsStart, DrawStart, // End of UI frame info  SyncQueued, SyncStart, IssueDrawCommandsStart, SwapBuffers, FrameCompleted, DequeueBufferDuration, QueueBufferDuration, // Must be the last value!  // Also must be kept in sync with FrameMetrics.java#FRAME_STATS_COUNT  NumIndexes }; Looper wake void Looper::wake() { uint64_t inc = 1; ssize_t nWrite = TEMP_FAILURE_RETRY(write(mWakeEventFd, \u0026amp;inc, sizeof(uint64_t))); if (nWrite != sizeof(uint64_t)) { if (errno != EAGAIN) { LOG_ALWAYS_FATAL(\u0026#34;Could not write wake signal to fd %d: %s\u0026#34;, mWakeEventFd, strerror(errno)); } } } 参考 android-surfaceflinger启动与绘图原理\n"
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%80%9D%E6%83%B3/%E7%BB%A7%E6%89%BF%E5%92%8C%E7%BB%84%E5%90%88/",
	"title": "继承和组合",
	"tags": [],
	"description": "",
	"content": "组织结构形态 继承和组合对应着客观事物的组织结构形态，具体的说：\n 继承: 子类是父类，是有相同行为(方法)签名但实现不同的父类能力延伸和拓展，拥有父类的public访问和protect override能力 组合: 包裹类组合多个被包裹类，拥有多个被包裹类的public访问能力  访问权限可以由不同语言的访问限定符进行不同粒度的控制，而继承和组合最大的区别在于继承体系中子类对父类protect 方法的override能力(在子类实现中可能会调用super的相同方法)\n一般优化方式 继承 对于继承和组合对代码结构的优化，首先开始的是由客观事物形态决定的继承关系，在子类继承父类的同时，自身有很多功能的定制\n组合 将子类对每个功能的定义进行依赖关系梳理，每个功能以高内聚低耦合的组合方式在子类中使用，可以考虑使用android lifecycle这种观察者模式将每个功能类的对关键事件(生命周期)的监听进行分发，降低其在子类中的耦合，一行代码完成一个功能\n这种优化方式已经可以使得项目代码逻辑清晰，对于需要某个高内聚功能时，可以选择直接继承(有合适的父类时)或者组合各个功能类进行实现，从而解决无法多继承但同时需要两个不同的父类功能时的问题\n函数式优化，组合代替继承 很多设计模式和设计思想都是为了组合代替继承，又如语言层面对委托的支持(kotlin delegate, dart mixin)。通过上面对组织结构形态的分析，继承和组合最大的区别在于继承体系中子类对父类protect 方法的override能力，因此函数式编程思想(kotlin, dart中的函数变量传递，java中则对应着lambda表达式或者单方法interface)解决这个问题，在flutter中更是推荐组合代理继承，所有widget只要继承StatefulWidget或者StatelessWidget并进行功能组合即可\ngraph LR subgraph 被别人组合获取能力: 要求两者对外具有相同的接口能力抽象,通过代理转发 MyViewWantsToBeCenter--\u0026gt;|继承|View MyViewWantsToBeCenter--\u0026gt;|组合|Center(\u0026quot;wrap it in a Center widget\u0026quot;) end subgraph 组合别人获取能力 子类--\u0026gt;|继承|父类 包裹者--\u0026gt;|包裹|被包裹者 end 具体做法 通过传递方法fun实现给被包裹类，在被包裹类中进行fun的调用，达到类似子类override父类的能力。如果要实现类似子类调用super同签名方法实现的功能，\n方法1(较难理解，要修改方法签名，不推荐) 从被包裹类到包裹类层层包裹方法实现:\n可以将被包裹类中的同签名fun作为额外的(原方法签名参数列表后新增一个)参数，让外部传递新的参数列表给被包裹类，被包裹类通过调用fun1时传递自身实现让包裹类拥有类似子类调用super同签名方法实现的能力，如果包裹类没有传递fun1，可以直接调用fun\nclass BeWrapperedA(Fun1 funA) otherFun() { funA(param1, param2, fun) } fun(param1, param2) { } Fun1(param1 a, param2 b, fun(param1, param2) c) ------------------------------------------------ class BeWrapperedB(Fun1 funB) BeWrapperedA((a, b, c) -\u0026gt; {funB(a, b, (a, b) -\u0026gt; (Fun1(a, b, c))))}) Fun1(param1 a, param2 b, fun(param1, param2) c) { c(a , b) //相当于调用super(a, b)  a + b;//自定义逻辑 } 方法2，便于理解，不用修改方法签名 正向思维，从包裹类到被包裹类，按需调用方法，类似代理等设计思想，都实现接口，按需调用，类似flutter的StatefulWidget的一级子类，通过build方法约定从包裹类最外层开始向内调用被包裹类的方法实现\n相比一般方式的优点 在面临多继承需求时，如果所需要功能父类没有很好的封装功能并进行组合，导致自身没有组合对象，因此可以通过函数式思想优化，组合代替继承，完成功能的包裹和组合\n在flutter custom widget的体现 https://flutter.dev/docs/resources/architectural-overview#widgets\nconst RaisedButton({ Key key, @required VoidCallback onPressed, @override Widget build(BuildContext context) { return RawMaterialButton( onPressed: onPressed, class RawMaterialButton extends StatefulWidget { /// Called when the button is tapped or otherwise activated.  ///  /// If this is set to null, the button will be disabled, see [enabled].  final VoidCallback onPressed; class _RawMaterialButtonState extends State\u0026lt;RawMaterialButton\u0026gt; { @override Widget build(BuildContext context) { final Widget result = Focus( child: ConstrainedBox( child: Material( child: InkWell( onTap: widget.onPressed, class Container extends StatelessWidget { @override Widget build(BuildContext context) { Widget current = child; "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/%E7%BC%96%E8%A7%A3%E7%A0%81/",
	"title": "编解码",
	"tags": [],
	"description": "",
	"content": "编解码 探索总结编解码知识\n 编解码知识     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/%E7%BC%96%E8%A7%A3%E7%A0%81/%E7%BC%96%E8%A7%A3%E7%A0%81%E7%9F%A5%E8%AF%86/",
	"title": "编解码知识",
	"tags": [],
	"description": "",
	"content": "视频编码器 第一步:帧类型分析(分组)\u0026ndash;确定I、P、B帧 经过压缩后的帧分为：I帧，P帧和B帧:\n　I帧：关键帧，采用帧内压缩技术。 P帧：向前参考帧，在压缩时，只参考前面已经处理的帧。采用帧音压缩技术。 B帧：双向参考帧，在压缩时，它即参考前而的帧，又参考它后面的帧。采用帧间压缩技术。\n理想情况下，一个视频流，从一个I帧开始后面轻微运动都是 P/B，直到遇到场景切换就再插一个I，如此往复。一般来说，P/B 参考范围不会越过I帧。\n我们可以强行指定 P/B 参考不允许越过 I 帧，这样的I帧我们叫它 IDR 帧，每个 IDR 帧（Instantaneous Decoding Refresh）的间隔我们称作一个 GOP（Group of Pictures）。\n上图中的箭头表示信息提供方向，二分方式确定Coding Order\n第二步:帧内/帧间预测 　帧内预测压缩，解决的是空域数据冗余问题。 帧间预测压缩（运动估计与补偿），解决的是时域数据冗徐问题。\n帧内 大量统计表明，源 YUV 中两个相邻像素值相等、相似或者缓变概率极大，发生突变的几率是极小。（简单解释下，缓变图像：细量化，粗采样；突变图像：粗量化，细采样，处理细节丰富的图像）\n通常，编码器会通过算法将图像划分为一块一块的，然后逐块进行后续的压缩处理。\n假设当前的块不在图像边缘，我们可以用上方相邻块边界邻近值作为基础值，也就是上面一行中的每一个值，都垂直向下做拷贝，构建出和源 YUV 块一样大小的预测块，这种构建预测块的方式，我们叫做垂直预测模式，属于帧内预测模式的一种。与它相似的，还有水平预测模式、均值预测模式（也就是4x4的均值填充整个 4x4）等。\n紧接着，用源YUV的数据和预测YUV的数据做差值，得到残差块，这样我们在码流中，就直接传输残差的数据和当前4x4块的预测模式的标志位就行，这极大地节省了码流。\n举例：计算源块与预测块的残差\n帧间 如果是帧间预测的话，编码器会以当前块空域相邻的位置，在时域参考帧上的同为块，作为起始点进行规则搜索，直到搜索完找到能够节省码流最大的块作为帧间预测块，当前块到预测块的位移称为运动矢量，这样我们在码流中传输运动矢量、帧间预测模式标志位、残差就可以。\nH.264 中我们把 16x16 大小的块称作宏块，宏块也是 H.264 中最大的块，做帧内/帧间预测的时候可以分成8x8、4*4 这样的子块，都是要把它们最能节省码流的预测模式都算出来，然后比较出最优秀的划分模式进行传输。\n第三步:变换+量化 　整数离散余弦变换（DCT），将空间上的相关性变为频域上无关的数据然后进行量化。\n大量统计表明，把经过预测后得到的残差经过DCT空频变换，直流和低频（相对平坦，图像或块中大部分占比）能量集中在左上，高频（细节，图像或块中少部分占比）能量集中在右下，DCT本身虽然没有压缩作用，却为以后压缩时的取舍，奠定了必不可少的基础。\n变换后直流分量DC都集中在左上角，是整块像素的求和的均值。由于人眼对高频信号不敏感，我们可以定义这样一个变量QP=5，将变换块中所有的值都除以QP，这样做进一步节省传输码流位宽，同时主要去掉了高频分量的值，在解码端只需要将变换块中所有的值在乘QP就可以基本还原低频分量。\n我们将QP运算的过程称为量化，可见量化值越大，丢掉的高频信息就越多，再加上编码器中都是用整形变量代表像素值，所以量化值最大还原的低频信息也会越不准确，即造成的失真就越大，块效应也会越大，视频编码的质量损失主要来源于此。\n块效应\n第四步:滤波 我们可以把滤波理解为一个在量化值波动特别大的时候的一个提升主观质量的操作。如果量化值波动特别大，有可能造成本不应该是真实边界的区域内有很明显的块效应。我们暂称为块效应边界。\n真实边缘就比如说我们人脸和身后的背景，中间的这一条线。那假边界就是图中人脸区域的一个一个小块当中的这样的一个线。\n为了优化这种情况我们需要对块效应边界两边的值进行补偿操作，让块效应边界两边的值差异不要过大，从而降低块效应，提升质量。\n具体的操作，我们分三步。我会细致给大家梳理下。这部分很重要，有需要或者感兴趣的同学可以参考：\n1、初步估算块效应边界强度。\n2、区分真假边界。\n3、计算差值。\n第五步:熵编码 我们在真实网络传输的过程中肯定都是二进制码，所以我们需要将当前的像素值进一步压缩成二进制流\n总结一下 到这里，走完一整个编码流程，生成的数据就是压缩后的结果，我们也可将它送到适应我们的网络中去。\n先是我们计算过没有经过编码压缩的视频需要极大的带宽，所以我们必须进行编码。后来又说道编码的各个过程，输入的原始YUV进来，采用帧类型分析得到IDR、I、P、B类型，然后采用帧内/帧间预测+块划分得到残差，再采用变换+量化进行进一步压缩，接着采用滤波去除方块效应，然后采用熵编码将像素值转换为二进制流进一步压缩，输出压缩后可传输的码流。\n最后和音频编码出来的码流一起封装成我们常见的mp4等格式。\n无损压缩 VLC 无损压缩技术大家最熟悉的可能就是哈夫曼编码了，给高频的词一个短码，给低频词一个长码从而达到数据压缩的目的。MPEG-2中使用的VLC就是这种算法，我们以 A-Z 作为例子，A属于高频数据，Z属于低频数据。\nCABAC CABAC也是给高频数据短码，给低频数据长码。同时还会根据上下文相关性进行压缩，这种方式又比VLC高效很多。其效果如下：\n从上面这张图中明显可以看出采用 CACBA 的无损压缩方案要比 VLC 高效的多。\n硬编码和软编码 android音视频开发之编码封装\n1、软编码只适用短时间摄像，并且应用多样化的场景，如秒拍、美拍等；\n2、硬编码用于长时间摄像，但是只能用于适应性好的手机，如高通CPU的手机系列\n1.硬编的好处主要在于速度快，而且系统自带不需要引入外部的库，但是特性支持有限，而且硬编的压缩率一般偏低， 2.而对于软编码来说，虽然速度较慢，但是压缩率比较高，而且支持的H264特性也会比硬编码多很多，相对来说比较可控。就可用性而言， 3.在4.4+的系统上，MediaCodec的可用性是能够基本保证的，但是不同等级的机器的编码器能力会有不少差别，建议可以根据机器的配置，选择不同的编码器配置。视频流合流然后包装到mp4文件\n参考 编码 H.264基本原理与编码流程\nH.264编解码原理浅析\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/aop/%E7%BC%96%E8%AF%91%E6%8F%92%E6%A1%A9%E5%92%8C%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/",
	"title": "编译插桩和动态代理",
	"tags": [],
	"description": "",
	"content": "编译插桩技术 Kotlin Symbol Processing (KSP) Alpha 版现已发布\nByteX https://github.com/bytedance/ByteX\nASM https://asm.ow2.io/\n【Android】函数插桩（Gradle + ASM）\n ASM代码生成 在Android Studio中安装ASM Bytecode Viewer插件； 2、安装后，在编译器中，点击右键，选择Show Bytecode Viewer；  查看java字节码:\njclasslib插件，View-\u0026gt;Show ByteCode with jclasslib\n极客时间\u0026ndash;android开发高手课07-sample项目\ncompile group: \u0026#39;org.ow2.asm\u0026#39;, name: \u0026#39;asm\u0026#39;, version: \u0026#39;5.1\u0026#39; compile group: \u0026#39;org.ow2.asm\u0026#39;, name: \u0026#39;asm-commons\u0026#39;, version: \u0026#39;5.1\u0026#39; 通过反射注入transform\nproject.getGradle().getTaskGraph().addTaskExecutionGraphListener(new TaskExecutionGraphListener() { @Override public void graphPopulated(TaskExecutionGraph taskGraph) { for (Task task : taskGraph.getAllTasks()) { if ((task.name.equalsIgnoreCase(hackTransformTaskName) || task.name.equalsIgnoreCase(hackTransformTaskNameForWrapper)) \u0026amp;\u0026amp; !(((TransformTask) task).getTransform() instanceof SystemTraceTransform)) { project.logger.warn(\u0026#34;find dex transform. transform class: \u0026#34; + task.transform.getClass() + \u0026#34; . task name: \u0026#34; + task.name) project.logger.info(\u0026#34;variant name: \u0026#34; + variant.name) Field field = TransformTask.class.getDeclaredField(\u0026#34;transform\u0026#34;) field.setAccessible(true) field.set(task, new SystemTraceTransform(project, variant, task.transform)) project.logger.warn(\u0026#34;transform class after hook: \u0026#34; + task.transform.getClass()) break } } } }) JavaAssist Android动态编译技术:Plugin Transform Javassist操作Class文件\n可以查看shadow源码中的相关部分： Transform + JavaAssist\n运行时生成代码 /** * 运行时生成业务逻辑 * @return * @throws Exception */ public static IDBQuery createJavassistBytecodeDynamicProxy() throws Exception{ ClassPool mPool = new ClassPool(true); //定义类名  CtClass mCtc = mPool.makeClass(IDBQuery.class.getName() + \u0026#34;JavaassistBytecodeProxy\u0026#34;); //需要实现接口  mCtc.addInterface(mPool.get(IDBQuery.class.getName())); //添加构造函数  mCtc.addConstructor(CtNewConstructor.defaultConstructor(mCtc)); //添加类的字段信息，使用动态Java代码  mCtc.addField(CtField.make(\u0026#34;public\u0026#34; + IDBQuery.class.getName() + \u0026#34;real;\u0026#34;, mCtc)); String dbQueryname = DBQuery.class.getName(); //添加方法，这里使用动态Java代码指定内部逻辑  mCtc.addMethod(CtNewMethod.make(\u0026#34;public String request() { if(real==null) real = new \u0026#34; +dbQueryname+\u0026#34;(); return real.request();}\u0026#34;, mCtc)); //基于以上信息，生成动态类  Class pc = mCtc.toClass(); //生成动态类的实例  IDBQuery bytecodeProxy = (IDBQuery) pc.newInstance(); return bytecodeProxy; } Jdk动态代理： http://www.cnblogs.com/xiaoluo501395377/p/3383130.html\nCGLIB 幸好我们有cglib。“CGLIB（Code Generation Library），是一个强大的，高性能，高质量的Code生成类库，它可以在运行期扩展Java类与实现Java接口。”\ncglib 创建某个类A的动态代理类的模式是：\n 查找A上的所有非final 的public类型的方法定义； 将这些方法的定义转换成字节码； 将组成的字节码转换成相应的代理的class对象； 实现 MethodInterceptor接口，用来处理 对代理类上所有方法的请求（这个接口和JDK动态代理InvocationHandler的功能和角色是一样的）  cglib动态代理\njdk中的动态代理通过反射类Proxy和InvocationHandler回调接口实现，要求委托类必须实现一个接口，只能对该类接口中定义的方法实现代理，这在实际编程中有一定的局限性。\n使用[cglibCode Generation Library]实现动态代理，并不要求委托类必须实现接口，底层采用asm字节码生成框架生成代理类的字节码，下面通过一个例子看看使用CGLib如何实现动态代理。\n参考 编译时插桩的方式，后面我会讲到 Aspect、ASM 和 ReDex\n动态代理解释-JDK,CGLIB,JAVASSIST,ASM\nJava动态代理：JDK 和CGLIB、Javassist、ASM之间的差别 (详细)\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%AE%89%E5%85%A8/",
	"title": "网络请求安全",
	"tags": [],
	"description": "",
	"content": "https://httpcanary.com/zh-hans/install.html\n安装根证书（必须） 安装证书要求设备必须设置锁屏密码或者图案，请按照系统提示进行设置（此乃系统限制与HttpCanary无关）\nHttpCanary使用Man-in-the-Middle(MITM)技术抓取和解析TLS/SSL协议数据包，比如常见的HTTPS、WSS等加密请求，所以使用之前必须先安装HttpCanary根证书。安装时，默认点击确定即可，请勿修改配置。\nSSL/TLS安全之——中间人攻击（MITM）浅析\nhttpcanary是通过VPN抓取数据包，因此通过禁用代理无法关闭抓包\n手机上的httpcanary或PC上的ss打开都会导致正常通过代理进行抓包抓不到\nhttps加密时，通过代理进行charles抓包时看到的数据时密文，但httpcanary看到的是明文，因为httpcanary是在应用层看到的未加密的数据和已解密的数据，加密解密发生在应用层和传输层之间。因此只能在业务上对网络参数进行加解密\nAndroid Okhttp/Retrofit网络请求加解密实现方案\nAndroid平台HTTPS抓包解决方案及问题分析 Android平台HTTPS抓包解决方案及问题分析\n1. 抓包原理 几乎所有网络数据的抓包都是采用中间人的方式（MITM），包括大家常用的Fiddler、Charles等知名抓包工具，HttpCanary同样是使用中间人的方式进行抓包。\n从上面这个原理图，可以看出抓包的核心问题主要是两个：\n MITM Server如何伪装成真正的Server； MITM Client如何伪装成真正的Client。  第一个问题，MITM Server要成为真正的Server，必须能够给指定域名签发公钥证书，且公钥证书能够通过系统的安全校验。比如Client发送了一条https://www.baidu.com/的网络请求，MITM Server要伪装成百度的Server，必须持有www.baidu.com域名的公钥证书并发给Client，同时还要有与公钥相匹配的私钥。\nMITM Server的处理方式是从第一个SSL/TLS握手包Client Hello中提取出域名www.baidu.com，利用应用内置的CA证书创建www.baidu.com域名的公钥证书和私钥。创建的公钥证书在SSL/TLS握手的过程中发给Client，Client收到公钥证书后会由系统会对此证书进行校验，判断是否是百度公司持有的证书，但很明显这个证书是抓包工具伪造的。为了能够让系统校验公钥证书时认为证书是真实有效的，我们需要将抓包应用内置的CA证书手动安装到系统中，作为真正的证书发行商（CA），即洗白。这就是为什么，HTTPS抓包一定要先安装CA证书。\n第二个问题，MITM Client伪装成Client。由于服务器并不会校验Client（绝大部分情况），所以这个问题一般不会存在。比如Server一般不会关心Client到底是Chrome浏览器还是IE浏览器，是Android App还是iOS App。当然，Server也是可以校验Client的，这个后面分析。\n2. 安装CA证书 抓包应用内置的CA证书要洗白，必须安装到系统中。而Android系统将CA证书又分为两种：用户CA证书和系统CA证书。顾明思议，用户CA证书是由用户自行安装的，系统CA证书是由系统内置的，很明显后者更加真实有效。\n系统CA证书存放在/etc/security/cacerts/目录下，名称是CA证书subjectDN的Md5值前四位移位取或，后缀名是.0，比如00673b5b.0。考虑到安全原因，系统CA证书需要有Root权限才能进行添加和删除。\n对于非Root的Android设备，用户只能安装用户CA证书。\n无论是系统CA证书还是用户CA证书，都可以在设置-\u0026gt;系统安全-\u0026gt;加密与凭据-\u0026gt;信任的凭据中查看\n3. Android 7.0的用户CA证书限制 Android从7.0开始系统不再信任用户CA证书（应用targetSdkVersion \u0026gt;= 24时生效，如果targetSdkVersion \u0026lt; 24即使系统是7.0+依然会信任）。也就是说即使安装了用户CA证书，在Android 7.0+的机器上，targetSdkVersion \u0026gt;= 24的应用的HTTPS包就抓不到了。\n比如上面的例子，抓包工具用内置的CA证书，创建了www.baidu.com域名的公钥证书发给Client，系统校验此证书时发现是用户CA证书签发的，sorry。。。\n那么，我们如果绕过这种限制呢？已知有以下四种方式（低于7.0的系统请忽略）：\n3.1 AndroidManifest中配置networkSecurityConfig\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;network-security-config\u0026gt; \u0026lt;base-config cleartextTrafficPermitted=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;trust-anchors\u0026gt; \u0026lt;certificates src=\u0026#34;system\u0026#34; /\u0026gt; \u0026lt;certificates src=\u0026#34;user\u0026#34; /\u0026gt; \u0026lt;/trust-anchors\u0026gt; \u0026lt;/base-config\u0026gt; \u0026lt;/network-security-config\u0026gt; 这样即表示，App信任用户CA证书，让系统对用户CA证书的校验给予通过。更多相关信息，详见Network security configuration。\n3.2 调低targetSdkVersion \u0026lt; 24\n3.3 平行空间抓包\n3.4 安装到系统CA证书目录\n5. 公钥证书固定 证书固定（Certificate Pinning）是指Client端内置Server端真正的公钥证书。在HTTPS请求时，Server端发给客户端的公钥证书必须与Client端内置的公钥证书一致，请求才会成功。\n在这种情况下，由于MITM Server创建的公钥证书和Client端内置的公钥证书不一致，MITM Server就无法伪装成真正的Server了。这时，抓包就表现为App网络错误。已知的知名应用，比如饿了么，就采用了证书固定。\n另外，有些服务器采用的自签证书（证书不是由真正CA发行商签发的），这种情况App请求时必须使用证书固定。\n证书固定的一般做法是，将公钥证书（.crt或者.cer等格式）内置到App中，然后创建TrustManager时将公钥证书加进去。很多应用还会将内置的公钥证书伪装起来或者加密，防止逆向提取，比如饿了么就伪装成了png，当然对公钥证书伪装或者加密没什么太大必要，纯粹自欺欺人罢了。\n证书固定对抓包是个非常麻烦的阻碍，不过我们总是有办法绕过的，就是麻烦了点。\n6. 双向认证  网络数据安全 https并不能阻挡攻击者分析请求接口并发起攻击，为了增加攻击者分析请求的难度，通常可以采用两种方式：\n  使用签名。 即给你的请求参数添加一个签名，后台服务接收到请求时，先验证签名，签名不正确的话，则不予处理。签名规则五花八门，大致策略就是根据请求参数做一些运算最后生成一个唯一的字符串当做sign，微信支付的签名大家可以做一个参考：https://pay.weixin.qq.com/wiki/doc/api/app/app.php?chapter=4_3\n  数据加密。 post到服务器和从服务器返回的数据都做加密，这样的话即使攻击者拿到你的数据，他不知道你的加密算法就无能为力了。秘钥使用JNI将敏感信息写到Native层\n  上面说的两种方式可以同时使用，但是大家还需要考虑一个问题：如何防止攻击者获取到你的签名生成规则和加密算法，例如你加密使用的AES算法，你的秘钥放在哪里呢？\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/",
	"title": "自动化测试",
	"tags": [],
	"description": "",
	"content": "自动化测试 探索总结自动化测试知识\n android代码自测     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/",
	"title": "跨平台",
	"tags": [],
	"description": "",
	"content": "跨平台 探索总结跨平台知识\n flutter    1startup    1startup     2startup_embedder_framwwork     3flutter_surface     4startup_dart_framework      engine    Engine     FlutterEngineCache     FlutterEngineDebug环境搭建     FlutterEngineGroup      touch    Touch      动画    动画      响应式架构    1跨组件传递数据     2Provider     3异步_响应式_状态管理     stream    Stream       混合开发    FlutterBoost     FlutterBoost3     混合开发      渲染    Widget     渲染      路由    路由      通信    EventChannel     MessageLoop     MethodChannel     Pigeon       "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E8%B7%AF%E7%94%B1/",
	"title": "路由",
	"tags": [],
	"description": "",
	"content": "路由 探索总结路由知识\n 路由     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E8%B7%AF%E7%94%B1/%E8%B7%AF%E7%94%B1/",
	"title": "路由",
	"tags": [],
	"description": "",
	"content": "原理    可能你会比较好奇_Theatre中 offstage 是如何做到不绘制的。\n你应该知道 Element 树的是通过其内部的mout方法将自己挂载到父 Element 上的。_Theatre的 mout方法不太一样， onstage走正常的挂载流程，加入到Element 树中； offstage集合中的 Widget 仅创建了对应的 Element，并没有挂载到 Element 树中。没有进入到Element中，也就不会进入到 RenderObject树中，也就不走到绘制流程了。\n这样你应该能理解Overlay其实是Stack的扩展。Overlay预先进行过滤，从而避免了无用的绘制。\n我们看下当路由中只有一个 Page 时的示意图：\n我们再看下当路由中又被 push 进一个 Page时的情况：\n因为通常 Page 的 opaque=true, maintainState=true,所以 Page2 进入 onstage， Page1 不在需要被绘制，但需要保持状态，进入了offstage。\n因为通常 popupWindow（dialog） 的 opaque=false,我们再向路由中 push 一个 dialog:\n类设计 Usage Navigator 1.0  **Navigator** — a widget that manages a stack of Route objects. **Route** — an object managed by a Navigator that represents a screen, typically implemented by classes like MaterialPageRoute.  Anonymous routes Navigator.push( context, MaterialPageRoute(builder: (context) { return DetailScreen(); }), ); Named routes return MaterialApp( routes: { \u0026#39;/\u0026#39;: (context) =\u0026gt; HomeScreen(), \u0026#39;/details\u0026#39;: (context) =\u0026gt; DetailScreen(), }, ); Navigator.pushNamed( context, \u0026#39;/details\u0026#39;, ); These routes must be predefined. Although you can pass arguments to a named route, you can’t parse arguments from the route itself. For example, if the app is run on the web, you can’t parse the ID from a route like /details/:id.\nAdvanced named routes with onGenerateRoute A more flexible way to handle named routes is by using onGenerateRoute. This API gives you the ability to handle all paths:\nreturn MaterialApp( onGenerateRoute: (settings) { // Handle \u0026#39;/\u0026#39;  if (settings.name == \u0026#39;/\u0026#39;) { return MaterialPageRoute(builder: (context) =\u0026gt; HomeScreen()); } // Handle \u0026#39;/details/:id\u0026#39;  var uri = Uri.parse(settings.name); if (uri.pathSegments.length == 2 \u0026amp;\u0026amp; uri.pathSegments.first == \u0026#39;details\u0026#39;) { var id = uri.pathSegments[1]; return MaterialPageRoute(builder: (context) =\u0026gt; DetailScreen(id: id)); } return MaterialPageRoute(builder: (context) =\u0026gt; UnknownScreen()); }, ); Navigator.pushNamed( context, \u0026#39;/details/1\u0026#39;, ); Here, settings is an instance of RouteSettings. The name and arguments fields are the values that were provided when Navigator.pushNamed was called, or what initialRoute is set to.\nNavigator 2.0 The Navigator 2.0 API adds new classes to the framework in order to make the app’s screens a function of the app state and to provide the ability to parse routes from the underlying platform (like web URLs). Here’s an overview of what’s new:\n **Page** — an immutable object used to set the navigator’s history stack. **Router** — configures the list of pages to be displayed by the Navigator. Usually this list of pages changes based on the underlying platform, or on the state of the app changing. **RouteInformationParser**, which takes the RouteInformation from RouteInformationProvider and parses it into a user-defined data type. **RouterDelegate** — defines app-specific behavior of how the Router learns about changes in app state and how it responds to them. Its job is to listen to the RouteInformationParser and the app state and build the Navigator with the current list of Pages. **BackButtonDispatcher** — reports back button presses to the Router.  The following diagram shows how the RouterDelegate interacts with the Router, RouteInformationParser, and the app’s state:\nHere’s an example of how these pieces interact:\n When the platform emits a new route (for example, “books/2”) , the RouteInformationParser converts it into an abstract data type T that you define in your app (for example, a class called BooksRoutePath). RouterDelegate’s setNewRoutePath method is called with this data type, and must update the application state to reflect the change (for example, by setting the selectedBookId) and call notifyListeners. When notifyListeners is called, it tells the Router to rebuild the RouterDelegate (using its build() method) RouterDelegate.build() returns a new Navigator, whose pages now reflect the change to the app state (for example, the selectedBookId).  return MaterialApp( title: \u0026#39;Books App\u0026#39;, home: Navigator( pages: [ MaterialPage( key: ValueKey(\u0026#39;BooksListPage\u0026#39;), child: Scaffold(), ) ], onPopPage: (route, result) =\u0026gt; route.didPop(result), ), ); Pages The Navigator has a new pages argument in its constructor. If the list of Page objects changes, Navigator updates the stack of routes to match.\npages: [ MaterialPage( key: ValueKey(\u0026#39;BooksListPage\u0026#39;), child: BooksListScreen( books: books, onTapped: _handleBookTapped, ), ), // New:  if (show404) MaterialPage(key: ValueKey(\u0026#39;UnknownPage\u0026#39;), child: UnknownScreen()) else if (_selectedBook != null) MaterialPage( key: ValueKey(_selectedBook), child: BookDetailsScreen(book: _selectedBook)) ], Note that the key for the page is defined by the value of the book object. This tells the Navigator that this MaterialPage object is different from another when the Book object is different. Without a unique key, the framework can’t determine when to show a transition animation between different Pages.\nFinally, it’s an error to provide a pages argument without also providing an onPopPage callback. This function is called whenever Navigator.pop() is called. It should be used to update the state (that determines the list of pages), and it must call didPop on the route to determine if the pop succeeded:\nonPopPage: (route, result) { if (!route.didPop(result)) { return false; } // Update the list of pages by setting _selectedBook to null  setState(() { _selectedBook = null; }); return true; }, It’s important to check whether didPop fails before updating the app state.\nUsing setState notifies the framework to call the build() method, which returns a list with a single page when _selectedBook is null.\nRouter So far, the app can show different pages, but it can’t handle routes from the underlying platform, for example if the user updates the URL in the browser.\nThis section shows how to implement the RouteInformationParser, RouterDelegate, and update the app state. Once set up, the app stays in sync with the browser’s URL.\n参考 Flutter 路由原理解析\nFlutter 路由源码解析\nhttps://flutter.dev/docs/development/ui/navigation\nLearning Flutter’s new navigation and routing system\nhttps://docs.google.com/document/d/1Q0jx0l4-xymph9O6zLaOY4d_f7YFpNWX_eGbzYxr9wY/edit#heading=h.l6kdsrb6j9id\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/system/%E7%B3%BB%E7%BB%9F%E7%BB%98%E5%88%B6/%E8%BD%AF%E4%BB%B6%E7%BB%98%E5%88%B6/",
	"title": "软件绘制",
	"tags": [],
	"description": "",
	"content": "软件绘制 深入理解Window\nAndroid的UI显示原理之Surface的创建\nAndroid的UI显示原理之Surface的渲染\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/AndroidFramework%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/Android%E7%9A%84UI%E6%98%BE%E7%A4%BA%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93.md\nhttps://github.com/SusionSuc/AdvancedAndroid/blob/master/framework/Android%E8%A7%86%E5%9B%BE%E5%B1%82%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/README.md\nAndroid图形系统（九）-View、Canvas与Surface的关系\n 整体流程 把整个流程再简单总结下，View、Canvas与Surface的关系也就一目了然了：\nSurface通过dequeueBuffer流程（具体操作在此不多赘述）获取一块存放绘制数据的buffer。\nView 在onDraw的时候，通过传入的Canvas进行绘制。（这里只是一个绘制的入口而已，本文是针对requestLayout 流程来讲述的，当然你单独用Canvas实现绘制也是一样的）。\n调用java层的CanvasAPI，实际真正负责绘制工作的是底层的Skia引擎，这里核心类包括SKCanvas（画家）以及SKBitmap（画布），绘制好的内容放入Surface 通过dequeueBuffer获取到的GraphicBuffer。\n绘制完毕后，Surface通过queueBuffer将存放好绘制数据的buffer投递到队列中，并通知SurfaceFlinger消费。\n SurfaceFlinger可以说是Android UI渲染体系的核心，在Android系统启动时会启动SurfaceFlinger服务,它的主要作用就是被Android应用程序调用，把绘制(测量，布局，绘制)后的窗口(Surface)渲染到手机屏幕上\nSurfaceControl surface.lockCanvas(): //android_view_Surface.cpp static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ... ANativeWindow_Buffer outBuffer; //调用了Surface的dequeueBuffer，从SurfaceFlinger中申请内存GraphicBuffer,这个buffer是用来传递绘制的元数据的  status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); ... SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType); //新建了一个SkBitmap，并进行了一系列设置  SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits);//bitmap对graphicBuffer进行关联  } else { // be safe with an empty bitmap.  bitmap.setPixels(NULL); } //构造一个native的Canvas对象（SKCanvas)，再返回这个Canvas对象，java层的Canvas对象其实只是对SKCanvas对象的一个简单包装，所有绘制方法都是转交给SKCanvas来做。  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); ... sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } canvas.drawXXX Skia深入分析\n==SkCanvas是按照SkBitmap的方法去关联GraphicBuffer==\n一、渲染层级 从渲染流程上分，Skia可分为如下三个层级：\n 指令层：SkPicture、SkDeferredCanvas-\u0026gt;SkCanvas  这一层决定需要执行哪些绘图操作，绘图操作的预变换矩阵，当前裁剪区域，绘图操作产生在哪些layer上，Layer的生成与合并。\n解析层：SkBitmapDevice-\u0026gt;SkDraw-\u0026gt;SkScan、SkDraw1Glyph::Proc  这一层决定绘制方式，完成坐标变换，解析出需要绘制的形体（点/线/规整矩形）并做好抗锯齿处理，进行相关资源解析并设置好Shader。\n渲染层：SkBlitter-\u0026gt;SkBlitRow::Proc、SkShader::shadeSpan等  这一层进行采样（如果需要），产生实际的绘制效果，完成颜色格式适配，进行透明度混合和抖动处理（如果需要）。\n//Canvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { super.drawLine(startX, startY, stopX, stopY, paint); } //BaseCanvas.java public void drawLine(float startX, float startY, float stopX, float stopY, @NonNull Paint paint) { throwIfHasHwBitmapInSwMode(paint); nDrawLine(mNativeCanvasWrapper, startX, startY, stopX, stopY, paint.getNativeInstance()); } //frameworks/base/core/jni/android_graphics_Canvas.cpp static void drawLine(JNIEnv* env, jobject, jlong canvasHandle, jfloat startX, jfloat startY, jfloat stopX, jfloat stopY, jlong paintHandle) { Paint* paint = reinterpret_cast\u0026lt;Paint*\u0026gt;(paintHandle); get_canvas(canvasHandle)-\u0026gt;drawLine(startX, startY, stopX, stopY, *paint); } //external/skia/src/core/SkCanvas.cpp void SkCanvas::drawLine(SkScalar x0, SkScalar y0, SkScalar x1, SkScalar y1, const SkPaint\u0026amp; paint) { SkPoint pts[2]; pts[0].set(x0, y0); pts[1].set(x1, y1); this-\u0026gt;drawPoints(kLines_PointMode, 2, pts, paint); } void SkCanvas::drawPoints(PointMode mode, size_t count, const SkPoint pts[], const SkPaint\u0026amp; paint) { TRACE_EVENT0(\u0026#34;skia\u0026#34;, TRACE_FUNC); this-\u0026gt;onDrawPoints(mode, count, pts, paint); } mSurface.unlockCanvasAndPost(canvas): //Surface.cpp status_t Surface::unlockAndPost() { if (mLockedBuffer == 0) { ALOGE(\u0026#34;Surface::unlockAndPost failed, no locked buffer\u0026#34;); return INVALID_OPERATION; } int fd = -1; status_t err = mLockedBuffer-\u0026gt;unlockAsync(\u0026amp;fd);//通过Gralloc模块，最后是操作的ioctl  err = queueBuffer(mLockedBuffer.get(), fd); mPostedBuffer = mLockedBuffer; mLockedBuffer = 0; return err; } int Surface::queueBuffer(android_native_buffer_t* buffer, int fenceFd) { ... int i = getSlotFromBufferLocked(buffer); ... IGraphicBufferProducer::QueueBufferOutput output; IGraphicBufferProducer::QueueBufferInput input(timestamp, isAutoTimestamp, static_cast\u0026lt;android_dataspace\u0026gt;(mDataSpace), crop, mScalingMode, mTransform ^ mStickyTransform, fence, mStickyTransform, mEnableFrameTimestamps); ... status_t err = mGraphicBufferProducer-\u0026gt;queueBuffer(i, input, \u0026amp;output); ... mQueueBufferCondition.broadcast(); return err; } int Surface::getSlotFromBufferLocked(android_native_buffer_t* buffer) const { for (int i = 0; i \u0026lt; NUM_BUFFER_SLOTS; i++) { if (mSlots[i].buffer != NULL \u0026amp;\u0026amp; mSlots[i].buffer-\u0026gt;handle == buffer-\u0026gt;handle) { return i; } } return BAD_VALUE; } 我们看到了queueBuffer函数, 而在Surface的queueBuffer函数中调用了如下函数：\nmGraphicBufferProducer-\u0026gt;queueBuffer status_t BufferQueueProducer::queueBuffer(int slot, const QueueBufferInput \u0026amp;input, QueueBufferOutput *output) { //从input中获取一些列参数  input.deflate(\u0026amp;requestedPresentTimestamp, \u0026amp;isAutoTimestamp, \u0026amp;dataSpace, \u0026amp;crop, \u0026amp;scalingMode, \u0026amp;transform, \u0026amp;acquireFence, \u0026amp;stickyTransform, \u0026amp;getFrameTimestamps); sp\u0026lt;IConsumerListener\u0026gt; frameAvailableListener; sp\u0026lt;IConsumerListener\u0026gt; frameReplacedListener; BufferItem item; //可以理解为一个待渲染的帧  frameAvailableListener = mCore-\u0026gt;mConsumerListener; ...下面就是对item的一系列赋值操作 item.mAcquireCalled = mSlots[slot].mAcquireCalled; item.mGraphicBuffer = mSlots[slot].mGraphicBuffer; //根据slot获取GraphicBuffer。  item.mCrop = crop; item.mTransform = transform \u0026amp; ~static_cast\u0026lt;uint32_t\u0026gt;(NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY); item.mTransformToDisplayInverse = (transform \u0026amp; NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY) != 0; item.mScalingMode = static_cast\u0026lt;uint32_t\u0026gt;(scalingMode); item.mTimestamp = requestedPresentTimestamp; item.mIsAutoTimestamp = isAutoTimestamp; ... if (frameAvailableListener != NULL) { frameAvailableListener-\u0026gt;onFrameAvailable(item); //item是一个frame，准备完毕，要通知外界  } else if (frameReplacedListener != NULL) { frameReplacedListener-\u0026gt;onFrameReplaced(item); } addAndGetFrameTimestamps(\u0026amp;newFrameEventsEntry,etFrameTimestamps ? \u0026amp;output-\u0026gt;frameTimestamps : nullptr); return NO_ERROR; } 这个函数最终会将BufferItem的buffer清除，通知消费者的onFrameAvailable接口。然后消费者可以根据mSlots的序号再来拿buffer。\n// --------------------------------------------------------------------------- // Interface implementation for SurfaceFlingerConsumer::ContentsChangedListener // --------------------------------------------------------------------------- void BufferLayer::onFrameAvailable(const BufferItem\u0026amp; item) { ... mFlinger-\u0026gt;signalLayerUpdate(); } void SurfaceFlinger::signalLayerUpdate() { mEventQueue-\u0026gt;invalidate(); } "
},
{
	"uri": "https://huanle19891345.github.io/en/%E8%B7%A8%E5%B9%B3%E5%8F%B0/flutter/%E9%80%9A%E4%BF%A1/",
	"title": "通信",
	"tags": [],
	"description": "",
	"content": "通信 探索总结通信知识\n EventChannel     MessageLoop     MethodChannel     Pigeon     "
},
{
	"uri": "https://huanle19891345.github.io/en/%E6%96%B9%E5%90%91%E5%92%8C%E8%B6%8B%E5%8A%BF/%E9%9F%B3%E8%A7%86%E9%A2%91/",
	"title": "音视频",
	"tags": [],
	"description": "",
	"content": "音视频 探索总结音视频知识\n ffmpeg    examples    TranscodingSource      FFmpegDebug      webrtc    WebRTC源码下载和编译      编解码    编解码知识      "
}]