[
{
	"uri": "https://huanle19891345.github.io/en/android/",
	"title": "Android",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/",
	"title": "AndroidX",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/",
	"title": "BitmapX",
	"tags": [],
	"description": "",
	"content": "Bitmap\nchild\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/bitmapx/",
	"title": "BitmapX",
	"tags": [],
	"description": "",
	"content": "Bitmap\nchild\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/bitmap/bitmapx/",
	"title": "BitmapX",
	"tags": [],
	"description": "",
	"content": "Bitmap\nchild\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/bitmapx/bitmapxx/",
	"title": "BitmapXX",
	"tags": [],
	"description": "",
	"content": "Bitmap\nchild\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/bitmapxx/",
	"title": "BitmapXX",
	"tags": [],
	"description": "",
	"content": "Bitmap\nchild\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/bitmap/bitmapx/bitmapxx/",
	"title": "BitmapXX",
	"tags": [],
	"description": "",
	"content": "Bitmap\nchild\n"
},
{
	"uri": "https://huanle19891345.github.io/en/",
	"title": "home",
	"tags": [],
	"description": "",
	"content": "Bitmap\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/bitmap/",
	"title": "Bitmap",
	"tags": [],
	"description": "",
	"content": "Bitmap\nchild\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/bitmap/bitmap/",
	"title": "Bitmap1",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时：\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/bitmap/",
	"title": "BitmapX",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/bitmapx/bitmap/",
	"title": "BitmapX",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/bitmap/bitmapx/bitmap/",
	"title": "BitmapX",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/bitmapx/bitmapxx/bitmap/",
	"title": "BitmapXX",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/bitmapx/bitmapxx/bitmap/",
	"title": "BitmapXX",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/android/bitmap/bitmapx/bitmapxx/bitmap/",
	"title": "BitmapXX",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/bitmap/",
	"title": "First_Bitmap",
	"tags": [],
	"description": "",
	"content": "[TOC]\nBitmap像素存储 03 | 内存优化（上）：4GB内存时代，再谈内存优化\nAndroid Bitmap变迁与原理解析（4.x-8.x）\nBitmap: 从出生到死亡\nBitmap创建 Java 层的创建 Bitmap 的所有 API 进入到 Native 层后，全都会走如下这四个步骤。\n ==资源转换== - 这一步将 Java 层传来的不同类型的资源转换成解码器可识别的数据类型 ==内存分配== - 分配内存时会考虑是否复用 Bitmap、是否缩放 Bitmap 等因素 ==图片解码== - 实际的解码工作由第三方库完成，解码结果填在上一步分配的内存中。注，Bitmap.createBitmap() 和 Bitmap.copy() 创建的 Bitmap 不需要进行图片解码 ==创建对象== - 这一步将包含解码数据的内存块包装成 Java 层的 android.graphics.Bitmap 对象，方便 App 使用  1. 资源转换 2. 内存分配 3. 图片解码 创建Java对象 Bitmap销毁 Bitmap.recycle() 自动释放：NativeAllocationRegistry NativeAllocationRegistry 用于将 native 内存跟 Java 对象关联，并将它们注册到 Java 运行时。注册 Java 对象关联的 native 内存有几个好处：\n Java 运行时在 GC 调度时可考虑 native 内存状态 Java 运行时在 Java 对象变得不可达时可以使用用户提供的函数来自动清理 native 内存  当 Java 层 Bitmap 对象不可达后关联的 native 内存会由 nativeGetNativeFinalizer() 指定的方法来回收\nstatic void Bitmap_destruct(BitmapWrapper* bitmap) { delete bitmap; } static jlong Bitmap_getNativeFinalizer(JNIEnv*, jobject) { return static_cast\u0026lt;jlong\u0026gt;(reinterpret_cast\u0026lt;uintptr_t\u0026gt;(\u0026amp;Bitmap_destruct)); } //we must ensure to not leak java Bitmap Object, this will recycle bitmap memory in native around GC, while it cannot be reclaim if the java bitmap is leak.\n//下图流程稍有问题，实测为ReferenceQueueDaemon便利enqueue过程会直接调用Cleaner.clean开启流程，没有使用到VMRuntime和CleanerRuner,具体流程见BitmapSource.md\nBitmap内存分配原理 8.0之前Bitmap内存分配原理 通过Bitmap的成员列表，就能看出一点眉目，Bitmap中有个byte[] mBuffer，其实就是用来存储像素数据的，很明显它位于java heap中：\npublic final class Bitmap implements Parcelable { private static final String TAG = \u0026#34;Bitmap\u0026#34;; ... private byte[] mBuffer; ... } Java层Bitmap的创建最终还是会走向native层：Bitmap.cpp\nstatic jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... SkBitmap Bitmap; Bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType)); \u0026lt;!--关键点1 像素内存分配--\u0026gt; Bitmap* nativeBitmap = GraphicsJNI::allocateJavaPixelRef(env, \u0026amp;Bitmap, NULL); if (!nativeBitmap) { return NULL; } ... \u0026lt;!--获取分配地址--\u0026gt; jbyte* addr = (jbyte*) env-\u0026gt;CallLongMethod(gVMRuntime, gVMRuntime_addressOf, arrayObj); ... \u0026lt;!--创建Bitmap--\u0026gt; android::Bitmap* wrapper = new android::Bitmap(env, arrayObj, (void*) addr, info, rowBytes, ctable); wrapper-\u0026gt;getSkBitmap(Bitmap); Bitmap-\u0026gt;lockPixels(); return wrapper; } 这里只看关键点1，像素内存的分配：GraphicsJNI::allocateJavaPixelRef从这个函数名可以就可以看出，是在Java层分配，跟进去，也确实如此\n由于只关心内存分配里其实就是在native层创建Java层byte[]，并将这个byte[]作为像素存储结构，之后再通过在native层构建Java Bitmap对象的方式，将生成的byte[]传递给Bitmap.java对象：\njobject GraphicsJNI::createBitmap(JNIEnv* env, android::Bitmap* bitmap, int bitmapCreateFlags, jbyteArray ninePatchChunk, jobject ninePatchInsets, int density) { ...\u0026lt;!--关键点1，构建java Bitmap对象，并设置byte[] mBuffer--\u0026gt; jobject obj = env-\u0026gt;NewObject(gBitmap_class, gBitmap_constructorMethodID, reinterpret_cast\u0026lt;jlong\u0026gt;(bitmap), bitmap-\u0026gt;javaByteArray(), bitmap-\u0026gt;width(), bitmap-\u0026gt;height(), density, isMutable, isPremultiplied, ninePatchChunk, ninePatchInsets); hasException(env); // For the side effect of logging.  return obj; } 8.0之后Bitmap内存分配 其实从8.0的Bitmap.java类也能看出区别，之前的 private byte[] mBuffer成员不见了，取而代之的是private final long mNativePtr，也就说，Bitmap.java只剩下一个壳了，具体如下：\npublic final class Bitmap implements Parcelable { ... // Convenience for JNI access  private final long mNativePtr; ... } 之前说过8.0之后的内存分配是在native，具体到代码是怎么样的表现呢？流程与8.0之前基本类似，区别在native分配时： static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors, jint offset, jint stride, jint width, jint height, jint configHandle, jboolean isMutable, jfloatArray xyzD50, jobject transferParameters) { SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle); ... \u0026lt;!--关键点1 ，native层创建bitmap，并分配native内存--\u0026gt; sk_sp\u0026lt;Bitmap\u0026gt; nativeBitmap = Bitmap::allocateHeapBitmap(\u0026amp;Bitmap); if (!nativeBitmap) { return NULL; } ... return createBitmap(env, nativeBitmap.release(), getPremulBitmapCreateFlags(isMutable)); } 看一下allocateHeapBitmap如何分配内存\nstatic sk_sp\u0026lt;Bitmap\u0026gt; allocateHeapBitmap(size_t size, const SkImageInfo\u0026amp; info, size_t rowBytes) { \u0026lt;!--关键点1 直接calloc分配内存--\u0026gt; void* addr = calloc(size, 1); if (!addr) { return nullptr; } \u0026lt;!--关键点2 创建native Bitmap--\u0026gt; return sk_sp\u0026lt;Bitmap\u0026gt;(new Bitmap(addr, size, info, rowBytes)); } 可以看出，8.0之后，Bitmap像素内存的分配是在native层直接调用calloc，所以其像素分配的是在native heap上， 这也是为什么8.0之后的Bitmap消耗内存可以无限增长，直到耗尽系统内存，也不会提示Java OOM的原因。\n8.0之后的Bitmap内存回收机制 NativeAllocationRegistry是Android 8.0引入的一种辅助自动回收native内存的一种机制，==当Java对象因为GC被回收后，NativeAllocationRegistry可以辅助回收Java对象所申请的native内存==，拿Bitmap为例，入下：\nBitmap(long nativeBitmap, int width, int height, int density, boolean isMutable, boolean requestPremultiplied, byte[] ninePatchChunk, NinePatch.InsetStruct ninePatchInsets) { ... mNativePtr = nativeBitmap; long nativeSize = NATIVE_ALLOCATION_SIZE + getAllocationByteCount(); \u0026lt;!--辅助回收native内存--\u0026gt; NativeAllocationRegistry registry = new NativeAllocationRegistry( Bitmap.class.getClassLoader(), nativeGetNativeFinalizer(), nativeSize); registry.registerNativeAllocation(this, nativeBitmap); if (ResourcesImpl.TRACE_FOR_DETAILED_PRELOAD) { sPreloadTracingNumInstantiatedBitmaps++; sPreloadTracingTotalBitmapsSize += nativeSize; } } 当然这个功能也要Java虚拟机的支持，有机会再分析。\n"
},
{
	"uri": "https://huanle19891345.github.io/en/supporttoandroidx/",
	"title": "First_Level2",
	"tags": [],
	"description": "",
	"content": "title1 Title2 https://developer.android.google.cn/jetpack/androidx/migrate?hl=zh-cn\nhttps://medium.com/androiddevelopers/migrating-to-androidx-tip-tricks-and-guidance-88d5de238876\n是时候迁移至 AndroidX 了！\n新架构单独封装一个独立的module(使用androidx)，和xhcore相互独立，确保项目组可以选择使用\nsupport和androidx必须通过cherrypick进行修改同步，同时分别发布独立的maven\ntest模块是support或者androidx都没关系，不影响发版仓库中的内容\n更基础的依赖模块，可能是support/androidx无关的，也可能有关的，有关时xhcore中调用的模块也要分离出support和androidx\nxhcorexxx_without_support_single_branch模块可以不存在\nandroidx利用灰度版本去进行测试901\ngraph TB app_support--component_support_branch app_support--xhcorexxx_without_support_single_branch  graph TB app_support--\u0026gt;component_support_branch app_support--\u0026gt;xhcorexxx_without_support_single_branch app_androidx--\u0026gt;component_androidx_branch app_androidx--\u0026gt;xhcorexxx_without_support_single_branch xhcorexxx_without_support_single_branch--\u0026gt;xhviewxxx_without_support_single_branch component_support_branch--\u0026gt;xhviewxxx_support_branch component_androidx_branch--\u0026gt;xhviewxxx_androidx_branch   在xhcore中搜索support进行处理,去除不必要的support库依赖\n  support升级到28\n  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/supporttoandroidx/",
	"title": "First_Level3",
	"tags": ["tag1", "tag2", "tag3"],
	"description": "",
	"content": "title1 Title2 https://developer.android.google.cn/jetpack/androidx/migrate?hl=zh-cn\nhttps://medium.com/androiddevelopers/migrating-to-androidx-tip-tricks-and-guidance-88d5de238876\n是时候迁移至 AndroidX 了！\n新架构单独封装一个独立的module(使用androidx)，和xhcore相互独立，确保项目组可以选择使用\nsupport和androidx必须通过cherrypick进行修改同步，同时分别发布独立的maven\ntest模块是support或者androidx都没关系，不影响发版仓库中的内容\n更基础的依赖模块，可能是support/androidx无关的，也可能有关的，有关时xhcore中调用的模块也要分离出support和androidx\nxhcorexxx_without_support_single_branch模块可以不存在\nandroidx利用灰度版本去进行测试901\ngraph TB app_support--component_support_branch app_support--xhcorexxx_without_support_single_branch  graph TB app_support--\u0026gt;component_support_branch app_support--\u0026gt;xhcorexxx_without_support_single_branch app_androidx--\u0026gt;component_androidx_branch app_androidx--\u0026gt;xhcorexxx_without_support_single_branch xhcorexxx_without_support_single_branch--\u0026gt;xhviewxxx_without_support_single_branch component_support_branch--\u0026gt;xhviewxxx_support_branch component_androidx_branch--\u0026gt;xhviewxxx_androidx_branch   在xhcore中搜索support进行处理,去除不必要的support库依赖\n  support升级到28\n  "
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/supporttoandroidx-copy/",
	"title": "First_Levelcopy",
	"tags": ["tag2", "tag3"],
	"description": "",
	"content": "title1 Title2 https://developer.android.google.cn/jetpack/androidx/migrate?hl=zh-cn\nhttps://medium.com/androiddevelopers/migrating-to-androidx-tip-tricks-and-guidance-88d5de238876\n是时候迁移至 AndroidX 了！\n新架构单独封装一个独立的module(使用androidx)，和xhcore相互独立，确保项目组可以选择使用\nsupport和androidx必须通过cherrypick进行修改同步，同时分别发布独立的maven\ntest模块是support或者androidx都没关系，不影响发版仓库中的内容\n更基础的依赖模块，可能是support/androidx无关的，也可能有关的，有关时xhcore中调用的模块也要分离出support和androidx\nxhcorexxx_without_support_single_branch模块可以不存在\nandroidx利用灰度版本去进行测试901\ngraph TB app_support--component_support_branch app_support--xhcorexxx_without_support_single_branch  graph TB app_support--\u0026gt;component_support_branch app_support--\u0026gt;xhcorexxx_without_support_single_branch app_androidx--\u0026gt;component_androidx_branch app_androidx--\u0026gt;xhcorexxx_without_support_single_branch xhcorexxx_without_support_single_branch--\u0026gt;xhviewxxx_without_support_single_branch component_support_branch--\u0026gt;xhviewxxx_support_branch component_androidx_branch--\u0026gt;xhviewxxx_androidx_branch   在xhcore中搜索support进行处理,去除不必要的support库依赖\n  support升级到28\n  "
},
{
	"uri": "https://huanle19891345.github.io/en/first_post/",
	"title": "First_post2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/tags/tag1/",
	"title": "tag1",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/tags/tag2/",
	"title": "tag2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/tags/tag3/",
	"title": "tag3",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/categories/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96%E4%BC%98%E5%8C%96/",
	"title": "内存优化优化",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/categories/%E5%B8%83%E5%B1%80%E4%BC%98%E5%8C%96/",
	"title": "布局优化",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/categories/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/",
	"title": "性能优化",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E7%BB%98%E5%88%B6source/",
	"title": "硬件加速绘制",
	"tags": [],
	"description": "",
	"content": "graph TB IRenderPipeline--\u0026gt;OpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaOpenGLPipeline IRenderPipeline--\u0026gt;SkiaPipeline--\u0026gt;SkiaVulkanPipeline graph TB Thread--\u0026gt;ThreadBase ThreadBase--\u0026gt;ReanderThread frameworks/base/core/java/android/view/IWindow.aidl\nIWindow /** * API back to a client window that the Window Manager uses to inform it of * interesting things happening. * * {@hide} */ oneway interface IWindow {} frameworks/base/core/java/android/view/IWindowSession.aidl\nIWindowSession /** * System private per-application interface to the window manager. * * {@hide} */ interface IWindowSession {} ViewRootImpl // These can be accessed by any thread, must be protected with a lock.  // Surface can never be reassigned or cleared (use Surface.clear()).  public final Surface mSurface = new Surface(); setView /** * We have one child */ public void setView(View view, WindowManager.LayoutParams attrs, View panelParentView) { // If the application owns the surface, don\u0026#39;t enable hardware acceleration  if (mSurfaceHolder == null) { // While this is supposed to enable only, it can effectively disable  // the acceleration too.  enableHardwareAcceleration(attrs); } // Schedule the first layout -before- adding to the window  // manager, to make sure we do the relayout before receiving  // any other events from the system.  requestLayout(); //mWindowSession是一个aidl，ViewRootImpl利用它来和WindowManagerService交互  //mWindow是一个aidl，WindowManagerService可以利用这个对象与服务端交互  res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); } enableHardwareAcceleration private void enableHardwareAcceleration(WindowManager.LayoutParams attrs) { // Try to enable hardware acceleration if requested  final boolean hardwareAccelerated = (attrs.flags \u0026amp; WindowManager.LayoutParams.FLAG_HARDWARE_ACCELERATED) != 0; if (hardwareAccelerated) { mAttachInfo.mThreadedRenderer = ThreadedRenderer.create(mContext, translucent, attrs.getTitle().toString()); if (mAttachInfo.mThreadedRenderer != null) { mAttachInfo.mHardwareAccelerated = mAttachInfo.mHardwareAccelerationRequested = true; } } } draw private boolean draw(boolean fullRedrawNeeded) { Surface surface = mSurface; if (!surface.isValid()) { return false; } if (!dirty.isEmpty() || mIsAnimating || accessibilityFocusDirty) { if (mAttachInfo.mThreadedRenderer != null \u0026amp;\u0026amp; mAttachInfo.mThreadedRenderer.isEnabled()) { mAttachInfo.mThreadedRenderer.draw(mView, mAttachInfo, this, callback); } else { drawSoftware(surface, mAttachInfo, xOffset, yOffset, scalingRequired, dirty, surfaceInsets) } } } ThreadedRenderer\ndrawSoftware /** * @return true if drawing was successful, false if an error occurred */ private boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty, Rect surfaceInsets) { // Draw with software renderer.  final Canvas canvas; canvas = mSurface.lockCanvas(dirty); ...... mView.draw(canvas); ...... surface.unlockCanvasAndPost(canvas); } lockCanvas\nnativeUnlockCanvasAndPost\nperformTraversals private void performTraversals() { // Execute enqueued actions on every traversal in case a detached view enqueued an action  host.dispatchAttachedToWindow(mAttachInfo, 0); relayoutResult = relayoutWindow(params, viewVisibility, insetsPending); if (mSurface.isValid()) { // If we are creating a new surface, then we need to  // completely redraw it. Also, when we get to the  // point of drawing it we will hold off and schedule  // a new traversal instead. This is so we can tell the  // window manager about all of the windows being displayed  // before actually drawing them, so it can display then  // all at once.  newSurface = true; mFullRedrawNeeded = true; mPreviousTransparentRegion.setEmpty(); // Only initialize up-front if transparent regions are not  // requested, otherwise defer to see if the entire window  // will be transparent  if (mAttachInfo.mThreadedRenderer != null) { hwInitialized = mAttachInfo.mThreadedRenderer.initialize(mSurface); if (hwInitialized \u0026amp;\u0026amp; (host.mPrivateFlags \u0026amp; View.PFLAG_REQUEST_TRANSPARENT_REGIONS) == 0) { // Don\u0026#39;t pre-allocate if transparent regions  // are requested as they may not be needed  mSurface.allocateBuffers(); } } } // Ask host how big it wants to be  performMeasure(childWidthMeasureSpec, childHeightMeasureSpec); ...... performLayout(lp, mWidth, mHeight); ...... performDraw(); ThreadedRenderer Surface\nrelayoutWindow private int relayoutWindow(WindowManager.LayoutParams params, int viewVisibility, boolean insetsPending) throws RemoteException { int relayoutResult = mWindowSession.relayout(mWindow, mSeq, params, (int) (mView.getMeasuredWidth() * appScale + 0.5f), (int) (mView.getMeasuredHeight() * appScale + 0.5f), viewVisibility, insetsPending ? WindowManagerGlobal.RELAYOUT_INSETS_PENDING : 0, frameNumber, mWinFrame, mPendingOverscanInsets, mPendingContentInsets, mPendingVisibleInsets, mPendingStableInsets, mPendingOutsets, mPendingBackDropFrame, mPendingDisplayCutout, mPendingMergedConfiguration, mSurface); } frameworks/base/services/core/java/com/android/server/wm/Session.java\nSession addToDisplay @Override public int addToDisplay(IWindow window, int seq, WindowManager.LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { return mService.addWindow(this, window, seq, attrs, viewVisibility, displayId, outFrame, outContentInsets, outStableInsets, outOutsets, outDisplayCutout, outInputChannel); } windowAddedLocked void windowAddedLocked(String packageName) { if (mSurfaceSession == null) { mSurfaceSession = new SurfaceSession(); mService.mSessions.add(this); } } relayout @Override public int relayout(IWindow window, int seq, WindowManager.LayoutParams attrs, int requestedWidth, int requestedHeight, int viewFlags, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper cutout, MergedConfiguration mergedConfiguration, Surface outSurface) { int res = mService.relayoutWindow(this, window, seq, attrs, requestedWidth, requestedHeight, viewFlags, flags, frameNumber, outFrame, outOverscanInsets, outContentInsets, outVisibleInsets, outStableInsets, outsets, outBackdropFrame, cutout, mergedConfiguration, outSurface); return res; } frameworks/base/services/core/java/com/android/server/wm/WindowManagerService.java\nWindowManagerService addWindow public int addWindow(Session session, IWindow client, int seq, LayoutParams attrs, int viewVisibility, int displayId, Rect outFrame, Rect outContentInsets, Rect outStableInsets, Rect outOutsets, DisplayCutout.ParcelableWrapper outDisplayCutout, InputChannel outInputChannel) { //WindowState用来描述一个Window  //生成WindowState对象，它是ViewRootImpl 在WindowManager Service端的代表。在它的构造函数里，WindowState 会生成IWindowId.Stub 对象和DeathRecipient对象来分别监听Focus和窗口死亡的信息  final WindowState win = new WindowState(this, session, client, token, parentWindow, appOp[0], seq, attrs, viewVisibility, session.mUid, session.mCanAddInternalSystemWindow); //创建用于通信的SocketPair , 将其传给InputManagerService, 用于接下来的用户输入事件对应的响应窗口（参考Android的用户输入处理）  final boolean openInputChannels = (outInputChannel != null \u0026amp;\u0026amp; (attrs.inputFeatures \u0026amp; INPUT_FEATURE_NO_INPUT_CHANNEL) == 0); if (openInputChannels) { win.openInputChannel(outInputChannel); } //创建了一个Surface Session 并将Surface Session，WindowSession 还有WindowState 三者关联起来.  win.attach(); //mWindowMap是WindowManagerService用来保存当前所有Window新的的集合  mWindowMap.put(client.asBinder(), win); //一个token下会有多个win state。 其实token与PhoneWindow是一一对应的。  win.mToken.addWindow(win); } relayoutWindow public int relayoutWindow(Session session, IWindow client, int seq, LayoutParams attrs, int requestedWidth, int requestedHeight, int viewVisibility, int flags, long frameNumber, Rect outFrame, Rect outOverscanInsets, Rect outContentInsets, Rect outVisibleInsets, Rect outStableInsets, Rect outOutsets, Rect outBackdropFrame, DisplayCutout.ParcelableWrapper outCutout, MergedConfiguration mergedConfiguration, Surface outSurface) { result = createSurfaceControl(outSurface, result, win, winAnimator); } createSurfaceControl private int createSurfaceControl(Surface outSurface, int result, WindowState win,WindowStateAnimator winAnimator) { ... surfaceController = winAnimator.createSurfaceLocked(win.mAttrs.type, win.mOwnerUid); ... surfaceController.getSurface(outSurface); } WindowStateAnimator createSurfaceLocked WindowSurfaceController createSurfaceLocked(int windowType, int ownerUid) { mSurfaceController = new WindowSurfaceController(mSession.mSurfaceSession, attrs.getTitle().toString(), width, height, format, flags, this, windowType, ownerUid); } WindowSurfaceController SurfaceControl mSurfaceControl; public WindowSurfaceController(SurfaceSession s, String name, int w, int h, int format, int flags, WindowStateAnimator animator, int windowType, int ownerUid) { final SurfaceControl.Builder b = win.makeSurface() .setParent(win.getSurfaceControl()) .setName(name) .setSize(w, h) .setFormat(format) .setFlags(flags) .setMetadata(windowType, ownerUid); mSurfaceControl = b.build(); } getSurface void getSurface(Surface outSurface) { outSurface.copyFrom(mSurfaceControl); } copyFrom\nSurfaceControl.java Builder.build /** * Construct a new {@link SurfaceControl} with the set parameters. */ public SurfaceControl build() { return new SurfaceControl(mSession, mName, mWidth, mHeight, mFormat, mFlags, mParent, mWindowType, mOwnerUid); } /** Good practice is to first create the surface with the {@link #HIDDEN} flag * specified, open a transaction, set the surface layer, layer stack, alpha, * and position, call {@link #show} if appropriate, and close the transaction. **/ private SurfaceControl(SurfaceSession session, String name, int w, int h, int format, int flags, SurfaceControl parent, int windowType, int ownerUid) throws OutOfResourcesException, IllegalArgumentException { mNativeObject = nativeCreate(session, name, w, h, format, flags, parent != null ? parent.mNativeObject : 0, windowType, ownerUid); } frameworks/base/core/jni/android_view_SurfaceControl.cpp\nandroid_view_SurfaceControl nativeCreate static jlong nativeCreate(JNIEnv* env, jclass clazz, jobject sessionObj, jstring nameStr, jint w, jint h, jint format, jint flags, jlong parentObject, jint windowType, jint ownerUid) { ScopedUtfChars name(env, nameStr); //这个client其实就是前面创建的SurfaceComposerClinent  sp\u0026lt;SurfaceComposerClient\u0026gt; client(android_view_SurfaceSession_getClient(env, sessionObj)); SurfaceControl *parent = reinterpret_cast\u0026lt;SurfaceControl*\u0026gt;(parentObject); sp\u0026lt;SurfaceControl\u0026gt; surface; status_t err = client-\u0026gt;createSurfaceChecked( String8(name.c_str()), w, h, format, \u0026amp;surface, flags, parent, windowType, ownerUid); surface-\u0026gt;incStrong((void *)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } frameworks/base/services/core/java/com/android/server/wm/WindowState.java\nWindowState openInputChannel void openInputChannel(InputChannel outInputChannel) { if (mInputChannel != null) { throw new IllegalStateException(\u0026#34;Window already has an input channel.\u0026#34;); } String name = getName(); InputChannel[] inputChannels = InputChannel.openInputChannelPair(name);//refer to TouchEventNative.md  mInputChannel = inputChannels[0]; mClientChannel = inputChannels[1]; mInputWindowHandle.inputChannel = inputChannels[0]; if (outInputChannel != null) { mClientChannel.transferTo(outInputChannel); mClientChannel.dispose(); mClientChannel = null; } else { // If the window died visible, we setup a dummy input channel, so that taps  // can still detected by input monitor channel, and we can relaunch the app.  // Create dummy event receiver that simply reports all events as handled.  mDeadWindowEventReceiver = new DeadWindowEventReceiver(mClientChannel); } mService.mInputManager.registerInputChannel(mInputChannel, mInputWindowHandle);//refer to TouchEventNative.md  } attach void attach() { mSession.windowAddedLocked(mAttrs.packageName); } SurfaceSession /** * An instance of this class represents a connection to the surface * flinger, from which you can create one or more Surface instances that will * be composited to the screen. */ public final class SurfaceSession { // Note: This field is accessed by native code.  private long mNativeClient; // SurfaceComposerClient* } SurfaceSession() /** Create a new connection with the surface flinger. */ public SurfaceSession() { mNativeClient = nativeCreate(); } frameworks/base/core/jni/android_view_SurfaceSession.cpp\nandroid_view_SurfaceSession.cpp nativeCreate static jlong nativeCreate(JNIEnv* env, jclass clazz) { SurfaceComposerClient* client = new SurfaceComposerClient(); client-\u0026gt;incStrong((void*)nativeCreate); return reinterpret_cast\u0026lt;jlong\u0026gt;(client); } SurfaceComposerClient onFirstRef void SurfaceComposerClient::onFirstRef() { sp\u0026lt;ISurfaceComposer\u0026gt; sf(ComposerService::getComposerService());//sf 就是SurfaceFlinger Service  if (sf != 0 \u0026amp;\u0026amp; mStatus == NO_INIT) { auto rootProducer = mParent.promote(); sp\u0026lt;ISurfaceComposerClient\u0026gt; conn; conn = (rootProducer != nullptr) ? sf-\u0026gt;createScopedConnection(rootProducer) : sf-\u0026gt;createConnection(); if (conn != 0) { mClient = conn; mStatus = NO_ERROR; } } } createSurfaceChecked status_t SurfaceComposerClient::createSurfaceChecked( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, sp\u0026lt;SurfaceControl\u0026gt;* outSurface, uint32_t flags, SurfaceControl* parent, int32_t windowType, int32_t ownerUid) { sp\u0026lt;SurfaceControl\u0026gt; sur; sp\u0026lt;IBinder\u0026gt; handle; sp\u0026lt;IBinder\u0026gt; parentHandle; sp\u0026lt;IGraphicBufferProducer\u0026gt; gbp; if (parent != nullptr) { parentHandle = parent-\u0026gt;getHandle(); } err = mClient-\u0026gt;createSurface(name, w, h, format, flags, parentHandle, windowType, ownerUid, \u0026amp;handle, \u0026amp;gbp); if (err == NO_ERROR) { *outSurface = new SurfaceControl(this, handle, gbp, true /* owned */); } return err; } frameworks/native/services/surfaceflinger/SurfaceFlinger.cpp\nSurfaceFlinger createConnection sp\u0026lt;ISurfaceComposerClient\u0026gt; SurfaceFlinger::createConnection() { return initClient(new Client(this)); } createLayer status_t SurfaceFlinger::createLayer( const String8\u0026amp; name, const sp\u0026lt;Client\u0026gt;\u0026amp; client, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* parent) { sp\u0026lt;Layer\u0026gt; layer; String8 uniqueName = getUniqueLayerName(name); switch (flags \u0026amp; ISurfaceComposerClient::eFXSurfaceMask) { case ISurfaceComposerClient::eFXSurfaceNormal: result = createBufferLayer(client, uniqueName, w, h, flags, format, handle, gbp, \u0026amp;layer); break; } result = addClientLayer(client, *handle, *gbp, layer, *parent); return result; } createBufferLayer status_t SurfaceFlinger::createBufferLayer(const sp\u0026lt;Client\u0026gt;\u0026amp; client, const String8\u0026amp; name, uint32_t w, uint32_t h, uint32_t flags, PixelFormat\u0026amp; format, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp, sp\u0026lt;Layer\u0026gt;* outLayer) { // initialize the surfaces  switch (format) { case PIXEL_FORMAT_TRANSPARENT: case PIXEL_FORMAT_TRANSLUCENT: format = PIXEL_FORMAT_RGBA_8888; break; case PIXEL_FORMAT_OPAQUE: format = PIXEL_FORMAT_RGBX_8888; break; } sp\u0026lt;BufferLayer\u0026gt; layer = new BufferLayer(this, client, name, w, h, flags); status_t err = layer-\u0026gt;setBuffers(w, h, format, flags); if (err == NO_ERROR) { *handle = layer-\u0026gt;getHandle(); *gbp = layer-\u0026gt;getProducer(); *outLayer = layer; } return err; } frameworks/native/services/surfaceflinger/BufferLayer.cpp\nBufferLayer getProducer sp\u0026lt;IGraphicBufferProducer\u0026gt; BufferLayer::getProducer() const { return mProducer; } onFirstRef void BufferLayer::onFirstRef() { // Creates a custom BufferQueue for SurfaceFlingerConsumer to use  sp\u0026lt;IGraphicBufferProducer\u0026gt; producer; sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer; BufferQueue::createBufferQueue(\u0026amp;producer, \u0026amp;consumer, true); //MonitoredProducer只是一个装饰类，它实际功能都委托给构造它的参数producer  mProducer = new MonitoredProducer(producer, mFlinger, this); mConsumer = new BufferLayerConsumer(consumer, mFlinger-\u0026gt;getRenderEngine(), mTextureName, this); const sp\u0026lt;const DisplayDevice\u0026gt; hw(mFlinger-\u0026gt;getDefaultDisplayDevice()); updateTransformHint(hw); } frameworks/native/libs/gui/BufferQueue.cpp\nBufferQueue createBufferQueue void BufferQueue::createBufferQueue(sp\u0026lt;IGraphicBufferProducer\u0026gt;* outProducer, sp\u0026lt;IGraphicBufferConsumer\u0026gt;* outConsumer, bool consumerIsSurfaceFlinger) { sp\u0026lt;BufferQueueCore\u0026gt; core(new BufferQueueCore()); sp\u0026lt;IGraphicBufferProducer\u0026gt; producer(new BufferQueueProducer(core, consumerIsSurfaceFlinger)); sp\u0026lt;IGraphicBufferConsumer\u0026gt; consumer(new BufferQueueConsumer(core)); *outProducer = producer; *outConsumer = consumer; } frameworks/native/libs/gui/include/gui/BufferQueueCore.h\nBufferQueueCore // mQueue is a FIFO of queued buffers used in synchronous mode.  Fifo mQueue; // mFreeSlots contains all of the slots which are FREE and do not currently  // have a buffer attached.  std::set\u0026lt;int\u0026gt; mFreeSlots; // mFreeBuffers contains all of the slots which are FREE and currently have  // a buffer attached.  std::list\u0026lt;int\u0026gt; mFreeBuffers; // mConsumerListener is used to notify the connected consumer of  // asynchronous events that it may wish to react to. It is initially  // set to NULL and is written by consumerConnect and consumerDisconnect.  sp\u0026lt;IConsumerListener\u0026gt; mConsumerListener; frameworks/native/libs/gui/BufferQueueProducer.cpp\nBufferQueueProducer class BufferQueueProducer : public BnGraphicBufferProducer, private IBinder::DeathRecipient { dequeueBuffer status_t BufferQueueProducer::dequeueBuffer(int* outSlot, sp\u0026lt;android::Fence\u0026gt;* outFence, uint32_t width, uint32_t height, PixelFormat format, uint64_t usage, uint64_t* outBufferAge, FrameEventHistoryDelta* outTimestamps) { int found = BufferItem::INVALID_BUFFER_SLOT; while (found == BufferItem::INVALID_BUFFER_SLOT) { status_t status = waitForFreeSlotThenRelock(FreeSlotCaller::Dequeue, \u0026amp;found); } const sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; buffer(mSlots[found].mGraphicBuffer); *outSlot = found; if ((buffer == NULL) || buffer-\u0026gt;needsReallocation(width, height, format, BQ_LAYER_COUNT, usage)) { returnFlags |= BUFFER_NEEDS_REALLOCATION; } if (returnFlags \u0026amp; BUFFER_NEEDS_REALLOCATION) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( width, height, format, BQ_LAYER_COUNT, usage, {mConsumerName.string(), mConsumerName.size()}); status_t error = graphicBuffer-\u0026gt;initCheck(); } } GraphicBuffer\nwaitForFreeSlotThenRelock status_t BufferQueueProducer::waitForFreeSlotThenRelock(FreeSlotCaller caller, int* found) const { // If we disconnect and reconnect quickly, we can be in a state where  // our slots are empty but we have many buffers in the queue. This can  // cause us to run out of memory if we outrun the consumer. Wait here if  // it looks like we have too many buffers queued up.  const int maxBufferCount = mCore-\u0026gt;getMaxBufferCountLocked(); bool tooManyBuffers = mCore-\u0026gt;mQueue.size() \u0026gt; static_cast\u0026lt;size_t\u0026gt;(maxBufferCount); if (tooManyBuffers) { BQ_LOGV(\u0026#34;%s: queue size is %zu, waiting\u0026#34;, callerString, mCore-\u0026gt;mQueue.size()); } else { // If in shared buffer mode and a shared buffer exists, always  // return it.  if (mCore-\u0026gt;mSharedBufferMode \u0026amp;\u0026amp; mCore-\u0026gt;mSharedBufferSlot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = mCore-\u0026gt;mSharedBufferSlot; } else { if (caller == FreeSlotCaller::Dequeue) { // If we\u0026#39;re calling this from dequeue, prefer free buffers  int slot = getFreeBufferLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else if (mCore-\u0026gt;mAllowAllocation) { *found = getFreeSlotLocked(); } } else { // If we\u0026#39;re calling this from attach, prefer free slots  int slot = getFreeSlotLocked(); if (slot != BufferQueueCore::INVALID_BUFFER_SLOT) { *found = slot; } else { *found = getFreeBufferLocked(); } } } } } getFreeBufferLocked int BufferQueueProducer::getFreeBufferLocked() const { if (mCore-\u0026gt;mFreeBuffers.empty()) { return BufferQueueCore::INVALID_BUFFER_SLOT; } int slot = mCore-\u0026gt;mFreeBuffers.front(); mCore-\u0026gt;mFreeBuffers.pop_front(); return slot; } requestBuffer status_t BufferQueueProducer::requestBuffer(int slot, sp\u0026lt;GraphicBuffer\u0026gt;* buf) { mSlots[slot].mRequestBufferCalled = true; *buf = mSlots[slot].mGraphicBuffer; } allocateBuffers void BufferQueueProducer::allocateBuffers(uint32_t width, uint32_t height, PixelFormat format, uint64_t usage) { Vector\u0026lt;sp\u0026lt;GraphicBuffer\u0026gt;\u0026gt; buffers; for (size_t i = 0; i \u0026lt; newBufferCount; ++i) { sp\u0026lt;GraphicBuffer\u0026gt; graphicBuffer = new GraphicBuffer( allocWidth, allocHeight, allocFormat, BQ_LAYER_COUNT, allocUsage, allocName); status_t result = graphicBuffer-\u0026gt;initCheck(); buffers.push_back(graphicBuffer); } } GraphicBuffer\nframeworks/native/libs/gui/include/gui/BufferQueueConsumer.h\nBufferQueueConsumer class BufferQueueConsumer : public BnGraphicBufferConsumer { // connect connects a consumer to the BufferQueue. Only one  // consumer may be connected, and when that consumer disconnects the  // BufferQueue is placed into the \u0026#34;abandoned\u0026#34; state, causing most  // interactions with the BufferQueue by the producer to fail.  // controlledByApp indicates whether the consumer is controlled by  // the application.  //  // consumerListener may not be NULL.  virtual status_t connect(const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp); } status_t BufferQueueConsumer::connect( const sp\u0026lt;IConsumerListener\u0026gt;\u0026amp; consumerListener, bool controlledByApp) { mCore-\u0026gt;mConsumerListener = consumerListener; mCore-\u0026gt;mConsumerControlledByApp = controlledByApp; return NO_ERROR; } frameworks/native/services/surfaceflinger/Client.h\nClient class Client : public BnSurfaceComposerClient { public: ... void attachLayer(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle, const sp\u0026lt;Layer\u0026gt;\u0026amp; layer); void detachLayer(const Layer* layer); ... private: // ISurfaceComposerClient interface。 gbp很重要，它维护这一个应用程序的渲染 Buffer队列  virtual status_t createSurface(...sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp); virtual status_t destroySurface(const sp\u0026lt;IBinder\u0026gt;\u0026amp; handle); //跨进程通信方法  virtual status_t onTransact(uint32_t code, const Parcel\u0026amp; data, Parcel* reply, uint32_t flags); ... // constant  sp\u0026lt;SurfaceFlinger\u0026gt; mFlinger; // protected by mLock  DefaultKeyedVector\u0026lt; wp\u0026lt;IBinder\u0026gt;, wp\u0026lt;Layer\u0026gt; \u0026gt; mLayers; // 一个应用程序的所有Layer  ... }; createSurface status_t Client::createSurface( const String8\u0026amp; name, uint32_t w, uint32_t h, PixelFormat format, uint32_t flags, const sp\u0026lt;IBinder\u0026gt;\u0026amp; parentHandle, int32_t windowType, int32_t ownerUid, sp\u0026lt;IBinder\u0026gt;* handle, sp\u0026lt;IGraphicBufferProducer\u0026gt;* gbp) { //postMessageSync到surfaceFlinger的主线程中处理消息任务，如下:  result = flinger-\u0026gt;createLayer(name, client, w, h, format, flags, windowType, ownerUid, handle, gbp, parent); } Surface /** * Handle onto a raw buffer that is being managed by the screen compositor. * * \u0026lt;p\u0026gt;A Surface is generally created by or from a consumer of image buffers (such as a * {@link android.graphics.SurfaceTexture}, {@link android.media.MediaRecorder}, or * {@link android.renderscript.Allocation}), and is handed to some kind of producer (such as * {@link android.opengl.EGL14#eglCreateWindowSurface(android.opengl.EGLDisplay,android.opengl.EGLConfig,java.lang.Object,int[],int) OpenGL}, * {@link android.media.MediaPlayer#setSurface MediaPlayer}, or * {@link android.hardware.camera2.CameraDevice#createCaptureSession CameraDevice}) to draw * into.\u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Note:\u0026lt;/strong\u0026gt; A Surface acts like a * {@link java.lang.ref.WeakReference weak reference} to the consumer it is associated with. By * itself it will not keep its parent consumer from being reclaimed.\u0026lt;/p\u0026gt; */ public class Surface implements Parcelable { } copyFrom /** * Copy another surface to this one. This surface now holds a reference * to the same data as the original surface, and is -not- the owner. * This is for use by the window manager when returning a window surface * back from a client, converting it from the representation being managed * by the window manager to the representation the client uses to draw * in to it. * * @param other {@link SurfaceControl} to copy from. * */ public void copyFrom(SurfaceControl other) { long surfaceControlPtr = other.mNativeObject; long newNativeObject = nativeGetFromSurfaceControl(surfaceControlPtr); synchronized (mLock) { if (mNativeObject != 0) { nativeRelease(mNativeObject); } setNativeObjectLocked(newNativeObject); } } nativeGetFromSurfaceControl\nallocateBuffers /** * Allocate buffers ahead of time to avoid allocation delays during rendering * @hide */ public void allocateBuffers() { synchronized (mLock) { checkNotReleasedLocked(); nativeAllocateBuffers(mNativeObject); } } nativeAllocateBuffers\ncome from performTraversals\nlockCanvas public Canvas lockCanvas(Rect inOutDirty) throws Surface.OutOfResourcesException, IllegalArgumentException { synchronized (mLock) { mLockedObject = nativeLockCanvas(mNativeObject, mCanvas, inOutDirty); return mCanvas; } } nativeLockCanvas\nframeworks/base/core/jni/android_view_Surface.cpp\nandroid_view_Surface nativeGetFromSurfaceControl static jlong nativeGetFromSurfaceControl(JNIEnv* env, jclass clazz, jlong surfaceControlNativeObj) { /* * This is used by the WindowManagerService just after constructing * a Surface and is necessary for returning the Surface reference to * the caller. At this point, we should only have a SurfaceControl. */ sp\u0026lt;SurfaceControl\u0026gt; ctrl(reinterpret_cast\u0026lt;SurfaceControl *\u0026gt;(surfaceControlNativeObj)); sp\u0026lt;Surface\u0026gt; surface(ctrl-\u0026gt;getSurface()); if (surface != NULL) { surface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); } return reinterpret_cast\u0026lt;jlong\u0026gt;(surface.get()); } SurfaceControl\nnativeAllocateBuffers static void nativeAllocateBuffers(JNIEnv* /* env */ , jclass /* clazz */, jlong nativeObject) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } surface-\u0026gt;allocateBuffers(); } Surface.cpp\nnativeLockCanvas static jlong nativeLockCanvas(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj, jobject dirtyRectObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); ANativeWindow_Buffer outBuffer; status_t err = surface-\u0026gt;lock(\u0026amp;outBuffer, dirtyRectPtr); SkImageInfo info = SkImageInfo::Make(outBuffer.width, outBuffer.height, convertPixelFormat(outBuffer.format), outBuffer.format == PIXEL_FORMAT_RGBX_8888 ? kOpaque_SkAlphaType : kPremul_SkAlphaType, GraphicsJNI::defaultColorSpace()); SkBitmap bitmap; ssize_t bpr = outBuffer.stride * bytesPerPixel(outBuffer.format); bitmap.setInfo(info, bpr); if (outBuffer.width \u0026gt; 0 \u0026amp;\u0026amp; outBuffer.height \u0026gt; 0) { bitmap.setPixels(outBuffer.bits); } Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); //bitmap对下关联了获取的内存buffer，对上关联了Canvas,把这个bitmap放入Canvas中  nativeCanvas-\u0026gt;setBitmap(bitmap); if (dirtyRectPtr) { nativeCanvas-\u0026gt;clipRect(dirtyRect.left, dirtyRect.top, dirtyRect.right, dirtyRect.bottom, SkClipOp::kIntersect); } // Create another reference to the surface and return it. This reference  // should be passed to nativeUnlockCanvasAndPost in place of mNativeObject,  // because the latter could be replaced while the surface is locked.  sp\u0026lt;Surface\u0026gt; lockedSurface(surface); lockedSurface-\u0026gt;incStrong(\u0026amp;sRefBaseOwner); return (jlong) lockedSurface.get(); } lock\nnativeUnlockCanvasAndPost static void nativeUnlockCanvasAndPost(JNIEnv* env, jclass clazz, jlong nativeObject, jobject canvasObj) { sp\u0026lt;Surface\u0026gt; surface(reinterpret_cast\u0026lt;Surface *\u0026gt;(nativeObject)); if (!isSurfaceValid(surface)) { return; } // detach the canvas from the surface  Canvas* nativeCanvas = GraphicsJNI::getNativeCanvas(env, canvasObj); nativeCanvas-\u0026gt;setBitmap(SkBitmap()); // unlock surface  status_t err = surface-\u0026gt;unlockAndPost(); } frameworks/native/libs/gui/SurfaceControl.cpp\nSurfaceControl getSurface sp\u0026lt;Surface\u0026gt; SurfaceControl::getSurface() const { Mutex::Autolock _l(mLock); if (mSurfaceData == 0) { return generateSurfaceLocked(); } return mSurfaceData; } generateSurfaceLocked sp\u0026lt;Surface\u0026gt; SurfaceControl::generateSurfaceLocked() const { // This surface is always consumed by SurfaceFlinger, so the  // producerControlledByApp value doesn\u0026#39;t matter; using false.  //这个mGraphicBufferProducer其实就是上面分析的BufferQueueProducer  mSurfaceData = new Surface(mGraphicBufferProducer, false); return mSurfaceData; } frameworks/native/libs/gui/Surface.cpp\nSurface.cpp struct BufferSlot // mSurfaceTexture is the interface to the surface texture server. All  // operations on the surface texture client ultimately translate into  // interactions with the server using this interface.  sp\u0026lt;IGraphicBufferProducer\u0026gt; mGraphicBufferProducer; struct BufferSlot { sp\u0026lt;GraphicBuffer\u0026gt; buffer; Region dirtyRegion; }; // mSlots stores the buffers that have been allocated for each buffer slot.  // It is initialized to null pointers, and gets filled in with the result of  // IGraphicBufferProducer::requestBuffer when the client dequeues a buffer from a  // slot that has not yet been used. The buffer allocated to a slot will also  // be replaced if the requested buffer usage or geometry differs from that  // of the buffer allocated to a slot.  BufferSlot mSlots[NUM_BUFFER_SLOTS]; Surface() Surface::Surface(const sp\u0026lt;IGraphicBufferProducer\u0026gt;\u0026amp; bufferProducer, bool controlledByApp) : mGraphicBufferProducer(bufferProducer), allocateBuffers void Surface::allocateBuffers() { uint32_t reqWidth = mReqWidth ? mReqWidth : mUserWidth; uint32_t reqHeight = mReqHeight ? mReqHeight : mUserHeight; mGraphicBufferProducer-\u0026gt;allocateBuffers(reqWidth, reqHeight, mReqFormat, mReqUsage); } BufferQueueProducer\nlock status_t Surface::lock(ANativeWindow_Buffer* outBuffer, ARect* inOutDirtyBounds) { ANativeWindowBuffer* out; int fenceFd = -1; status_t err = dequeueBuffer(\u0026amp;out, \u0026amp;fenceFd); sp\u0026lt;GraphicBuffer\u0026gt; backBuffer(GraphicBuffer::getSelf(out)); status_t res = backBuffer-\u0026gt;lockAsync( GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN, newDirtyRegion.bounds(), \u0026amp;vaddr, fenceFd); mLockedBuffer = backBuffer; outBuffer-\u0026gt;width = backBuffer-\u0026gt;width; outBuffer-\u0026gt;height = backBuffer-\u0026gt;height; outBuffer-\u0026gt;stride = backBuffer-\u0026gt;stride; outBuffer-\u0026gt;format = backBuffer-\u0026gt;format; outBuffer-\u0026gt;bits = vaddr; } dequeueBuffer int Surface::dequeueBuffer(android_native_buffer_t** buffer, int* fenceFd) { status_t result = mGraphicBufferProducer-\u0026gt;dequeueBuffer(\u0026amp;buf, \u0026amp;fence, reqWidth, reqHeight, reqFormat, reqUsage, \u0026amp;mBufferAge, enableFrameTimestamps ? \u0026amp;frameTimestamps : nullptr); sp\u0026lt;GraphicBuffer\u0026gt;\u0026amp; gbuf(mSlots[buf].buffer); if ((result \u0026amp; IGraphicBufferProducer::BUFFER_NEEDS_REALLOCATION) || gbuf == nullptr) { result = mGraphicBufferProducer-\u0026gt;requestBuffer(buf, \u0026amp;gbuf); } *buffer = gbuf.get(); return OK; } requestBuffer\nframeworks/native/libs/ui/GraphicBuffer.cpp\nGraphicBuffer GraphicBuffer::GraphicBuffer(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t usage, std::string requestorName) : GraphicBuffer() { mInitCheck = initWithSize(inWidth, inHeight, inFormat, inLayerCount, usage, std::move(requestorName)); } com from dequeueBuffer\ninitWithSize status_t GraphicBuffer::initWithSize(uint32_t inWidth, uint32_t inHeight, PixelFormat inFormat, uint32_t inLayerCount, uint64_t inUsage, std::string requestorName) { GraphicBufferAllocator\u0026amp; allocator = GraphicBufferAllocator::get(); uint32_t outStride = 0; status_t err = allocator.allocate(inWidth, inHeight, inFormat, inLayerCount, inUsage, \u0026amp;handle, \u0026amp;outStride, mId, std::move(requestorName)); return err; } frameworks/native/libs/ui/GraphicBufferAllocator.cpp\nGraphicBufferAllocator GraphicBufferMapper\u0026amp; mMapper; const std::unique_ptr\u0026lt;const Gralloc2::Allocator\u0026gt; mAllocator; allocate status_t GraphicBufferAllocator::allocate(uint32_t width, uint32_t height, PixelFormat format, uint32_t layerCount, uint64_t usage, buffer_handle_t* handle, uint32_t* stride, uint64_t /*graphicBufferId*/, std::string requestorName) { Gralloc2::IMapper::BufferDescriptorInfo info = {}; info.width = width; info.height = height; info.layerCount = layerCount; info.format = static_cast\u0026lt;Gralloc2::PixelFormat\u0026gt;(format); info.usage = usage; Gralloc2::Error error = mAllocator-\u0026gt;allocate(info, stride, handle); } frameworks/native/libs/ui/include/ui/Gralloc2.h\nAllocator // A wrapper to IAllocator class Allocator { sp\u0026lt;IAllocator\u0026gt; mAllocator } Allocator::Allocator(const Mapper\u0026amp; mapper) : mMapper(mapper) { mAllocator = IAllocator::getService(); } allocate Error Allocator::allocate(BufferDescriptor descriptor, uint32_t count, uint32_t* outStride, buffer_handle_t* outBufferHandles) const { Error error; auto ret = mAllocator-\u0026gt;allocate(descriptor, count, [\u0026amp;](const auto\u0026amp; tmpError, const auto\u0026amp; tmpStride, const auto\u0026amp; tmpBuffers) { error = tmpError; if (tmpError != Error::NONE) { return; } // import buffers  for (uint32_t i = 0; i \u0026lt; count; i++) { error = mMapper.importBuffer(tmpBuffers[i], \u0026amp;outBufferHandles[i]); if (error != Error::NONE) { for (uint32_t j = 0; j \u0026lt; i; j++) { mMapper.freeBuffer(outBufferHandles[j]); outBufferHandles[j] = nullptr; } return; } } *outStride = tmpStride; }); // make sure the kernel driver sees BC_FREE_BUFFER and closes the fds now  hardware::IPCThreadState::self()-\u0026gt;flushCommands(); return (ret.isOk()) ? error : kTransactionError; } hardware/interfaces/graphics/allocator/2.0/IAllocator.hal\ninterface IAllocator /** * Allocates buffers with the properties specified by the descriptor. * * @param descriptor specifies the properties of the buffers to allocate. * @param count is the number of buffers to allocate. * @return error is NONE upon success. Otherwise, * BAD_DESCRIPTOR when the descriptor is invalid. * NO_RESOURCES when the allocation cannot be fulfilled at this * time. * UNSUPPORTED when any of the property encoded in the descriptor * is not supported. * @return stride is the number of pixels between two consecutive rows of * the buffers, when the concept of consecutive rows is defined. * Otherwise, it has no meaning. * @return buffers is an array of raw handles to the newly allocated * buffers. */ @entry @exit @callflow(next=\u0026#34;*\u0026#34;) allocate(BufferDescriptor descriptor, uint32_t count) generates (Error error, uint32_t stride, vec\u0026lt;handle\u0026gt; buffers); frameworks/native/libs/ui/include/ui/BufferQueueDefs.h\nBufferQueueDefs.h NUM_BUFFER_SLOTS namespace android { namespace BufferQueueDefs { // BufferQueue will keep track of at most this value of buffers.  // Attempts at runtime to increase the number of buffers past this  // will fail.  static constexpr int NUM_BUFFER_SLOTS = 64; } // namespace BufferQueueDefs } // namespace android  ThreadedRenderer create /** * Creates a threaded renderer using OpenGL. * * @param translucent True if the surface is translucent, false otherwise * * @return A threaded renderer backed by OpenGL. */ public static ThreadedRenderer create(Context context, boolean translucent, String name) { ThreadedRenderer renderer = null; if (isAvailable()) { renderer = new ThreadedRenderer(context, translucent, name); } return renderer; } ThreadedRenderer() ThreadedRenderer(Context context, boolean translucent, String name) { long rootNodePtr = nCreateRootRenderNode(); mRootNode = RenderNode.adopt(rootNodePtr); mRootNode.setClipToBounds(false); mIsOpaque = !translucent; mNativeProxy = nCreateProxy(translucent, rootNodePtr); nSetName(mNativeProxy, name); ProcessInitializer.sInstance.init(context, mNativeProxy); loadSystemProperties(); } initialize /** * Initializes the threaded renderer for the specified surface. * @param surface The surface to render * @return True if the initialization was successful, false otherwise. */ boolean initialize(Surface surface) throws OutOfResourcesException { updateEnabledState(surface); nInitialize(mNativeProxy, surface); return status; } android_view_ThreadedRenderer_initialize\nframeworks/base/core/jni/android_view_ThreadedRenderer.cpp\nandroid_view_ThreadedRenderer android_view_ThreadedRenderer_initialize static void android_view_ThreadedRenderer_initialize(JNIEnv* env, jobject clazz, jlong proxyPtr, jobject jsurface) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); sp\u0026lt;Surface\u0026gt; surface = android_view_Surface_getSurface(env, jsurface); proxy-\u0026gt;initialize(surface); } RenderProxy\nAttachInfo /** * A set of information given to a view when it is attached to its parent * window. */ final static class AttachInfo { } RenderNode adopt /** * Adopts an existing native render node. */ public static RenderNode adopt(long nativePtr) { return new RenderNode(nativePtr); } frameworks/base/core/jni/android_view_ThreadedRenderer.cpp\nandroid_view_ThreadedRenderer android_view_ThreadedRenderer_createRootRenderNode static jlong android_view_ThreadedRenderer_createRootRenderNode(JNIEnv* env, jobject clazz) { RootRenderNode* node = new RootRenderNode(env); node-\u0026gt;incStrong(0); node-\u0026gt;setName(\u0026#34;RootRenderNode\u0026#34;); return reinterpret_cast\u0026lt;jlong\u0026gt;(node); } android_view_ThreadedRenderer_createProxy static jlong android_view_ThreadedRenderer_createProxy(JNIEnv* env, jobject clazz, jboolean translucent, jlong rootRenderNodePtr) { RootRenderNode* rootRenderNode = reinterpret_cast\u0026lt;RootRenderNode*\u0026gt;(rootRenderNodePtr); ContextFactoryImpl factory(rootRenderNode); return (jlong) new RenderProxy(translucent, rootRenderNode, \u0026amp;factory); } android_view_ThreadedRenderer_syncAndDrawFrame static int android_view_ThreadedRenderer_syncAndDrawFrame(JNIEnv* env, jobject clazz, jlong proxyPtr, jlongArray frameInfo, jint frameInfoSize) { RenderProxy* proxy = reinterpret_cast\u0026lt;RenderProxy*\u0026gt;(proxyPtr); env-\u0026gt;GetLongArrayRegion(frameInfo, 0, frameInfoSize, proxy-\u0026gt;frameInfo()); return proxy-\u0026gt;syncAndDrawFrame(); } frameworks/base/libs/hwui/renderthread/RenderProxy.cpp\nRenderProxy.cpp RenderProxy() RenderProxy::RenderProxy(bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) : mRenderThread(RenderThread::getInstance()), mContext(nullptr) { mContext = mRenderThread.queue().runSync([\u0026amp;]() -\u0026gt; CanvasContext* { return CanvasContext::create(mRenderThread, translucent, rootRenderNode, contextFactory); }); mDrawFrameTask.setContext(\u0026amp;mRenderThread, mContext, rootRenderNode); } CanvasContext\ninitialize void RenderProxy::initialize(const sp\u0026lt;Surface\u0026gt;\u0026amp; surface) { mRenderThread.queue().post( [ this, surf = surface ]() mutable { mContext-\u0026gt;setSurface(std::move(surf)); }); } CanvasContext\nsyncAndDrawFrame int RenderProxy::syncAndDrawFrame() { return mDrawFrameTask.drawFrame(); } DrawFrameTask\nRenderThread getInstance RenderThread\u0026amp; RenderThread::getInstance() { // This is a pointer because otherwise __cxa_finalize  // will try to delete it like a Good Citizen but that causes us to crash  // because we don\u0026#39;t want to delete the RenderThread normally.  static RenderThread* sInstance = new RenderThread(); gHasRenderThreadInstance = true; return *sInstance; } RenderThread() RenderThread::RenderThread() : ThreadBase() , mVsyncSource(nullptr) , mVsyncRequested(false) , mFrameCallbackTaskPending(false) , mRenderState(nullptr) , mEglManager(nullptr) , mVkManager(nullptr) { Properties::load(); start(\u0026#34;RenderThread\u0026#34;); } threadLoop bool RenderThread::threadLoop() { setpriority(PRIO_PROCESS, 0, PRIORITY_DISPLAY); if (gOnStartHook) { gOnStartHook(); } initThreadLocals(); while (true) { waitForWork(); processQueue(); ...... requestVsync(); } return false; } initThreadLocals void RenderThread::initThreadLocals() { mDisplayInfo = DeviceInfo::queryDisplayInfo(); nsecs_t frameIntervalNanos = static_cast\u0026lt;nsecs_t\u0026gt;(1000000000 / mDisplayInfo.fps); mTimeLord.setFrameInterval(frameIntervalNanos); initializeDisplayEventReceiver(); mEglManager = new EglManager(*this); mRenderState = new RenderState(*this); mVkManager = new VulkanManager(*this); mCacheManager = new CacheManager(mDisplayInfo); } initializeDisplayEventReceiver void RenderThread::initializeDisplayEventReceiver() { LOG_ALWAYS_FATAL_IF(mVsyncSource, \u0026#34;Initializing a second DisplayEventReceiver?\u0026#34;); if (!Properties::isolatedProcess) { auto receiver = std::make_unique\u0026lt;DisplayEventReceiver\u0026gt;(); status_t status = receiver-\u0026gt;initCheck(); // Register the FD  mLooper-\u0026gt;addFd(receiver-\u0026gt;getFd(), 0, Looper::EVENT_INPUT, RenderThread::displayEventReceiverCallback, this); mVsyncSource = new DisplayEventReceiverWrapper(std::move(receiver)); } else { mVsyncSource = new DummyVsyncSource(this); } } frameworks/base/libs/hwui/thread/ThreadBase.h\nThreadBase waitForWork void waitForWork() { nsecs_t nextWakeup; { std::unique_lock lock{mLock}; nextWakeup = mQueue.nextWakeup(lock); } int timeout = -1; if (nextWakeup \u0026lt; std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max()) { timeout = ns2ms(nextWakeup - WorkQueue::clock::now()); if (timeout \u0026lt; 0) timeout = 0; } int result = mLooper-\u0026gt;pollOnce(timeout); LOG_ALWAYS_FATAL_IF(result == Looper::POLL_ERROR, \u0026#34;RenderThread Looper POLL_ERROR!\u0026#34;); } ThreadBase() ThreadBase() : Thread(false) , mLooper(new Looper(false)) , mQueue([this]() { mLooper-\u0026gt;wake(); }, mLock) {} processQueue void processQueue() { mQueue.process(); } frameworks/base/libs/hwui/thread/WorkQueue.h\nWorkQueue std::function\u0026lt;void()\u0026gt; mWakeFunc; std::vector\u0026lt;WorkItem\u0026gt; mWorkQueue; struct WorkItem struct WorkItem { nsecs_t runAt; std::function\u0026lt;void()\u0026gt; work; }; nextWakeup nsecs_t nextWakeup(std::unique_lock\u0026lt;std::mutex\u0026gt;\u0026amp; lock) { if (mWorkQueue.empty()) { return std::numeric_limits\u0026lt;nsecs_t\u0026gt;::max(); } else { return std::begin(mWorkQueue)-\u0026gt;runAt; } } enqueue void enqueue(WorkItem\u0026amp;\u0026amp; item) { bool needsWakeup; { std::unique_lock _lock{mLock}; auto insertAt = std::find_if( std::begin(mWorkQueue), std::end(mWorkQueue), [time = item.runAt](WorkItem \u0026amp; item) { return item.runAt \u0026gt; time; }); needsWakeup = std::begin(mWorkQueue) == insertAt; mWorkQueue.emplace(insertAt, std::move(item)); } if (needsWakeup) { mWakeFunc(); } } process void process() { auto now = clock::now(); std::vector\u0026lt;WorkItem\u0026gt; toProcess; { std::unique_lock _lock{mLock}; if (mWorkQueue.empty()) return; toProcess = std::move(mWorkQueue); auto moveBack = find_if(std::begin(toProcess), std::end(toProcess), [\u0026amp;now](WorkItem\u0026amp; item) { return item.runAt \u0026gt; now; }); if (moveBack != std::end(toProcess)) { mWorkQueue.reserve(std::distance(moveBack, std::end(toProcess)) + 5); std::move(moveBack, std::end(toProcess), std::back_inserter(mWorkQueue)); toProcess.erase(moveBack, std::end(toProcess)); } } for (auto\u0026amp; item : toProcess) { item.work(); } } frameworks/base/libs/hwui/renderthread/CanvasContext.cpp\nCanvasContext create CanvasContext* CanvasContext::create(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory) { auto renderType = Properties::getRenderPipelineType(); switch (renderType) { case RenderPipelineType::OpenGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;OpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaGL: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaOpenGLPipeline\u0026gt;(thread)); case RenderPipelineType::SkiaVulkan: return new CanvasContext(thread, translucent, rootRenderNode, contextFactory, std::make_unique\u0026lt;skiapipeline::SkiaVulkanPipeline\u0026gt;(thread)); default: LOG_ALWAYS_FATAL(\u0026#34;canvas context type %d not supported\u0026#34;, (int32_t)renderType); break; } return nullptr; } come from RenderProxy\nCanvasContext() CanvasContext::CanvasContext(RenderThread\u0026amp; thread, bool translucent, RenderNode* rootRenderNode, IContextFactory* contextFactory, std::unique_ptr\u0026lt;IRenderPipeline\u0026gt; renderPipeline) : mRenderThread(thread) , mGenerationID(0) , mOpaque(!translucent) , mAnimationContext(contextFactory-\u0026gt;createAnimationContext(mRenderThread.timeLord())) , mJankTracker(\u0026amp;thread.globalProfileData(), thread.mainDisplayInfo()) , mProfiler(mJankTracker.frames()) , mContentDrawBounds(0, 0, 0, 0) , mRenderPipeline(std::move(renderPipeline)) { rootRenderNode-\u0026gt;makeRoot(); mRenderNodes.emplace_back(rootRenderNode); mRenderThread.renderState().registerCanvasContext(this); mProfiler.setDensity(mRenderThread.mainDisplayInfo().density); } setSurface void CanvasContext::setSurface(sp\u0026lt;Surface\u0026gt;\u0026amp;\u0026amp; surface) { mNativeSurface = std::move(surface); ColorMode colorMode = mWideColorGamut ? ColorMode::WideColorGamut : ColorMode::Srgb; bool hasSurface = mRenderPipeline-\u0026gt;setSurface(mNativeSurface.get(), mSwapBehavior, colorMode); } called by RenderProxy\ndraw void CanvasContext::draw() { mCurrentFrameInfo-\u0026gt;markIssueDrawCommandsStart(); Frame frame = mRenderPipeline-\u0026gt;getFrame(); SkRect windowDirty = computeDirtyRect(frame, \u0026amp;dirty); bool drew = mRenderPipeline-\u0026gt;draw(frame, windowDirty, dirty, mLightGeometry, \u0026amp;mLayerUpdateQueue, mContentDrawBounds, mOpaque, mWideColorGamut, mLightInfo, mRenderNodes, \u0026amp;(profiler())); bool didSwap = mRenderPipeline-\u0026gt;swapBuffers(frame, drew, windowDirty, mCurrentFrameInfo, \u0026amp;requireSwap); } frameworks/base/libs/hwui/FrameInfo.h\nFrameInfo FrameInfoIndex enum class FrameInfoIndex { Flags = 0, IntendedVsync, Vsync, OldestInputEvent, NewestInputEvent, HandleInputStart, AnimationStart, PerformTraversalsStart, DrawStart, // End of UI frame info  SyncQueued, SyncStart, IssueDrawCommandsStart, SwapBuffers, FrameCompleted, DequeueBufferDuration, QueueBufferDuration, // Must be the last value!  // Also must be kept in sync with FrameMetrics.java#FRAME_STATS_COUNT  NumIndexes }; frameworks/base/libs/hwui/renderthread/OpenGLPipeline.cpp\nOpenGLPipeline setSurface bool OpenGLPipeline::setSurface(Surface* surface, SwapBehavior swapBehavior, ColorMode colorMode) { if (surface) { const bool wideColorGamut = colorMode == ColorMode::WideColorGamut; mEglSurface = mEglManager.createSurface(surface, wideColorGamut); } return false; } frameworks/base/libs/hwui/renderthread/EglManager.cpp\nEglManager createSurface EGLSurface EglManager::createSurface(EGLNativeWindowType window, bool wideColorGamut) { initialize(); EGLSurface surface = eglCreateWindowSurface( mEglDisplay, wideColorGamut ? mEglConfigWideGamut : mEglConfig, window, attribs); return surface; } DrawFrameTask setContext void DrawFrameTask::setContext(RenderThread* thread, CanvasContext* context, RenderNode* targetNode) { mRenderThread = thread; mContext = context; mTargetNode = targetNode; } drawFrame int DrawFrameTask::drawFrame() { postAndWait(); return mSyncResult; } postAndWait void DrawFrameTask::postAndWait() { AutoMutex _lock(mLock); mRenderThread-\u0026gt;queue().post([this]() { run(); }); mSignal.wait(mLock); } called by RenderProxy\nrun void DrawFrameTask::run() { canUnblockUiThread = syncFrameState(info); // Grab a copy of everything we need  CanvasContext* context = mContext; // From this point on anything in \u0026#34;this\u0026#34; is *UNSAFE TO ACCESS*  if (canUnblockUiThread) { unblockUiThread(); } if (CC_LIKELY(canDrawThisFrame)) { context-\u0026gt;draw(); } else { // wait on fences so tasks don\u0026#39;t overlap next frame  context-\u0026gt;waitOnFences(); } if (!canUnblockUiThread) { unblockUiThread(); } } CanvasContext\nLooper wake void Looper::wake() { uint64_t inc = 1; ssize_t nWrite = TEMP_FAILURE_RETRY(write(mWakeEventFd, \u0026amp;inc, sizeof(uint64_t))); if (nWrite != sizeof(uint64_t)) { if (errno != EAGAIN) { LOG_ALWAYS_FATAL(\u0026#34;Could not write wake signal to fd %d: %s\u0026#34;, mWakeEventFd, strerror(errno)); } } } "
},
{
	"uri": "https://huanle19891345.github.io/en/categories/androidx/",
	"title": "AndroidX",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/categories/bitmap/",
	"title": "Bitmap",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/categories/home/",
	"title": "home",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/first_post-copy/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://huanle19891345.github.io/en/android/androidx/first_post/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
}]